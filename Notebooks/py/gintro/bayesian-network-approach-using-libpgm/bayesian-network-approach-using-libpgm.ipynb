{"cells":[{"metadata":{"_uuid":"e25eb14f67d3832a0b33c202b414b65024ce0a3c"},"cell_type":"markdown","source":"## Bayesian network approach using libpgm\n\nIn this tutorial I show how to implement a Bayesian network on the Titanic dataset. I employ the python Libpgm library for modeling the network in three different and independent ways: \n    1. the structure and the parameters (CPD) at each node are defined and calculated manually, the library is thus used to encode this information. \n    2. the library is applied to calculate the structure of the network\n    3. the library calculates both the strucuture and the parameters of the network"},{"metadata":{"_execution_state":"idle","collapsed":true,"_uuid":"84a4dbee796e4853efe0dcb3cc22be9358b34dad","trusted":false},"cell_type":"code","source":"import pandas as pd\nimport graphviz as gv\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19b2c5e01b4867e16305d10d4fbc942e2438ba8e"},"cell_type":"markdown","source":"## Data Dictionary\n\n* Variable\tDefinition\tKey\n* survival \tSurvival \t0 = No, 1 = Yes\n* pclass \tTicket class \t1 = 1st, 2 = 2nd, 3 = 3rd\n* sex \tSex \t\n* Age \tAge in years \t\n* sibsp \t# of siblings / spouses aboard the Titanic \t\n* parch \t# of parents / children aboard the Titanic \t\n* ticket \tTicket number \t\n* fare \tPassenger fare \t\n* cabin \tCabin number \t\n* embarked \tPort of Embarkation \tC = Cherbourg, Q = Queenstown, S = Southampton\n\n### Variable Notes\n\n* pclass: A proxy for socio-economic status (SES)\n - 1st = Upper\n - 2nd = Middle\n - 3rd = Lower\n\n* age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\n* sibsp: The dataset defines family relations in this way...\n    Sibling = brother, sister, stepbrother, stepsister\n    Spouse = husband, wife (mistresses and fianc√©s were ignored)\n\n* parch: The dataset defines family relations in this way...\n    Parent = mother, father\n    Child = daughter, son, stepdaughter, stepson\n    Some children travelled only with a nanny, therefore parch=0 for them."},{"metadata":{"_uuid":"e31e6c0126aae071d4669ea5d9d143db05e6e78b"},"cell_type":"markdown","source":"**Bayesian network** is a special case of graphical Models. Graphical models solve the problem of defining the joint probability distribution, which is is difficult and requires a huge number of parameters.\n\nIn particular, Bayesian Networks present the following properties: \n * The independence assumptions made in a BN allows to avoid specifying the joint distributions. \n * A BN is a directed acyclic graph, and it allows a compact and modular representation of the joint probability distribution (probabilities at vertices are the local probability models). It allows to observe the conditional independence.\n * In general, each variable X in the model is associated with a conditional probability distribution (CPD) that specifies a distribution over the values of X for each possible joint assignment of its parents in the model (local distributions). For a node with no parents, the CPD is conditioned on the empty set of variables, and can be seen as a marginal distribution (or prior).\n * A BN consist of a structure and the CPDs. The chain rule for BN allows to express the joint distributions as a product of CPDs <br\\>\n => P(X1 , X2 , ... , Xn ) = Product_i  P(X_i | Parents( X_i )). "},{"metadata":{"_uuid":"ac63f50c17fe50b50ac36dbe147f663108f3fc18"},"cell_type":"markdown","source":"### Libpgm library\n\nThe library reads the network information (nodes, edges, and CPD probabilities) from a JSON-formatted\nfile with a specific format. This JSON file is read into\n* NodeData \n* GraphSkeleton"},{"metadata":{"_execution_state":"idle","collapsed":true,"_uuid":"084d952c91500cdcae8168109f92c86595412444","trusted":false},"cell_type":"code","source":"from libpgm.graphskeleton import GraphSkeleton\nfrom libpgm.nodedata import NodeData","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e068451170f6d00f0de9b261a8a4df8a8e4ac77f"},"cell_type":"markdown","source":"The TableCPDFactorization object wraps the discrete Bayesian network and allows us to query the CPDs in the network.\n\nTo make queries: use \n> table_cpd=getTableCPD() <br\\>\n> table_cpd.specificquery(dict(Offer='1'),dict(Grades='0'))\n\nIn BN parlance, the first argument is the \"query\" whilst the second corresponds to the \"evidence\". "},{"metadata":{"collapsed":true,"_uuid":"1d7b403b1a23e40ab13e12802f284fc68509c67f","trusted":false},"cell_type":"code","source":"from libpgm.tablecpdfactorization import TableCPDFactorization","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a5c62ab8ee3bb22358f79e03bbd93e80b4f1ac7a"},"cell_type":"markdown","source":"In this tutorial I'm using a discrete Bayesian network (variables take on only discrete\nvalues)."},{"metadata":{"collapsed":true,"_uuid":"3fcd3e647447b81248ad3f960a40323cb91230b3","trusted":false},"cell_type":"code","source":"from libpgm.discretebayesiannetwork import DiscreteBayesianNetwork","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"201a752ea90c6370b088767041f7a6fc0e73c637"},"cell_type":"markdown","source":"## Prepare training data"},{"metadata":{"collapsed":true,"_uuid":"28ccbc5ac72c8833b3a96dd736b894aaf40d99c1","trusted":false},"cell_type":"code","source":"df_input = pd.read_csv('../input/train.csv', sep=',')\ndf_test  = pd.read_csv('../input/test.csv', sep=',')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8c7e88dc2b8dffcfe66803e4e7ef50d7478396e"},"cell_type":"markdown","source":"For the sole purpose of illustrating how to use BN on a dataset, I'll keep only a few features in what follows"},{"metadata":{"collapsed":true,"_uuid":"5df7b0c4977b41b6bca780d14c211777e48af6c8","trusted":false},"cell_type":"code","source":"df_train            = df_input[['Survived', 'Pclass','Sex', 'Fare']][df_input.Fare!=0].dropna()\ndf_train.dropna(inplace=True)\ndf_train.loc[:,'Sex']  = df_train.Sex.map({'female':0 , 'male':1})\n\n# Fare is arbitrary divided in two categories: cheap and expensive\ndf_train.loc[:,'Fare'] = pd.cut(df_train.Fare, [df_input.Fare.min(),15, df_input.Fare.max()], labels =[0,1])\ndf_train = df_train.rename(columns = {'Survived' : 'Surv'})\ndf_train_target        = df_train['Surv']","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"fbb58e4f76d7502d1e966148b1600ae3820d52b0","trusted":false},"cell_type":"code","source":"def get_probs_surv_cond(df, df_target, Surv, Pclass, Sex):\n    # Return survival probability conditioned on Class and Sex\n    # P(Surv | Sex, Pclass)\n    return (df[ (df.Surv==Surv) & (df.Pclass==Pclass) & (df.Sex==Sex)].shape[0]\n            /(1.0*df[(df.Pclass==Pclass) & (df.Sex==Sex)].shape[0]))\n\ndef format_data(df):\n    result = []\n    for row in df.itertuples():\n        #print(row.Pclass)\n        result.append(dict(Surv= row.Surv, Class=row.Pclass , Sex=row.Sex, Fare=row.Fare ))\n    return result\n\ndef calc_BNprob(df_test):\n    \n    result = pd.Series()\n    \n    for row in df_test.itertuples():\n        tablecpd=TableCPDFactorization(bn)\n        prob_surv = tablecpd.specificquery(dict(Surv='1'), dict(Fare=str(row.Fare) , Sex=str(row.Sex) , Class=str(row.Pclass) ))\n\n        if prob_surv >= 0.5:\n            surv_class = 1\n        else:\n            surv_class  = 0        \n        result = result.append(pd.Series([surv_class]), ignore_index = True )\n    return result\n\ndef calc_accuracy(dff_train, dff_train_target, nb_iterations):\n    \n    result = np.zeros(nb_iterations)\n\n    for itera in range(nb_iterations):\n        XX_train, XX_test, yy_train, yy_test = train_test_split(dff_train, dff_train_target, test_size=0.33)\n        data4bn = format_data(XX_train)\n        learner = PGMLearner()\n        # estimate parameters\n        result_bn = learner.discrete_mle_estimateparams(skel, data4bn)\n        #result_bn.Vdata\n        result_predict = calc_BNprob(XX_test)\n        BN_test_probs = pd.DataFrame()\n        BN_test_probs['ground_truth'] = yy_test\n        Test_prob = pd.concat([yy_test.reset_index().Surv, result_predict],  axis = 1, ignore_index = True)\\\n                    .rename(columns = {0:'ground_truth' , 1:'class_resu'})\n        accuracy = Test_prob[Test_prob.ground_truth == Test_prob.class_resu].shape[0]/(1.0*Test_prob.shape[0])\n        #print(\"Accuracy is {}\").format(accuracy)\n        result[itera] = accuracy\n        \n    return result","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13643712f1a2387d2f0a6d56237b6bd517cb0352"},"cell_type":"markdown","source":"## Structure and parameters  defined"},{"metadata":{"_uuid":"048dd29adf3a57715af4e2ce93665ea8b766e71c"},"cell_type":"raw","source":"Now I will manually calculate the CPD's. I'm assuming that the Fare is directly related to the Class, and hence the BN looks like this:\n\n    Fare\n      |\n    Class   Sex\n        \\   /\n         \\ /\n        Surv"},{"metadata":{"_uuid":"442f046680616c19ebe107026b3dd21fb49ac19d"},"cell_type":"markdown","source":"### Calculating the CPDs"},{"metadata":{"_uuid":"f81add4d077c8686fc854948e802b5c8168b00a5","trusted":false,"collapsed":true},"cell_type":"code","source":"print (\"P(Class|Fare)\")\nprint (\"Class= 1, 2 ,3  ; Fare = 0 (cheap):\")\nprint(df_train[(df_train.Fare==0) & (df_train.Pclass==1)].shape[0] /(1.0*df_train[df_train.Fare==0].shape[0]),\ndf_train[(df_train.Fare==0) & (df_train.Pclass==2)].shape[0] /(1.0*df_train[df_train.Fare==0].shape[0]),\ndf_train[(df_train.Fare==0) & (df_train.Pclass==3)].shape[0]/(1.0*df_train[df_train.Fare==0].shape[0]))\nprint (\"Class= 1, 2 ,3  ; Fare = 1 (expensive):\")\nprint(df_train[(df_train.Fare==1) & (df_train.Pclass==1)].shape[0] /(1.0*df_train[df_train.Fare==1].shape[0]),\ndf_train[(df_train.Fare==1) & (df_train.Pclass==2)].shape[0] /(1.0*df_train[df_train.Fare==1].shape[0]),\ndf_train[(df_train.Fare==1) & (df_train.Pclass==3)].shape[0]/(1.0*df_train[df_train.Fare==1].shape[0]))\n\n#Sex: Prior probability\nprint(\"------------\")\nprint (\"P(Sex)\")\nprint (\"Sex = 0 (female), 1 (male)\")\nprint (df_train[df_train.Sex==0].shape[0]/float(df_train.Sex.shape[0]) , \n       df_train[df_train.Sex==1].shape[0]/float(df_train.Sex.shape[0]))\n\n# Surv Probability\nprint(\"------------\")\nprint(\"P(Surv|Class,Sex)\")\nprint(\"Surv = 0 ,1 , Class = 1 , Sex = 0\")\nprint(get_probs_surv_cond(df_train, df_train_target, 0, 1, 0),\nget_probs_surv_cond(df_train, df_train_target, 1, 1, 0))\nprint(\"Surv = 0 ,1 , Class = 2 , Sex = 0\")\nprint(get_probs_surv_cond(df_train, df_train_target, 0, 2, 0),\nget_probs_surv_cond(df_train, df_train_target, 1, 2, 0))\nprint(\"Surv = 0 ,1 , Class = 3 , Sex = 0\")\nprint(get_probs_surv_cond(df_train, df_train_target, 0, 3, 0),\nget_probs_surv_cond(df_train, df_train_target, 1, 3, 0))\nprint(\"Surv = 0 ,1 , Class = 1 , Sex = 1\")\nprint(get_probs_surv_cond(df_train, df_train_target, 0, 1, 1),\nget_probs_surv_cond(df_train, df_train_target, 1, 1, 1))\nprint(\"Surv = 0 ,1 , Class = 2 , Sex = 1\")\nprint(get_probs_surv_cond(df_train, df_train_target, 0, 2, 1),\nget_probs_surv_cond(df_train, df_train_target, 1, 2, 1))\nprint(\"Surv = 0 ,1 , Class = 3 , Sex = 1\")\nprint(get_probs_surv_cond(df_train, df_train_target, 0, 3, 1),\nget_probs_surv_cond(df_train, df_train_target, 1, 3, 1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36a1d547199a65897853ce04baf5831c948b4a9e"},"cell_type":"markdown","source":"All these distributions (tables) are then written into a json file with the following format:"},{"metadata":{"_uuid":"4bb21c66b5aec82d46f351c12ff6364a21718950"},"cell_type":"raw","source":"{\n  \"V\": [\n    \"Surv\",\n    \"Class\",\n    \"Sex\",\n    \"Fare\"\n  ],\n  \"E\": [\n    [\n      \"Fare\",\n      \"Class\"\n    ],\n    [\n      \"Class\",\n      \"Surv\"\n    ],\n    [\n      \"Sex\",\n      \"Surv\"\n    ]\n  ],\n  \"Vdata\": {\n    \"Surv\": {\n      \"ord\": 3,\n      \"numoutcomes\": 2,\n      \"vals\": [\n        \"0\",\n        \"1\"\n      ],\n      \"parents\": [\n        \"Class\",\n        \"Sex\"\n      ],\n      \"children\": ,\n           ,\n        \"['2' , '0']\": [\n          0.079,\n          0.921\n        ],\n        \"['3' , '0']\": [\n          0.5,\n          0.5\n        ],\n        \"['1' , '1']\": [\n          0.631,\n          0.368\n        ],\n        \"['2' , '1']\": [\n          0.842,\n          0.157\n        ],\n        \"['3' , '1']\": [\n          0.864,\n          0.135\n        ]\n      }\n    },\n    \"Class\": {\n      \"ord\": 1,\n      \"numoutcomes\": 3,\n      \"vals\": [\n        \"1\",\n        \"2\",\n        \"3\"\n      ],\n      \"parents\": [\n        \"Fare\"\n      ],\n      \"children\": [\n        \"Surv\"\n      ],\n      \"cprob\": {\n        \"['0']\": [\n          0.002,\n          0.2,\n          0.797\n        ],\n        \"['1']\": [\n          0.485,\n          0.205,\n          0.31\n        ]\n      }\n    },\n    \"Sex\": {\n      \"ord\": 2,\n      \"numoutcomes\": 2,\n      \"vals\": [\n        \"0\",\n        \"1\"\n      ],\n      \"parents\": ,\n      \"children\": [\n        \"Surv\"\n      ],\n      \"cprob\": [\n        0.352,\n        0.647\n      ]\n    },\n    \"Fare\": {\n      \"ord\": 0,\n      \"numoutcomes\": 2,\n      \"vals\": [\n        \"0\",\n        \"1\"\n      ],\n      \"parents\": None,\n      \"children\": [\n        \"Class\"\n      ],\n      \"cprob\": [\n        0.505,\n        0.49\n      ]\n    }\n  }\n}"},{"metadata":{"_uuid":"ace0b7298441946ec60b7a05c5f9cc76b511e399"},"cell_type":"markdown","source":"In this file we define the probabilities at each node. \"cprob\" contains a dictionary if the node has at least one parent node. In this case, the keys of the dictionary are the values assigned to the parent nodes, whilst the values correspond to the probabilities of the nodes. \n    For example, in the Surv node, we find\n    \n    \"cprob\": {\n        \"['1' , '0']\": [\n          0.032,\n          0.968\n        ], (...)\n        \nThis means that the survival probability given Class=1 and Sex = 0 is 0.968; the prob of not survival given the same conditions is 0.032.       "},{"metadata":{"_uuid":"9314d34e94331f9f18e169823744ca4bfcb6f30d"},"cell_type":"markdown","source":"I now create a bayesian network in order to run queries on it, given \nsome evidence. In this case, we're not learning any parameters, \nwe've calculated them previously and we use them to define the net."},{"metadata":{"_uuid":"e7ec8168a416d5bce25b89167fd8a366303e0dc5","trusted":false,"collapsed":true},"cell_type":"code","source":"nd       = NodeData()\nskel     = GraphSkeleton()\njsonpath_skel =\"titanic_skel.json\"\njsonpath_node =\"titanic_nodes.json\"\nnd.load(jsonpath_node)\nskel.load(jsonpath_skel)\n\n# load bayesian network\nbn       = DiscreteBayesianNetwork(skel, nd)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4da66861534fbb878f76ada2c68e5058122f8055"},"cell_type":"raw","source":"print (skel.getchildren(\"Class\"),skel.getchildren(\"Sex\"),skel.getchildren(\"Fare\"),skel.getchildren(\"Surv\"))\n([u'Surv'], [u'Surv'], [u'Class'], [])"},{"metadata":{"_uuid":"c8f62868aac7920ba71f3e51bdfcc2b8b45766d4","trusted":false,"collapsed":true},"cell_type":"code","source":"# We can now start querying our network. We provide a query (first dictionary in the arguments)\n# and an evidence (second dictionary in the args))\n\ntablecpd=TableCPDFactorization(bn)\nprint (\"P(Surv=0) = {}\".format(tablecpd.specificquery(dict(Surv='0'),dict())))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a06ff18788c047000f22c3e1028d09703ae05e0","trusted":false,"collapsed":true},"cell_type":"code","source":"tablecpd=TableCPDFactorization(bn)\nprint(\"P(Surv = 1) = {}\".format(tablecpd.specificquery(dict(Surv='1'),dict())))\n\ntablecpd=TableCPDFactorization(bn)\nprint(\"P(Surv = 1 | Fare = 0) = {}\".format(tablecpd.specificquery(dict(Surv='1'),dict(Fare='0'))))\ntablecpd=TableCPDFactorization(bn)\nprint(\"P(Surv = 1 | Fare = 1) = {}\".format(tablecpd.specificquery(dict(Surv='1'),dict(Fare='1'))))\ntablecpd=TableCPDFactorization(bn)\nprint(\"P(Surv = 1 | Fare = 1, Sex = 0) = {}\".format(tablecpd.specificquery(dict(Surv='1'),dict(Fare='1' , Sex='0'))))\ntablecpd=TableCPDFactorization(bn)\nprint(\"P(Surv = 1 | Fare = 1, Sex = 1, Class=3) = {}\".format(tablecpd.specificquery(dict(Surv='1'),dict(Fare='1' , Sex='1' , Class='3'))))\ntablecpd=TableCPDFactorization(bn)\nprint(\"P(Surv = 1 | Fare = 1, Sex = 1) = {}\".format(tablecpd.specificquery(dict(Surv='1'),dict(Fare='1' , Sex='1'))))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"c745ddd3a0ca9c2e0e55c1930dd255689fe46ff7"},"cell_type":"markdown","source":"## Learning Parameters\n\nOur aim now is to calculate the parameters of the network. We provide the structure of the network \nand then let the algorithm learn the parameters.\n"},{"metadata":{"collapsed":true,"_uuid":"00c8e12e5792f031069ba476114591fa098fa545","trusted":false},"cell_type":"code","source":"from libpgm.pgmlearner import PGMLearner","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"d0806a904813053dd639a223d9a75a6516082626","trusted":false},"cell_type":"code","source":"training_data = format_data(df_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8d4005ac74cbb5b26491d474123bc4032d4b2c3"},"cell_type":"raw","source":"data has the following format:\n[{'Class': 3, 'Fare': 0, 'Sex': 1, 'Surv': 0},\n {'Class': 1, 'Fare': 1, 'Sex': 0, 'Surv': 1},\n {'Class': 3, 'Fare': 0, 'Sex': 0, 'Surv': 1},\n {'Class': 1, 'Fare': 1, 'Sex': 0, 'Surv': 1},...]"},{"metadata":{"_uuid":"272450931bb922edfb7dfa753f42a377459b7f6e","trusted":false,"collapsed":true},"cell_type":"code","source":"nd       = NodeData()\nskel     = GraphSkeleton()\n\n#The structure is defined in the file titanic_skel\njsonpath =\"titanic_skel.json\"\nskel.load(jsonpath)\n\n#instatiate the learner\nlearner = PGMLearner()\n\n# The methos estimates the parameters for a discrete Bayesian network with\n# a structure given by graphskeleton in order to maximize the probability \n# of data given by data\nresult_params = learner.discrete_mle_estimateparams(skel, training_data)\n\nresult_params.Vdata['Class']# to inspect the network","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a840cbf69b6b17210f8ebe800692356c92439e8e"},"cell_type":"markdown","source":"Check the prediction accuracy"},{"metadata":{"_uuid":"5a819451a4ee09011ff47fe81d0dcde5e3a39c73","trusted":false,"collapsed":true},"cell_type":"code","source":"#results = calc_accuracy(dff_train, dff_train_target, 100)\n#plt.hist(results, bins='auto')\ncalc_accuracy(df_train, df_train_target, 1)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"a89c10e7e031606533cbf8b7e0a73d5f372148da"},"cell_type":"markdown","source":"## Learning the structure"},{"metadata":{"_uuid":"88a3479bc165efe0bc553982f2924f39eaf098d7","trusted":false,"collapsed":true},"cell_type":"code","source":"#instatiate learner\nlearner_struc = PGMLearner()\n\n#load data and tranform it to a list of dictionaries\ndata = format_data(df_train)\n\n# This method learns a Bayesian network structure from discrete data given\n# by data, using constraint-based approaches. The function calls discrete_condind \n# (voir ci-dessous) to determine the dependencies between variables.\n# Possible params are:\n# * pvalparam is te value of the p-value used to determine whether two variables \n# are conditionally indep.(This is obviously necessary to find the net structure).\n# * indegree = is used to determine the size of the set of variables used to find dependencies\n# (basically the \"witness\" variables, this will determine the size of the array passed in the\n# third argument of the discrete_condind call). \n\nresult_structure = learner_struc.discrete_constraint_estimatestruct(data, indegree=1,pvalparam=0.05)\n\n# The result if always the same for any value of indegree\n# result is stable for smaller values of 0.05\n\n#The resulting structure is the identical\nresult_structure.getchildren('Fare'), result_structure.getchildren('Class')\nresult_structure.E","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"038b664ba2113d73c5b5b9ec2d80ce5a6bcb6b41","trusted":false},"cell_type":"code","source":"# We can thus use the skeleton defined before in jsonpath_skel to learn params\n# \n\nskel     = GraphSkeleton()\nskel.load(jsonpath_skel)\nbn_params2 = learner_struc.discrete_mle_estimateparams(skel, data)\n\n#use result_params2.Vdata to inspect the network\n# By looking at result_params2.Vdata we'll notice that the probabilities correpond \n# to the probabilities we calculated (manually) in the beginning.  ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"66561a750b29964b28461b69e75ce3b6c3de5671"},"cell_type":"markdown","source":"## Learning both the structure and the parameters"},{"metadata":{"collapsed":true,"_uuid":"34e06fc79192233818b62af332c782bdf519e43d","trusted":false},"cell_type":"code","source":"#instatiate the learner\nlearner_full = PGMLearner()\n\n# Learn structure and parameters. This method fully learns a BN from\n# discrete data given by data. This function combines the \n# discrete_constraint_estimatestruct method (where it passes in the \n# pvalparam and indegree arguments) with the discrete_mle_estimateparams method.\n# It returns a complete DiscreteBayesianNetwork class instance learned from the data\nresult_full_bn = learner_full.discrete_estimatebn(training_data)\n\n#result_full_bn.E","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"619150b9310e6dc21d2636a509562b180ef2880f","trusted":false},"cell_type":"code","source":"# We can also manually test and verify how independent two varaibles are","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b601e3390e70395fb1881ac3581682cbc52436c2","trusted":false,"collapsed":true},"cell_type":"code","source":"learner_indep = PGMLearner()\nlearner_indep.discrete_condind(training_data,'Surv', 'Fare', ['Class'])\n# In this case, the result is chi, pval et variable U\n\nlearner_indep = PGMLearner()\nprint(\"Chi, pval, U: {}{}\".format(learner_indep.discrete_condind(training_data,'Surv', 'Fare', ['Class']),\n      \"(Ho can't be rejected since Surv and Fare are cond independent)\"))\nprint(\"Chi, pval, U: {}{}\".format(learner_indep.discrete_condind(training_data,'Surv', 'Class', ['Fare']),\n                               \"(Ho is rejected: Surv and Class are not indep)\"))\nprint(\"Chi, pval, U: {}{}\".format(learner_indep.discrete_condind(training_data,'Sex', 'Class', ['Surv']),\n                               \"(Ho is rejected: Sex and Class are not indep)\"))\nprint(\"Chi, pval, U: {}\".format(learner_indep.discrete_condind(training_data,'Fare', 'Class', ['Sex'])))\nprint(\"Chi, pval, U: {}\".format(learner_indep.discrete_condind(training_data,'Fare', 'Sex', ['Sex'])))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7e7da4f9ce78e7c2e7176263499980dee3a0841"},"cell_type":"raw","source":"chi ‚Äì The result of the chi-squared test on the data (compare the actual and the expected distri of X and Y given U). The expected distribution is P(X,Y,U)=P(U)P(X|U)P(Y|U). The Chi squared is a measure of the deviance between two distributions.  \n    \npval ‚Äì The p-value of the test, meaning the probability of attaining a chi-square result as extreme as or more extreme than the one found, assuming that the null hypothesis is true. (e.g., a p-value of .05 means that if X and Y were independent given U, the chance of getting a chi-squared result this high or higher are .05). The Null H (independence) is rejected if the p-value is smaller than 0.05.\n\nU ‚Äì The ‚Äòwitness‚Äô of X and Y‚Äôs independence. This is the variable that, when it is known, leaves X and Y independent.\n\nRecall: conditional independence means: P(X|Y,Z) = P(X|Z) in this case X and Y are independent given Z. "},{"metadata":{"_uuid":"128f9e778960b8d3968183a21ccbc9866ca2c3c1"},"cell_type":"markdown","source":"# Random Notes"},{"metadata":{"collapsed":true,"_uuid":"a51d243c5654a7de13f7a724d5ba60f33f555e0c"},"cell_type":"markdown","source":"1. It is important to note another advantage of representing the joint distribution on a network: modularity.\nWhen you add a new variable G, the joint distribution changes entirely. Had we used the\nexplicit representation of the joint, we would have had to write down twelve new numbers. In\nthe factored representation, we could reuse our local probability models for the variables I and\nS, and specify only the probability model for G ‚Äî the CPD P (G | I). This property will turn\nout to be invaluable in modeling real-world systems.\n\n2. Bayesian networks build on the same intuitions as the naive Bayes model by exploiting con-\nditional independence properties of the distribution in order to allow a compact and natural\nrepresentation. However, they are not restricted to representing distributions satisfying the\nstrong independence assumptions implicit in the naive Bayes model. They allow us the flexibil-\nity to tailor our representation of the distribution to the independence properties that appear\nreasonable in the current setting.\n\n3. The core of the Bayesian network representation is a directed acyclic graph (DAG) G, whose\nnodes are the random variables in our domain and whose edges correspond, intuitively, to direct\ninfluence of one node on another.This graph G can be viewed in two very different ways:\n‚Ä¢ as a data structure that provides the skeleton for representing a joint distribution\ncompactly in a factorized way;as a compact representation for a set of conditional independence assumptions about\na distribution.\n\n4. Other librairies are: \n    * BNFinder: a lib for identification of optimal BN, fast and efficient (cross validations and ROC curves included) "},{"metadata":{"_execution_state":"idle","_uuid":"63e8517933b33b07c406c39ed276aae6e4963143","trusted":false,"collapsed":true},"cell_type":"markdown","source":"I provide below the content of \n\n* titanic_nodes.json:\n<pre>\n    <code>\n{\n\t\"Vdata\": {\n\t\t\"Surv\": {\n\t\t\t\"ord\": 3,\n\t\t\t\"numoutcomes\": 2,\n\t\t\t\"vals\": [\"0\", \"1\"],\n\t\t\t\"parents\": [\"Class\", \"Sex\"],\n\t\t\t\"children\": None,\n\t\t\t\"cprob\": {\n\t\t\t\t\"['1' , '0']\": [.032, .968],\n\t\t\t\t\"['2' , '0']\": [.079, .921],\n\t\t\t\t\"['3' , '0']\": [.5, .5],\n\t\t\t\t\"['1' , '1']\": [.631, .368],\n\t\t\t\t\"['2' , '1']\": [.842, .157],\n\t\t\t\t\"['3' , '1']\": [.864, .135]\n\t\t\t}\n\t\t},\n\t\t\"Class\": {\n\t\t\t\"ord\": 1,\n\t\t\t\"numoutcomes\": 3,\n\t\t\t\"vals\": [\"1\", \"2\", \"3\"],\n\t\t\t\"parents\": [\"Fare\"],\n\t\t\t\"children\": [\"Surv\"],\n\t\t\t\"cprob\": {\n\t\t\t\t\"['0']\": [.002, .2, .797],\n\t\t\t\t\"['1']\": [.485, .205, .31]\n\t\t\t}\n\t\t},\n\t\t\"Sex\": {\n\t\t\t\"ord\": 2,\n\t\t\t\"numoutcomes\": 2,\n\t\t\t\"vals\": [\"0\", \"1\"],\n\t\t\t\"parents\": None,\n\t\t\t\"children\": [\"Surv\"],\n\t\t\t\"cprob\": [.352, .647]\n\t\t},\n\t\t\"Fare\": {\n\t\t\t\"ord\": 0,\n\t\t\t\"numoutcomes\": 2,\n\t\t\t\"vals\": [\"0\", \"1\"],\n\t\t\t\"parents\": None,\n\t\t\t\"children\": [\"Class\"],\n\t\t\t\"cprob\": [.505, .49]\n\t\t}\n\t}\n}\n</code>\n</pre>    \n********\n\n* titanic_skel.json\n<pre>\n    <code>\n{\n\t\"V\": [\"Surv\", \"Class\", \"Sex\", \"Fare\"],\n\t\"E\": [\n\t\t[\"Fare\", \"Class\"],\n\t\t[\"Class\", \"Surv\"],\n\t\t[\"Sex\", \"Surv\"]\n\t]\n}\n</code>\n</pre>\n***********\n\nThere is a **None** value in the titanic_nodes.json (thus not a valid json in principle), but the load function is able to open the file.\n\n\n"},{"metadata":{"_uuid":"0f54c3d0bc664dcaff7df443fa93fe3c33c3e9f3"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c9c4c2ab1907767fa4b3032ffa939087b3bfdad1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}