{"cells":[{"metadata":{"_uuid":"942e5b8562a5cc0edd504eea58f0309166f03b03"},"cell_type":"markdown","source":"# Titanic Problem:\nWe want to discover which passengers survived through the data.\n\nThis notebook is divide by:\n* Data analysis\n* Feature Engineer at:\n   * Gender, Embarked type, Name, Age and Fare\n* Modeling with:\n   * KNeighborsClassifier, LogisticRegression, DecisionTreeClassifier, RandomForestClassifier\n   * Score and Cross-Validation"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3e2bbdda124dd57a947ac72c1c0649f87a934478"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":60,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3dad6b92669f8be5488067c743a03fc3ddc1b3a3"},"cell_type":"code","source":"titanic = pd.read_csv(\"../input/train.csv\")\ntitanic_test = pd.read_csv(\"../input/test.csv\")\n# Creating a list with two files, more accuracy for to the math to fill NaN values\ncombined = [titanic, titanic_test]","execution_count":61,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d867b40092d355cd0d381be72ada8a133dbec120"},"cell_type":"code","source":"titanic.head()","execution_count":62,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"faf2b1a674e40f0a70942102377ff4fe7656f47c"},"cell_type":"code","source":"titanic_test.head()","execution_count":63,"outputs":[]},{"metadata":{"_uuid":"39789c11fdcb5da880fc9f25cfd8b1ae7d3b861e"},"cell_type":"markdown","source":"## Working with Gender"},{"metadata":{"trusted":true,"_uuid":"5b15ffae386e14ad035b50c2d02fc6095074580c"},"cell_type":"code","source":"#Checking if exist some NaN value\nlen(titanic[titanic['Sex'].isnull()])","execution_count":64,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8f64e59248a469d0bfc1e7ca0e512fab15ce1bc"},"cell_type":"code","source":"#How many unique enters this array have.\ntitanic[\"Sex\"].unique()","execution_count":65,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"760d033643577683b446d151533c5889b7495b49"},"cell_type":"code","source":"#Checking which gender have more survivers\ntitanic[['Survived', 'Sex']].groupby('Sex').mean()","execution_count":66,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3440f96b012bbfc9676563960fc28d38f5526aa4"},"cell_type":"code","source":"# Replacing Categorical variables by continuous, with this for and this list(combined),\n# we can replace Sex in titanic and test_ticanic\n\ndicsex = {\"male\": 0, \"female\": 1}\nfor dfsex in combined:\n    dfsex['Sex'] = dfsex['Sex'].map(dicsex)\n    \n#other method    \n#titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n#titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1","execution_count":67,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54ad00b94305c62a6191b94a25b6a4c158dcaae0"},"cell_type":"code","source":"titanic.head()","execution_count":68,"outputs":[]},{"metadata":{"_uuid":"1184ab52db1641bf94b359edaa86f39d9181a271"},"cell_type":"markdown","source":"# Working with Embarked type"},{"metadata":{"trusted":true,"_uuid":"2bca232c98c5e487851c941e895da18186e73e8f"},"cell_type":"code","source":"#Checking if exist some NaN value\nlen(titanic[titanic['Embarked'].isnull()])","execution_count":69,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fde9c140a3ebeba720089c303ea7e292f97ea011"},"cell_type":"code","source":"titanic[titanic['Embarked'].isnull()]","execution_count":70,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e2ca4243f2596d0b10855cca890511c13ddbccc"},"cell_type":"code","source":"# Trying to found an insight, connecting all common variables of these people to predict where they embarked, without success\ntitanic[(titanic['Pclass'] == 1) & (titanic['Survived'] == 1) & (titanic['Sex'] == 1)].groupby('Embarked').sum()","execution_count":71,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b302e57259374b77c8de8d2d131a4b0ea481f113"},"cell_type":"code","source":"# Here we can see, at all classes most of people embarked on \"S\", so to fill this data with less variation we put \"S\".\nsns.countplot(x = 'Pclass', data = titanic, hue = 'Embarked')","execution_count":72,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1239708626dfe76d7da1b49ca89ff316c582fa53"},"cell_type":"code","source":"titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(\"S\")","execution_count":73,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e7fcebe4a009cab3f97228ea42f36324e63f18bd"},"cell_type":"code","source":"# Same concept to replace used at Sex column\ndic_embarked = {\"S\": 0, \"C\": 1, \"Q\": 2}\nfor df_embarked in combined:\n    df_embarked['Embarked'] = df_embarked['Embarked'].map(dic_embarked)","execution_count":74,"outputs":[]},{"metadata":{"_uuid":"f650e329a6fb61fbf0a4ec79d8481546a40111d0"},"cell_type":"markdown","source":"# Working with Name"},{"metadata":{"_uuid":"8e41482f972e93ee6e3ee15a94f265b473d6a9aa"},"cell_type":"markdown","source":"#Combining both Dataset, BECAUSE EXIST THE POSSIBILITY THAT IN ONE DF DOESN'T EXIST THE SAME PRONOUNS TREATMENT in the other"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1b55fc3b9a40243ff5588dff7defdcd4b5d745ba"},"cell_type":"code","source":"# getting all Title from Name column in both DataFrames through the list and creating a new column with those titles\nfor df in combined:\n    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=True)","execution_count":75,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a1bb218c319ad573c0f63648625040157b28dd4"},"cell_type":"code","source":"# concat both updated dataframes to see the distribution of titles at titanic\ncombined_df = pd.concat([titanic, titanic_test], axis = 0)\ncombined_df['Title'].value_counts()","execution_count":76,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ccc9ec2a50f7cd06838f3a5a931c7abbb57577d5"},"cell_type":"code","source":"plt.subplots(figsize = (16,6))\nsns.countplot(x = 'Title', data = combined_df)","execution_count":77,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d1926b3051fae4544d0bd4337ab407b3117498a8"},"cell_type":"code","source":"# Same concept to replace used at Sex column, considering the 4 largest groups of people and the rest of them in 1 group\n# Mr: 0\n# Miss: 1\n# Mrs: 2\n# Master: 3\n# Others: 4\ntitlemap = {\"Mr\": 0,\n            \"Miss\": 1, \n            \"Mrs\": 2, \n            \"Master\": 3, \n            \"Dr\": 4, \"Rev\": 4, \"Col\": 4, \"Major\": 4, \"Mlle\": 4,\"Countess\": 4, \"Ms\": 4, \n            \"Lady\": 4, \"Jonkheer\": 4,\"Don\": 4, \"Dona\" : 4, \"Mme\": 4,\"Capt\": 4,\"Sir\": 4 }\nfor df in combined:\n    df['Title'] = df['Title'].map(titlemap)","execution_count":78,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"630093839a65263f2c47673d30199a6bbf64c33f"},"cell_type":"code","source":"titanic.head()","execution_count":79,"outputs":[]},{"metadata":{"_uuid":"c6951ff5c1d78dd8015f4bbc842ffffa408c7bff"},"cell_type":"markdown","source":"# Working with Age"},{"metadata":{"trusted":true,"_uuid":"b695f81536cb77fc7f996cc115df5e44897949f2"},"cell_type":"code","source":"# Lets see how is the distribuition by gender for people who survived and whos dont.\nsurvived = titanic[titanic['Survived']==1]['Sex'].value_counts()\n# Extract how many peoples for each sex survived\ndead = titanic[titanic['Survived']==0]['Sex'].value_counts()\n# Extract how many peoples for each sex not survived\ndf = pd.DataFrame([survived,dead])\ndf.columns= ['Male', 'Female']\ndf.index = ['Survived','Dead']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))\nplt.legend(bbox_to_anchor=(1, 1), loc=2, borderaxespad=1)","execution_count":80,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81ea9d246ae85b9503dba211cc86d99c1a2e07cb"},"cell_type":"code","source":"#looking for null values ate Age.\nlen(titanic[titanic['Age'].isnull()])","execution_count":81,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"398ec86ab7664dc0523aa6178759dfea956b5a34"},"cell_type":"code","source":"# Here we need to make a decision, which  variable we'll relate with Age to fill the empty values\ntitanic[titanic['Age'].isnull()].head()","execution_count":82,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b798d84d5e17b5cf0cc2d4621812b756bd9fdce"},"cell_type":"code","source":"# looking to the first possibility, calculate new ages through Pclass\ncombined_df[['Age','Pclass']].groupby('Pclass').mean()","execution_count":83,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b09fa417b62d71c92dc17c3bb5f0057df13e1fae"},"cell_type":"code","source":"#Here we have more accuracy, title it is very related to age\ncombined_df = pd.concat([titanic, titanic_test], axis = 0)\ncombined_df[['Age','Title']].groupby('Title').mean()","execution_count":84,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3cb8db7274fb283243ad23b4970c58a2435edc3b"},"cell_type":"code","source":"# this is one function to verify all null values at AGE, and substitute to this respective new value considering Title\n# using combined_df, we can be more accurate to get the new mean values, because we consider a bigger data\ndef impute_age(cols):\n    Age = cols[0]\n    Title = cols[1]\n    \n    if pd.isnull(Age):\n        if Title == 0:\n            return combined_df['Age'][combined_df['Title'] == 0].mean()\n        elif Title == 1:\n            return combined_df['Age'][combined_df['Title'] == 1].mean()\n        elif Title == 2:\n            return combined_df['Age'][combined_df['Title'] == 2].mean()\n        elif Title == 3:\n            return combined_df['Age'][combined_df['Title'] == 3].mean()\n        else:\n            return combined_df['Age'][combined_df['Title'] == 4].mean()\n    else:\n        return Age","execution_count":85,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3dff244170e825a2144fa896cb593d8a663025de"},"cell_type":"code","source":"# aplly the function on DF's, titanic and titanic_test\ntitanic['Age'] = titanic[['Age','Title']].apply(impute_age,axis=1)\ntitanic_test['Age'] = titanic_test[['Age','Title']].apply(impute_age,axis=1)","execution_count":86,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"be22797749c86b175d1c4c5bfd4f63566602821c"},"cell_type":"code","source":"# To improve our machine learning model, we need to smooth our data, so we'll divide our Age values in 5 categories\nfor df_age in combined:\n    df_age.loc[ df_age['Age'] <= 16, 'Age'] = 0,\n    df_age.loc[(df_age['Age'] > 16) & (df_age['Age'] <= 26), 'Age'] = 1,\n    df_age.loc[(df_age['Age'] > 26) & (df_age['Age'] <= 36), 'Age'] = 2,\n    df_age.loc[(df_age['Age'] > 36) & (df_age['Age'] <= 62), 'Age'] = 3,\n    df_age.loc[ df_age['Age'] > 62, 'Age'] = 4\n    #using this for, we can substitute all values at titanic and also titanic_test","execution_count":87,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df314719c0ab2d67e84612b9d4f431fa3230a76b"},"cell_type":"code","source":"# Lets see how is the distribuition by Age for people who survived and whos dont.\nsurvivedAge = titanic[titanic['Survived']==1]['Age'].value_counts()\n# Extract how many peoples for each Age survived\ndeadAge = titanic[titanic['Survived']==0]['Age'].value_counts()\n# Extract how many peoples for each Age not survived\ndf = pd.DataFrame([survivedAge,deadAge])\ndf.columns= ['0-16','17-26', '27-36', '37-62', '63+']\ndf.index = ['Survived','Dead']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))\nplt.legend(bbox_to_anchor=(1, 1), loc=2, borderaxespad=1)","execution_count":88,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"902130253c19eed2cc6c1151b8f26ec539248bf2"},"cell_type":"code","source":"df_age2 = titanic[['Age', 'Survived']]\nsns.countplot(x = 'Age', hue = 'Survived', data = df_age2)","execution_count":89,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec67c624926214dff4cbbbec07b9956ddb23cbe6"},"cell_type":"code","source":"titanic_test.head()","execution_count":90,"outputs":[]},{"metadata":{"_uuid":"23c20fa67a1670ab4dbb7ea1b921a025d4bb529b"},"cell_type":"markdown","source":"# Working with FARE\n"},{"metadata":{"trusted":true,"_uuid":"9b5cc181d157213cb0342eb547770bc939648385"},"cell_type":"code","source":"#looking for null values ate Fare, Test DF.\ntitanic_test[titanic_test['Fare'].isnull()]","execution_count":91,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7afe670a6245e5e05036037c2eb6a187ce822655"},"cell_type":"code","source":"#looking for null values ate Fare, Train DF.\ntitanic[titanic['Fare'].isnull()]","execution_count":92,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a015d049d87fa7af5b2238bc45b750e0aa151543"},"cell_type":"code","source":"# In general, the fare paid is directly relate to the class. the miss value was replaced by the mean value at third class\ntitanic_test['Fare'] = titanic_test['Fare'].fillna(combined_df['Fare'][combined_df['Pclass'] == 3].mean())","execution_count":93,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cfe295537fc6b1df4a4b13efd1e36dd5917e61e"},"cell_type":"code","source":"combined_df = pd.concat([titanic, titanic_test], axis = 0)","execution_count":94,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c03f3d96560451278e960d206528726aa6eb733d"},"cell_type":"code","source":"combined_df['Fare'].describe()\n# Isn't good to see the distribution in that way","execution_count":95,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"580490c87f5a4a192a213995a191081888502afb"},"cell_type":"code","source":"# To improve our machine learning model, we need to smooth our data, so we'll divide our Fare values in 4 categories\nfor dataset in combined:\n    dataset.loc[ dataset['Fare'] <= 17, 'Fare'] = 0,\n    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1,\n    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2,\n    dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 3","execution_count":96,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd918162772f53ebb5edfa309a940cf368bf08dd"},"cell_type":"code","source":"titanic_test.head()","execution_count":97,"outputs":[]},{"metadata":{"_uuid":"bb57231fb8c06f23ba1bbde1a17a547c722817e1"},"cell_type":"markdown","source":"# Cabin"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"eaa9e30109ca39a36ebb9dee8421da01007a22b5"},"cell_type":"code","source":"for dfcabin in combined:\n    dfcabin['Cabin'] = dfcabin['Cabin'].str[:1]","execution_count":98,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd730405300cd7c4e00e1eedab71f7def1ecff2b"},"cell_type":"code","source":"# if we try to associate Cabin location to Fare, data are very confused\nprint(titanic[titanic['Fare'] == 0]['Cabin'].unique())\nprint(titanic[titanic['Fare'] == 1]['Cabin'].unique())\nprint(titanic[titanic['Fare'] == 2]['Cabin'].unique())\nprint(titanic[titanic['Fare'] == 3]['Cabin'].unique())","execution_count":99,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"644f9d20af9db0c205df20b5af69c4a3270865ea"},"cell_type":"code","source":"# if we try to associate Cabin location to Pclass, we can see a pattern\nprint(titanic[titanic['Pclass'] == 1]['Cabin'].unique())\nprint(titanic[titanic['Pclass'] == 2]['Cabin'].unique())\nprint(titanic[titanic['Pclass'] == 3]['Cabin'].unique())\n","execution_count":100,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a17492a44754fa66fb28eb89e3fad52e25584da0"},"cell_type":"code","source":"PC1 = titanic[titanic['Pclass'] == 1]['Cabin'].value_counts()\nPC2 = titanic[titanic['Pclass'] == 2]['Cabin'].value_counts()\nPC3 = titanic[titanic['Pclass'] == 3]['Cabin'].value_counts()\ndfCabin = pd.DataFrame([PC1, PC2, PC3])\ndfCabin.index = ['1 Class', '2 Class', '3 Class']\ndfCabin.plot(kind = 'bar', stacked = True, figsize = (12,6))\nplt.style.use('bmh')","execution_count":101,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"db36dcf37d6cdf21446cf738ca4c8699b136c047"},"cell_type":"code","source":"# Due Cabin A,B,T,C only exist at First class, they become only A\ntitanic['Cabin'].replace(['B', 'T', 'C'], ['A', 'A', 'A'], inplace = True);\ntitanic_test['Cabin'].replace(['B', 'T', 'C'], ['A', 'A', 'A'], inplace = True);","execution_count":102,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c96546b8719cd87d168bae45fe0ba0d39835134"},"cell_type":"code","source":"titanic['Cabin'].unique()","execution_count":103,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"84922b150f21417def5d324a3e2d615375750f01"},"cell_type":"code","source":"dicCabins = {\"A\": 0, \"D\": 0.5, \"E\": 1, \"F\": 1.5, \"G\": 2}\nfor dataset2 in combined:\n    dataset2['Cabin'] = dataset2['Cabin'].map(dicCabins)","execution_count":104,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c31953dca38f1f8f3df4649964da9e303572adf7"},"cell_type":"code","source":"def impute_cabin(cols):\n    Cabin  = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Cabin):\n        if Pclass == 1:\n            return 0\n        elif Pclass == 2:\n            return 1\n        else:\n            return 1.5\n    else:\n        return Cabin\ntitanic['Cabin'] = titanic[['Cabin','Pclass']].apply(impute_cabin,axis=1)\ntitanic_test['Cabin'] = titanic[['Cabin','Pclass']].apply(impute_cabin,axis=1)","execution_count":105,"outputs":[]},{"metadata":{"_uuid":"253791a7ba4c08df302a4c9a4733d34877e67496"},"cell_type":"markdown","source":"# MODELING"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9b03614323abe58e63f2808906d40776ba08ce60"},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=100, shuffle=True, random_state=0)","execution_count":106,"outputs":[]},{"metadata":{"_uuid":"265d705bc67808b8dbd2e4da4f773a2ee05f8e51"},"cell_type":"markdown","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_teste, Y_train, Y_teste = train_test_split(titanic.drop([\"Survived\",'PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n                                                      , titanic[\"Survived\"], test_size = 0.3, random_state = 101)\n"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4aa58cb64d35e9567017e6a7c782c7009d6f4c50"},"cell_type":"code","source":"X_train = titanic.drop([\"Survived\",'PassengerId', 'Name', 'Ticket'], axis=1)\nY_train = titanic[\"Survived\"]\nX_test  = titanic_test.drop([\"PassengerId\", 'Name', 'Ticket'], axis=1)","execution_count":107,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa9ed8362c8ca5cbdcf2fae58c8713698f551662"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 25)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nscore_knn = cross_val_score(knn, X_train, Y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy')\nprint('KNN Cross: {}\\nKNN:       {}'.format(round(np.mean(score_knn)*100,3), acc_knn))","execution_count":108,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f33443fc2620c5d9e5accebac8b513295532556"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogistic = LogisticRegression()\nlogistic.fit(X_train, Y_train)\nY_pred = logistic.predict(X_test)\nacc_log = round(logistic.score(X_train, Y_train) * 100, 2)\nscore_lr = cross_val_score(logistic, X_train, Y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy')\nprint('Logistic Cross: {}\\nLogistic:       {}'.format(round(np.mean(score_lr)*100,2), acc_log))","execution_count":109,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cf017c5111abcc5fe125961835d98f0cfecea74"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nscore_dt = cross_val_score(decision_tree, X_train, Y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy')\nprint('Decision Tree Cross: {}\\nDecision Tree:       {}'.format(round(np.mean(score_dt)*100,2), acc_decision_tree))","execution_count":110,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f5e4a58580b1c5508034547914d5ed2687a1c71"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(n_estimators=200)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nscore_rf = cross_val_score(random_forest, X_train, Y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy')\nprint('Random Forest Cross: {}\\nRandom Forest:       {}'.format(round(np.mean(score_rf)*100,2), acc_random_forest))","execution_count":111,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1822b34925bdca9e3501cb3cdd4ad918d0eed39c"},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier()\ngbk.fit(X_train, Y_train)\nY_pred = gbk.predict(X_test)\nacc_gbk = round(gbk.score(X_train, Y_train) * 100, 2)\nscore_gbk = cross_val_score(gbk, X_train, Y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy')\nprint('Gradient Boosting Classifier Cross: {}\\nGradient Boosting Classifier:       {}'.format(round(np.mean(score_gbk)*100,2), acc_gbk))","execution_count":112,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74f5576037c6a8c5c6ca6cc41c90f942fdbf9ada"},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvc = SVC(gamma = 'scale')\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nscore_svc = cross_val_score(svc, X_train, Y_train, cv=k_fold, n_jobs=1, scoring = 'accuracy')\nprint('SVC Cross: {}\\nSVC:       {}'.format(round(np.mean(score_svc)*100,2), acc_svc))","execution_count":113,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7da1c14ef9c5eea664c009168c94eed4cb7b1b7a"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_trainG, x_testeG, y_trainG, y_testeG = train_test_split(titanic.drop([\"Survived\",'PassengerId',\n                                                                    'Name', 'Ticket', 'Cabin'],\n                                                                     axis=1), titanic[\"Survived\"], \n                                                                     test_size = 0.4, random_state = 101)\nerror_rate = []\nfor i in range(1,35):\n    knnG = KNeighborsClassifier(n_neighbors = i)\n    knnG.fit(x_trainG, y_trainG)\n    y_predG = knnG.predict(x_testeG)\n    error_rate.append(np.mean(y_predG!=y_testeG))\nplt.figure(figsize = (14, 8))\nplt.plot(range(1, 35), error_rate, color = 'blue', ls = 'dashed', marker = 'o')\n","execution_count":114,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b57f3e78da99337e902360bdf5a6773f7a7a8bf"},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Decision Tree',\n              'Random Forest', 'KNN', 'Gradient Boosting Classifier', 'SVC'],\n    'Score': [np.mean(score_lr)*100, np.mean(score_dt)*100, np.mean(score_rf)*100,\n             np.mean(score_knn)*100, np.mean(score_gbk)*100, np.mean(score_svc)*100]})\nprint('Cross Validation')\nmodels.sort_values(by='Score', ascending=False)","execution_count":115,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f39cb1b1bb297966a824c7bb12fce3fc45720081"},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Decision Tree',\n              'Random Forest', 'KNN', 'Gradient Boosting Classifier', 'SVC'],\n    'Score': [acc_log, acc_decision_tree, acc_random_forest,\n             acc_knn, acc_gbk, acc_svc]})\nprint('Score')\nmodels.sort_values(by='Score', ascending=False)","execution_count":116,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c089f669b708a92d04a7be18fbe327bd08a1ae86"},"cell_type":"code","source":"# Run the Model First\nsubmission = pd.DataFrame({\n        \"PassengerId\": titanic_test[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('submission.csv', index=False)","execution_count":117,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}