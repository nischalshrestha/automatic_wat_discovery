{"nbformat": 4, "metadata": {"language_info": {"mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "version": "3.6.4", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "cells": [{"source": ["import numpy as np\n", "import pandas\n", "import matplotlib.pyplot as plt\n", "\n", "from sklearn.base import BaseEstimator, TransformerMixin\n", "from sklearn.pipeline import Pipeline, FeatureUnion\n", "from sklearn.preprocessing import StandardScaler, Imputer, OneHotEncoder, LabelBinarizer, LabelEncoder"], "cell_type": "code", "metadata": {"_uuid": "a16cf8928d37ea56673a1dd00c2579812a1e42cf", "_cell_guid": "09266791-ecf3-48fc-a744-091c993788f5", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["# Data Visualization"], "cell_type": "markdown", "metadata": {"_uuid": "adafe4740aa5fb9c878c499155a80995f0cb46f8", "_cell_guid": "d072797c-ce43-4266-9a07-5c5e1929b12a"}}, {"source": ["# Possible things to upgrade :\n", "# Split the validation/test sets to make sure they represent the whole population\n", "\n", "# In the Name format, we could extract a Title since it's always in the same place. There's probably a good correlation\n", "# Ticket doesn't seem useful, neither does Cabin because of NaN, we'll check that.\n", "\n", "\n", "np.random.seed(31)\n", "data = pandas.read_csv('../input/train.csv')\n", "data.head(5)"], "cell_type": "code", "metadata": {"_uuid": "7af82e42566e4f4c1f7e9249130d6270f3959ab4", "_cell_guid": "8b5bd22b-d1ca-4fd5-aaf4-65e6a0da9d17", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["# The main point of this is to check how many null entries there are per column and check the type of each column\n", "data.info()\n", "\n", "# There is a lot of NaN in Age.\n", "# There is so much NaN in Cabin that it should be dropped\n", "# Embarked has some NaN too."], "cell_type": "code", "metadata": {"_uuid": "11f8998378d06c21197257159214a88f0186bd57", "_cell_guid": "810a8725-85e1-4a1f-99de-b02b7bc8f9a5", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["data.corr()\n", "\n", "# Correlation is strong between Survived and Fare\n", "# Correlation is strong between Survived and PClass.\n", "# Correlation is strong between Fare and PClass, maybe one of them should be dropped to remove false correlation\n", "# Should produce histograms of Fare/Survived and PClass/Survived"], "cell_type": "code", "metadata": {"scrolled": true, "_uuid": "c53c45125a627d505aa9768d647e9496ae0c7958", "_cell_guid": "f9bb88cd-5847-446f-aa40-66e4063257ef", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["v_data = data.copy()\n", "fare_labels = [\"Low\", \"Medium\", \"Medium-High\", \"High\"]\n", "v_data[\"Fare\"] = pandas.cut(v_data[\"Fare\"], bins=[0,10,50,100,600], labels=fare_labels, include_lowest=True).factorize()[0]\n", "\n", "width = 0.3\n", "fare_survived = plt.bar(v_data[\"Fare\"].unique(), v_data[v_data[\"Survived\"] == 1][\"Fare\"].value_counts(), width,  color=\"r\")\n", "fare_died = plt.bar(v_data[\"Fare\"].unique() + width, v_data[v_data[\"Survived\"] == 0][\"Fare\"].value_counts(), width, color=\"g\")\n", "plt.legend((fare_survived[0], fare_died[0]), ('Survived', 'Died'))\n", "plt.xticks(v_data[\"Fare\"].unique(), fare_labels)\n", "plt.show()\n", "\n", "# There seems to be a good correlation. People who paid less than 50 dollars seem to alot die more (feature?)"], "cell_type": "code", "metadata": {"_uuid": "6400cd14115be0ca871daee6e8579c0e4e942e24", "_cell_guid": "f9012658-df9c-48d4-a04c-ff5d1586afae", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["pclass_labels = [\"Low\", \"Medium\", \"High\"]\n", "pclass_values = np.sort(v_data[\"Pclass\"].unique())\n", "\n", "width = 0.3\n", "pclass_survived = plt.bar(pclass_values, v_data[v_data[\"Survived\"] == 1][\"Pclass\"].value_counts(), width,  color=\"r\")\n", "pclass_died = plt.bar(pclass_values + width, v_data[v_data[\"Survived\"] == 0][\"Pclass\"].value_counts(), width, color=\"g\")\n", "plt.legend((pclass_survived[0], pclass_died[0]), ('Survived', 'Died'))\n", "plt.xticks(pclass_values, pclass_labels)\n", "plt.show()\n", "\n", "# People in low class died much more than the others (feature?)"], "cell_type": "code", "metadata": {"_uuid": "0dcd44d85ffb3eb1b4d1431f76c5e044071abe92", "_cell_guid": "831eaef7-e569-425b-9a1c-46573ce041d1", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["class TitleAttributeAdder(BaseEstimator, TransformerMixin):\n", "\n", "    def __init__(self, remove_sex=False):\n", "        self.remove_sex = remove_sex\n", "\n", "    def fit(self, X, y = None):\n", "        return self\n", "\n", "    def transform(self, X, y = None):\n", "        x_copy = X.copy(deep=True)\n", "        titles = x_copy.apply(TitleAttributeAdder.__extract_title, axis=1)\n", "        title_names = (titles.value_counts() < 10)\n", "        titles = titles.apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n", "        x_copy[\"Title\"] = titles\n", "        return x_copy\n", "\n", "    @staticmethod\n", "    def __extract_title(a):\n", "        comma_index = 0\n", "        name = a[\"Name\"]\n", "        try:\n", "            comma_index = name.index(',') + 1\n", "            result = name[comma_index:]\n", "            space_index = result.index(\".\")\n", "            return result[:space_index].strip()\n", "        except AttributeError as ae:\n", "            print(a)\n", "            raise Exception\n", "        \n", "\n"], "cell_type": "code", "metadata": {"_uuid": "4064381f245b814309668465b9089899e719142b", "_cell_guid": "479b4ed9-d7d5-4415-add3-2f8614302735", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["p_data = data.copy(deep = True)\n", "\n", "plt.figure(figsize=(20,15))\n", "\n", "ax1 = plt.subplot2grid((2, 2), (0, 0))\n", "ax2 = plt.subplot2grid((2, 2), (0, 1))\n", "ax3 = plt.subplot2grid((2, 2), (1, 0))\n", "\n", "width = 0.35\n", "p_data[\"FamilySize\"] = p_data[\"Parch\"] + p_data[\"SibSp\"] + 1\n", "p_data[\"FamilySize\"] = pandas.cut(p_data[\"FamilySize\"], bins=[-1,1,2, 4, 100])\n", "p_data[\"FamilySize\"] = p_data[\"FamilySize\"].factorize()[0]\n", "fam_survived = ax1.bar(p_data[\"FamilySize\"].unique(), p_data[\"FamilySize\"].astype('category')[p_data[\"Survived\"] == 1].value_counts(), width,  color=\"r\")\n", "fam_died = ax1.bar(p_data[\"FamilySize\"].unique() + width, p_data[\"FamilySize\"].astype('category')[p_data[\"Survived\"] == 0].value_counts(), width, color=\"g\")\n", "ax1.legend((fam_survived[0], fam_died[0]), ('Survived', 'Died'))\n", "ax1.set_title(\"Survival/Death by family size\")\n", "ax1.set_xticks(range(p_data[\"FamilySize\"].max() + 1))\n", "ax1.set_xticklabels([\"Alone\",\"Couple\", \"2 < x < 5\", \">= 5\"])\n", "\n", "val, labels = TitleAttributeAdder().transform(data)[\"Title\"].factorize()\n", "p_data[\"Title\"] = val\n", "title_survived = ax2.bar(p_data[\"Title\"].unique(), p_data[\"Title\"].astype('category')[p_data[\"Survived\"] == 1].value_counts(), width,  color=\"r\")\n", "title_died = ax2.bar(p_data[\"Title\"].unique() + width, p_data[\"Title\"].astype('category')[p_data[\"Survived\"] == 0].value_counts(), width, color=\"g\")\n", "ax2.legend((title_survived[0], title_died[0]), ('Survived', 'Died'))\n", "ax2.set_xticks(range(p_data[\"Title\"].max() + 1))\n", "ax2.set_xticklabels(labels)\n", "ax2.set_title(\"Survival/Death by title\")\n", "\n", "\n", "p_data[\"Alone\"] = p_data[\"FamilySize\"].apply(lambda x : 1 if x == 1 else 0)\n", "alone_survived = ax3.bar(p_data[\"Alone\"].unique(), p_data[p_data[\"Survived\"] == 1][\"Alone\"].value_counts(), width,  color=\"r\")\n", "alone_died = ax3.bar(p_data[\"Alone\"].unique() + width, p_data[p_data[\"Survived\"] == 0][\"Alone\"].value_counts(), width, color=\"g\")\n", "ax3.legend((alone_survived[0], alone_died[0]), ('Survived', 'Died'))\n", "ax3.set_xticks([0,1])\n", "ax3.set_xticklabels([\"Alone\", \"Not alone\"])\n", "ax3.set_title(\"Survival/Death if alone\")\n", "\n", "plt.show()"], "cell_type": "code", "metadata": {"_uuid": "e5f8a2e265292dc5668318397c18e306d3679989", "_cell_guid": "e7bdafdc-8df0-4da9-a6a2-5f7bcf0e79fa", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["v_data[[\"Age\", \"Fare\", \"Survived\"]].hist()\n", "plt.show()"], "cell_type": "code", "metadata": {"_uuid": "61bb435c738c8803262d836b9ee942ff56623a18", "_cell_guid": "ba1626a6-7e89-4dc0-b260-c0d636512167", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["## Data Preparation"], "cell_type": "markdown", "metadata": {"_uuid": "56a453b09059f4baa07f6ff6cf570c8a0a225a73", "_cell_guid": "f8bbcfe2-1e41-4fb9-95d9-3e317e3929f0"}}, {"source": ["# Bug live : Les titres ne sont pas tous assez pr\u00e9sents dans le X_test pour apparaitre comme colonne avec le One-Hot\n", "# Il faut s'arranger pour que le fit trouve les colonnes et les ajoutent pareille I guess\n", "\n", "class PreparationTransformer(BaseEstimator, TransformerMixin):\n", "    def __init__(self, age_format=\"scaled\", fare_format=\"scaled\", title_format=\"one-hot\",\n", "                 embarked_format=\"one-hot\", drop_sex=False, drop_id=False, drop_survived = False):\n", "        \n", "        self.age_format = age_format\n", "        self.fare_format = fare_format\n", "        self.title_format = title_format\n", "        self.embarked_format = embarked_format\n", "        self.drop_sex = drop_sex\n", "        self.drop_id = drop_id\n", "        self.drop_survived = drop_survived\n", "        self.embarked_mode = \"\"\n", "        self.age_imputer = Imputer(strategy=\"median\")\n", "        self.fare_imputer = Imputer(strategy=\"median\")\n", "        self.title_lbz = LabelBinarizer()\n", "        self.embarked_lbz = LabelBinarizer()\n", "        self.title_fact = LabelEncoder()\n", "        self.emb_fact = LabelEncoder()\n", "        \n", "    def fit(self, X, y=None):\n", "        df = X.copy(deep=True)\n", "        \n", "        # Maybe find a way to avoid this\n", "        df[\"Title\"] = TitleAttributeAdder().transform(df)[\"Title\"]\n", "\n", "        self.embarked_mode = df[\"Embarked\"].mode()[0]\n", "        df[\"Embarked\"] = df[\"Embarked\"].fillna(self.embarked_mode)\n", "        self.age_imputer = self.age_imputer.fit(df[[\"Age\"]])\n", "        self.fare_imputer = self.fare_imputer.fit(df[[\"Fare\"]])\n", "        self.title_fact = self.title_fact.fit(df[\"Title\"])\n", "        self.title_lbz = self.title_lbz.fit(df[\"Title\"])\n", "        self.embarked_lbz = self.embarked_lbz.fit(df[\"Embarked\"])\n", "        self.emb_fact = self.emb_fact.fit(df[\"Embarked\"])\n", "        \n", "        return self\n", "    \n", "    def transform(self, X, y=None):\n", "        df = X.copy(deep = True)\n", "        df.reset_index(drop=True, inplace=True)\n", "\n", "        # Clean Embarked\n", "        df[\"Embarked\"] = df[\"Embarked\"].fillna(self.embarked_mode)\n", "        if self.embarked_format == \"factorized\":\n", "            emb = pandas.DataFrame(self.emb_fact.transform(df[\"Embarked\"]), columns=[\"Embarked\"])\n", "        if self.embarked_format == \"one-hot\":\n", "            labels = [\"Emb_\" + x for x in self.embarked_lbz.classes_]\n", "            emb = pandas.DataFrame(self.embarked_lbz.transform(df[\"Embarked\"]), columns=labels)\n", "\n", "        df.drop([\"Embarked\"], axis=1, inplace=True)\n", "        df = pandas.concat([df, emb], axis=1, verify_integrity=True)\n", "        \n", "        # Create Title\n", "        df[\"Title\"] = TitleAttributeAdder().transform(df)[\"Title\"]\n", "        if self.title_format == \"factorized\":\n", "            titles = pandas.DataFrame(self.title_fact.transform(df[\"Title\"]), columns=[\"Title\"])\n", "        if self.title_format == \"one-hot\":\n", "            labels = [\"Title_\" + x for x in self.title_lbz.classes_]\n", "            titles = pandas.DataFrame(self.title_lbz.transform(df[\"Title\"]), columns=labels)    \n", "\n", "        df.drop([\"Title\"], axis=1, inplace=True)        \n", "        df = pandas.concat([df, titles], axis=1, verify_integrity=True)\n", "\n", "            \n", "        # Create FamilySize Feature\n", "        df[\"FamilySize\"] = df[\"Parch\"] + df[\"SibSp\"] + 1\n", "        #df[\"FamilySize\"] = pandas.cut(df[\"FamilySize\"], bins=[-1,1,2, 4, 100])\n", "        #df[\"FamilySize\"] = df[\"FamilySize\"].factorize()[0]\n", "        \n", "        # Factorize Sex\n", "        df[\"Sex\"] = df[\"Sex\"].factorize()[0]        \n", "        \n", "        # Add Alone Feature\n", "        df[\"Alone\"] =  df[\"FamilySize\"].apply(lambda x : 1 if x == 1 else 0)\n", "        \n", "        # Clean Fare\n", "        df[\"Fare\"] = self.fare_imputer.transform(df[[\"Fare\"]])\n", "        \n", "        if self.fare_format == \"scaled\":\n", "            df[\"Fare\"] = StandardScaler().fit_transform(df[\"Fare\"].values.reshape(-1,1))\n", "        elif self.fare_format == \"binned\":\n", "            df[\"Fare\"] = pandas.cut(df[\"Fare\"], bins=[0,10,50,100,600]).factorize()[0]        \n", "        \n", "        # Clean Age\n", "        df[\"Age\"] = self.age_imputer.transform(df[[\"Age\"]])\n", "        \n", "        if self.age_format == \"scaled\":\n", "            df[\"Age\"] = StandardScaler().fit_transform(df[\"Age\"].values.reshape(-1,1))\n", "        elif self.age_format == \"binned\":\n", "            df[\"Age\"] = pandas.cut(df[\"Age\"], np.linspace(0,80,9)).factorize()[0]\n", "\n", "        # Drop useless columns\n", "        df.drop([\"Cabin\",\"Ticket\", \"Name\"], axis = 1, inplace = True)\n", "\n", "        if self.drop_sex == True:\n", "            df.drop([\"Sex\"], axis=1, inplace = True)\n", "        if self.drop_id == True:\n", "            df.drop([\"PassengerId\"], axis=1, inplace = True)\n", "        if \"Survived\" in df.columns and self.drop_survived == True:\n", "            df.drop([\"Survived\"], axis=1, inplace=True)\n", "            \n", "        return df"], "cell_type": "code", "metadata": {"_uuid": "16dc51ee93000f23e787ae70c498274f30bcb039", "_cell_guid": "8dffed78-9a5f-4896-ad0c-29ad9cb83c13", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["pipeline = PreparationTransformer(embarked_format=\"factorized\", title_format=\"factorized\")\n", "\n", "df = data.copy(deep=True)\n", "pipeline.fit_transform(df).head(1)"], "cell_type": "code", "metadata": {"_uuid": "f3eb82a26c71895b1521e08c4d45eeba69de797f", "_cell_guid": "b0f9812b-9193-458d-8bf2-d0182d26784a", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["## Model Training"], "cell_type": "markdown", "metadata": {"_uuid": "21f15d8f591217bf9bcb57b1ca7332a337bd5018", "_cell_guid": "8869e6f0-ee46-4146-94db-7db635634bb3"}}, {"source": ["from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import f1_score\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.metrics import roc_auc_score\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.decomposition import PCA\n", "from sklearn.model_selection import RandomizedSearchCV\n", "from sklearn.metrics import make_scorer\n", "\n", "from sklearn.neural_network import MLPClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.svm import SVC\n", "from sklearn.gaussian_process import GaussianProcessClassifier\n", "from sklearn.gaussian_process.kernels import RBF\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"], "cell_type": "code", "metadata": {"_uuid": "1948ddb940a1cb42249e72a8d4e15360da2d57ce", "_cell_guid": "9689e66e-a3b5-4376-b948-40a6ff00248d", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["X = data.copy(deep=True)\n", "#X = X.apply(np.random.permutation)\n", "y = X[\"Survived\"]\n", "\n", "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=0.4, random_state=42)\n", "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, test_size=0.5, random_state=42)\n", "prep = PreparationTransformer(embarked_format=\"factorized\", title_format=\"one-hot\", age_format=\"scaled\", fare_format=\"scaled\", drop_id=True, drop_survived=True)\n", "prep = prep.fit(X_train)"], "cell_type": "code", "metadata": {"_uuid": "cb3eff2c788c0784536c827330431db662028cdd", "_cell_guid": "667d5641-acbb-40b5-bd12-7233d98f45b9", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["classifiers = [\n", "    KNeighborsClassifier(3),\n", "    SVC(C= 1.1, degree= 2, kernel= 'poly'),\n", "    SVC(gamma=2, C=1),\n", "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n", "    DecisionTreeClassifier(max_depth=5),\n", "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n", "    MLPClassifier(solver=\"lbfgs\"),\n", "    AdaBoostClassifier(),\n", "    GaussianNB(),\n", "    QuadraticDiscriminantAnalysis()]\n", "\n", "\n", "x_train_transformed = prep.fit_transform(X_train)\n", "x_val_transformed = prep.transform(X_val)\n", "\n", "for clf in classifiers:\n", "    clf = clf.fit(x_train_transformed, y_train)\n", "    \n", "    y_pred = clf.predict(x_val_transformed)\n", "    val_score = roc_auc_score(y_val, y_pred)\n", "    \n", "    print(\"{0} : Cross-validation score {1}\".format(clf.__class__.__name__, val_score))"], "cell_type": "code", "metadata": {"_uuid": "acd8f0ee62c5afe02d661d153653adee3e9eb2bc", "_cell_guid": "3cc7ba7f-d33f-4e4c-a0e1-2a97f9f4eae3", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["grid_params = {\n", "    \"svc__C\" : [1,1.1,1.2,1.3,1.4],\n", "    \"svc__kernel\" : [\"poly\", \"linear\"],\n", "    \"svc__degree\" : [2,3,4,5],\n", "}\n", "\n", "clf = Pipeline([\n", "    (\"prep\", PreparationTransformer(title_format=\"one-hot\", embarked_format=\"factorized\", age_format=\"scaled\", fare_format=\"scaled\", drop_id=True, drop_survived=True)),\n", "    (\"svc\", SVC())])\n", "\n", "rscv = RandomizedSearchCV(clf, param_distributions=grid_params, n_jobs=1, n_iter=15, scoring=make_scorer(roc_auc_score))\n", "rscv = rscv.fit(X_train, y_train)\n", "\n", "rscv.best_params_"], "cell_type": "code", "metadata": {"_uuid": "65be3fa92cc2141ea1d4160078a2a3d340033349", "_cell_guid": "ca56f3ca-13a6-4eee-a602-a3033f9b0b1c", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["prep = PreparationTransformer(embarked_format=\"one-hot\", title_format=\"factorized\", age_format=\"scaled\", fare_format=\"factorized\", drop_sex=False, drop_id=True, drop_survived=True)\n", "\n", "prep = prep.fit(X_train)\n", "\n", "# GaussianNB ended up being the better\n", "clf = GaussianNB() #SVC(C= 1.1, degree= 2, kernel= 'poly')\n", "sub_xt = prep.transform(X_train)\n", "sub_xv = prep.transform(X_val)\n", "\n", "results = []\n", "for i in range(20, len(X_train),20):\n", "    clf = clf.fit(sub_xt[:i], y_train[:i])\n", "    \n", "    y_pred_train = clf.predict(sub_xt)\n", "    y_pred_val = clf.predict(sub_xv)\n", "    \n", "    score_train = roc_auc_score(y_train, y_pred_train)\n", "    score_val = roc_auc_score(y_val, y_pred_val)\n", "    results.append((i, score_train, score_val))\n", "    \n", "indexes = [x[0] for x in results]\n", "scores_train = [1 - x[1] for x in results]\n", "scores_val = [1 - x[2] for x in results]\n", "\n", "train_plot = plt.plot(indexes, scores_train, color=\"g\")\n", "val_plot = plt.plot(indexes, scores_val, color=\"r\")\n", "plt.legend((train_plot[0], val_plot[0]), (\"Train error\", \"Val error\"))\n", "plt.title(\"Validation Curve\")\n", "plt.show()\n", "\n", "print(\"Lowest error : {0}\".format(np.array(scores_val).min()))\n"], "cell_type": "code", "metadata": {"scrolled": true, "_uuid": "20aad4956e828a019e82f1f5a24564b4871b200c", "_cell_guid": "c0c713d8-18ed-4441-84fd-b1924a3b3f9f", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["xtest_prep = prep.transform(X_test)\n", "clf = GaussianNB() #SVC(C= 1.1, degree= 2, kernel= 'poly')\n", "clf = clf.fit(sub_xt, y_train)\n", "\n", "test_pred = clf.predict(xtest_prep)\n", "roc_auc_score(y_test, test_pred)"], "cell_type": "code", "metadata": {"_uuid": "f5dda1b9556dfc11236dcc50eddcca00e07a5ccc", "_cell_guid": "d2dd0746-4748-4b3a-9f49-ee9a1c6fe8c3", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["test = pandas.read_csv('../input/test.csv')\n", "X_prediction = test.copy(deep = True)\n", "X_prediction_ids = test[\"PassengerId\"]\n", "\n", "# Caution not to call fit_transform, the model was already fitted"], "cell_type": "code", "metadata": {"_uuid": "5ed4f40547da91f02cd9ca73c96f13ac0b05601e", "_cell_guid": "ad1de463-a771-4392-88a0-016542abc38a", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["X_tran = prep.transform(X)\n", "X_prediction_tran = prep.transform(X_prediction)\n", "print(X_prediction_tran.shape)\n", "print(X_tran.shape)\n", "clf = clf.fit(X_tran, y)\n", "y_pred_pre = clf.predict(X_prediction_tran)"], "cell_type": "code", "metadata": {"_uuid": "39c782dbc115d9ebab2119d7cd3508b60c8ba79f", "_cell_guid": "948631d2-25f9-40b7-8369-de30ac987b0f", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["result = np.column_stack((X_prediction_ids, y_pred_pre))\n", "result[0:5]"], "cell_type": "code", "metadata": {"_uuid": "211db5f4fdaf121b26b237d0e278466e57103a86", "_cell_guid": "9ecc79f7-c0eb-4d74-b462-bc09ff1e7a92", "collapsed": true}, "outputs": [], "execution_count": null}, {"source": ["with open('data/submission_1.csv', 'w') as f : \n", "    f.write('PassengerId,Survived\\n')\n", "    for row in result:\n", "        f.write('{0},{1}\\n'.format(row[0], row[1]))\n", "        \n", "    f.close()\n", "    \n", "print(\"Done! :)\")"], "cell_type": "code", "metadata": {"_uuid": "5de444a0cd109a364afbbe3d335d7c7e7cff8346", "_cell_guid": "24aceffb-b8cf-4d41-9c48-e3bff5096c5c", "collapsed": true}, "outputs": [], "execution_count": null}], "nbformat_minor": 1}