{"nbformat": 4, "cells": [{"metadata": {"_cell_guid": "cef6f63e-b0d7-429a-9105-f9605cb639c8", "_uuid": "4fc797e9c165838478f1aa49bb41d5895fc8622a"}, "cell_type": "markdown", "source": ["**Set up dependencies & load data**"]}, {"execution_count": null, "metadata": {"_cell_guid": "4e0073a7-ca6a-4a9f-a697-549a80dd6312", "_uuid": "4076661565519ae98861be68b8e521f4e87c1d4e"}, "outputs": [], "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from IPython.display import display\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output.\n", "\n", "#read training set\n", "train_set= pd.read_csv(\"../input/train.csv\")\n", "test_set= pd.read_csv(\"../input/test.csv\")\n", "\n", "# Store our test passenger IDs for easy access\n", "PassengerId = test_set['PassengerId']"]}, {"metadata": {"_cell_guid": "b4a6de1a-e72c-49f6-918a-ee191a79c8e8", "_uuid": "112bb6ebc7a7466188fe60d6e37d93a854f8c563"}, "cell_type": "markdown", "source": ["**Discover the sets**"]}, {"execution_count": null, "metadata": {"_cell_guid": "127bee4c-3e3c-4b8f-9656-35eae4d8bc7a", "scrolled": true, "_uuid": "effa51cd05d353961fd157954e23aba0c8fd577e"}, "outputs": [], "cell_type": "code", "source": ["\n", "display(train_set.head())\n", "display(train_set.describe())\n", "display(train_set.info())"]}, {"metadata": {"_cell_guid": "1e5390c8-3a7c-48e2-8419-9714f9eaa8a8", "_uuid": "d057cb86d7872f715ef74870bb60eafacca7cf05"}, "cell_type": "markdown", "source": ["Zoomer sur des r\u00e9partitions => identifier les 'outliers'"]}, {"execution_count": null, "metadata": {"_cell_guid": "814ade6b-f5ca-45c8-8320-d8b53d3c663c", "_uuid": "780d7a45fbea93653d43ce452faca613a2c38ca3"}, "outputs": [], "cell_type": "code", "source": ["train_set.describe(include=['O'])\n", "#description des types \"Objets\"\n", "#https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html\n", "train_set[['Age', 'Fare']].describe(percentiles=[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99])"]}, {"execution_count": null, "metadata": {"_cell_guid": "a836d728-90e2-4852-b1ac-ce51fc150879", "_uuid": "57e6e830c58daa98c2e29e67f91efaf85bd69f85"}, "outputs": [], "cell_type": "code", "source": ["display(train_set[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n", "train_set[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).count().sort_values(by='Survived', ascending=False)"]}, {"metadata": {"_cell_guid": "432d02ff-cd96-452c-a56b-f90a215b1762", "_uuid": "a1ec5003873e8aea54f6ec5fbf6b55a691232f6d"}, "cell_type": "markdown", "source": ["**detailed exploration**\n", "explore correlations & missing values"]}, {"execution_count": null, "metadata": {"_cell_guid": "0a03ee7f-e3d7-4967-b049-71c9261ff393", "_uuid": "5ce5bbc2a883d92679c1cda427d5404277b2f027"}, "outputs": [], "cell_type": "code", "source": ["%matplotlib inline\n", "import seaborn\n", "seaborn.set() \n", "\n", "#-------------------Survived/Died by Class -------------------------------------\n", "survived_class = train_set[train_set['Survived']==1]['Pclass'].value_counts()\n", "dead_class = train_set[train_set['Survived']==0]['Pclass'].value_counts()\n", "df_class = pd.DataFrame([survived_class,dead_class])\n", "df_class.index = ['Survived','Died']\n", "df_class.plot(kind='bar',stacked=True, figsize=(5,3), title=\"Survived/Died by Class\")\n", "\n", "Class1_survived= df_class.iloc[0,0]/df_class.iloc[:,0].sum()*100\n", "Class2_survived = df_class.iloc[0,1]/df_class.iloc[:,1].sum()*100\n", "Class3_survived = df_class.iloc[0,2]/df_class.iloc[:,2].sum()*100\n", "print(\"Percentage of Class 1 that survived:\" ,round(Class1_survived),\"%\")\n", "print(\"Percentage of Class 2 that survived:\" ,round(Class2_survived), \"%\")\n", "print(\"Percentage of Class 3 that survived:\" ,round(Class3_survived), \"%\")\n", "\n", "# display table\n", "display(df_class)\n", "display(survived_class)"]}, {"execution_count": null, "metadata": {"_cell_guid": "45a361f4-71af-4771-8005-bf1a56dd9b9d", "_uuid": "03ae005ada9f7381d5089e7d6363fdb84cc9d614"}, "outputs": [], "cell_type": "code", "source": ["# ou plus simplement\n", "train_set[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"]}, {"execution_count": null, "metadata": {"_cell_guid": "8dbea5ed-ddce-44a5-824f-45f6237e6ef3", "scrolled": true, "_uuid": "3fdd6b96ccafaa5ad5b23af3bcd107eac03bbeb3"}, "outputs": [], "cell_type": "code", "source": ["# feature correlation\n", "#drop not number/category features\n", "correl_train = train_set.drop(['PassengerId', 'Name', 'Ticket', 'Cabin' ], axis=1)\n", "correl_train['Sex01']=(correl_train['Sex']=='male')\n", "\n", "corr=correl_train.corr()\n", "\n", "# Generate a mask for the upper triangle\n", "mask = np.zeros_like(corr, dtype=np.bool)\n", "mask[np.triu_indices_from(mask)] = True\n", "\n", "# Set up the matplotlib figure\n", "f, ax = plt.subplots(figsize=(11, 9))\n", "\n", "# Generate a custom diverging colormap\n", "cmap = sns.diverging_palette(220, 2, as_cmap=True)\n", "\n", "# Draw the heatmap with the mask and correct aspect ratio\n", "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n", "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n", "\n", "correl_train.head()"]}, {"execution_count": null, "metadata": {"_cell_guid": "73076537-48ae-4e3c-b7bf-5094a2cfdd93", "_uuid": "7245f78ccfae0653426cd092bd8adb31ecd1eeb0"}, "outputs": [], "cell_type": "code", "source": ["with sns.axes_style(\"white\"):\n", "    sns.jointplot(x=np.minimum(train_set['Fare'] , 75) , y=train_set['Age'], kind=\"hex\", color=\"k\");\n", "            \n", "with sns.axes_style(\"white\"):\n", "    sns.jointplot(x=np.minimum(train_set['Fare'] , 75) , y=train_set['Pclass'], kind=\"hex\", color=\"k\");\n"]}, {"execution_count": null, "metadata": {"_cell_guid": "60e0f65f-8460-4aec-b602-d758e721152c", "_uuid": "97cbf9491c8a38b522cf4c2898b06b4d07cefc9c"}, "outputs": [], "cell_type": "code", "source": ["#En visualisant la variance:\n", "sns.barplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=train_set);"]}, {"execution_count": null, "metadata": {"_cell_guid": "cf2f9d03-0e66-4619-9939-b38ea27c9053", "_uuid": "61e4270656c55ce7bfa55a72677faf08458aab1c"}, "outputs": [], "cell_type": "code", "source": ["#Copy to ensure we don't poluate initial set\n", "easy_correl_train = correl_train.copy()\n", "easy_correl_train['Age'][easy_correl_train['Age'].isnull()] = -10\n", "#correl_train.dropna()\n", "easy_correl_train.loc[:,'Fare']= np.minimum(easy_correl_train['Fare'] , 100)\n", "display(easy_correl_train.describe())\n", "display(correl_train.describe())"]}, {"execution_count": null, "metadata": {"_cell_guid": "680d9e97-3423-48fa-9770-128eecb3287a", "scrolled": false, "_uuid": "1defc810b9622b99858074962a674356a4c9f23d"}, "outputs": [], "cell_type": "code", "source": ["#correl_train[['Fare', 'Pclass']]\n", "#correl_train.dropna()\n", "sns.pairplot(easy_correl_train)"]}, {"execution_count": null, "metadata": {"_cell_guid": "1d15e48c-7a17-4b93-9ad7-995d89f612be", "scrolled": true, "_uuid": "b0aa4243feaccff3f15a3393245518bd44dcc4a7"}, "outputs": [], "cell_type": "code", "source": ["#Approximation gaussiennes\n", "g = sns.PairGrid(easy_correl_train)\n", "g.map_diag(sns.kdeplot)\n", "g.map_offdiag(sns.kdeplot, cmap=\"Blues_d\", n_levels=6);"]}, {"metadata": {"_cell_guid": "deda81a0-f74b-4e72-8251-ec0c69476e47", "_uuid": "bb0930a2ab2c9e3c30773fd40b77cfe013fbe554"}, "cell_type": "markdown", "source": []}, {"metadata": {"_cell_guid": "d0152496-7cf5-43ce-9f0d-8df78846b964", "_uuid": "c363b53cdbd332cfdfedc755a877e6f75cac5bf1"}, "cell_type": "markdown", "source": ["**OK, let's start !**  \n", "*Features*"]}, {"execution_count": null, "metadata": {"_cell_guid": "5c9b0525-684d-4fbf-a4a8-148f07b616f9", "scrolled": true, "_uuid": "b40d71de9165bc2c7a2150e191a6fd9b8cc0ea1a"}, "outputs": [], "cell_type": "code", "source": ["# easy start : 3 variables : sex, age, class\n", "#Bucket / categorise age\n", "# replace sex by binary number for easier modeling (2 categories -> no need for dummyfication)\n", "# splits & categories can be parametrised to optimise split\n", "def simplify_ages(df, bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120), group_names = [10, 0, 1, 2, 3, 4, 5, 6]):\n", "                  #['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']):\n", "    #remove NA & void\n", "    idx=df['Age'].isnull()\n", "    df['Age'][idx] = -0.5\n", "    categories = pd.cut(df.Age, bins, labels=group_names)\n", "    df.Age = categories\n", "    return df\n", "\n", "def simplify_set(df):\n", "    df=simplify_ages(df)\n", "    df['Sex'] = df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n", "    return df\n", "\n", "featured_set=simplify_set(train_set[[\"Survived\",\"Age\",\"Sex\",\"Pclass\"]].copy())\n", "simple_test_set=simplify_set(test_set[[\"Age\",\"Sex\",\"Pclass\"]].copy())\n", "\n", "sns.barplot(x=\"Age\", y=\"Survived\", hue=\"Sex\", data=featured_set);"]}, {"execution_count": null, "metadata": {"_cell_guid": "eaf48d4d-49c0-4fe1-b24b-eb369ccd7452", "_uuid": "62e237cbf786c5c33885a347fbf2afcd81688968"}, "outputs": [], "cell_type": "code", "source": ["grid = sns.FacetGrid(featured_set, row='Pclass', col='Sex', size=2.2, aspect=1.6)\n", "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n", "grid.add_legend()\n", "#plt.hist2d(easy_correl_train['Pclass'], easy_correl_train['Age'])\n", "#x=easy_correl_train['Pclass'], y=easy_correl_train['Age'], c=easy_correl_train['Survived'])\n", "#simple_set=easy_correl_train[['Pclass'],['Age']].groupby(['Pclass','Age']).count()\n", "#simple_set.head()"]}, {"execution_count": null, "metadata": {}, "outputs": [], "cell_type": "code", "source": ["#from https://www.kaggle.com/dmilla/introduction-to-decision-trees-titanic-dataset\n", "from sklearn import tree\n", "from sklearn.metrics import accuracy_score\n", "from sklearn.model_selection import KFold\n", "from sklearn.model_selection import cross_val_score\n", "from IPython.display import Image as PImage\n", "from subprocess import check_call\n", "from PIL import Image, ImageDraw, ImageFont\n", "\n", "\n", "cv = KFold(n_splits=10)            # Desired number of Cross Validation folds\n", "accuracies = list()\n", "max_attributes = len(list(featured_set))\n", "depth_range = range(1, max_attributes + 1)\n", "\n", "# Testing max_depths from 1 to max attributes\n", "# Uncomment prints for details about each Cross Validation pass\n", "for depth in depth_range:\n", "    fold_accuracy = []\n", "    tree_model = tree.DecisionTreeClassifier(max_depth = depth)\n", "    print(\"Current max depth: \", depth, \"\\n\")\n", "    for train_fold, valid_fold in cv.split(featured_set):\n", "        f_train = featured_set.loc[train_fold] # Extract train data with cv indices\n", "        f_valid = featured_set.loc[valid_fold] # Extract valid data with cv indices\n", "\n", "        model = tree_model.fit(X = f_train.drop(['Survived'], axis=1), \n", "                               y = f_train[\"Survived\"]) # We fit the model with the fold train data\n", "        valid_acc = model.score(X = f_valid.drop(['Survived'], axis=1), \n", "                                y = f_valid[\"Survived\"])# We calculate accuracy with the fold validation data\n", "        fold_accuracy.append(valid_acc)\n", "\n", "    avg = sum(fold_accuracy)/len(fold_accuracy)\n", "    accuracies.append(avg)\n", "    print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n", "    # print(\"Average accuracy: \", avg)\n", "    print(\"\\n\")\n", "    \n", "# Just to show results conveniently\n", "df = pd.DataFrame({\"Max Depth\": depth_range, \"Average Accuracy\": accuracies})\n", "df = df[[\"Max Depth\", \"Average Accuracy\"]]\n", "print(df.to_string(index=False))"]}, {"execution_count": null, "metadata": {}, "outputs": [], "cell_type": "code", "source": ["# Create Numpy arrays of train, test and target (Survived) dataframes to feed into our models\n", "y_train = featured_set['Survived']\n", "x_train = featured_set.drop(['Survived'], axis=1).values \n", "x_test = simple_test_set.values\n", "\n", "depth_target=4\n", "\n", "# Create Decision Tree with max_depth\n", "decision_tree = tree.DecisionTreeClassifier(max_depth = depth_target)\n", "decision_tree.fit(x_train, y_train)\n", "\n", "# Predicting results for test dataset\n", "y_pred = decision_tree.predict(x_test)\n", "submission = pd.DataFrame({\n", "        \"PassengerId\": PassengerId,\n", "        \"Survived\": y_pred\n", "    })\n", "submission.to_csv('submission.csv', index=False)\n", "\n", "# Export our trained model as a .dot file\n", "with open(\"tree1.dot\", 'w') as f:\n", "     f = tree.export_graphviz(decision_tree,\n", "                              out_file=f,\n", "                              max_depth = depth_target,\n", "                              impurity = True,\n", "                              feature_names = list(featured_set.drop(['Survived'], axis=1)),\n", "                              class_names = ['Died', 'Survived'],\n", "                              rounded = True,\n", "                              filled= True )\n", "        \n", "#Convert .dot to .png to allow display in web notebook\n", "check_call(['dot','-Tpng','tree1.dot','-o','tree1.png'])\n", "\n", "# Annotating chart with PIL\n", "img = Image.open(\"tree1.png\")\n", "draw = ImageDraw.Draw(img)\n", "font = ImageFont.truetype('/usr/share/fonts/truetype/liberation/LiberationSerif-Bold.ttf', 26)\n", "draw.text((10, 0), # Drawing offset (position)\n", "          'tree title', # Text to draw\n", "          (0,0,255), # RGB desired color\n", "          font=font) # ImageFont object with desired font\n", "img.save('sample-out.png')\n", "PImage(\"sample-out.png\")\n", "\n", "# Code to check available fonts and respective paths\n", "# import matplotlib.font_manager\n", "# matplotlib.font_manager.findSystemFonts(fontpaths=None, fontext='ttf')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"nbconvert_exporter": "python", "mimetype": "text/x-python", "file_extension": ".py", "version": "3.6.4", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "pygments_lexer": "ipython3"}}, "nbformat_minor": 1}