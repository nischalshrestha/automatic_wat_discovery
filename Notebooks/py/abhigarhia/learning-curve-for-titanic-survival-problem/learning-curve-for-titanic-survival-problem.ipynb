{"cells":[{"metadata":{"trusted":true,"_uuid":"28ae140ad43a0191eaf05f992165747fcd9fcca1"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndf = pd.read_csv('../input/train.csv')\ny = df['Survived']\n\nX = df.drop(['Survived','PassengerId','Ticket','Name'],axis = 1)\n\nX['Age'].fillna(X['Age'].mean(), inplace = True)\n\nX['Cabin'] = X['Cabin'].isnull().astype('int')\n\nenc = LabelEncoder()\n\nX['Embarked'].fillna(method = 'pad',inplace = True)\nX['Sex'] = enc.fit_transform(X['Sex'])\nX['Embarked'] = enc.fit_transform(X['Embarked'])\n\nprint(X.head())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcf018874b25f878291792028a092dd2010fd34f"},"cell_type":"code","source":"def plot_curve(clf,title):\n    \n    train_sizes,train_scores,test_scores = learning_curve(clf,X,y,random_state = 42,cv = 5)\n\n    plt.figure()\n    plt.title(title)\n    \n    ylim = (0.7, 1.01)\n    if ylim is not None:\n        plt.ylim(*ylim)\n        \n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    \n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                train_scores_mean + train_scores_std, alpha=0.1,\n                color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n        label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n        label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    plt.show()\n\nplot_curve(LogisticRegression(),'Learning Curve of Logistic Regression')\nplot_curve(RandomForestClassifier(),'Learning Curve of Random Forest')\nplot_curve(DecisionTreeClassifier(),'Learning Curve of Decision Tree')\n\n# In this scenario random forest algorithm is doing quit good.But after doing some hyperparameter \n# tuning or some other statistical operations may be some other algorithm may also perform well or \n# simply outperform random forest. ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.0"}},"nbformat":4,"nbformat_minor":1}