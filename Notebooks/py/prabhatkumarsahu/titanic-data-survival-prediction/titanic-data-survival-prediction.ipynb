{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/train.csv\")\ntest_data= pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4647bbd38014741aafd04985992dabf4ef5549f6","collapsed":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3186ceda0e6b5f953e661a3f43d47c0f9db0835","collapsed":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"efab628152f7153fb89c56456ba9d64929ea7bc8"},"cell_type":"code","source":"# there is missing values in both datasets.\n# there is no \"Survived\" column in train_data because that is what we have to predict!  \n# my main aim is to find the \"Survived\" value for each Passenge","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"322404fab9e1f855d34acd61d445f580c138bfab"},"cell_type":"code","source":"# Before going there, let's analyse and visualise our data to get a feel of it.\n# I need only useful features to be able to predict efficiently.\n# Let's start from the first column^\n# PassengerId: It is clearly of no use; just a serial no. Let's DROP it then. \ntrain_data.drop(['PassengerId'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"872b84be819a260f441dbde3b05c8f77d0af92ca","collapsed":true},"cell_type":"code","source":"# Let's move on to the next feature 'Name'\n# Useless feature quite obviously. \n# Let's drop it\ntrain_data.drop(['Name'], axis=1, inplace=True)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"80538687ed015a5b067936aa4769309a1a580140"},"cell_type":"code","source":"# \"Survived\" == 0 indicates \"DID NOT Survive\"; 1 == \"Survived\"\n# Now, we've looked at features uptil Pclass; Next is \"Sex\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2f42d405efbcb4010f1139f037e0d4432cfaa0f9"},"cell_type":"code","source":"# There are many children, so let's study them separately.\n# Convert \"Sex\" into \"Person\" column which can take values: \"Male\", \"Female\", \"Child\"\n# Let's create a function for that\ndef what_person(passenger):\n    age,sex = passenger\n    if age <= 16:\n        return 'Child'\n    else: \n        return sex","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d30dde78b271c99c9211c6267899589cf114257","collapsed":true},"cell_type":"code","source":"# Let's \"apply\" now\ntrain_data[\"Person\"] = train_data[['Age','Sex']].apply(what_person, axis=1)\n# axis=1 specifies that the operation is to be done on columns!\n# Drop \"Sex\" now, since it is redundant\ntrain_data.drop(['Sex'], axis=1, inplace=True)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb95ac4315f514c18b50e2cb105fd385cd54cdd3","collapsed":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02852b3ac6e8ce83344d5551c70fb96f6201a49d","collapsed":true},"cell_type":"code","source":"print(\"Missing Age values:\", train_data['Age'].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf3da0e3b806270a2e8bbc58f5b0ee5bf54001a1","collapsed":true},"cell_type":"code","source":"# Let's fill the missing^ Age values now\n# Generate random numbers between mean-std & mean+std\nmean = train_data['Age'].mean()\nstd = train_data['Age'].std()\n\nr = np.random.randint(mean-std, mean+std)\ntrain_data[\"Age\"].fillna(r, inplace=True)\n\ntrain_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de96bb956ec25bd7e89129d944c07b9e456877a5","collapsed":true},"cell_type":"code","source":"# Let's look at next two features:\n# SibSp is any siblings/spouses on board?\n# Parch is any parent/child on board?\n# We could reduce these to a single feature: \"WithFamily\"?\n# This would make our feature-vector more efficient and dimensionality reduction!!\ntrain_data['WithFamily'] =train_data['SibSp'] + train_data['Parch']\ntrain_data.drop(['SibSp','Parch'], axis=1, inplace=True)\ntrain_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2c7df382adc54bbd74b971aa745059de585df8b","collapsed":true},"cell_type":"code","source":"# Let's clean that!\n# If \"WithFamily\" == 0, He was alone. Hence, value should be 0.\ntrain_data['WithFamily'].loc[train_data['WithFamily'] > 0] = 1\ntrain_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"258478655f0ee29c0513986d7c1a843c984a12f4"},"cell_type":"code","source":"# Next feature is Ticket, which is useless again.lets Remove it!\ntrain_data.drop(['Ticket'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e162620ff14cce1690173321452f8751454bd735","collapsed":true},"cell_type":"code","source":"test_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0e881a9db80d2144744ad66bf4c1a19bf4908448"},"cell_type":"code","source":"# Fare:\n# Missing values only in test_df\ntest_data[\"Fare\"].fillna(test_data[\"Fare\"].median(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b430b6feec3990c13a81cda67faa0c0d5df33a59"},"cell_type":"code","source":"# Convert from float to int\ntrain_data['Fare'] = train_data['Fare'].astype(int)\ntest_data['Fare'] = test_data['Fare'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48ca5503a301f991077ffa201ba4ea291497bdca","collapsed":true},"cell_type":"code","source":"# Let's see if they vary with Survival chances\nfare_notSurvived = train_data[\"Fare\"][train_data[\"Survived\"] == 0]\nfare_survived =train_data['Fare'][train_data[\"Survived\"] == 1]\nprint(\"Died: \", fare_notSurvived.mean())\nprint(\"Survived: \", fare_survived.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"667a87dacf9436e3ad7260f91c5d3ded944535c7","collapsed":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c859327a440a8ef40e654bdfdfd3ff6b4709a35c"},"cell_type":"code","source":"\n# Now, I've looked at \"Survived\" \"Pclass\" \"Age\" \"Fare\"# Now, w \n# Created two new features/columns \"Person\" \"WithFamily\"; also dropped some columns \n# Let's look at Cabin now:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7767f0c013845323c4854b4303e5ee536c303904","collapsed":true},"cell_type":"code","source":"# Cabin is in the format: C85 where the first letter ('C', in this case) is the deck\n# Deck seems to give out important info as compared to the room no. \n# Let's extract all decks from Cabin; let's drop null values first!\ndeck = train_data['Cabin'].dropna()\ndeck.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"927b9bcc61db527fdeb23dc0e443720e9d188376"},"cell_type":"code","source":"floor = []\nfor level in deck:\n    floor.append(level[0])\n\n# To visualise it, let's convert it into a DataFrame\ndf = pd.DataFrame(floor, columns=['Level'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8360d53f74317ca068e80bb85ead47549c90e7fe","collapsed":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"032c61174fc72e835142a80b3f01e0a3341d550c","collapsed":true},"cell_type":"code","source":"#  the 'Cabin' column has a lot of missing values.\n# On top of that, there is just one value for deck 'T' which doesn't make a lot of sense.\n# Filling 75% of the values on our own would affect prediction\n# Hence, it is better to drop this column\ntrain_data.drop('Cabin', axis=1, inplace=True)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"592a166feafbba92c1c8c12504d5be351c3539e5","collapsed":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a65978db021146b80e10f48910be8daf5937b871"},"cell_type":"code","source":"# Just two missing values! Let's fill it with \"S\" (the most frequent)# Just t \ntrain_data['Embarked'].fillna(\"S\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f8e67ffd9cf56566885dd7139619df92501d01c","collapsed":true},"cell_type":"code","source":"# Passengers that embarked at \"S\" had a less rate of survival; Let's confirm that:\nembark = train_data[['Embarked', 'Survived']].groupby(['Embarked']).mean()\nembark","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"245492248b42865fa0c542388c85f014bdf0f25d"},"cell_type":"code","source":"# Let's make our test_data compatible with train_data; since we're going to train our classifier on train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"802301374ed90875511a8c6085a6b29e63f73fb8","collapsed":true},"cell_type":"code","source":"test_data.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n\n# Now, let's create Person for test_df:\ntest_data[\"Person\"] =test_data[['Age','Sex']].apply(what_person, axis=1)\ntest_data.drop(['Sex'], inplace=True, axis=1)\n\n# Now, let's create WithFamily for test_df:\ntest_data['WithFamily'] = test_data['SibSp'] + test_data['Parch']\ntest_data.drop(['SibSp','Parch'], axis=1, inplace=True)\ntest_data['WithFamily'].loc[test_data['WithFamily'] > 0] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9915545f248af81ea024e9db5565c0050a85297e","collapsed":true},"cell_type":"code","source":"test_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99f8a431dd6e68568d8ccb80595d99d299976bad","collapsed":true},"cell_type":"code","source":"print(\"Missing: \", test_data['Age'].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"99348b656c951951dc6de12f75609ca9b90eda84"},"cell_type":"code","source":"# Let's fill in the missing Age values\nmean = test_data['Age'].mean()\nstd = test_data['Age'].std()\n\nr = np.random.randint(mean-std, mean+std)\ntest_data['Age'].fillna(r, inplace=True)\n\n# Change its dataype to int\ntrain_data['Age'] =train_data['Age'].astype(int)\ntest_data['Age'] = test_data['Age'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1dcc6bd1ad7a08b3c8630c72819264459bfff2b5","collapsed":true},"cell_type":"code","source":"test_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0cce4fa2376348953fe2a6e0508a0a0b5c57b740","collapsed":true},"cell_type":"code","source":"# There is one last issue remaining before i can feed this dataset to ML algortihm\n# Embarked & Person need to converted to Numeric variables\n# I'll use dummy variables: \n# It is a variable that takes 0/1 indicating absence/presence of a particular category\n# You can read more about it - https://en.wikipedia.org/wiki/Dummy_variable_(statistics)\n\n# EMBARKED-\ntitanic_embarked = pd.get_dummies(train_data['Embarked'])\ntitanic_embarked.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"541f1c20fdf8231cdc0944f2cfcbd3b84906e1a8","collapsed":true},"cell_type":"code","source":"train_data =train_data.join(titanic_embarked)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18bec5d14b0a7e30f1dd56b24baeb0127fd6f8d1","collapsed":true},"cell_type":"code","source":"# Person \ntitanic_person = pd.get_dummies(train_data['Person'])\ntitanic_person.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9c5395690daf77781038c377d5c669587ab4ccf","collapsed":true},"cell_type":"code","source":"train_data = train_data.join(titanic_person)\n# Let's remove Person/Embarked now\ntrain_data.drop(['Person','Embarked'], axis=1, inplace=True)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d304826256aeaeb0cb2c72533fad3222418a4290","collapsed":true},"cell_type":"code","source":"# Let's repeat the same procedure for test_data# Let's  \ntest_embarked = pd.get_dummies(test_data['Embarked'])\ntest_data = test_data.join(test_embarked)\n\ntest_person = pd.get_dummies(test_data['Person'])\ntest_data = test_data.join(test_person)\n\ntest_data.drop(['Person','Embarked'], axis=1, inplace=True)\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a7a1bb1ff02899c7a44de052268a1e08a737ddd","collapsed":true},"cell_type":"code","source":"# Now is the time set up our training and test datasets:\nx_train = train_data.drop(['Survived'], axis=1)\n\ny_train = train_data['Survived']\n\nx_test = test_data.drop(['PassengerId'], axis=1)\n\nx_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"cc42beb0066bcb4a600f292c48e0c99722bf7d28"},"cell_type":"code","source":"from sklearn import svm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4660afd0c32f5246fa8cdb7aed588118aebe6083","collapsed":true},"cell_type":"code","source":"model = svm.SVC(kernel='linear', C=1, gamma=1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0ff5cefb20957b64bb3550afdf4c548102cd35a","collapsed":true},"cell_type":"code","source":"model.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5661c22d14ee68dae237639332a199f0d656b0ad"},"cell_type":"code","source":"prediction = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68f5d6f5d0e6955c3c4a1ccb8869fc88f8e8c256","collapsed":true},"cell_type":"code","source":"prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5449934b207da023d8a7ec1910e5c94a7dbeea1","collapsed":true},"cell_type":"code","source":"model.score(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8aaa66c794fa7281ed90e490460bf4851bb7eddb","collapsed":true},"cell_type":"code","source":"# Let's finally submit !!!!\nsub_file = pd.DataFrame({'PassengerId':test_data['PassengerId'], 'Survived':prediction})\nsub_file.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fc221b5dbd3052982ad637dfc7d0be32be905999"},"cell_type":"code","source":"sub_file.to_csv('result.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e1dc04ddadc9988809d8038a9cf7a561b670156d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}