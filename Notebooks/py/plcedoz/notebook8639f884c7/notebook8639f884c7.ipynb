{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1b76c4d9-362b-9144-256d-cd5bab063ae4"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b582cb8d-875d-6bf3-8e7c-64296626a518"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f1373fd4-1895-684d-48b6-e061b8278780"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"../input/train.csv\")\n",
        "test = pd.read_csv(\"../input/test.csv\")\n",
        "train = train.drop([\"Ticket\", \"Cabin\", \"PassengerId\"], axis=1)\n",
        "test = test.drop([\"Ticket\", \"Cabin\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b527d480-109c-3930-5d25-90c0cf21b499"
      },
      "outputs": [],
      "source": [
        "#Embarked\n",
        "train['Embarked'] = train['Embarked'].fillna('S')\n",
        "test['Embarked'] = test['Embarked'].fillna('S')\n",
        "by_embarked = train.groupby('Embarked')['Survived'].mean()\n",
        "by_embarked.plot(x=by_embarked.index,y=by_embarked.values, kind='bar', figsize=(5, 3))\n",
        "\n",
        "#Create Dummies variables\n",
        "train = train.join(pd.get_dummies(train[\"Embarked\"]))\n",
        "train = train.drop(['S', 'Embarked'], axis=1)\n",
        "test = test.join(pd.get_dummies(test[\"Embarked\"]))\n",
        "test = test.drop(['S', 'Embarked'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d4be266a-a3cd-bd1d-c25e-95a053522a98"
      },
      "outputs": [],
      "source": [
        "#Age for train\n",
        "old_age = train['Age']\n",
        "n_null = train['Age'].isnull().sum()\n",
        "mean_age = train['Age'].mean()\n",
        "std_age = train['Age'].std()\n",
        "rand_age = np.random.randint(mean_age-std_age, mean_age+std_age, size = n_null)\n",
        "train.loc[np.isnan(train['Age']), \"Age\"] = rand_age\n",
        "\n",
        "#Age for test\n",
        "n_null = test['Age'].isnull().sum()\n",
        "mean_age = test['Age'].mean()\n",
        "std_age = test['Age'].std()\n",
        "rand_age = np.random.randint(mean_age-std_age, mean_age+std_age, size = n_null)\n",
        "test.loc[np.isnan(test['Age']), \"Age\"] = rand_age\n",
        "\n",
        "#plot distribution\n",
        "#plt.figure(1)\n",
        "#plt.subplot(211)\n",
        "#plt.hist(old_age, bins = 20)\n",
        "#plt.subplot(212)\n",
        "#plt.hist(train['Age'], bins = 20)\n",
        "#train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aa3b1725-8465-35e2-2dc2-7451e96c1068"
      },
      "outputs": [],
      "source": [
        "#Sex\n",
        "train.loc[train[\"Sex\"]==\"male\", \"Sex\"] = 1\n",
        "train.loc[train[\"Sex\"]==\"female\", \"Sex\"] = 0\n",
        "test.loc[test[\"Sex\"]==\"male\", \"Sex\"] = 1\n",
        "test.loc[test[\"Sex\"]==\"female\", \"Sex\"] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3c0e76c5-dcfa-bad5-4305-342dcaea214b"
      },
      "outputs": [],
      "source": [
        "#Family\n",
        "train[\"Family\"] = (train[\"SibSp\"] + train[\"Parch\"]).copy()\n",
        "train.loc[train[\"Family\"]==0, \"Family\"] = 0\n",
        "train.loc[train[\"Family\"]>0, \"Family\"] = 1\n",
        "train = train.drop([\"SibSp\", \"Parch\"], axis = 1)\n",
        "\n",
        "\n",
        "test[\"Family\"] = (test[\"SibSp\"] + test[\"Parch\"]).copy()\n",
        "test.loc[test[\"Family\"]==0, \"Family\"] = 0\n",
        "test.loc[test[\"Family\"]>0, \"Family\"] = 1\n",
        "test = test.drop([\"SibSp\", \"Parch\"], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e561b8a3-6c7f-54f4-3c83-a864e1e25196"
      },
      "outputs": [],
      "source": [
        "#Fare\n",
        "train[\"Fare\"]=train[\"Fare\"].fillna(train[\"Fare\"].mean())\n",
        "test[\"Fare\"]=test[\"Fare\"].fillna(test[\"Fare\"].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f2115c87-3c90-edc2-234e-227c85563afc"
      },
      "outputs": [],
      "source": [
        "#Name to title\n",
        "title = []\n",
        "for ind in train.index:\n",
        "    title.append(train[\"Name\"][ind].split(',')[1].split('.')[0])\n",
        "train[\"Title\"] = pd.Series(title)\n",
        "by_title = train.groupby(\"Title\")[\"Age\"].count()\n",
        "for ind in train.index:\n",
        "    if by_title[train[\"Title\"][ind]] <10:\n",
        "        train.loc[ind,\"Title\"] = \"rare\"\n",
        "        \n",
        "avg_title = train.groupby(\"Title\")[\"Survived\"].mean()\n",
        "avg_title.plot(x=avg_title.index, y=avg_title.values, kind = \"bar\")        \n",
        "        \n",
        "title_2 = []\n",
        "for ind in test.index:\n",
        "    title_2.append(test[\"Name\"][ind].split(',')[1].split('.')[0])\n",
        "test[\"Title\"] = pd.Series(title_2)\n",
        "by_title = test.groupby(\"Title\")[\"Age\"].count()\n",
        "for ind in test.index:\n",
        "    if by_title[test[\"Title\"][ind]] <10:\n",
        "        test.loc[ind,\"Title\"] = \"rare\"\n",
        "        \n",
        "#Create dummy variables\n",
        "title_dummies_train = pd.get_dummies(train[\"Title\"])\n",
        "title_dummies_train = title_dummies_train.drop([\" Mr\"], axis = 1)\n",
        "\n",
        "title_dummies_test = pd.get_dummies(test[\"Title\"])\n",
        "title_dummies_test = title_dummies_test.drop([\" Mr\"], axis = 1)\n",
        "\n",
        "train = train.join(title_dummies_train)\n",
        "test = test.join(title_dummies_test)\n",
        "\n",
        "train = train.drop([\"Name\", \"Title\"], axis=1)\n",
        "test = test.drop([\"Name\", \"Title\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3b80ce90-c405-8248-228b-00af9d38d776"
      },
      "outputs": [],
      "source": [
        "#Pclass\n",
        "\n",
        "by_pclass = train.groupby('Pclass')['Survived'].mean()\n",
        "by_pclass.plot(x=by_pclass.index, y=by_pclass.values, kind='bar', figsize=(5, 3))\n",
        "\n",
        "Pclass_dummies = pd.get_dummies(train['Pclass'])\n",
        "Pclass_dummies.columns = [\"Pclass1\", \"Pclass2\", \"Pclass3\"]\n",
        "Pclass_dummies = Pclass_dummies.drop([\"Pclass3\"], axis=1)\n",
        "train = train.join(Pclass_dummies)\n",
        "train = train.drop([\"Pclass\"], axis=1)\n",
        "\n",
        "Pclass_dummies = pd.get_dummies(test['Pclass'])\n",
        "Pclass_dummies.columns = [\"Pclass1\", \"Pclass2\", \"Pclass3\"]\n",
        "Pclass_dummies = Pclass_dummies.drop([\"Pclass3\"], axis=1)\n",
        "test = test.join(Pclass_dummies)\n",
        "test = test.drop([\"Pclass\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1efb9d04-2d02-35ff-663e-fab65a3f5a22"
      },
      "outputs": [],
      "source": [
        "test.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c3f04920-58d3-00a7-33ba-cb6d942b8a57"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#Split the dataset\n",
        "X_train = train.drop([\"Survived\"], axis=1)\n",
        "y_train = train[\"Survived\"]\n",
        "X_test = test.drop (\"PassengerId\", axis=1).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5f3e1365-f654-37cb-df34-67b931eae38e"
      },
      "outputs": [],
      "source": [
        "#Training SVM\n",
        "from sklearn.svm import SVC\n",
        "grid = {'kernel' : ['rbf'], 'C' : [1000,10000], 'gamma': [1e-3, 1e-4]}\n",
        "svc = GridSearchCV(SVC(), grid, cv=5)\n",
        "svc.fit (X_train, y_train)\n",
        "params = svc.best_params_\n",
        "cv_scores = cross_val_score (svc, X_train, y_train, cv = 5)\n",
        "print(cv_scores, params)\n",
        "y_svc = svc.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9a2dbfcb-bc41-875a-59a0-55b9278a803f"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_lr = lr.predict(X_test)\n",
        "lr.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a67ae28b-74ae-b368-af87-b0168526017c"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "grid = {'n_estimators' : [1000], 'max_features' : [2,3]}\n",
        "rf = GridSearchCV(RandomForestClassifier(), grid, cv=5)\n",
        "rf.fit (X_train, y_train)\n",
        "params = rf.best_params_\n",
        "cv_scores = cross_val_score (rf, X_train, y_train, cv = 5)\n",
        "print(cv_scores, params)\n",
        "y_rf = rf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4620b478-6768-1d92-fe25-72c2b9ae900b"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "kn = KNeighborsClassifier()\n",
        "kn.fit(X_train, y_train)\n",
        "y_kn = kn.predict(X_test)\n",
        "kn.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "736c7885-2a10-26ba-78f9-2c8d30be22d9"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB# Logistic Regression\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "y_gnb = gnb.predict(X_test)\n",
        "gnb.score(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f594dd45-5210-af14-0d6b-31db36e7ae95"
      },
      "outputs": [],
      "source": [
        "X_train_nn = X_train.values\n",
        "y_train_nn = y_train.values\n",
        "X_test_nn = X_test.values\n",
        "X_train_nn, X_valid_nn, y_train_nn, y_valid_nn = train_test_split(\n",
        "    X_train_nn, y_train_nn, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "58a4c159-6f91-09b3-cc3e-23fa45e220ff"
      },
      "outputs": [],
      "source": [
        "X_train_nn = X_train.values\n",
        "y_train_nn = y_train.values\n",
        "X_test_nn = X_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2d2979ed-8588-2d5c-34b5-cc655090a188"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "import numpy\n",
        "\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# Create Model\n",
        "def create_model(neurons_layer_1=12, neurons_layer_2=12, dropout=0.2):\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(output_dim = neurons_layer_1, input_dim=12, init='uniform', activation='relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(output_dim = neurons_layer_2, init='uniform', activation='relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
        "    # Compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, nb_epoch=50, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "neurons_layer_1=[20]\n",
        "neurons_layer_2=[20]\n",
        "dropout=[0.25]\n",
        "grid = dict(neurons_layer_1=neurons_layer_1, neurons_layer_2=neurons_layer_2, dropout=dropout)\n",
        "nn = GridSearchCV(estimator=model, param_grid=grid)\n",
        "nn = nn.fit(X_train_nn, y_train_nn)\n",
        "params = nn.best_params_\n",
        "cv_scores = cross_val_score (nn, X_train_nn, y_train_nn, cv = 5)\n",
        "print(params, cv_scores)\n",
        "#Make predictions\n",
        "y_nn = nn.predict(X_test_nn)\n",
        "y_nn[y_nn>0.5]=1\n",
        "y_nn[y_nn<0.5]=0\n",
        "y_nn = y_nn[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a569b45d-98cd-e5dc-b9ad-c88e2ab5ef5b"
      },
      "outputs": [],
      "source": [
        "cv_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "231c1c2f-ad8b-aff4-e3f2-31612365a442"
      },
      "outputs": [],
      "source": [
        "y_test = test[\"PassengerId\"]\n",
        "solution_nn = pd.DataFrame({\n",
        "    \"PassengerId\" : y_test,\n",
        "    \"Survived\" : y_nn[:,0]\n",
        "})\n",
        "solution_nn.to_csv(\"solution_nn.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "632b73f9-964a-37fc-6111-73071352cfe5"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}