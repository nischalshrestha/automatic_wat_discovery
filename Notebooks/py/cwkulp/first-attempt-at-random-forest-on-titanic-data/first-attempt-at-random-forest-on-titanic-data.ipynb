{"cells":[{"metadata":{"_uuid":"a314e45b431de3ac54059fb541b2b33be4b21abe"},"cell_type":"markdown","source":"# The titanic data set\n\nChris Kulp\n\nJuly 26, 2018\n\nThis is my first attempt at a Kaggle competition. I chose to use a Random Forest Classifier because another research  project that I am working on uses one as well. I wanted to get some experience using Random Forests before applying it to my research projet.\n\nThis notebook imports the data, targets the features I wanted to use, trains a RandomForest classifier, and makes predictions on the test data using the trained model.\n\nThis is the first kernel that I have uploaded to Kaggle."},{"metadata":{"trusted":true,"_uuid":"f607bb64669191db905642bf7d78768089683f46"},"cell_type":"code","source":"#load the necessary libraries\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix,accuracy_score\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00a30d5e6d7d2d897b4f8cce805b0ecdc0b1c656"},"cell_type":"markdown","source":"## Import and inspect data"},{"metadata":{"trusted":true,"_uuid":"9dd34dfddf986ead9f5418880a31da41507de076"},"cell_type":"code","source":"df_train = pd.read_csv('../input/train.csv',delimiter=\",\")\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57372d00b8585672416a08e2cf5f6ca202ed547e"},"cell_type":"code","source":"df_test = pd.read_csv('../input/test.csv',delimiter=\",\")\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8ff7e5f8ca7972ae27f36d24e508662ffa8415e"},"cell_type":"markdown","source":"## Data Cleaning and Feature Engineering\nI wanted to avoid columns with NaN because I didn't want to deal with replacing those values with interpolations, averages, etc... on my first attempt. Hence, I eliminated any columns with a NaN. In addition, I removed Fare on this attempt thinking that it is likely correlated with Pclass (i.e. higher class tickets cost more).\n\nI also replaced the categorical data, Embarked and Sex so that they are computable. \n"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"fb22910b1cb8dec6ea57cf3702d69a85f7440f22"},"cell_type":"code","source":"def clean_data(df):\n    df_elim_cols=df.drop(['Age','Cabin','Ticket','Fare','Embarked'],axis=1) #eliminate columns I don't want\n    df_replace_sex = df_elim_cols.replace({'Sex': {'female': 1, 'male': 2}}) #replace Sex data\n    return df_replace_sex\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"738c66c09a86322c4d6c9c49c30f7b0f453eaf36"},"cell_type":"code","source":"clean_train = clean_data(df_train)\nclean_test = clean_data(df_test)\nclean_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"1a46c88072dcb898f7e9e87b65c6e7deccf3c543"},"cell_type":"code","source":"clean_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96d2d7a047d7e0c1a6bc221e0775560608d439d8"},"cell_type":"markdown","source":"Inspired by other kernels, I decided to do some feature engineering. I created a new feature that is based on the title of the passenger."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"e3711ef4db174c055aeaa6b147a8bb5aa6fa5dc1"},"cell_type":"code","source":"def engineer_title_column(df):\n    '''This function will look at the name of each individual, determine the title in the name and assign \n    that title a number. It will then create and append a Title column to the data frame. Note that I am sure\n    that there are better ways of doing this!'''\n    \n    title_list = [] #dummy list of title numbers\n    \n    for item in df['Name']: #go through each person and identify their title and assign it a number\n        if \"Mr.\" in item:\n            title_list.append(1)\n        elif \"Mrs.\" in item:\n            title_list.append(2)\n        elif \"Miss.\" in item:\n            title_list.append(3)\n        elif \"Master.\" in item:\n            title_list.append(4)\n        elif \"Rev.\" in item:\n            title_list.append(5)\n        else:\n            title_list.append(6) #a \"catch-all\" for any other title\n        \n    titles_to_column = pd.Series(title_list) #create a pandas series\n    df['Title'] = titles_to_column.values #append the above series to the data frame\n    name_dropped = df.drop(['Name'],axis=1) #remove the name column\n    return name_dropped","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"74362680c66044fc203cd4dfb9345fccdeed744b"},"cell_type":"code","source":"training_df=engineer_title_column(clean_train)\ntest_df = engineer_title_column(clean_test)\ntraining_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"93559f507770c24111f9d7450424ee2c459630d5"},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d9c89455bef04bcfe5b68a7e853fdb4ee7d98c3"},"cell_type":"markdown","source":"## Train the model\n\nFirst I convert the data frames to NumPy arrays so that I can use the data to train the random forest classifier. "},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"3fa7c9f1cdc2f7247ce9b351bc17dc8ce5242f37"},"cell_type":"code","source":"X_train = training_df.iloc[:,2:].values #.values turns the dataframe into a numpy array (Gets rid of index)\ny_train = training_df.iloc[:,1].values\n\nX_test = test_df.iloc[:,1:].values #.values turns the dataframe into a numpy array (Gets rid of index)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"deff4d9b8bf2cae1b8e484aaa0652e7d1a5ac2e0"},"cell_type":"markdown","source":"Train the classifier."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"95a17178d166e115e50c169a69f0ca70ed213bc4"},"cell_type":"code","source":"estimator = RandomForestClassifier(n_estimators=10)\nrnd_clf = estimator\nrnd_clf.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b77beae03eb09ddf2068b4aa4e90be73d8e3fa1d"},"cell_type":"markdown","source":"Check accuracy of model on the training data. I also compute the confusion matrix. "},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"ab22cc6aec5686dfa35d5d1e511c671e0c94ba44"},"cell_type":"code","source":"y_pred = rnd_clf.predict(X_train)\nprint(accuracy_score(y_train,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"b1e4b559b82afc7f11a82db96217852f9a1ed47b"},"cell_type":"code","source":"confusion_matrix(y_train, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d070ae2f3ab6587fa012119d7b18111462ea14f5"},"cell_type":"markdown","source":"Additional feature engineering and hyperparameter tuning would likely improve the above scores, but since this is a first attempt, we'll keep moving forward. "},{"metadata":{"_uuid":"272bf57761c051c8696cee6856f647d05bfaaf3b"},"cell_type":"markdown","source":"## Make predictions on test data"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"7cbf114396e5e6be297448f0fbc03822c0a51b4e"},"cell_type":"code","source":"test_pred = rnd_clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9217460e9311f38236f2c1f73c9f0e61a8b6b21c"},"cell_type":"markdown","source":"## Prepare test results for submission\n\nI do this by adding a column of test results to the cleaned up and engineered test data frame and removing all of the feature columns. There are probably better ways of doing this..."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"e171f1bbfe12cfd0985465d1a08dcad5ea66409e"},"cell_type":"code","source":"test_df['Survived'] = test_pred\noutput_df = test_df.drop(['Pclass','Sex','SibSp','Parch','Title'],axis=1) \noutput_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"9ad50188310e2c927804a46434a1617dcd53ad8b"},"cell_type":"code","source":"#finally, export results to a submission file\n#output_df.to_csv('submission_file.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6b1d4986394d665a84672bdb9d2e00777e927c4"},"cell_type":"markdown","source":"While there is clearly room for improvement here, I found this exercise to be very helpful in learning how to put to practice my studies in machine learning. I hope you find this kernel useful in some way. Thank you for reading it."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"26f7d2da81bbceb4e2ff594f81cdd500acf8d476"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}