{"cells":[{"metadata":{"scrolled":false,"_cell_guid":"0c101bb7-d8bf-490e-bc09-f54bb4a729b9","_uuid":"d22468a87d9476db1d865a18b6c248e155dcd531","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndata_raw = pd.read_csv(\"../input/train.csv\")\ndata_val = pd.read_csv(\"../input/test.csv\")\n\ncombine = [data_raw, data_val]\n","execution_count":103,"outputs":[]},{"metadata":{"_cell_guid":"6d7e0e27-cf3d-4493-848b-f7cffae3afa3","_uuid":"c11f8a112314c8296520e516fa00e90ba84793a3","trusted":true},"cell_type":"code","source":"# 预览数据\ndata_raw.head()","execution_count":104,"outputs":[]},{"metadata":{"_cell_guid":"4b13afb7-3d25-4959-b913-1775d0c2cb57","_uuid":"ac89c481189a1131af9096b280ef432fc7e8671c","trusted":true},"cell_type":"code","source":"data_val.head()","execution_count":105,"outputs":[]},{"metadata":{"scrolled":false,"_cell_guid":"e6be5c5e-a1f6-4e1e-b4d2-7c8e42e845e6","_uuid":"0fbe8ec8743d06e1e86d18a01c00a099b077d64d","trusted":true},"cell_type":"code","source":"print(data_raw.info())\nprint('*'*40)\nprint(data_val.info())","execution_count":106,"outputs":[]},{"metadata":{"_cell_guid":"6deab857-432b-4646-aceb-1a2dea94fcc4","_uuid":"b334f82af7c2689c6bd736148a8cee068abde6b6","trusted":true},"cell_type":"code","source":"#数值变量描述\ndata_raw.describe() \ndata_val.describe(include='all')","execution_count":107,"outputs":[]},{"metadata":{"_cell_guid":"f070ab75-9103-4799-ab0d-62feea5c0091","_uuid":"a49343a3d6c45c34849625e948b7076157f3ed68"},"cell_type":"markdown","source":"# 数据预处理"},{"metadata":{"_cell_guid":"a7def010-6faa-4074-ad5f-777b8c35e0b7","_uuid":"f3ddcb2d5d095b925c58cd7aa76648d9f8ead13e"},"cell_type":"markdown","source":"### Sex"},{"metadata":{"_cell_guid":"64f25405-d090-41a7-84de-e9643a73780e","_uuid":"1c7739adbf2c0910efad14800bd3370a67275749","trusted":true},"cell_type":"code","source":"sex_mapping = {'male':1, 'female':0}\nfor df in combine:\n    df['Sex'] = df['Sex'].map(sex_mapping)\ndata_raw.head()","execution_count":108,"outputs":[]},{"metadata":{"_cell_guid":"6ca00716-3ec2-4246-8bad-b8f748fdd69f","_uuid":"b18d29b81d091d67207ea5c6431c5167904d2f96"},"cell_type":"markdown","source":"### Age"},{"metadata":{"_cell_guid":"24d27aa5-a830-42ba-9464-bccc571831f1","_uuid":"6dca823d43846a7a0b7a1ee7f6b08658a211536d","trusted":true},"cell_type":"code","source":"for df in combine:\n    df['Age'] = df['Age'].fillna(df['Age'].median())\ndata_raw.info()","execution_count":109,"outputs":[]},{"metadata":{"_cell_guid":"6926c515-9eca-4266-a4fa-4f8f68aaacb0","_uuid":"11a08ba69bc3457a7712832a938dc35c2e6c1b95"},"cell_type":"markdown","source":"### Embarked"},{"metadata":{"scrolled":false,"_cell_guid":"490d442e-9675-4928-b4f8-98686f8c3d4e","_uuid":"6f5180d69e0687cc93d382a90441c0651ea24105","trusted":true},"cell_type":"code","source":"data_raw['Embarked'] = data_raw['Embarked'].fillna('S')\ndummies1 = pd.get_dummies(data_raw['Embarked'], prefix='Embarked')\ndata_raw = pd.concat([data_raw, dummies1], axis=1)\ndata_raw.drop(['Embarked'], axis=1, inplace=True)\n# for df in combine:\n#     dummies = pd.get_dummies(df['Embarked'])\n#     df = pd.concat([df, dummies], axis=1)\n#     df.drop(['Embarked'], axis=1, inplace=True)\ndata_raw.head()\n\ndummies2 = pd.get_dummies(data_val['Embarked'], prefix='Embarked')\ndata_val = pd.concat([data_val, dummies2], axis=1)\ndata_val.drop(['Embarked'], axis=1, inplace=True)\ndata_val.head()","execution_count":110,"outputs":[]},{"metadata":{"_cell_guid":"42f3585b-0842-4bf2-a76a-7b1fb34a87db","_uuid":"9a91e563b2de7f0538c06e725d57d8331c834777"},"cell_type":"markdown","source":"### Fare"},{"metadata":{"_cell_guid":"eb96fc75-c80f-492e-8d27-6f07571f2fe7","_uuid":"f0d0ab3e4a04af6b25efb0fc72bbd0135e68ee63","trusted":true},"cell_type":"code","source":"# 缺失值处理\ndata_val['Fare'].fillna(data_val['Fare'].mean(), inplace=True)","execution_count":111,"outputs":[]},{"metadata":{"_cell_guid":"ea882245-1eb1-4b86-b860-e5d4e7dddfa5","_uuid":"b481cb9e603906d3ee198be7e9f8c35b655ddfa5"},"cell_type":"markdown","source":"### 选择哪些特征加入建模"},{"metadata":{"_cell_guid":"36fb4830-5c23-41f5-b71c-7511cd5f627f","_uuid":"da57fbf5b05888d62f62ebfc9959423aaa68ad32","trusted":true},"cell_type":"code","source":"from sklearn import model_selection\n\ncolumns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\nx_train = data_raw[columns]\ny_train = data_raw['Survived']\n#  将数据分为训练集和测试集\n# train_x, test_x, train_y, test_y = model_selection.train_test_split(x_raw, y_raw, random_state = 0)\nx_test = data_val[columns]\nx_train.shape\n\nprint(len(x_train),len(y_train))","execution_count":115,"outputs":[]},{"metadata":{"_cell_guid":"feb3ad9b-3eb5-464a-9ccd-dc183e468fbe","_uuid":"3af78179d92618846ee9c24deeb3bb3549856004","trusted":true},"cell_type":"code","source":"colormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(data.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","execution_count":113,"outputs":[]},{"metadata":{"_cell_guid":"c3260b95-faad-4116-acc3-5b8c33015c52","_uuid":"96e79a82ea4aa455334e31e778583b231cd8b5bc"},"cell_type":"markdown","source":"# 建模预测"},{"metadata":{"scrolled":false,"_cell_guid":"9efbe021-ac8a-46ad-ab6c-d65181832fe3","_uuid":"12a63fb328fd2904a893a8d76d17440e06e1a67b","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import cross_validate\n\nlr_model = LogisticRegression()\nlr_model.fit(train_x, train_y)\nscores = cross_validate(lr_model,x_raw,y_raw,cv=5)\n# 准确率\nacc = lr_model.score(train_x, train_y)\nprint(\"训练集准确率:\", acc)\nprint(\"测试集准确率:\", lr_model.score(test_x, test_y))\n\ny_pred_lr = lr_model.predict(x_val)\nscores","execution_count":44,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"6e80df0f-c097-4813-86ca-4728ef4eb249","_uuid":"39b971975605e1811f1f9d71950f672f27072db5","trusted":false},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.metrics import mean_absolute_error\nsvc = SVC()\nsvc.fit(train_x, train_y)\n\n# 准确率\nacc_svc = svc.score(train_x, train_y)\nprint(\"SVC准确率:\", acc_svc)\nprint(\"测试集准确率:\", svc.score(test_x, test_y))\n\ny_pred_svc = svc.predict(x_val)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"a87c79f1-aeb0-4659-872c-0b5de23632c2","_uuid":"46c2b82d2e18d5949413da43a70cce55bcb298dc","trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=200)\nrf.fit(train_x, train_y)\n# rf_feature = rf.fit(train_x, train_y).feature_importances_\n# print(rf_feature)\n\n# 准确率\nacc_rf = rf.score(train_x, train_y)\nprint(\"训练集准确率:\", acc_rf)\nprint(\"测试集准确率:\", rf.score(test_x, test_y))\n\ny_pred_rf = rf.predict(x_val)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"4c61fe88-0c4f-49d6-93cf-0ed1f50a81f4","_uuid":"7bbf34d1b8bff5e831126d0b383dc10b16abb9ac","trusted":false},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgb = XGBClassifier(n_estimators=200)\nxgb.fit(train_x, train_y)\n# rf_feature = rf.fit(train_x, train_y).feature_importances_\n# print(rf_feature)\n\n# 准确率\nacc_xgb = xgb.score(train_x, train_y)\nprint(\"训练集准确率:\", acc_xgb)\nprint(\"测试集准确率:\", xgb.score(test_x, test_y))\n\ny_pred_xgb = xgb.predict(x_val)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3acb714c-8d1f-4929-b5a9-abb9078f34f2","_uuid":"fa2d2f95f06f0670f26118ec931f0a9d25410b00"},"cell_type":"markdown","source":"# ensembing"},{"metadata":{"collapsed":true,"scrolled":true,"_cell_guid":"cea23cce-06b1-4813-b1dd-7669dea4fa1b","_uuid":"c4ad83dd2ce0f48c3989406b55bf44ceaf0f3146","trusted":false},"cell_type":"code","source":"from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\nimport sklearn.model_selection\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(),\n    linear_model.Perceptron(),\n    \n    #Navies Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    \n    #Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n    \n    #SVM\n    svm.SVC(probability=True),\n    svm.NuSVC(probability=True),\n    svm.LinearSVC(),\n    \n    #Trees    \n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n    \n    #Discriminant Analysis\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n\n    \n    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n    XGBClassifier()    \n    ]\n\ncv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = 0.25, random_state = 0)\n\n\nMLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\nMLA_compare = pd.DataFrame(columns = MLA_columns)\n\n#create table to compare MLA predictions\n# MLA_predict = y_raw\n\n#index through MLA and save performance to table\nrow_index = 0\nfor alg in MLA:\n\n    #set name and parameters\n    MLA_name = alg.__class__.__name__\n    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n    \n    #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n    cv_results = model_selection.cross_validate(alg, x_raw, y_raw, cv=cv_split)\n\n    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n    \n\n    #save MLA predictions - see section 6 for usage\n    alg.fit(x_raw, y_raw)\n#     MLA_predict[MLA_name] = alg.predict(x_val)\n    \n    row_index+=1\n\n    \n#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\nMLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\nMLA_compare","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"8d7a4c9d-d104-4886-b9e8-00f0ad59246c","_uuid":"e5f47660c0d4dbb01786a93376d0fdb39d2adab7","trusted":false},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\n\n#prettify using pyplot: https://matplotlib.org/api/pyplot_api.html\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bdb8ea4d-a966-4ad9-bfc9-91a265bdb406","_uuid":"9ed0e83d2db072cf5711e5e85a33ba5cbf069c38"},"cell_type":"markdown","source":"## ensembling/stacking 步骤\n1. 定义算法类\n1. 定义获取预测结果的方法\n1. 第一层模型：模型参数、算法类实例化、产出第一层预测结果、针对不同分类器的特征权重\n1. 第二层建模：将第一层预测输出作为新的特征、第一层各模型预测结果之间的相关性、第二层建模（xgboost）            "},{"metadata":{"_cell_guid":"00906015-d136-4742-8969-3225dff0575c","_uuid":"ca86521d2ce6d1efbdd5bfc44e0caa77856bd516","trusted":true,"scrolled":true},"cell_type":"code","source":"from sklearn.cross_validation import KFold\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n                              GradientBoostingClassifier, ExtraTreesClassifier)\nfrom sklearn.svm import SVC\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n        self.clf = clf(**params)\n\n    def train(self, x_train, y_train):\n        self.clf.fit(x_train, y_train)\n\n    def predict(self, x):\n        return self.clf.predict(x)\n    \n    def fit(self,x,y):\n        return self.clf.fit(x,y)\n    \n    def feature_importances(self,x,y):\n        print(self.clf.fit(x,y).feature_importances_)\n    \nntrain = x_train.shape[0]\nntest = x_test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED) \n\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    oof_test_skf = np.empty((NFOLDS, ntest))\n    \n    # 将训练集分成5份，4份用作训练，1份用作预测，共进行5次\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr) # 4/5训练集用作训练\n\n        oof_train[test_index] = clf.predict(x_te)  # 1/5训练集用作预测\n        oof_test_skf[i, :] = clf.predict(x_test)   # 对测试集进行预测\n\n    oof_test[:] = oof_test_skf.mean(axis=0)\n    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n\n\n\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth': 8,\n    'min_samples_leaf': 2,\n    'verbose': 0\n}\n\n# AdaBoost parameters\nada_params = {\n    'n_estimators': 500,\n    'learning_rate' : 0.75\n}\n\n# Gradient Boosting parameters\ngb_params = {\n    'n_estimators': 500,\n     #'max_features': 0.2,\n    'max_depth': 5,\n    'min_samples_leaf': 2,\n    'verbose': 0\n}\n\n# Support Vector Classifier parameters \nsvc_params = {\n    'kernel' : 'linear',\n    'C' : 0.025\n    }\n\n\n# Create 5 objects that represent our 4 models\nrf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)\n\n\n# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = y_train.ravel()\nx_train = x_train.values # Creates an array of the train data\nx_test = x_test.values # Creats an array of the test data\n\n# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) # Gradient Boost\nsvc_oof_train, svc_oof_test = get_oof(svc,x_train, y_train, x_test) # Support Vector Classifier\n\nprint(\"Training is complete\")\n","execution_count":116,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6dce0f7f3315594dd8a4ff9e4123a3dc1c0afbe"},"cell_type":"code","source":"rf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)","execution_count":121,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1df8efd095c5eff9adcfd6768274475ba0558a10"},"cell_type":"code","source":"import xgboost as xgb\n\nx_train2 = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train, svc_oof_train), axis=1)\nx_test2 = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test, svc_oof_test), axis=1)\n\ngbm = xgb.XGBClassifier(\n    #learning_rate = 0.02,\n n_estimators= 2000,\n max_depth= 4,\n min_child_weight= 2,\n #gamma=1,\n gamma=0.9,                        \n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread= -1,\n scale_pos_weight=1).fit(x_train2, y_train)\n\npredictions = gbm.predict(x_test2)","execution_count":129,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"865b8e261a96be19b80684ea29fece8d459c061a"},"cell_type":"code","source":"# 准确率\nacc_xgb = gbm.score(x_train2, y_train)\nprint(\"训练集准确率:\", acc_xgb)","execution_count":132,"outputs":[]},{"metadata":{"_cell_guid":"bffd09a9-fec9-4d7a-859c-80589527ae4d","_uuid":"42cda5949ae55ac086c3f38794e4c944d66f96c9"},"cell_type":"markdown","source":" # 提交预测结果"},{"metadata":{"collapsed":true,"scrolled":true,"_cell_guid":"e8e3f68e-d0dd-4ff4-b9c6-5860dda129fc","_uuid":"2b5bee1bccb7fa83d841f46dad1a3f3f73d8d0fc","trusted":true},"cell_type":"code","source":"my_submission = pd.DataFrame({'PassengerId':data_val.PassengerId, 'Survived':predictions})\nmy_submission.to_csv('titanic_submission.csv', index=False)\n","execution_count":133,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"850c2e49-bf70-431f-a893-8d7a7171cf80","_uuid":"242382f12bec632ce975b7035c7787afc371fd09","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}