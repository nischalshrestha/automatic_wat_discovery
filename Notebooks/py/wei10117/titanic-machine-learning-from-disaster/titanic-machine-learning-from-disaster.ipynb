{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b29fdb6d-5f1c-0b57-640a-311fe21a72b8"
      },
      "source": [
        "#**Titanic: Machine Learning from Disaster**\n",
        "\n",
        "The notebook is about predicting the Titanic Survivors with basic Machine Learning process in Python. It's also my first Kaggle Challenge. I am still working on improving the accuracy of my model. Please feel free to give me some feedback.\n",
        "\n",
        "# **content**\n",
        "**1. Introduction**\n",
        "   \n",
        "1.1 Understanding the Problem  \n",
        "1.2 Goal and Metric  \n",
        "1.3 Exploring the Data \n",
        "\n",
        "**2. Data Cleaning**\n",
        "\n",
        "**3. Model and Prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "75dfde7a-a980-70ce-3ee2-246db662c61b"
      },
      "source": [
        "# 1. Introduction\n",
        "\n",
        "## 1.1 Problem Understanding  \n",
        "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
        "\n",
        "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
        "\n",
        "the challenge is to complete the analysis of what sorts of people were likely to survive and to apply the tools of machine learning to predict which passengers survived the tragedy.\n",
        "\n",
        "## 1.2 Goal and Metric\n",
        "\n",
        " - Goal: To predict if a passenger survived the sinking of the Titanic or not.   \n",
        " - Metric: Accuracy, The percentage of passengers the model correctly predict. \n",
        "\n",
        "## 1.3 Exploring the Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "58e3e546-88b8-5e74-5051-c2a6d2ef6996"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "train = pd.read_csv('../input/train.csv')\n",
        "test = pd.read_csv('../input/test.csv')\n",
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "508aaa37-1a92-7bde-6834-4b5fd0b03ffc"
      },
      "outputs": [],
      "source": [
        "train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8311a09e-c00d-6c3f-5149-61a74a6b8a74"
      },
      "outputs": [],
      "source": [
        "# show the overall survival rate (38.38), as the standard when choosing the fts\n",
        "print('Overall Survival Rate:',train['Survived'].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "95804645-44c1-6334-866a-0c0da4f4b7f5"
      },
      "source": [
        "# 2. Data Cleaning and Features Choosing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f46c8089-3caf-250a-4eee-a0908f57514d"
      },
      "outputs": [],
      "source": [
        "# get_dummies function\n",
        "def dummies(col,train,test):\n",
        "    train_dum = pd.get_dummies(train[col])\n",
        "    test_dum = pd.get_dummies(test[col])\n",
        "    train = pd.concat([train, train_dum], axis=1)\n",
        "    test = pd.concat([test,test_dum],axis=1)\n",
        "    train.drop(col,axis=1,inplace=True)\n",
        "    test.drop(col,axis=1,inplace=True)\n",
        "    return train, test\n",
        "\n",
        "# get rid of the useless cols\n",
        "dropping = ['PassengerId', 'Name', 'Ticket']\n",
        "train.drop(dropping,axis=1, inplace=True)\n",
        "test.drop(dropping,axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b5b2257e-0995-d95b-d514-8905c4da7f4b"
      },
      "outputs": [],
      "source": [
        "#pclass\n",
        "# ensure no na contained\n",
        "print(train.Pclass.value_counts(dropna=False))\n",
        "sns.factorplot('Pclass', 'Survived',data=train, order=[1,2,3])\n",
        "# according to the graph, we found there are huge differences between\n",
        "# each pclass group. keep the ft\n",
        "train, test = dummies('Pclass', train, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5634cdbb-ddb8-bb7f-f4bb-b6e4867f35bf"
      },
      "outputs": [],
      "source": [
        "# sex\n",
        "print(train.Sex.value_counts(dropna=False))\n",
        "sns.factorplot('Sex','Survived', data=train)\n",
        "# female survival rate is way better than the male\n",
        "train, test = dummies('Sex', train, test)\n",
        "# cos the male survival rate is so low, delete the male col\n",
        "train.drop('male',axis=1,inplace=True)\n",
        "test.drop('male',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "49527b86-4dd8-36c2-e4ed-47f2e432bae8"
      },
      "outputs": [],
      "source": [
        "#age \n",
        "#dealing the missing data\n",
        "nan_num = train['Age'].isnull().sum()\n",
        "# there are 177 missing value, fill with random int\n",
        "age_mean = train['Age'].mean()\n",
        "age_std = train['Age'].std()\n",
        "filling = np.random.randint(age_mean-age_std, age_mean+age_std, size=nan_num)\n",
        "train['Age'][train['Age'].isnull()==True] = filling\n",
        "nan_num = train['Age'].isnull().sum()\n",
        "\n",
        "# dealing the missing val in test\n",
        "nan_num = test['Age'].isnull().sum()\n",
        "# 86 null\n",
        "age_mean = test['Age'].mean()\n",
        "age_std = test['Age'].std()\n",
        "filling = np.random.randint(age_mean-age_std,age_mean+age_std,size=nan_num)\n",
        "test['Age'][test['Age'].isnull()==True]=filling\n",
        "nan_num = test['Age'].isnull().sum()\n",
        "\n",
        "#look into the age col\n",
        "s = sns.FacetGrid(train,hue='Survived',aspect=3)\n",
        "s.map(sns.kdeplot,'Age',shade=True)\n",
        "s.set(xlim=(0,train['Age'].max()))\n",
        "s.add_legend()\n",
        "\n",
        "# from the graph, we see that the survival rate of children\n",
        "# is higher than other and the 15-30 survival rate is lower\n",
        "def under15(row):\n",
        "    result = 0.0\n",
        "    if row<15:\n",
        "        result = 1.0\n",
        "    return result\n",
        "def young(row):\n",
        "    result = 0.0\n",
        "    if row>=15 and row<30:\n",
        "        result = 1.0\n",
        "    return result\n",
        "\n",
        "train['under15'] = train['Age'].apply(under15)\n",
        "test['under15'] = test['Age'].apply(under15)\n",
        "train['young'] = train['Age'].apply(young)\n",
        "test['young'] = test['Age'].apply(young)\n",
        "\n",
        "train.drop('Age',axis=1,inplace=True)\n",
        "test.drop('Age',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "541ebae8-13b1-5c2f-365f-2ec3ec827ad7"
      },
      "outputs": [],
      "source": [
        "#family\n",
        "# chek\n",
        "print(train['SibSp'].value_counts(dropna=False))\n",
        "print(train['Parch'].value_counts(dropna=False))\n",
        "\n",
        "sns.factorplot('SibSp','Survived',data=train,size=5)\n",
        "sns.factorplot('Parch','Survived',data=train,size=5)\n",
        "\n",
        "'''through the plot, we suggest that with more family member, \n",
        "the survival rate will drop, we can create the new col\n",
        "add up the parch and sibsp to check our theory''' \n",
        "train['family'] = train['SibSp'] + train['Parch']\n",
        "test['family'] = test['SibSp'] + test['Parch']\n",
        "sns.factorplot('family','Survived',data=train,size=5)\n",
        "\n",
        "train.drop(['SibSp','Parch'],axis=1,inplace=True)\n",
        "test.drop(['SibSp','Parch'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ade4acd4-5e83-1894-c424-903afe44cdd4"
      },
      "outputs": [],
      "source": [
        "# fare\n",
        "# checking null, found one in test group. leave it alone til we find out\n",
        "# wether we should use this ft\n",
        "train.Fare.isnull().sum()\n",
        "test.Fare.isnull().sum()\n",
        "\n",
        "sns.factorplot('Survived','Fare',data=train,size=5)\n",
        "#according to the plot, smaller fare has higher survival rate, keep it\n",
        "#dealing the null val in test\n",
        "test['Fare'].fillna(test['Fare'].median(),inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9643756d-9325-28bf-3264-0dd107eac145"
      },
      "outputs": [],
      "source": [
        "#Cabin\n",
        "# checking missing val\n",
        "# 687 out of 891 are missing, drop this col\n",
        "train.Cabin.isnull().sum()\n",
        "train.drop('Cabin',axis=1,inplace=True)\n",
        "test.drop('Cabin',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "567560ea-434c-9919-d66c-c1eb2c7f20ee"
      },
      "outputs": [],
      "source": [
        "#Embark\n",
        "train.Embarked.isnull().sum()\n",
        "# 2 missing value\n",
        "train.Embarked.value_counts()\n",
        "# fill the majority val,'s', into missing val col\n",
        "train['Embarked'].fillna('S',inplace=True)\n",
        "\n",
        "sns.factorplot('Embarked','Survived',data=train,size=6)\n",
        "# c has higher survival rate, drop the other two\n",
        "train,test = dummies('Embarked',train,test)\n",
        "train.drop(['S','Q'],axis=1,inplace=True)\n",
        "test.drop(['S','Q'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6020aa37-3e1d-21d1-18c1-d3e8243e59da"
      },
      "source": [
        "# 3. Model and Prediction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9359358e-43e3-30c1-3eb6-5e2b70f59987"
      },
      "outputs": [],
      "source": [
        "# import machine learning libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "def modeling(clf,ft,target):\n",
        "    acc = cross_val_score(clf,ft,target,cv=kf)\n",
        "    acc_lst.append(acc.mean())\n",
        "    return \n",
        "\n",
        "accuracy = []\n",
        "def ml(ft,target,time):\n",
        "    accuracy.append(acc_lst)\n",
        "\n",
        "    #logisticregression\n",
        "    logreg = LogisticRegression()\n",
        "    modeling(logreg,ft,target)\n",
        "    #RandomForest\n",
        "    rf = RandomForestClassifier(n_estimators=50,min_samples_split=4,min_samples_leaf=2)\n",
        "    modeling(rf,ft,target)\n",
        "    #svc\n",
        "    svc = SVC()\n",
        "    modeling(svc,ft,target)\n",
        "    #knn\n",
        "    knn = KNeighborsClassifier(n_neighbors = 3)\n",
        "    modeling(knn,ft,target)\n",
        "    \n",
        "    \n",
        "    # see the coefficient\n",
        "    logreg.fit(ft,target)\n",
        "    feature = pd.DataFrame(ft.columns)\n",
        "    feature.columns = ['Features']\n",
        "    feature[\"Coefficient Estimate\"] = pd.Series(logreg.coef_[0])\n",
        "    print(feature)\n",
        "    return "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8ab38d92-85bc-72c4-6091-c365ecd01832"
      },
      "outputs": [],
      "source": [
        "# testing no.1, using all the feature\n",
        "train_ft=train.drop('Survived',axis=1)\n",
        "train_y=train['Survived']\n",
        "#set kf\n",
        "kf = KFold(n_splits=3,random_state=1)\n",
        "acc_lst = []\n",
        "ml(train_ft,train_y,'test_1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "330ec3f8-463c-0d82-5aea-789ca4ba7782"
      },
      "outputs": [],
      "source": [
        "# testing 2, lose young\n",
        "train_ft_2=train.drop(['Survived','young'],axis=1)\n",
        "test_2 = test.drop('young',axis=1)\n",
        "train_ft.head()\n",
        "\n",
        "# ml\n",
        "kf = KFold(n_splits=3,random_state=1)\n",
        "acc_lst=[]\n",
        "ml(train_ft_2,train_y,'test_2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "24c370cb-e624-1c44-6dad-52749f4ae00f"
      },
      "outputs": [],
      "source": [
        "#test3, lose young, c\n",
        "train_ft_3=train.drop(['Survived','young','C'],axis=1)\n",
        "test_3 = test.drop(['young','C'],axis=1)\n",
        "train_ft.head()\n",
        "\n",
        "# ml\n",
        "kf = KFold(n_splits=3,random_state=1)\n",
        "acc_lst = []\n",
        "ml(train_ft_3,train_y,'test_3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2ea7e76f-9cf9-e4cc-e156-6058d534888b"
      },
      "outputs": [],
      "source": [
        "# test4, no FARE\n",
        "train_ft_4=train.drop(['Survived','Fare'],axis=1)\n",
        "test_4 = test.drop(['Fare'],axis=1)\n",
        "train_ft.head()\n",
        "# ml\n",
        "kf = KFold(n_splits=3,random_state=1)\n",
        "acc_lst = []\n",
        "ml(train_ft_4,train_y,'test_4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "45142dc9-6146-065c-00a0-9c05d88588ed"
      },
      "outputs": [],
      "source": [
        "# test5, get rid of c \n",
        "train_ft_5=train.drop(['Survived','C'],axis=1)\n",
        "test_5 = test.drop('C',axis=1)\n",
        "\n",
        "# ml\n",
        "kf = KFold(n_splits=3,random_state=1)\n",
        "acc_lst = []\n",
        "ml(train_ft_5,train_y,'test_5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cc86c101-e612-5dcd-cef7-ae30024a1403"
      },
      "outputs": [],
      "source": [
        "# test6, lose Fare and young\n",
        "train_ft_6=train.drop(['Survived','Fare','young'],axis=1)\n",
        "test_6 = test.drop(['Fare','young'],axis=1)\n",
        "train_ft.head()\n",
        "# ml\n",
        "kf = KFold(n_splits=3,random_state=1)\n",
        "acc_lst = []\n",
        "ml(train_ft_6,train_y,'test_6')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "88809257-8fe7-3e42-63e4-79adb3ec407f"
      },
      "outputs": [],
      "source": [
        "accuracy_df=pd.DataFrame(data=accuracy,\n",
        "                         index=['test1','test2','test3','test4','test5','test6'],\n",
        "                         columns=['logistic','rf','svc','knn'])\n",
        "accuracy_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5ecb8b71-d34a-d832-5ec8-0ed364e5e35a"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "According to the accuracy chart, 'features test4 with svc'\n",
        "got best performance\n",
        "'''  \n",
        "#test4 svc as submission\n",
        "svc = SVC()\n",
        "svc.fit(train_ft_4,train_y)\n",
        "svc_pred = svc.predict(test_4)\n",
        "print(svc.score(train_ft_4,train_y))\n",
        "\n",
        "\n",
        "test = pd.read_csv('../input/test.csv')\n",
        "submission = pd.DataFrame({\n",
        "        \"PassengerId\": test[\"PassengerId\"],\n",
        "        \"Survived\": svc_pred\n",
        "    })\n",
        "#submission.to_csv(\"kaggle.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}