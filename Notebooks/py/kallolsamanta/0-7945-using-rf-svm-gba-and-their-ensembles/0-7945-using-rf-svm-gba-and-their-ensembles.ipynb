{"nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "version": "3.6.4", "mimetype": "text/x-python", "file_extension": ".py", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "name": "python"}}, "nbformat_minor": 1, "cells": [{"cell_type": "code", "source": ["import pandas as pd\n", "import numpy as np"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#read the files\n", "titanicTrain=pd.read_csv(\"../input/train.csv\")\n", "titanicTest=pd.read_csv(\"../input/test.csv\")"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#display first five row of train data\n", "titanicTrain.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#display first five row of the test data\n", "titanicTest.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#find total no. of records in train data\n", "titanicTrain.PassengerId.count()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#removing unwanted columns from the dataframe\n", "#name, passanger id, cabin doesn't make any sense for prediction\n", "#Same goes for embarked\n", "titanicTrain=titanicTrain.drop('Ticket',1)\n", "titanicTrain=titanicTrain.drop('Fare',1)\n", "titanicTrain=titanicTrain.drop('Cabin',1)\n", "titanicTrain=titanicTrain.drop('PassengerId',1)\n", "titanicTrain=titanicTrain.drop('Embarked',1)\n", "titanicTrain=titanicTrain.drop('Name',1)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#Same thing will be done for test data as well\n", "titanicTest=titanicTest.drop('Ticket',1)\n", "titanicTest=titanicTest.drop('Fare',1)\n", "titanicTest=titanicTest.drop('Cabin',1)\n", "titanicTest=titanicTest.drop('PassengerId',1)\n", "titanicTest=titanicTest.drop('Embarked',1)\n", "titanicTest=titanicTest.drop('Name',1)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#now check for train data\n", "titanicTrain.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#test data\n", "titanicTest.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#now we found that ticket is also not required\n", "#let's remove tickets as well\n", "#titanicTrain=titanicTrain.drop('Ticket',1)\n", "#titanicTest=titanicTest.drop('Ticket',1)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#now we found that there are two categories in sex(e.g. male and female) We can create another category as child based on age.\n", "#so first let's check if any null value present in age and sex column\n", "print (sum(titanicTrain.Sex.isnull()))\n", "print (sum(titanicTrain.Age.isnull()))"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#we found 177 null values for age column should we replace those with some value or can we go for removing those columns\n", "#lets check if the data is imbalanced\n", "from collections import Counter\n", "Counter(titanicTrain.Survived)"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#lets check the same for those 177 rows\n", "nullRaw=pd.read_csv(\"../input/train.csv\")\n", "nullData=nullRaw[(nullRaw.Age.isnull())]"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#Lets check\n", "Counter(nullData.Survived)"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#check for null data head\n", "nullData.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#create another dataframe where age is not null\n", "notNullData=nullRaw[(nullRaw.Age.notnull())]"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#check the head for notNullData\n", "notNullData.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#now I will apply random forest methode to replace missing age values\n", "#so we need to remove unwanted columns\n", "notNullData=notNullData.drop('Survived',1)\n", "notNullData=notNullData.drop('PassengerId',1)\n", "notNullData=notNullData.drop('Name',1)\n", "notNullData=notNullData.drop('Ticket',1)\n", "notNullData=notNullData.drop('Cabin',1)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#calling sklearn library to apply random forest\n", "from sklearn.ensemble import RandomForestRegressor"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#importing necessary files\n", "from sklearn.model_selection import train_test_split"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["modelRF=RandomForestRegressor()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["notNullData.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["notNullData.iloc[:,[0,1,3,4,5,6]].head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#converting into dummies for sex and Embarked\n", "notNullData.Sex=pd.get_dummies(notNullData.Sex)\n", "notNullData.Embarked=pd.get_dummies(notNullData.Embarked)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#passing parameters in random forest classifier for creating the model\n", "modelRF.fit(np.array(notNullData.iloc[:,[0,1,3,4,5,6]]),notNullData.iloc[:,2])"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["nullData=nullData.drop('Survived',1)\n", "nullData=nullData.drop('PassengerId',1)\n", "nullData=nullData.drop('Name',1)\n", "nullData=nullData.drop('Ticket',1)\n", "nullData=nullData.drop('Cabin',1)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["nullData=nullData.drop('Age',1)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["nullData.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#converting into dummies for sex and embarked\n", "nullData.Embarked=pd.get_dummies(nullData.Embarked)\n", "nullData.Sex=pd.get_dummies(nullData.Sex)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#check for nullData\n", "nullData.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#remove Survived and Age for prediction\n", "#nullData=nullData.drop('Survived',1)\n", "#nullData=nullData.drop('Age',1)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#check again\n", "#nullData.head()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#storing the predicted value\n", "p=modelRF.predict(nullData)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#assigning the predicted value in place of NA\n", "nullData['Age']=p"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#checking again\n", "nullData.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#check for not null data head\n", "notNullData.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#check the titanic train\n", "titanicTrain.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#titanicTrain.iloc[1,3]==nullData\n", "#pd.isnull(titanicTrain.iloc[1,3])==False\n", "p[0]"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["x=0\n", "for i in range(0,890):\n", "    if(pd.isnull(titanicTrain.iloc[i,3])==True):\n", "        titanicTrain.iloc[i,3]=p[x]\n", "        x=x+1"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#check for titanicData if it got replaced\n", "sum(titanicTrain.Age.isnull())"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#so it NA got replaced\n", "#lets see titanic data again for further analysis\n", "titanicTrain.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#adding a new column\n", "titanicTrain['Child']=np.nan"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#right now we have two categories of sex, either male or female but in original titanic movie, child had a big impact.\n", "#so we will create another class child in sex who had age less than 12 years\n", "for i in range(0,891):\n", "    if(titanicTrain.iloc[i,3]<=12):\n", "        titanicTrain['Child']='child'\n", "    else:\n", "        titanicTrain['Child']='adult'"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#convert Sex and Child into dummies\n", "titanicTrain.Child=pd.get_dummies(titanicTrain.Child)\n", "titanicTrain.Sex=pd.get_dummies(titanicTrain.Sex)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["titanicTrain.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#now we can find the family size by adding SibSp and Parch\n", "titanicTrain['FamilySize']=np.nan\n", "for i in range(0,891):\n", "    titanicTrain.iloc[i,7]=titanicTrain.iloc[i,4]+titanicTrain.iloc[i,5]"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#now delete SibSp and Parch columns\n", "#titanicTrain=titanicTrain.drop('SibSp',1)\n", "#titanicTrain=titanicTrain.drop('Parch',1)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#Final EDA\n", "titanicTrain.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#adding dummy variables for sex\n", "#titanicTrain.Sex=pd.get_dummies(titanicTrain.Sex)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#adding libraries for cross validation\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.model_selection import cross_val_predict"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#applying train test split to measure the accuracy\n", "#xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,4,5,6,7]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#xtrain.head()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#use random forest first for prediction:\n", "from sklearn.ensemble import RandomForestClassifier\n", "rf=RandomForestClassifier()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#cross validation scores using all colums got after EDA\n", "#rf_cv_score=cross_val_score(estimator=rf,X=xtrain,y=xtest,cv=5)\n", "#rf_cv_score.mean()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#applying train test split to measure the accuracy\n", "#we are removing SibSp column from EDA\n", "#xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,5,6,7]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#cross validation scores after removing sibsp colums got after EDA\n", "#rf_cv_score=cross_val_score(estimator=rf,X=xtrain,y=xtest,cv=5)\n", "#rf_cv_score.mean()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#applying train test split to measure the accuracy\n", "#we are removing ParCh column from EDA\n", "#xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,4,6,7]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#cross validation scores After removing Parch colums got after EDA\n", "#rf_cv_score=cross_val_score(estimator=rf,X=xtrain,y=xtest,cv=5)\n", "#rf_cv_score.mean()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#applying train test split to measure the accuracy\n", "#we are removing ParCh and SibSp column from EDA\n", "#xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,6,7]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#cross validation scores after removing parch and sibsp colums got after EDA\n", "#rf_cv_score=cross_val_score(estimator=rf,X=xtrain,y=xtest,cv=5)\n", "#rf_cv_score.mean()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#we found if we remove SIBSP colums from the final EDA we got the better accuray as we dont know which columns to remove.\n", "#So the final rf model will be build after removing sibSp column from the final EDA"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#we need the same EDA for test data as well\n", "#lets check the titanic test data at first\n", "nullRaw=pd.read_csv(\"../input/test.csv\")\n", "\n", "nullData=nullRaw[(nullRaw.Age.isnull())]\n", "notNullData=nullRaw[(nullRaw.Age.notnull())]\n", "\n", "notNullData=notNullData.drop('PassengerId',1)\n", "notNullData=notNullData.drop('Name',1)\n", "notNullData=notNullData.drop('Ticket',1)\n", "notNullData=notNullData.drop('Cabin',1)\n", "\n", "nullData=nullData.drop('PassengerId',1)\n", "nullData=nullData.drop('Name',1)\n", "nullData=nullData.drop('Ticket',1)\n", "nullData=nullData.drop('Cabin',1)\n", "nullData=nullData.drop('Age',1)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["nullData.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["notNullData.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#check if there is any null value in age\n", "print (sum(titanicTest.Age.isnull()))"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#we have one null value in fare and 86 values in Age.\n", "#we will apply mean value for one null fare\n", "#we will use random forest for null age values like train data\n", "#check how many rows are there in test data\n", "titanicTest.Pclass.count()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["notNullData.head()\n", "sum(notNullData.Fare.isnull())"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["for i in range(0,notNullData.Pclass.count()):\n", "    if(pd.isnull(notNullData.iloc[i,5])==True):\n", "        notNullData.iloc[i,5]=notNullData.Fare.mean()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#creating test data where age is null\n", "#nullTest=titanicTest[titanicTest.Age.isnull()]"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#creating not null test data\n", "#notNullTest=titanicTest[titanicTest.Age.notnull()]"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#lets check for not null test data\n", "nullData.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["notNullData.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#converting sex,embarked into dummy variables\n", "nullData.Sex=pd.get_dummies(nullData.Sex)\n", "nullData.Embarked=pd.get_dummies(nullData.Embarked)\n", "notNullData.Sex=pd.get_dummies(notNullData.Sex)\n", "notNullData.Embarked=pd.get_dummies(notNullData.Embarked)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#applying random forest for test\n", "testRF=RandomForestRegressor()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#fitting data\n", "modelTestRF=testRF.fit(np.array(notNullData.iloc[:,[0,1,3,4,5,6]]),notNullData.iloc[:,2])"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#assigning the predicted value into a variable\n", "z=modelTestRF.predict(nullData)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#check for the values in z\n", "z[1]"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["titanicTest.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#assigning these falues into titanic test data set\n", "x=0\n", "for i in range(0,418):\n", "    if(pd.isnull(titanicTest.iloc[i,2])==True):\n", "        titanicTest.iloc[i,2]=z[x]\n", "        x=x+1"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#check for titanic test data\n", "titanicTest.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#adding a new column\n", "titanicTest['Child']=np.nan\n", "#assigning the values\n", "for i in range(0,418):\n", "    if(titanicTest.iloc[i,2]<=12):\n", "        titanicTest['Child']='child'\n", "    else:\n", "        titanicTest['Child']='adult'"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#check if the column child is created\n", "titanicTest.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#creating dummy variable for Sex and child category\n", "titanicTest.Sex=pd.get_dummies(titanicTest.Sex)\n", "titanicTest.Child=pd.get_dummies(titanicTest.Child)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#creating family size for test data\n", "titanicTest['FamilySize']=np.nan\n", "for i in range(0,418):\n", "    titanicTest.iloc[i,6]=titanicTest.iloc[i,3]+titanicTest.iloc[i,4]"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["titanicTest.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#applying train test split to measure the accuracy\n", "#we are removing SibSp column from EDA\n", "#xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,5,6,7]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#titanicTest.head()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["titanicTrain.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["Counter(titanicTrain.Survived)"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#we found that this is an imbalanced dataset, so we are balancing it by undersampling\n", "titanicTrain1=titanicTrain[titanicTrain.Survived==1]"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#fetching those rows having target class as zero\n", "titanicTrain2=titanicTrain[titanicTrain.Survived==0]"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#taking a sample of 342\n", "titanicTrain0=titanicTrain2.sample(n=342)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#joining two different datasets\n", "titanicTrain=titanicTrain1.append(titanicTrain2)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["titanicTrain=titanicTrain.sample(frac=1).reset_index(drop=True)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#creating test set and train set for cross validation\n", "xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,4,6]],titanicTrain['Survived'],test_size=0.25,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["xtrain.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#now we are going to apply random forest but with some parameter tuning let's check for the accuracy \n", "#cross validation scores using all colums got after EDA\n", "m=1\n", "for i in range (0,10):\n", "        rf=RandomForestClassifier(max_depth=m)\n", "        rf_cv_score=cross_val_score(estimator=rf,X=xtrain,y=xtest,cv=5)\n", "        print (rf_cv_score.mean())\n", "        m=m+1"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#now we are going to apply random forest but with some parameter tuning let's check for the accuracy \n", "#cross validation scores using all colums got after EDA\n", "m=65\n", "for i in range (0,20):\n", "        rf=RandomForestClassifier(max_depth=4,n_estimators=m)\n", "        rf_cv_score=cross_val_score(estimator=rf,X=xtrain,y=xtest,cv=5)\n", "        print (rf_cv_score.mean())\n", "        m=m+1"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#so we found the parameters\n", "#let's predict for the test data\n", "rfFinalModel=RandomForestClassifier(max_depth=6,n_estimators=74)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#lets check the data before fitting\n", "titanicTrain.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["xtrain.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#we found parch and family are not required for final model, we are not putting it\n", "rfFinalModel.fit(titanicTrain.iloc[:,[1,2,3,4,6]],titanicTrain['Survived'])"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["ytrain.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#x=sclf.predict(ytrain)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["from sklearn import metrics"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#metrics.accuracy_score(x,ytest)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["ytrain.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#model got build, now check for test data before predicting\n", "titanicTest.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#Lets predict and store it\n", "rfModelOutput=rfFinalModel.predict(titanicTest.iloc[:,[0,1,2,3,5]])"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["Counter(rfModelOutput)\n", "#titanicTest.Age.count()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#now we will use SVM for another model we will do ensambling later.\n", "from sklearn import svm"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["modelSvm=svm.SVC()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#applying train test split to measure the accuracy\n", "#xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,4,5,6,7]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#cross validation scores using all colums got after EDA\n", "#rf_cv_score=cross_val_score(estimator=modelSvm,X=xtrain,y=xtest,cv=5)\n", "#rf_cv_score.mean()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#applying train test split to measure the accuracy\n", "#we are removing SibSp column from EDA\n", "#xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,5,6,7]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#cross validation scores after removing sibsp colums got after EDA\n", "#rf_cv_score=cross_val_score(estimator=modelSvm,X=xtrain,y=xtest,cv=5)\n", "#rf_cv_score.mean()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#applying train test split to measure the accuracy\n", "#we are removing ParCh column from EDA\n", "#xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,4,6,7]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#cross validation scores After removing Parch colums got after EDA\n", "#rf_cv_score=cross_val_score(estimator=modelSvm,X=xtrain,y=xtest,cv=5)\n", "#rf_cv_score.mean()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#applying train test split to measure the accuracy\n", "#we are removing ParCh and SibSp column from EDA\n", "#xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,6,7]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#cross validation scores after removing parch and sibsp colums got after EDA\n", "#rf_cv_score=cross_val_score(estimator=modelSvm,X=xtrain,y=xtest,cv=5)\n", "#rf_cv_score.mean()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#for final one\n", "xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,4,6]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#here the the train set with all the variables are giving better results\n", "#lets tune the parameters befor creating final model 8202\n", "m=4.5\n", "for i in range(0,10):\n", "    modelSvm=svm.SVC(kernel='rbf',C=m)\n", "    svm_cv_score=cross_val_score(estimator=modelSvm,X=xtrain,y=xtest,cv=5)\n", "    print (svm_cv_score.mean())\n", "    m=m+0.1"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#so we found if cost is 0.04 the accuracy is maximum, lets find the gamma function lets predict the output\n", "#but lets check the train and test data first\n", "titanicTrain.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["titanicTest.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#fit the model 0.4\n", "modelSvm=svm.SVC(kernel='rbf',C=5)\n", "modelSvm.fit(titanicTrain.iloc[:,[1,2,3,4,6]],titanicTrain['Survived'])"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#lets predict the output\n", "svmModelOutput=modelSvm.predict(titanicTest.iloc[:,[0,1,2,3,5]])"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["Counter(svmModelOutput)"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#gradiant boosting\n", "from sklearn.ensemble import GradientBoostingClassifier\n", "modelGradBoost=GradientBoostingClassifier(max_depth=4,min_samples_leaf=4)\n", "modelGradBoost.fit(titanicTrain.iloc[:,[1,2,3,4,6]],titanicTrain['Survived'])"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["m=2\n", "for i in range(0,10):\n", "    modelGradBoost=GradientBoostingClassifier(max_depth=4,min_samples_split=m)\n", "    svm_cv_score=cross_val_score(estimator=modelGradBoost,X=xtrain,y=xtest,cv=5)\n", "    print (svm_cv_score.mean())\n", "    m=m+1"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["modelGradBoost=GradientBoostingClassifier(max_depth=4,min_samples_split=5)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#cross validation scores using all colums got after EDA\n", "rf_cv_score=cross_val_score(estimator=modelGradBoost,X=xtrain,y=xtest,cv=5)\n", "rf_cv_score.mean()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#fitting the data\n", "modelGradBoost.fit(titanicTrain.iloc[:,[1,2,3,4,6]],titanicTrain['Survived'])"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#storing the output of gradient boosting\n", "gradBoostOutput=modelGradBoost.predict(titanicTest.iloc[:,[0,1,2,3,5]])"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#lets try logistic regression model\n", "from sklearn import linear_model"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["modelLogit=linear_model.LogisticRegression(penalty='l1')"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["titanicTrain.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#applying train test split to measure the accuracy\n", "xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,4,6]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#cross validation scores using all colums got after EDA\n", "rf_cv_score=cross_val_score(estimator=modelLogit,X=xtrain,y=xtest,cv=5)\n", "rf_cv_score.mean()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#applying train test split to measure the accuracy\n", "#we are removing SibSp column from EDA\n", "#xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,5,6,7]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#m=1\n", "#for i in range(0,10):\n", "    #modelLogit=linear_model.LogisticRegression(penalty='l1')\n", "    #svm_cv_score=cross_val_score(estimator=modelSvm,X=xtrain,y=xtest,cv=5)\n", "    #print svm_cv_score.mean()\n", "    #m=m+1"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#cross validation scores after removing sibsp colums got after EDA\n", "#rf_cv_score=cross_val_score(estimator=modelLogit,X=xtrain,y=xtest,cv=5)\n", "#rf_cv_score.mean()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#applying train test split to measure the accuracy\n", "#we are removing ParCh column from EDA\n", "#xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,4,6,7]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#cross validation scores After removing Parch colums got after EDA\n", "#rf_cv_score=cross_val_score(estimator=modelLogit,X=xtrain,y=xtest,cv=5)\n", "#rf_cv_score.mean()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#applying train test split to measure the accuracy\n", "#we are removing ParCh and SibSp column from EDA\n", "#xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,6,7]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#cross validation scores after removing parch and sibsp colums got after EDA\n", "#rf_cv_score=cross_val_score(estimator=modelLogit,X=xtrain,y=xtest,cv=5)\n", "#rf_cv_score.mean()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["titanicTrain.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#we need to include all columns to create logistic regression model\n", "#fit the model\n", "modelLogit=linear_model.LogisticRegression(penalty='l1')\n", "modelLogit.fit(titanicTrain.iloc[:,[1,2,3,4,6]],titanicTrain['Survived'])"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["titanicTest.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#predict the output\n", "logitFinalOutput=modelLogit.predict(titanicTest.iloc[:,[0,1,2,3,5]])"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["Counter(logitFinalOutput)"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#lets try knn method\n", "from sklearn import neighbors"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["modelKnn=neighbors.KNeighborsClassifier()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["titanicTrain.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#applying train test split to measure the accuracy\n", "xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,4,6]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#cross validation scores using all colums got after EDA\n", "rf_cv_score=cross_val_score(estimator=modelKnn,X=xtrain,y=xtest,cv=5)\n", "rf_cv_score.mean()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#applying train test split to measure the accuracy\n", "#we are removing SibSp column from EDA\n", "#xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,5,6,7]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#cross validation scores after removing sibsp colums got after EDA\n", "#rf_cv_score=cross_val_score(estimator=modelKnn,X=xtrain,y=xtest,cv=5)\n", "#rf_cv_score.mean()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#applying train test split to measure the accuracy\n", "#we are removing ParCh column from EDA\n", "#xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,4,6,7]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#cross validation scores After removing Parch colums got after EDA\n", "#rf_cv_score=cross_val_score(estimator=modelKnn,X=xtrain,y=xtest,cv=5)\n", "#rf_cv_score.mean()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#applying train test split to measure the accuracy\n", "#we are removing ParCh and SibSp column from EDA\n", "#xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,6,7]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#cross validation scores after removing parch and sibsp colums got after EDA\n", "#rf_cv_score=cross_val_score(estimator=modelKnn,X=xtrain,y=xtest,cv=5)\n", "#rf_cv_score.mean()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#the final one\n", "#applying train test split to measure the accuracy\n", "#xtrain,ytrain,xtest,ytest=train_test_split(titanicTrain.iloc[:,[1,2,3,4,5,6,7]],titanicTrain['Survived'],test_size=0.3,random_state=123)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#first one is giving better accuracy hence, we will be going for this one but need to tune parameters\n", "m=1\n", "for i in range(0,10):\n", "    modelKnn=neighbors.KNeighborsClassifier(n_neighbors=m)\n", "    knn_cv_score=cross_val_score(estimator=modelKnn,X=xtrain,y=xtest,cv=5)\n", "    print (knn_cv_score.mean())\n", "    m=m+1"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#when n=16 it gives best results\n", "#lets create the model with n=3\n", "#fit the model\n", "modelKnn=neighbors.KNeighborsClassifier(n_neighbors=3)\n", "modelKnn.fit(titanicTrain.iloc[:,[1,2,3,6]],titanicTrain['Survived'])"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#lets predict\n", "knnOutput=modelKnn.predict(titanicTest.iloc[:,[0,1,2,5]])"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#lets try with nural net\n", "from sklearn.neural_network import MLPClassifier"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["modelAnn = MLPClassifier()"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#fitdata into model\n", "modelAnn.fit(titanicTrain.iloc[:,[1,2,3,4,6]],titanicTrain['Survived'])"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["annOutput=modelAnn.predict(titanicTest.iloc[:,[0,1,2,3,5]])"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#lets do voting ensemble\n", "z=[]\n", "for i in range(0,418):\n", "    p=(rfModelOutput[i]+svmModelOutput[i]+gradBoostOutput[i])\n", "    #p=(rfModelOutput[i]+svmModelOutput[i]+logitFinalOutput[i])\n", "    if(p>2):\n", "        z.append(1)\n", "    elif(p<2):\n", "        z.append(0)\n", "    elif(p==2):\n", "        z.append(rfModelOutput[i])\n", "    #if(rfModelOutput[i]==0 and svmModelOutput[i]==0 and logitFinalOutput[i]==0 and knnOutput[i]==0  and annOutput[i]==1):\n", "        #z.append(1)\n", "    #else:\n", "        #z.append(rfModelOutput[i])"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["Counter(z)"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#data preperation according to the format\n", "Test=pd.read_csv(\"../input/test.csv\")"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["Test=Test.drop('Pclass',axis=1)\n", "Test=Test.drop('Name',axis=1)\n", "Test=Test.drop('Sex',axis=1)\n", "Test=Test.drop('Age',axis=1)\n", "Test=Test.drop('SibSp',axis=1)\n", "Test=Test.drop('Parch',axis=1)\n", "Test=Test.drop('Ticket',axis=1)\n", "Test=Test.drop('Fare',axis=1)\n", "Test=Test.drop('Cabin',axis=1)\n", "Test=Test.drop('Embarked',axis=1)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["Test['Survived']=z"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["#check for the submission file\n", "Test.head()"], "execution_count": null, "metadata": {}, "outputs": []}, {"cell_type": "code", "source": ["#Lets convert this to excel file\n", "Test.to_csv('titanicOutput.csv',index=False)"], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}]}