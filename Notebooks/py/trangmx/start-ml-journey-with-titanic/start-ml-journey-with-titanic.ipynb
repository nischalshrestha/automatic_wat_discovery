{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0e7543ac-d6df-7aaf-7a43-3f135208dcf6"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "90552fff-8ed2-48aa-4286-a7f9a8a19c2b"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "44c4f13d-b513-12e4-568c-c029bf9e1aea"
      },
      "outputs": [],
      "source": [
        "from IPython.core.display import HTML\n",
        "HTML(\"\"\"\n",
        "<style>\n",
        ".output_png {\n",
        "    display: table-cell;\n",
        "    text-align: center;\n",
        "    vertical-align: middle;\n",
        "}\n",
        "</style>\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "011a187c-d9c3-098c-8946-710980ec8c1e"
      },
      "source": [
        "# I - Exploratory data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "11116d42-6060-283c-25ba-4aa121a7da02"
      },
      "source": [
        "Import some useful libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0746d7fe-042f-9560-7939-7ac30071c03a"
      },
      "outputs": [],
      "source": [
        "# remove warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "pd.options.display.max_columns = 100\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.style.use('ggplot')\n",
        "import numpy as np\n",
        "pd.options.display.max_rows = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "072f5a07-7aaf-dd21-86fe-9537d722d763"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "33b91af4-ce9d-f872-a4de-fb8da046c7a7"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('../input/train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "94890713-a0ae-d235-7628-8438732435b8"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fb9de0cc-748f-dc9d-5867-6ff6d8d99f67"
      },
      "source": [
        "Pandas allows us to statistically describe numerical features using the describe method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8a2224a9-b75d-3ee0-3ec5-4c3b09ef7f95"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cda7a09e-45ef-5868-3512-f239e41a653b"
      },
      "source": [
        "Age column has missing values. A solution is to replace the null values with the median age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "20275c3c-5405-95e9-86be-73b61f598ab2"
      },
      "outputs": [],
      "source": [
        "data['Age'].fillna(data['Age'].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f181fead-85d5-6c73-e6f5-480d8ef73a8e"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7471e71d-14b3-4dcd-320a-0efa406a7a5b"
      },
      "source": [
        "Draw some charts to understand more about the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "61063cb4-6063-b843-e965-42ebc8623042"
      },
      "outputs": [],
      "source": [
        "survived_sex = data[data['Survived']==1]['Sex'].value_counts()\n",
        "dead_sex = data[data['Survived']==0]['Sex'].value_counts()\n",
        "df = pd.DataFrame([survived_sex, dead_sex])\n",
        "df.index = ['Survived', 'Dead']\n",
        "df.plot(kind='bar', stacked=True, figsize=(6, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "606b9b46-0cf6-e4b9-561e-94dd8cbefa31"
      },
      "source": [
        "The Sex variable seems to be a decisive feature. Women are more likely to survive\n",
        "\n",
        "Let's now correlate the suvival with the age variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1b07457e-b936-cc3b-9de5-f77cd1f0fa3f"
      },
      "outputs": [],
      "source": [
        "figure = plt.figure(figsize=(6, 4))\n",
        "plt.hist([data[data['Survived']==1]['Age'],data[data['Survived']==0]['Age']], stacked=True, color = ['g','r'],\n",
        "         bins = 30,label = ['Survived','Dead'])\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Number of passengers')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9072ee8c-efe3-94b7-a7fe-d383d2928e28"
      },
      "source": [
        "It seems that children age under 10 have high chance of survival"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "06e01208-76cf-ae5b-769c-7c9b943dad77"
      },
      "source": [
        "Let's now focus on the Fare ticket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "81b9ffd2-2c0a-80c7-a19d-3ec482cb7a65"
      },
      "outputs": [],
      "source": [
        "figure = plt.figure(figsize=(8, 4))\n",
        "plt.hist([data[data['Survived']==1]['Fare'], data[data['Survived']==0]['Fare']], stacked=True, color=['g', 'r'], bins=30, label=['Survived', 'Dead'])\n",
        "plt.xlabel('Fare')\n",
        "plt.ylabel('Number of passengers')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6e821a60-f4ac-dd93-3d38-b3c6003c860d"
      },
      "source": [
        "Passengers with high fare ticket are likely to be survived"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e94b253a-97eb-967d-5184-438b2b4e58ff"
      },
      "source": [
        "Combine the age, the fare and the survival on a single chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ff95a2a1-05a6-f38f-0d09-d3435b0c8e43"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "ax = plt.subplot()\n",
        "ax.scatter(data[data['Survived']==1]['Age'], data[data['Survived']==1]['Fare'], c='green', s=40)\n",
        "ax.scatter(data[data['Survived']==0]['Age'], data[data['Survived']==0]['Fare'], c='red', s= 40)\n",
        "ax.set_xlabel('Age')\n",
        "ax.set_ylabel('Fare')\n",
        "ax.legend(('survived', 'dead'), scatterpoints=1, loc='upper righ', fontsize=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b5cc9962-ef45-84bf-58b7-2c96a05d4f41"
      },
      "source": [
        "Except for children, passengers with high fare ticket have high chance of survival"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5f359db3-96ab-f8a0-366c-ffe735f558aa"
      },
      "source": [
        "The fare is correlated with the Pclass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bd714598-98c6-61ee-41c6-7153b64579e5"
      },
      "outputs": [],
      "source": [
        "ax = plt.subplot()\n",
        "ax.set_ylabel('Average fare')\n",
        "data.groupby('Pclass').mean()['Fare'].plot(kind='bar',figsize=(6, 3), ax = ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9cfb3105-c925-3e3b-5a12-3bd6658b779c"
      },
      "source": [
        "Let's now see how the embarkation site affects the survival"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9a5a43dc-702f-663f-b903-5608bb54cd00"
      },
      "outputs": [],
      "source": [
        "survived_embark = data[data['Survived']==1]['Embarked'].value_counts()\n",
        "dead_embark = data[data['Survived']==0]['Embarked'].value_counts()\n",
        "df = pd.DataFrame([survived_embark, dead_embark])\n",
        "df.index = ['Survived', 'Dead']\n",
        "df.plot(kind='bar', stacked=True, figsize=(8,4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "71c6e050-ca93-9724-5a7f-88e9507272e4"
      },
      "source": [
        "There seems to be no distinct correlation here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6593e337-87d7-659e-966f-a8fac210ef70"
      },
      "source": [
        "# II - Feature Enginerring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5ccb1573-33fc-5d40-533b-a090a76a4baf"
      },
      "outputs": [],
      "source": [
        "# Function that asserts whether or not a feature has been processed\n",
        "def status(feature):\n",
        "    print('Processing %s :ok' %(feature))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4a686d06-b5bf-c692-081d-0f07ae0fcb78"
      },
      "source": [
        "## Loading data\n",
        "Load and combine train set and test set. Combined set will be tranning set for a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0aeb42be-7efa-d71f-c436-a76516ef6bb7"
      },
      "outputs": [],
      "source": [
        "def get_combined_data():\n",
        "    # reading train data\n",
        "    train = pd.read_csv('../input/train.csv')\n",
        "    \n",
        "    # reading test data\n",
        "    test = pd.read_csv('../input/test.csv')\n",
        "    \n",
        "    # extracting and then removing the targets from the traing data\n",
        "    targets = train.Survived\n",
        "    train.drop('Survived', 1, inplace=True)\n",
        "    \n",
        "    # Merging train data and test data for future engineering\n",
        "    combined = train.append(test)\n",
        "    combined.reset_index(inplace=True)\n",
        "    combined.drop('index', inplace=True, axis=1)\n",
        "    return combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fca1fe8e-c600-1f68-acea-cc9a84290f74"
      },
      "outputs": [],
      "source": [
        "combined = get_combined_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "63d04487-4850-4892-6a25-985a6aa033e4"
      },
      "outputs": [],
      "source": [
        "combined.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7cb8e062-412c-7ae7-a45b-b9d6d0e12896"
      },
      "outputs": [],
      "source": [
        "combined.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2052780f-e877-addb-2ed9-8cbaaf098655"
      },
      "source": [
        "## Extracting the passenger titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c9863c54-c523-b13f-7068-df03c5dd3593"
      },
      "outputs": [],
      "source": [
        "def get_titles():\n",
        "    global combined\n",
        "    \n",
        "    # we extract the title from each name\n",
        "    combined['Title'] = combined['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
        "    \n",
        "    # a map of more aggregated titles\n",
        "    Title_Dictionary = {\n",
        "                        \"Capt\":       \"Officer\",\n",
        "                        \"Col\":        \"Officer\",\n",
        "                        \"Major\":      \"Officer\",\n",
        "                        \"Jonkheer\":   \"Royalty\",\n",
        "                        \"Don\":        \"Royalty\",\n",
        "                        \"Sir\" :       \"Royalty\",\n",
        "                        \"Dr\":         \"Officer\",\n",
        "                        \"Rev\":        \"Officer\",\n",
        "                        \"the Countess\":\"Royalty\",\n",
        "                        \"Dona\":       \"Royalty\",\n",
        "                        \"Mme\":        \"Mrs\",\n",
        "                        \"Mlle\":       \"Miss\",\n",
        "                        \"Ms\":         \"Mrs\",\n",
        "                        \"Mr\" :        \"Mr\",\n",
        "                        \"Mrs\" :       \"Mrs\",\n",
        "                        \"Miss\" :      \"Miss\",\n",
        "                        \"Master\" :    \"Master\",\n",
        "                        \"Lady\" :      \"Royalty\"\n",
        "\n",
        "                        }\n",
        "    \n",
        "    # we map each title\n",
        "    combined['Title'] = combined.Title.map(Title_Dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6f44fab4-3e54-a644-0f05-26c1c1e5ca6e"
      },
      "outputs": [],
      "source": [
        "get_titles()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7e567d3d-37f7-8e7d-f41b-7989b99a1362"
      },
      "source": [
        "## Processing the ages\n",
        "\n",
        "The are 177 values missing for Age. We need to fill the missing value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4a0f7368-235a-228f-c794-67262affc1b9"
      },
      "outputs": [],
      "source": [
        "grouped = combined.groupby(['Sex', 'Pclass', 'Title'])\n",
        "grouped.median()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2e7d0310-44e3-a248-a24b-2a0fd863dfb1"
      },
      "source": [
        "Look at the median age column and see how this value can be different based on the Sex, Pclass and Title put together.\n",
        "\n",
        "For example:\n",
        "- If the passenger is female, from Pclass 1, and from royalty the median age is 39.\n",
        "- If the passenger is male, from Pclass 3, with a Mr title, the median age is 26.\n",
        "\n",
        "Let's create a function that fills in the missing age in **combined** based on these different attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "60c8dc67-db16-f85c-d118-af49b0064d5e"
      },
      "outputs": [],
      "source": [
        "def process_age():\n",
        "    global combined\n",
        "    \n",
        "    def fillAges(row):\n",
        "        if row['Sex']=='female' and row['Pclass'] == 1:\n",
        "            if row['Title'] == 'Miss':\n",
        "                return 30\n",
        "            elif row['Title'] == 'Mrs':\n",
        "                return 45\n",
        "            elif row['Title'] == 'Officer':\n",
        "                return 49\n",
        "            elif row['Title'] == 'Royalty':\n",
        "                return 39\n",
        "\n",
        "        elif row['Sex']=='female' and row['Pclass'] == 2:\n",
        "            if row['Title'] == 'Miss':\n",
        "                return 20\n",
        "            elif row['Title'] == 'Mrs':\n",
        "                return 30\n",
        "\n",
        "        elif row['Sex']=='female' and row['Pclass'] == 3:\n",
        "            if row['Title'] == 'Miss':\n",
        "                return 18\n",
        "            elif row['Title'] == 'Mrs':\n",
        "                return 31\n",
        "\n",
        "        elif row['Sex']=='male' and row['Pclass'] == 1:\n",
        "            if row['Title'] == 'Master':\n",
        "                return 6\n",
        "            elif row['Title'] == 'Mr':\n",
        "                return 41.5\n",
        "            elif row['Title'] == 'Officer':\n",
        "                return 52\n",
        "            elif row['Title'] == 'Royalty':\n",
        "                return 40\n",
        "\n",
        "        elif row['Sex']=='male' and row['Pclass'] == 2:\n",
        "            if row['Title'] == 'Master':\n",
        "                return 2\n",
        "            elif row['Title'] == 'Mr':\n",
        "                return 30\n",
        "            elif row['Title'] == 'Officer':\n",
        "                return 41.5\n",
        "\n",
        "        elif row['Sex']=='male' and row['Pclass'] == 3:\n",
        "            if row['Title'] == 'Master':\n",
        "                return 6\n",
        "            elif row['Title'] == 'Mr':\n",
        "                return 26\n",
        "    combined.Age = combined.apply(lambda r : fillAges(r) if np.isnan(r['Age']) else r['Age'], axis=1)\n",
        "    \n",
        "    status('age')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0f8acdaf-b059-5142-3e95-ad36b839f845"
      },
      "outputs": [],
      "source": [
        "process_age()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a7486e15-09a6-c0d1-dee2-0c4c6cd36cd6"
      },
      "outputs": [],
      "source": [
        "combined.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1c427746-3096-94e9-f94c-22643701810b"
      },
      "source": [
        "There are still some missing value in Fare, Embarked, Cabin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e3865874-7c67-2dca-8677-a54c0a371b4b"
      },
      "outputs": [],
      "source": [
        "def process_names():\n",
        "    global combined\n",
        "    \n",
        "    combined.drop('Name', inplace=True, axis=1)\n",
        "    title_dummies = pd.get_dummies(combined['Title'], prefix='Title')\n",
        "    combined = pd.concat([combined, title_dummies], axis=1)\n",
        "    \n",
        "    combined.drop('Title', axis=1, inplace=True)\n",
        "    \n",
        "    status('names')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "113295fb-a769-4de0-fd13-84a73fc57df7"
      },
      "outputs": [],
      "source": [
        "process_names()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "60a8f9bd-d6a6-3c14-503a-a3807f26871a"
      },
      "source": [
        "## Processing Fare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8e24467c-7276-f822-46e9-c95982700cbe"
      },
      "outputs": [],
      "source": [
        "def process_fares():\n",
        "    \n",
        "    global combined\n",
        "    \n",
        "    combined.Fare.fillna(combined.Fare.mean(), inplace=True)\n",
        "    \n",
        "    status('fare')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b5fae6fe-81e6-8e54-f1bd-f59d95fb360b"
      },
      "outputs": [],
      "source": [
        "process_fares()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "444c33d7-07e4-ed59-46fa-00a250024448"
      },
      "source": [
        "## Processing Embarked\n",
        "Fill missing values with the most frequent Embarked value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "625e1880-26a9-c16d-041c-fff7fe461b74"
      },
      "outputs": [],
      "source": [
        "def process_embarked():\n",
        "    global combined\n",
        "    \n",
        "    combined.Embarked.fillna('S', inplace=True)\n",
        "    \n",
        "    embarked_dummies = pd.get_dummies(combined['Embarked'], prefix='Embarked')\n",
        "    combined = pd.concat([combined, embarked_dummies], axis=1)\n",
        "    combined.drop('Embarked', axis=1, inplace=True)\n",
        "    \n",
        "    status('embarked')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "902e15c7-5fe2-d9f0-744e-667311c145e3"
      },
      "outputs": [],
      "source": [
        "process_embarked()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "25b915b9-9e35-6102-2354-52ac1778b956"
      },
      "source": [
        "## Processing Cabin\n",
        "Fill missing cabins with U (for Unknown)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5962812f-3575-d26d-99b2-00f048a23685"
      },
      "outputs": [],
      "source": [
        "def process_cabin():\n",
        "    global combined\n",
        "    \n",
        "    combined.Cabin.fillna('U',inplace=True)\n",
        "    \n",
        "    combined['Cabin'] = combined['Cabin'].map(lambda c: c[0])\n",
        "    \n",
        "    cabin_dummies = pd.get_dummies(combined['Cabin'], prefix='Cabin')\n",
        "    \n",
        "    combined = pd.concat([combined, cabin_dummies], axis=1)\n",
        "    \n",
        "    combined.drop('Cabin', axis=1, inplace=True)\n",
        "    \n",
        "    status('cabin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d6a8bb34-4a19-c42f-4a98-5e5a5f894d9b"
      },
      "outputs": [],
      "source": [
        "process_cabin()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7770a0fe-b360-9379-d5cb-91b69bd89dc8"
      },
      "outputs": [],
      "source": [
        "combined.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d47599fb-72cf-4c6a-1af6-bbf9434ef492"
      },
      "source": [
        "## Processing Sex "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e79795f1-80e2-1b60-3c74-2068269fd38e"
      },
      "outputs": [],
      "source": [
        "def process_sex():\n",
        "    \n",
        "    global combined\n",
        "    \n",
        "    combined['Sex'] = combined['Sex'].map({'male':1, 'female': 0})\n",
        "    \n",
        "    status('sex')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8c5ecdb3-96db-09ea-0297-8596e34a039e"
      },
      "outputs": [],
      "source": [
        "process_sex()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5eeb6cc9-fa34-f2a0-3e43-10e9cfab303b"
      },
      "source": [
        "## Processing Pclass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e1cabf9a-efe2-6bbe-54c6-9964057c76d1"
      },
      "outputs": [],
      "source": [
        "def process_pclass():\n",
        "    \n",
        "    global combined\n",
        "    \n",
        "    pclass_dummies = pd.get_dummies(combined['Pclass'], prefix=\"Pclass\")\n",
        "    \n",
        "    combined = pd.concat([combined, pclass_dummies], axis=1)\n",
        "    \n",
        "    combined.drop('Pclass', axis=1, inplace=True)\n",
        "    \n",
        "    status('pclass')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3acba2ae-db1f-0516-be64-5cd668decbb7"
      },
      "outputs": [],
      "source": [
        "process_pclass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a3037d46-3c66-e6bd-d71c-3ff34db9b024"
      },
      "source": [
        "## Processing Ticket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ebc7d23b-0c7c-861d-8b10-794402d5152a"
      },
      "outputs": [],
      "source": [
        "def process_ticket():\n",
        "    \n",
        "    global combined\n",
        "    \n",
        "    # a function that extracts each prefix of the ticket, returns 'XXX' if no prefix (i.e the ticket is a digit)\n",
        "    def cleanTicket(ticket):\n",
        "        ticket = ticket.replace('.','')\n",
        "        ticket = ticket.replace('/','')\n",
        "        ticket = ticket.split()\n",
        "        ticket = list(map(lambda t : t.strip() , ticket))\n",
        "        ticket = list(filter(lambda t : not t.isdigit(), ticket))\n",
        "        if len(ticket) > 0:\n",
        "            return ticket[0]\n",
        "        else:\n",
        "            return 'XXX'\n",
        "    \n",
        "\n",
        "    # Extracting dummy variables from tickets:\n",
        "\n",
        "    combined['Ticket'] = combined['Ticket'].map(cleanTicket)\n",
        "    tickets_dummies = pd.get_dummies(combined['Ticket'],prefix='Ticket')\n",
        "    combined = pd.concat([combined, tickets_dummies],axis=1)\n",
        "    combined.drop('Ticket',inplace=True,axis=1)\n",
        "\n",
        "    status('ticket')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bcd3852c-f0e5-3c9b-d6b0-fef6ed80612b"
      },
      "outputs": [],
      "source": [
        "process_ticket()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0e5db4ae-7127-c9bc-d181-431d62df39c9"
      },
      "source": [
        "## Processing Family"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1fd1d82b-1392-c6d8-b901-5189aa0f4e2d"
      },
      "outputs": [],
      "source": [
        "def process_family():\n",
        "    \n",
        "    global combined\n",
        "    # introducing a new feature : the size of families (including the passenger)\n",
        "    combined['FamilySize'] = combined['Parch'] + combined['SibSp'] + 1\n",
        "    \n",
        "    # introducing other features based on the family size\n",
        "    combined['Singleton'] = combined['FamilySize'].map(lambda s : 1 if s == 1 else 0)\n",
        "    combined['SmallFamily'] = combined['FamilySize'].map(lambda s : 1 if 2<=s<=4 else 0)\n",
        "    combined['LargeFamily'] = combined['FamilySize'].map(lambda s : 1 if 5<=s else 0)\n",
        "    \n",
        "    status('family')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cbbe54bf-f3ff-295e-49f4-c24b83a3b2ee"
      },
      "outputs": [],
      "source": [
        "process_family()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6686dfec-1570-058c-59ea-337c509b0438"
      },
      "outputs": [],
      "source": [
        "combined.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e7817230-e365-8672-4a94-8b252ecf9a7d"
      },
      "source": [
        "Now we have 68 features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "57a1c2e2-8051-80c2-fd5b-983130c80194"
      },
      "source": [
        "We need to scale all features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cd532bdc-38d5-c74d-7ccd-61d7cdfae5d4"
      },
      "outputs": [],
      "source": [
        "def scale_all_features():\n",
        "    \n",
        "    global combined\n",
        "    \n",
        "    features = list(combined.columns)\n",
        "    features.remove('PassengerId')\n",
        "    combined[features] = combined[features].apply(lambda x: x/x.max(), axis=0)\n",
        "    \n",
        "    print('Features scaled sucessfully!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "45099f19-27e3-3f92-7d5c-37a4e0a8e53c"
      },
      "outputs": [],
      "source": [
        "scale_all_features()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ec5460a0-8b1a-fd8a-660d-6223b76330ad"
      },
      "source": [
        "# III - Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d27d5408-5ea2-bfc6-a1a9-1f7f3bbfae95"
      },
      "source": [
        "We'll be using Random Forests. Random Froests has proven a great efficiency in Kaggle competitions.\n",
        "\n",
        "For more details about why ensemble methods perform well, you can refer to these posts:\n",
        "- http://mlwave.com/kaggle-ensembling-guide/\n",
        "- http://www.overkillanalytics.net/more-is-always-better-the-power-of-simple-ensembles/\n",
        "\n",
        "Steps:\n",
        "1. Break the combined dataset to train set and test set\n",
        "2. Use the train set to build a predictive model\n",
        "3. Evaluate the model using the train set\n",
        "4. Test the model using the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "06428d23-1e3c-7e94-aab2-0db377659ea1"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.cross_validation import StratifiedKFold\n",
        "from sklearn.grid_search import GridSearchCV\n",
        "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
        "from sklearn.cross_validation import cross_val_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "18b8e3fb-8e42-a54d-71b9-dd02774f39f9"
      },
      "source": [
        "We use 5-fold cross validation with the Accuracy metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2e17d766-f278-82a7-8e9d-c05b13b45629"
      },
      "outputs": [],
      "source": [
        "def compute_score(clf, X, y,scoring='accuracy'):\n",
        "    xval = cross_val_score(clf, X, y, cv = 5, scoring=scoring)\n",
        "    return np.mean(xval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fb23c245-e801-6782-a7b8-a2d0f1e084e5"
      },
      "source": [
        "Now we need to separate training set and test set from the combined set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7a39c087-57a0-1d71-2318-e6062e7275fe"
      },
      "outputs": [],
      "source": [
        "def recover_train_test_target():\n",
        "    train0 = pd.read_csv('../input/train.csv')\n",
        "    \n",
        "    targets = train0.Survived\n",
        "    train = combined.ix[0:890]\n",
        "    test = combined.ix[891:]\n",
        "    return train,test,targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9d213d21-b5e7-0355-6cc6-689e6caf0a0a"
      },
      "outputs": [],
      "source": [
        "train,test,targets = recover_train_test_target()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7bdb2b45-428b-34b9-de74-a3c2cbcc0c2a"
      },
      "source": [
        "## Feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "431e8d9c-3be1-8cf5-b3da-90a476f8361d"
      },
      "source": [
        "We select features from 68 features:\n",
        "\n",
        "- This decreases redundancy among the data\n",
        "- This speeds up the training process\n",
        "- This reduces overfitting\n",
        "\n",
        "Tree-based estimators can be used to compute feature importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "77cc9570-f6ea-1e47-671e-2e934670e9cf"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "clf = ExtraTreesClassifier(n_estimators=200)\n",
        "clf = clf.fit(train, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "63892512-5cf3-fb3b-47f5-887bd5d5595f"
      },
      "outputs": [],
      "source": [
        "features = pd.DataFrame()\n",
        "features['feature'] = train.columns\n",
        "features['importance'] = clf.feature_importances_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e9eb9889-3659-f92a-23a0-84694d71a551"
      },
      "outputs": [],
      "source": [
        "features.sort(['importance'], ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0802f61e-60c0-8e92-3796-342b45d72337"
      },
      "source": [
        "Now we transform the train set and test set in a more compact datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2787dec1-4676-613b-6f68-e45dd93c4547"
      },
      "outputs": [],
      "source": [
        "model = SelectFromModel(clf, prefit=True)\n",
        "train_new = model.transform(train)\n",
        "train_new.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "194ec31c-da5d-bc27-9069-f1eae6b47bcf"
      },
      "outputs": [],
      "source": [
        "test_new = model.transform(test)\n",
        "test_new.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5c232da1-1e42-2b12-2d85-7fde430611ca"
      },
      "source": [
        "## Hyperparameters tuning\n",
        "\n",
        "As mentioned in the beginning of the Modeling part, we will be using a Random Forest model.\n",
        "\n",
        "Random Forest are quite handy. They do however come with some parameters to tweak in order to get an optimal model for the prediction task.\n",
        "\n",
        "To learn more about Random Forests, you can refer to this link: https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6e3ab0c8-eb94-69ff-081c-788ab1c28a36"
      },
      "outputs": [],
      "source": [
        "forest = RandomForestClassifier(max_features='sqrt')\n",
        "\n",
        "parameter_grid = {'max_depth' : [4,5,6,7,8],\n",
        "                  'n_estimators':[200,210,240,250],\n",
        "                  'criterion':['gini', 'entropy']}\n",
        "cross_validation = StratifiedKFold(targets, n_folds=5)\n",
        "\n",
        "grid_search = GridSearchCV(forest, param_grid=parameter_grid, cv=cross_validation)\n",
        "\n",
        "grid_search.fit(train_new, targets)\n",
        "\n",
        "print('Best score: {}'.format(grid_search.best_score_))\n",
        "print('Best parameters: {}'.format(grid_search.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2fae301b-e0e5-e75e-03b5-6414ce7541a4"
      },
      "source": [
        "Now we generate solution for sumission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9815a282-61b5-4ff7-837d-cd273668b74b"
      },
      "outputs": [],
      "source": [
        "output = grid_search.predict(test_new).astype(int)\n",
        "df_output = pd.DataFrame()\n",
        "df_output['PassengerId'] = test['PassengerId']\n",
        "df_output['Survived'] = output\n",
        "df_output[['PassengerId','Survived']].to_csv('titanic_submission.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fec2f4f8-fadf-c72a-8e1c-669ae878ddc3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}