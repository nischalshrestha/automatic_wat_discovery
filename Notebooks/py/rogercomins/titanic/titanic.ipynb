{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Code you have previously used to load data\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom xgboost import XGBClassifier\n\n\n# Path of the file to read. We changed the directory structure to simplify submitting to a competition\ntrain_file_path = '../input/train.csv'\n# path to file you will use for predictions on submission data\nsubmission_data_path = '../input/test.csv'\n\ndata = pd.read_csv(train_file_path)\ndata.dropna(axis=0, subset=['Survived'], inplace=True)\nsubmission_data = pd.read_csv(submission_data_path)\n\nfeatures = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked']\ny = data.Survived\nX = data[features]\nsubmission_X = submission_data[features]\n\n# Feature Engineering on Age\nX['Elderly'] = np.where(X['Age'] >= 50, 1, 0)\nX['Child'] = np.where(X['Age'] <= 13, 1, 0)\nsubmission_X['Elderly'] = np.where(submission_X['Age'] >= 50, 1, 0)\nsubmission_X['Child'] = np.where(submission_X['Age'] <= 13, 1, 0)\n\n# One-hot Encoding\nX = pd.get_dummies(X)\nsubmission_X = pd.get_dummies(submission_data)\n\nfinal_train, final_submission = X.align(submission_X, join='left', axis=1)\n\n# Test-train Split\ntrain_X, test_X, train_y, test_y = train_test_split(final_train.as_matrix(), y.as_matrix(), test_size=0.25)\n\n# Handle Missing Values\nmy_imputer = Imputer()\ntrain_X = my_imputer.fit_transform(train_X)\ntest_X = my_imputer.transform(test_X)\nfinal_submission = my_imputer.transform(final_submission)\n\n# Logistic Regression\nlogreg = LogisticRegression()\nlogreg.fit(train_X, train_y)\nlogreg_pred = logreg.predict(test_X)\nacc_log = accuracy_score(test_y, logreg_pred)\n\n# Support Vector Machines\nsvc = SVC()\nsvc.fit(train_X, train_y)\nsvc_pred = svc.predict(test_X)\nacc_svc = accuracy_score(test_y, svc_pred)\n\n# Linear SVC\nlinear_svc = LinearSVC()\nlinear_svc.fit(train_X, train_y)\nlinear_svc_pred = linear_svc.predict(test_X)\nacc_linear_svc = accuracy_score(test_y, linear_svc_pred)\n\n# KNN\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(train_X, train_y)\nknn_pred = knn.predict(test_X)\nacc_knn = accuracy_score(test_y, knn_pred)\n\n# Gaussian Naive Bayes\ngaussian = GaussianNB()\ngaussian.fit(train_X, train_y)\ngaussian_pred = gaussian.predict(test_X)\nacc_gaussian = accuracy_score(test_y, gaussian_pred)\n\n# Perceptron\nperceptron = Perceptron()\nperceptron.fit(train_X, train_y)\nperceptron_pred = perceptron.predict(test_X)\nacc_perceptron = accuracy_score(test_y, perceptron_pred)\n\n# Stochastic Gradient Descent\nsgd = SGDClassifier()\nsgd.fit(train_X, train_y)\nsgd_pred = sgd.predict(test_X)\nacc_sgd = accuracy_score(test_y, sgd_pred)\n\n# Decision Tree\ndecision_tree = DecisionTreeClassifier(max_leaf_nodes=100, random_state=1)\ndecision_tree.fit(train_X, train_y)\ndecision_tree_pred = decision_tree.predict(test_X)\nacc_decision_tree = accuracy_score(test_y, decision_tree_pred)\n\n# Random Forest\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(train_X, train_y)\nrandom_forest_pred = random_forest.predict(test_X)\nacc_random_forest = accuracy_score(test_y, random_forest_pred)\n\n# XGBoost default\nxgb_def = XGBClassifier(n_estimators=1000, learning_rate=0.05)\nxgb_def.fit(train_X, train_y, early_stopping_rounds=5, \n             eval_set=[(test_X, test_y)], verbose=False)\nxgb_def_pred = xgb_def.predict(test_X)\nacc_xgb_def = accuracy_score(test_y, xgb_def_pred)\n\n# XGBoost Binary Logistic Regression\nxgb_binl = XGBClassifier(n_estimators=1000, learning_rate=0.05, objective='binary:logistic')\nxgb_binl.fit(train_X, train_y, early_stopping_rounds=5, \n             eval_set=[(test_X, test_y)], verbose=False)\nxgb_binl_pred = xgb_binl.predict(test_X)\nacc_xgb_binl = accuracy_score(test_y, xgb_binl_pred)\n\n# XGBoost Reg Logistic Regression\nxgb_regl = XGBClassifier(n_estimators=1000, learning_rate=0.05, objective='reg:logistic')\nxgb_regl.fit(train_X, train_y, early_stopping_rounds=5, \n             eval_set=[(test_X, test_y)], verbose=False)\nxgb_regl_pred = xgb_regl.predict(test_X)\nacc_xgb_regl = accuracy_score(test_y, xgb_regl_pred)\n\nmodels = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree', 'XGBoost Default', 'XGBoost Binary Logistic',\n              'XGBoost Reg Logistic'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree, acc_xgb_def,\n              acc_xgb_binl, acc_xgb_regl]})\nprint(models.sort_values(by='Score', ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4342f67333f1842a62f73f7b568cb2e48a889b3"},"cell_type":"code","source":"# make predictions which we will submit. \nsubmission_preds = xgb_regl.predict(final_submission)\n\nprint(submission_preds)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"output = pd.DataFrame({\n        \"PassengerId\": submission_data.PassengerId,\n        \"Survived\": submission_preds})\n\noutput.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}