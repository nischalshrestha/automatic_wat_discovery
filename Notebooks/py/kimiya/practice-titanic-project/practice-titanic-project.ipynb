{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9f9e6669-6785-19a6-2d65-1f27beade261"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "344bb833-848f-3670-8454-0fd5c18a1ce4"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "badf41fe-7b4f-ffe5-6b85-0f4eb5a11d54"
      },
      "outputs": [],
      "source": [
        "# read data sheets\n",
        "titanic = pd.read_csv(\"../input/train.csv\")\n",
        "\n",
        "#Fill missing value in the column Age with median\n",
        "titanic[\"Age\"]=titanic[\"Age\"].fillna(titanic[\"Age\"].median())\n",
        "#print(titanic[\"Age\"])\n",
        "#print(titanic[\"Sex\"].unique())\n",
        "\n",
        "#Replace Sex with digit\n",
        "titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
        "titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
        "\n",
        "#Replace Embarked with digit\n",
        "#print(titanic[\"Embarked\"].unique())\n",
        "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(\"S\")\n",
        "titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
        "titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
        "titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
        "#print(titanic[\"Embarked\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f6d2dbc3-a9c5-537e-468c-fc0a5ebef47b"
      },
      "outputs": [],
      "source": [
        "#Finished preparing data\n",
        "#Start machine learning now\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.cross_validation import KFold\n",
        "\n",
        "#Columsn to be used for predicting the target\n",
        "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
        "\n",
        "#Initializing algorithm\n",
        "alg = LinearRegression()\n",
        "\n",
        "#Generate cross validation folds\n",
        "kf = KFold(titanic.shape[0], n_folds = 3, random_state = 1)\n",
        "#print(kf)\n",
        "predictions = []\n",
        "for train, test in kf:\n",
        "    train_predictors = (titanic[predictors].iloc[train, :])\n",
        "    #print(train_predictors)\n",
        "    train_target = titanic[\"Survived\"].iloc[train]\n",
        "    #print(train_target)\n",
        "    alg.fit(train_predictors, train_target)\n",
        "    #print(alg.fit(train_predictors, train_target))\n",
        "    test_predictions = alg.predict(titanic[predictors].iloc[test,:])\n",
        "    #print(test_predictions)\n",
        "    predictions.append(test_predictions)\n",
        "    #print(predictions)\n",
        "    \n",
        "#Combine the predictions which are numpy arrays\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "predictions[predictions > 0.5] = 1\n",
        "predictions[predictions <= 0.5] = 0\n",
        "accuracy = sum(predictions[predictions == titanic[\"Survived\"]])/len(titanic[\"Survived\"])\n",
        "\n",
        "#Survived = np.array(titanic[\"Survived\"])\n",
        "#rightly_predicted = np.where(predictions == Survived)\n",
        "#accuracy = len(rightly_predicted[0])/len(titanic[\"Survived\"])\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "95d12ed5-2092-34af-13b0-c9c9bba9c86a"
      },
      "outputs": [],
      "source": [
        "#Improve the prediction with logistic regression\n",
        "from sklearn import cross_validation\n",
        "from sklearn.linear_model import LogisticRegression\n",
        " \n",
        "#Initialize the algorithm\n",
        "alg = LogisticRegression(random_state=1)\n",
        "\n",
        "#Computing the accuracy score for all the cross validation folds.\n",
        "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv = 3)\n",
        "\n",
        "print(scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "23d3c7ca-ae31-772b-bf07-a81973731d90"
      },
      "outputs": [],
      "source": [
        "#Procee titanic_test in the same way with titanic processed.\n",
        "titanic_test = pd.read_csv('../input/test.csv')\n",
        "titanic_test[\"Age\"] =  titanic_test[\"Age\"].fillna(titanic[\"Age\"].median())\n",
        "titanic_test.loc[titanic_test[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
        "titanic_test.loc[titanic_test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
        "titanic_test[\"Embarked\"] = titanic_test[\"Embarked\"].fillna(\"S\")\n",
        "titanic_test.loc[titanic_test[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
        "titanic_test.loc[titanic_test[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
        "titanic_test.loc[titanic_test[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
        "\n",
        "titanic_test[\"Fare\"] = titanic_test[\"Fare\"].fillna(titanic_test[\"Fare\"].median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "67b93385-2d38-657e-0ddb-0cdd12713668"
      },
      "outputs": [],
      "source": [
        "#Submit the prediction result\n",
        "\n",
        "#Initialize the algorithm class\n",
        "alg = LogisticRegression(random_state = 1)\n",
        "\n",
        "#Train the algorithm using all the training data\n",
        "#print(predictors)\n",
        "alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
        "\n",
        "#Make predictions with the test set\n",
        "predictions = alg.predict(titanic_test[predictors])\n",
        "#print(predictions)\n",
        "\n",
        "#Create a new dataframe with only the columns Kaggle wants from the dataset\n",
        "submission = pd.DataFrame({\n",
        "    \"PassengerId\": titanic_test[\"PassengerId\"],\n",
        "    \"Survived\": predictions\n",
        "})\n",
        "#print(submission)\n",
        "#submission.to_csv(\"first_titanic_practice.csv\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4491a89b-a95a-6f9c-79b2-c9322a0753ef"
      },
      "outputs": [],
      "source": [
        "#Improving the model with random forest \n",
        "from sklearn import cross_validation\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
        "alg = RandomForestClassifier(random_state = 1,\n",
        "                            n_estimators = 10, #num of trees \n",
        "                            min_samples_split = 2, #min num of row to split\n",
        "                            min_samples_leaf = 1 #min of samples at a branch\n",
        "                            )\n",
        "\n",
        "#Generate cross validation folds\n",
        "kf_rf = cross_validation.KFold(titanic.shape[0], n_folds = 3, random_state = 1)\n",
        "#Generate cross validation prediction\n",
        "scores = cross_validation.cross_val_score(alg, titanic[predictors],titanic[\"Survived\"], cv = kf_rf )\n",
        "#print(scores)\n",
        "scores = scores.mean()\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "848619e3-e198-64bd-8e0b-22ecb6402bb9"
      },
      "outputs": [],
      "source": [
        "#Tweak the parameter of the random forest\n",
        "alg = RandomForestClassifier(random_state = 1, n_estimators = 50, min_samples_split = 4, min_samples_leaf = 2)\n",
        "\n",
        "kf_rf_tweaked = cross_validation.KFold(titanic.shape[0], n_folds = 3, random_state = 1)\n",
        "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv = kf_rf_tweaked)\n",
        "\n",
        "scores = scores.mean()\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a8246ac1-8014-0e0b-3c1a-2279edb948aa"
      },
      "outputs": [],
      "source": [
        "#Add new features\n",
        "titanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]\n",
        "titanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a604d14b-1668-8bf2-8e0d-2218de10fa43"
      },
      "outputs": [],
      "source": [
        "#Data cleansing with regex\n",
        "import re\n",
        "\n",
        "def get_title(name):\n",
        "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
        "    if title_search:\n",
        "        return title_search.group(1)\n",
        "    return \"\"\n",
        "\n",
        "#Get all the titles and find out how often each one occurs\n",
        "titles = titanic[\"Name\"].apply(get_title)\n",
        "#print(pd.value_counts(titles))\n",
        "\n",
        "#Map each title to an integer\n",
        "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
        "for key, value in title_mapping.items():\n",
        "    titles[titles == key] = value\n",
        "#print(titles)\n",
        "titanic[\"Title\"] = titles   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3916ebb2-0fc3-e335-267d-3f5f70a7462f"
      },
      "outputs": [],
      "source": [
        "#Define family size\n",
        "import operator\n",
        "\n",
        "family_id_mapping = {}\n",
        "def get_family_id(row):\n",
        "    last_name = row[\"Name\"].split(\",\")[0]\n",
        "    \n",
        "    family_id = \"{0}{1}\".format(last_name, row[\"FamilySize\"])\n",
        "    \n",
        "    if family_id not in family_id_mapping:\n",
        "        if len(family_id_mapping) == 0:\n",
        "            current_id = 1\n",
        "        else:\n",
        "            current_id = (max(family_id_mapping.items(), key = operator.itemgetter(1))[1] + 1)\n",
        "        family_id_mapping[family_id] = current_id\n",
        "    \n",
        "    return family_id_mapping[family_id]\n",
        " \n",
        "family_ids = titanic.apply(get_family_id, axis = 1) \n",
        "family_ids[titanic[\"FamilySize\"] < 3] = 1\n",
        "#print(pd.value_counts(family_ids))\n",
        "\n",
        "titanic[\"FamilyId\"] = family_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4473b01c-9241-2e0c-e5e2-ff342ae0eee6"
      },
      "outputs": [],
      "source": [
        "#Finding The Best Features\n",
        "#Check columns if correlate most closely with what to predict \n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "import matplotlib.pyplot as plt \n",
        "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\", \"NameLength\"]\n",
        "\n",
        "#Perform feature selection\n",
        "#http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html\n",
        "selector = SelectKBest(f_classif, k = 5)\n",
        "    #Where k = Number of top features to select\n",
        "    #f_classif = ANOVA F-value between label/feature for classification tasks. \n",
        "    #It returns a pair of arrays (scores_, pvalues_) or a single array with scores.\n",
        "selector.fit(titanic[predictors], titanic[\"Survived\"])\n",
        "#print(selector.pvalues_)\n",
        "#print(selector.scores_)\n",
        "scores = -np.log10(selector.pvalues_)\n",
        "    #Here, the smaller p_value means the more the feature affect the target \"Survived\"\n",
        "\n",
        "#Plot the scores of each feature\n",
        "plt.bar(range(len(predictors)), scores)\n",
        "plt.xticks(range(len(predictors)), predictors, rotation = \"vertical\")\n",
        "plt.show()\n",
        "\n",
        "#Pick the 4 best features\n",
        "predictors = [\"Pclass\", \"Sex\", \"Fare\", \"Title\"]\n",
        "alg = RandomForestClassifier(random_state = 1, n_estimators = 50,  min_samples_split = 8, min_samples_leaf = 4)\n",
        "kf = cross_validation.KFold(titanic.shape[0], n_folds = 3, random_state = 1)\n",
        "cv_scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv = kf)\n",
        "\n",
        "print(cv_scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a62bc684-e630-08bd-ebb2-698d5cfc517f"
      },
      "outputs": [],
      "source": [
        "##One thing we can do to improve the accuracy of our predictions \n",
        "##is to ensemble different classifiers.\n",
        "##generate predictions using information from a set of classifiers, instead of just one. \n",
        "##In practice, this means that we average their predictions.\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import numpy as np\n",
        "\n",
        "algorithms = [\n",
        "    [GradientBoostingClassifier(random_state = 1, n_estimators=25, max_depth = 3), [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]],\n",
        "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
        "]  \n",
        "\n",
        "#Initialize the cross validation folds\n",
        "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
        "\n",
        "predictions = []\n",
        "for train, test in kf:\n",
        "    train_target = titanic[\"Survived\"].iloc[train]\n",
        "    full_test_predictions = []\n",
        "#Make predictions for each algorithm on each fold\n",
        "    for alg, predictors in algorithms:\n",
        "        alg.fit(titanic[predictors].iloc[train, :], train_target)\n",
        "    #Make prediction on the test fold\n",
        "        test_predictions = alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]\n",
        "        full_test_predictions.append(test_predictions)\n",
        "        \n",
        "#Emsembling by averaging the predictions\n",
        "    test_predictions = (full_test_predictions[0] + full_test_predictions[1])/2\n",
        "    test_predictions[test_predictions <= 0.5] = 0\n",
        "    test_predictions[test_predictions > 0.5] = 1\n",
        "    predictions.append(test_predictions)\n",
        "\n",
        "#Concatenate all the predictions into one array\n",
        "predictions = np.concatenate(predictions, axis = 0)\n",
        " \n",
        "accuracy = sum(predictions[predictions == titanic[\"Survived\"]])/len(predictions)\n",
        "print(accuracy)\n",
        "\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5dcb6770-d4da-d2cb-42c8-637014f8ba4c"
      },
      "outputs": [],
      "source": [
        "###Apply changes to test set\n",
        "titles = titanic_test[\"Name\"].apply(get_title)\n",
        "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2, \"Dona\": 10}\n",
        "\n",
        "for key, value in title_mapping.items():\n",
        "    titles[titles == key] = value\n",
        "titanic_test[\"Title\"] = titles\n",
        "titanic_test[\"FamilySize\"] = titanic_test[\"SibSp\"] + titanic_test[\"Parch\"]\n",
        "\n",
        "family_ids = titanic_test.apply(get_family_id, axis = 1)\n",
        "family_ids[titanic_test[\"FamilySize\"] < 3] = -1\n",
        "titanic_test[\"FamilyId\"] = family_ids\n",
        "\n",
        "titanic_test[\"NameLength\"] = titanic_test[\"Name\"].apply(lambda x: len(x))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eb4cc193-2d05-4ff2-c8c9-ba82cf7f870d"
      },
      "outputs": [],
      "source": [
        "###Predicting on the test set\n",
        "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]\n",
        "\n",
        "algorithms = [\n",
        "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors],\n",
        "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
        "]\n",
        "\n",
        "full_predictions = []\n",
        "for alg, predictors in algorithms:\n",
        "    alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
        "    predictions = alg.predict_proba(titanic_test[predictors].astype(float))[:,1]\n",
        "    full_predictions.append(predictions)\n",
        "predictions = (full_predictions[0] * 3 + full_predictions[1])/4\n",
        "\n",
        "predictions[predictions <= 0.5] = 0\n",
        "predictions[predictions > 0.5] = 1\n",
        "predictions = predictions.astype(int)\n",
        "    \n",
        "submission = pd.DataFrame({\n",
        "    \"passengerId\": titanic_test[\"PassengerId\"],\n",
        "    \"Survived\": predictions\n",
        "})\n",
        "\n",
        "#print(submission)    \n",
        "submission.to_csv(\"kaggle_practice.csv\", index = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "732adf20-468e-2a05-32d4-194e8eedefcb"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}