{"cells": [{"metadata": {"_cell_guid": "95327b67-94e6-44f7-962d-b43ad294dd81", "_uuid": "142dd454cdac4e5526caae4ff461917c793cd6b6"}, "cell_type": "markdown", "source": ["# Titanic Competition"]}, {"metadata": {"_cell_guid": "46502909-d0f0-49b0-ab5e-1eb2a7ac0d35", "_uuid": "6359bf717f12d28268889c7cdcdd2283c414e025"}, "cell_type": "markdown", "source": ["# PART 1 : File train.csv"]}, {"execution_count": null, "metadata": {"_cell_guid": "8ad193d4-7b52-42fb-a153-6b4d89179bd5", "collapsed": true, "_uuid": "3c0da363ecb08cf2ad87c19127c6ee4b54dd2f55"}, "cell_type": "code", "outputs": [], "source": ["#import libraries are needed\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n", "from sklearn.preprocessing import Imputer, StandardScaler\n", "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, log_loss\n", "from sklearn.svm import SVC, LinearSVC\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier,BaggingClassifier,AdaBoostClassifier\n", "from matplotlib.pyplot import show\n", "%matplotlib inline"]}, {"execution_count": null, "metadata": {"_cell_guid": "9b350ea8-f01d-44ff-8d0f-e7c20dba658b", "collapsed": true, "_uuid": "0001cebe24e169017c1bfcb79288ffc51e09bb22"}, "cell_type": "code", "outputs": [], "source": ["#create function to calling data in file train.csv\n", "def importdata(data):\n", "    #Memanggil data train.csv\n", "    data=pd.read_csv(data)\n", "    #Shape data (row,col)\n", "    print('sum of observation,columns = ',data.shape)\n", "    #Check , is it any duplicated data?\n", "    print('Duplicated data = ',data.duplicated().sum())\n", "    #if any duplicated data, drop it\n", "    data=data.drop_duplicates()\n", "    #check shape of data\n", "    print('sum of (observation,columns) after remove duplicate = ', data.shape)\n", "    #give it back the data\n", "    return data\n", "#Calling funtions of import data\n", "data_train=importdata('../input/train.csv')"]}, {"execution_count": null, "metadata": {"_cell_guid": "524a568f-5870-475b-88aa-52af8d215695", "collapsed": true, "_uuid": "917c59cab360aa1d3baea9e1d8328c627b33f20a"}, "cell_type": "code", "outputs": [], "source": ["#Separates data_train into x and y\n", "def sep_xy(data,output):\n", "    #data_output merupakan nilai dari variabel output\n", "    data_output=data[output]\n", "    #data_input merupakan nilai dari variabel kecuali variabel output\n", "    data_input=data.drop(output,axis=1)\n", "    #kembalikan nilai data_input,data_output\n", "    return data_input, data_output\n", "x,y=sep_xy(data_train,'Survived')"]}, {"execution_count": null, "metadata": {"_cell_guid": "6249d341-692d-41b9-af17-1f1651331be7", "collapsed": true, "_uuid": "6d9c1e7d85667d18c9bfcc6584bd5c1867e31bd6"}, "cell_type": "code", "outputs": [], "source": ["#Separates x and y into training and testing with size 80/20 using train_test_split library\n", "x_train, x_test, y_train, y_test= train_test_split(x,y, test_size=0.2, random_state=105)"]}, {"metadata": {"_cell_guid": "f5cdf96e-2bd8-4588-ad43-274418dbd9b2", "_uuid": "119e637d0dd8d9cd47a1aa3f808f3538d3c225c3"}, "cell_type": "markdown", "source": ["# Explore x_train in file train.csv"]}, {"execution_count": null, "metadata": {"_cell_guid": "f8bf7002-6745-44f0-aac3-ac7d677545b6", "collapsed": true, "_uuid": "eceb9cdceccee7fb406234d323a5359e4dfbd3d2"}, "cell_type": "code", "outputs": [], "source": ["#Info each attribute\n", "x_train.info()"]}, {"execution_count": null, "metadata": {"_cell_guid": "3288756f-02be-4030-abb3-a27bd3374257", "collapsed": true, "_uuid": "fccf2ead02cb33de23bfaaa59405441870fe7002"}, "cell_type": "code", "outputs": [], "source": ["#---------------------------------------\n", "#Noted:\n", "#Numerical data:\n", "#SibSp          668 non-null int64\n", "#Parch          668 non-null int64\n", "#Age            529 non-null float64\n", "#Fare           668 non-null float64\n", "#categorical data:\n", "#Pclass         668 non-null int64\n", "#Sex            668 non-null object\n", "#Embarked       666 non-null object\n", "#Drop data:\n", "#Name           668 non-null object\n", "#Ticket         668 non-null object\n", "#Cabin          146 non-null object\n", "#PassengerId    668 non-null int64\n", "#---------------------------------------"]}, {"execution_count": null, "metadata": {"_cell_guid": "f05e2404-d2a8-49ae-88dd-a88a279f054b", "collapsed": true, "_uuid": "f8d97dcbb6c2a0f2832e5d4a994234f9decbff25"}, "cell_type": "code", "outputs": [], "source": ["#create functions Separates x_train into numerical and categorical\n", "def numerical_categorical(data,categoric_type,drop_data):\n", "    #create Numerical\n", "    data_numerical=data._get_numeric_data()\n", "    data_numerical=data_numerical.drop(categoric_type,axis=1)\n", "    #create Categorical\n", "    data_categorical=data.drop(data_numerical.columns, axis=1)\n", "    data_categorical=data_categorical.drop(drop_data,axis=1)\n", "    return data_numerical, data_categorical\n", "x_train_numerical, x_train_categorical=numerical_categorical(x_train,['Pclass','PassengerId'],['Name','Ticket','Cabin','PassengerId'])"]}, {"execution_count": null, "metadata": {"_cell_guid": "21f66590-95c8-441a-9f29-9fd347016953", "collapsed": true, "_uuid": "83bed84d9e664b0c11d1d39c8e279321bd47a3b9"}, "cell_type": "code", "outputs": [], "source": ["#info x_train_numerical\n", "x_train_numerical.info()"]}, {"execution_count": null, "metadata": {"_cell_guid": "05798282-e39c-43a4-a4a4-ad559905ef0b", "collapsed": true, "_uuid": "567ae1aea3c340a2fe1f3a298d531f7d98605341"}, "cell_type": "code", "outputs": [], "source": ["#Statistika Deskriptif for numerical attribute\n", "x_train_numerical.describe()"]}, {"execution_count": null, "metadata": {"_cell_guid": "c9f4ab65-7c20-425a-83c2-0f0c03a9e216", "collapsed": true, "_uuid": "ec3e3381e4ef2765b1326c5daa7f65f516e98bd7"}, "cell_type": "code", "outputs": [], "source": ["#check sum of missing value in x_train_numerical\n", "print('Sum of Missing Values = ', np.count_nonzero(x_train_numerical.isnull()))\n", "print('Sum of Non Missing Values = ', np.count_nonzero(x_train_numerical.notnull()))\n", "#Persen data missing\n", "print('Persen Missing = ', \n", "      np.count_nonzero(x_train_numerical.isnull())/(np.count_nonzero(x_train_numerical.isnull()) + np.count_nonzero(x_train_numerical.notnull())))                            "]}, {"execution_count": null, "metadata": {"_cell_guid": "2ecd009c-eae8-489d-b5ca-5d65dbb3bfcc", "collapsed": true, "_uuid": "e4729204be8fe377dc59a75da1919e4c1d557d65"}, "cell_type": "code", "outputs": [], "source": ["#check how much each attribute in x_train_numerical has null value \n", "x_train_numerical.isnull().sum()"]}, {"execution_count": null, "metadata": {"_cell_guid": "14eae43d-6d1f-465b-84d2-c9199dc5858a", "collapsed": true, "_uuid": "f26d6e86fa1ad0e63f995321446fa22a785ebadd"}, "cell_type": "code", "outputs": [], "source": ["#How many persen missing value in attribute Age?\n", "print('Persen Missing Of Age = ',\n", "      x_train_numerical['Age'].isnull().sum()/(x_train_numerical['Age'].isnull().sum() + x_train_numerical['Age'].notnull().sum()))"]}, {"execution_count": null, "metadata": {"_cell_guid": "65c10823-3048-421a-a118-867d55a96353", "collapsed": true, "_uuid": "02d4c742ba5e6e3d9b5cf7cb113be7bedf2e8a23"}, "cell_type": "code", "outputs": [], "source": ["#create function to imputer missing value in x_train_numerical\n", "def imput_numerical(data,missing_value,method):\n", "    #create imputer\n", "    imput_numeric=Imputer(missing_values=missing_value, strategy=method)\n", "    #fit imputer into data\n", "    imput_numeric.fit(data)\n", "    #transfor data with imputer for change missing value into kind of imputer, ex:median\n", "    data_imput_numerical=pd.DataFrame(imput_numeric.transform(data))\n", "    #return column name\n", "    data_imput_numerical.columns=data.columns\n", "    #return index \n", "    data_imput_numerical.index=data.index\n", "    \n", "    return data_imput_numerical, imput_numeric\n", "x_train_imput_numerical,imput_numerical=imput_numerical(x_train_numerical,'NaN','median')"]}, {"execution_count": null, "metadata": {"_cell_guid": "93973822-79d7-4ab7-8dc3-0699df30890c", "collapsed": true, "_uuid": "1800c1a7c7efb2b51fc86c0a03a58a3297b92d76"}, "cell_type": "code", "outputs": [], "source": ["#info x_train_categorical\n", "x_train_categorical.info()"]}, {"execution_count": null, "metadata": {"_cell_guid": "daf8896b-a016-470e-b102-b33f5e118694", "collapsed": true, "_uuid": "236315c54ea64cf03c9227ddc1f99fadfff73d6b"}, "cell_type": "code", "outputs": [], "source": ["#check sum of missing value in x_train_categorical\n", "print('Sum of Missing Values = ', np.count_nonzero(x_train_categorical.isnull()))\n", "print('Sum of Non Missing Values = ', np.count_nonzero(x_train_categorical.notnull()))\n", "#Persen data missing\n", "print('Persen Missing = ', \n", "      np.count_nonzero(x_train_categorical.isnull())/(np.count_nonzero(x_train_categorical.isnull()) + np.count_nonzero(x_train_categorical.notnull())))                            "]}, {"execution_count": null, "metadata": {"_cell_guid": "62d8ea35-805c-487c-ae28-7e9a8ef30a4a", "collapsed": true, "_uuid": "56fa70b877f32f77a3f0cd8ffc31f689c42ee213"}, "cell_type": "code", "outputs": [], "source": ["#check how much each attribute in x_train_categorical has null value \n", "x_train_categorical.isnull().sum()"]}, {"execution_count": null, "metadata": {"_cell_guid": "25b9f845-6525-4c2b-8a95-39c636c1a850", "collapsed": true, "_uuid": "c792b92ba5313f005f4a86216841a39069847466"}, "cell_type": "code", "outputs": [], "source": ["#How many persen missing value in attribute Embarked?\n", "print('Persen Missing Of Embarked = ',\n", "      x_train_categorical['Embarked'].isnull().sum()/(x_train_categorical['Embarked'].isnull().sum() + x_train_categorical['Embarked'].notnull().sum()))"]}, {"execution_count": null, "metadata": {"_cell_guid": "491bea93-2447-4028-9a29-8e483a4005e2", "collapsed": true, "_uuid": "c5372d46947879ec29afa4c217e7597a9ca4f0e8"}, "cell_type": "code", "outputs": [], "source": ["#check kind of kategorik whom has much proportion in each attribute\n", "pclass_count=x_train_categorical['Pclass'].value_counts(True)\n", "sex_count=x_train_categorical['Sex'].value_counts(True)\n", "embarked_count=x_train_categorical['Embarked'].value_counts(True)\n", "print(pclass_count,'\\n')\n", "print(sex_count,'\\n')\n", "print(embarked_count)"]}, {"execution_count": null, "metadata": {"_cell_guid": "695d3849-1f48-4dc4-b69c-52e224fbb8f9", "collapsed": true, "_uuid": "a1979a3fdc2978259da2c7ec34f8ff4b677a1d61"}, "cell_type": "code", "outputs": [], "source": ["# let create visualiztion on x_train_categorical\n", "#How much size to draw shape\n", "plt.figure(figsize=(5,5))\n", "#create barplot with Embarked data\n", "sns.barplot(embarked_count.index, embarked_count.values)\n", "#giving name on ylabel\n", "plt.ylabel('count', fontsize=12)\n", "#giving name on xlabel\n", "plt.xlabel('Embarked', fontsize=12)\n", "#giving strecht on barplot\n", "plt.grid()\n", "#show the result\n", "plt.show()"]}, {"execution_count": null, "metadata": {"_cell_guid": "14f873cc-fe55-4b4a-8187-58a5cf2cc88c", "collapsed": true, "_uuid": "e804f8440df801b321eb111d8cb45282eaad3d24"}, "cell_type": "code", "outputs": [], "source": ["# let create visualiztion on x_train_categorical\n", "#How much size to draw shape\n", "plt.figure(figsize=(5,5))\n", "#create barplot with Embarked data\n", "sns.barplot(pclass_count.index, pclass_count.values)\n", "#giving name on ylabel\n", "plt.ylabel('count', fontsize=12)\n", "#giving name on xlabel\n", "plt.xlabel('Pclass', fontsize=12)\n", "#giving strecht on barplot\n", "plt.grid()\n", "#show the result\n", "plt.show()"]}, {"execution_count": null, "metadata": {"_cell_guid": "79937d22-0435-40b4-a962-beea346ee323", "collapsed": true, "_uuid": "8d653d926390278c52b461e0e56b833f9c3ac7f7"}, "cell_type": "code", "outputs": [], "source": ["# let create visualiztion on x_train_categorical\n", "#How much size to draw shape\n", "plt.figure(figsize=(5,5))\n", "#create barplot with Embarked data\n", "sns.barplot(sex_count.index, sex_count.values)\n", "#giving name on ylabel\n", "plt.ylabel('count', fontsize=12)\n", "#giving name on xlabel\n", "plt.xlabel('Sex', fontsize=12)\n", "#giving strecht on barplot\n", "plt.grid()\n", "#show the result\n", "plt.show()"]}, {"execution_count": null, "metadata": {"_cell_guid": "15d6dd05-51e1-4b5d-8a53-4d8f6c0e98b6", "collapsed": true, "_uuid": "3a067b8f6927d6381582a1530f732b6dc4269c50"}, "cell_type": "code", "outputs": [], "source": ["plt.figure(figsize=(8,8))\n", "plt.grid()\n", "sns.countplot(x=\"Pclass\", hue=\"Sex\", data=x_train_categorical)"]}, {"execution_count": null, "metadata": {"_cell_guid": "98f172ea-aec1-49a3-bbec-bd677f0b6e24", "collapsed": true, "_uuid": "8acd2f56e9dd83af2e76c599a69661c8429f1241"}, "cell_type": "code", "outputs": [], "source": ["total = float(len(x_train_categorical))  \n", "ax = sns.countplot(x=\"Pclass\", hue=\"Sex\", data=x_train_categorical) \n", "for p in ax.patches:\n", "    height = p.get_height()\n", "    ax.text(p.get_x()+p.get_width()/2.,\n", "            height + 3,\n", "            '{:1.2f}'.format(height/total),\n", "            ha=\"center\") \n", "show()"]}, {"execution_count": null, "metadata": {"_cell_guid": "23438fb9-82ba-4fe1-a413-e0d07c9135e8", "collapsed": true, "_uuid": "a56fe6f3640827e0a7552fdee8b7a9f029d7179f"}, "cell_type": "code", "outputs": [], "source": ["plt.figure(figsize=(8,8))\n", "plt.grid()\n", "sns.countplot(x=\"Pclass\", hue=\"Embarked\", data=x_train_categorical)"]}, {"execution_count": null, "metadata": {"_cell_guid": "8db69e4a-51c7-4a93-8994-3f8e45d781f3", "collapsed": true, "_uuid": "be1f0f3206d32ceafd3dc72405a34b4f396b7578"}, "cell_type": "code", "outputs": [], "source": ["#create function to imputer missing value in x_train_categorical\n", "def imput_categorical(data,value):\n", "    #fill missing value S in Embarked \n", "    data_categorical_imput=data.fillna(value)\n", "    #Change data type into string beacuse the next step to create dummy must string\n", "    data_categorical_imput=data_categorical_imput.astype('str')\n", "    #create dummy variabel\n", "    data_categorical_imput=pd.get_dummies(data_categorical_imput,drop_first=True)\n", "    return data_categorical_imput, data_categorical_imput.columns\n", "x_train_imput_categorical, dummy_columns=imput_categorical(x_train_categorical,'S')"]}, {"execution_count": null, "metadata": {"_cell_guid": "08406d4c-eaa2-44d8-b58a-2f0953c1163a", "collapsed": true, "_uuid": "c7f539485225fcde1f493211a8d8ae7e6dadb476"}, "cell_type": "code", "outputs": [], "source": ["#Combine x_train_imput_numerical and x_train_imput_categorical\n", "x_train_preprocessed=pd.concat([x_train_imput_numerical,x_train_imput_categorical],axis=1)\n", "x_train_preprocessed.head()"]}, {"execution_count": null, "metadata": {"_cell_guid": "4c42eac9-78da-4695-9a21-808b65773a96", "collapsed": true, "_uuid": "45bcd8c3d1351f6f8676a1ab9b934d464ad27c53"}, "cell_type": "code", "outputs": [], "source": ["#info from 2 combine x_train imput numerical and categorical\n", "x_train_preprocessed.info()"]}, {"execution_count": null, "metadata": {"_cell_guid": "db172045-fc64-4653-807a-6168c67ca24d", "collapsed": true, "_uuid": "eb84303c2a15f686803d97668a5a5db272cc1580"}, "cell_type": "code", "outputs": [], "source": ["def male_female_child(data):\n", "    if (data['Age'] > 16 and data['Sex_male']==1 ):\n", "        return 'male' \n", "    elif (data['Age'] > 16 and data['Sex_male']==0 ):\n", "        return 'female'\n", "    elif (data['Age'] <= 16 and data['Sex_male']==1 ):\n", "        return 'child'\n", "    elif (data['Age'] <= 16 and data['Sex_male']==0 ):\n", "        return 'child'\n", "    else:\n", "        return data['Sex_male']\n", "x_train_preprocessed['Person'] = x_train_preprocessed.apply(male_female_child, axis=1)\n", "x_train_preprocessed.head()"]}, {"execution_count": null, "metadata": {"_cell_guid": "59eb59d6-936a-469e-8db5-e717898328f7", "collapsed": true, "_uuid": "529acd71bf1918c87251c7b7ad981b2a2401a110"}, "cell_type": "code", "outputs": [], "source": ["xy_train=pd.concat([x_train_preprocessed,y_train],axis=1)\n", "xy_train.head()"]}, {"execution_count": null, "metadata": {"_cell_guid": "b2303e09-0ffa-4422-b133-48b82885e906", "collapsed": true, "_uuid": "44b1bfaf2ccd0d57091cc5d4eb2a3ab2df7bcfb6"}, "cell_type": "code", "outputs": [], "source": ["plt.figure(figsize=(8,8))\n", "plt.grid()\n", "sns.countplot(x=\"Survived\", hue=\"Person\", data=xy_train)"]}, {"execution_count": null, "metadata": {"_cell_guid": "0b4ce33f-d789-499e-92ba-61a3e66890bc", "collapsed": true, "_uuid": "dea5cc40ee7013d6f68910a20d0e475b636d7dd6"}, "cell_type": "code", "outputs": [], "source": ["xy_train['Person'].value_counts(True)"]}, {"execution_count": null, "metadata": {"_cell_guid": "63a0f26f-4cec-40bd-b6a1-8da5e3276abe", "collapsed": true, "_uuid": "345498111e0e5b104ecff6c3404ce2b8dd7583fc"}, "cell_type": "code", "outputs": [], "source": ["xy_train.head()"]}, {"execution_count": null, "metadata": {"_cell_guid": "d20e65a7-ae0d-4844-afeb-293dc39ddd67", "collapsed": true, "_uuid": "62358e9d0982d3808f26438e9334d4ee5c7d9c01"}, "cell_type": "code", "outputs": [], "source": ["# Buatalah kolom Alone dengan menambahkan titanic_df.Parch + titanic_df.SibSp\n", "# Kemudian tampilkan series sesuai di bawah ini\n", "Alone=data_train.Parch+data_train.SibSp\n", "Alone=pd.DataFrame(Alone)\n", "Alone.columns=['Alone']"]}, {"execution_count": null, "metadata": {"_cell_guid": "f8706e87-798a-49fb-9b6b-ae5e66d25e5a", "collapsed": true, "_uuid": "f9f1342ea36e0557e0ed017645b925762c226b1e"}, "cell_type": "code", "outputs": [], "source": ["xy_train=xy_train.join(Alone)"]}, {"execution_count": null, "metadata": {"_cell_guid": "4a0aa729-dfd7-4b54-aab3-2455ff950115", "collapsed": true, "_uuid": "0a95a946d628bbac778c92737ce4b0337cf656cc"}, "cell_type": "code", "outputs": [], "source": ["xy_train.head()"]}, {"execution_count": null, "metadata": {"_cell_guid": "d956928f-4ffb-4864-b1f0-5a7552e61fe3", "collapsed": true, "_uuid": "96c23bfaef0ca3730f8d290c4cc868e815a46d2b"}, "cell_type": "code", "outputs": [], "source": ["def alone(data):\n", "    if (data['Alone'] == 1):\n", "        return 'With Family' \n", "    else:\n", "        return 'Alone'\n", "xy_train['Alone'] = xy_train.apply(alone, axis=1)"]}, {"execution_count": null, "metadata": {"_cell_guid": "c2f6f0be-0bf9-4bc6-86ac-e977ca8b3927", "collapsed": true, "_uuid": "71291b2c19b358e767c5fbac0d28d091b723454d"}, "cell_type": "code", "outputs": [], "source": ["plt.figure()\n", "sns.barplot(xy_train['Alone'].value_counts().index,xy_train['Alone'].value_counts().values)\n", "plt.ylabel('count', fontsize=12)\n", "plt.xlabel('Alone', fontsize=12)\n", "plt.show()"]}, {"execution_count": null, "metadata": {"_cell_guid": "a06a3a4e-565a-4e0f-b467-a74f9fe53f15", "collapsed": true, "_uuid": "6e64db60d5af942702b99fb41ba57d9b4e0bb260"}, "cell_type": "code", "outputs": [], "source": ["plt.figure(figsize=(8,8))\n", "sns.countplot(x=\"Survived\", hue=\"Alone\", data=xy_train)\n", "plt.xlabel('Survivor')\n"]}, {"execution_count": null, "metadata": {"_cell_guid": "a51cd6b8-8a9d-4953-8d73-ca61e8cf50b4", "collapsed": true, "_uuid": "8048505970aee2120819150e762388ed97a7feeb"}, "cell_type": "code", "outputs": [], "source": ["#xy_train-->combine x_train_preprocessed and y_train\n", "x_train_preprocessed=x_train_preprocessed.drop(['Person'],axis=1)"]}, {"execution_count": null, "metadata": {"_cell_guid": "de9c8a3e-b589-411d-8326-42615418b73c", "collapsed": true, "_uuid": "d0869ce9711383240d4c3d82eb59bec0b0598f5d"}, "cell_type": "code", "outputs": [], "source": ["#Create function to Standardize x_train_preprocessed\n", "def standardize(data):\n", "    scaler=StandardScaler()\n", "    scaler.fit(data)\n", "    data_standardize=pd.DataFrame(scaler.transform(data))\n", "    data_standardize.columns=data.columns\n", "    data_standardize.index=data.index\n", "    return data_standardize, scaler\n", "x_train_norm, standardize=standardize(x_train_preprocessed)"]}, {"execution_count": null, "metadata": {"_cell_guid": "1d80b644-5c40-41ab-aec1-3cb8a3cce717", "collapsed": true, "_uuid": "6a526cff50e52cbad1c54d0c011734729b41abf5"}, "cell_type": "code", "outputs": [], "source": ["#Function logistics regression\n", "def logreg_fit(x_train, y_train):\n", "    logreg = LogisticRegression()\n", "    hyperparam = {'C': [1000, 333.33, 100, 33.33, 10, 3.33, 10, 3.33, 1, 0.33, 0.1, 0.033, 0.01, 0.0033, \n", "                        0.001, 0.00033, 0.0001]}\n", "    #n_jobs=2 artinya tergantung spech leptop\n", "    random_logreg = RandomizedSearchCV(logreg, param_distributions = hyperparam, cv = 10,\n", "                                    n_iter = 10, n_jobs=-1, random_state = 125)\n", "    random_logreg.fit(x_train, y_train)\n", "    print (\"Best Accuracy\", random_logreg.best_score_)\n", "    print (\"Best Param\", random_logreg.best_params_)\n", "    return random_logreg"]}, {"execution_count": null, "metadata": {"_cell_guid": "3fe06e65-1432-41bf-8b2e-d42e62168fc1", "collapsed": true, "_uuid": "d7a021629beaa143d6cedceacebdd411aef6828a"}, "cell_type": "code", "outputs": [], "source": ["best_logreg = logreg_fit(x_train_norm, y_train) "]}, {"execution_count": null, "metadata": {"_cell_guid": "8882233f-dc8c-4d63-83ad-b893b71d0c95", "collapsed": true, "_uuid": "7fbb15c15652992cec51cf1f253dd24c0be08f3b"}, "cell_type": "code", "outputs": [], "source": ["best_logreg"]}, {"execution_count": null, "metadata": {"_cell_guid": "1a80a7f9-3c03-46ba-b3f7-52b9aa859fb6", "collapsed": true, "_uuid": "f83f0a573c70105c62662144258b0709cf239c48"}, "cell_type": "code", "outputs": [], "source": ["logreg = LogisticRegression(C=best_logreg.best_params_.get('C'))\n", "logreg.fit(x_train_norm, y_train)"]}, {"execution_count": null, "metadata": {"_cell_guid": "eb32b0f9-1696-4e59-839b-d74c0728184e", "collapsed": true, "_uuid": "f1ab4724ead753d660497681f6440ef3b1c5fe89"}, "cell_type": "code", "outputs": [], "source": ["#Function Decision Tree\n", "def dectree_fit(x_train, y_train, scoring = 'accuracy'):\n", "    dectree = DecisionTreeClassifier(random_state=125)\n", "    #min_samples_split untuk \n", "    #max_features untuk\n", "    #max_depth untuk\n", "    hyperparam = {'min_samples_split': [3, 5, 7, 9, 13, 17, 21, 27, 33, 41, 50, 60, 80, 100],\n", "                  'max_features': ['sqrt', 'log2', 0.25, 0.5, 0.75],\n", "                  'max_depth': [2, 4, 6, 8]                 }\n", "\n", "    random_dectree = RandomizedSearchCV(dectree, \n", "                                        param_distributions= hyperparam, \n", "                                        cv = 20, n_iter = 20, \n", "                                        scoring = scoring, n_jobs=10, random_state = 125)\n", "    \n", "    random_dectree.fit(x_train, y_train)\n", "    \n", "    print (\"Best Accuracy\", random_dectree.best_score_)\n", "    print (\"Best Param\", random_dectree.best_params_)\n", "    \n", "    return random_dectree"]}, {"execution_count": null, "metadata": {"_cell_guid": "cfd16cc8-8943-4080-9a37-d35f87e21a18", "collapsed": true, "_uuid": "db9372eb9a0654c930879a2be9115db51cc66536"}, "cell_type": "code", "outputs": [], "source": ["best_dectree = dectree_fit(x_train_norm, y_train)"]}, {"execution_count": null, "metadata": {"_cell_guid": "91e507b8-b341-45d1-ae39-a7081ccb7d61", "collapsed": true, "_uuid": "a62635fd0153696c6b9d0fabb9888f3e081e4d0a"}, "cell_type": "code", "outputs": [], "source": ["best_dectree.score(x_train_norm,y_train)"]}, {"execution_count": null, "metadata": {"_cell_guid": "d57a4a11-4da2-4ec5-b592-755e0c71eed7", "collapsed": true, "_uuid": "bfeec281b9b4e9a00405405362cedecebcb67ed0"}, "cell_type": "code", "outputs": [], "source": ["dectree = DecisionTreeClassifier(random_state=125,\n", "                                  min_samples_split= best_dectree.best_params_.get('min_samples_split'),\n", "                                  max_features = best_dectree.best_params_.get('max_features'),\n", "                                  max_depth = best_dectree.best_params_.get('max_depth'))\n", "dectree.fit(x_train_norm, y_train)"]}, {"execution_count": null, "metadata": {"_cell_guid": "c90b68ae-489f-4823-adea-25aff6f37890", "collapsed": true, "_uuid": "06ecd1415e3e83da43a5aca9b37150a660328919"}, "cell_type": "code", "outputs": [], "source": ["##Function Bagging Boostrap\n", "def bagging_fit(x_train, y_train, scoring = 'accuracy'):\n", "    dectree = DecisionTreeClassifier(random_state=125)\n", "    \n", "    bagging = BaggingClassifier(base_estimator = dectree, \n", "                                random_state=125)\n", "    \n", "    #base_estimator_min_samples_split untuk\n", "    #base_estimator_max_depth untuk\n", "    #n_estimators untuk\n", "    hyperparam = {'base_estimator__min_samples_split': [3, 5, 7, 9, 13, 17, 21, 27, 33, 41, 50, 60, 80, 100],\n", "                  'base_estimator__max_depth': [2, 4, 6, 8],\n", "                  'n_estimators': [100, 200, 300, 500, 750, 1000]}\n", "    # 'base_estimator__' sebelum 'min_samples_leaf' menandakan hyperparameter yang dicari ada di dalam base estimatornya\n", "    # dalam hal ini berarti decTree\n", "    # (min_samples_leaf ada di dalam decTree)\n", "    \n", "    #scoring ada berapa macam selain accuracy--->\n", "    random_bagging = RandomizedSearchCV(bagging, \n", "                                        param_distributions = hyperparam, \n", "                                        cv = 20, \n", "                                        n_iter = 20, \n", "                                        scoring = scoring,\n", "                                        n_jobs = 5, \n", "                                        random_state = 125)\n", "    \n", "    random_bagging.fit(x_train, y_train)\n", "    \n", "    print(\"Best Accuracy\", random_bagging.best_score_)\n", "    print(\"Best Param\", random_bagging.best_params_)\n", "    return random_bagging"]}, {"execution_count": null, "metadata": {"_cell_guid": "8afba067-74dd-448c-9b87-80cbd26c18df", "collapsed": true, "_uuid": "811a219731bd033c8b879960344eef50f6336b12"}, "cell_type": "code", "outputs": [], "source": ["best_bagging = bagging_fit(x_train_norm, y_train)"]}, {"execution_count": null, "metadata": {"_cell_guid": "e3c24bb7-2e6c-427b-ad2a-e17ad84405db", "collapsed": true, "_uuid": "5cf463086b2bb5ff12304b751a5aa89b49be896e"}, "cell_type": "code", "outputs": [], "source": ["dectree_bagging = DecisionTreeClassifier(min_samples_split = best_bagging.best_params_.get('base_estimator__min_samples_split'),\n", "                                         max_depth = best_bagging.best_params_.get('base_estimator__max_depth'),\n", "                                         random_state=125)\n", "bagging = BaggingClassifier(base_estimator = dectree_bagging, \n", "                            n_estimators = best_bagging.best_params_.get('n_estimators'),\n", "                            random_state=125, n_jobs=2)\n", "bagging.fit(x_train_norm, y_train)"]}, {"execution_count": null, "metadata": {"_cell_guid": "ccd03907-8d6d-43b6-a226-0561c1261fb9", "collapsed": true, "_uuid": "9884d201c363946e2aba66a76fbc2bb8f796b442"}, "cell_type": "code", "outputs": [], "source": ["#Function Random Forest\n", "def rf_fit(x_train, y_train, scoring = 'accuracy'):\n", "    random_forest = RandomForestClassifier(random_state=125)\n", "\n", "    hyperparam = {'min_samples_split': [3, 5, 7, 9, 13, 17, 21, 27, 33, 41, 50, 60, 80, 100],\n", "                  'max_features': ['sqrt', 'log2', 0.25, 0.5, 0.75], \n", "                  'n_estimators': [100, 200, 300, 500, 750, 1000]}\n", "    \n", "    random_rf = RandomizedSearchCV(random_forest, \n", "                                             param_distributions = hyperparam,\n", "                                             cv = 20, \n", "                                             n_iter = 20, \n", "                                             scoring = scoring, \n", "                                             n_jobs=8, \n", "                                             random_state = 125)\n", "    \n", "    random_rf.fit(x_train, y_train)\n", "    \n", "    print(\"Best Accuracy\", random_rf.best_score_)\n", "    print(\"Best Param\", random_rf.best_params_)\n", "    return random_rf"]}, {"execution_count": null, "metadata": {"_cell_guid": "aa28b554-b1b5-454f-9dc0-65124c945ad4", "collapsed": true, "_uuid": "d01c8eefd40e11a747c5e176069379d50f27fdb9"}, "cell_type": "code", "outputs": [], "source": ["best_rf = rf_fit(x_train_norm, y_train)"]}, {"execution_count": null, "metadata": {"_cell_guid": "ef032a38-10f5-4e8a-8006-3fc6e11f0960", "collapsed": true, "_uuid": "23e4f0e686a2f0ed825888b7d873baf34ff17043"}, "cell_type": "code", "outputs": [], "source": ["random_forest = RandomForestClassifier(random_state=125, n_jobs = 2,\n", "                                   min_samples_split = best_rf.best_params_.get('min_samples_split'),\n", "                                   max_features = best_rf.best_params_.get('max_features'),\n", "                                   n_estimators = best_rf.best_params_.get('n_estimators'))\n", "random_forest.fit(x_train_norm, y_train)"]}, {"execution_count": null, "metadata": {"_cell_guid": "03e6e088-f29d-4010-9881-6b767169b27b", "collapsed": true, "_uuid": "0deca88aba977db117fc57d05bbf009c726b8e83"}, "cell_type": "code", "outputs": [], "source": ["#Functions adaboost\n", "def adaboost_fit(x_train, y_train, scoring = 'accuracy'):\n", "    dectree = DecisionTreeClassifier(random_state=125)\n", "    \n", "    adaboost = AdaBoostClassifier(base_estimator = dectree, \n", "                                  random_state=125)\n", "    \n", "    hyperparam = {'base_estimator__min_samples_split': [3, 5, 7, 9, \n", "                                                       13, 17, 21, 27, \n", "                                                       33, 41, 50, 60, \n", "                                                       80, 100],\n", "                  'base_estimator__max_features': ['sqrt', 'log2', \n", "                                                   0.25, 0.5, 0.75],\n", "                  'learning_rate': [0.01, 0.015, 0.02, \n", "                                    0.05, 0.08, 0.1],\n", "                  'n_estimators': [100, 200, 300, \n", "                                   500, 750, 1000]}\n", "    \n", "    random_adaboost = RandomizedSearchCV(adaboost, \n", "                                         param_distributions = hyperparam, \n", "                                         cv = 20, \n", "                                         n_iter = 20, \n", "                                         scoring = scoring, \n", "                                         n_jobs=10, \n", "                                         random_state = 125)\n", "    \n", "    random_adaboost.fit(x_train, y_train)\n", "    \n", "    print (\"Best Accuracy\", random_adaboost.best_score_)\n", "    print (\"Best Param\", random_adaboost.best_params_)\n", "    return random_adaboost"]}, {"execution_count": null, "metadata": {"_cell_guid": "d51e528a-1cc8-4aef-a951-7d8bbc47d695", "collapsed": true, "_uuid": "abea83cd0734629cd2753de95bef6e1f0bd697b9"}, "cell_type": "code", "outputs": [], "source": ["best_adaboost = adaboost_fit(x_train_norm, y_train)"]}, {"execution_count": null, "metadata": {"_cell_guid": "26cc7114-0231-43ea-8807-a867b3c6cc87", "collapsed": true, "_uuid": "3f9e4eb77574180074558e7147dc04e2066d4414"}, "cell_type": "code", "outputs": [], "source": ["dectree_boost = DecisionTreeClassifier(min_samples_split = best_adaboost.best_params_.get('base_estimator__min_samples_split'),\n", "                                      max_features = best_adaboost.best_params_.get('base_estimator__max_features'),\n", "                                      random_state=125)\n", "adaboost = AdaBoostClassifier(base_estimator = dectree_boost, \n", "                             n_estimators = best_adaboost.best_params_.get('n_estimators'),\n", "                             learning_rate = best_adaboost.best_params_.get('learning_rate'),\n", "                             random_state=125)\n", "adaboost.fit(x_train_norm, y_train)"]}, {"execution_count": null, "metadata": {"_cell_guid": "19c467aa-23a9-4e44-90a4-73d7220cf960", "collapsed": true, "_uuid": "de7d11c1125ea9e432193e8f3f41047339d4fbc6"}, "cell_type": "code", "outputs": [], "source": ["#Functions Gradient Boosting\n", "def gradientboost_fit(x_train, y_train, scoring = 'accuracy'):\n", "    gradient_boost = GradientBoostingClassifier(random_state=125)\n", "    \n", "    hyperparam = {'min_samples_split': [3, 5, 7, 9, 13, 17, 21, 27, 33, 41, 50, 60, 80, 100],\n", "                  'max_features': ['sqrt', 'log2', 0.25, 0.5, 0.75], \n", "                  'n_estimators': [100, 200, 300, 500, 750, 1000],\n", "                  'learning_rate': [0.01, 0.015, 0.02, 0.05, 0.08, 0.1] }\n", "    random_gradientboost = RandomizedSearchCV(gradient_boost, param_distributions = hyperparam, cv = 20,\n", "                                          n_iter = 20, scoring = scoring, n_jobs=10, \n", "                                          random_state = 125, verbose = True)\n", "    random_gradientboost.fit(x_train, y_train)\n", "    \n", "    print (\"Best Accuracy\", random_gradientboost.best_score_)\n", "    print (\"Best Param\", random_gradientboost.best_params_)\n", "    return random_gradientboost"]}, {"execution_count": null, "metadata": {"_cell_guid": "a64cbb4b-0af3-4b8f-8586-d462a01952ff", "collapsed": true, "_uuid": "1ec5d72800780ce8407685b48ddbb00318ad0cc9"}, "cell_type": "code", "outputs": [], "source": ["best_gradientboost = gradientboost_fit(x_train_norm, y_train)"]}, {"execution_count": null, "metadata": {"_cell_guid": "e6654e88-e528-424d-892c-fe37d5be9abe", "collapsed": true, "_uuid": "bf263fdb8c46b6deb76e9652c012a96a18798e07"}, "cell_type": "code", "outputs": [], "source": ["gradient_boost = GradientBoostingClassifier(n_estimators=best_gradientboost.best_params_.get('n_estimators'),\n", "                                       min_samples_leaf = best_gradientboost.best_params_.get('min_samples_split'),\n", "                                       max_features = best_gradientboost.best_params_.get('max_features'),\n", "                                       learning_rate = best_gradientboost.best_params_.get('learning_rate'), random_state=123)\n", "gradient_boost.fit(x_train_norm, y_train)"]}, {"metadata": {"_cell_guid": "24e900ca-f617-4f0d-a57e-134737c9ff20", "_uuid": "835d6e3fca5f10d0147eabd6d52a97a1c3a22007"}, "cell_type": "markdown", "source": ["# TESTING                     x_test       y_test"]}, {"execution_count": null, "metadata": {"_cell_guid": "00e4548f-62ff-48a8-ac90-1b8c96b18cc2", "collapsed": true, "_uuid": "5507aa111635ac72a8309a11eb73eaf72b1c505f"}, "cell_type": "code", "outputs": [], "source": ["#All functions Test\n", "def testNumeric(data, imputer):\n", "    numerical_data_imputed = pd.DataFrame(imputer.transform(data))\n", "    numerical_data_imputed.columns = data.columns\n", "    numerical_data_imputed.index = data.index\n", "    return  numerical_data_imputed\n", "def testCategorical(data, value, dummy_column):\n", "    categorical_data_imputed = data.fillna(value)\n", "    categorical_data_imputed = categorical_data_imputed.astype('str')\n", "    dummy = pd.get_dummies(categorical_data_imputed)\n", "    dummy = dummy.reindex(columns = dummy_column, fill_value = 0)\n", "    return dummy\n", "def testStandardize(data, standardize):\n", "    data_columns = data.columns  # agar nama column tidak hilang\n", "    data_index = data.index # agar index tidak hilang\n", "    data_standardized = pd.DataFrame(standardize.transform(data))\n", "    data_standardized.columns = data_columns\n", "    data_standardized.index = data_index\n", "    return data_standardized\n", "def newData(data, imput_numerical, value_categorical, dummy_columns, standardizer):\n", "    #Numerical Categorical Split\n", "    data_numerical, data_categorical = numerical_categorical(data, [\"Pclass\",\"PassengerId\"],[\"Name\",\"Ticket\",\"Cabin\",\"PassengerId\"])\n", "    # Numerical Imputation\n", "    data_numerical_imputed = testNumeric(data_numerical, imput_numerical)\n", "    # Categorical Imputation\n", "    data_categorical_imputed = testCategorical(data_categorical, value_categorical, dummy_columns)\n", "    # Join\n", "    data_preprocessed = pd.concat([data_numerical_imputed, data_categorical_imputed], axis = 1)\n", "    # Normalization\n", "    data_norm = testStandardize(data_preprocessed, standardizer)\n", "    return data_norm\n", "def evalModel(x, y, clf):\n", "    print (\"Accuracy  : %.5f\" % accuracy_score(y, clf.predict(x)))\n", "    print (\"Recall    : %.5f\" % recall_score(y, clf.predict(x)))\n", "    print (\"Precision : %.5f\" % precision_score(y, clf.predict(x)))\n", "    print (\"F1 score  : %.5f\" % f1_score(y, clf.predict(x)))"]}, {"execution_count": null, "metadata": {"_cell_guid": "91801b00-bd44-41a9-8ade-3582260060df", "collapsed": true, "_uuid": "e304bf70a633af60380333870daa0810615bbf9e"}, "cell_type": "code", "outputs": [], "source": ["x_test_norm = newData(x_test, imput_numerical, \"S\", dummy_columns, standardize)"]}, {"execution_count": null, "metadata": {"_cell_guid": "f9cedc6a-7e44-47e8-8aa3-dea21ce63961", "collapsed": true, "_uuid": "e58e7557c6068b270cd0a11068acf861a78c2323"}, "cell_type": "code", "outputs": [], "source": ["print(logreg.score(x_test_norm, y_test))\n", "print(dectree.score(x_test_norm, y_test))\n", "print(bagging.score(x_test_norm, y_test))\n", "print(random_forest.score(x_test_norm, y_test))\n", "print(adaboost.score(x_test_norm, y_test))\n", "print(gradient_boost.score(x_test_norm, y_test))"]}, {"execution_count": null, "metadata": {"_cell_guid": "8550dfb5-71a2-4685-953f-e38e5c6cb538", "collapsed": true, "_uuid": "f80535d95ae22a55eccc6eac23418f02410df917"}, "cell_type": "code", "outputs": [], "source": ["evalModel(x_test_norm, y_test, logreg)"]}, {"execution_count": null, "metadata": {"_cell_guid": "bd099b36-1c53-4530-9e10-f3e2a276f2c2", "collapsed": true, "_uuid": "1127eecb53a140a0551f9ef92640f272d98b9ab3"}, "cell_type": "code", "outputs": [], "source": ["evalModel(x_test_norm, y_test, dectree)"]}, {"execution_count": null, "metadata": {"_cell_guid": "31ed7024-de77-4344-b138-9eff2570f8e0", "collapsed": true, "_uuid": "3c2ddd0e3f7ca68676b47acd4d562c1052a418fc"}, "cell_type": "code", "outputs": [], "source": ["evalModel(x_test_norm, y_test, bagging)"]}, {"execution_count": null, "metadata": {"_cell_guid": "d6719faa-6c44-4d05-957c-5e8877dfe1f8", "collapsed": true, "_uuid": "1e9981d9be4b56b9cf42d47576e3ecbcbb032280"}, "cell_type": "code", "outputs": [], "source": ["evalModel(x_test_norm, y_test, random_forest)"]}, {"execution_count": null, "metadata": {"_cell_guid": "e5935dd4-5fc4-46fe-9a6c-362a6cc101bc", "collapsed": true, "_uuid": "01f2453e5c188aed3bb2b0ec4af9e4dc6fa293fe"}, "cell_type": "code", "outputs": [], "source": ["evalModel(x_test_norm, y_test, adaboost)"]}, {"execution_count": null, "metadata": {"_cell_guid": "a8783f9e-7c66-4276-97cc-88fa72b07857", "collapsed": true, "_uuid": "de3616b84d07f5d1f7f2efa03274f55a8a504c53"}, "cell_type": "code", "outputs": [], "source": ["evalModel(x_test_norm, y_test, gradient_boost)"]}, {"metadata": {"_cell_guid": "63c50df5-db9c-46de-844b-0bd2219cf152", "_uuid": "e0422efb43ba328c36784c3c2d83651495e3fa41"}, "cell_type": "markdown", "source": ["# PART 2 Y_PREDICTION ON NEW DATA in file test.csv"]}, {"execution_count": null, "metadata": {"_cell_guid": "7ae1c199-298d-4b5d-8b6d-fc1c6588a370", "collapsed": true, "_uuid": "20e0f883764fbdcf3cddb8043797bf826218546b", "scrolled": true}, "cell_type": "code", "outputs": [], "source": ["data=pd.read_csv(\"../input/test.csv\")\n", "data1=pd.read_csv(\"../input/test.csv\")\n", "data2=pd.read_csv(\"../input/test.csv\")\n", "data3=pd.read_csv(\"../input/test.csv\")\n", "data4=pd.read_csv(\"../input/test.csv\")\n", "data5=pd.read_csv(\"../input/test.csv\")"]}, {"execution_count": null, "metadata": {"_cell_guid": "759bb9ac-b129-436a-a67f-203f8dbbd846", "collapsed": true, "_uuid": "aa3bc7a21ea7349eb9714aacc5dc04d1ab760d0f"}, "cell_type": "code", "outputs": [], "source": ["x_new_norm = newData(data, imput_numerical, \"S\", dummy_columns, standardize)\n", "x_new_norm.head()"]}, {"execution_count": null, "metadata": {"_cell_guid": "779b40f4-1d57-420f-b540-232cacda8ecb", "collapsed": true, "_uuid": "3974c66d61491d3a45fa31abe9682ee71cef368a"}, "cell_type": "code", "outputs": [], "source": ["y_predict_logreg=logreg.predict(x_new_norm)\n", "y_predict_logreg"]}, {"execution_count": null, "metadata": {"_cell_guid": "6288301c-ee95-4215-abe4-41f455239aae", "collapsed": true, "_uuid": "16fd21f0940515446b2181c8d32640fa8ab6dc9f"}, "cell_type": "code", "outputs": [], "source": ["y_predict_dectree=dectree.predict(x_new_norm)\n", "y_predict_dectree"]}, {"execution_count": null, "metadata": {"_cell_guid": "875a8f2f-837e-483a-99aa-a5eb3951329c", "collapsed": true, "_uuid": "3fee1d54e2f1fa242454ab5e9628334e40484829"}, "cell_type": "code", "outputs": [], "source": ["y_predict_bagging=bagging.predict(x_new_norm)\n", "y_predict_bagging"]}, {"execution_count": null, "metadata": {"_cell_guid": "d558f6ce-7dd7-42c5-a3d8-cfc701d6b36e", "collapsed": true, "_uuid": "93b66a15b14de2e0663f4b38be3f750fb1e64d35"}, "cell_type": "code", "outputs": [], "source": ["y_predict_random_forest=random_forest.predict(x_new_norm)\n", "y_predict_random_forest"]}, {"execution_count": null, "metadata": {"_cell_guid": "1434eb59-aea9-46b9-9237-841e3b8e9136", "collapsed": true, "_uuid": "7067004d56ab27a440a5ad3de26fce7df7f765c1"}, "cell_type": "code", "outputs": [], "source": ["y_predict_adaboost=adaboost.predict(x_new_norm)\n", "y_predict_adaboost"]}, {"execution_count": null, "metadata": {"_cell_guid": "b4c50556-baaf-4324-9acd-1c631adb3bd3", "collapsed": true, "_uuid": "6d2559fa3ddcf2f2076472afe34b1188b9db972d"}, "cell_type": "code", "outputs": [], "source": ["y_predict_gradient_boost=gradient_boost.predict(x_new_norm)\n", "y_predict_gradient_boost"]}, {"execution_count": null, "metadata": {"_cell_guid": "65670d70-70df-4b0f-ba9f-a64328762556", "collapsed": true, "_uuid": "129dd12d110cf54b9023279dc763cf006a7ec4d6"}, "cell_type": "code", "outputs": [], "source": ["data[\"Survived\"]=y_predict_logreg\n", "data1[\"Survived\"]=y_predict_dectree\n", "data2[\"Survived\"]=y_predict_bagging\n", "data3[\"Survived\"]=y_predict_random_forest\n", "data4[\"Survived\"]=y_predict_adaboost\n", "data5[\"Survived\"]=y_predict_gradient_boost"]}, {"execution_count": null, "metadata": {"_cell_guid": "6451b8e1-7757-4d75-ae0c-edc88777464c", "collapsed": true, "_uuid": "eafaa5b98605b152e3dcc532e320b4300ac3d5a9"}, "cell_type": "code", "outputs": [], "source": ["#save output to excel\n", "df_output = data.drop(['Pclass','Name','Sex','SibSp','Parch','Ticket','Fare','Cabin','Embarked','Age'], axis=1)\n", "df_output1 = data1.drop(['Pclass','Name','Sex','SibSp','Parch','Ticket','Fare','Cabin','Embarked','Age'], axis=1)\n", "df_output2 = data2.drop(['Pclass','Name','Sex','SibSp','Parch','Ticket','Fare','Cabin','Embarked','Age'], axis=1)\n", "df_output3 = data3.drop(['Pclass','Name','Sex','SibSp','Parch','Ticket','Fare','Cabin','Embarked','Age'], axis=1)\n", "df_output4 = data4.drop(['Pclass','Name','Sex','SibSp','Parch','Ticket','Fare','Cabin','Embarked','Age'], axis=1)\n", "df_output5 = data5.drop(['Pclass','Name','Sex','SibSp','Parch','Ticket','Fare','Cabin','Embarked','Age'], axis=1)\n", "writerxls = pd.ExcelWriter('../input/Submission_logreg.xls')\n", "writerxls1 = pd.ExcelWriter('../input/Submission_dectree.xls')\n", "writerxls2 = pd.ExcelWriter('../input/Submission_bagging.xls')\n", "writerxls3 = pd.ExcelWriter('../input/Submission_random_forest.xls')\n", "writerxls4 = pd.ExcelWriter('../input/Submission_adaboost.xls')\n", "writerxls5 = pd.ExcelWriter('../input/Submission_gradient_boost.xls')\n", "df_output.to_excel(writerxls,'Sheet1')\n", "df_output1.to_excel(writerxls1,'Sheet1')\n", "df_output2.to_excel(writerxls2,'Sheet1')\n", "df_output3.to_excel(writerxls3,'Sheet1')\n", "df_output4.to_excel(writerxls4,'Sheet1')\n", "df_output5.to_excel(writerxls5,'Sheet1')\n", "writerxls.save()\n", "writerxls1.save()\n", "writerxls2.save()\n", "writerxls3.save()\n", "writerxls4.save()\n", "writerxls5.save()"]}, {"metadata": {"_cell_guid": "76bd1017-2f75-4bc4-afaf-6b6660f1c864", "_uuid": "7185cf179be9b3c0c9700c48781994cf0240226d"}, "cell_type": "markdown", "source": ["# FINISH"]}], "nbformat_minor": 1, "metadata": {"language_info": {"mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "name": "python", "file_extension": ".py", "version": "3.6.3", "nbconvert_exporter": "python"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "nbformat": 4}