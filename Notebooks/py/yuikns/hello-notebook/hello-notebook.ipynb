{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "05ffb6ae-6776-3d1c-904d-de9578c8d9fa"
      },
      "source": [
        "## This is a practice to solve problems using notebook\n",
        "\n",
        "this nb is based on a set of previous kernels, list as follow:\n",
        "\n",
        "+ [/sachinkulkarni/titanic/an-interactive-data-science-tutorial](/sachinkulkarni/titanic/an-interactive-data-science-tutorial)\n",
        "+ [/mariammohamed/titanic/training-different-models](/mariammohamed/titanic/training-different-models)\n",
        "+ [/shivendra91/titanic/rolling-in-the-deep](/shivendra91/titanic/rolling-in-the-deep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "750a076c-9e20-ec28-d43a-a2458613c66e"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Modelling Algorithms\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\n",
        "\n",
        "# Modelling Helpers\n",
        "from sklearn.preprocessing import Imputer , Normalizer , scale\n",
        "# from sklearn.cross_validation import train_test_split , StratifiedKFold\n",
        "from sklearn.feature_selection import RFECV\n",
        "\n",
        "\n",
        "# Visualisation\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as pylab\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "mpl.style.use( 'ggplot' )\n",
        "sns.set_style( 'white' )\n",
        "pylab.rcParams[ 'figure.figsize' ] = 8 , 6\n",
        "\n",
        "# Helpers for plot\n",
        "def plot_histograms( df , variables , n_rows , n_cols ):\n",
        "    fig = plt.figure( figsize = ( 16 , 12 ) )\n",
        "    for i, var_name in enumerate( variables ):\n",
        "        ax=fig.add_subplot( n_rows , n_cols , i+1 )\n",
        "        df[ var_name ].hist( bins=10 , ax=ax )\n",
        "        ax.set_title( 'Skew: ' + str( round( float( df[ var_name ].skew() ) , ) ) ) # + ' ' + var_name ) #var_name+\" Distribution\")\n",
        "        ax.set_xticklabels( [] , visible=False )\n",
        "        ax.set_yticklabels( [] , visible=False )\n",
        "    fig.tight_layout()  # Improves appearance a bit.\n",
        "    plt.show()\n",
        "\n",
        "def plot_distribution( df , var , target , **kwargs ):\n",
        "    row = kwargs.get( 'row' , None )\n",
        "    col = kwargs.get( 'col' , None )\n",
        "    facet = sns.FacetGrid( df , hue=target , aspect=4 , row = row , col = col )\n",
        "    facet.map( sns.kdeplot , var , shade= True )\n",
        "    facet.set( xlim=( 0 , df[ var ].max() ) )\n",
        "    facet.add_legend()\n",
        "\n",
        "def plot_categories( df , cat , target , **kwargs ):\n",
        "    row = kwargs.get( 'row' , None )\n",
        "    col = kwargs.get( 'col' , None )\n",
        "    facet = sns.FacetGrid( df , row = row , col = col )\n",
        "    facet.map( sns.barplot , cat , target )\n",
        "    facet.add_legend()\n",
        "\n",
        "def plot_correlation_map( df ):\n",
        "    corr = df.corr()\n",
        "    _ , ax = plt.subplots( figsize =( 12 , 10 ) )\n",
        "    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n",
        "    _ = sns.heatmap(\n",
        "        corr, \n",
        "        cmap = cmap,\n",
        "        square=True, \n",
        "        cbar_kws={ 'shrink' : .9 }, \n",
        "        ax=ax, \n",
        "        annot = True, \n",
        "        annot_kws = { 'fontsize' : 12 }\n",
        "    )\n",
        "\n",
        "def describe_more( df ):\n",
        "    var = [] ; l = [] ; t = []\n",
        "    for x in df:\n",
        "        var.append( x )\n",
        "        l.append( len( pd.value_counts( df[ x ] ) ) )\n",
        "        t.append( df[ x ].dtypes )\n",
        "    levels = pd.DataFrame( { 'Variable' : var , 'Levels' : l , 'Datatype' : t } )\n",
        "    levels.sort_values( by = 'Levels' , inplace = True )\n",
        "    return levels\n",
        "\n",
        "def plot_variable_importance( X , y ):\n",
        "    tree = DecisionTreeClassifier( random_state = 99 )\n",
        "    tree.fit( X , y )\n",
        "    plot_model_var_imp( tree , X , y )\n",
        "    \n",
        "def plot_model_var_imp( model , X , y ):\n",
        "    imp = pd.DataFrame( \n",
        "        model.feature_importances_  , \n",
        "        columns = [ 'Importance' ] , \n",
        "        index = X.columns \n",
        "    )\n",
        "    imp = imp.sort_values( [ 'Importance' ] , ascending = True )\n",
        "    imp[ : 10 ].plot( kind = 'barh' )\n",
        "    print (model.score( X , y ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1057606d-dced-ab82-5c9e-2dfee10eb780"
      },
      "outputs": [],
      "source": [
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "print(check_output([\"head\", \"../input/train.csv\"]).decode(\"utf8\"))\n",
        "print(check_output([\"head\", \"../input/test.csv\"]).decode(\"utf8\"))\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "346f2850-68ad-bb7a-eca8-c45186b493af"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('../input/train.csv')\n",
        "# test data\n",
        "test_data = pd.read_csv('../input/test.csv')\n",
        "\n",
        "\n",
        "# let's have a look at the dataset\n",
        "#drop unnecessary columns\n",
        "#train_data.drop(['PassengerId', 'Ticket', 'Cabin', 'Name'], inplace=True, axis=1)\n",
        "train_data.drop(['PassengerId', 'Ticket', 'Cabin', 'Name'], inplace=True, axis=1)\n",
        "test_data.drop(['PassengerId', 'Ticket', 'Cabin', 'Name'], inplace=True, axis=1)\n",
        "\n",
        "# type of data structure\n",
        "# http://pandas.pydata.org/pandas-docs/stable/dsintro.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6cfcd8b0-6ce6-271a-7913-02f54a0720c9"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8c2301fe-f852-2f4d-97a0-15357f75f300"
      },
      "outputs": [],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f3feb363-dad2-5c8c-dc8a-3efdde0c4e4c"
      },
      "outputs": [],
      "source": [
        "train_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bb3a99c2-446f-3f1d-9786-7ee44f24e74b"
      },
      "outputs": [],
      "source": [
        "plt.hist(train_data['Pclass'], color='lightblue')\n",
        "plt.tick_params(top='off', bottom='on', left='off', right='off', labelleft='on', labelbottom='on')\n",
        "plt.xlim([0, 4])\n",
        "ax = plt.gca()\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['left'].set_visible(True)\n",
        "ax.spines['bottom'].set_visible(True)\n",
        "ax.set_xticks([1, 2, 3])\n",
        "plt.xlabel('Pclass')\n",
        "plt.ylabel('Count')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "071adf6d-f1c4-e6b5-1170-89822f6e82b7"
      },
      "outputs": [],
      "source": [
        "plot_correlation_map( train_data )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "15ef4df6-f990-296f-59b3-91f25add4941"
      },
      "outputs": [],
      "source": [
        "plot_distribution( train_data , var = 'Age' , target = 'Survived' , row = 'Sex' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "79bcec1d-eb82-f9c0-54a0-eb89257ce59f"
      },
      "outputs": [],
      "source": [
        "plot_categories( train_data , cat = 'Pclass' , target = 'Survived' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a46379b4-ae8e-9537-7316-46e4b39a8e3e"
      },
      "outputs": [],
      "source": [
        "plot_categories( train_data , cat = 'Sex' , target = 'Survived' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "14002205-bf41-bd49-dbfa-dbe414ee065c"
      },
      "outputs": [],
      "source": [
        "plot_categories( train_data , cat = 'Age' , target = 'Survived' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c4b96b6a-ab5a-de9e-a30e-4dcb0cc22862"
      },
      "outputs": [],
      "source": [
        "plot_categories( train_data , cat = 'SibSp' , target = 'Survived' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c0ee1ce4-0653-7091-22ac-bf1c77e5e887"
      },
      "outputs": [],
      "source": [
        "plot_categories( train_data , cat = 'Parch' , target = 'Survived' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "edb1cafb-9546-53c8-a465-b60cd4d53751"
      },
      "outputs": [],
      "source": [
        "plot_categories( train_data , cat = 'Fare' , target = 'Survived' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "50a5c0ee-28b9-d477-21e0-45a79a7022f3"
      },
      "outputs": [],
      "source": [
        "plot_categories( train_data , cat = 'Embarked' , target = 'Survived' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c0ae98fb-7396-f619-f133-f0d6e41d2d02"
      },
      "outputs": [],
      "source": [
        "# Transform Sex into binary values 0 and 1\n",
        "sex = pd.Series( np.where( train_data.Sex == 'male' , 1 , 0 ) , name = 'Sex' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6d549bf3-6e26-96bb-aef7-5f6aa26eb2da"
      },
      "outputs": [],
      "source": [
        "# Create a new variable for every unique value of Embarked\n",
        "embarked = pd.get_dummies( train_data.Embarked , prefix='Embarked' )\n",
        "embarked.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c4d00fc4-2976-741e-6984-5c038ca63f6d"
      },
      "outputs": [],
      "source": [
        "# Create a new variable for every unique value of Embarked\n",
        "pclass = pd.get_dummies( train_data.Pclass , prefix='Pclass' )\n",
        "pclass.head()"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}