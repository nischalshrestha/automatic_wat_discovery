{"cells":[{"metadata":{"_cell_guid":"94be1112-8853-41c5-b570-3ccacf8aed23","_uuid":"d6ba76d76665670335dbee54eb8c1b2e88ef408b"},"cell_type":"markdown","source":"# Tackling Titanic with basic Tensorflow\n\nIn this notebook, we're going to explore the data a bit, and try basic pandas and tensorflow to get the job done. It is meant for beginners, and should help those who're just getting started with kaggle and/or tensorflow.\n\n**What you can learn from it :**\n- How to read the data and do basic preprocessing required to use neural networks\n- Design a 2 layer Neural Network model yourself using tensorflow instead of using in built DNN classifier\n\n\n**What is NOT covered in this tutorial :**\n- Data visualization with lot of graphs and their observations\n- Comparison of different classifiers for the problem\n\nI'm myself trying to improve everyday. This is my first Kernel at Kaggle. Your feedback would be very appreciative. "},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"},"cell_type":"markdown","source":"# Read Data\n\nHere's what we'll do \n- Read data into csv files (train and test)\n- Print out a small summary of the data\n- Combine them into one dataset if we require later on\n- Find out how many examples of each class exist in the training data (check if skewed or not)\n- Find out how many features have null values\n- Fix null values for numerical features\n- Fix null values with some values for categorical features"},{"metadata":{"_cell_guid":"ae5a0f1e-38e7-4767-af5f-c9e92fb9c5c4","_uuid":"c271e9a42063b776cfa8def1fa3e6ca6aa6b9120"},"cell_type":"markdown","source":" ## Read data into csv files"},{"metadata":{"_cell_guid":"e0ce7063-5c8a-4ec9-8992-948db5ba8d6a","_uuid":"93acd5d867a147f567cdfe541ec2a23e61ba5daa","collapsed":true,"trusted":true},"cell_type":"code","source":"# Read data into csv files\ntrain_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\nprint(\"train_df shape : \",train_df.shape)\nprint(\"test_df shape : \",test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"82bd9ccf-90b7-4422-8088-e1e1888eec9c","_uuid":"1a7038bea44483e00d4dcfa224836cb2b05b2813"},"cell_type":"markdown","source":"## Print out summary of data"},{"metadata":{"_cell_guid":"889f4b2c-ffb0-4b05-b4db-e85ee5c165ea","_uuid":"ab9955211cbc36244805ff836d89cb855dd6f965","collapsed":true,"trusted":true},"cell_type":"code","source":"# Print small summary\nprint(\"A look at training data:\")\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eb5d8eb9-9078-492a-be00-0f38a17587ba","_uuid":"aa79c8fe2bf76d847a225a309376e5d319f72743","collapsed":true,"trusted":true},"cell_type":"code","source":"print(\"A look at testing data:\")\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"966d2a48-7482-49c8-b91e-ee95fe13b0bb","_uuid":"8566ea5c22cf69f11cdebb3ac6e64294edbc33d8"},"cell_type":"markdown","source":"> ***Obvious observation - 'Survived' column is missing in test_df***"},{"metadata":{"_cell_guid":"b1d199dc-275b-4c04-ba25-cfbcb2809113","_uuid":"a802e4a312c37870113f7a3fd4807626cb2d3856"},"cell_type":"markdown","source":"## Find out how many examples of each class in training data"},{"metadata":{"_cell_guid":"f3230aaa-c108-40d2-b676-9ae61a6d8e1f","_uuid":"0f6fca9063bce97ea6bc50641d95b7a0df63f694","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df.groupby('Survived')['PassengerId'].count()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6e844766-8978-496a-9150-a22cd9abbc4a","_uuid":"f28ac6e46794dd26115bc33e80c0c213ea736170"},"cell_type":"markdown","source":"**Observations** : \n1. 549+342 = 891. So no data in the training data is missing its class\n2. It's not such a skewed dataset "},{"metadata":{"_cell_guid":"1f22483a-a295-46dc-92a9-b4bd394fa92b","_uuid":"29b3dbe3c9634a6deafbcf75053ce36090d7f9c4"},"cell_type":"markdown","source":"## How many features have null values"},{"metadata":{"_cell_guid":"d05bcb46-97d6-4a92-927e-da962ceff85a","_uuid":"4c5230cacfd1e079cd3715c316a7e137c2623c9c","collapsed":true,"trusted":true},"cell_type":"code","source":"# What any does is return whether any element in a particular axis is true or not. So, it works for us in this case. For each column, it checks if any column has a NaN value or not.\ntrain_df.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"14d190bb-fb0e-42e7-9d5c-b3084acc0d02","_uuid":"dc4c59e61b2a027cb04a4d146efc12c8ceafcb3c"},"cell_type":"markdown","source":"**Age**, **Cabin** and **Embarked** are the only ones having NaN values. We gotta fix them. "},{"metadata":{"_cell_guid":"22303fa2-44a9-485b-8686-d2bf3e2ef220","_uuid":"6fceb74db0bbfa3cefbe5e48c7779ccdcf18df55","collapsed":true,"trusted":true},"cell_type":"code","source":"# How many NaN values of Age in train_df?\ntrain_df['Age'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"490e4b65-5097-4945-9750-7a2c235c48d9","_uuid":"e284bdfdd31ae0375b4a8e9007bb10e9aca3ccd8","collapsed":true,"trusted":true},"cell_type":"code","source":"# For Cabin\ntrain_df['Cabin'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"70fafbde-6498-491c-87a2-14338d9281fc","_uuid":"d13739d3a0195c4161fc35abfeaec97781b9dcae","collapsed":true,"trusted":true},"cell_type":"code","source":"# For Embarked\ntrain_df['Embarked'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"be973170-db43-4bde-b1ef-24435c379204","_uuid":"6ba65f2651f04590e63786ed9dee43c4de01e7a7"},"cell_type":"markdown","source":"## Fixing null / NaN values for each column one by one"},{"metadata":{"_cell_guid":"503fd234-a659-466f-91c1-70df5f831390","_uuid":"555646f8afe1ea5b4818cd43380133531a0ff75d"},"cell_type":"markdown","source":"### For embarked"},{"metadata":{"_cell_guid":"677dcd34-2364-4f53-ba78-e6969c3457e4","_uuid":"457cc7e18ed946947aecc3bfed80a2bf7b14018c","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df.groupby('Embarked')['PassengerId'].count()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6ce4f64c-0da5-4dff-a06d-cf2ddea5d1b2","_uuid":"663824d65d95834bf097b4324b8a6b03470cea3c"},"cell_type":"markdown","source":"We observed earlier that only 2 entries have NaN for Embarked. And here, we see there are only 3 possible values of Embarked - C, Q and S. Out of which, S has the most number. So, let's just assign the missing ones to S. "},{"metadata":{"_cell_guid":"44eeb547-f721-4da8-8e42-82271744e861","_uuid":"ddc0fe4242d146761c82b11e96097d64deb039d9","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df['Embarked'] = train_df['Embarked'].fillna('S')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1ab5994d-039d-482a-9a3c-dc73e68c5737","_uuid":"a4027c9ec404e9af75e37fd545ee67818f832da8"},"cell_type":"markdown","source":"Now, let's check again...."},{"metadata":{"_cell_guid":"8d70ea2d-cdb5-4bc9-b12f-66bfd98a8447","_uuid":"63872c657fbee0643ed9d63b20d63d3b1b465a39","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df.groupby('Embarked')['PassengerId'].count()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0d8f9d47-738c-4d56-9af2-0eceafea721a","_uuid":"575ecc7dc22997aad63e70c2f0d1514af3fbc5ba"},"cell_type":"markdown","source":"Perfect."},{"metadata":{"_cell_guid":"ea8a0bef-415f-45a5-ab7d-b6bbaec3a3c3","_uuid":"c279a1509f78b400cfc00bebe958a2d11285988d"},"cell_type":"markdown","source":"### For Age"},{"metadata":{"_cell_guid":"f234733f-5289-4116-ade3-708f634dac0d","_uuid":"1cea91351872a48c0a5ffd475561453a6f4fc693","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df.groupby('Age')['PassengerId'].count()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1f919afb-b2af-40ea-b5b3-c501a2db4909","_uuid":"e4204d5f0dd18533662995363f25f2781db5945e"},"cell_type":"markdown","source":"So, the first thing to note is, thie Age can be in decimals! So, it's more of a continuous variable than discrete one.\nI think it would make sense to fix the missing ones by filling them with the mean?"},{"metadata":{"_cell_guid":"6d9c7349-726a-4d23-b3e2-08fd9298dd37","_uuid":"7e891707df51253a5b369fe08c5c309c10b7e964","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df['Age'].mean()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2bda0a23-8ab0-463e-af4a-17f5270c4c5c","_uuid":"e5d7be7cc1facc520fff1d0ec7234a36f99173ee","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df['Age'] = train_df['Age'].fillna(train_df['Age'].mean())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"76b0606d-bd85-4aaa-98d1-ada3437a3e17","_uuid":"e7032f2754dc4ab7f689fa44408dd08e9f4e229a"},"cell_type":"markdown","source":"Now, let's check how many missing values remain."},{"metadata":{"_cell_guid":"2dc0d6ab-ea8f-4994-a76d-322f5501dcb7","_uuid":"41151b525ff7fdd0d7d1bd334f80f11ad3123191","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df['Age'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4e0f46b4-00e8-479b-adf2-0e00f166fcd1","_uuid":"d48d43305ee948afb201f2f8faeff4a9f704f2a4"},"cell_type":"markdown","source":"Perfect."},{"metadata":{"_cell_guid":"d04a3b1a-519d-4662-ba2e-dace1075bb36","_uuid":"8dfac3aceaa1a36a775b0e29701344930c1fd191"},"cell_type":"markdown","source":"### For Cabin"},{"metadata":{"_cell_guid":"7d9dce10-b813-468a-83bb-b835d3355af4","_uuid":"caef1b4f21c9b545459d1e8440820948d21ed47f","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df.groupby('Cabin')['PassengerId'].count()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f50f41c9-1085-4cb6-8a0e-74765ef698b2","_uuid":"cdf837ff32346220b59c0aa39bfa0e8095995716"},"cell_type":"markdown","source":"Okay, So : \n- This can be alphanumeric\n- 147 different vaulues exist for Cabin\n- None of them seem to be far far greater in number than others\n- A lot of values are actually missing - 687!\n\nSo, let's do one thing - Add a new 'Cabin' value as 'UNKNOWN' and fill the data with that"},{"metadata":{"_cell_guid":"06e5e7ae-dd88-46d3-94a3-4795d8be0921","_uuid":"422660b880279158ab3a454f19c5531ac9dc8344","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df['Cabin'] = train_df['Cabin'].fillna('UNKNOWN')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9d4c4c03-c860-437e-bf5d-1d542961fd6e","_uuid":"11a8856b34c9166e33dc846cef325f6810aa508d"},"cell_type":"markdown","source":"Check how many NaN now"},{"metadata":{"_cell_guid":"c0372aae-117e-4e0b-85ac-62d174e35ff9","_uuid":"fa493c886c93ea945c4c8a88a410872e6ece7ab6","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df['Cabin'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"248a6290-ca5b-4d93-88ff-42c47a9d9b4c","_uuid":"4f87fdfa05847920741c5b9fc40ec1bc1ee1ce2e"},"cell_type":"markdown","source":"Perfect."},{"metadata":{"_cell_guid":"7db9fa91-2589-4977-963f-527875a5f6f7","_uuid":"99f0d9422641f4579594db39392ba2fdd00c5632"},"cell_type":"markdown","source":"### All NaN values fixed"},{"metadata":{"_cell_guid":"75991fe7-e95b-480e-9998-21f20bcac50f","_uuid":"b80554750fd5d4e7bcf970e54b37f6a6cff57f58","collapsed":true,"trusted":true},"cell_type":"code","source":"# What any does is return whether any element in a particular axis is true or not. So, it works for us in this case. For each column, it checks if any column has a NaN value or not.\ntrain_df.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d003e687-cee2-4571-9017-977515df1d07","_uuid":"12fb48243010b8c0ccb02184660caaa9bf657dd7"},"cell_type":"markdown","source":"## Helper Methods we learnt from above\n\nWe'll use these for testing dataset, and maybe in future as well."},{"metadata":{"_cell_guid":"2037ae87-51da-442f-a5d7-6ac52f170008","_uuid":"1869bcc7c906c8d7ef73e0d1cb372e7eacbd0d53","collapsed":true,"trusted":true},"cell_type":"code","source":"def get_num_of_NaN_rows(df):\n    return df.isnull().sum()\n\ndef fill_NaN_values_for_numerical_column(df, colname):\n    df[colname] = df[colname].fillna(df[colname].mean())\n    return df\n\ndef fill_NaN_values_for_categorical_column(df, colname, value):\n    df[colname] = df[colname].fillna(value)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"06b9ae58-b56f-4897-90a3-c56d4e1913c9","_uuid":"6646f8e8ed41822e9962d0c59c7424ee486b3d85","collapsed":true,"trusted":true},"cell_type":"code","source":"# Let's test them on test data (which still might have missing rows!)\nnum_of_NaN_rows_of_test_set = get_num_of_NaN_rows(test_df)\nprint(\"num_of_NaN_rows_of_test_set : \",num_of_NaN_rows_of_test_set)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1e975c9a-96c6-4e90-b7a0-55f2707d9319","_uuid":"56df5eca27b763db884876730770aa89d33eaa99"},"cell_type":"markdown","source":"One chapter done. "},{"metadata":{"_cell_guid":"d170a225-e8a8-4408-a517-768e27a23c78","_uuid":"4e9ce88ff4cd005649539691b2b9f4b58a6821df"},"cell_type":"markdown","source":"# Preprocessing Data\n\n- Convert Categorical values to numerical ones\n- Divide train_df into train_df_X and train_df_y\n- One hot values"},{"metadata":{"_cell_guid":"7a4dc49b-7188-4856-a604-9f6346b5e630","_uuid":"05859c25be3cbfcc2a3e1ebeeae10ea6ce89624b"},"cell_type":"markdown","source":"### Convert Categorical values to numerical ones"},{"metadata":{"_cell_guid":"de9801a6-1d9a-41ba-a0f5-b65e97ca915d","_uuid":"de7b719dd5e364bac3596d5a015045a479d6824c"},"cell_type":"markdown","source":"**1. Find which columns are categorical**\n\nRef : https://stackoverflow.com/questions/29803093/check-which-columns-in-dataframe-are-categorical/29803290#29803290"},{"metadata":{"_cell_guid":"a588f113-a311-48cf-8fc7-52e792c050d4","_uuid":"57bdc5e7c89f4ff47a3ace399264e6ba517aa428","collapsed":true,"trusted":true},"cell_type":"code","source":"all_cols = train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9dd8ee78-4dc5-4272-9517-933cf1f1ead2","_uuid":"5d17ba74addd657890fddc9d4c6392a76ab6c3d4","collapsed":true,"trusted":true},"cell_type":"code","source":"numeric_cols = train_df._get_numeric_data().columns","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"56633f88-446c-400b-97d1-f4495c139eb9","_uuid":"0aae0e87028fa387ab4925c825025f514e36b1ba","collapsed":true,"trusted":true},"cell_type":"code","source":"categorical_cols = set(all_cols) - set(numeric_cols)\ncategorical_cols","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"12d0198e-e350-4529-bda3-ee8f0fed74b3","_uuid":"a8ba798afb2320a4635a0d3e7f5a43e6c72095ea","collapsed":true,"trusted":true},"cell_type":"code","source":"# Let's make a helper method from this now.\ndef find_categorical_columns(df):\n    all_cols = df.columns\n    numeric_cols = df._get_numeric_data().columns\n    return set(all_cols) - set(numeric_cols)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b6f1e030-d2b2-44a2-9947-68ec6f1a8023","_uuid":"109322e8ea2dda40357b72b536fcb8e1c9eaa0d9"},"cell_type":"markdown","source":"**2. Convert to numerical ones using get_dummies of Pandas**\n\nRef : http://fastml.com/converting-categorical-data-into-numbers-with-pandas-and-scikit-learn/"},{"metadata":{"_cell_guid":"e6ce3139-b340-456d-aa71-ec277a0a9dde","_uuid":"3074a2d8bbccf80caf4e0ce49f6cd540234950c8","collapsed":true,"trusted":true},"cell_type":"code","source":"# First, let's backup our train_df and test_df till now\ntrain_df_backup_filledna_still_having_categorical_data = train_df\ntrain_df_backup_filledna_still_having_categorical_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"18c6806b-9ee4-41d9-93e9-f72c52c6a734","_uuid":"f130afd68fb49254fde2c56caee2fd8fdd5d70e4","collapsed":true,"trusted":true},"cell_type":"code","source":"# Now, let's convert it.\ntrain_df_dummies = pd.get_dummies(train_df, columns=categorical_cols)\ntrain_df_dummies.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"874fc8c7-d181-4f9f-84ff-dbac2eee85ac","_uuid":"90e2bccb4ea509f590824b454c1ddb4cb5162712","collapsed":true,"trusted":true},"cell_type":"code","source":"# However, backup's shape is still \ntrain_df_backup_filledna_still_having_categorical_data.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"31b0a8aa-3f19-44a5-9ce6-077d77d6ee65","_uuid":"eac180edc84145662bd3ab8f17c5d83eed2ecaa7","collapsed":true,"trusted":true},"cell_type":"code","source":"# Let's check out data once\ntrain_df_dummies.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6e792fc1-68a5-473b-a1ae-f730cf6a03a7","_uuid":"0a4c6966ecccacc2c522510133bc58d2c3a03d65","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"12912989-070d-4530-8266-ba2665ba4b3d","_uuid":"fb300f6e35216545132444654716e9bfd9e4032f"},"cell_type":"markdown","source":"### Another way to convert Categorical columns data into numerical is assigning them integers\nRef : https://stackoverflow.com/questions/42215354/pandas-get-mapping-of-categories-to-integer-value"},{"metadata":{"_cell_guid":"0bfcfeb9-409c-426c-a4d4-85e750ca7ae5","_uuid":"1ef6827e56fa3df922e1486963fcdd68bd8d14ed","collapsed":true,"trusted":true},"cell_type":"code","source":"# 2nd way to convert is having integers represent different values of each categorical column\ntrain_df_numerical = train_df.copy()\nfor col in categorical_cols:\n    train_df_numerical[col] = train_df_numerical[col].astype('category')\n    train_df_numerical[col] = train_df_numerical[col].cat.codes\ntrain_df_numerical.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3245a0d2-d089-4aed-b371-17001230c88d","_uuid":"b0b99b54af0728512f0566aaf61a5d5b936f5a1a","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df_numerical.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e383941d-f0a6-4762-a822-7b44594ce64a","_uuid":"bfa0c2942508189d7e652cb1feb59928c18f4f48","collapsed":true,"trusted":true},"cell_type":"code","source":"# Let's make helper function here also\ndef convert_categorical_column_to_integer_values(df):\n    df_numerical = df.copy()\n    for col in find_categorical_columns(df):\n        df_numerical[col] = df_numerical[col].astype('category')\n        df_numerical[col] = df_numerical[col].cat.codes\n    return df_numerical","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"99a52e82-b995-4330-8c82-78a1fefb0411","_uuid":"a4ff661f428e97f1eb758e5f2ea7766862ffeb03"},"cell_type":"markdown","source":"*Perfect*.\n\nNow, we have all of these available for our use : \n\n* **train_df**                    : original training dataset   (891,12)\n* **train_df_dummies**  : training dataset with dummies (891, 1732)\n* **train_df_numerical** : training dataset with integers for categorical attributes (891,12) "},{"metadata":{"_cell_guid":"9f0d77ea-6a9a-46e5-a10f-ea2badd00121","_uuid":"92e693929151e0fe4655805d0a4965fbce207a40"},"cell_type":"markdown","source":"# Running a model in Tensorflow\n\nThis will again involve a set of steps\n- Get data converted to numpy arrays so tensorflow can read them\n- Write tensorflow model\n- Run a session of tensorflow model and check accuracy on training data set\n\nTry the above for both train_df_dummies and train_df_numerical"},{"metadata":{"_cell_guid":"50d50bcb-5c32-4585-a429-3f14d164c49f","_uuid":"ac48a581aa491924e8001676169755346c0eae71","collapsed":true,"trusted":true},"cell_type":"code","source":"# import tensorflow stuff...\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0b38e3db-1b4e-456c-8450-48ef492ce12f","_uuid":"6475152eeddb252d8857a6214e59b470eb727256","collapsed":true,"trusted":true},"cell_type":"code","source":"# Dividing data between X and Y\n# Ref : https://stackoverflow.com/questions/29763620/how-to-select-all-columns-except-one-column-in-pandas\n\ntrain_df_dummies_Y = train_df_dummies['Survived']\n# Don't worry. drop does not change the existing dataframe unless inplace=True is passed.\ntrain_df_dummies_X = train_df_dummies.drop('Survived', axis=1)\n\ntrain_df_numerical_X = train_df_numerical.drop('Survived', axis=1)\ntrain_df_numerical_Y = train_df_numerical['Survived']\n\nprint(\"train_df_numerical_X shape : \",train_df_numerical_X.shape)\nprint(\"train_df_numerical_Y shape : \",train_df_numerical_Y.shape)\nprint(\"train_df_dummies_X shape : \",train_df_dummies_X.shape)\nprint(\"train_df_dummies_Y shape : \",train_df_dummies_Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6162d69e-fa84-4f64-95ac-64c7c6acfc5d","_uuid":"ff0063289704a1d675371acf68409992acc4d7f3"},"cell_type":"markdown","source":"### Converting to numpy arrays so tensorflow variables can pick it up"},{"metadata":{"_cell_guid":"77ee5b0b-829f-42b8-a21d-162ce1dc496c","_uuid":"f0aeadac660453bcdcd3a105ad8530c2e5defc99","collapsed":true,"trusted":true},"cell_type":"code","source":"trainX_num = train_df_numerical_X.as_matrix()\ntrainY_num = train_df_numerical_Y.as_matrix()\n\ntrainX_dummies = train_df_dummies_X.as_matrix()\ntrainY_dummies = train_df_dummies_Y.as_matrix()\n\nprint(\"trainX_num.shape = \",trainX_num.shape)\nprint(\"trainY_num.shape = \",trainY_num.shape)\nprint(\"trainX_dummies.shape = \",trainX_dummies.shape)\nprint(\"trainY_dummies.shape = \",trainY_dummies.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ebbdeaf2-5d0a-4e06-ba0f-d57ccf17e73b","_uuid":"71455c6a3d9bb3efac4105f164fcb31dc9e8e556","collapsed":true,"trusted":true},"cell_type":"code","source":"# Reshaping the rank 1 arrays formed to proper 2 dimensions\ntrainY_num = trainY_num[:,np.newaxis]\ntrainY_dummies = trainY_dummies[:,np.newaxis]\n\nprint(\"trainX_num.shape = \",trainX_num.shape)\nprint(\"trainY_num.shape = \",trainY_num.shape)\nprint(\"trainX_dummies.shape = \",trainX_dummies.shape)\nprint(\"trainY_dummies.shape = \",trainY_dummies.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9a6eb8a6-4c9e-44fa-9997-90f5606e2619","_uuid":"bb97c7a4cd92eb2b9bcc6a9863fca1e97e80b17d"},"cell_type":"markdown","source":"### Tensorflow Model\n\nNow, let's build our model. \nWe could use existing DNN classifier. But instead, we're gonna build this one with calculations ourselves.\n2 layers. Hence, W1, b1, W2, b2 as parameters representing weights and biases to layer 1 and layer 2 respectively. \n\nWe'll use RELU as our activation function for first layer. Why? Because it performs better in general.\nAnd sigmoid for the 2nd layer. Since output is going to be a binary classification, it makes sense to use sigmoid."},{"metadata":{"_cell_guid":"945171b7-3737-4cc7-9d80-5d9f054cf146","_uuid":"510a17c7bac58a2e8c6fe8db0632b941e3680ffe","collapsed":true,"trusted":true},"cell_type":"code","source":"### Tensorflow model\ndef model(learning_rate, X_arg, Y_arg, num_of_epochs):\n    # 1. Placeholders to hold data\n    X = tf.placeholder(tf.float32, [11,None])\n    Y = tf.placeholder(tf.float32, [1, None])\n\n    # 2. Model. 2 layers NN. So, W1, b1, W2, b2.\n    # This is basically coding forward propagation formulaes\n    W1 = tf.Variable(tf.random_normal((20,11)))\n    b1 = tf.Variable(tf.zeros((20,1)))\n    Z1 = tf.matmul(W1,X) + b1             # This is also called logits in tensorflow terms\n    A1 = tf.nn.relu(Z1)\n\n    W2 = tf.Variable(tf.random_normal((1, 20)))\n    b2 = tf.Variable(tf.zeros((1,1)))\n    Z2 = tf.matmul(W2,A1) + b2\n    A2 = tf.nn.sigmoid(Z2)\n\n    # 3. Calculate cost\n    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=Z2, labels=Y)\n    cost_mean = tf.reduce_mean(cost)\n\n    # 4. Optimizer (Gradient Descent / AdamOptimizer ) - Using this line, tensorflow automatically does backpropagation\n    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost_mean)\n    \n    # 5. initialize variabls\n    session = tf.Session()\n    tf.set_random_seed(1)\n    init = tf.global_variables_initializer()\n    session.run(init)\n    \n    # 6. Actual loop where learning happens\n    for i in range(num_of_epochs):\n        _, cost_mean_val = session.run([optimizer, cost_mean], feed_dict={X:X_arg, Y:Y_arg})\n        if i % 100 == 0:\n            print(\"i : \",i,\", cost : \",cost_mean_val)\n            \n    return session.run([W1,b1,W2,b2,A2,Y],feed_dict={X:X_arg, Y:Y_arg})","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"def67d5f-fcfd-45bd-b4bb-0e2575b6d787","_uuid":"108c40bde0fe872da823f000f9568ac959687e77","collapsed":true,"trusted":true},"cell_type":"code","source":"W1_tr,b1_tr,W2_tr,b2_tr,A2,Y = model(0.01, trainX_num.T, trainY_num.T, 3000)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e6bd600c-8faf-4982-a48a-7b7f97280cd3","_uuid":"5342004533241f23a260a21d39ec757bcceda874","collapsed":true,"trusted":true},"cell_type":"code","source":"# Validating that our formulaes were correct by checking shapes of ouput prediction\nA2.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ec9bc3f8-ea91-4cae-a5f5-decd5745a2cb","_uuid":"5ab614f0bb50ca3ca8373cc839b475d7bcd6eb25","collapsed":true,"trusted":true},"cell_type":"code","source":"Y.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"46fae9fa-f9ff-453b-824e-fa8e468e035c","_uuid":"946213023625b02d635fe3d953efc0e9bdbdcb6f","collapsed":true,"trusted":true},"cell_type":"code","source":"# Let's see the predictions variable\nA2[:,0:5]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a36cb857-1c47-42d9-811d-62377f88e8f9","_uuid":"5f299e26988322bb2100f7dcfd56678d2f0ba989"},"cell_type":"markdown","source":"**As we see, our predictions array isn't 0s or 1s. So, we must convert it to 0s / 1s. **"},{"metadata":{"_cell_guid":"095c8328-db5c-403b-a6f2-0ca5a82eeaff","_uuid":"3925356e326d4c1f0290f063f389420c9a4138b4","collapsed":true,"trusted":true},"cell_type":"code","source":"A2_bool = A2 > 0.5\nY_prediction_training = A2_bool.astype(int)\nY_int = Y.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"304034f8-912c-48e6-a609-e4d97ccd7cb3","_uuid":"66e3d20d1ef485524f453fdae28b623797fbe9c8","collapsed":true,"trusted":true},"cell_type":"code","source":"Y_int","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d5d55c08-39ce-47f8-8119-e0c52e09f505","_uuid":"ccf93485ec714a28e72256091e115c12d4557dc4","collapsed":true,"trusted":true},"cell_type":"code","source":"Y_prediction_training","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dbd494aa-be4c-4765-bf33-8a9280da2f50","_uuid":"8c78b9abc22f6805d03195ee44962f2012ad9793","collapsed":true,"trusted":true},"cell_type":"code","source":"accuracy = (Y_prediction_training == Y_int).mean()\naccuracy","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bd4624eb-5c9d-4fbe-b1c5-bc1da03f3394","_uuid":"46c0e766df485a688181fa27e2e30d41c3247a68"},"cell_type":"markdown","source":"### Awesome\n\n81.48% accuracy isn't bad on training dataset. That too, with just 3000 epochs!\n\nPeople got near 85% with 40000 epochs. So, it's fine. This is good enough.\n"},{"metadata":{"_cell_guid":"088f830e-6750-4458-935f-e551a8d7903a","_uuid":"458dd029f8623870e0a0682c2d924f9f1da8fe7f","collapsed":true,"trusted":true},"cell_type":"code","source":"# First, let's list our helper functions we could make from logic used above.\ndef convert_sigmoid_output_to_boolean_array(array, threshold):\n    array = array > threshold\n    return array\n\ndef convert_boolean_array_to_binary_array(array):\n    array_binary = array.astype(int)\n    return array_binary","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c44db26c-5bdf-430c-af0d-080a7971d90c","_uuid":"fb614c70877b5f3ce45d61841480d89772250f45"},"cell_type":"markdown","source":"* **Let's try now with dummies (one-hot vectors) data.**\n\nThis is the time. Let's generalize the model we wrote above to take more arguments and not be specific to shapes of our X or Y.\nAlso, let's now print the training accuracy in the model itself with the cost at each 100th epoch!"},{"metadata":{"_cell_guid":"7f4c3853-c9ca-4a5e-b9b8-4a06fdf8a8c3","_uuid":"dfdadd2396db77a905b9e10595000ebbae8e9fa0","collapsed":true,"trusted":true},"cell_type":"code","source":"### Tensorflow model\ndef model_generic(learning_rate, X_arg, Y_arg, num_of_epochs, hidden_units, threshold):\n    # 1. Placeholders to hold data\n    X = tf.placeholder(tf.float32, [X_arg.shape[0],None])\n    Y = tf.placeholder(tf.float32, [1, None])\n\n    # 2. Model. 2 layers NN. So, W1, b1, W2, b2.\n    # This is basically coding forward propagation formulaes\n    W1 = tf.Variable(tf.random_normal((hidden_units,X_arg.shape[0])))\n    b1 = tf.Variable(tf.zeros((hidden_units,1)))\n    Z1 = tf.matmul(W1,X) + b1\n    A1 = tf.nn.relu(Z1)\n\n    W2 = tf.Variable(tf.random_normal((1, hidden_units)))\n    b2 = tf.Variable(tf.zeros((1,1)))\n    Z2 = tf.matmul(W2,A1) + b2\n    A2 = tf.nn.sigmoid(Z2)\n\n    # 3. Calculate cost\n    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=Z2, labels=Y)\n    cost_mean = tf.reduce_mean(cost)\n\n    # 4. Optimizer (Gradient Descent / AdamOptimizer ) - Using this line, tensorflow automatically does backpropagation\n    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost_mean)\n    \n    # 5. Accuracy methods\n    predicted_class = tf.greater(A2,threshold)\n    prediction_arr = tf.equal(predicted_class, tf.equal(Y,1.0))\n    accuracy = tf.reduce_mean(tf.cast(prediction_arr, tf.float32))\n    \n    # 5. initialize variabls\n    session = tf.Session()\n    tf.set_random_seed(1)\n    init = tf.global_variables_initializer()\n    session.run(init)\n    \n    # 6. Actual loop where learning happens\n    for i in range(num_of_epochs):\n        _, cost_mean_val, accuracy_val = session.run([optimizer, cost_mean, accuracy], feed_dict={X:X_arg, Y:Y_arg})\n        if i % 100 == 0:\n            print(\"i:\",i,\", cost : \",cost_mean_val,\", training accuracy : \",accuracy_val)\n            \n    return session.run([W1,b1,W2,b2,A2,Y,accuracy],feed_dict={X:X_arg, Y:Y_arg})","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"afa7a982-45a4-4be2-8d32-61aff199831a","_uuid":"db2029eb89368b236cbf6b55b89e6244cd383bb7","collapsed":true,"trusted":true},"cell_type":"code","source":"W1_dum,b1_dum,W2_dum,b2_dum,A2_dummies,Y_dummies,training_accuracy_val = model_generic(0.005, trainX_num.T, trainY_num.T, 3000, 100,0.5)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"758ae1a7-5f87-487c-ad8e-f0a5a24684d8","_uuid":"7fae0f2bdd7566ec05cef49449e3dd849e4feeda","collapsed":true,"trusted":true},"cell_type":"code","source":"    training_accuracy_val","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"07c54abc-a6e5-46c1-8e2d-995f38fdd333","_uuid":"bd38ff125de91f524217ebe0ca7bb48bec3936e3"},"cell_type":"markdown","source":"So, for when we use dummies data, accuracy goes up and down, and after 3000 epochs is somewhere near 85.52%. This is good only! "},{"metadata":{"_cell_guid":"e9fc019d-fac7-4f7b-97d7-0ddcb8054209","_uuid":"044349742f1dd1b05439e3facbaed36f28189c66"},"cell_type":"markdown","source":"# Prediction on Test Data\n\nLet's use 'numerical' vector  data only now.\n- Converting test data in the same form\n- Pass it through the network to get the value of A2\n- Concatenate this with the data and write that into csv\n- Submit the csv"},{"metadata":{"_cell_guid":"ecaab17b-0ec5-417b-bfc4-7b06d612fbba","_uuid":"ee02bda7bfc74c67424bc809fac22882569d2aa0","collapsed":true,"trusted":true},"cell_type":"code","source":"test_df","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2cd38d20-6b31-43ec-a813-59780206442a","_uuid":"5566bdcdc694176854ec0754e9ce3aae4230df92","collapsed":true,"trusted":true},"cell_type":"code","source":"test_df.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3574ca83-ecc3-4902-b813-4e50dd99cb25","_uuid":"de5924a5250e35b7cb8e3339c0e7cfe6cbc957c6","collapsed":true,"trusted":true},"cell_type":"code","source":"test_df['Age'] = test_df['Age'].fillna(test_df['Age'].mean())\ntest_df['Fare'] = test_df['Fare'].fillna(test_df['Fare'].mean())\ntest_df['Cabin'] = test_df['Cabin'].fillna('UNKNOWN')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2653ba68-e862-422a-8dc5-6cb8491a2e39","_uuid":"58f8b29466bd7462ef68231abb9c8a4f2402020f","collapsed":true,"trusted":true},"cell_type":"code","source":"test_df.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6a8420c2-e80a-40e2-b853-7fd8b2f3937a","_uuid":"c10aa1355d89b8f838f92a035919643c78ed1f5d","collapsed":true,"trusted":true},"cell_type":"code","source":"# Converting to numerical data\ntest_df_numerical = test_df.copy()\nfor col in categorical_cols:\n    test_df_numerical[col] = test_df_numerical[col].astype('category')\n    test_df_numerical[col] = test_df_numerical[col].cat.codes\ntest_df_numerical.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fb614986-eb50-4978-9a0c-48093bbc52fd","_uuid":"58c1b2bd793bb937da91c062c6ff73fb9f1722e3","collapsed":true,"trusted":true},"cell_type":"code","source":"test_df_numerical.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"34485ef8-4b81-4063-8dd7-d6aae80b0255","_uuid":"1ec0994a48dcd7509dbaa26d1ae98596e8938794","collapsed":true,"trusted":true},"cell_type":"code","source":"import math\n# Ref : https://stackoverflow.com/questions/32109319/how-to-implement-the-relu-function-in-numpy\n# Ref : https://stackoverflow.com/questions/3985619/how-to-calculate-a-logistic-sigmoid-function-in-python\ndef predict(W1,b1,W2,b2,X):\n    \n    Z1 = np.dot(W1,X) + b1\n    A1 = np.maximum(Z1, 0, Z1)\n    \n    Z2 = np.dot(W2,A1) + b2\n    A2 = 1 / (1 + np.exp(-Z2))\n    return A2","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cac735aa-b3d8-427c-91b0-6790d1aaaa09","_uuid":"b2da5f548439c867c9d86c3fa25ddd8e4636a5c2","collapsed":true,"trusted":true},"cell_type":"code","source":"# Let's predict\nX_test = test_df_numerical.as_matrix()\nX_test.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9c1501b6-a205-4554-af93-fd6236fb63f0","_uuid":"25dce3714aae8053480baa90d0e5255e039591d4","collapsed":true,"trusted":true},"cell_type":"code","source":"W1_tr.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"444e923c-53c0-4056-beb3-9c85eadbdc3f","_uuid":"1ffcee8fb44ce9139824a923be8c5122c84cf072","collapsed":true,"trusted":true},"cell_type":"code","source":"W2_tr.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"52bfb483-4ba2-44fb-baff-a159abeb1931","_uuid":"5eb489f7f6335574d6cd6229fef95df5c9fdfb6c","collapsed":true,"trusted":true},"cell_type":"code","source":"final_prediction = predict(W1_tr,b1_tr,W2_tr,b2_tr,X_test.T)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"73f86075-3aa0-49e3-afa1-044450d26cda","_uuid":"9e606456b38d8fbab46e590af9e14fc2ba03ef78","collapsed":true,"trusted":true},"cell_type":"code","source":"final_prediction_int = final_prediction > 0.5\nfinal_prediction_int = final_prediction_int.astype(int)\nfinal_prediction_int.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"370872ce-9c70-4a9d-b0ec-0fbc21b8b890","_uuid":"199641f87a01b28d16c5069792188da78a9f0951","collapsed":true,"trusted":true},"cell_type":"code","source":"final_survived_df = pd.DataFrame(data=final_prediction_int.T, columns=['Survived'])\nfinal_survived_df","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f11d65ad-3581-4822-8346-e7084641f146","_uuid":"616342cde8d2b6ae60c2301c50b0cd5da3af06e4","collapsed":true,"trusted":true},"cell_type":"code","source":"test_df['PassengerId']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f5789fba-4ffd-4975-8408-229da26e5927","_uuid":"736363528b2c36ce7355a5f6a9f0851ee75c4922","collapsed":true,"trusted":true},"cell_type":"code","source":"final_df = pd.concat([test_df['PassengerId'], final_survived_df], axis=1)\nfinal_df","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6bf29a84-c5fe-4edc-a6fd-068024f3b3c5","_uuid":"81012d55e9c5d8e2fa9822b8e0e7b4c591713714","collapsed":true,"trusted":true},"cell_type":"code","source":"# Exporting to a csv file\nfinal_df.to_csv(\"output-prediction.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f1d30d20-1f2a-4bc7-be1d-42abdfe323b5","_uuid":"507f197af9b5acfc42f8eff9acf7ef78871d5a76"},"cell_type":"markdown","source":"# One function to sum the whole notebook\n\nNow that we've reached here, we would want to execute the same notebook for different values of hyperparameters - to see how well our ouput csv file does on the leaderboard, and if we can improve our position. \nFor this, I've tried to utilize the helper functions we kept writing above and made one method which does everything from loading data, to fixing null values, to evaluating the model and then predicting and outputing a csv file. \nUltimately, you could just call this method with a range of hyperparameters, and let it do its magic. I'm gonna do the same on a "},{"metadata":{"_cell_guid":"5275e6b5-4fe7-47dc-8973-3f29c01b412b","_uuid":"52c73ea34b13f3d491fc63be9d7e7c7f63e32c49","collapsed":true,"trusted":true},"cell_type":"code","source":"# helper exercise which does the whole thing for any training dataframe given \ndef execute_steps_for_titanic(columns_to_use, output_file_name, learning_rate=0.01, num_of_epochs=3000, hidden_units=50, threshold_for_output=0.5, ):\n    # read data\n    training_df_orig = pd.read_csv(\"../input/train.csv\")\n    testing_df_orig = pd.read_csv(\"../input/test.csv\")\n    # get X and Y separated\n    train_df_Y = training_df_orig['Survived']\n    train_df_X = training_df_orig[columns_to_use]\n    test_df_X = testing_df_orig[columns_to_use]\n    # fix missing data\n    categorical_columns = find_categorical_columns(train_df_X)\n    replace_values_dict = {'Embarked':'S', 'Cabin':'UNKNOWN'}\n    for col in columns_to_use:\n        num_of_NaN_rows = get_num_of_NaN_rows(train_df_X)[col]\n        num_of_NaN_rows_test = get_num_of_NaN_rows(test_df_X)[col]\n        if(num_of_NaN_rows > 0):\n            print(\"Filling NaN values for column:\",col)\n            if col not in categorical_columns:\n                train_df_X[col] = train_df_X[col].fillna(train_df_X[col].mean())\n            else:\n                train_df_X[col] = train_df_X[col].fillna(replace_values_dict[col])\n        if(num_of_NaN_rows_test > 0):\n            print(\"Filling NaN values for column:\",col,\" in test data\")\n            if col not in categorical_columns:\n                test_df_X[col] = test_df_X[col].fillna(test_df_X[col].mean())\n            else:\n                test_df_X[col] = test_df_X[col].fillna(replace_values_dict[col])\n    print(\"Fixed NaN values in training and testing data.\")\n    # convert categorical to numerical data\n    train_df_X_num = convert_categorical_column_to_integer_values(train_df_X)\n    test_df_X_num = convert_categorical_column_to_integer_values(test_df_X)\n    # Get numpy arrays for this data\n    train_X = train_df_X_num.as_matrix()\n    test_X = test_df_X_num.as_matrix()\n    train_Y = train_df_Y.as_matrix()\n    # fix rank-1 array created\n    train_Y = train_Y[:,np.newaxis]\n    # call model and get values \n    W1,b1,W2,b2,A2,Y,final_tr_accuracy = model_generic(learning_rate, train_X.T, train_Y.T, num_of_epochs, hidden_units, threshold_for_output)\n    print(\"Final training accuracy : \",final_tr_accuracy)\n    # get prediction and save it to output file\n    prediction = predict(W1,b1,W2,b2,test_X.T)\n    # if prediction value > threshold, then set as True, else as False\n    prediction = prediction > threshold_for_output\n    # Convert the True/False array to a 0 , 1 array\n    prediction = prediction.astype(int)\n    # Convert back to dataframe and give the column name as 'Survived'\n    prediction_df = pd.DataFrame(data=prediction.T, columns=['Survived'])\n    # Make a final data frame of the required output and output to csv\n    final_df = pd.concat([testing_df_orig['PassengerId'], prediction_df], axis=1)\n    final_df.to_csv(output_file_name+\"_tr_acc_\"+\"{0:.2f}\".format(final_tr_accuracy)+\"_prediction.csv\", index=False)\n    print(\"Done.\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d7c05f41-ed53-4f93-b924-0fced7a33e56","_uuid":"1d99258af8e9788593cdd214da3d2d08d0d9ff8e","collapsed":true,"trusted":true},"cell_type":"code","source":"# Let's try this once?\n# All this while, we kept including Name and PassengerId as 2 important columns however in real life, they actually don't really matter in deciding whether a person would live or not. \n# So, now let's check without them.\ncolumns_to_use = ['Pclass','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked']\nexecute_steps_for_titanic(columns_to_use, \"bhavul\", learning_rate=0.005, num_of_epochs=5000, hidden_units=30, threshold_for_output=0.5)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"62e111d1-67e4-43d4-9ca3-9cb155ca95b4","_uuid":"b553a180e6f3d5791d3bfd057c2135ca04e1efcb","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}