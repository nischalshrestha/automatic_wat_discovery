{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "44177293-392a-34bf-2b38-0af9ef2b43fe"
      },
      "source": [
        "This is my exploration through the Titanic survival data. This is my first Kraggle Kernal and Competition as well. I am fairly new to Machine learning and Data Science, so my Main goal is to better my process and understanding.  \n",
        "\n",
        "Lots of inspiration of this Kernal came from the following Kernals.\n",
        "\n",
        "https://www.kaggle.com/omarelgabry/titanic/a-journey-through-titanic\n",
        " \n",
        "https://www.kaggle.com/oysteijo/titanic/titanic-passenger-survival"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "34db8359-160f-e467-6d2e-ceab8fc01cdb"
      },
      "source": [
        "**Importing Statements and Loading the Data**\n",
        "\n",
        "Nothing to special at this moment, just loading in the Data into a Dataframe, which should help exploring the data a little easier. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a4a8c563-619b-20e5-2739-46eb7d95ff3e"
      },
      "outputs": [],
      "source": [
        "#import Statements:\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from pandas import Series,DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# loading the train & test csv files as a DataFrame\n",
        "train_df = pd.read_csv(\"../input/train.csv\", dtype={\"Age\": np.float64}, )\n",
        "test_df    = pd.read_csv(\"../input/test.csv\", dtype={\"Age\": np.float64}, )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "36b2142b-89e8-3ff7-d8a2-0a9c178f3bf1"
      },
      "source": [
        "To Start out, I just want to explore the data and get it to a point where I can run it to get a baseline. Not really exploring the features to much. Feature creation and exploration I have planned for later. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bdd8d05e-c52e-f8b9-0de5-20c773b4065a"
      },
      "outputs": [],
      "source": [
        "# Looking at info of the data sets\n",
        "train_df.info()\n",
        "print(\"----------------------------\")\n",
        "test_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6e468e96-cdef-8d43-2a33-6d8e99eecc21"
      },
      "source": [
        "From the Information above, it seems to get the data to a \"Usable\" state \n",
        "we will have to get rid or fill in all the null values.  Then we will have to convert all Text based set into numerical data. \n",
        "\n",
        "To start lets first work on fill in the null values.  I like to start with the easiest things first. It looks like Embarked on has two missing values in the training set, so  I will start there. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "577c4fbb-7104-e0aa-fcad-c5d3066f81b8"
      },
      "outputs": [],
      "source": [
        "#Embarked\n",
        "sns.countplot(x=\"Embarked\", data=train_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "22678b6c-8053-e666-b84d-a96234df5b33"
      },
      "source": [
        "With the majority of people starting their journey from \"S\". I think it is safe to say we can fill in the the two Null values with \"S\" as well.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3ce969f7-f12c-6ad5-3876-ec2898eb9735"
      },
      "outputs": [],
      "source": [
        "train_df['Embarked'] = train_df['Embarked'].fillna(value='S')\n",
        "train_df.info()\n",
        "print(\"----------------------------\")\n",
        "test_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3fc86267-0b1a-c009-41ca-5b82a066c258"
      },
      "source": [
        "Next step, Cabin. Cabin seems to have some many null values both in the training and testing test, I think the best plan of action it to just drop it from the data sets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "008a8eca-3e0c-aa2d-86ac-233395550f28"
      },
      "outputs": [],
      "source": [
        "#Cabin\n",
        "train_df = train_df.drop(['Cabin'], axis=1)\n",
        "test_df = test_df.drop(['Cabin'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "602ac4d0-1a8b-56a9-16f4-d33465587532"
      },
      "source": [
        "Next  is Fare,  for Fare there is one missing value in the testing set, so lets add that in. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a7a8ed83-f1e0-e357-0396-1b2b71bcc2fd"
      },
      "outputs": [],
      "source": [
        "#Fare\n",
        "fare_Plot = test_df['Fare'].dropna(axis = 0)\n",
        "fare_Plot=fare_Plot.astype(int)\n",
        "sns.distplot(fare_Plot , bins= 20)\n",
        "median_Fare = test_df['Fare'].median()\n",
        "print (median_Fare)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "21bf3a0d-2e87-706e-e775-2a4efb39ee18"
      },
      "source": [
        "It seems looking at the graph and numbers it is okay to fill in the Null value with the median fare. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c6f7fe8b-0f24-a453-3bb8-9cc03ba0811b"
      },
      "outputs": [],
      "source": [
        "#Fare\n",
        "test_df['Fare'] = test_df['Fare'].fillna(value=median_Fare)\n",
        "\n",
        "train_df.info()\n",
        "print(\"----------------------------\")\n",
        "test_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "434b82e7-c6fd-9a58-9f8d-5fd2e3322230"
      },
      "source": [
        "To fill in the values of age I will be taking a simple route and adding random ages to the test set between the 1st standard deviation, but before I do this I am wondering if there is at large difference in mean and deviation  between people who survived and people who didn't, so let look into that below. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e8b20ba3-7941-8560-d47d-1a768fb4728c"
      },
      "outputs": [],
      "source": [
        "# Age\n",
        "#Looking at the data\n",
        "age_plot = train_df.loc[train_df['Survived'] == 0, 'Age'].dropna(axis = 0)\n",
        "age_plot_survived = train_df.loc[train_df['Survived'] == 1, 'Age'].dropna(axis = 0)\n",
        "age_STD = age_plot.std()\n",
        "age_mean = age_plot.mean()\n",
        "age_median = age_plot.median()\n",
        "print (age_STD)\n",
        "print (age_mean)\n",
        "print ('-------------------')\n",
        "age_STD_survived = age_plot_survived.std()\n",
        "age_mean_survived = age_plot_survived.mean()\n",
        "age_median_survived = age_plot_survived.median()\n",
        "print (age_STD_survived)\n",
        "print (age_mean_survived)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9177482f-c06a-2b1d-1eb7-5fb21e0e58fa"
      },
      "source": [
        "From above it seem there isn't to much difference so I will just fill in the data not caring if they have survived or not. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "74025344-bf68-6505-220a-3b85e62ffe79"
      },
      "outputs": [],
      "source": [
        "#Age\n",
        "#Filling in the data.\n",
        "train_null= train_df.loc[train_df['Age'].isnull() == True]\n",
        "test_null= test_df.loc[test_df['Age'].isnull() == True]\n",
        "train_index = train_null['Age'].index.tolist()\n",
        "test_index = test_null['Age'].index.tolist()\n",
        "min_age_range = age_mean - age_STD\n",
        "min_age_range=int(min_age_range)\n",
        "max_age_range = age_mean + age_STD\n",
        "max_age_range = int(max_age_range)\n",
        "\n",
        "train_filler =np.random.randint(min_age_range, high=max_age_range, size=len(train_null))\n",
        "test_filler = np.random.randint(min_age_range, high=max_age_range, size=len(test_null))\n",
        "\n",
        "train_Replace = pd.Series(train_filler, index=train_index)\n",
        "train_df['Age']= train_df['Age'].fillna(train_Replace)\n",
        "\n",
        "test_Replace = pd.Series(test_filler, index=test_index)\n",
        "test_df['Age']= test_df['Age'].fillna(test_Replace)\n",
        "\n",
        "train_df.info()\n",
        "print(\"----------------------------\")\n",
        "test_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f625c262-1e1d-10e6-d3cb-88ef51b42a1b"
      },
      "source": [
        "Almost there! To make the model runn-able. I will now covert all the categorical data into process-able data for the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "622adc9d-25a8-f312-4417-2b98248eb4db"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(train_df['Sex'])\n",
        "print(list(le.classes_))\n",
        "train_df['Sex']=le.transform(train_df['Sex'])\n",
        "\n",
        "le.fit(test_df['Sex'])\n",
        "test_df['Sex']=le.transform(test_df['Sex'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1f994e71-0342-e754-10da-f643536c3f28"
      },
      "source": [
        "Improvement #1\n",
        "From just looking at how well the the classifiers predicts the training data, my guess is that it is over-fitting a bit to the training data. I am going to implement cross validation so I can help keep an eye out for this.  \n",
        "\n",
        "Also at the same time  I will dive into each feature to see what feature is valid.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c0f68213-0fa2-b2ea-a515-d7154635a4b0"
      },
      "outputs": [],
      "source": [
        "#Passenger\n",
        "fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
        "sns.distplot(train_df.loc[train_df['Survived'] == 0, 'PassengerId'] , bins= 20, ax=ax1)\n",
        "sns.distplot(train_df.loc[train_df['Survived'] == 1, 'PassengerId'] , bins= 20, ax=ax2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d284590a-c1e6-f240-1470-5dd08e6c72fc"
      },
      "outputs": [],
      "source": [
        "#Embarked\n",
        "fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
        "sns.countplot(x=\"Embarked\", hue='Survived', data=train_df, ax = ax1)\n",
        "sns.countplot(x=\"Embarked\", hue='Sex', data=train_df, ax = ax2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3733543b-0a44-cc72-55e9-229ef157755b"
      },
      "source": [
        "From the above data and Graphs, I believe Passenger ID and Embarked, don't provide useful information to learn off of. So I will drop them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7dad5e7e-f804-6b87-13d3-04f05a32ac54"
      },
      "outputs": [],
      "source": [
        "#Ticket\n",
        "plot_df = train_df\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(plot_df['Ticket'])\n",
        "plot_df['Ticket'] = le.transform(plot_df['Ticket'])\n",
        "    \n",
        "count_plot = train_df['Ticket'].value_counts().head(20)\n",
        "count_plot_index=count_plot.index.tolist()\n",
        "\n",
        "ticket_count=[]\n",
        "survived_count=[]\n",
        "WC_count=[]\n",
        "for x in range(0, len(count_plot_index)):\n",
        "    new_ticket_count = 0\n",
        "    new_survived_count = 0\n",
        "    new_WC_count = 0\n",
        "    for y in range(0,len(train_df['Ticket'])):\n",
        "        if train_df['Ticket'][y]== count_plot_index[x]:\n",
        "            new_ticket_count =new_ticket_count+1\n",
        "            if (train_df['Age'][y]<16) or (train_df['Sex'][y]==0):\n",
        "                new_WC_count = new_WC_count+ 1\n",
        "            if train_df['Survived'][y]== 1:\n",
        "                new_survived_count = new_survived_count+1\n",
        "                \n",
        "    ticket_count.append(new_ticket_count)\n",
        "    survived_count.append(new_survived_count)\n",
        "    WC_count.append(new_WC_count)\n",
        "ag_count_plot = pd.DataFrame({'Ticket_Number': count_plot_index, \n",
        "                              'Ticket_Count': ticket_count,\n",
        "                              'Survived_Count':survived_count,\n",
        "                              'WC_Count': WC_count})\n",
        "#To Do add Class\n",
        "\n",
        "g =sns.barplot(x=\"Ticket_Number\", y='Ticket_Count', data=ag_count_plot, color = \"red\")\n",
        "topbar =sns.barplot(x=\"Ticket_Number\", y='WC_Count', data=ag_count_plot, color = 'yellow', )\n",
        "bottombar =sns.barplot(x=\"Ticket_Number\", y='Survived_Count', data=ag_count_plot, linewidth=2.5, facecolor=(1, 1, 1, 0))\n",
        "\n",
        "print(ag_count_plot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5fe19af5-fe37-78da-2cab-0a686e4185d7"
      },
      "source": [
        "For ticket, my thought process was to see if carried importance to the learning process. Maybe exposing an  unknown trend or did it just reflect other factors in features we are also training on. Based on the above I believe it doesn't just reflect other factors, so we will keep it in the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d547860e-8250-d2f3-de42-ff3b0e1943d1"
      },
      "outputs": [],
      "source": [
        "\n",
        "#storing PassengerId for Submission:\n",
        "Test_PId= test_df['PassengerId']\n",
        "\n",
        "#Droping PassengerId\n",
        "train_df=train_df.drop(['PassengerId'], axis=1)\n",
        "test_df=test_df.drop(['PassengerId'], axis=1)\n",
        "#Droping Embarked\n",
        "train_df=train_df.drop(['Embarked'], axis=1)\n",
        "test_df=test_df.drop(['Embarked'], axis=1)\n",
        "\n",
        "\n",
        "train_df.info()\n",
        "print(\"----------------------------\")\n",
        "test_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "687869fc-0ac9-8c2b-03d6-9150901829a4"
      },
      "source": [
        "For  improvement # 2,\n",
        "\n",
        "I think I am going to try and convert name in to something more descriptive. From reading other blogs it seem that Name can be quite important, but currently my seems to have a pretty low weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5aa07d85-5235-b475-0d81-584f9c6d360e"
      },
      "outputs": [],
      "source": [
        "TitleTrain=[]\n",
        "TitleTest=[]\n",
        "trainTitle_index =  train_df['Name'].index.tolist()\n",
        "testTitle_index =  test_df['Name'].index.tolist()\n",
        "\n",
        "for X in train_df['Name']:\n",
        "    NameTitle = X.partition(', ')[-1].rpartition('.')[0] \n",
        "    TitleTrain.append(NameTitle)\n",
        "    \n",
        "for X in test_df['Name']:\n",
        "    NameTitle = X.partition(', ')[-1].rpartition('.')[0] \n",
        "    TitleTest.append(NameTitle)\n",
        "\n",
        "trainTitle_Replace = pd.Series(TitleTrain, index=trainTitle_index)\n",
        "train_df['Name']= trainTitle_Replace\n",
        "\n",
        "testTitle_Replace = pd.Series(TitleTest, index=testTitle_index)\n",
        "test_df['Name']= testTitle_Replace\n",
        "\n",
        "#Changing MRS and MISS to one category:\n",
        "train_df.loc[train_df['Name'] == 'Mrs', 'Name'] = 'Miss'\n",
        "test_df.loc[test_df['Name'] == 'Mrs', 'Name'] = 'Miss'\n",
        "\n",
        "NameListIndex = train_df['Name'].value_counts().index.tolist()\n",
        "\n",
        "NameList = train_df['Name'].value_counts().tolist()\n",
        "for x in range(0,len(NameListIndex)):\n",
        "    if NameList[x] <10:\n",
        "        train_df.loc[train_df['Name'] == NameListIndex[x], 'Name'] = 'Misc'\n",
        "    else:\n",
        "        train_df.loc[train_df['Name'] == NameListIndex[x], 'Name'] = NameListIndex[x]\n",
        "\n",
        "NameTestListIndex = test_df['Name'].value_counts().index.tolist()\n",
        "NameTestList = test_df['Name'].value_counts().tolist()\n",
        "for x in range(0,len(NameTestListIndex)):\n",
        "    if NameTestList[x] <10:\n",
        "        test_df.loc[test_df['Name'] == NameTestListIndex[x], 'Name'] = 'Misc'\n",
        "    else:\n",
        "        test_df.loc[test_df['Name'] == NameTestListIndex[x], 'Name'] = NameTestListIndex[x]\n",
        "\n",
        "sns.countplot(x=\"Name\", hue=\"Survived\", data=train_df)\n",
        "print(train_df['Name'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bdc53ace-a900-629c-77f1-541f51f9333f"
      },
      "outputs": [],
      "source": [
        "\n",
        "le.fit(train_df['Name'])\n",
        "train_df['Name'] = le.transform(train_df['Name'])\n",
        "le.fit(test_df['Name'])\n",
        "test_df['Name'] = le.transform(test_df['Name'])\n",
        "\n",
        "le.fit(test_df['Ticket'])\n",
        "test_df['Ticket'] = le.transform(test_df['Ticket'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "37f43bbb-2da9-74de-ca6e-43dd1dd3a29b"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Now to split the data into a form that can be run in a model \n",
        "X_train = train_df.drop(['Survived'], axis=1)\n",
        "Y_train = train_df['Survived']\n",
        "X_Pred = test_df\n",
        "print(X_train.columns.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a336f90b-8dab-e120-9207-8847660682fb"
      },
      "source": [
        "Run it through a couple different classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "90e9405c-da21-0a16-bba8-24e5a9789e30"
      },
      "outputs": [],
      "source": [
        "from sklearn import  grid_search \n",
        "parameters = {'n_estimators':[100, 150, 200]}\n",
        "random_forest = RandomForestClassifier()\n",
        "RF_clf = grid_search.GridSearchCV(random_forest, parameters)\n",
        "RF_clf.fit(X_train, Y_train)\n",
        "\n",
        "#Cross Validation Output\n",
        "from sklearn.cross_validation import KFold, cross_val_score\n",
        "k_fold = KFold(len(Y_train), n_folds=10, shuffle=True, random_state=0)\n",
        "CV_AVG = cross_val_score(random_forest, X_train, Y_train, cv=k_fold, n_jobs=1)\n",
        "print (sum(CV_AVG) / float(len(CV_AVG)))\n",
        "\n",
        "# Submission Output\n",
        "#Y_Pred = random_forest.predict(X_Pred)\n",
        "#print(Y_Pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "314315a5-efcc-e53b-4293-4062e2c02483"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "parameters = {'n_estimators':[100, 150, 200]}\n",
        "Ada = AdaBoostClassifier()\n",
        "Ada_clf = grid_search.GridSearchCV(Ada, parameters)\n",
        "Ada_clf.fit(X_train, Y_train)\n",
        "\n",
        "#Cross Validation Output\n",
        "k_fold = KFold(len(Y_train), n_folds=10, shuffle=True, random_state=0)\n",
        "CV_AVG = cross_val_score(Ada_clf, X_train, Y_train, cv=k_fold, n_jobs=1)\n",
        "print (sum(CV_AVG) / float(len(CV_AVG)))\n",
        "\n",
        "# Submission Output\n",
        "Y_Pred = Ada_clf.predict(X_Pred)\n",
        "print(Y_Pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ed5cb612-afa2-9caa-306e-1225dfbc71b3"
      },
      "source": [
        "Create the submission data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6d2d465e-be79-318e-84f5-3da0d0564508"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({\n",
        "        \"PassengerId\": Test_PId,\n",
        "        \"Survived\": Y_Pred\n",
        "    })\n",
        "submission.to_csv('titanic.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}