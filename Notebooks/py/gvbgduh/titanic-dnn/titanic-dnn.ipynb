{"nbformat": 4, "metadata": {"language_info": {"nbconvert_exporter": "python", "pygments_lexer": "ipython3", "name": "python", "version": "3.6.3", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "file_extension": ".py"}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat_minor": 1, "cells": [{"cell_type": "markdown", "source": ["# Let's try to improve prediction accuracy using DNN\n", "\n", "As the first step, let's prepare data the same way"], "metadata": {"_uuid": "8c706ab75f61195b3784627879f572af078df539", "_cell_guid": "038cbe31-8ec9-4cc9-92de-2834f3a82b53"}}, {"cell_type": "code", "outputs": [], "metadata": {"_uuid": "ba231fd41b245722c322ee72d4bb19013b09e2d4", "_cell_guid": "40ca232e-d7ab-4ce4-874d-6e5b3005958a"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output.\n", "\n", "df_train = pd.read_csv('../input/train.csv')\n", "df_train.info()\n", "df_test = pd.read_csv('../input/test.csv')\n", "df_test.info()"], "execution_count": 1}, {"cell_type": "code", "outputs": [], "metadata": {"_uuid": "e6230802f3f60cd8d560de35ad3dbb4e2e339372", "_cell_guid": "0c2efbf5-2954-45fd-9cf6-7fa5a55a0ebf"}, "source": ["def prepare_data(df_raw, test=False):\n", "    \"\"\"\n", "    Preprocess data\n", "    \"\"\"\n", "    df = df_raw.copy()\n", "    # Categorize Pclass\n", "    df.Pclass = df.Pclass.astype('category')\n", "    print('Pclass categories: ', df.Pclass.cat.categories)\n", "    # Name\n", "    titles = df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n", "    df['Title'] = df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False).astype('category')\n", "    cats = df['Title'].value_counts()[:9]  # [df['Title'].value_counts() > 1]\n", "    df['Title'] = pd.Categorical(titles, categories=[x for x, y in cats.items()])\n", "    print('Title categories: ', df.Title.cat.categories)\n", "    # Categorize Sex\n", "    df.Sex = df.Sex.astype('category')\n", "    print('Sex categories: ', df.Sex.cat.categories)\n", "    # print('Sex categories: ', dict(enumerate(df_train.Sex.cat.categories)))\n", "    # Fill NAN for Age using mean\n", "    df.Age.fillna(df.Age.mean(), inplace=True)\n", "    # Categorize SibSp\n", "    df.SibSp = df.SibSp.astype('category')\n", "    print('SibSp categories: ', df.SibSp.cat.categories)\n", "    # Categorize Parch\n", "    df.Parch = pd.Categorical(df.Parch, categories=range(10))\n", "    print('Parch categories: ', df.Parch.cat.categories)\n", "    # Ticket\n", "    tick = df_train.Ticket.str.extract('(\\d+)', expand=False)\n", "    tick_start_with = tick.apply(lambda x: str(x)[:1])\n", "    tick_num_lenght = tick.apply(lambda x: len(str(x)))\n", "    df['TickStartWith'] = tick_start_with.astype('category')\n", "    df['TickNumLength'] = tick_num_lenght.astype('category')\n", "    print('TickStartWith categories: ', df.TickStartWith.cat.categories)\n", "    print('TickNumLength categories: ', df.TickNumLength.cat.categories)\n", "    # Fare\n", "    df.Fare.fillna(df.Fare.mean(), inplace=True)\n", "    # Cabin\n", "    cab_char = df_train.Cabin.str.extract('([A-Za-z]{1})', expand=False)\n", "    df['CabChar'] = cab_char.astype('category')\n", "    print('CabChar categories: ', df.CabChar.cat.categories)\n", "    # Categorize Embarked\n", "    df.Embarked = df.Embarked.astype('category')\n", "    df.Embarked.fillna(df.Embarked.value_counts().idxmax(), inplace=True)\n", "    print('Embarked categories: ', df.Embarked.cat.categories)\n", "    \n", "    if test:\n", "        Y_train = df.PassengerId\n", "        df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n", "    else:\n", "        Y_train = df.Survived\n", "        df.drop(['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n", "    df.info()\n", "    return Y_train, df\n", "\n", "def dummify(some_df):\n", "    df = some_df.copy()\n", "    df_d = pd.get_dummies(df, columns=['Pclass', 'Sex', 'SibSp', \n", "                                       'Parch', 'Embarked', 'Title', \n", "                                       'TickStartWith', 'TickNumLength', 'CabChar'])\n", "    df_d.info()\n", "    return df_d\n", "\n", "Y_train, X_train = prepare_data(df_train)\n", "Y_test, X_test = prepare_data(df_test, test=True)\n", "# print('Dummifying...')\n", "# X_d_train = dummify(X_train)\n", "# X_d_test = dummify(X_test)"], "execution_count": 2}, {"cell_type": "code", "outputs": [], "metadata": {"_uuid": "38ea780870d7009eef862f7a73179cb14e885ddb", "collapsed": true, "_cell_guid": "b9c38f61-e2ba-4272-b210-7d5d0465e6ed"}, "source": [], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"_uuid": "c951193ba5a74fafdd37287709e9f0f0ada1e88f", "_cell_guid": "01a93839-7f40-4460-a646-9cb09d29be73"}, "source": ["from keras.layers import Dense, Dropout\n", "from keras.utils import to_categorical, normalize\n", "from keras.models import Sequential\n", "from sklearn.model_selection import train_test_split\n", "\n", "\n", "x_tr, x_t, y_tr, y_t = train_test_split(X_train, Y_train, test_size=0.3, random_state=17)\n", "\n", "def shape_data(some_df, norm=True):\n", "    if norm:\n", "        # age = normalize(X_train.Age.values.reshape(some_df.shape[0],1))\n", "        # fare = normalize(X_train.Fare.values.reshape(some_df.shape[0],1))\n", "        age = some_df.Age.values.reshape(some_df.shape[0],1)\n", "        fare = some_df.Fare.values.reshape(some_df.shape[0],1)\n", "        m_age, s_age = age.mean(), age.std()\n", "        m_fare, s_fare = fare.mean(), fare.std()\n", "        age = (age - m_age) / s_age\n", "        fare = (fare - m_fare) / s_fare\n", "    else:\n", "        age = some_df.Age.values.reshape(some_df.shape[0],1)\n", "        fare = some_df.Fare.values.reshape(some_df.shape[0],1)\n", "    cat_sex = to_categorical(some_df.Sex.cat.codes)\n", "    pclass = to_categorical(some_df.Pclass.cat.codes)\n", "    sibsp = to_categorical(some_df.SibSp.cat.codes)\n", "    parch = to_categorical(some_df.Parch.cat.codes, num_classes=10)\n", "    embarked = to_categorical(some_df.Embarked.cat.codes)\n", "    title = to_categorical(some_df.Title.cat.codes)\n", "    TickStartWith = to_categorical(some_df.TickStartWith.cat.codes)\n", "    TickNumLength = to_categorical(some_df.TickNumLength.cat.codes)\n", "    CabChar = to_categorical(some_df.CabChar.cat.codes, num_classes=8)\n", "    return np.concatenate([age, fare, cat_sex, pclass, \n", "                           sibsp, parch, embarked, title,\n", "                           TickStartWith, TickNumLength, CabChar], axis=1)\n", "\n", "x, y = shape_data(x_tr, norm=True), y_tr.values.reshape(y_tr.shape[0], 1)\n", "x_test, y_test = shape_data(x_t, norm=True), y_t.values.reshape(y_t.shape[0], 1)\n", "print('x.shape: ', x.shape)\n", "print('y.shape: ', y.shape)\n", "print('x_test.shape: ', x.shape)\n", "print('y_test.shape: ', y.shape)\n", "\n", "model = Sequential()\n", "model.add(Dense(units=64, activation='relu', input_dim=x.shape[1]))\n", "model.add(Dropout(0.5))\n", "model.add(Dense(units=128, activation='relu'))\n", "model.add(Dropout(0.6))\n", "model.add(Dense(units=128, activation='relu'))\n", "model.add(Dropout(0.7))\n", "model.add(Dense(units=32, activation='relu'))\n", "model.add(Dropout(0.8))\n", "model.add(Dense(units=1, activation='sigmoid'))\n", "\n", "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n", "# model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n", "\n", "model.fit(x, y, epochs=700, batch_size=1024)\n", "\n", "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=1024)\n", "# classes = model.predict(x_test, batch_size=40)\n", "print(loss_and_metrics)\n", "# print(classes, y_test)\n", "# print(classes.shape)\n", "# cl = pd.Series(list(classes))\n", "# yt = pd.Series(list(y_test))\n", "# ddd = pd.DataFrame(data={'classes': list(classes), 'y': list(y_test)}, index=x_t.index)\n", "# clss = classes >= 0.5\n", "# ddd = pd.concat([y_tr, pd.Series(classes.reshape(-1)), pd.Series(clss.reshape(-1))], axis=1)\n", "# print(ddd)\n", "\n", "print('==========================================')\n", "\n", "# Y_train, X_train\n", "# X_test, Y_test\n", "\n", "# Let's try train model with full avail data and try to predict\n", "# x_train, y_train = shape_data(X_train, norm=True), Y_train.values.reshape(Y_train.shape[0], 1)\n", "# x_pred = shape_data(X_test, norm=True)\n", "\n", "# model.fit(x_train, y_train, epochs=43, batch_size=1000)\n", "\n", "# classes = model.predict(x_pred, batch_size=40)\n", "# # print(classes)\n", "# pred = pd.Series(classes.reshape(-1), name='Survived')\n", "# pred = pred.apply(lambda x: int(x >= 0.45))\n", "# ans = pd.concat([Y_test, pred], axis=1)\n", "# ans = ans.set_index('PassengerId')\n", "# ans.to_csv('ans_dnn.csv')\n", "# print(ans)\n", "res = \"\"\"\n", "For 1 HL net\n", "For Age, Fare, Sex\n", "Epoch 25/25\n", "623/623 [==============================] - 0s 50us/step - loss: 0.4663 - acc: 0.8010\n", "268/268 [==============================] - 0s 1ms/step\n", "[0.52375767124232964, 0.75746268745678569]\n", "\n", "+ Pclass\n", "Epoch 25/25\n", "623/623 [==============================] - 0s 50us/step - loss: 0.4105 - acc: 0.8170\n", "268/268 [==============================] - 0s 1ms/step\n", "[0.47460541529441946, 0.7574626865671642]\n", "\n", "+ 2 Layers without Pclass\n", "Epoch 25/25\n", "623/623 [==============================] - 0s 57us/step - loss: 0.4443 - acc: 0.8090\n", "268/268 [==============================] - 0s 1ms/step\n", "[0.50794072382485689, 0.772388058811871]\n", "\n", "+ Pclass\n", "Epoch 25/25\n", "623/623 [==============================] - 0s 59us/step - loss: 0.3729 - acc: 0.8363\n", "268/268 [==============================] - 0s 1ms/step\n", "[0.46900954531199895, 0.78358208955223885]\n", "\n", "+ SibSp\n", "Epoch 25/25\n", "623/623 [==============================] - 0s 57us/step - loss: 0.3461 - acc: 0.8604\n", "268/268 [==============================] - 0s 2ms/step\n", "[0.47837811797412472, 0.77611940387469625]\n", "# Note: Looks like var is increasing\n", "\n", "+ Embarked\n", "Epoch 25/25\n", "623/623 [==============================] - 0s 61us/step - loss: 0.3206 - acc: 0.8700\n", "268/268 [==============================] - 0s 2ms/step\n", "[0.52090917772321554, 0.76119403074036784]\n", "# Note: Looks like var is increasing even more\n", "\n", "+ Title\n", "Epoch 25/25\n", "623/623 [==============================] - 0s 61us/step - loss: 0.2913 - acc: 0.8764\n", "268/268 [==============================] - 0s 2ms/step\n", "[0.54417172207761166, 0.78358209044186033]\n", "\n", "+ TickStartWith\n", "Epoch 25/25\n", "623/623 [==============================] - 0s 59us/step - loss: 0.2600 - acc: 0.8812\n", "268/268 [==============================] - 0s 2ms/step\n", "[0.56602454808220937, 0.75746268745678569]\n", "\n", "+ TickNumLength\n", "Epoch 25/25\n", "623/623 [==============================] - 0s 59us/step - loss: 0.2399 - acc: 0.9053\n", "268/268 [==============================] - 0s 2ms/step\n", "[0.57680059902703584, 0.78358208955223885]\n", "\n", "+ CabChar\n", "Epoch 25/25\n", "623/623 [==============================] - 0s 63us/step - loss: 0.1974 - acc: 0.9230\n", "268/268 [==============================] - 1s 2ms/step\n", "[0.55896452558574394, 0.79477611940298509]\n", "\n", "+ Parch\n", "Epoch 25/25\n", "623/623 [==============================] - 0s 63us/step - loss: 0.1904 - acc: 0.9213\n", "268/268 [==============================] - 1s 2ms/step\n", "[0.60053732146078076, 0.78731343283582089]\n", "\n", "+ Reg: Dropout + 1 more L\n", "Dropout: 0.6\n", "Epoch 43/43\n", "623/623 [==============================] - 0s 92us/step - loss: 0.3944 - acc: 0.8427\n", "268/268 [==============================] - 1s 3ms/step\n", "[0.44395681637436596, 0.82089552238805974]\n", "\n", "Dropout: 0.7 (-1)\n", "Epoch 43/43\n", "623/623 [==============================] - 0s 81us/step - loss: 0.3145 - acc: 0.8876\n", "268/268 [==============================] - 1s 3ms/step\n", "[0.48667496709681268, 0.82089552238805974]\n", "\n", "Some very rough tunning\n", "Epoch 43/43\n", "623/623 [==============================] - 0s 88us/step - loss: 0.4723 - acc: 0.8363\n", "268/268 [==============================] - 1s 5ms/step\n", "[0.44081404582778022, 0.82089552416730283]\n", "\n", "\n", "\"\"\""], "execution_count": 9}, {"cell_type": "code", "outputs": [], "metadata": {"_uuid": "98f560f52913ebada4bee2280dda4e5354c7c4ac", "collapsed": true, "_cell_guid": "efbb625f-042b-4dbf-b9f6-080c51f604f1"}, "source": [], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"_uuid": "f1d00457081dce8569444b2a6413c64d0143c9a8", "collapsed": true, "_cell_guid": "6e117e9b-3694-4709-b7d8-8c26c8e9dbbd"}, "source": [], "execution_count": null}]}