{"cells":[{"metadata":{"_uuid":"19502ffcd53332a508469dd0e33c3e3436c62c96"},"cell_type":"markdown","source":"# Classification with the Generative Model"},{"metadata":{"_uuid":"53cb03c1e8dfc855492b91ba9de092c5d48897d0"},"cell_type":"markdown","source":"The goal of this notebook is to use generative models to predict the Titanic survivors.\n\nWe will create a Multi-Gaussian distribution and use probabilities to predict the results. No black boxes!\n\nThe idea is to calculate the probabilty (pi) of each label (survived or not) and multiply it by the corresponding value of the probability density function of the other features (P(feature)). \n\nSo, for each person we will have 2 pi*P(feature) values. The largest one will be the chosen label."},{"metadata":{"_uuid":"03f2533369b9c91ba52b08c3d0fcff0c600a44c9"},"cell_type":"markdown","source":"## Load the data "},{"metadata":{"_uuid":"b8f19ac41b20dbe040ad93dd99d58c1f75e8a3cc"},"cell_type":"markdown","source":"Load libraries and data."},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"c5ce2fd1e6b096e647c91fe30a42b4a512b8020b"},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\n\nfrom scipy.stats import norm","execution_count":23,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"23c36d264cc0f56ce86d5852dc3994d89e6aa75c"},"cell_type":"code","source":"# Load data set.\ndata_train = pd.read_csv('../input/train.csv')\ndata_test = pd.read_csv('../input/test.csv')","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"567728a1b85f9b12aac9c55c291d2c062a877b7d"},"cell_type":"markdown","source":"First, let's take a look at the dataset."},{"metadata":{"trusted":false,"_uuid":"899a309a46d14e602c69cf2b470f6ee14156511c"},"cell_type":"code","source":"data_train.head()","execution_count":3,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b8baf6a476ff33a9c35bdfc689d174839f0b057f"},"cell_type":"code","source":"data_train.describe()","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"0a53e1bbc5d675df68ac40ce6d398fb041103089"},"cell_type":"markdown","source":"The data need some adjustments. The functions below will do the job."},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"a19bebb014a6d7b4b99ab4c82d007a1eed9fb05d"},"cell_type":"code","source":"def simplify_ages(df):\n    #Get titles\n    unknow = df['Age'].isnull()\n    master_title = df['Title'] == 'Master'\n    mr_title = df['Title'] == 'Mr'\n    mrs_title = df['Title'] == 'Mrs'\n    miss_title = df['Title'] == 'Miss'\n    dr_title = df['Title'] == 'Dr'\n    \n    #Fill the missing ages with the mean age of the corresponding title\n    df.loc[master_title & unknow,'Age'] = df[master_title]['Age'].mean()\n    df.loc[mr_title & unknow,'Age'] = df[mr_title]['Age'].mean()\n    df.loc[mrs_title & unknow,'Age'] = df[mrs_title]['Age'].mean()\n    df.loc[miss_title & unknow,'Age'] = df[miss_title]['Age'].mean()\n    df.loc[dr_title & unknow,'Age'] = df[dr_title]['Age'].mean()\n\n    df.Age = df.Age.fillna(-0.5)\n    return df\n\ndef simplify_cabins(df):\n    df.Cabin = df.Cabin.fillna('N')\n    df.Cabin = df.Cabin.apply(lambda x: x[0])\n    return df\n\ndef simplify_fares(df):\n    df.Fare = df.Fare.fillna(-0.5)\n    return df\n\ndef format_name(df):\n    df['Lname'] = df.Name.apply(lambda x: x.split(',')[0])\n    df['Title'] = df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n    return df    \n\ndef simplify_family(df):\n    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n    return df\n\ndef simplify_embarks(df):\n    df.Embarked = df.Embarked.fillna('N')\n    df.Embarked = df.Embarked.apply(lambda x: x[0])\n    return df\n\ndef simplify_titles(df):\n    #Groups together some titles\n    df['Title'] = df['Title'].replace(['Col','Dr','Major'], 'MidNoble')\n    df['Title'] = df['Title'].replace(['Mlle','Ms','Mme','Countess','Sir', 'Lady'], 'Noble')\n    df['Title'] = df['Title'].replace(['Don','Jonkheer'], 'Mr')\n    df['Title'] = df['Title'].replace(['Capt','Rev'], 'Worker')\n    return df\n\ndef create_sex_class(df):\n    #Combine gender and class to create a new feature\n    male = df['Sex']=='male'\n    female = df['Sex']=='female'\n    Class1 = df['Pclass']==1\n    Class2 = df['Pclass']==2\n    Class3 = df['Pclass']==3\n\n    df.loc[female & Class1,'Class'] = (0)\n    df.loc[female & Class2,'Class'] = (1)\n    df.loc[female & Class3,'Class'] = (2)\n    df.loc[male & Class1,'Class'] = (3)\n    df.loc[male & Class2,'Class'] = (4)\n    df.loc[male & Class3,'Class'] = (5)\n    \n    return df\n\ndef drop_features(df):\n    #Drop features that were combined or are not very usefull\n    return df.drop(['Ticket', 'SibSp', 'Parch', 'Name', 'Lname', 'Pclass'], axis=1)\n\ndef transform_features(df):\n    df = format_name(df)\n    df = simplify_ages(df)\n    df = simplify_cabins(df)\n    df = simplify_fares(df)\n    df = simplify_family(df)\n    df = simplify_embarks(df)\n    df = simplify_titles(df)\n    df = create_sex_class(df)\n    df = drop_features(df)\n    return df\n\ndef encode_features(df_train, df_test):\n    #Features that are not numeric must be converted before we can make statistics on them.\n    features = ['Cabin', 'Title', 'Embarked', 'Sex']\n    df_combined = pd.concat([df_train[features], df_test[features]])\n    \n    for feature in features:\n        le = preprocessing.LabelEncoder()\n        le = le.fit(df_combined[feature])\n        df_train[feature] = le.transform(df_train[feature])\n        df_test[feature] = le.transform(df_test[feature])\n    return df_train, df_test","execution_count":5,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"bc0395da87d1bae020efb76fcd412e13b6c8e945"},"cell_type":"code","source":"data_train = transform_features(data_train)\ndata_test = transform_features(data_test)","execution_count":6,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"ddc40626c3a578c45941d9e7be14c1b113b49693"},"cell_type":"code","source":"data_train, data_test = encode_features(data_train, data_test)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"aa9205caff45781d0e06c7c7092f32fde01b7b22"},"cell_type":"markdown","source":"Spliting the data to train our model"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"1912c786cde4e643704108345a2f77b5736f4bd1"},"cell_type":"code","source":"X_all = data_train.drop(['Survived', 'PassengerId'], axis=1)\ny_all = data_train['Survived']","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"e4738eb423d8bd17ea5d0da191f27f62925f0674"},"cell_type":"markdown","source":"First, let's take a look at the normal distributions. The Age, for instance, seems to be well represented by its Gaussian distribution."},{"metadata":{"trusted":false,"_uuid":"8012c4976b0cb6e009af6bf89a4d96d1eafcec6a"},"cell_type":"code","source":"sns.distplot(X_all.Age.values, label = \"Age\")\nx = np.random.normal(X_all.Age.mean(), X_all.Age.std(), size=1000)\nsns.distplot(x, label=\"Gaussian Age\")\nplt.legend()","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"3c00f1952d74315c636232b8d8d39fdeee702162"},"cell_type":"markdown","source":"The Fares however, are not very well represented."},{"metadata":{"trusted":false,"_uuid":"3734b9eb4d8464e2dc8bb3c6d082ddda14061c7d"},"cell_type":"code","source":"sns.distplot(X_all.Fare.values, label = \"Fare\")\nx = np.random.normal(X_all.Fare.mean(), X_all.Fare.std(), size=1000)\nsns.distplot(x, label=\"Gaussian Fare\")","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"8b394cfab2c8e4837c063339b01a1636fb7adc3e"},"cell_type":"markdown","source":"Function to extract the mean vector em covariance matrix:"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"d77044738fefe6b8477c00e5b6fcf3b89bdc096f"},"cell_type":"code","source":"def MultivariateGaussian(x,y):\n    k = 2  # labels 1,2,...,k\n    d = (x.shape)[1]  # number of features\n    mu = np.zeros((k,d))\n    sigma = np.zeros((k,d,d))\n    pi = np.zeros(k)\n    for label in range(2):\n        indices = (y == label)\n        mu[label] = np.mean(x[indices,:], axis=0)\n        sigma[label] = np.cov(x[indices,:], rowvar=0, bias=1)\n        pi[label] = float(sum(indices))/float(len(y))\n    return mu, sigma, pi","execution_count":13,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"59d3d5ac0e2a28214dabe1d75e284876a56762b8"},"cell_type":"code","source":"mu, sigma, pi = MultivariateGaussian(X_all.values,y_all.values)","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"c8239566e899f3fb8456c7db04cdf51818a9c2ef"},"cell_type":"markdown","source":"## Testing the model"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"0aff846f34d5f6a434aac3cb6fa17b4d557204ee"},"cell_type":"code","source":"# Now test the performance of a predictor based on a subset of features\ndef test_model(mu, sigma, pi, features, tx, ty):   \n    preds = []\n    errors = 0\n    for x,y in zip(tx,ty):\n        piP_list = []\n        for label in range(2):\n            S = np.linalg.inv(sigma[label])\n            dS = np.linalg.det(sigma[label])\n            xTsigmax=0\n            for i in features:\n                for j in features:\n                    xTsigmax += S[i][j]*(x[i]-mu[label][i])*(x[j]-mu[label][j])\n            piP_list.append(pi[label]*np.exp(-0.5*xTsigmax)/np.sqrt(dS))\n            \n        predict = np.argmax(piP_list)\n        \n        preds.append(predict)\n        if predict != y:\n            errors+=1\n        \n    return errors, preds","execution_count":15,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"72a8a33b431246285e2c4c166d9a89e955b7cb11"},"cell_type":"code","source":"data_test.tail()","execution_count":16,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"691dece51c62e4a406b7780ab520e92fac75bb8d"},"cell_type":"markdown","source":"Using this method, the accuracy in the training data we get is:"},{"metadata":{"trusted":false,"_uuid":"71f3b32345c31d91c0d663651aa7d94ea8e55f89"},"cell_type":"code","source":"errors, preds = test_model(mu, sigma, pi, [0,1,2,3,4,5,6,7], X_all.values, y_all.values)\nprint('Accuracy for training data:', (1-errors/len(y_all))*100, '%' )","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"62fbb356bec7cec074860586e5bda123fe332be9"},"cell_type":"markdown","source":"Which is a good estimate of the test accuracy of this notebook which is 0.78468."},{"metadata":{"_uuid":"41fb9421ded68c5d9e6e6f4573339dff152b5f7c"},"cell_type":"markdown","source":"## Calculate Predictions"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"6f13d4d6f8d5c821c9cfab412b1e89b6287cfffd"},"cell_type":"code","source":"def write_predictions(mu, sigma, pi, features, tx):   \n    preds = []\n    for x in tx:\n        piP_list = []\n        for label in range(2):\n            S = np.linalg.inv(sigma[label])\n            dS = np.linalg.det(sigma[label])\n            xTsigmax=0\n            for i in features:\n                for j in features:\n                    xTsigmax += S[i][j]*(x[i]-mu[label][i])*(x[j]-mu[label][j])\n            piP_list.append(pi[label]*np.exp(-0.5*xTsigmax)/np.sqrt(dS))\n            \n        predict = np.argmax(piP_list)\n        \n        preds.append(predict)\n        \n    return preds","execution_count":18,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"35885edb453e1448a6e25d7e66f12973650c70ae"},"cell_type":"code","source":"preds = write_predictions(mu, sigma, pi, [0,1,2,3,4,5,6,7], data_test.drop('PassengerId',axis=1).values)","execution_count":19,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"e373c9e70b0536c779bb68c76a698d8cc9b3d29d"},"cell_type":"code","source":"data_pred = pd.DataFrame()\ndata_pred['PassengerId']=data_test['PassengerId']\ndata_pred['Survived']=preds","execution_count":20,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e568e2f2d485601873cf36254bffb531325fe676"},"cell_type":"code","source":"data_pred.head()","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"824d126deeb29c5dba56ff50b5b05753890e6226"},"cell_type":"markdown","source":"## Write results"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"c7cd5d3feee83d4397d26286bf858e8d75ac3736"},"cell_type":"code","source":"data_pred.to_csv('predictions_generative_multGauss.csv', index = False)","execution_count":22,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"toc":{"colors":{"hover_highlight":"#DAA520","navigate_num":"#000000","navigate_text":"#333333","running_highlight":"#FF0000","selected_highlight":"#FFD700","sidebar_border":"#EEEEEE","wrapper_background":"#FFFFFF"},"moveMenuLeft":true,"nav_menu":{"height":"12px","width":"252px"},"navigate_menu":true,"number_sections":false,"sideBar":true,"threshold":4,"toc_cell":false,"toc_section_display":"block","toc_window_display":false,"widenNotebook":false}},"nbformat":4,"nbformat_minor":1}