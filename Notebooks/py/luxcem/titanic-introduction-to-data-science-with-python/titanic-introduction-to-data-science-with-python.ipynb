{"nbformat": 4, "cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Introduction to data science with python"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A classic machine learning workflow arround Titanic data,\n", " 1. Exploring data\n", " 1. Cleaning and feature Engineering\n", " 1. Simple ML algorithms\n", " 1. Improving the score"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Exploring the data"]}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["# Data libs\n", "import numpy as np\n", "import pandas as pd\n", "# ML libs\n", "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.ensemble import GradientBoostingClassifier\n", "from sklearn.model_selection import train_test_split\n", "from sklearn import metrics\n", "# Plot libs\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import plotly.offline as pyo\n", "import plotly.figure_factory as ff\n", "import plotly.graph_objs as go\n", "%matplotlib inline\n", "pyo.init_notebook_mode(connected=False)"], "execution_count": 5}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["train, test = pd.read_csv(\"../input/train.csv\"), pd.read_csv(\"../input/test.csv\")\n", "test_ids = test[[\"PassengerId\"]]"], "execution_count": 6}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["train.head()"], "execution_count": 7}, {"cell_type": "markdown", "metadata": {}, "source": ["We will plot various features with their relation to survival rate to have an idea of correlations"]}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["fig, axs = plt.subplots(ncols=3, figsize=(16,5))\n", "sns.pointplot(x=\"Embarked\", y=\"Survived\", hue=\"Sex\", data=train, ax=axs[0]);\n", "sns.pointplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=train, ax=axs[1]);\n", "sns.violinplot(x=\"Survived\", y=\"Age\", hue=\"Sex\", data=train, ax=axs[2]);"], "execution_count": 8}, {"cell_type": "markdown", "metadata": {}, "source": ["We can already see some (strong) correlation between sex, age, Pclass, embarked and survival rate"]}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["data_age = [train[train.Survived == 1].Age.dropna(), train[train.Survived == 0].Age.dropna()]\n", "labels = [\"Survived\", \"Not survived\"]\n", "fig = ff.create_distplot(data_age, labels, bin_size=2, show_rug=False)\n", "pyo.iplot(fig)"], "execution_count": 9}, {"cell_type": "markdown", "metadata": {}, "source": ["Correlations values"]}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["corr = train.corr().abs().Survived.sort_values(ascending=False)[1:]\n", "data = [go.Bar(\n", "            x=corr.index.values,\n", "            y=corr.values\n", "    )]\n", "\n", "pyo.iplot(data, filename='basic-bar')"], "execution_count": 10}, {"cell_type": "markdown", "metadata": {}, "source": ["## Cleaning & feature engineering\n", "\n", "The data is not yet ready to be feed to machine learning algorithms."]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["train.head()\n", "# Keep train as read only\n", "data = train.copy()"], "execution_count": 11}, {"cell_type": "markdown", "metadata": {}, "source": ["### Feature engineering\n", "\n", "The name is not as it is exploitable, a popular idea on this dataset is to extract the title of the name as some are rare and their survival rate may be higher."]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["data.Title = None\n", "test.Title = None\n", "\n", "title_cats = {\n", "    \"Mr\": [\"Mr.\"],\n", "    \"Miss\": [\"Miss.\", \"Ms.\", \"Mlle.\"],\n", "    \"Mrs\": [\"Mrs.\", \"Mme.\"],\n", "    \"Rare_M\": [\"Master.\", \"Don.\", \"Rev.\", \"Dr.\", \"Major.\", \"Sir.\", \"Col\", \"Capt.\", \"Jonkheer.\"],\n", "    \"Rare_F\": [\"Lady.\", \"the Countess.\", \"Dona.\"]\n", "}\n", "\n", "data[\"LastName\"] = train[\"Name\"].str.split(\",\", expand=True)[1].str.strip()\n", "test[\"LastName\"] = test[\"Name\"].str.split(\",\", expand=True)[1].str.strip()\n", "\n", "for c_title, l_title in title_cats.items():\n", "    for title in l_title:\n", "        data.loc[data[\"LastName\"].str.startswith(title), \"Title\"] = c_title\n", "        test.loc[test[\"LastName\"].str.startswith(title), \"Title\"] = c_title\n", "\n", "le = LabelEncoder().fit(data[\"Title\"].append(test[\"Title\"]))\n", "data[\"Title\"] = le.transform(data[\"Title\"])\n", "test[\"Title\"] = le.transform(test[\"Title\"])"], "execution_count": 12}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["data[\"FamilySize\"] = train[\"Parch\"] + train[\"SibSp\"] + 1\n", "data[\"Alone\"] = 0\n", "data.loc[data[\"FamilySize\"] == 1, \"Alone\"] = 1\n", "\n", "test[\"FamilySize\"] = test[\"Parch\"] + test[\"SibSp\"] + 1\n", "test[\"Alone\"] = 0\n", "test.loc[test[\"FamilySize\"] == 1, \"Alone\"] = 1"], "execution_count": 13}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["train[train[\"Cabin\"].notnull()][[\"Cabin\"]].sample(10)"], "execution_count": 14}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["le = LabelEncoder()\n", "\n", "data.loc[train[\"Cabin\"].notnull(), \"Cabin\"] = train.loc[train[\"Cabin\"].notnull(), \"Cabin\"].str[0]\n", "data.loc[train[\"Cabin\"].isnull(), \"Cabin\"] = \"\"\n", "\n", "test.loc[test[\"Cabin\"].notnull(), \"Cabin\"] = test.loc[test[\"Cabin\"].notnull(), \"Cabin\"].str[0]\n", "test.loc[test[\"Cabin\"].isnull(), \"Cabin\"] = \"\"\n", "\n", "le.fit(data[\"Cabin\"].append(test[\"Cabin\"]))\n", "\n", "data[\"Cabin\"] = le.transform(data[\"Cabin\"])\n", "test[\"Cabin\"] = le.transform(test[\"Cabin\"])"], "execution_count": 15}, {"cell_type": "markdown", "metadata": {}, "source": ["Let see the correlation between our engineeered feature and the Survived column"]}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["data[[\"Title\", \"FamilySize\", \"Alone\", \"Survived\", \"Cabin\"]].corr().abs()[[\"Survived\"]]"], "execution_count": 16}, {"cell_type": "markdown", "metadata": {}, "source": ["### Cleaning data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Preparing data for ML algorithms"]}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["data.head()"], "execution_count": 17}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["fig, axs = plt.subplots(ncols=2, figsize=(16,5))\n", "sns.distplot(data[data[\"Age\"].notnull()][\"Age\"], ax=axs[0])\n", "sns.distplot(data[data[\"Fare\"].notnull()][\"Fare\"], ax=axs[1])"], "execution_count": 18}, {"cell_type": "markdown", "metadata": {}, "source": ["Age and Fare are mostly gaussian"]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["data[\"Sex\"] = LabelEncoder().fit_transform(data[\"Sex\"])\n", "data.loc[train[\"Embarked\"].notnull(), \"Embarked\"] = LabelEncoder().fit_transform(train.loc[train[\"Embarked\"].notnull(), \"Embarked\"])\n", "data[\"Age\"] = pd.qcut(train[\"Age\"], q=5, labels=False)\n", "data[\"Fare\"] = pd.qcut(train.loc[train[\"Fare\"] != 0, \"Fare\"], q=5, labels=False)\n", "\n", "data.loc[train[\"Age\"].isnull(), \"Age\"] = None\n", "data.loc[train[\"Fare\"] == 0, \"Fare\"] = None\n", "\n", "test[\"Sex\"] = LabelEncoder().fit_transform(test[\"Sex\"])\n", "test.loc[test[\"Embarked\"].notnull(), \"Embarked\"] = LabelEncoder().fit_transform(test.loc[test[\"Embarked\"].notnull(), \"Embarked\"])\n", "test[\"Age\"] = pd.qcut(test[\"Age\"], q=5, labels=False)\n", "test[\"Fare\"] = pd.qcut(test.loc[test[\"Fare\"] != 0, \"Fare\"], q=5, labels=False)\n", "\n", "test.loc[test[\"Age\"].isnull(), \"Age\"] = None\n", "test.loc[test[\"Fare\"] == 0, \"Fare\"] = None"], "execution_count": 19}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["data.head()"], "execution_count": 20}, {"cell_type": "markdown", "metadata": {}, "source": ["One Hot Encoding for non hierarchical categories"]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["ohe_columns = [\"Cabin\", \"Embarked\", \"Title\"]\n", "data = pd.get_dummies(data, prefix=ohe_columns, columns=ohe_columns, drop_first=True)\n", "test = pd.get_dummies(test, prefix=ohe_columns, columns=ohe_columns, drop_first=True)"], "execution_count": 21}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["set(data.columns) - set(test.columns)"], "execution_count": 22}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["test[\"Cabin_8\"] = 0"], "execution_count": 23}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["data.drop([\"PassengerId\", \"Name\", \"LastName\", \"SibSp\", \"Parch\", \"Ticket\"], axis=1, inplace=True)\n", "test.drop([\"PassengerId\", \"Name\", \"LastName\", \"SibSp\", \"Parch\", \"Ticket\"], axis=1, inplace=True)"], "execution_count": 24}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Dealing with empty data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A very simple strategy is to use the median value for all missing values. A not so simple is to use another ML algorithm to guess age"]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["data.loc[data[\"Age\"].isnull() & data[\"Fare\"].isnull(), \"Age\"] = data[\"Age\"].value_counts().idxmax()\n", "data.loc[data[\"Age\"].isnull() & data[\"Fare\"].isnull(), \"Fare\"] = data[\"Fare\"].value_counts().idxmax()\n", "\n", "test.loc[test[\"Age\"].isnull() & test[\"Fare\"].isnull(), \"Age\"] = test[\"Age\"].value_counts().idxmax()\n", "test.loc[test[\"Age\"].isnull() & test[\"Fare\"].isnull(), \"Fare\"] = test[\"Fare\"].value_counts().idxmax()"], "execution_count": 25}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["clf = GradientBoostingClassifier() \n", "X_train = data[data[\"Fare\"].notnull()].copy()\n", "\n", "X_Age_nn = X_train[X_train[\"Age\"].notnull()].drop(\"Age\", axis=1)\n", "y_Age_nn = X_train[X_train[\"Age\"].notnull()][\"Age\"]\n", "X_Age_n = X_train[X_train[\"Age\"].isnull()].drop(\"Age\", axis=1)\n", "X_Age_train, X_Age_test, y_Age_train, y_Age_test = train_test_split(X_Age_nn, y_Age_nn, test_size=0.80)\n", "clf.fit(X_Age_nn, y_Age_nn)\n", "predictions = clf.predict(X_Age_test)\n", "print(metrics.accuracy_score(predictions, y_Age_test))\n", "\n", "data.loc[data[\"Fare\"].notnull() & data[\"Age\"].isnull(), \"Age\"] = clf.predict(X_Age_n)"], "execution_count": 26}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["clf = GradientBoostingClassifier() \n", "X_train = test[test[\"Fare\"].notnull()].copy()\n", "\n", "X_Age_nn = X_train[X_train[\"Age\"].notnull()].drop(\"Age\", axis=1)\n", "y_Age_nn = X_train[X_train[\"Age\"].notnull()][\"Age\"]\n", "X_Age_n = X_train[X_train[\"Age\"].isnull()].drop(\"Age\", axis=1)\n", "X_Age_train, X_Age_test, y_Age_train, y_Age_test = train_test_split(X_Age_nn, y_Age_nn, test_size=0.80)\n", "clf.fit(X_Age_nn, y_Age_nn)\n", "predictions = clf.predict(X_Age_test)\n", "print(metrics.accuracy_score(predictions, y_Age_test))\n", "\n", "test.loc[test[\"Fare\"].notnull() & test[\"Age\"].isnull(), \"Age\"] = clf.predict(X_Age_n)"], "execution_count": 27}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["clf = GradientBoostingClassifier() \n", "X_train = data.copy()\n", "\n", "X_Fare_nn = X_train[X_train[\"Fare\"].notnull()].drop(\"Fare\", axis=1)\n", "y_Fare_nn = X_train[X_train[\"Fare\"].notnull()][\"Fare\"]\n", "X_Fare_n = X_train[X_train[\"Fare\"].isnull()].drop(\"Fare\", axis=1)\n", "X_Fare_train, X_Fare_test, y_Fare_train, y_Fare_test = train_test_split(X_Fare_nn, y_Fare_nn, test_size=0.80)\n", "clf.fit(X_Fare_nn, y_Fare_nn)\n", "predictions = clf.predict(X_Fare_test)\n", "print(metrics.accuracy_score(predictions, y_Fare_test))\n", "\n", "data.loc[data[\"Fare\"].isnull(), \"Fare\"] = clf.predict(X_Fare_n)"], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["clf = GradientBoostingClassifier() \n", "X_train = test.copy()\n", "\n", "X_Fare_nn = X_train[X_train[\"Fare\"].notnull()].drop(\"Fare\", axis=1)\n", "y_Fare_nn = X_train[X_train[\"Fare\"].notnull()][\"Fare\"]\n", "X_Fare_n = X_train[X_train[\"Fare\"].isnull()].drop(\"Fare\", axis=1)\n", "X_Fare_train, X_Fare_test, y_Fare_train, y_Fare_test = train_test_split(X_Fare_nn, y_Fare_nn, test_size=0.80)\n", "clf.fit(X_Fare_nn, y_Fare_nn)\n", "predictions = clf.predict(X_Fare_test)\n", "print(metrics.accuracy_score(predictions, y_Fare_test))\n", "\n", "test.loc[test[\"Fare\"].isnull(), \"Fare\"] = clf.predict(X_Fare_n)"], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["## Let's do it"]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["clf = GradientBoostingClassifier() \n", "X = data.drop(\"Survived\", axis=1)\n", "y = data[\"Survived\"]\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.80)\n", "\n", "clf.fit(X_train, y_train)\n", "predictions = clf.predict(X_test)\n", "metrics.accuracy_score(predictions, y_test)"], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["predictions = clf.predict(test)\n", "final = test_ids.copy()\n", "final[\"Survived\"] = predictions\n", "final.set_index(\"PassengerId\", inplace=True)\n", "final.to_csv(\"final.csv\")"], "execution_count": null}], "metadata": {"language_info": {"name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.6.4", "codemirror_mode": {"version": 3, "name": "ipython"}}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat_minor": 1}