{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"## Importing libraries"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import cross_val_score","execution_count":43,"outputs":[]},{"metadata":{"_uuid":"2c52ef57efb291da2e002d9b53034f95d6410753"},"cell_type":"markdown","source":"## Importing data"},{"metadata":{"trusted":true,"_uuid":"95e4ad3378a569682006933ab37da19d35f86f6f"},"cell_type":"code","source":"titanic_df = pd.read_csv(\"../input/train.csv\")\ntest_df    = pd.read_csv(\"../input/test.csv\")\n\n\ntitanic_df.info()\nprint('-'*50)\ntest_df.info()","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"ea19eed1ea75fcdf433a3da808cd4320b1041cb3"},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true,"_uuid":"9ff55ba7ed7fbbe4d861fa67e31c225f9b114244","collapsed":true},"cell_type":"code","source":"# drop unnecessary columns, these columns won't be useful in analysis and prediction\ntitanic_df.drop(['PassengerId','Name','Ticket'], axis=1, inplace=True)\ntest_df.drop(['Name','Ticket'], axis=1, inplace=True)","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"3f98856a87af2c9c2102e83bdd53f6d698c6615a"},"cell_type":"markdown","source":"### Filling NAs"},{"metadata":{"trusted":true,"_uuid":"467ce7a2f69daf4e070c8ecf6c0f293d35b2f535"},"cell_type":"code","source":"# Checking for na values in datasets columns\nprint('Titanic dataset:')\nprint(titanic_df.isnull().sum())\nprint('-'*50)\nprint('Test dataset:')\nprint(test_df.isnull().sum())\nprint('-'*50)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6df80437473bba2f4c47e5cd3f384c4f6501fb44"},"cell_type":"code","source":"#################\n# Titanic dataset\n#################\n# Getting the proportion of Embarked within titanic dataframe\nprint(\"\\nProportion of Embarked values in dataset: \\n{}\".format(titanic_df.Embarked.value_counts() / len(titanic_df)))\n\n# Filling missed Embarked records with S\ntitanic_df.Embarked.fillna('S', inplace=True)\n\n# Filling missing ages with random values with normal distribution of current ages\ntitanic_df.loc[titanic_df.Age.isnull(),'Age'] = np.random.randint(titanic_df.Age.mean() - titanic_df.Age.std(),\n                                                                  titanic_df.Age.mean() + titanic_df.Age.std(),\n                                                                  size=titanic_df.Age.isnull().sum())\n\n# Checking for cabin columns\nprint(\"\\nProportion of NAs in cabin column:{}\".format(titanic_df.Cabin.isnull().sum() / len(titanic_df))) # 78% NAs, we can drop it\ntitanic_df.drop('Cabin', axis=1, inplace=True)\n\n##############\n# Test dataset\n##############\ntest_df.fillna(test_df.Fare.median(), inplace=True)\n\n# Filling missing ages with random values with normal distribution of current ages\ntest_df.loc[test_df.Age.isnull(),'Age'] = np.random.randint(test_df.Age.mean() - test_df.Age.std(),\n                                                            test_df.Age.mean() + test_df.Age.std(),\n                                                            size=test_df.Age.isnull().sum())\n\ntest_df.drop('Cabin', axis=1, inplace=True)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18a46535c8ea2dfe7c7ca8538d2d81e9a496f1de"},"cell_type":"code","source":"# Checking for na values in datasets columns\nprint('Titanic dataset:')\nprint(titanic_df.isnull().sum())\nprint('-'*50)\nprint('Test dataset:')\nprint(test_df.isnull().sum())\nprint('-'*50)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b6a38c87e171ede5fedf5f7ca37414d89a64220"},"cell_type":"code","source":"titanic_df.info()","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4993c36f1f9a72d04956070c2e2aa823cbfdc3c3"},"cell_type":"code","source":"titanic_df.SibSp.value_counts()","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48632f259b40e0cd1d0aebeeab782315e0203c98","collapsed":true},"cell_type":"code","source":"###########################\n# Setting proper data types\n###########################\ntitanic_df['Survived'] = titanic_df.Survived.astype('category')\ntitanic_df['Pclass'] = titanic_df.Pclass.astype('category')\ntitanic_df['Sex'] = titanic_df.Sex.astype('category')\ntitanic_df['Embarked'] = titanic_df.Embarked.astype('category')\n\ntest_df['Pclass'] = test_df.Pclass.astype('category')\ntest_df['Sex'] = test_df.Sex.astype('category')\ntest_df['Embarked'] = test_df.Embarked.astype('category')","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"330915288b0021bac5f6c77af71868caf49e2e74"},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{"trusted":true,"_uuid":"139ee048baf22531a36c92a4277c4f319617ae1e","collapsed":true},"cell_type":"code","source":"# Constructing FamilySize and traveling Alone columns and removing Parch and SibSp\ntitanic_df['FamilySize'] =  titanic_df[\"Parch\"] + titanic_df[\"SibSp\"]\ntitanic_df.loc[titanic_df['FamilySize'] > 0, 'Alone'] = 0\ntitanic_df.loc[titanic_df['FamilySize'] == 0, 'Alone'] = 1\ntitanic_df['Alone'] = titanic_df.Alone.astype('category')\ntitanic_df = titanic_df.drop(['SibSp','Parch'], axis=1)\n\n# Doing the same for test dataset\ntest_df['FamilySize'] =  test_df[\"Parch\"] + test_df[\"SibSp\"]\ntest_df.loc[test_df['FamilySize'] > 0, 'Alone'] = 0\ntest_df.loc[test_df['FamilySize'] == 0, 'Alone'] = 1\ntest_df['Alone'] = test_df.Alone.astype('category')\ntest_df = test_df.drop(['SibSp','Parch'], axis=1)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a34e01af901bddf06fca963e8c3dbc31eeda337a"},"cell_type":"code","source":"# Defining categorical variables encoder method\ndef fit_transform_ohe(df,col_name):\n    \"\"\"This function performs one hot encoding for the specified\ncolumn.\n    Args:\n        df(pandas.DataFrame): the data frame containing the mentioned column name\n        col_name: the column to be one hot encoded\n    Returns:\n        tuple: label_encoder, one_hot_encoder, transformed column as pandas Series\n    \"\"\"\n    # label encode the column\n    le = preprocessing.LabelEncoder()\n    le_labels = le.fit_transform(df[col_name])\n    df[col_name+'_label'] = le_labels\n    # one hot encoding\n    ohe = preprocessing.OneHotEncoder()\n    feature_arr = ohe.fit_transform(df[[col_name+'_label']]).toarray()\n    feature_labels = [col_name+'_'+str(cls_label) for cls_label in le.classes_]\n    features_df = pd.DataFrame(feature_arr, columns=feature_labels)\n    return le,ohe,features_df\n\n# given label encoder and one hot encoder objects, \n# encode attribute to ohe\ndef transform_ohe(df,le,ohe,col_name):\n    \"\"\"This function performs one hot encoding for the specified\n        column using the specified encoder objects.\n\n    Args:\n        df(pandas.DataFrame): the data frame containing the mentioned column name\n        le(Label Encoder): the label encoder object used to fit label encoding\n        ohe(One Hot Encoder): the onen hot encoder object used to fit one hot encoding\n        col_name: the column to be one hot encoded\n\n    Returns:\n        tuple: transformed column as pandas Series\n\n    \"\"\"\n    # label encode\n    col_labels = le.transform(df[col_name])\n    df[col_name+'_label'] = col_labels\n    \n    # ohe \n    feature_arr = ohe.fit_transform(df[[col_name+'_label']]).toarray()\n    feature_labels = [col_name+'_'+str(cls_label) for cls_label in le.classes_]\n    features_df = pd.DataFrame(feature_arr, columns=feature_labels)\n    \n    return features_df","execution_count":13,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"de402f728bf02a997f0822a4b6ccc0dba9c3392e"},"cell_type":"code","source":"X = titanic_df.iloc[:,1:]\ny = titanic_df.iloc[:,0]\n\nX_test = test_df.iloc[:,1:]\ny_test = test_df.iloc[:,0]","execution_count":54,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"201a479ecb67bd6af7d55c009e4ae4e48a309a9d"},"cell_type":"code","source":"# Encoding all the categorical features\ncat_attr_list = ['Pclass','Sex',\n                 'Embarked','Alone']\n# though we have transformed all categoricals into their one-hot encodings, note that ordinal\n# attributes such as hour, weekday, and so on do not require such encoding.\nnumeric_feature_cols = ['Age','Fare','FamilySize']\nsubset_cat_features =  ['Pclass','Sex','Embarked','Alone']\n\n###############\n# Train dataset\n###############\nencoded_attr_list = []\nfor col in cat_attr_list:\n    return_obj = fit_transform_ohe(X,col)\n    encoded_attr_list.append({'label_enc':return_obj[0],\n                              'ohe_enc':return_obj[1],\n                              'feature_df':return_obj[2],\n                              'col_name':col})\n\n\nfeature_df_list  = [X[numeric_feature_cols]]\nfeature_df_list.extend([enc['feature_df'] \\\n                        for enc in encoded_attr_list \\\n                        if enc['col_name'] in subset_cat_features])\n\ntrain_df_new = pd.concat(feature_df_list, axis=1)\nprint(\"Train dataset shape::{}\".format(train_df_new.shape))\nprint(train_df_new.head())\n\n##############\n# Test dataset\n##############\ntest_encoded_attr_list = []\nfor enc in encoded_attr_list:\n    col_name = enc['col_name']\n    le = enc['label_enc']\n    ohe = enc['ohe_enc']\n    test_encoded_attr_list.append({'feature_df':transform_ohe(X_test,\n                                                              le,ohe,\n                                                              col_name),\n                                   'col_name':col_name})\n    \n    \ntest_feature_df_list = [X_test[numeric_feature_cols]]\ntest_feature_df_list.extend([enc['feature_df'] \\\n                             for enc in test_encoded_attr_list \\\n                             if enc['col_name'] in subset_cat_features])\n\ntest_df_new = pd.concat(test_feature_df_list, axis=1) \nprint(\"Test dataset shape::{}\".format(test_df_new.shape))\nprint(test_df_new.head())","execution_count":55,"outputs":[]},{"metadata":{"_uuid":"0dd6d4d95f366843be2408f30e513955d1167f25"},"cell_type":"markdown","source":"## Modeling"},{"metadata":{"trusted":true,"_uuid":"e3519372d2b2bb05179f44ed2334bf26c4287f42"},"cell_type":"code","source":"# Constructing train dataset\nX = train_df_new\n#y= y.Survived\n\n# Constructing test dataset\nX_test = test_df_new\n#y_test = y_test.Survived\nprint(X.shape,y.shape)","execution_count":56,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc08cbadaf049071502bc54216e6f86e3aa1a0a2"},"cell_type":"code","source":"logreg = LogisticRegression()\n\nlogreg.fit(X,y)\nprint(\"R-Squared on train dataset={}\".format(logreg.score(X,y)))\n\nY_pred = logreg.predict(X_test)\n\nlogreg.fit(X_test,y_test)   \nprint(\"R-Squared on test dataset={}\".format(logreg.score(X_test,y_test)))","execution_count":57,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae2c5b12e5186351a1ca27c8dcb14d66a39587b6"},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('titanic.csv', index=False)","execution_count":58,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"aaf835bae30052e8738b977f290ade1e163921ae"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}