{"cells":[{"metadata":{"_cell_guid":"a97852b3-e806-91d3-74b0-d40d4fca938d","_uuid":"c650ecdf23d62d3983d060633b31de7ac11d9dd9"},"cell_type":"markdown","source":"# Titanic Part I\n\nThis is the part 1 of Titanic survival modeling. The given data is 891 Titanic passengers' information. Ground truth (survival) is given along with the data. We will build a model based on the given training data and test our model on additional test data (another 418 passengers).\n\nFirst I want to have a deep understanding of the data, clean them up and analyze the raw attributes. I will try to extract features from the data, encode them, and understand the correlations of the features. Based on the understanding of features I will build some classifiers to do the predictions.\n\nFor most of the times the machine learning is an iterative work. In the latter part of this notebook I will analyize features and do advanced feature engineering. Each type of model might give different bias and variance. Some may fit better to a given data set than others. I will also build a spectrum of models and figure out the best performer.\n\nWhen training models, I will use cross-validation for each of the model and find its best hyper-parameter set.\n\nTo be specific the notebook takes the following steps:\n - Import and visualize data. Get some basic understanding of the data\n   (distributions, validness, importance)\n - Clean up and normalize features.\n - Split train/test folds\n - Train models \n - Debug false-predicted cases and improve feature engineering.\n \n \n# Iteration #1: Basic feature engineering and model\n\n## Import and visualize data #\nFirst let's import the training data. Print out samples to get some basic idea of the data."},{"metadata":{"_cell_guid":"4f1e85cf-d2e5-a2d8-e7ca-3197361bb6e1","_uuid":"2e86ef0eb5aa8631a9dff2efda001ae2eb89da41","trusted":true},"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nfrom xgboost import XGBClassifier\n\n%matplotlib inline\n\n# helper funcs\nsns.set(style=\"white\", palette=\"muted\", color_codes=True)\ndef is_nan(num):\n    return num != num\n\n# load data \ndata_train = pd.read_csv('../input/train.csv')\ndata_test = pd.read_csv('../input/test.csv')\nprint(\"Total training examples: {n}\".format(n=len(data_train)))\nprint(\"Total test examples: {n}\".format(n=len(data_test)))\n\ndata_train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5109f75d6d64a47151719f903f64d8d8e48b18a8"},"cell_type":"code","source":"data_test.loc[data_test['PassengerId'] == 1116]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"34a0a8b7-ffd9-c488-1660-45419b06a9af","_uuid":"4ee727e065a832b117e52b6a0d2c75434ae68f75"},"cell_type":"markdown","source":"There are a few categorical features which I think are good feature candidates: *Pclass, Sex, SibSp, Parch, Embarked*. Also there are some continuous features that can be converted into categorical features: *Age, Cabin, Fare*\n\nFirst I want to plot the features to have some sense of their distributions and correlation to survival. I note that some of the raw data are not cleaned, for eg there are **Nan** in *Age*.\n\nWhen I train a model, I want to be careful not to add too many features to avoid overfitting because I do not have too many training examples. \n\nA feature can be a good feature if it has high correlation to survival.  To pick the right feature I want to have a sense of the correlation of each feature. Following are the plot of *Pclass* and *Sex*. We can see that there are clear differences between various values of *Pclass* or *Sex* in terms of survival.\n\nIn the latter part of this notebook I will calculate the Pearson correlation of features vs survival. At that time we will be able to tell which features are the most correlated. They are the good feature candidates. Some feature is not a good feature. For example the *Ticket*. As we will see later, *Ticket* has almost zero correlation to survival. (Interestingly I found ticket numbers are not evenly distributed: the ticket ends with number **9** are at least twice as many as other tickets. Maybe a historian can tell me why is that?)"},{"metadata":{"_cell_guid":"2c322325-9203-1078-f98a-6e941e82764f","_uuid":"416c5d2a641f52fb14834f5a1c52316254f049f3","trusted":false},"cell_type":"code","source":"# Pclass\npclass = data_train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean()\n_ = sns.barplot(data=pclass, x='Pclass', y='Survived')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7f62f2e3-56b1-dea2-e549-b5dbb46f81d4","_uuid":"31204e86f259462a3e9c0158c2ce2ca6d72f47d5","trusted":false},"cell_type":"code","source":"# Sex\nsex = data_train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean()\n_ = sns.barplot(data=sex, x='Sex', y='Survived')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3b4a0f97-3f1c-f87a-0fb2-d355f01f32c9","_uuid":"57645e970c530a71118ecc29ac8578e28308b9e8","trusted":false},"cell_type":"code","source":"# Age\ncleaned_age = [c for c in data_train[\"Age\"].values.tolist() if not is_nan(c)]  # some basic data cleaning\nsns.distplot(cleaned_age, kde=False, color=\"b\")\n_ = sns.FacetGrid(data_train, col='Survived').map(plt.hist, 'Age', bins=20)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"468c7cce-f7fa-e317-6e35-14d7e1169618","_uuid":"15c9991be5ba0c1db4573bf620968cdf49ed6ea2","trusted":false},"cell_type":"code","source":"# Fare\ncleaned_fare = [c for c in data_train[\"Fare\"].values.tolist() if not is_nan(c)]  # some basic data cleaning\nsns.distplot(cleaned_fare, kde=False, color=\"b\")\n_ = sns.FacetGrid(data_train, col='Survived').map(plt.hist, 'Fare', bins=20)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e15f59e8-f7fa-fad4-6420-16a1b407af85","_uuid":"725d766f2f2176693603817eb2521b14edf96bea","trusted":false},"cell_type":"code","source":"# Ticket last digit\ndata_train['Ticket_last_digit'] = data_train[\"Ticket\"].map(lambda x: float(x[-1:]) % 10 if x[-1:].isdigit() else float('NaN'))\n_ = sns.distplot([c for c in data_train[\"Ticket_last_digit\"].values.tolist() if not is_nan(c)], kde=False, color=\"b\")\ndel data_train['Ticket_last_digit']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3921a16a-76f1-0d18-a886-743014083cae","_uuid":"95e3396330f5bbf128852d3d19f19ec7496e554a"},"cell_type":"markdown","source":"## Clean up and normalize features \nI want to extract the following features: *Pclass, Sex, Age, SibSp, Parch, Cabin, Fare*\n\n**Feature| Type| Needs Cleanup**\n\n - Pclass | Numerical | No\n - Sex | Categorical | No\n - Age | Numerical | Cleanup + To age_bucket\n - SibSp | Numerical | No\n - Parch | Numerical | No\n - Fare | Numerical | Celanup + To fare_bucket\n - Cabin | Categorial | To cabin_init_letter"},{"metadata":{"_cell_guid":"cccbae24-1d20-d6be-900c-e1dd2a786ff1","_uuid":"ccb0aed6febe23ced75601ed287e80f2047871cb","trusted":false},"cell_type":"code","source":"# preprocess data\n_features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\", \"Embarked\"]\n\ndef sanity_checks(df, is_train):\n    assert (not is_train) or all(x in [0, 1] for x in df.Survived)\n    assert all(x in [1,2,3] for x in df.Pclass)    \n    assert all(not is_nan(x) for x in df.SibSp)\n    assert all(not is_nan(x) for x in df.Parch)\n    assert all(x in [\"S\", \"C\", \"U\", \"Q\"] for x in df.Embarked)\n\ndef preprocess_sex(df):\n    df.Sex = df.Sex.apply(lambda x: x.lower() if x.lower() in [\"female\", \"male\"] else \"unknown\")\n    return df\n\ndef preprocess_age(df):\n    # bucket age\n    df.Age = df.Age.fillna(-0.5)\n    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n    group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n    categories = pd.cut(df.Age, bins, labels=group_names)\n    df.Age = categories\n    return df\n  \ndef preprocess_fare(df):\n    # bucket fare\n    df.Fare = df.Fare.fillna(-0.5)\n    bins = (-1, 0, 8, 15, 31, 50, 100, 300, 1000)\n    group_names = ['Unknown', 'fare_1', 'fare_2', 'fare_3', 'fare_4', 'fare_5', 'fare_6', 'fare_7']\n    categories = pd.cut(df.Fare, bins, labels=group_names)\n    df.Fare = categories\n    return df\n\ndef preprocess_cabin(df):\n    # get init letter of cabin\n    df.Cabin = df.Cabin.fillna('X')\n    df.Cabin = df.Cabin.apply(lambda x: x[0])\n    return df\n\ndef drop_features(df, features, is_train):\n    if is_train:\n        return df[features + ['PassengerId','Survived']]\n    else:\n        return df[features + ['PassengerId']]\n\ndef preprocess_embarked(df):\n    df.Embarked = df.Embarked.fillna('U')\n    return df\n\n# run this func for both train and test\ndef preprocess1(df, is_train):    \n    df = preprocess_embarked(df)\n    df = preprocess_sex(df)\n    df = preprocess_age(df)\n    df = preprocess_fare(df)\n    df = preprocess_cabin(df)\n    df = drop_features(df, features=_features, is_train=is_train)\n    sanity_checks(df, is_train)\n    return df\n\ndata_train1 = preprocess1(data_train.copy(), is_train=True)\ndata_test1 = preprocess1(data_test.copy(), is_train=False)\ndata_train1.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d2f63ef7-2843-c667-fffc-6218bbaf4513","_uuid":"71523faf337d2b984ef94754fe938095d364e5dd"},"cell_type":"markdown","source":"Now we convert categorical values into numerical values."},{"metadata":{"_cell_guid":"1134aacc-ca52-6808-71e8-81c124383b6c","_uuid":"dad95f13117c42d4201a0c5b3356570f1ba73c61","trusted":false},"cell_type":"code","source":"# encode features\ndef encode_features(train_df, test_df, features):    \n    combined = pd.concat([train_df[features], test_df[features]])\n    \n    encoders = list()\n    for feature in features:\n        le = preprocessing.LabelEncoder()\n        le.fit(combined[feature])\n        train_df[feature] = le.transform(train_df[feature])\n        test_df[feature] = le.transform(test_df[feature])\n        encoders.append(le)\n    train_df = train_df.sort_values(\"PassengerId\")\n    test_df = test_df[['PassengerId'] + features].sort_values('PassengerId')\n    assert(len(encoders) == len(features))\n    return train_df, test_df, encoders\n       \ndata_train1, data_test1, encoders = encode_features(data_train1, data_test1, features=_features)\nprint(\"First 5 data_train out of {n}\".format(n=len(data_train1.values)))\nprint(data_train1.head(5))\nprint(\"First 5 data_test out of {n}\".format(n=len(data_test1.values)))\nprint(data_test1.head(5))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7d5a834c-e444-3a5a-eed9-03c5d2cf85c6","_uuid":"e7b8b194912e37b6a8e0050f49791ce01a3e970d"},"cell_type":"markdown","source":"Finally, with features being encoded, let's take a look at the [correlation of the features](http://www.statisticshowto.com/what-is-the-pearson-correlation-coefficient/) against Survival. It seems Sex is the most correlated, followed by Pclass and Fare. The least correlated are PassengerId and SibSp.\n\nWe need to keep in mind that the correlation of single feature against survival only scratches the top of the truth. Chances are survival is correlated to multiple features. We will see how they are different when you plot the feature importance of trained model and compare that with the single feature correlation."},{"metadata":{"_cell_guid":"6c276cad-154d-48ef-bc56-ce1f5d06028b","_uuid":"1ae90276754136fef9ab57a310c0f043ec6609cd","trusted":false},"cell_type":"code","source":"data_train1.corr().sort_values(by='Survived', axis=0, ascending=False).Survived","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0c74deb1-74f5-3911-a733-74ac120062a2","_uuid":"d7d2b06176145377383af869ee9012411541066b"},"cell_type":"markdown","source":"In the following training, I will use *GridSearchCV()* to help us run grid search on each model and each hyper-parameter combination. Under the hood of GridSearchCV() it partitions the training data into N folds and use N-1 folds for training and 1 fold for validation. \n\nI also need to separate the label (survived) from the features."},{"metadata":{"_cell_guid":"4aed8c5d-c490-0d34-86c7-bc4074768593","_uuid":"7b638d324b5ca01061439c1ef48a2d44e739c220","trusted":false},"cell_type":"code","source":"X_train1 = data_train1[_features]\ny_train1 = data_train1['Survived']\nprint(\"Total data train: {n}\".format(n=len(data_train1.values)))\nprint(\"First 3 X_train out of {n}\".format(n=len(X_train1.values)))\nprint(X_train1.head(3))\nprint(\"First 3 y_train out of {n}\".format(n=len(y_train1.values)))\nprint(y_train1.head(3))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f3f23a17-f973-7b67-0129-8fde1c6d5150","_uuid":"149a0901b3df7776590085f22cba5e2897f9a72e"},"cell_type":"markdown","source":"## Train SVM model\nHere I will train a SVM model on the training data. I specify a range for each of its hyper-parameters and use GridSearchCV (grid search with cross-validation) to find the best hyper-parameter combination. \n\nThe cross-validation splits training data into 5 folds."},{"metadata":{"_cell_guid":"a368843b-fdae-eba7-dbe9-acc6620e6033","_uuid":"d089bb9a312526dbde576f7b61c4c69bb013d2a5","trusted":false},"cell_type":"code","source":"# First let's try default hyper-parameters of SVM.\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom scipy.stats import randint as sp_randint\nfrom time import time\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.svm import LinearSVC\n\n\nX_svm_train, X_svm_test, y_svm_train, y_svm_test = train_test_split(X_train1, y_train1,\n                                                                    test_size=0.2, random_state=42)\nlsvc = LinearSVC()\nlsvc.fit(X_svm_train, y_svm_train)\ny_svm_predict = lsvc.predict(X_svm_test)\nprint(\"Default hyper-parameter. SVM accuracy = \", accuracy_score(y_svm_predict, y_svm_test))\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2105d75a-b060-5928-1270-2e16e60f663f","_uuid":"369a842cf88ce0ae477623b25719f6b7bab1252f","trusted":false},"cell_type":"code","source":"def get_best_estimator(estimator, param, X_train, y_train, verbose=0, n_jobs=1, cv=5):\n    \"\"\"Run grid search to get the best hyper-parameter set for the given estimator.\n    param is the map of various of hyper-parameters.\n    cv is an int to specify the number of folds for training.\n    \"\"\"\n    # Type of scoring used to compare parameter combinations\n    acc_scorer = make_scorer(accuracy_score)\n\n    grid_search = GridSearchCV(\n        estimator=estimator, \n        param_grid=param,\n        scoring=acc_scorer,\n        verbose=verbose,\n        cv=cv)\n\n    start = time()\n    grid_search.fit(X_train, y_train)\n    print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n          % (time() - start, len(grid_search.cv_results_['params'])))\n\n    # get the best hyper-param set and its score\n    return grid_search.best_estimator_, grid_search.best_score_","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3186e448-b9d7-519b-474f-7b9f5146de59","_uuid":"82d89cb35127de5db8150d4eb34a03c577c59d81","trusted":false},"cell_type":"code","source":"from sklearn.svm import LinearSVC\nlsvc_param = {\n    'C': np.logspace(-2, 2, 4),\n    'dual': [False],\n    'penalty': ['l1', 'l2']\n}\nlsvc, lsvc_accu = get_best_estimator(estimator=LinearSVC(), param=lsvc_param, X_train=X_train1, y_train=y_train1)\nprint(\"GridSearchCV found the best hyper-parameter set for LinearSVC:\\n{s}\\n\\n{r}\".format(\n    s=lsvc_accu, r=lsvc.get_params()))\n# re-train the model using the best hyper-param set on entire training set\nlsvc.fit(X_train1, y_train1)\n# test the model on test set\ny_submit_predict = lsvc.predict(data_test1[_features])\nsubmission = pd.DataFrame({\n        \"PassengerId\": data_test1[\"PassengerId\"],\n        \"Survived\": y_submit_predict\n    })\n#submission.to_csv('../output/submission.csv', index=False)\nsubmission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1a17c38-509b-bbe6-51ad-340f6c7cf4a3","_uuid":"19061ffbb44fbd044e9ef903c1607456fc300f77"},"cell_type":"markdown","source":"Without hyper-parameter tuning the SVM model gives us 77% accuracy. With tuning, its accuracy is improved to 78%. This is our baseline to improve our solution. The first time I want to check is if there are models that perform better. SVM model may have worse bias or variance than others.\n\n# Iteration #2: Model engineering\n\nI will run a spectrum of models using the same cross-validation technique. The models are: **Logistic Regression, KNN, Perceptron, SVC, Decision Tree, Rendom Forest, XGBoost**."},{"metadata":{"_cell_guid":"97acb807-952c-b65a-9442-acd95c1f6a79","_uuid":"2813d795c1132977e32efcb8b1f329dadad00c84"},"cell_type":"markdown","source":"## 1. LogReg"},{"metadata":{"_cell_guid":"f6e34a17-be4b-4a10-a9a5-8ec530615149","_uuid":"585f207511d4e43116a0ea690aeafac2fbac5450","trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# specify the ranges of hyper-parameters\nlogreg_param = {\n    #'penalty': ['l1', 'l2'],\n    'penalty': ['l2'],\n    #'C': np.logspace(-3, 4, 8),\n    'C': [1.0],\n}\nlogreg, logreg_accu = get_best_estimator(estimator=LogisticRegression(), param=logreg_param, X_train=X_train1, y_train=y_train1)\nprint(\"GridSearchCV found the best hyper-parameter set for LogReg:\\n{s}\\n\\n{r}\".format(\n    s=logreg_accu, r=logreg.get_params()))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8f22ade3-0400-9675-ec1d-d36dbee8cf30","_uuid":"4aec13b95c528c6f82e6e4bf5f68984b1c50d582"},"cell_type":"markdown","source":"## 2. Perceptron"},{"metadata":{"_cell_guid":"1179c095-099f-e9e5-89d7-83b072ea03b2","_uuid":"d4018420f3bd280f13b112730a987bb7ba79baaf","trusted":false},"cell_type":"code","source":"from sklearn.linear_model import Perceptron\n\n# specify the ranges of hyper-parameters\npercep_param = {\n    #'penalty': ['l1', 'l2', 'elasticnet'],\n    'penalty': ['l1'],\n    #'alpha': np.logspace(-5, 2, 8),\n    'alpha': [0.0001],\n    #'n_iter': np.arange(1,8),\n    'n_iter': [5]\n}\npercep, percep_accu = get_best_estimator(estimator=Perceptron(), param=percep_param, X_train=X_train1, y_train=y_train1)\nprint(\"GridSearchCV found the best hyper-parameter set for Percepton:\\n{s}\\n\\n{r}\".format(\n    s=percep_accu, r=percep.get_params()))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f8abcec3-88de-39ab-a470-151305b2977a","_uuid":"63593513280fef7e1c5b5520c7c634420d3959fc"},"cell_type":"markdown","source":"## 3. KNN"},{"metadata":{"_cell_guid":"ae1491e9-c024-6b60-9415-3593272e7af6","_uuid":"c76007f89f8194d429ecdca49776f7efc4f0c2c3","trusted":false},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_param = {\n    #'n_neighbors': np.arange(1, 10),\n    'n_neighbors': [5],\n    #'weights': ['uniform', 'distance'],\n    'weights': ['uniform'],\n    #'p': [1, 2],\n    'p': [1],\n}\nknn, knn_accu = get_best_estimator(estimator=KNeighborsClassifier(), param=knn_param, X_train=X_train1, y_train=y_train1)\nprint(\"GridSearchCV found the best hyper-parameter set for KNN:\\n{s}\\n\\n{r}\".format(\n    s=knn_accu, r=knn.get_params()))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9190f26d-a220-f4bb-9332-02ef879e0e77","_uuid":"cae2238ef9df926c32953b7ac56cab77acba6462"},"cell_type":"markdown","source":"## 4. SVC"},{"metadata":{"_cell_guid":"4684d66e-2475-1783-ef53-498bc7ffa7a7","_uuid":"45cba41b5d1fed1c2a59b311ca7b50314945726f","trusted":false},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc_param = {\n    #'C': np.logspace(-2, 2, 4),\n    'C': [4.6415888336127775],\n    #'kernel': ['rbf', 'linear'],\n    'kernel': ['rbf'],\n}\nsvc, svc_accu = get_best_estimator(estimator=SVC(), param=svc_param, X_train=X_train1, y_train=y_train1)\nprint(\"GridSearchCV found the best hyper-parameter set for SVC:\\n{s}\\n\\n{r}\".format(\n    s=svc_accu, r=svc.get_params()))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b47f7c66-26c6-0086-2421-2f033a636baa","_uuid":"130d940f29163680ff58661e7753d6481d239271"},"cell_type":"markdown","source":"## 5. DecisionTree"},{"metadata":{"_cell_guid":"24429550-4e13-adcd-8678-31f93a2225c4","_uuid":"043483f48fe8f94069585509faa85fd375cb460d","trusted":false},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ntree_param = {\n    #'criterion': ['gini', 'entropy'],\n    'criterion': ['entropy'],\n    #'splitter': ['best', 'random'],\n    'splitter': ['best'],\n    #'max_features': [None, 'sqrt', 'log2'],\n    'max_features': [None],\n}\n\ntree, tree_accu = get_best_estimator(estimator=DecisionTreeClassifier(), param=tree_param, X_train=X_train1, y_train=y_train1)\nprint(\"GridSearchCV found the best hyper-parameter set for DecisionTreeClassifier:\\n{s}\\n\\n{r}\".format(\n    s=tree_accu, r=tree.get_params()))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"442eb6cc-c26f-1e7b-4956-707c907877d0","_uuid":"c04eb0676e6a617d13b3359fc3c8a444caa27320"},"cell_type":"markdown","source":"## 6. RandomForestClassifier"},{"metadata":{"_cell_guid":"f6b2fd45-99d8-5176-29c1-175568281d28","_uuid":"b24b6729a312c66d9586ee81d0b21b08ff2a233b","trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf_param = {\n    #'n_estimators': np.arange(5, 15, 1),\n    'n_estimators': [11],\n    'criterion': ['gini', 'entropy'],\n    'max_features': [None, 'sqrt', 'log2'],\n}\n\nrf, rf_accu = get_best_estimator(estimator=RandomForestClassifier(), param=rf_param, X_train=X_train1, y_train=y_train1)\nprint(\"GridSearchCV found the best hyper-parameter set for RandomForestClassifier:\\n{s}\\n\\n{r}\".format(\n    s=rf_accu, r=rf.get_params()))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2cfa25e1-13c3-4869-7c12-2b0f54581a00","_uuid":"c5962baba990632533d74b0a315f491575831557"},"cell_type":"markdown","source":"## 7. XGBoost"},{"metadata":{"_cell_guid":"c4b24788-8336-e056-a89a-911dcf31c285","_uuid":"9adeb74dd4ddb1d822804c76ff34d8998255c45c","trusted":false},"cell_type":"code","source":"# running the grid search on XGBoost takes long time. \n# I commented the ranges and set the best paramters learned.\nxgb_param = {\n    #'max_depth': np.arange(4, 10, 1),\n    'max_depth': [4],\n    #'learning_rate': np.logspace(-4, 1, 20),\n    'learning_rate': [0.88586679041008232],\n    #'n_estimators': np.arange(15, 16, 1),\n    'n_estimators': [15],\n    #'gamma': np.logspace(-4, 1, 20)\n    'gamma': [2.9763514416313193]\n}\nxgb1, xgb_accu = get_best_estimator(estimator=XGBClassifier(), param=xgb_param, X_train=X_train1, y_train=y_train1, verbose=1, n_jobs=4)\nprint(\"GridSearchCV found the best hyper-parameter set for XGBClassifier:\\n{s}\\n\\n{r}\".format(\n    s=xgb_accu, r=xgb1.get_params()))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"da7e3a11-5271-fed6-a179-4071148fe2e9","_uuid":"b382bb59c7448358d615a678dcfc966eb78b1b9e"},"cell_type":"markdown","source":"Overall, the XGBoost model achieved the best performace."},{"metadata":{"_cell_guid":"973377b8-2aa3-ce12-350e-4e7293ab9336","_uuid":"7fd409df9508b779c6c50af206c0ba530646a4be","trusted":false},"cell_type":"code","source":"m = pd.DataFrame({\n    'Model': ['SVC', 'KNN', 'Logistic Regression', \n              'Random Forest', 'XGBoost', 'Perceptron', \n              'Linear SVC', 'Decision Tree'],\n    'Score': [svc_accu, knn_accu, logreg_accu, \n              rf_accu, xgb_accu, percep_accu, \n              lsvc_accu, tree_accu]})\nm.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a36cd95d-aade-3de5-f817-911f02c7a198","_uuid":"e4a5575f14d87fb87b864935e1b01d88ed55cbf0"},"cell_type":"markdown","source":"I want to have a better understanding of the trained XBGoost model. Here I output its feature importance. The feature importance means how importance a feature is when the sub-trees split. \n\nIt looks like *Age, Fare* are most important. *Embarked* is the least."},{"metadata":{"_cell_guid":"183a833e-7196-f84d-fa67-b5cb6aadf0d9","_uuid":"89e9af07378ee4e63e8fb65d020c42e1f4276a61","trusted":false},"cell_type":"code","source":"from xgboost import plot_importance as xgb_plot_imp, plot_tree as xgb_plot_tree\n_, ax = plt.subplots(1, 1, figsize=(7, 7))\n_ = xgb_plot_imp(booster=xgb1, ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"df9d94b4-122f-8d0c-afa5-282608691198","_uuid":"43ba27e01f79ec7aa3baa91a08e73aac3da00060"},"cell_type":"markdown","source":"We can sample a tree of the GBDT model to see how the scores are calculated based on features. To better understand the tree graph, I also print out feature code -> feature name. \n\nWe can see that in this tree, the highest score path is: **Sex<1 & Pclass>=2 & Age>=1 & Age<2**. This means Pclass 2 or Pclass 3 female baby has the highest survival odds. \nThe lowest score path is **Sex<1 & Pclass>=2 & Age<1**. This means Pclass 3 female Adult. \n\nAgain this is just one of the 15 trees in GBDT model. It only focuses on some part of the features. The overall score is from each of the 15 trees.\n\nCompared with single feature correlation we found Age gets more wrights in the model."},{"metadata":{"_cell_guid":"0d31a771-edf4-f8fb-9d92-6ea4c6baa5f1","_uuid":"eba381fbd8d95f9faa7454337bbd10e3005c0a1a","trusted":false},"cell_type":"code","source":"_, ax = plt.subplots(1, 1, figsize=(12, 12))\n_ = xgb_plot_tree(booster=xgb1, num_trees=1, ax=ax)\nsex_coder = encoders[_features.index(\"Sex\")]\nprint(list(zip(sex_coder.classes_, sex_coder.transform(sex_coder.classes_))))\npclass_coder = encoders[_features.index(\"Pclass\")]\nprint(list(zip(pclass_coder.classes_, pclass_coder.transform(pclass_coder.classes_))))\nage_coder = encoders[_features.index(\"Age\")]\nprint(list(zip(age_coder.classes_, age_coder.transform(age_coder.classes_))))\ncabin_coder = encoders[_features.index(\"Cabin\")]\nprint(list(zip(cabin_coder.classes_, cabin_coder.transform(cabin_coder.classes_))))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b057caf0-ecd4-c86c-c112-b8ff3e807938","_uuid":"685167cf76c817d06ac43db7d34c3dc04edfe46d","trusted":false},"cell_type":"code","source":"# xgb1 was trained on 80% of training data (using cv)\n# now retrain on the entire traning data.\nxgb1.fit(X_train1, y_train1)\ny_submit_predict = xgb1.predict(data_test1[_features])\nsubmission = pd.DataFrame({\n        \"PassengerId\": data_test1[\"PassengerId\"],\n        \"Survived\": y_submit_predict\n    })\n#submission.to_csv('../output/submission.csv', index=False)\nsubmission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eef1f3d87110d08232ff8fb64bbb7cbf4d353f1b"},"cell_type":"code","source":"submission.loc[submission['PassengerId'] == 1116]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d5f728ca-6c4f-ec27-8374-02ae496236ff","_uuid":"1740b6c48006389fdf607c76ba99450d8c4c17f2","trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_dbg_train, X_dbg, y_dbg_train, y_dbg = train_test_split(X_train1, y_train1,\n                                                          test_size=0.2, random_state=42)\n\nxgb1.fit(X_dbg_train, y_dbg_train)\ny_predict = xgb1.predict(X_dbg)\nall_predictions = zip(y_dbg.index.tolist(), y_dbg.tolist(), y_predict.tolist())\n# Let's look at false negative: those who survived but model says they died\nfalse_predictions = [t[0] for t in all_predictions if (t[1] == 1 and t[2] == 0)]\n\ndata_train.loc[data_train.index.isin(false_predictions)].loc[data_train.Sex == \"male\"].head(1)","execution_count":null,"outputs":[]}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}