{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"input_dir = '../input/'\n\ntrain_csv = pd.read_csv(input_dir + 'train.csv')\ntrain_csv.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20aa58ac681aebbae6c4b5f4554161960d52bbff"},"cell_type":"code","source":"train_csv.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37f9a83d778ac76eabe0309be390646a9f653b44"},"cell_type":"code","source":"train_csv.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a2711e5d501385e8d0fd3e79ac46bb890d47c41"},"cell_type":"code","source":"for col in train_csv.columns:\n    print(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff5bc0000fc9264658389b404f387306c04ddb47"},"cell_type":"code","source":"unique_count_df = pd.Series()\nfor col in train_csv.columns:\n    unique_count_df[col] = len(train_csv[col].unique())\nunique_count_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3636aba7883cb92c39e1548d4db498f12eec985"},"cell_type":"code","source":"train_csv.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e4a6c4ac55d39c72a46c87a5cc19b08522da125"},"cell_type":"code","source":"train_csv['Cabin'].str[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a519035509e35c5bfcd5301176fcb161482b65a0"},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6467044afd3068b72495bd4c47af629097593919","collapsed":true},"cell_type":"code","source":"def split_data(df: pd.DataFrame):\n    df_shuffled = df.sample(frac=1).reset_index(drop=True)\n    num_rows = df.shape[0]\n    num_rows_train_data = int(num_rows * 0.8)\n\n    train_data = df_shuffled[:num_rows_train_data]\n    val_data = df_shuffled[num_rows_train_data:]\n    \n    return (train_data, val_data)\n\ndef input_fn(df: pd.DataFrame, labels, batch_size: int, num_epochs: int):\n    if labels is None:\n        input = df.to_dict(orient='series')\n    else:\n        input = (df.to_dict(orient='series'), labels)\n    dataset = tf.data.Dataset.from_tensor_slices(input)\n    return dataset.shuffle(buffer_size=10000).repeat(count=num_epochs).batch(batch_size)\n\ndef eval_input_fn(df: pd.DataFrame, labels):\n    if labels is None:\n        input = df.to_dict(orient='series')\n    else:\n        input = (df.to_dict(orient='series'), labels)\n    dataset = tf.data.Dataset.from_tensor_slices(input)\n    return dataset.batch(128)\n\ndef embedding_dimension(unique_count):\n    return min(50, unique_count // 2)\n\ndef define_feature_columns(df: pd.DataFrame, numeric_columns, categorical_columns):\n    feature_columns = []\n    for col in df.columns:\n        if col in categorical_columns:\n            sorted_unique_values = sorted(set(list(df[col].unique()) + ['']))\n            cat_col = tf.feature_column.categorical_column_with_vocabulary_list(key=col, vocabulary_list=sorted_unique_values)\n            embedding_dim = embedding_dimension(len(sorted_unique_values))\n            if embedding_dim <= 2:\n                feature_columns.append((col, tf.feature_column.indicator_column(cat_col)))\n            else:\n                feature_columns.append((col, tf.feature_column.embedding_column(cat_col, embedding_dim)))\n        elif col in numeric_columns:\n            feature_columns.append((col, tf.feature_column.numeric_column(key=col)))\n            isnull_col_name = col + 'IsNull'\n            feature_columns.append((isnull_col_name, tf.feature_column.numeric_column(key=isnull_col_name)))\n    return dict(feature_columns)\n\ndef feature_preprocess(df: pd.DataFrame, numeric_columns, categorical_columns, col_mean, col_stddev):\n    processed = pd.DataFrame()\n    processed['PassengerId'] = df['PassengerId']\n    \n    for col_name in numeric_columns:\n        processed[col_name] = (df[col_name].astype(float) - col_mean[col_name]) / col_stddev[col_name]\n        isnull_col_name = col_name + 'IsNull'\n        processed[isnull_col_name] = df[col_name].isnull()\n        processed.loc[processed[isnull_col_name], col_name] = 0\n        processed[isnull_col_name] = processed[isnull_col_name].astype(np.int8)\n        \n    for col_name in categorical_columns:\n        processed[col_name] = df[col_name].copy().astype(str)\n        processed.loc[df[col_name].isnull(), col_name] = ''\n    \n    return processed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b166b1718c26c1366a8eb220bf545ca6e92e16f"},"cell_type":"code","source":"input_dir = '../input/'\n\ntrain_csv = pd.read_csv(input_dir + 'train.csv')\ntest_csv = pd.read_csv(input_dir + 'test.csv')\n\ntrain_csv['Deck'] = train_csv['Cabin'].str[0]\ntest_csv['Deck'] = test_csv['Cabin'].str[0]\n\ntrain_data, val_data = split_data(train_csv)\nprint(train_data.shape, val_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"548620b851805a20649d5f18de09f34a8cd8b97f","scrolled":true},"cell_type":"code","source":"numeric_columns = ['Age', 'SibSp', 'Parch', 'Fare']\ncategorical_columns = ['Pclass', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Deck']\n\ncol_mean = train_data[numeric_columns].mean()\ncol_stddev = train_data[numeric_columns].std()\n\ndef feature_preprocess_1(df: pd.DataFrame):\n    return feature_preprocess(df, numeric_columns=numeric_columns, categorical_columns=categorical_columns, col_mean=col_mean, col_stddev=col_stddev)\n\ntrain_features = feature_preprocess_1(train_data)\nval_features = feature_preprocess_1(val_data)\n\nprint(train_features.head())\n\nfeature_columns = define_feature_columns(\n    train_features,\n    numeric_columns=numeric_columns,\n    categorical_columns=categorical_columns)\n\nclassifier = tf.estimator.DNNClassifier(\n    feature_columns=list(feature_columns.values()),\n    hidden_units=[64, 32, 16],\n    n_classes=2,\n    dropout=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ab5b8d71a478afab91e12254d8962e5c6621298","scrolled":true},"cell_type":"code","source":"classifier.train(input_fn=lambda: input_fn(train_features, train_data['Survived'], batch_size=64, num_epochs=500))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b8eaa7d52d809eb272f2cd2d08490d1315f3c7b","scrolled":false},"cell_type":"code","source":"classifier.evaluate(input_fn=lambda: eval_input_fn(val_features, val_data['Survived']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8d95d141553d602c9e6088a1b9130ba67386444","scrolled":false},"cell_type":"code","source":"submit_data = feature_preprocess_1(test_csv)\n\npredictions = classifier.predict(input_fn=lambda: eval_input_fn(submit_data, None))\npredictions = list(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e3b183241773b632c51e58768a5339de3969842"},"cell_type":"code","source":"submit_output_csv = pd.DataFrame({'PassengerId': submit_data['PassengerId'], 'Survived': [x['class_ids'][0] for x in predictions]})\nsubmit_output_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07309da966d540db0814b5fe219d5b2ff4c72ed1"},"cell_type":"code","source":"submit_output_csv.to_csv('submit_output_1.csv', index=False)\nsubmit_output = pd.read_csv('submit_output_1.csv')\nsubmit_output.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"37ffe4d5fccf4ce386b7d76d3fdf8627fae57814"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}