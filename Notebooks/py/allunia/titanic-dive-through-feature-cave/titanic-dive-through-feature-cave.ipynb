{"cells":[{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7d88cd03cd29ecf24a5fd7f78b8702368663bceb"},"cell_type":"markdown","source":"## Welcome Kaggler!\n\nWith this interactive diving course I invite you to learn some machine learning basics. This course is designed as a series of kernels that guides you through different topics and hopefully you can discover some hidden treasures that push you forward on your data science road. You don't have to pick the courses in sequence if you are only interested in some topics that are covered. If you are new I would recommend you to take them step by step one after another. ;-)\n\nJust fork the kernels and have fun! :-)\n\n* [Prepare to start](https://www.kaggle.com/allunia/titanic-dive-through-prepare-to-start): Within this kernel we will prepare our data such that we can use it to proceed. Don't except nice feature selection or extraction techniques here because we will stay as simple as possible. Without a clear motivation we won't change any features. Consequently we are only going to explore how to deal with missing values and how to turn objects to numerical values. In the end we will store our prepared data as output such that we can continue working with it in the next kernel.\n* [MyClassifier](https://www.kaggle.com/allunia/titanic-dive-through-myclassifier): Are you ready to code your own classifier? Within this kernel you will build logistic regression from scratch. By implementing the model ourselves we can understand the assumptions behind it. This knowledge will help us to make better decisions in the next kernel where we will use this model and build some diagnosis tools to improve its performance.\n* **The feature cave**: By using our own logistic regression model we will explore how we can improve by adding a bias term and why we should encode categorical features. \n* [Feature scaling and outliers](https://www.kaggle.com/allunia/titanic-dive-through-feature-scaling-and-outliers): Why is it important to scale features and to detect outliers? By analyzing the model structure we will discover how our gradients and our model performance are influenced by these topics. "},{"metadata":{"_uuid":"3d4e4f4c4411d396fec1965a48b07f6374d9d0c2"},"cell_type":"markdown","source":"## Get your equipment\n...\n\nTitanic! \n...\n\nWe are on the way to your wrack!\n...\n\nWith our own classifier at hand we are now able to analyse every step we take while playing with our data. But before doing so, let's get our equipment:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"We will use the prepared data we made during the first course:"},{"metadata":{"trusted":true,"_uuid":"92d1c216a0c5d4abd080ea961ebcf525daeb459d","collapsed":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d57604438b3ee9fcc451e3ea3627ac13ef781084","collapsed":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/titanicdivethrough/prepared_train.csv\", index_col=0)\ntest = pd.read_csv(\"../input/titanicdivethrough/prepared_test.csv\", index_col=0)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3469727e03b6ed19082bd323cd8517d8695f0c9b"},"cell_type":"markdown","source":"And of course we will use our own classifier we build during the second course: "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f477a5ab0d8e9be09f6bb76a62c7419fb078848b"},"cell_type":"code","source":"class MyClassifier:\n    \n    def __init__(self, n_features):\n        self.n_features = n_features\n        np.random.seed(0)\n        self.w = np.random.normal(loc=0, scale=0.01, size=n_features)\n        self.losses = []\n    \n    def predict(self, x):\n        y = sigmoid(np.sum(self.w*x, axis=1))\n        return y\n    \n    def loss(self, y, t):\n        E = - np.sum(t * np.log(y) + (1-t) * np.log(1-y))\n        return E\n        \n    def gradient(self, x, y, t):\n        grad = np.zeros(self.w.shape[0])\n        for d in range(self.w.shape[0]):\n            grad[d] = np.sum((y-t)*x[:, d])\n        return grad\n        \n    def update(self, eta, grad):\n        w_next = np.zeros(self.w.shape) \n        for d in range(self.w.shape[0]):\n            w_next[d] = self.w[d] - eta * grad[d]\n        return w_next\n    \n    def learn(self, x, t, eta, max_steps, tol):\n        y = self.predict(x)\n        for step in range(max_steps):\n            error = self.loss(y, t)\n            grad = self.gradient(x, y, t)\n            self.w = self.update(eta, grad)\n            self.losses.append(error)\n            y = self.predict(x)\n            error_next = self.loss(y, t)\n            if (error - error_next) < tol:\n                break\n                \n    def decide(self, y):\n        decision = np.zeros(y.shape)\n        decision[y >= 0.5] = 1\n        decision[y < 0.5] = 0\n        return decision.astype(np.int)\n    \n    def accuracy(self, y, t):\n        N = y.shape[0]\n        return 1/N * np.sum(1 - np.abs(t-y))\n        \n    def score(self, x, t):\n        y = self.predict(x)\n        y = self.decide(y)\n        return self.accuracy(y, t)\n\ndef sigmoid(x):\n    result = 1/(1+np.exp(-x))\n    return result","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06246e3ce76e267702ae2f667d90ea1884fb5fee"},"cell_type":"markdown","source":"Now, we are ready to dive! ;-)"},{"metadata":{"_uuid":"3d30862dc9f38168fa1cf1323805057db9a4464d"},"cell_type":"markdown","source":"## Station 1 - Validation\n\nSo far, we haven't thought about the topic \"how to measure the performance\" of our model. In the last course we used the accuracy score, namely the percentage of right predictions, solely based on the train set. Consequently we can only say: \"We learned how to make more or less good predictions for the passengers in the train set\". Instead we would like to estimate how good our model makes predictions on unseen data. Thus it would be great to split our data into a train and validation set. By looking at the performance on the validation set we can adjust our strategies such that we find an optimal solution for unknown data. But of course this is again some kind of \"fitting\" and the validation data becomes part of the training as well. For this reason we need a third data set where we can measure the final performance of our model: the test data. In our case the test data is already given by the competition. But the validation data is still missing.\n\nDo generate it we will use [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) from scikit-learn (sklearn), an opensource tool for data science and machine learning.   "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9064545c6f70a2f83f10436c881a1f52dcbb1f3d"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nfeatures = train.drop([\"PassengerId\", \"Survived\"], axis=1).columns\n\nX = train[features].values\nY = train.Survived.values\n\nx_train, x_val, t_train, t_val = train_test_split(X, Y, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2b95178afbdc117ed2db9f45ec18679f0ceaa42"},"cell_type":"markdown","source":"Let's see how good our model is on the train and validation set. "},{"metadata":{"trusted":true,"_uuid":"f289cc0e06c90946af83d9c79e59ad6efd34f47a","collapsed":true},"cell_type":"code","source":"# your task: call the score method to find out how well your model performs \n# on the train and validation data\nclassifier = MyClassifier(x_train.shape[1])\nclassifier.learn(x_train, t_train, 0.000001, 100000, 0.00001)\n#train_score = <your code>\n#test_score = <your code>","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"051abe9e53a0236508a7532f8d763ffad60d69e3"},"cell_type":"code","source":"#assert(np.round(train_score, 4) == 0.7994)\n#assert(np.round(test_score, 4) == 0.7803)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"23c349a0a65bf2dd8936e8226785b3f2d6657232"},"cell_type":"markdown","source":"Luckily our predictions are similar good on the train and validation set and we will proceed to measure our performance this way until we run into problems. Let's check if the train loss converged to a minimum during our learning procedure:"},{"metadata":{"trusted":true,"_uuid":"a7c00587a757f393ba57135461056c707940f951","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.plot(classifier.losses)\nplt.xlabel(\"Iteration steps\")\nplt.ylabel(\"cross entropy loss\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ba1cb35816a7a7b328f225c1b7275275351e698"},"cell_type":"markdown","source":"That's ok for us. We don't expect the classifier to be much better with more iteration steps. "},{"metadata":{"_uuid":"be9d7e92573edca14d11cd069c6996dc979537ea"},"cell_type":"markdown","source":"## Station 2 - The bias term\n\nThe example submission we have given is based just on one feature: the sex. The submission predicts \"not survived - 0\" if the passenger was a male and \"survived - 1\" otherwise. Let's perform an experiment and make predictions with our model solely on this feature. "},{"metadata":{"trusted":true,"_uuid":"62be34359c5faed4f30a0d4f1b9bc576b51b5685","collapsed":true},"cell_type":"code","source":"x_sex_train = x_train[:, 1].reshape(-1,1)\nx_sex_val = x_val[:, 1].reshape(-1,1)\n\nclassifier = MyClassifier(1)\nclassifier.learn(x_sex_train, t_train, 0.000001, 100000, 0.00001)\nprint(classifier.score(x_sex_train, t_train))\nprint(classifier.score(x_sex_val, t_val))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b7552137b3174dad7205e2c955f174cac3aace7"},"cell_type":"markdown","source":"Ok, now let's have a look if we would directly pass 0 for males and 1 for females:"},{"metadata":{"trusted":true,"_uuid":"11bd0a5cc0deb9d899d6f7f36804bc009fe861ab","collapsed":true},"cell_type":"code","source":"classifier.accuracy(x_val[:,1], t_val)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"558683dc87bfe0206ee66eca0b564d88c6a27a41"},"cell_type":"markdown","source":"Obviously our model is much worst than the example submission even if we use the sex feature alone. Something is wrong here!  Let's have a look at the predictions our model can make after learning:"},{"metadata":{"trusted":true,"_uuid":"bb62825d9c1987cf64bfa579bc3fc10914a27e67","collapsed":true},"cell_type":"code","source":"predictions = classifier.predict(x_sex_train)\n# It's your turn now: Plot the survival probabilites given by the predictions our classifier made:\nplt.figure(figsize=(15,4))\n#<your code>\nplt.xlabel(\"predicted survival probability\")\nplt.ylabel(\"frequency\")\nplt.title(\"Distribution of predictions\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24879c9bef3b71b4ecff8f86a261a23f5a5b5e88"},"cell_type":"markdown","source":"What do you observe? The predicted probability is always >= 0.5. Consequently our model always predicts that the passengers survived. To understand why that happened, look closer at the prediction function we used:\n\n$$ y = \\sigma (w_{sex} \\cdot x_{sex}) $$\n\nThis sum has vanished as we only use one feature. Given a male we would have $x_{sex} = 0$ and in this case $y$ would always yield 0.5 due to the sigmoid function. This is of course not what we want. To overcome this problem we need a term that enables us to shif the sigmoid function such that we can map some other value than $x=0$ to $y=0.5$. This can be done by including the so called bias term:\n\n$$ y = \\sigma(w_{sex} \\cdot x_{sex} + w_{bias})$$\n\nThis course already provides a skeleton for an improved classifier. It's your turn now! Add a bias parameter to self.w and adjust the method to make predictions and to compute the gradients. "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"27b59ee24fdeaf9c9a4b4d6a554c806e35c04504"},"cell_type":"code","source":"class ImprovedClassifier(MyClassifier):\n    \n    def __init__(self, n_features):\n        super().__init__(n_features)\n        np.random.seed(0)\n        self.w = np.random.normal(loc=0, scale=0.01, size=n_features + 1)\n    \n    def predict(self, x):\n        # your task: replace the compuation of y by including the bias term self.w[-1] * 1\n        y = sigmoid(np.sum(self.w[:-1]*x, axis=1))\n        return y\n        \n    def gradient(self, x, y, t):\n        grad = np.zeros(self.w.shape[0])\n        for d in range(self.w.shape[0]):\n            if d == self.n_features:\n                # replace the computation of the gradient of E with respect to the bias term\n                grad[d] = 0\n            else:\n                grad[d] = np.sum((y-t)*x[:, d])\n        return grad","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca55518ebce5b212599276e25024e7f5ed7174cb","collapsed":true},"cell_type":"code","source":"iclassifier = ImprovedClassifier(1)\niclassifier.learn(x_sex_train, t_train, 0.000001, 100000, 0.00001)\ntrain_score = iclassifier.score(x_sex_train, t_train)\nval_score = iclassifier.score(x_sex_val, t_val)\nprint(\"train accuracy: %f , validation accuracy: %f\" %(train_score, val_score) )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a573566a71b499c995aa03dc3664211dde68f98"},"cell_type":"markdown","source":"After your improvement the model is as good as if we would directly pass \"0 for males\" and \"1 for females\":"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8e61f59ade55b2e2b79f4342145d615933177c5b"},"cell_type":"code","source":"#assert(train_score == iclassifier.accuracy(x_train[:,1], t_train))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d13ef62c6336521f741390f2523310665a158e44"},"cell_type":"markdown","source":"## Station 2 - Categorical features\n\nIn the last section we have already seen that we have to take care about our sigmoid function. By playing with a binary categorical feature we have seen that we need to introduce a bias term to shift the sensitive region close to zero of the sigmoid function. But what about categorical features with more than two values? Let's have a look at the Embarked feature:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bfd119c224c5183e622a395d90e07dc24f1f994d"},"cell_type":"code","source":"train_df = pd.DataFrame(x_train, columns=features)\nval_df = pd.DataFrame(x_val, columns=features)\ntrain_df[\"Survived\"] = t_train","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"011ec7ca38e36c46e93dede89072fafbcf9b69cb"},"cell_type":"markdown","source":"Let's pass only the Embarked feature to train our model and have a look at the predictions we can make this way:"},{"metadata":{"trusted":true,"_uuid":"33f6f379251795b3a92ca82ba30579e85215e478","collapsed":true},"cell_type":"code","source":"x_embarked_train = train_df.Embarked.values.reshape(-1,1)\nx_embarked_val = val_df.Embarked.values.reshape(-1,1)\n\niclassifier = ImprovedClassifier(1)\niclassifier.learn(x_embarked_train, t_train, 0.000001, 100000, 0.00001)\ntrain_score = iclassifier.score(x_embarked_train, t_train)\nval_score = iclassifier.score(x_embarked_val, t_val)\npredictions_proba = iclassifier.predict(x_embarked_train)\npredictions = iclassifier.decide(predictions_proba)\n\nprint(\"train accuracy: %f , validation accuracy: %f\" %(train_score, val_score))\n\ntrain_df[\"predictions_proba\"] = np.round(predictions_proba, 2)\ntrain_df[\"predictions\"] = predictions","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"957b7b7b3b755e8ea9aa0127e2637b042e66cad2"},"cell_type":"markdown","source":"If you have done the bias term station right, you should see:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"63e340a93b09d34d46cfac1afbc348ab662ee82e"},"cell_type":"code","source":"#assert(np.round(train_score, 4) == 0.6138)\n#assert(np.round(val_score, 4) == 0.6233)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c484f1311b874dee43b6566e22d88e40a96eb9d5","collapsed":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,4, figsize=(20,5))\nsns.countplot(train_df.Embarked, ax=ax[0])\nax[0].set_title(\"Embarkation counts\")\nsns.countplot(x=\"Embarked\", hue=\"Survived\", data=train_df, ax=ax[1])\nax[1].set_title(\"True Survival\")\nsns.countplot(x=\"Embarked\", hue=\"predictions\", data=train_df, ax=ax[2])\nax[2].set_title(\"Predicted Survival\")\nsns.countplot(x=\"Embarked\", hue=\"predictions_proba\", data=train_df, ax=ax[3])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12f7e746e6ee7c12584359a0b01db060a1ba9fe0"},"cell_type":"markdown","source":"The decisions of our model for embarkation of value zero and two are ok as more passengers in those cases died. But what about embarkation with value one? In this case our model should predict that the passengers survived even though the true distribution shows only slightly differences. \n\nBy considering the bahaviour of the sigmoid function, can you explain what went wrong?\n\n...\n\nWhat would have happend if we would change the original map of:\n\n```python\nembarked_map = {\"S\": 0, \"C\": 1, \"Q\": 2}\n```\n\nto\n\n```python\nembarked_map = {\"S\": 0, \"C\": 2, \"Q\": 1}\n```\n?\n\nBy choosing numerical values we already assumed some kind of order that has to fit to our target variables. That's bad! Let's solve this problem by assigning binary values to each property per categorical variable:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e29191d29810c437abdae7acd1175b36ffbf14fa"},"cell_type":"code","source":"train_df[\"S\"] = train_df.Embarked.apply(lambda l: np.where(l==0, 1, 0))\ntrain_df[\"C\"] = train_df.Embarked.apply(lambda l: np.where(l==1, 1, 0))\ntrain_df[\"Q\"] = train_df.Embarked.apply(lambda l: np.where(l==2, 1, 0))\nval_df[\"S\"] = val_df.Embarked.apply(lambda l: np.where(l==0, 1, 0))\nval_df[\"C\"] = val_df.Embarked.apply(lambda l: np.where(l==1, 1, 0))\nval_df[\"Q\"] = val_df.Embarked.apply(lambda l: np.where(l==2, 1, 0))\n\ntrain_df.drop(\"Embarked\", axis=1, inplace=True)\nval_df.drop(\"Embarked\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3fe1e0cd741f7a5076792d6b05ce50dca28ae28","collapsed":true},"cell_type":"code","source":"x_embarked_train = train_df[[\"S\", \"C\", \"Q\"]].values\nx_embarked_val = val_df[[\"S\", \"C\", \"Q\"]].values\n\niclassifier = ImprovedClassifier(x_embarked_train.shape[1])\niclassifier.learn(x_embarked_train, t_train, 0.000001, 100000, 0.00001)\ntrain_score = iclassifier.score(x_embarked_train, t_train)\nval_score = iclassifier.score(x_embarked_val, t_val)\npredictions_proba = iclassifier.predict(x_embarked_train)\npredictions = iclassifier.decide(predictions_proba)\n\nprint(\"train accuracy: %f , validation accuracy: %f\" %(train_score, val_score))\n\ntrain_df[\"predictions_proba\"] = np.round(predictions_proba, 2)\ntrain_df[\"predictions\"] = predictions","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e1bfe2317c0d69e8bc1fa37d7bcce790e99a244f"},"cell_type":"markdown","source":"If you have done the bias-term station right, you should see:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"023450aada06c233e7a5c3e59c1d4d185643dd78"},"cell_type":"code","source":"#assert(np.round(train_score, 4) == 0.6287)\n#assert(np.round(val_score, 4) == 0.6592)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f5338579a55d44e3f5b37fd473fa2d97624c031"},"cell_type":"markdown","source":"Using binary representations per property of embarkation we improved!!! :-) \n\n**This way we made sure that we don't introduce an order of survival by passing the numerical values of a categorical feature through the sigmoid function.**\n\nOur improvement should turn passengers that embarked in Cherbourg from \"not survived - 0\" to \"survived - 1\". Let's check this:"},{"metadata":{"trusted":true,"_uuid":"96bdfcf43c109c769ed841c9a52df6aecca3ad59","collapsed":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,3,figsize=(15,4))\nsns.countplot(x=\"C\", hue=\"Survived\", data=train_df, ax=ax[0])\nax[0].set_title(\"True Survival\")\nsns.countplot(x=\"C\", hue=\"predictions\", data=train_df, ax=ax[1])\nax[1].set_title(\"Predicted Survival\")\nsns.countplot(x=\"C\", hue=\"predictions_proba\", data=train_df, ax=ax[2])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f60ad98f383874bc75c968dd6d489b32818e4c5"},"cell_type":"markdown","source":"Yup! :-)\n\nNow, it's your turn: Use binary representation for all remaining categorical features in our data sets! \nEven though there are opensource solutions out there let's use our own encoder that is build on the procedure we used before:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e8f6f799942a3a30d13d61a06634c3f38062fdf4"},"cell_type":"code","source":"class MyEncoder:\n    \n    def __init__(self, features):\n        self.features = features\n        self.feature_levels = []\n    \n    def fit(self, df):\n        for feature in self.features:\n            levels = df[feature].unique()\n            self.feature_levels.append(levels)\n    \n    def transform(self,df):\n        for f in range(len(self.features)):\n            feature = self.features[f]\n            levels = self.feature_levels[f]\n            for level in levels:\n                new_name = feature + \"_\" + str(level)\n                df[new_name] = df[feature].apply(lambda l: np.where(l==level, 1, 0))\n        return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a1a35ca8f0f802e38a43c538509c38b8a2ec2f22"},"cell_type":"markdown","source":"To make sure that we don't miss any property per categorical feature of train and test, we should fit our encoder on the combined data set and transform train and test separately:"},{"metadata":{"trusted":true,"_uuid":"e4bf131a3b714837002376b6a1cc1d3b53abbdb8","collapsed":true},"cell_type":"code","source":"combined = train.drop(\"Survived\", axis=1).append(test)\ncombined.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebac35012e4b1cc0c5269faadf79f90013748226","collapsed":true},"cell_type":"code","source":"to_encode = [\"Embarked\"] # put your categorical features into the list!!!\nencoder = MyEncoder(to_encode)\nencoder.fit(combined)\ntrain = encoder.transform(train)\ntest = encoder.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5601ba2bc868e75a8aa6569ab3dc2cc48d14db9"},"cell_type":"markdown","source":"If you are not sure taking one feature or not, try:\n\n```python\nsns.countplot(x=featuretotry, hue=\"Survived\", data=train)\n```\n\nDoes the order of the numerical values fit to the target and predictions you would obtain by passing through sigmoid? Hint: There are more than Embarked! ;-)"},{"metadata":{"_uuid":"cd371a22980d615798757e56f5842620e7f94572"},"cell_type":"markdown","source":"After extracting the new features clean your data and drop the old ones:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"af9c7a80097820bbf821f5aa933b2af04f4b72ed"},"cell_type":"code","source":"for feature in to_encode:\n    train.drop(feature, axis=1, inplace=True)\n    test.drop(feature, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64e546b3e29e9710cc397b2c3a7c837e80b904b8"},"cell_type":"markdown","source":"For the next stattion, make sure that you gain the right score:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b1aed8f14b0254398656631f03a53db98e9b7a46"},"cell_type":"code","source":"features = train.drop([\"PassengerId\", \"Survived\"], axis=1).columns\n\nX = train[features].values\nY = train.Survived.values\n\nx_train, x_val, t_train, t_val = train_test_split(X, Y, random_state=0)\n\niclassifier = ImprovedClassifier(x_train.shape[1])\niclassifier.learn(x_train, t_train, 0.000001, 100000, 0.00001)\ntrain_score = iclassifier.score(x_train, t_train)\nval_score = iclassifier.score(x_val, t_val)\nprint(\"train accuracy: %f , validation accuracy: %f\" %(train_score, val_score))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5119c6ba7afe16d2cb7317da8acdd3044d84947d"},"cell_type":"markdown","source":"You should obtain:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"061be5da37bbea8e0b55d00e46d9787e0fbb659b"},"cell_type":"code","source":"#assert(np.round(train_score, 4) == 0.8114)\n#assert(np.round(val_score, 4) == 0.8072)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}