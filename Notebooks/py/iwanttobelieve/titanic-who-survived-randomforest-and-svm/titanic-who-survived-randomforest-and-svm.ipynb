{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Titanic - Who survived?\nI am new to data visualisation and machine learning, so any comments, any feedbacks, or any tips will be much appreciated.\n\n## Section 1. Data exploration\n### 1.1. Importing libraries for data exploration and visualisation"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Data exploration and visualisation\nimport pandas as pd\npd.set_option('display.max_columns', 30) # avoiding truncated tables\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\n# Statistics\nfrom scipy.stats import chi2_contingency\nfrom scipy.stats import chi2\nimport scipy.stats as stats","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dee156f7312528eb66dc0f98379b4824a8dba263"},"cell_type":"markdown","source":"### 1.2. Reading in the data and first look at the data\n\nThere are **891 entries in the train dataset** and **418 entries in the test dataset**:\n* **Survived (train dataset only)**: the target variable showing 1 for passengers who survived and 0 for passengers who died,\n* **Pclass**: 3 travel classes coded as 1, 2 and 3,\n* **Name**: name of the passengers,\n* **Sex**: gender coded as a categorical variable (male and female), \n* **Age**: continuous variable with 177 missing values in the train dataset and 86 in the test dataset. I am assuming age might be relevant to predicting the odds of surviving, so will look at filling in the missing data later on,\n* **SibSp**: number of siblings and spouses of the passengers,\n* **Parch**: number of parents and children of the passengers, can be combined with the SibSp variable to get the family size of the passenger,\n* **Ticket**: ticket number,\n* **Fare**: price paid by the passengers,\n* **Cabin**: there are too many missing data points; I will just probably not use this variable,\n* **Embarked**: only 2 missing values in the train dataset that we can probably easily impute.\n\nBased on the train dataset, the **survival rate was 38%**. If we were to assume only that all the passengers died in a predictive model, the accuracy should be 62%."},{"metadata":{"trusted":true,"_uuid":"05b04fb0dd18ab5603538a9014846bd4f23b6a60"},"cell_type":"code","source":"# Datasets\ndf_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ef75d41e47b9c13ac4cd17febd661e0c15e05a7"},"cell_type":"code","source":"# Checking for missing data in the training dataset\nprint('Number of records:')\nprint(len(df_train.index))\nprint('{:=<70}'.format(''))\nprint('Missing values in the training dataset:')\nprint(df_train.isnull().sum())\nprint('{:=<70}'.format(''))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d534d9a16ebfab810c5eca9103e4095110ff0bc"},"cell_type":"code","source":"# Checking for missing data in the test dataset\nprint('Number of records:')\nprint(len(df_test.index))\nprint('{:=<70}'.format(''))\nprint('Missing values in the test dataset:')\nprint(df_test.isnull().sum())\nprint('{:=<70}'.format(''))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfbe3e5b89c2f15ccd153a4b26ccb5ca2f7b6877"},"cell_type":"code","source":"# Combining the two datasets\ndf_train['Dataset'] = 'train'\ndf_test['Dataset'] = 'test'\ndf_test.insert(loc=1, column='Survived', value=np.nan) # Insert as first column to be aligned with df_train\ndf_all = df_train.append(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17647a508c608778d2e40efa2854210c59f408f6"},"cell_type":"code","source":"# Checking for missing data in the test dataset\nprint('Number of records:')\nprint(len(df_all.index))\nprint('{:=<70}'.format(''))\nprint('Missing values in the test dataset:')\nprint(df_all.isnull().sum())\nprint('{:=<70}'.format(''))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"196b045c681ddc58e1e90cf2423d86ff29f3576e"},"cell_type":"code","source":"# Percentage of passengers who survived (=38% of the total) \nprint('Percentage of passengers who survived (1) and died (0):')\nprint(df_train['Survived'].value_counts(normalize=True))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d28db23d1868ee755c067a9dd3aecb12fb97834"},"cell_type":"markdown","source":"### 1.3. Data exploration: gender and travel class seem to be strong predictors\n\n* **Female had greater odds of survival**: not only did 74% of the females survive but females who survived were also over-represented compared to the females in the total population (35%),\n* **1st class travellers had greater odds of survival**: again, 63% of 1st travellers survived while they only represented less than a quarter (24%) of the total population,\n* **Male and 3rd class travellers had lesser odds of survival**: males and 3rd class travellers were under-represented among the passengers who survived (19% and 24% of the survivors, respectively) compared to the total population (65% and 55% of the total, respectively),\n* Looking at both gender and travel class, there is a higher proportion of female passengers who survived in the 1st (97%) and 2nd (92%) classes as opposed to the 3rd class (50%). By contrast, there was a lower proportion of survivors among male passengers regardless of the travel class.\n\nNote that if we were to assume *only* that all the female passengers survived in a predictive model, the accuracy should be 74%. I guess we should be aiming at a score of at least 74% at the end.\n"},{"metadata":{"trusted":true,"_uuid":"59434fe402f29f92d2ebe7fedf5fa8cdda8c5556"},"cell_type":"code","source":"# Proportion of survivors based on gender (F=74%, M=19%)\nsummary_sex = pd.crosstab(index=df_train['Survived'],\n                            columns=[df_train['Sex']],\n                            margins=True)\n                            \nsex_survived = summary_sex / summary_sex.iloc[-1, :]\n\n# Summary\nprint('{:=<70}'.format(''))\nprint('Proportion of survivors by gender:')\nprint(sex_survived)\nprint('{:=<70}'.format(''))\n\n# Saving results for later use (visualisation)\nf_survived = sex_survived.loc[1, 'female']\nm_survived = sex_survived.loc[1, 'male']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e757be64fcfa50264d10b382454d9f1a2b600736"},"cell_type":"code","source":"# Proportion of survivors based on travel class (1st=63%, 2nd=47%, 3rd=24%)\nsummary_class = pd.crosstab(index=df_train['Survived'],\n                            columns=[df_train['Pclass']],\n                            margins=True)\n\npclass_survived = summary_class / summary_class.iloc[-1, :]\n\n# Summary\nprint('{:=<70}'.format(''))\nprint('Proportion of survivors by travel class:')\nprint(pclass_survived)\nprint('{:=<70}'.format(''))\n\n# Saving results for later use (visualisation)\nc1_survived = pclass_survived.loc[1, 1]\nc2_survived = pclass_survived.loc[1, 2]\nc3_survived = pclass_survived.loc[1, 3]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef4f513e5efb1436916b9a25d8de767b78408c5a"},"cell_type":"markdown","source":"So far we've learned that there is a higher proportion of male (81%) and 3rd class passengers (76%) among the passengers who died. However, this is not enough to support the idea that they had lesser odds of surviving that the other passengers. After all, there was a higher proportion of male and 3rd class passengers among the total population and no one should have been surprised had the male population  represented 81% of the total population or had the 3rd class passengers represented 76% of the total population. More remarkable is the fact that male 3rd class passengers are under-represented in the population of survivors compared to their proportion in the total population. Now we are going to look at the over- or under-representation of survivors/dead passengers compared to theoriginal population."},{"metadata":{"trusted":true,"_uuid":"d68052350a65856bf2f7ada7f1fe4482afdcdb72"},"cell_type":"code","source":"# Proportion of passengers based on gender\nsex = df_train['Sex'].value_counts(normalize=True)\n\n# Summary\nprint('{:=<70}'.format(''))\nprint('Proportion of passengers by gender:')\nprint(sex)\nprint('{:=<70}'.format(''))\n\n# Saving results for later use (visualisation)\nf_passengers = sex['female']\nm_passengers = sex['male']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2333d0430a13e7367226ebdac16d6940ea27247c"},"cell_type":"code","source":"# Proportion of passengers based on travel class\npclass = df_train['Pclass'].value_counts(normalize=True)\n\n# Summary\nprint('{:=<70}'.format(''))\nprint('Proportion of passengers by travel class:')\nprint(pclass)\nprint('{:=<70}'.format(''))\n\n# Saving results for later use (visualisation)\nc1_passengers = pclass[1]\nc2_passengers = pclass[2]\nc3_passengers = pclass[3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f27158b2e75bb1c7637b546f1932aee73da8ebbf"},"cell_type":"code","source":"# Putting it all together (visualisation)\nproportions_col = ['category', '%passengers', '%survived']\nproportions_cat = ['female', 'male', 'class 1', 'class 2', 'class 3']\nproportions_survived = [f_survived, m_survived, c1_survived, c2_survived, c3_survived]\nproportions_passengers =[f_passengers, m_passengers, c1_passengers, c2_passengers, c3_passengers]\n\n# Zipping passengers and survivors proportions into a dataframe\ndf_proportions = pd.DataFrame(\n                            list(zip(proportions_cat,\n                                    proportions_passengers,\n                                    proportions_survived)\n                                ),\n                            columns=proportions_col)\n\ndf_proportions['variance'] = df_proportions['%passengers'] - df_proportions['%survived']\n\n# Melting the dataframe in order to have the layout ready to display the data as a point plot\ndf_proportions_melted = df_proportions.melt(id_vars=['category', 'variance'],\n                                            var_name='ratio type',\n                                            value_name='ratio value')\n\n# Dictionary showing categories with higher or lower odds of surviving. This will be used\n# for the colour palette of the point plot.\nmy_red = '#EF6F6C'\nmy_green = '#435E53'\nl_colours = [my_red if i >=0 else my_green for i in df_proportions['variance'].tolist()]\nd_colours = dict(zip(df_proportions['category'],l_colours))\n\n# Pointplot\nfig, ax = plt.subplots(figsize=(6,8))\nax = sns.pointplot(x='ratio type', \n                    y='ratio value', \n                    hue='category', \n                    data=df_proportions_melted,\n                    palette=d_colours)\n\n# Add data labels as legend\nfor i in range(0, len(df_proportions)):\n    lbl_offset = 1.1\n    if (df_proportions['%passengers'] - df_proportions['%survived'])[i] < 0:\n        ax.text(x=lbl_offset, \n                y=df_proportions['%survived'][i], \n                s=df_proportions['category'][i],\n                ha='left',\n                color=my_green)\n    else:\n        ax.text(x=lbl_offset, \n                y=df_proportions['%survived'][i], \n                s=df_proportions['category'][i],\n                ha='left',\n                color=my_red)\n\n# Other bits of formatting\nax.set(title='Proportions of passengers in the total and survivors population',\n        ylabel='Percentage')\nax.xaxis.label.set_visible(False)\nax.legend_.set_visible(False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"701b0a60ea25f9c432d495fc50598a20d1bcbccb"},"cell_type":"code","source":"# Final summary table: there is a high proportion of surviving females in all travel classes but the 3rd (50%)\nsummary = pd.pivot_table(data=df_train,\n                            index=['Survived'],\n                            columns=['Sex', 'Pclass'],\n                            values=['Name'],\n                            aggfunc=('count'),\n                            margins=True,\n                            margins_name='Total')\n\nprint('{:=<70}'.format(''))\nprint(summary.div(summary.iloc[-1]))\nprint('{:=<70}'.format(''))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a71cc119eaa298e9f192d7bea87b810dbdd86d4"},"cell_type":"code","source":"# Defining a function which will run a chi-square test of independence\ndef get_chi2(crosstab, HasMargin=True, proba=0.95):\n    \n    \"\"\"\n    Get a summary of a chi-square test of independence\n    \n    crosstab: frequency table in a Pandas crosstab format\n    HasMargin: whether the crosstab has margins (totals) or not\n    proba: maximum probability of accepting a false null hypothesis\n    \n    \"\"\"\n    \n    # Data\n    var1 = crosstab.index.name\n    var2 = crosstab.columns.name\n    \n    # Integer offset to pass crosstab with no totals\n    if HasMargin==True:\n        i = -1\n    else:\n        i = \"\"\n    \n    # Contigency table from scipy\n    stat, p, dof, expected = chi2_contingency(\n                                            observed=crosstab.iloc[:i,:i],\n                                            correction=True)\n    \n    # Independence of the variable: comparing chi2 result (stat) and the \"critical\" expected chi2 value\n    # (which is based on the maximum probability of accepting a false null hypothesis and the degree of freedom)\n    critical = chi2.ppf(proba, dof)\n    if stat >= critical:\n        chi2_independence = 'The variables {} and {} are dependent (X2>eX2)'.format(var1, var2)\n    else:\n        chi2_independence = 'The variables {} and {} are independent (X2<eX2)'.format(var1, var2)\n    \n    # Significance of the test: interpreting the p-value\n    alpha = 1 - proba\n    if p <= alpha:\n        chi2_significance = 'The test is statistically significant (p<alpha)'\n    else:\n        chi2_significance = 'The test is not statistically significant (p>alpha)'\n\n    # Summary of the results\n    print('{:^70}'.format('Chi2 test of independence'))\n    print('{:=<70}'.format(''))\n    \n    print('Tested variables')\n    print(var1)\n    print(var2)\n    \n    print('{:=<70}'.format(''))\n    print('{}'.format('Test of independence'))\n    print('Chi-square statistic (X2): {:.3f}'.format(stat))\n    print('Minimum expected chi-square statistic (eX2): {:.3f}'.format(critical))\n    print(chi2_independence)\n        \n    print('{:=<70}'.format(''))\n    print('Significance of the test')\n    print('p-value (p): {:.3f}'.format(p))\n    print('Accepted significance level (alpha): {:.3f}'.format(alpha))\n    print(chi2_significance)\n    \n    print('{:=<70}'.format(''))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17a422bdd19e5171c11a7c1702f01271998f5216"},"cell_type":"code","source":"# The chi-square test of independence suggests that there is a relationship between 'Survived' and 'Sex'\nget_chi2(summary_sex, proba=0.99)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22c7dfdc5c193c743b22f4ff1e645e90765bd4cf"},"cell_type":"code","source":"# The chi-square test of independence suggests that there is a relationship between 'Survived' and 'Pclass'\nget_chi2(summary_class, proba=0.99)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"759c086d061cb208269c783a83f0015406012485"},"cell_type":"markdown","source":"### 1.4. Data exploration: single passengers seem to had lesser odds of survival\nIn this section we are going to group 'Siblings/spouses' and 'Parents/children' into a single 'FamilySize' variable. Again, we are going to look at the over- or under-representation of the surviving populations compared to the total:\n* **Passengers travelling on their own showed lesser odds of surviving**: 30% of them survived while they represented 60% of the passengers,\n* **Passengers with a family had higher odds of surviving**.\n"},{"metadata":{"trusted":true,"_uuid":"b2b5c312268199a1809b1e0a7627f745af17cae4"},"cell_type":"code","source":"# Combining the SibSp and Parch variables into one 'FamilySize' variable\ndf_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1\ndf_all['FamilySize'] = df_all['SibSp'] + df_all['Parch'] + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1bfeaf2581d692d6fa8d1126d7c6abdb69403ae1"},"cell_type":"code","source":"# Proportion of passengers based on family size (and convert to dataframe for later merge)\nfamily_passengers = df_train['FamilySize'].value_counts(normalize=True, sort=False).to_frame().reset_index()\n\n# Renaming the columns of family_passengers\nfamily_passengers.columns = ['FamilySize', '%total']\n\nprint('{:=<70}'.format(''))\nprint(family_passengers)\nprint('{:=<70}'.format(''))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"204e9677e7be303a78bacf78a7df6152f824cc23"},"cell_type":"code","source":"# Proportion of survivors based on family size\nsummary_family = pd.crosstab(index=df_train['Survived'],\n                            columns=[df_train['FamilySize']],\n                            margins=True)\n\nfamily_survived = summary_family / summary_family.iloc[-1, :]\n\n# Only keeping a slice of the crosstab with the proportions of survivors (1) by family size, \n# excluding the totals ([:-1]) \nfamily_survived = family_survived.T[1][:-1].to_frame().reset_index()\n\n# Renaming the columns of family_survived\nfamily_survived.columns = ['FamilySize', '%survived']\n\nprint('{:=<70}'.format(''))\nprint(family_survived)\nprint('{:=<70}'.format(''))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e063d97311bbb519e0de5a4ac1f8c2696c24e776"},"cell_type":"code","source":"# Merging family_passengers and family_survived into a single dataframe\ndf_family = pd.merge(left=family_passengers,\n                     right=family_survived,\n                     how='inner',\n                     on='FamilySize')\n\n# Melting the dataframe\ndf_family_melted = df_family.melt(id_vars=['FamilySize'],\n                                    var_name='ratio type',\n                                    value_name='ratio value')\n\n# Panel charts showing the difference between proportions of in the total population and the population of\n# survivors based on family size\nax = sns.catplot(data=df_family_melted,\n                    x='ratio type',\n                    y='ratio value',\n                    col='FamilySize',\n                    col_wrap=9,\n                    kind='point',\n                    height=3,\n                    aspect=0.8)\n\n# Formatting\nax.set_axis_labels('', 'Percentage')\nplt.subplots_adjust(top=0.7)\nplt.suptitle('Proportions of passengers: total and survivors')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b53129e4d134d16c3c884ce4479706e45b09779"},"cell_type":"code","source":"# The chi-square test of independence suggests that there is a relationship between 'Survived' and 'FamilySize'\nget_chi2(summary_family)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0fba0a5e567bb1a9f1bc3e188532a20f5013ac87"},"cell_type":"markdown","source":"### 1.5. Data exploration: Is 'Age' really relevant to predicting survival?\n\n **Age seems to be mostly irrelevant to predicting survival**. The median age of passengers who survived and died is not massively different and shows a similar age distribution. On top of that, the point-biserial correlation of almost 0 sems to bear out that age is mostly irrelevant here."},{"metadata":{"trusted":true,"_uuid":"da3df5ce05b3714c83fff54adaf4b94eadc1bf02"},"cell_type":"code","source":"# Age dataframe without missing values\ndf_age = df_train[['Age', 'Sex', 'Survived', 'Pclass']]\ndf_age = df_age.dropna(axis=0)\n\n# Let's draw a swarmplot and a boxplot. Adding the boxplot onto the swarmplot shows a similar median age \n# between the two groups (survived and died) with a similar distribution.\nfig, ax = plt.subplots(figsize=(8,8))\nax = sns.swarmplot(data=df_age, x='Survived', y='Age', hue='Sex')\nax = sns.boxplot(data=df_age, x='Survived', y='Age', orient='v', color='lightsteelblue')\nax.set(title='Age distribution among the population who survived and died')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a74b4821b6aab090fe7516ce6094333d4f5bd36c"},"cell_type":"code","source":"# It looks like there is little to no correlation between age and surival/death, which is confirmed by a \n# Point-Biserial correlation of almost 0 (r=-0.08 with p=0.04).\nstats.pointbiserialr(x=df_age['Survived'], y=df_age['Age'])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"27cbd3b9f2444579cf0c58959527a1c3f7f0f0e3"},"cell_type":"code","source":"# First we are going to fill in the 177 missing 'Age' data points using the median age. Instead of just using \n# the median age, we will be using the median age by gender and travel class. I am not sure this will improve \n# anything later on but I thought it would be a good for me to learn something new.\n#\n\n# Median age by gender and by travel class\ndf_median_age = pd.pivot_table(data=df_age, \n                               index=['Sex','Pclass'],\n                               values='Age',\n                               aggfunc=np.median).reset_index()\n\n# Function returning the median age depending on gender and travel class\ndef fill_age(data):\n    \n    median = df_median_age\n    age = data['Age']\n    sex = data['Sex']\n    pclass = data['Pclass']\n    \n    if pd.isnull(age):\n        \n        if sex == 'female' and pclass == 1:\n            return median[(median['Sex'] == 'female') & (median['Pclass'] == 1)]['Age'].values[0]\n        if sex == 'female' and pclass == 2:\n            return median[(median['Sex'] == 'female') & (median['Pclass'] == 2)]['Age'].values[0]\n        if sex == 'female' and pclass == 3:\n            return median[(median['Sex'] == 'female') & (median['Pclass'] == 3)]['Age'].values[0]\n        if sex == 'male' and pclass == 1:\n            return median[(median['Sex'] == 'male') & (median['Pclass'] == 1)]['Age'].values[0]\n        if sex == 'male' and pclass == 2:\n            return median[(median['Sex'] == 'male') & (median['Pclass'] == 2)]['Age'].values[0]\n        if sex == 'male' and pclass == 3:\n            return median[(median['Sex'] == 'male') & (median['Pclass'] == 3)]['Age'].values[0]\n    \n    else:\n        \n        return age\n\n# Filling in the missing values\ndf_train['Age'] = df_train[['Age', 'Sex', 'Pclass']].apply(fill_age, axis=1)\n\n# We use the data from the training dataset to fill in all the missing values in df_all to avoid data leakage\ndf_all['Age'] = df_all[['Age', 'Sex', 'Pclass']].apply(fill_age, axis=1)\n\n# Check for null values\nprint('{:=<70}'.format(''))\nprint('Missing age values in the combined dataset:')\nprint(df_all['Age'].isnull().sum())\nprint('{:=<70}'.format(''))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bd005197fdebbb2b2174987807d78f6a03b900e"},"cell_type":"markdown","source":"### 5. Data exploration: port of embarkation\n\nPassengers embarked either in Southampton ('S'), Cherbourg ('C) or Queenstown ('Q'). \n\n**The vast majority (73%) of the passengers embarked in Southampton but had a survival rate of 33%, or less than the overall 38% survival rate. By contrast, passengers who embarked in Cherbourg had a noticeably higher survival rate of 55%**. A reason for that might be that a higer proportion of passengers who embarked in Cherbourg travelled in first class (51%) as opposed to passengers who embarked in Southampton (20%)."},{"metadata":{"trusted":true,"_uuid":"21e52ee0bebbbb203babcecc2321ad6cd6729ec7"},"cell_type":"code","source":"# Proportion of passengers by port of embarkation\nprint(df_train['Embarked'].value_counts(normalize=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"760aed61d7738b29e1538ee02803d4a8bf6c27d8"},"cell_type":"code","source":"# The vast majority of the passengers embarked in Southampton. Let's just fill in the 2 missing\n# piece of data with 'S'\ndf_train['Embarked'].fillna(value='S', inplace=True)\ndf_all['Embarked'].fillna(value='S', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9307c3bd59c85c8b6df2e023da29e33a9c719dc8"},"cell_type":"code","source":"# Survival rate based on the port of embarkation\nsummary_embarked = pd.crosstab(index=df_train['Survived'],\n                                columns=df_train['Embarked'],\n                                margins=True)\n\nprint(summary_embarked / summary_embarked.iloc[-1,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3986daed6e8f492a54fcf0822a11f8077dc02708"},"cell_type":"code","source":"# Port of embarkation and travel class\nport_class = pd.crosstab(index=df_train['Pclass'],\n                                columns=df_train['Embarked'],\n                                margins=True)\n\nprint(port_class / port_class.iloc[-1,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5eb66debc9effeb1162a9e6b572e338c91748282"},"cell_type":"code","source":"# The chi-square test of independence suggests that there is a relationship between 'Survived' and 'Embarked'\nget_chi2(summary_embarked)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34a765feb8863b095d1478aee6d23415d4e4879a"},"cell_type":"markdown","source":"### 6. Data exploration: fares and adjusted fares\nThe fares in the dataset are actually the fares paid for the corresponding ticket and not for the corresponding passenger alone. Several passengers share the same ticket (family or friends), which obviously gives an inaccurate picture of the individual fares. Therefore, we are going to calculate the average individual fare by passenger depending on the ticket number. Credit goes to [Geoffrey Wong](https://www.kaggle.com/csw4192/titanic-randomforest).\nEventually, we find that survival based on the adjusted fares reflect survival based on travel classes. Therefore, we might not include the adjusted fares into our final model."},{"metadata":{"trusted":true,"_uuid":"329b183bb114037f0ba841d7a13e4927052bc109"},"cell_type":"code","source":"# Only one missing piece of data (test dataset)\ndf_all[df_all['Fare'].isnull() == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8db461d1a758dc6d98a4ddc59f39cb96c53b30b9"},"cell_type":"code","source":"# Median fare paid by 3rd class travellers (train dataset)\nmedian_fare = df_train['Fare'][df_train['Pclass']==3].median()\n\n# Filling in the one missing fare (test dataset)\ndf_all['Fare'].fillna(value=median_fare, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e890764668a6644a4b5c6d18992f978170ce94ac"},"cell_type":"code","source":"# Showing a few examples of fares corresponding to a ticket and not a passengers\ndf_train[['Ticket', 'Fare', 'Name']].sort_values(by='Ticket', axis=0).head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"acb2cd7054f2bb64d6cba48cbc19e0ce9df5a623"},"cell_type":"code","source":"# Calculating adjusted fares in the combined dataset\nd_ticket_count = dict(df_all['Ticket'].value_counts())\ndf_all['TicketCount'] = df_all['Ticket'].map(d_ticket_count)\ndf_all['AdjFare'] = df_all['Fare'] / df_all['TicketCount']\n\n# Adding the adjusted fares in the training dataset\ndf_train['AdjFare'] = df_all[df_all['Dataset'] == 'train']['AdjFare']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5175809fdd53576b0ee04e4f0ef5b76510410c8"},"cell_type":"code","source":"# Fare and survival within each travel class\nax = sns.catplot(data=df_train,\n                x='Survived',\n                y='AdjFare',\n                col='Pclass',\n                col_wrap=3,\n                kind='box',\n                color='lightsteelblue',\n                showfliers=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"09db2cc05c231677a1f05202d80ca4cedf5cd665"},"cell_type":"markdown","source":"## Section 2. Features engineering\n\n### 2.1. Single passengers\nWe saw that passengers travelling on their own (as defined by the number of family relationships) seem to have lesser odds of survival (see 1.4.). Now I would like to identify group of passengers travelling together based on their last name and ticket number, assuming that the fate of the different groups might have been similar."},{"metadata":{"trusted":true,"_uuid":"8dd69cbdb3d9b0c58da18265c4ae6f5ff0b920bc"},"cell_type":"code","source":"# Extracting the last name of the passengers\ndf_all['LastName'] = df_all['Name'].str.extract(pat= '^([^,]*),', expand=True)\n#df_all['LastName'] = df_all['Name'].str.split(pat= ',').str[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b66178682cd0fff679275830a6b01f7e5ad9117"},"cell_type":"code","source":"# Extracting only the digits from 'Ticket'\ndf_all['TicketNum'] = df_all['Ticket'].str.replace(pat= '(\\D)', repl= '')\n#df_all['TicketNum'] = df_all['Ticket'].str.extract(pat= '(\\d+\\d)', expand=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb3934e021568fe4f7f4c6fb0d13b9b42a24b3a7"},"cell_type":"code","source":"# Calculating adjusted fares in the combined dataset\nd_ticket_count = dict(df_all['Ticket'].value_counts())\ndf_all['TicketCount'] = df_all['Ticket'].map(d_ticket_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99136c2cb71bda9e3b90352981a0bb4acd194307"},"cell_type":"code","source":"# New 'SharedTicket' (0=False, 1=True)\ndf_all['SharedTicket'] = [1 if i > 1 else 0 for i in df_all['TicketCount']]\n\n# New 'SharedName' (0=False, 1=True)\nd_shared_name = dict(df_all['LastName'].value_counts())\ndf_all['SharedName'] = [1 if i > 1 else 0 for i in df_all['LastName'].map(d_shared_name)]  \n\n# New 'SharedFeatures'\ndf_all['SharedFeatures'] = df_all['SharedTicket'] + df_all['SharedName']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6208232425a6353865121d8b4998ce8c31178b8"},"cell_type":"code","source":"# Adding 'IsSingle' column\nshared_features = [\n                    df_all['SharedFeatures'] == 0,\n                    df_all['SharedFeatures'] == 1,\n                    (df_all['SharedTicket'] == 0) & (df_all['SharedName'] == 1) & (df_all['FamilySize']  == 1),\n                    (df_all['SharedTicket'] == 0) & (df_all['SharedName'] == 1) & (df_all['FamilySize']  > 1),\n                    (df_all['SharedTicket'] == 1) & (df_all['SharedName'] == 0)\n                  ]\n\nis_single = [1, 0, 1, 0, 0]\n\n    \ndf_all['IsSingle'] = np.select(shared_features, is_single)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"756e038cef941dc98da63e0270c7b2f900430c55"},"cell_type":"code","source":"df_all.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"041638b627911cb072bdece0d21ea95624d237fb"},"cell_type":"code","source":"# # Combining 'Ticket' and 'LastName'\n# df_all['Group'] = df_all['LastName'] + df_all['TicketNum']\n\n# # Get a list of all the unique groups\n# group_keys = df_all['Group'].unique()\n\n# # Get a dictionary of the unique groups with a unique incremental identifier (id: 'unique group')\n# group_id = dict([(count, key) for (count, key) in enumerate(group_keys,start=1)])\n\n# # Invert the keys and values ('unique group': id)\n# group_id = dict([(v, k) for (k, v) in group_id.items()])\n\n# # Adding 'GroupId' to the dataframe\n# df_all['GroupId'] = df_all['Group'].map(group_id)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe8d873a9f430690bf99319a9535b821f0d2a340"},"cell_type":"markdown","source":"## Section 3. Predictions\n### 3.1. Machine learning libraries"},{"metadata":{"trusted":true,"_uuid":"5bb15cc8d3c9e2720629c7ac7a7f48bdc61f36a5"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2591aac296bf4b34037bf847f19fd49e4f8b9e0"},"cell_type":"markdown","source":"### 3.2. Setting up the final dataframe"},{"metadata":{"trusted":true,"_uuid":"9db838ef4f6eb28fce3596d404638af554bad690"},"cell_type":"code","source":"# Converting 'Sex' into a binary variable\ndf_all['Sex'] = [1 if i == 'female' else 0 for i in df_all['Sex']]\n\n# Predictors\nl_predictors = ['Dataset', 'Survived', 'Pclass', 'Sex', 'Embarked', 'IsSingle', 'FamilySize']\n\n# Final dataframe\ndf_final = df_all[l_predictors]\n\n# Get dummies\ndf_final = pd.get_dummies(data = df_final,\n                          columns = ['Pclass', 'Embarked', 'FamilySize'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d88ab1d9b4430cb14cea86ad2fde3270750e57a8"},"cell_type":"code","source":"df_final.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"172d9c714452fed60acfc7b3c33831e8ba0a01c1"},"cell_type":"markdown","source":"### 3.3. Random Forest"},{"metadata":{"trusted":true,"_uuid":"f4ddc819792a6bc561e8e6b79060d5cc03c9902b"},"cell_type":"code","source":"# Going back to the training dataset to test our model\npredictors = df_final[df_final['Dataset'] == 'train'].drop(['Dataset', 'Survived'], axis=1)\ntargets = df_final[df_final['Dataset'] == 'train']['Survived']\nX_train, X_test, y_train, y_test = train_test_split(predictors, targets, test_size=0.30, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d3767457052c4fc42b870884919b8cab4d5e77b"},"cell_type":"code","source":"# Random forest\nrfc = RandomForestClassifier(n_estimators=100, random_state = 42)\nrfc.fit(X_train, y_train)\nrfc_pred = rfc.predict(X_test)\n\n#print(classification_report(y_test,rfc_pred))\nprint(accuracy_score(rfc_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43865817773bd07bca9c39fc344bd41f2cfaa99f"},"cell_type":"code","source":"# Tuning hyperparameters with GridSearchCV\nparam = {'n_estimators': [100, 500],\n         'criterion' :['gini'],\n         'max_features': ['auto'],\n         'max_depth': [3, 4, 5]}\n         \ngrid = GridSearchCV(estimator=rfc, param_grid=param, refit=True, cv=3)\ngrid.fit(X_train,y_train)\ngrid_pred = grid.predict(X_test)\nprint(accuracy_score(grid_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d168c3bc7a886dbcc4321ac97fcf41cfa661720"},"cell_type":"code","source":"# Best parameters from the grid search\ngrid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9191c30fb82040497b2d3d9a20d534c8a6de099"},"cell_type":"code","source":"# applying the best parameters to a new random forest model\nrfc_best = RandomForestClassifier(random_state = 42,\n                                  criterion = 'gini',\n                                  max_depth = 4,\n                                  max_features = 'auto',\n                                  n_estimators = 100)\n\nrfc_best.fit(X_train, y_train)\nrfc_best_pred = rfc_best.predict(X_test)\nprint(accuracy_score(rfc_best_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2884ad6a63b917c9d0a58c16d03d2a228e4b0ba4"},"cell_type":"markdown","source":"### 3.4. Support Vector Machine"},{"metadata":{"trusted":true,"_uuid":"0aefb9d39ff87e7db8c69317606c2d561ee3749d"},"cell_type":"code","source":"# Support vector machine\nsvc = SVC(random_state=42, gamma='scale')\nsvc.fit(X_train, y_train)\nsvc_pred = svc.predict(X_test)\nprint(accuracy_score(svc_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c02cefca97cf9a398335da849c5f24ca9928e5bf"},"cell_type":"code","source":"# Tuning hyperparameters with GridSearchCV\nparam = {'C': [1, 10, 100, 1000],\n         'gamma' :[1, 0.1, 0.001, 0.0001],\n         'kernel': ['linear', 'rbf']}\n         \nsvm_grid = GridSearchCV(estimator=svc, param_grid=param, refit=True, cv=3, iid=False)\nsvm_grid.fit(X_train,y_train)\nsvm_grid_pred = svm_grid.predict(X_test)\nprint(accuracy_score(svm_grid_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fc705617cdd5c1614e6483d52b0c18c8e69db60"},"cell_type":"code","source":"# Best parameters from the grid search\nsvm_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d772362c69ad4ec22b06d21716b0f840f58c45b6"},"cell_type":"code","source":"# Applying the best parameters to a new svm model\nsvm_best = SVC(random_state = 42,\n                C = 1,\n                gamma = 0.1,\n                kernel = 'rbf')\n\nsvm_best.fit(X_train, y_train)\nsvm_best_pred = svm_best.predict(X_test)\nprint(accuracy_score(svm_best_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9ede590c91c362bd9a2823ee026b9f2dad52ecf"},"cell_type":"code","source":"# import thomas","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5118fde260a91984077bc8c35a633a1ad221ae6d"},"cell_type":"markdown","source":"### 3.5. File for submission"},{"metadata":{"trusted":true,"_uuid":"43993993afa16b5372bb45d8b0af1dafd20e7360"},"cell_type":"code","source":"X_test_submit = df_final[df_final['Dataset'] == 'test'].drop(['Dataset', 'Survived'], axis=1)\nsubmit_pred = rfc_best.predict(X_test_submit)\n\n# File for submission\nfile_submit = pd.DataFrame({'PassengerId': df_test['PassengerId'].values,\n                            'Survived': submit_pred.astype(np.int32)})\n\nfile_submit.to_csv('titanic_submit_pred.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}