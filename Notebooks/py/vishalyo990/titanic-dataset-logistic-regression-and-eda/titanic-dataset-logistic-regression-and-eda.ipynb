{"metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "file_extension": ".py", "name": "python", "pygments_lexer": "ipython3", "version": "3.6.3", "nbconvert_exporter": "python"}}, "cells": [{"metadata": {"_cell_guid": "2e6d691c-11e4-47d1-ae7f-2115bb708d34", "_uuid": "df29a10a0d4d8c35b5021bbe73296c34c113b3c0"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "import cufflinks as cf\n", "cf.go_offline()\n", "%matplotlib inline"]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["train = pd.read_csv('../input/train.csv')"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Lest see how the data is distributed\n", "train.head()"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["train.info()"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Lets do some exploratory data analysis.\n", "\n", "#Lets find out the missing data in our data set\n", "#This heatmap shows the null values in yellow line.\n", "sns.heatmap(train.isnull(), yticklabels = False, cbar = False, cmap = 'viridis')"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#EDA\n", "#Lets see how many of survived andd how many of not.\n", "sns.set_style('whitegrid')\n", "sns.countplot(x = 'Survived', data = train)"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Lets see this survival rate as per sex.\n", "sns.countplot(x = 'Survived', data = train, hue = 'Sex')"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Now the survival rate as per of Pclass\n", "#Here we see the the passenger are in 3rd clas are more likely to not survived.\n", "sns.countplot(x = 'Survived', data = train, hue = 'Pclass')"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Lets see distribution of age in the dataset\n", "#Here we see that mor number of peoples as of the young age between 20 to 30\n", "sns.distplot(train['Age'].dropna(), kde = False, bins = 30)"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Lets look at the sibling and spouse column \n", "sns.countplot(x = 'SibSp', data = train)"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Now lets explore the fair column\n", "train['Fare'].hist(bins = 40, figsize=(10,4))"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Now lets explore this column with some interactive plot using cufflinks.\n", "train['Fare'].iplot(kind='hist')"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Now lets deal with the missing data.\n", "#Filling the age as the mean of the present ages.\n", "#Lets do it the smart way by considering Pclass.\n", "sns.boxplot(x = 'Pclass', y='Age', data = train)"]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Now impute the age as considering the Pclass\n", "def impute_age(cols):\n", "    Age = cols[0]\n", "    Pclass = cols[1]\n", "    \n", "    if pd.isnull(Age):\n", "        if Pclass == 1:\n", "            return 37\n", "        elif Pclass == 2:\n", "            return 29\n", "        else:\n", "            return 24\n", "    else:\n", "        return Age\n", "        "]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["train['Age'] = train[['Age', 'Pclass']].apply(impute_age, axis = 1)"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Now lets check our data.\n", "#We see that our data is sucessfully filled the age values.\n", "sns.heatmap(train.isnull(), yticklabels = False, cbar = False, cmap=\"viridis\")"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Now lets drop the coloumn Cabin because it has high number of missing valus.\n", "train.drop('Cabin', axis = 1, inplace = True)\n", "sns.heatmap(train.isnull(), yticklabels = False, cbar = False, cmap=\"viridis\")\n", "\n", "#Now our data is free from missing values as the plot showing one solid color only."]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Now lets create dummy varibles for the categorical columns.\n", "sex = pd.get_dummies(train['Sex'],drop_first = True)"]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["embark = pd.get_dummies(train['Embarked'],drop_first = True)"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#lets join the two dummies we have make in our original dataset\n", "train = pd.concat([train, sex, embark], axis = 1)\n"]}, {"metadata": {"_kg_hide-output": false, "_kg_hide-input": true}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["train.drop(['Sex', 'Embarked', 'Name', 'Ticket'], axis=1, inplace = True)"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Now we see that our dataset is good for performing machine learning algorithms.\n", "#We have now all numerical columns\n", "\n", "train.drop(['PassengerId'], axis=1, inplace = True)"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["train.head()"]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Now lets train our model to do predictions.\n", "#For that first we need to divide our data set in two datasets\n", "X=train.drop('Survived', axis = 1)\n", "y= train['Survived']"]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["from sklearn.cross_validation import train_test_split"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.3, random_state=101)"]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression"]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Lets create a instance of LogisticRegression\n", "logmodel = LogisticRegression()"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Lets fit a model first\n", "logmodel.fit(X_train, y_train)"]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Lets do predictions\n", "predictions = logmodel.predict(X_test)"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#we have predict our predictions now.\n", "#Lets check the classification report of our predictions\n", "from sklearn.metrics import classification_report\n", "print(classification_report(y_test, predictions))"]}, {"metadata": {"scrolled": true}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Lets check the confusion matrix for the same.\n", "from sklearn.metrics import confusion_matrix\n", "confusion_matrix(y_test, predictions)"]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "outputs": [], "source": []}], "nbformat": 4, "nbformat_minor": 1}