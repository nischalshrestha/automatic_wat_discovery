{"cells":[{"metadata":{"trusted":true,"_uuid":"3c2af12107fa13474fd9522015db7b2fd2ceab2c"},"cell_type":"code","source":"#Now let's open it with pandas\nimport pandas as pd\nfrom pandas import Series,DataFrame\n# Importing the libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n%matplotlib inline\nimport time\nimport random\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2bed23ebc71adbe5ce8ecaf19825224d9a205f0"},"cell_type":"code","source":"# Set up the Titanic csv file as a DataFrame\ntitanic_train = pd.read_csv('../input/train.csv')\ntitanic_test = pd.read_csv('../input/test.csv')\ntitanic_ytest = pd.read_csv('../input/gender_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be01360bcbf4a0bf8a470f265d925ab2ed81359f"},"cell_type":"code","source":"titanic_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5b74b566fde8d8f4789d2bb85d4852121bb8a3e"},"cell_type":"code","source":"titanic_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a6140a306be947b593e6eaac2a1238740aa1219"},"cell_type":"code","source":"titanic_ytest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8ee032a62c717d0ea72d8865252f466c50eb63c"},"cell_type":"code","source":"\nresult = pd.merge(titanic_ytest,titanic_test, how='inner', on=['PassengerId'])\nresult=result.append(titanic_train)\nresult.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9bd8ff95d173c036352b79e5dc0b22060bd60b9"},"cell_type":"code","source":"titanic=result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d728b1288893c731321ac46559d4f3dd9c77a9e5"},"cell_type":"code","source":"titanic.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d070d4d95892bd9587e9427695a6c652625dd387"},"cell_type":"code","source":"titanic.isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"188454a5520d6b2cbdc7039a53c45d0f4276983a"},"cell_type":"code","source":"# Actual replacement of the missing value using median value.\ntitanic = titanic.fillna((titanic.median()))\ntitanic.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e167973652285a2984da52531bc4fcaf29361b60"},"cell_type":"code","source":"titanic.isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b8776bbe41eb73d35342e6d337ca88c82719d10"},"cell_type":"code","source":"titanic.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a080983b6cfcd6463676cff3820f31220731acd"},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true,"_uuid":"e6307a11422f91c2e8ed275bfd145f76a8e24fd7"},"cell_type":"code","source":"#Correlation with Quality with respect to attributes\ntitanic.corrwith(titanic.Survived).plot.bar(\n        figsize = (20, 10), title = \"Correlation with quality\", fontsize = 15,\n        rot = 45, grid = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"396af54b4027947f5ff50236a8acb5fff9d8fe72"},"cell_type":"code","source":"## Correlation Matrix\nsns.set(style=\"white\")\n\n# Compute the correlation matrix\ncorr = titanic.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"172391bde5d22f87baa3d0a1a5f0d3ac563656c8"},"cell_type":"code","source":"corr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de70157061475e388d1aca56692882a7c4c08e06"},"cell_type":"code","source":"# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(18, 15))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15bae0a034d8da184936543581a492f54f6db1ac"},"cell_type":"code","source":"titanic.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e26075339daaf2098f94c7a404e05c7fa8754741"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"391b6477899890058384a078b4b03a17c301b01f"},"cell_type":"code","source":"#Assigning and dividing the dataset\nX = titanic.drop(columns=['Survived','Embarked','Cabin','Name','Ticket'],axis=1)\ny=titanic['Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b59144b267528ebc96214f2fc6d26da2ed63274"},"cell_type":"code","source":"X.isna().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d0313ac4c68ac47f44cac7f35aa6ec940368a0e"},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c523c37e74636b12a53ac9c9821c51b34eeef18b"},"cell_type":"code","source":"data=titanic.drop(columns=['Survived','Embarked','Cabin','Name','Ticket'],axis=1)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c95e6fb158bcf1d7d5653dead0531823c467ade"},"cell_type":"code","source":"#Encoding categorical data\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\n#Encoding the Dependent Variable\nlabelencoder_y = LabelEncoder()\n\nX['Sex'] = labelencoder_y.fit_transform(X['Sex'])\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c6a4b1d6be3a2a2c59e7d70989ba2d56c91e8e5"},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3b896ae3cf0323670df58b691c0a687be02c8bd"},"cell_type":"code","source":"#Encoding categorical data\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\n#Encoding the Dependent Variable\nlabelencoder_y = LabelEncoder()\n\ndata['Sex'] = labelencoder_y.fit_transform(data['Sex'])\n\ndata.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a53de6567fdff131d3a3d1a6f3bf183a57cc845b"},"cell_type":"code","source":"features_label = data.columns[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2c83ad9c5596b7ec1ed9486a567ada753db400f"},"cell_type":"code","source":"features_label\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39ae2b12a75c00ee574a7a4f4c97f03d6d2fee84"},"cell_type":"code","source":"#Fitting Random Forest Classification to the Training set\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = 0)\nclassifier.fit(X, y)\nimportances = classifier.feature_importances_\nindices = np. argsort(importances)[::-1]\nfor i in range(X.shape[1]):\n    print (\"%2d) %-*s %f\" % (i+1, 30, features_label[i],importances[indices[i]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f09a9db6d67e32374c4b30ca3e2f360adc7170f"},"cell_type":"code","source":"plt.title('Feature Importances')\nplt.bar(range(X.shape[1]),importances[indices], color=\"green\", align=\"center\")\nplt.xticks(range(X.shape[1]),features_label, rotation=90)\nplt.xlim([-1, X.shape[1]])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1852cbe02a195aac8822ee0ed31dc92afa3ba2b"},"cell_type":"markdown","source":"# Model Training"},{"metadata":{"trusted":true,"_uuid":"e414e7ef3c0f854e3206e1ce9ae2c6dea12044ad"},"cell_type":"code","source":"\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection  import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b7d885d05c1568863029dda78f201a2b1586243"},"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train2 = pd.DataFrame(sc.fit_transform(X_train))\nX_test2 = pd.DataFrame(sc.transform(X_test))\nX_train2.columns = X_train.columns.values\nX_test2.columns = X_test.columns.values\nX_train2.index = X_train.index.values\nX_test2.index = X_test.index.values\nX_train = X_train2\nX_test = X_test2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"766ae88f21a6300da31883847765287a9cb270c6"},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components = None)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)\nexplained_variance = pca.explained_variance_ratio_\npd.DataFrame(explained_variance)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44c5f2c93da2b5b000f0bcea96d391ab6821c276"},"cell_type":"code","source":"#### Model Building ####\n\n### Comparing Models\n\n## Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0, penalty = 'l1')\nclassifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = classifier.predict(X_test)\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nresults = pd.DataFrame([['Logistic Regression', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87349a455b78e0776b651e9ce2388d804dcccc9b"},"cell_type":"code","source":"## SVM (rbf)\nfrom sklearn.svm import SVC\nclassifier = SVC(random_state = 0, kernel = 'rbf')\nclassifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['SVM (RBF)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nresults = results.append(model_results, ignore_index = True)\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27e2f7fe7e2bf4d483efb69abc3a114ac70eb835"},"cell_type":"code","source":"## Randomforest\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(random_state = 0, n_estimators = 100,\n                                    criterion = 'entropy')\nclassifier.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = classifier.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Random Forest (n=100)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nresults = results.append(model_results, ignore_index = True)\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73c315d5b2627041c47e6abfade9fc8f1e5368fe"},"cell_type":"markdown","source":"# Model Evaluation"},{"metadata":{"trusted":true,"_uuid":"b0ffae681983d29b056071e342a5bcac66529a69"},"cell_type":"code","source":"#we ttok the highest accuracy model svm rbf classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"387f1f1b70bc888ba21f9ecfd9d1fc405bf6c3b5"},"cell_type":"code","source":"## K-fold Cross Validation\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = classifier, X= X_train, y = y_train,\n                             cv = 100)\nprint(\"SVM Classifier Accuracy: %0.2f (+/- %0.2f)\"  % (accuracies.mean(), accuracies.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fb05aacda4249144f39a0a693bb6ed709eb5f16"},"cell_type":"code","source":"# Round 1: SVM tuning\nparameters = [{ 'C': [1,  100],'kernel': ['linear']},\n              { 'C': [1,  100],'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5]}]\n# Make sure classifier points to the RF model\nfrom sklearn.model_selection import GridSearchCV\ngrid_search = GridSearchCV(estimator = classifier, \n                           param_grid = parameters,\n                           scoring = \"accuracy\",\n                           cv = 10,\n                           n_jobs = -1)\n\nt0 = time.time()\ngrid_search = grid_search.fit(X_train, y_train)\nt1 = time.time()\nprint(\"Took %0.2f seconds\" % (t1 - t0))\n\nrf_best_accuracy = grid_search.best_score_\nrf_best_parameters = grid_search.best_params_\nrf_best_accuracy, rf_best_parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e82b614e11d7dd4852da30f128807536342d9a6e"},"cell_type":"code","source":"# Predicting Test Set\ny_pred = grid_search.predict(X_test)\nacc = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred)\nrec = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['SVM (n=100, GSx2 + Gini)', acc, prec, rec, f1]],\n               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n\nresults = results.append(model_results, ignore_index = True)\nresults","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf1b408292504b5a5ea8944f3da6c98dc0c4a065"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport itertools\n\nfrom sklearn import svm, datasets\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8229134ce9bf3a53444209d3c51b6c91deabf5c"},"cell_type":"code","source":"# Making the Confusion Matrix \nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\nnp.set_printoptions(precision=2)\n\n# Plot normalized confusion matrix\nplot_confusion_matrix(cm,classes=[0,1])\nsns.set(rc={'figure.figsize':(6,6)})\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2080f776fc9a388e718d22bb18609bcb1f5b31f"},"cell_type":"code","source":"#Let's see how our model performed\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"393d1a3a45d2e1a84b97bcbce6d8e2b6a46c51b6"},"cell_type":"markdown","source":"# Visualisation"},{"metadata":{"trusted":true,"_uuid":"6f7bbc1f8e570a704a415cf8a914120dbeafa34b"},"cell_type":"code","source":"# Let's import what we'll need for the analysis and visualization\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69b58ae92f132f07d93acfa02b0c6b0918a57fa4"},"cell_type":"code","source":"# Let's first check gender\nsns.countplot('Sex',data=result)\nsns.set(rc={'figure.figsize':(6,6)})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b2d714fd74fd1bca9bf227db0144d1f7c0fb4f2"},"cell_type":"code","source":"# Now let's seperate the genders by classes, remember we can use the 'hue' arguement here!\nsns.countplot('Pclass',data=result,hue='Sex')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86c538d82b2e2ded77f942b62d959aae47796df3"},"cell_type":"code","source":"# We'll treat anyone as under 16 as a child, and then use the apply technique with a function to create a new column\n\n\n# First let's make a function to sort through the sex \ndef male_female_child(passenger):\n    # Take the Age and Sex\n    age,sex = passenger\n    # Compare the age, otherwise leave the sex\n    if age < 16:\n        return 'child'\n    else:\n        return sex\n    \n\n# We'll define a new column called 'person', remember to specify axis=1 for columns and not index\nresult['person'] = result[['Age','Sex']].apply(male_female_child,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8944229a57cafeaf13c06670f4e97d6fb674040"},"cell_type":"code","source":"# Let's see if this worked, check out the first ten rows\nresult[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7a21672e4dd9dd645dc501fead18a6689e536dc"},"cell_type":"code","source":"# Let's try the factorplot again!\nsns.countplot('Pclass',data=result,hue='person')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df4b9674fc4a123311dc260ab8645b0a188a8b15"},"cell_type":"code","source":"# Quick way to create a histogram using pandas\nresult['Age'].hist(bins=70)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6aa400e0225adc43ffba78ed058e4495bd2cf9b2"},"cell_type":"code","source":"# We could also get a quick overall comparison of male,female,child\nresult['person'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e0bb97aaf68e3d53c128cfecea29d4ca46b531c"},"cell_type":"code","source":"# Another way to visualize the data is to use FacetGrid to plot multiple kedplots on one plot\n\n# Set the figure equal to a facetgrid with the pandas dataframe as its data source, set the hue, and change the aspect ratio.\nfig = sns.FacetGrid(result, hue=\"Sex\",aspect=4)\n\n# Next use map to plot all the possible kdeplots for the 'Age' column by the hue choice\nfig.map(sns.kdeplot,'Age',shade= True)\n\n# Set the x max limit by the oldest passenger\noldest = result['Age'].max()\n\n#Since we know no one can be negative years old set the x lower limit at 0\nfig.set(xlim=(0,oldest))\n\n#Finally add a legend\nfig.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"556fe1206b792daba86284268ee325209720ce78"},"cell_type":"code","source":"# We could have done the same thing for the 'person' column to include children:\n\nfig = sns.FacetGrid(result, hue=\"person\",aspect=4)\nfig.map(sns.kdeplot,'Age',shade= True)\noldest = result['Age'].max()\nfig.set(xlim=(0,oldest))\nfig.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c6eb6b07695905abd0e43cc02eef22d538a3575"},"cell_type":"code","source":"# Let's do the same for class by changing the hue argument:\nfig = sns.FacetGrid(result, hue=\"Pclass\",aspect=4)\nfig.map(sns.kdeplot,'Age',shade= True)\noldest = result['Age'].max()\nfig.set(xlim=(0,oldest))\nfig.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bfa8c0b2ee9603986b944b230f70f07d09a0cd0"},"cell_type":"code","source":"# Let's get a quick look at our dataset again\nresult.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a51b40cbc62f88db14f9ed52ab345f3eb5e1b84"},"cell_type":"code","source":"# First we'll drop the NaN values and create a new object, deck\ndeck = result['Cabin'].dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b45fd2431ab8442e02407165880f894a9d78887"},"cell_type":"code","source":"# Quick preview of the decks\ndeck.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"589c02c2e38e00e3bfe8f75123dd591d28ab1741"},"cell_type":"code","source":"# So let's grab that letter for the deck level with a simple for loop\n\n# Set empty list\nlevels = []\n\n# Loop to grab first letter\nfor level in deck:\n    levels.append(level[0])    \n\n# Reset DataFrame and use factor plot\ncabin_df = DataFrame(levels)\ncabin_df.columns = ['Cabin']\nsns.countplot('Cabin',data=cabin_df,palette='winter_d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8aa061789672a9e4fc4bb51fff3cee1239e72b8"},"cell_type":"code","source":"# Redefine cabin_df as everything but where the row was equal to 'T'\ncabin_df = cabin_df[cabin_df.Cabin != 'T']\n#Replot\nsns.countplot('Cabin',data=cabin_df,palette='summer')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"048934bce500b4bc32b13e8d06b8d4ff037e000e"},"cell_type":"code","source":"# Now we can make a quick factorplot to check out the results, note the x_order argument, used to deal with NaN values\nsns.countplot('Embarked',data=result,hue='Pclass',order=['C','Q','S'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b5c057fe2681c0bd917d1d901aa120692c919b1"},"cell_type":"code","source":"# Let's start by adding a new column to define alone\n\n# We'll add the parent/child column with the sibsp column\nresult['Alone'] =  result.Parch + result.SibSp\nresult['Alone']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c41598cb502287896d0b2d979b1f5f2c3fe7483"},"cell_type":"code","source":"# Look for >0 or ==0 to set alone status\nresult['Alone'].loc[result['Alone'] >0] = 'With Family'\nresult['Alone'].loc[result['Alone'] == 0] = 'Alone'\n\n# Note it's okay to ignore an  error that sometimes pops up here. For more info check out this link\nurl_info = 'http://stackoverflow.com/questions/20625582/how-to-deal-with-this-pandas-warning'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13e43bf649207db28365d6719b4c15e83d12ca8a"},"cell_type":"code","source":"# Let's check to make sure it worked\nresult.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"facc20acaf7667f4e6c5fa39e54481aa3145bef0"},"cell_type":"code","source":"# Now let's get a simple visualization!\nsns.countplot('Alone',data=result,palette='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2dc2657816994edef7ada9f8fb8d09e17095ba89"},"cell_type":"code","source":"# Let's start by creating a new column for legibility purposes through mapping (Lec 36)\nresult[\"Survivor\"] = result.Survived.map({0: \"no\", 1: \"yes\"})\n\n# Let's just get a quick overall view of survied vs died. \nsns.countplot('Survivor',data=result,palette='Set1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4474da401a27bca67cd683c8ca91e9ef2a36baaa"},"cell_type":"code","source":"# Let's use a factor plot again, but now considering class\nsns.pointplot('Pclass','Survived',data=result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45c19f79c3aa203e2f1a78cc3c4aa83ea7222669"},"cell_type":"code","source":"# Let's use a factor plot again, but now considering class and gender\nsns.pointplot('Pclass','Survived',hue='person',data=result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63510f4811a35833bb6125dc6adffe81eeb22b23"},"cell_type":"code","source":"# Let's use a linear plot on age versus survival\nsns.lmplot('Age','Survived',data=result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4aff5d98f0da925f6ee0630bdf699586d5244232"},"cell_type":"code","source":"# Let's use a linear plot on age versus survival using hue for class seperation\nsns.lmplot('Age','Survived',hue='Pclass',data=result,palette='winter')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"067a778d83a78c1a154ea6e041c30d5dfa90ea73"},"cell_type":"code","source":"# Let's use a linear plot on age versus survival using hue for class seperation\ngenerations=[10,20,40,60,80]\nsns.lmplot('Age','Survived',hue='Pclass',data=result,palette='winter',x_bins=generations)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32b6f0c594d5a01e6f49dd8defd0f49538df4dc0"},"cell_type":"code","source":"sns.lmplot('Age','Survived',hue='Sex',data=result,palette='winter',x_bins=generations)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c60dd31502a6cf46e73f19524058d160ad488dce"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"370a9306dce8a46dff2115e84ad7728b6b7259d4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39600a035853cec1a0a8f1133ffa72b72f9661b8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80d9648f33a5e4853c9e0cb8a82c013e5963ef9a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea2da5845b1874d78e94859a0bac06612725f25a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb221b3aa64154085b933339d4a5b1a397c03e50"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0481727a1cf1893d75e5dfbee17ff590c486b17d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}