{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pandas.plotting import scatter_matrix\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib import rcParams\n#rcParams.update({'figure.autolayout': True})\n\nimport seaborn as sns\nfrom functools import reduce\nimport pylab\nimport scipy.stats as scp\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n%matplotlib inline\n# Any results you write to the current directory are saved as output.","execution_count":54,"outputs":[]},{"metadata":{"_cell_guid":"308cbcb5-ca61-45c4-a34f-51934495069e","_uuid":"eec16a32f4e1ed1f710b012be2edf9d150bf01be","collapsed":true,"trusted":true},"cell_type":"code","source":"#We have there all the functions\n\ndef ecdf(x):\n    \"\"\"\n        Returns the ECDF of the data\n    \"\"\"\n    xs = np.sort(x)\n    ys = np.arange(1, len(xs)+1)/float(len(xs))\n    return xs, ys\n\ndef permutation_sample(data1, data2):\n    \"\"\"\n    Generate a permutation sample from two data sets.\n    \"\"\"\n\n    # Concatenate the data sets: data\n    data = np.concatenate((data1, data2))\n\n    # Permute the concatenated array: permuted_data\n    permuted_data = np.random.permutation(data)\n\n    # Split the permuted array into two: perm_sample_1, perm_sample_2\n    perm_sample_1 = permuted_data[:len(data1)]\n    perm_sample_2 = permuted_data[len(data1):]\n\n    return perm_sample_1, perm_sample_2\n\ndef draw_bs1d_func(data, func, size=10):\n    \"\"\"Generate bootstrap replicate of 1D data\"\"\"\n    bs_replicates = np.empty(size)\n    for i in range(size):\n        bs_replicates[i] = func(np.random.choice(data, len(data)))\n    return bs_replicates\n\ndef draw_bs_pairs_linreg(x, y, size=10):\n    \"\"\"Perform pairs bootstrap for linear regression.\"\"\"\n\n    # Set up array of indices to sample from: inds\n    inds = np.arange(len(x))\n\n    # Initialize replicates: bs_slope_reps, bs_intercept_reps\n    bs_slope_reps = np.empty(size)\n    bs_intercept_reps = np.empty(size)\n\n    # Generate replicates\n    for i in range(size):\n        bs_inds = np.random.choice(inds, size=len(inds))\n        bs_x, bs_y = x[bs_inds], y[bs_inds]\n        bs_slope_reps[i], bs_intercept_reps[i] = np.polyfit(bs_x, bs_y, 1)\n\n    return bs_slope_reps, bs_intercept_reps\n\ndef draw_perm_reps(data_1, data_2, func, size=10):\n    \"\"\"\n    Generate multiple permutation replicates.\n    \"\"\"\n\n    # Initialize array of replicates: perm_replicates\n    perm_replicates = np.empty(size)\n\n    for i in range(size):\n        # Generate permutation sample\n        perm_sample_1, perm_sample_2 = permutation_sample(data_1, data_2)\n\n        # Compute the test statistic\n        perm_replicates[i] = func(perm_sample_1, perm_sample_2)\n\n    return perm_replicates\n\ndef diff_of_means(data_1, data_2):\n    \"\"\"\n    Difference in means of two arrays.\n    \"\"\"\n\n    # The difference of means of data_1, data_2: diff\n    diff = np.mean(data_1) - np.mean(data_2)\n\n    return diff\n\ndef p_value(test_sample, emp_val):\n    \"\"\"\n    Return the p value between an empirical value and a data sample\n    \"\"\"\n    p = np.sum(test_sample >= emp_val) / len(test_sample)\n    return p\n\ndef data_cleaning(df, col_list):\n    \"\"\"\n    Return a dataset with the col_list removed and without duplicates\n    \"\"\"\n    df2 = df.drop(col_list, axis=1)\n    df2.drop_duplicates(inplace=True)\n    return df2\n\ndef mean_comparison(df, column, category1, category2, measure, any_or_but1 = True, any_or_but2 = True):\n    \"\"\"\n    Take a dataframe, a column, two categories and two boolean values whether it is about the categories or anything but the categories\n    On the input dataframe, selects a column and slices the dataframe to get all the data with the input category on the input column (if any_or_but is True)\n    or all data but the ones with the category (if any_or_true is False) into two Series\n    Perfoms a TTest (unequal variances) and bootstraps the two Series to get a distribution of the mean of the measure. Shows them.\n    Returns of the TTest \n    \"\"\"\n    if any_or_but1 == True:\n        s_1 = df[df[column] == category1][measure]\n    elif any_or_but1 == False:\n        s_1 = df[df[column] != category1][measure]\n    if any_or_but2 == True:\n        s_2 = df[df[column] == category2][measure]\n    elif any_or_but2 == False:\n        s_2 = df[df[column] != category2][measure]\n\n    ttest = scp.ttest_ind(s_1, s_2, equal_var = False)\n\n    boots_1 = draw_bs1d_func(s_1, np.mean, size=10000)\n    boots_2 = draw_bs1d_func(s_2, np.mean, size=10000)\n\n    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6,6))\n    if any_or_but1 == True:\n        sns.distplot(boots_1, label = category1)\n    elif any_or_but1 == False:\n        sns.distplot(boots_1, label = 'Anything but ' + category1)\n    if any_or_but2 == True:\n        sns.distplot(boots_2, label = category2)\n    elif any_or_but2 == False:\n        sns.distplot(boots_2, label = 'Anything but ' + category2)\n    plt.xlabel('Mean of the ' + measure)\n    plt.title('Distribution of the ' + measure + ' through bootstrapping')\n    plt.legend(ncol = 2)\n\n    plt.show()\n    plt.close(fig)\n    \n    return ttest","execution_count":55,"outputs":[]},{"metadata":{"_cell_guid":"ce83a447-d62e-48af-8612-b4af3384cd9b","_uuid":"8b17b9e3191a8f32cd1bd8f197e8357d0b56c84b","trusted":true},"cell_type":"code","source":"#Import the datasets\ndf_train = pd.read_csv(\"../input/train.csv\", index_col = 'PassengerId')\ndf_test = pd.read_csv('../input/test.csv', index_col = 'PassengerId')\n\nplt.style.use('seaborn')\ndf_train.info()\ndf_train.head()","execution_count":56,"outputs":[]},{"metadata":{"_cell_guid":"ef8f891f-be2e-4c4d-9a9d-8f40add31fd4","_uuid":"00a9c4c47cb1c0a4f5b3b576bfc1abe51a972d61","trusted":true},"cell_type":"code","source":"sns.countplot(x='Survived', data=df_train)\nprint(df_train.Survived.sum()/df_train.Survived.count())","execution_count":57,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_train[\"Pclass\"] = df_train[\"Pclass\"].astype('category')\ndf_train[\"Sex\"] = df_train[\"Sex\"].astype('category')\ndf_train[\"Embarked\"] = df_train[\"Embarked\"].astype('category')\ndf_train.describe()","execution_count":58,"outputs":[]},{"metadata":{"_cell_guid":"3ea33ba8-3c0c-4cba-97c9-d72cbecf5c05","_uuid":"bfa87155961f4a01753a60dd2b90958473dcec0e","trusted":true},"cell_type":"code","source":"df_train.describe(include=['O'])","execution_count":59,"outputs":[]},{"metadata":{"_cell_guid":"6ea94f07-6ad1-45b6-8487-14311c1308b3","_uuid":"7999c151ece1a7f48dbe622e5da4f1fbd779dd92","collapsed":true,"trusted":true},"cell_type":"code","source":"df_survived = df_train[df_train['Survived'] == 1]\ndf_died = df_train[df_train['Survived'] == 0]","execution_count":60,"outputs":[]},{"metadata":{"_cell_guid":"7859b7e0-1c68-4259-9daa-4c9e74b56d5a","_uuid":"3d001ac62ed307b135df49d3fdcd305bbe216516","trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (12, 6))\n\nplt.subplot(121)\nplt.hist([df_survived.Fare.dropna(), df_died.Fare.dropna()], rwidth = 0.95, stacked = True, color = ['xkcd:blue', 'xkcd:red'], label = ['Survived', 'Died'])\nplt.legend(loc='best')\nplt.title(\"Histogram of the Fare column\")\n\nplt.subplot(122)\nplt.hist([df_survived.Age.dropna(), df_died.Age.dropna()], rwidth = 0.95, stacked = True, color = ['xkcd:blue', 'xkcd:red'], label = ['Survived', 'Died'])\nplt.legend(loc='best')\nplt.title(\"Histogram of the Age column\")","execution_count":61,"outputs":[]},{"metadata":{"_cell_guid":"60a27387-a55a-4a46-ad8c-7529e962c8fb","_uuid":"b363b3468bedfcf12da23b656d125cd13a3504d6","trusted":true},"cell_type":"code","source":"df_train.groupby(['Survived', 'Pclass']).mean()","execution_count":62,"outputs":[]},{"metadata":{"_cell_guid":"c2b167ee-15a2-4911-b3b4-8f3b441016a9","_uuid":"dc68af254ddbe306ac95b98f25b34023e79ac1fa","trusted":true},"cell_type":"code","source":"df_train_stat = df_train.copy()\ndf_train_stat.Survived = df_train_stat.Survived.replace([0,1], ['Died', 'Survived'])\nprint(mean_comparison(df_train_stat, 'Survived', 'Died', 'Survived', 'Fare', any_or_but1 = True, any_or_but2 = True))","execution_count":63,"outputs":[]},{"metadata":{"_cell_guid":"070f43b5-d9bc-4f82-b767-bb1027b85f2a","_uuid":"94a8b73fbfab0716a4826d9aaac4ccecf20c9cf1","trusted":true},"cell_type":"code","source":"print(mean_comparison(df_train_stat.dropna(), 'Survived', 'Died', 'Survived', 'Age', any_or_but1 = True, any_or_but2 = True))","execution_count":64,"outputs":[]},{"metadata":{"_cell_guid":"a195dbc5-08d9-4bd9-bd56-eb2330d9147d","_uuid":"d35b54606db470583ff096c1f4340c1341e62ed0"},"cell_type":"markdown","source":"# Improving the dataset"},{"metadata":{"_cell_guid":"38dcbc62-8fd5-47bf-b2dd-263c027f7ead","_uuid":"34eb78d8bb7d003f7bc1237ffaacaa449d60d8e0","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.feature_selection import RFE\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler","execution_count":65,"outputs":[]},{"metadata":{"_cell_guid":"bd212399-38da-4b60-9c4e-3fd967960a80","_uuid":"537bacda57708ded82defc2269d10bfd3b7eb50b","collapsed":true,"trusted":true},"cell_type":"code","source":"# df_train_ml['Age'].fillna(np.random.normal(df_train_ml['Age'].mean(), df_train_ml['Age'].std()), inplace = True)\n# df_train_ml['Age_Cat'] = pd.cut(df_train_ml['Age'], bins = 10)\n# df_train_ml = pd.get_dummies(df_train, columns = ['Sex', 'Embarked', 'Age_Cat'], drop_first = True)\n# df_train_ml.drop(['Cabin', 'Ticket', 'Name', 'Age'], axis = 1, inplace = True)","execution_count":66,"outputs":[]},{"metadata":{"_cell_guid":"6da300a7-cd5f-4700-8aa3-dee73fc18e89","_uuid":"2bae1ffc2f312082a5d455925c07dbb16fbe0da2","trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\nminmax = MinMaxScaler((-1,1))\n\ndf_train_ml = pd.get_dummies(df_train, columns = ['Sex', 'Embarked'], drop_first = True)\ndf_train_ml['Age'].fillna(np.random.normal(df_train_ml['Age'].mean(), df_train_ml['Age'].std()), inplace = True)\ndf_train_ml['Age_Cat'] = pd.cut(df_train_ml['Age'], bins = 10, labels = [i for i in range(10)])\n\ndf_train_ml['Title'] = df_train_ml['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n#Yes, sadly in 1900 society, women condition seemed mostly determined by their marital status\nman_regular = 'Mr'\nwoman_married = ['Mrs', 'Countess', 'Mme', 'Lady', 'Dona']\nman_upper = ['Master','Dr','Major','Sir','Don']\nwoman_unmarried = ['Miss', 'Mlle', 'Ms']\nother = ['Rev','Col','Major','Capt','Jonkheer']\n\ndf_train_ml['Title'] = df_train_ml['Title'].replace(man_regular, 1)\ndf_train_ml['Title'] = df_train_ml['Title'].replace(woman_married, 2)\ndf_train_ml['Title'] = df_train_ml['Title'].replace(man_upper, 3)\ndf_train_ml['Title'] = df_train_ml['Title'].replace(woman_unmarried, 4)\ndf_train_ml['Title'] = df_train_ml['Title'].replace(other, 5)\n\ndf_train_ml = pd.get_dummies(df_train_ml, columns = ['Title'], drop_first = True)\n\ndf_train_ml.drop(['Cabin', 'Ticket', 'Name', 'Age'], axis = 1, inplace = True)\n\nscaler.fit(df_train_ml[['Fare']])\n\ndf_train_ml[['Fare']] = scaler.transform(df_train_ml[['Fare']])\n\ndf_train_ml.head()","execution_count":67,"outputs":[]},{"metadata":{"_cell_guid":"35bcaa12-83a6-4e74-8c94-9724c8c87594","_uuid":"50ac31752190b4df35f0daa4814fa548e47f0bae","trusted":true},"cell_type":"code","source":"df_test_ml = pd.get_dummies(df_test, columns = ['Sex', 'Embarked'], drop_first = True)\ndf_test_ml['Age'].fillna(np.random.normal(df_test_ml['Age'].mean(), df_test_ml['Age'].std()), inplace = True)\ndf_test_ml['Fare'].fillna(np.random.normal(df_test_ml['Fare'].mean(), df_test_ml['Fare'].std()), inplace = True)\ndf_test_ml['Age_Cat'] = pd.cut(df_test_ml['Age'], bins = 10, labels = [i for i in range(10)])\n\ndf_test_ml['Title'] = df_test_ml['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ndf_test_ml['Title'] = df_test_ml['Title'].replace(man_regular, 1)\ndf_test_ml['Title'] = df_test_ml['Title'].replace(woman_married, 2)\ndf_test_ml['Title'] = df_test_ml['Title'].replace(man_upper, 3)\ndf_test_ml['Title'] = df_test_ml['Title'].replace(woman_unmarried, 4)\ndf_test_ml['Title'] = df_test_ml['Title'].replace(other, 5)\nprint(df_test_ml['Title'])\n\ndf_test_ml = pd.get_dummies(df_test_ml, columns = ['Title'], drop_first = True)\n\ndf_test_ml.drop(['Cabin', 'Ticket', 'Name', 'Age'], axis = 1, inplace = True)\n\ndf_test_ml.head()\n\nscaler.fit(df_test_ml[['Fare']])\ndf_test_ml[['Fare']] = scaler.transform(df_test_ml[['Fare']])\n\ndf_test_ml['PassengerId'] = df_test.index.tolist()\ndf_test_ml.set_index('PassengerId', inplace=True)","execution_count":68,"outputs":[]},{"metadata":{"_cell_guid":"05343143-cb84-4990-9c06-a514fb60d3b8","_uuid":"74c914562301f0f4685cb1ca2a5a3c4a38f7f0bf","trusted":true},"cell_type":"code","source":"corr = df_train_ml.corr()\nsns.heatmap(corr)","execution_count":69,"outputs":[]},{"metadata":{"_cell_guid":"81324528-7604-49f4-9ce8-1c53b7579efd","_uuid":"4d8bd9c687facc56686232148b745b78cb0fed07","trusted":true,"collapsed":true},"cell_type":"code","source":"X_train, X_test = train_test_split(df_train_ml, test_size=0.25)\n\nused_features =[\n    'Pclass'\n    ,'Sex_male'\n    ,'Age_Cat'\n    ,'Fare'\n    ,'Title_2'\n    ,'Title_3'\n    ,'Title_4'\n    ,'Title_5'\n    ,'Embarked_Q'\n    ,'Embarked_S'\n]\n\ny_train = X_train[\"Survived\"]\nX_train = X_train[used_features].values","execution_count":70,"outputs":[]},{"metadata":{"_cell_guid":"c3b418dd-05b0-4265-9df8-6a09a086ef9d","_uuid":"4f176e6dc3c375959a8fee061494f5325db5c7a8","scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Setup the best parameters selection\nn_estimators = [20, 25, 30, 35, 40, 45]\nmax_depth = [i for i in range (7, 11)]\nmin_samples_split = [2, 3, 5, 7]\nparam_grid = {'n_estimators' : n_estimators, 'max_depth' : max_depth, 'min_samples_split' : min_samples_split}\n\ndetc_cv = GridSearchCV(RandomForestClassifier(), param_grid, scoring='accuracy', cv=5)\ndetc_cv.fit(X_train, y_train)\nprint(\"Tuned Decision Tree Parameters: {}\".format(detc_cv.best_params_)) \nprint(\"Best score is {}\".format(detc_cv.best_score_))\n\n#Instantiate the classifier\nrfc = RandomForestClassifier(\n    n_estimators = detc_cv.best_params_['n_estimators'],\n    max_depth = detc_cv.best_params_['max_depth'],\n    min_samples_split = detc_cv.best_params_['min_samples_split'],\n    min_impurity_decrease = 0.01)\n\n# Train classifier\nrfc.fit(\n    X_train,\n    y_train\n)\n\ny_pred = rfc.predict(X_test[used_features])\n\n# Show features importance\nfor i in range(len(rfc.feature_importances_)):\n    print(\"Importance of {} : {}\".format(used_features[i], rfc.feature_importances_[i]))\n\n# Print results\nprint(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n      .format(\n          X_test.shape[0],\n          (X_test[\"Survived\"] != y_pred).sum(),\n          100*(1-(X_test[\"Survived\"] != y_pred).sum()/X_test.shape[0])\n))\n\nprint(confusion_matrix(X_test['Survived'], y_pred))\nprint(classification_report(X_test['Survived'], y_pred))","execution_count":71,"outputs":[]},{"metadata":{"_cell_guid":"7f47f1e9-383c-4979-bdc6-c248cad87f34","_uuid":"c864b8f6b6ce1c7cabac3899f266daf33d10661c","trusted":true},"cell_type":"code","source":"X_predict_rfc = df_test_ml[used_features]\ndf_test_ml['SurvivedRFC'] = rfc.predict(X_predict_rfc).astype(int)\ndf_rfc = df_test_ml['SurvivedRFC'].rename('Survived')\ndf_rfc.to_csv('SubmissionRFC.csv', header=True)\ndf_rfc.head()","execution_count":72,"outputs":[]},{"metadata":{"_cell_guid":"b2c9ba04-dfe3-4d6d-907e-13f6f4f52ed7","_uuid":"0315578dca1ef340832b08ba501d559a06a8e866","trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\n# Setup the best parameters selection\nc_space = [i for i in range (1, 2, 9)]\ngamma = [0.25, 0.5, 1]\ndegree = [i for i in range (2, 5)]\nkernel = ['poly','rbf','linear']\nparam_grid = {'C' : c_space, 'gamma' : gamma, 'degree' : degree, 'kernel': kernel}\n\nsvc_cv = GridSearchCV(SVC(), param_grid, scoring='accuracy', cv=5)\nsvc_cv.fit(X_train, y_train)\nprint(\"Tuned Support Vector Machine Parameters: {}\".format(svc_cv.best_params_)) \nprint(\"Best score is {}\".format(svc_cv.best_score_))\n                \n#Instantiate the classifier\nsvc = SVC(\n    C = svc_cv.best_params_['C'],\n    gamma = svc_cv.best_params_['gamma'],\n    degree = svc_cv.best_params_['degree'],\n    kernel = svc_cv.best_params_['kernel'],\n    probability = True\n         )\n\n# Train classifier\nsvc.fit(\n    X_train,\n    y_train\n)\n\ny_pred = svc.predict(X_test[used_features])\n\n# Print results\nprint(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n      .format(\n          X_test.shape[0],\n          (X_test[\"Survived\"] != y_pred).sum(),\n          100*(1-(X_test[\"Survived\"] != y_pred).sum()/X_test.shape[0])\n))\n\nprint(confusion_matrix(X_test['Survived'], y_pred))\nprint(classification_report(X_test['Survived'], y_pred))","execution_count":73,"outputs":[]},{"metadata":{"_cell_guid":"845a8f23-dec5-46c1-b784-b935c1c8b300","_uuid":"b0e421133dea15ac23af8d7328dca1e5984f2914","trusted":true},"cell_type":"code","source":"X_predict_svc = df_test_ml[used_features]\ndf_test_ml['SurvivedSVC'] = svc.predict(X_predict_svc).astype(int)\ndf_svc = df_test_ml['SurvivedSVC'].rename('Survived')\ndf_svc.to_csv('SubmissionSVC.csv', header=True)\ndf_svc.head()","execution_count":74,"outputs":[]},{"metadata":{"_cell_guid":"591956fc-1c64-4944-a014-cf5fe7f2cf34","_uuid":"3c1d32f4a369d61436f50a5a18e1773a4aa02df5","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# Setup the best parameters selection\nc_space = [1, 3, 5, 7, 10]\nsolvers = ['sag', 'saga', 'newton-cg', 'lbfgs', 'liblinear']\nmulti_class = ['ovr']\nparam_grid = {'solver': solvers, 'multi_class': multi_class, 'C' : c_space}\n\nlre_cv = GridSearchCV(LogisticRegression(max_iter = 500), param_grid, scoring='accuracy', cv=5)\nlre_cv.fit(X_train, y_train)\nprint(\"Tuned Logistic Regression Parameters: {}\".format(lre_cv.best_params_)) \nprint(\"Best score is {}\".format(lre_cv.best_score_))\n\n#Instantiate the classifier\nlre = LogisticRegression(solver = lre_cv.best_params_['solver'], \n                         max_iter = 500, \n                         multi_class = lre_cv.best_params_['multi_class'], \n                         C = lre_cv.best_params_['C'])\n\n# Train classifier\nlre.fit(\n    X_train,\n    y_train\n)\ny_pred = lre.predict(X_test[used_features])\n\n# Print results\nprint(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n      .format(\n          X_test.shape[0],\n          (X_test[\"Survived\"] != y_pred).sum(),\n          100*(1-(X_test[\"Survived\"] != y_pred).sum()/X_test.shape[0])\n))\n\nprint(confusion_matrix(X_test['Survived'], y_pred))\nprint(classification_report(X_test['Survived'], y_pred))","execution_count":75,"outputs":[]},{"metadata":{"_cell_guid":"e8243768-fb84-44ab-a053-fb09d2bdbe59","_uuid":"1c4980551dabdfea78ce88812fab7df4c72f1b57","trusted":true},"cell_type":"code","source":"X_predict_lre = df_test_ml[used_features]\ndf_test_ml['SurvivedLRE'] = rfc.predict(X_predict_lre).astype(int)\ndf_lre = df_test_ml['SurvivedLRE'].rename('Survived')\ndf_lre.to_csv('SubmissionLRE.csv', header=True)\ndf_lre.head()","execution_count":76,"outputs":[]},{"metadata":{"_cell_guid":"ed0f840e-6d93-4673-b687-2f8549100890","_uuid":"1a1f15b5eb5a6bf621a1b336e2f790c9871fe4d0","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\neclf = VotingClassifier(estimators=[('svc', svc), ('rf', rfc), ('lr', lre)], voting='soft')\n\neclf.fit(X_train, y_train)\n\nX_predict_eclf = df_test_ml[used_features]\ndf_test_ml['SurvivedECLF'] = rfc.predict(X_predict_eclf).astype(int)\ndf_eclf = df_test_ml['SurvivedECLF'].rename('Survived')\ndf_eclf.to_csv('SubmissionECLF.csv', header=True)\ndf_eclf.head()","execution_count":77,"outputs":[]},{"metadata":{"_cell_guid":"7e08b89a-ff8c-424a-ae09-0d8be54c469c","_uuid":"1d99a2fa6c66a2bb0cae17d63716bb78e2ada80b","trusted":true},"cell_type":"code","source":"import keras\nfrom keras.layers import Dense, Dropout\nfrom keras.models import Sequential\nfrom keras.utils import to_categorical\nfrom keras.optimizers import Adam, rmsprop, SGD\nfrom keras.callbacks import EarlyStopping\nfrom keras import regularizers\n\ntarget = to_categorical(df_train_ml.Survived)\nused_features =[\n    'Pclass'\n    ,'Sex_male'\n    ,'Age_Cat'\n    ,'Title_2'\n    ,'Title_3'\n    ,'Title_4'\n    ,'Title_5'\n    ,'Fare'  \n    ,'Embarked_Q'\n    ,'Embarked_S'\n]\npredictors = df_train_ml[used_features]\n#predictors = df_train.drop('price_range', axis=1)\nnb_features = len(predictors.columns)\n\ndef get_new_model():\n    # Set up the model: model\n    model = Sequential()\n    model.add(Dense(50, kernel_initializer='uniform', activation='relu', input_shape=(nb_features,)))\n    model.add(Dropout(0.2))\n    model.add(Dense(50, kernel_initializer='uniform', activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(50, kernel_initializer='uniform', activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(2, activation='softmax'))\n    return model","execution_count":88,"outputs":[]},{"metadata":{"_cell_guid":"5d948bae-512b-4994-9883-09a09c3ebfa9","_uuid":"068c267a79bc11c22bc959b6aba6888dd321411f","trusted":true},"cell_type":"code","source":"# Create list of learning rates: lr_to_test\nlr_to_test = [0.000001, 0.0001, 0.01, 1]\n\n# Loop over learning rates\nfor lr in lr_to_test:\n    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n    \n    # Build new model to test, unaffected by previous models\n    model = get_new_model()\n    \n    # Create SGD optimizer with specified learning rate: my_optimizer\n    my_optimizer = Adam(lr=lr)\n    \n    # Compile the model\n    model.compile(optimizer = my_optimizer, loss = 'categorical_crossentropy')\n    \n    # Fit the model\n    model.fit(predictors, target, validation_split = 0.3)","execution_count":80,"outputs":[]},{"metadata":{"_cell_guid":"0d378956-ea0a-44dc-9041-75d51c26a829","_uuid":"f5fcdade43879ded9bca0239c74858c4d1873fe0","trusted":true},"cell_type":"code","source":"model = get_new_model()\nmy_optimizer = Adam(lr=0.01)\nmodel.compile(my_optimizer, loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n\n# Define early_stopping_monitor\nearly_stopping_monitor = EarlyStopping(patience = 3)\n\nmodel.fit(predictors, target, epochs = 30, verbose = 1, validation_split = 0.25, callbacks = [early_stopping_monitor])","execution_count":89,"outputs":[]},{"metadata":{"_cell_guid":"4c65f76b-bd8b-4666-b42d-75a041f23563","_uuid":"09d63443275bec69b31b9a2b44cebbeb75d0267b","collapsed":true,"trusted":true},"cell_type":"code","source":"y_predict = model.predict_classes(df_test_ml[used_features])\ndf_test_ml['SurvivedNN'] = model.predict_classes(df_test_ml[used_features]).astype(int)\ndf_nn = df_test_ml['SurvivedNN'].rename('Survived')\ndf_nn.to_csv('SubmissionNN.csv', header=True)","execution_count":90,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}