{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sklearn\nimport re\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\nfullset = [train, test] \ntrain.columns\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92db4afd3b7a650800e34fd19685056ec265a882"},"cell_type":"markdown","source":"The following EDA and feature engineering are inspired  by Sina: https://www.kaggle.com/sinakhorami/titanic-best-working-classifier\n"},{"metadata":{"trusted":true,"_uuid":"6591757afacc1f7ff6c8d605f2574cb5eb5f5c6d"},"cell_type":"code","source":"# Feature Engineering\n\n# Let's tackle each feature one by one\n# PassengerId, leave it there?\n# Survived: our target\n# Pclass\ntrain.Pclass.isnull().value_counts() # there are no null values\n# train.Sex.value_counts()\n# train.Sex.isnull().value_counts()\n# test.Sex.isnull().value_counts()\nfor dataset in fullset:\n    # Sex: let's convert Sex into binary variable. Non-binary shouldn't exist back then right?\n    dataset['Sex'] = dataset['Sex'].map({'male': 0, 'female': 1}).astype(int)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bba1be4edf74129d9a35c36a167691ec2441bb2"},"cell_type":"code","source":"# for age we need imputation\nfor dataset in fullset:\n    age_mean = dataset['Age'].mean()\n    age_std = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    age_imp = np.random.randint(age_mean - age_std,age_mean + age_std, size = age_null_count)\n    \n    dataset['Age'][np.isnan(dataset['Age'])] = age_imp\n    dataset['Age'] = dataset['Age'].astype(int)\n    dataset['Categorical_Age'] = pd.qcut(dataset['Age'],4)\n    \nprint(train[['Survived','Categorical_Age']].groupby(['Categorical_Age'],as_index = False).mean())\nfor dataset in fullset:\n    dataset.loc[dataset['Age']<=21.0,'Age'] = 0\n    dataset.loc[(dataset['Age']>21.0)&(dataset['Age']<=28.0),'Age'] = 1\n    dataset.loc[(dataset['Age']>28.0)&(dataset['Age']<=38.0),'Age'] = 2\n    dataset.loc[dataset['Age']>38.0,'Age'] = 4\n    dataset['Age'] = dataset['Age'].astype(int)\n    \nprint(dataset['Age'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"916052364842b6f523023421f95b29743809e62b"},"cell_type":"code","source":"# Create feature FamilySize from sibsp and parch\nfor dataset in fullset:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\nprint (train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a038ab467e3cab10d22ee879f63189392561200"},"cell_type":"code","source":"train['Fare'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0c30257c1103a7001ddb1b5db3f8fa3b2b1df86"},"cell_type":"code","source":"# Fare\n\ntest['Fare'].isnull().value_counts() # only one missing value in testing set\n# we can just use mean imputation\ntest['Fare'] = test['Fare'].fillna(test['Fare'].mean())\nfor dataset in fullset:\n    dataset['Categorical_Fare'] = pd.qcut(dataset['Fare'],4)\n    \nprint(train[['Survived','Categorical_Fare']].groupby('Categorical_Fare',as_index = False).mean())\nprint(train['Categorical_Fare'].value_counts())\nprint(test['Categorical_Fare'].value_counts())\n\nfor dataset in fullset:\n    dataset.loc[dataset['Fare']<=7.91,'Fare'] = 0\n    dataset.loc[(dataset['Fare']<=14.454) & (dataset['Fare']>7.91),'Fare'] = 1\n    dataset.loc[(dataset['Fare']<=31.0) & (dataset['Fare']>14.454),'Fare'] = 2\n    dataset.loc[dataset['Fare']>31.0,'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\nprint(train['Fare'].value_counts())\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af5826f1430ca14f5d04002f862fcccfece21992"},"cell_type":"code","source":"# Cabin Number\ntrain.Cabin.isnull().value_counts()\n# perhaps no need for using this feature??","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7eb2b294b25af44b3b5beb1995de0d994153945"},"cell_type":"code","source":"# Embarked\ntrain.Embarked.isnull().value_counts() # 2 missing values\ntest.Embarked.isnull().value_counts()  # no missing values\n# impute using median\ntrain['Embarked'] = train['Embarked'].fillna('S')\n# train.Embarked.value_counts() # 2 missing values\n\n\n# converting\nembarked_mapping = {'C':0,'Q':1,'S':2}\nfor dataset in fullset:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping).astype(int)\n\nprint(train[['Survived','Embarked']].groupby(['Embarked'],as_index = False).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcccab55055f3fd5f2b15ebf6ad429410bf0e19d"},"cell_type":"code","source":"# credit to Sina \ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    # If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\nfor dataset in fullset:\n    dataset['Title'] = dataset['Name'].apply(get_title)\n\nprint(pd.crosstab(train['Title'], train['Sex']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89947466a7872c720baba6e367367bbbc14346db"},"cell_type":"code","source":"# Here let's be creative and get some manual feature different from the original\nfor dataset in fullset:\n    dataset['Title'] = dataset['Title'].replace(['Capt','Major','Col'],'Military')\n    dataset['Title'] = dataset['Title'].replace(['Countess','Don','Dona','Jonkheer','Lady','Master','Sir'],'Nobility')\n    dataset['Title'] = dataset['Title'].replace(['Dr','Rev'],'Educated')\n    #common sense replacement\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \nprint(train[['Survived','Title']].groupby(['Title'],as_index = False).mean())\nprint(test['Title'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"becbc07dafd21b16eee75d17056b85ae253a359a"},"cell_type":"code","source":"title_mapping = {'Educated': 0, 'Military':1,'Miss':2,'Mr':3,'Mrs':4,'Nobility':5}\nfor dataset in fullset:\n    dataset['Title'] = dataset['Title'].map(title_mapping).astype(int)\n    \nprint(train['Title'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# preparing training and testing dataset\ntrain_X = train.drop(['Survived','Name','Ticket','Categorical_Age','Categorical_Fare',\n                     'PassengerId','SibSp','Parch','Cabin'],axis = 1)\n# test_X = test.drop(['Name','Ticket'],axis = 1)\ntrain_y = train['Survived']\ntest_X = test.drop(['Name','Ticket','Categorical_Age','Categorical_Fare',\n                     'PassengerId','SibSp','Parch','Cabin'],axis = 1)\n# retain only numpy array\ntrain_X = train_X.values\ntrain_y = train_y.values\ntest_X = test_X.values\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62971bc5c2c057b84a14101c6f75234079f51cc7"},"cell_type":"markdown","source":"Investigate different classifiers:\n* Logistic Regression\n* SVM\n* Decision Tree\n* Random Forest\n* AdaBoost\n* Gradient Boosting Classifier\n* Multilayer perceptron\n* Gaussian Naive Bayes\n* Linear Discriminant Analysis\n* K-Nearest Neighbor\n\n\n"},{"metadata":{"trusted":true,"_uuid":"baf1eeb049cd199d4dcf960f1ef0cabcbc2371c5"},"cell_type":"code","source":"# import model\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score\n\nsss = StratifiedShuffleSplit(n_splits = 10,test_size= 0.1,random_state = 10)\nsss.split(train_X,train_y)\nclassifiers = [SVC(),\n               RandomForestClassifier(),\n               AdaBoostClassifier(),\n               GradientBoostingClassifier(),\n               LogisticRegression(),\n               GaussianNB(),\n               KNeighborsClassifier(),\n               LinearDiscriminantAnalysis(),\n               MLPClassifier(),\n               DecisionTreeClassifier()]\n\nacc_table = {} # a dictionary store the prediction\nfor train_index, test_index in sss.split(train_X,train_y):\n    train_X_cv, test_X_cv = train_X[train_index],train_X[test_index]\n    train_y_cv, test_y_cv = train_y[train_index],train_y[test_index]\n    for clf in classifiers:\n        name = clf.__class__.__name__\n        clf.fit(train_X_cv,train_y_cv)\n        predict_y = clf.predict(test_X_cv)\n        acc = accuracy_score(test_y_cv,predict_y)\n        if name in acc_table:\n            acc_table[name] += acc\n        else:\n            acc_table[name] = acc\n\nfor name in acc_table:\n    acc_table[name] = acc_table[name]/10.0\nprint(acc_table)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eaecc7afab1e0a5c195f04f2b22a58d4884a5a42"},"cell_type":"code","source":"# print()\n# acc_df = pd.DataFrame(acc_table.items(),columns = ['Classifier','Accuracy'])\n\nacc_df = pd.DataFrame(list(acc_table.items()),columns = ['Classifier','Accuracy'])\n# acc_df.index.name = 'Classifier'\n# acc_df.reset_index()\nacc_df = acc_df.sort_values('Accuracy',ascending = 0)\n# acc_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3319b9d7cae99179bdebaacec66313906c1a20bb"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.xlabel('Accuracy')\nplt.title('Classifier Accuracy')\n\nsns.set_color_codes(\"muted\")\nsns.barplot(x='Accuracy', y='Classifier', data=acc_df, color=\"b\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}