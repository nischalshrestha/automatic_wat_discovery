{"cells": [{"outputs": [], "metadata": {"_cell_guid": "d04cb595-fda4-4d52-b1cc-3fb0d4377edd", "_execution_state": "idle", "_uuid": "269a8b7dcb46117e532c6bc63d0bee8ac1bbe24a"}, "execution_count": null, "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import re\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "color = sns.color_palette()\n", "from sklearn.metrics import confusion_matrix\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."]}, {"outputs": [], "metadata": {"_cell_guid": "372157a0-6910-4992-8779-a6ce5fba5c67", "_execution_state": "idle", "_uuid": "82f7d06e07aa59bb6bd0b320e75d076ca8e5c6f8", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["train_df = pd.read_csv('../input/train.csv')\n", "test_df = pd.read_csv('../input/test.csv')\n", "sub_df = pd.read_csv('../input/genderclassmodel.csv')"]}, {"outputs": [], "metadata": {"_cell_guid": "6674ad1c-10f0-4c28-89cc-5c21266d6495", "_execution_state": "idle", "_uuid": "4c11432ba269d485590d6334db2c4fc5af6038f3"}, "execution_count": null, "cell_type": "code", "source": ["train_df.head(2)"]}, {"outputs": [], "metadata": {"_cell_guid": "8d24bf03-3bee-4fc7-b8fb-330eff2b15ba", "_uuid": "53f22d784a75b5022a78d28b39ae9003bd212ed6"}, "execution_count": null, "cell_type": "code", "source": ["train_df.info()\n", "print('---------------------------')\n", "test_df.info()"]}, {"source": ["**We can know there are some columns have unknown value.**"], "metadata": {"_cell_guid": "4798348b-a786-42c4-ac03-792a0ef5b990", "_uuid": "41cec724e135780f3667ceaf3527d3c2f5e5ff81"}, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "111de5ec-9fce-4a83-a559-f9ad87533bd8", "_uuid": "eb14b46baf29ffccad885ae9971c02734311d9fc", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["def has_cabin(data):\n", "    data['Has_Cabin'] = data[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n", "\n", "def sex_map(data):\n", "    data['Sex'] = data['Sex'].map({'female':0, 'male':1}).astype(int)\n", "\n", "def familysize(data):\n", "    data['Family_Size'] = data['SibSp'] + data['Parch'] + 1\n", "\n", "def get_title(name):\n", "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n", "    # If the title exists, extract and return it.\n", "    if title_search:\n", "        return title_search.group(1)\n", "    return \"\"\n", "\n", "def title_name(data):\n", "    data['Title'] = data['Name'].apply(get_title)\n", "    #-------------------training dataset-------------------------\n", "    #Mr          517\n", "    #Miss        182\n", "    #Mrs         125\n", "    #Master       40\n", "    #Dr_7, Rev_6, Col_2, Major_2, Mlle_2, Lady_1\n", "    #Sir_1, Countess_1, Don_1, Capt_1, Mme_1, Ms_1, Jonkheer_1\n", "    data['Title'] = data['Title'].replace(['Countess','Capt', 'Col','Don', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n", "    data['Title'] = data['Title'].replace(['Mlle', 'Lady', 'Ms'], 'Miss')\n", "    data['Title'] = data['Title'].replace('Dr', 'Master')\n", "    data['Title'] = data['Title'].replace('Mme', 'Mrs')\n", "    data['Title'] = data['Title'].replace('Sir', 'Mr')\n", "    #Mapping title\n", "    data['Title'] = data['Title'].map({\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5})\n", "    #Remove all NULLS in the Title column\n", "    data['Title'] = data['Title'].fillna(0)\n", "\n", "def embarked_map(data):\n", "    # Mapping Embarked\n", "    data['Embarked'] = data['Embarked'].map( {'S': 1, 'C': 2, 'Q': 3} )\n", "    #Remove all NULLS in the Embarked column\n", "    data['Embarked'] = data['Embarked'].fillna(0).astype(int)\n", "        "]}, {"outputs": [], "metadata": {"_cell_guid": "eab8a153-f611-471e-a8bf-752b70ce716d", "_uuid": "d4ded9292ff3b3f61b113df054c84d6c9a080012"}, "execution_count": null, "cell_type": "code", "source": ["plt.figure(figsize=(12, 8))\n", "sns.kdeplot(train_df.Fare, shade=True)\n", "plt.title('Fare distribution', fontsize = 15)\n", "plt.xlabel('Fare', fontsize = 12)\n", "plt.ylabel('Percent', fontsize = 12)\n", "plt.show()"]}, {"outputs": [], "metadata": {"_cell_guid": "dfa2b13b-f1aa-4756-a55b-e8695ba3bf8f", "_uuid": "1503d97ef039600cca25e5c9e35a08905f0437f7"}, "execution_count": null, "cell_type": "code", "source": ["train_fare = train_df.groupby('Fare')['Fare'].count()\n", "for i in range(0, len(train_fare)):\n", "    k = train_fare[0:train_fare.index[i]].sum()\n", "    if ((k/train_fare.sum()* 100) >= 15) & ((k/train_fare.sum()* 100) <= 17):\n", "        print('Fare that appear less than {} times: {}%'.format(train_fare.index[i], k/train_fare.sum()* 100))\n", "    elif ((k/train_fare.sum()* 100) >= 49) & ((k/train_fare.sum()* 100) <= 51):\n", "        print('Fare that appear less than {} times: {}%'.format(train_fare.index[i], k/train_fare.sum()* 100))\n", "    elif ((k/train_fare.sum()* 100) >= 84) & ((k/train_fare.sum()* 100) <= 86):\n", "        print('Fare that appear less than {} times: {}%'.format(train_fare.index[i], k/train_fare.sum()* 100))"]}, {"source": ["**From the above, we can be divided into four kinds of fares. (15%, 50%, 84%, 100%)**"], "metadata": {"_cell_guid": "4bf6b678-519c-4219-b831-ede0569253b3", "_uuid": "02125b220f86c37492112049527673a1b9a4a44d"}, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "4101eac3-8f19-4e90-a4cc-4262f493b01e", "_uuid": "f30cf0bafd230db5e2dec27d05ae71ca5f9b1479", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["def fare_map(data):\n", "    # Mapping Fare\n", "    data.loc[ data['Fare'] <= 7.8, 'Fare'] = 1\n", "    data.loc[(data['Fare'] > 7.8) & (data['Fare'] <= 14.455 ), 'Fare'] = 2\n", "    data.loc[(data['Fare'] > 14.455 ) & (data['Fare'] <= 54), 'Fare']   = 3\n", "    data.loc[ data['Fare'] > 54, 'Fare'] = 4\n", "    #Remove all NULLS in the Fare column\n", "    data['Fare'] = data['Fare'].fillna(0)\n", "    data['Fare'] = data['Fare'].astype(int)\n", "    "]}, {"outputs": [], "metadata": {"_cell_guid": "85ccc71a-3e83-4190-8e69-0b1ce6012cc1", "_uuid": "a713c21cffc68b96b39e604febc6fe6c21fd330c"}, "execution_count": null, "cell_type": "code", "source": ["plt.figure(figsize=(12, 8))\n", "sns.kdeplot(train_df.Age, shade=True)\n", "plt.title('Age distribution', fontsize = 15)\n", "plt.xlabel('Age', fontsize = 12)\n", "plt.ylabel('Percent', fontsize = 12)\n", "plt.show()"]}, {"outputs": [], "metadata": {"_cell_guid": "1a9b3f03-1775-479d-a5ce-a452e6d0c28c", "_uuid": "0c27724424248be50030fe6dffc89e7953d048ee"}, "execution_count": null, "cell_type": "code", "source": ["train_age = train_df.groupby('Age')['Age'].count()\n", "for i in range(0, len(train_age)):\n", "    k = train_age[0:train_age.index[i]].sum()\n", "    if ((k/train_age.sum()* 100) >= 15) & ((k/train_age.sum()* 100) <= 17):\n", "        print('Age that appear less than {} times: {}%'.format(train_age.index[i], k/train_age.sum()* 100))\n", "    elif ((k/train_age.sum()* 100) >= 49) & ((k/train_age.sum()* 100) <= 51):\n", "        print('Age that appear less than {} times: {}%'.format(train_age.index[i], k/train_age.sum()* 100))\n", "    elif ((k/train_age.sum()* 100) >= 84) & ((k/train_age.sum()* 100) <= 86):\n", "        print('Age that appear less than {} times: {}%'.format(train_age.index[i], k/train_age.sum()* 100))"]}, {"source": ["**From the above, we can be divided into four kinds of Ages. (15%, 50%, 84%, 100%)**"], "metadata": {"_cell_guid": "c0fb246b-1357-4ff0-8811-96bf2df726f2", "_uuid": "a76bd9b8a300465b7c710a84d959d2339ab3a2f7"}, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "cdcb34ad-065d-4f56-bde9-d7fcaa4e055e", "_uuid": "5aada6f464a4524974e29b0c241d748b79ada17c", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["def age_map(data):\n", "    # Mapping age\n", "    data.loc[ data['Age'] <= 17, 'Age'] = 1\n", "    data.loc[(data['Age'] > 17) & (data['Age'] <= 28 ), 'Age'] = 2\n", "    data.loc[(data['Age'] > 28 ) & (data['Age'] <= 45), 'Age']   = 3\n", "    data.loc[ data['Age'] > 45, 'Age'] = 4\n", "    #Remove all NULLS in the Age column\n", "    data['Age'] = data['Age'].fillna(0)\n", "    data['Age'] = data['Age'].astype(int)"]}, {"outputs": [], "metadata": {"_cell_guid": "4e5029d7-b201-4032-9b33-839af1085ad6", "_uuid": "394af543fc824bb3daa56335c815f6c31064b943", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["def data_map(data):\n", "    has_cabin(data)\n", "    sex_map(data)\n", "    familysize(data)\n", "    title_name(data)\n", "    embarked_map(data)\n", "    fare_map(data)\n", "    age_map(data)\n", "    return data\n", "#---------------------------------\n", "train_data = data_map(train_df)\n", "test_data = data_map(test_df)\n", "train_data = train_data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis = 1)\n", "test_data = test_data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis = 1)"]}, {"outputs": [], "metadata": {"_cell_guid": "d1f805d7-60ce-4483-83a6-6147d4a0bd2e", "_uuid": "ebdb54f2aadca76a71a43d965290a9b0a01f2b43"}, "execution_count": null, "cell_type": "code", "source": ["train_data.head(3)"]}, {"source": ["**This table has been fully numeric.**"], "metadata": {"_cell_guid": "a77de62f-e245-42ff-bc28-7a0d16f547c1", "_uuid": "6add10b8d79a78faca13dce6874f2b5e4625e941"}, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "dc6d55ef-3f95-4e5c-9ea5-11f9cb7b1cd5", "_uuid": "5bb8f7076985652874e9c3f5536809cee7ae8661"}, "execution_count": null, "cell_type": "code", "source": ["colormap = plt.cm.viridis\n", "plt.figure(figsize=(10,10))\n", "plt.title(' The Absolute Correlation Coefficient of Features', y=1.05, size=15)\n", "sns.heatmap(abs(train_data.astype(float).corr()),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True, )\n", "plt.show()"]}, {"source": ["**From this figure, we can know there are 5 features that have a higher relationship with survival (Pclass, Sex, Fare, Has_Cabin, and Title).**\n", "\n", "**We take off the lower correlation coefficient of features, and generate some pair plots to observe the distribution of data from one feature to the other. **\n"], "metadata": {"_cell_guid": "9b861d1a-634f-49ef-92f1-9a4dc9a2e1e5", "_uuid": "82b99ee1bce20aaca4948227c607bad3f88c9879"}, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "58405e09-ee35-4797-8b50-3eaaebc6d2f8", "_uuid": "f610ccf69349b6aa11e340bded64c42ff170dde1"}, "execution_count": null, "cell_type": "code", "source": ["plt.figure(figsize=(15,15))\n", "sns.pairplot(train_data[[u'Survived', u'Pclass', u'Sex', u'Parch', u'Fare', u'Embarked', u'Has_Cabin', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10)).set(xticklabels=[])\n", "plt.show()"]}, {"source": ["**The following began to build neural networks**\n", "* I use the tflearn model to build neural networks."], "metadata": {"_cell_guid": "72954f50-fae6-45b7-ba9d-47d2c10dc01b", "_uuid": "a67669f3c0e43b5c9a3c12e3bd033b943a917a5c", "collapsed": true}, "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["from tpot import TPOTClassifier"]}, {"outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "source": []}, {"outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "source": []}, {"outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "source": []}, {"outputs": [], "metadata": {"_cell_guid": "273fc91e-0eee-4be4-9f8e-de343209925b", "_uuid": "d188b10d99916cbffe40b3066fd1a3ef5cdbdd17", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["import tensorflow as tf\n", "import tflearn as tfl\n", "\n", "def survived_logic(data):\n", "    x = []\n", "    for i in range(len(data.Survived)):\n", "        if data.Survived[i] == 0:\n", "            x.append(np.array([0, 1]))\n", "        elif data.Survived[i] == 1:\n", "            x.append(np.array([1, 0]))\n", "    return x\n", "#----------------------------dataset-----------------------------------\n", "train_x = np.array(train_data.drop(['Survived'], axis = 1)).tolist()\n", "train_y = survived_logic(train_data)\n", "test_x = np.array(test_data).tolist()\n", "#---------------------------------------------------------------------"]}, {"source": ["Change Survived data to Binary type."], "metadata": {"_cell_guid": "cc05b2be-a380-42a9-bf0e-9e53f0556587", "_uuid": "b4493873b220238fb775a704d2a06b37f9bcee87"}, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "bb0da92b-6223-4f69-993d-512ba7aec9c2", "_uuid": "8244dade0efd6a9e383b1308d397f15de8c07c83", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["#----------------------------model build---------------------------------------\n", "def network_structure():\n", "    network = tfl.layers.core.input_data(shape=[None, 10], name='Input')\n", "    network = tfl.layers.core.fully_connected(network, 10, activation='relu')\n", "    network = tfl.layers.core.fully_connected(network, 22, activation='tanh')\n", "    network = tfl.layers.core.fully_connected(network, 35, activation='relu')\n", "    network = tfl.layers.core.fully_connected(network, 44, activation='relu')\n", "    network = tfl.layers.core.fully_connected(network, 25, activation='relu')\n", "    network = tfl.layers.core.fully_connected(network, 10, activation='relu')\n", "    network = tfl.layers.core.fully_connected(network, 2, activation='softmax')\n", "    network = tfl.layers.estimator.regression(network, optimizer='adam', learning_rate=0.001, loss='categorical_crossentropy', name='Targets')\n", "    model = tfl.DNN(network)\n", "    return model\n", "#---------------------------------------------------------------------------------\n", "model = network_structure()\n", "#training model\n", "import random\n", "for _ in range(10):\n", "    samp = random.sample(range(len(train_x)), 500)\n", "    train_x_samp = []\n", "    train_y_samp = []\n", "    for j in range(len(samp)):\n", "        train_x_samp.append(train_x[j])\n", "        train_y_samp.append(train_y[j])\n", "    model.fit({'Input': train_x_samp}, {'Targets': train_y_samp}, n_epoch=50, validation_set = 0.3, snapshot_step=100, show_metric=True)"]}, {"source": ["If the training data is not enough, we can use for_loop and random function to train more times."], "metadata": {"_cell_guid": "8ba53196-de87-4399-bc04-3ff7e5b82109", "_uuid": "d2d256736e89ba2d2079b2730f67bfec13f6b172"}, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "04729d84-127a-45f1-83e8-1072d24a0c7d", "_uuid": "a124276930250d9b82e42a10d759f1bb15d36c45", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["#------------------------prediction-----------------------------------------\n", "temp = model.predict(test_x)\n", "test_y = []\n", "for i in range(len(temp)):\n", "    if temp[i][0] > temp[i][1]:\n", "        test_y.append(1)\n", "    else:\n", "        test_y.append(0)\n", "t_y = pd.Series(test_y).reset_index()\n", "print(\"\\n Predicted output: \")\n", "print(test_y)\n", "plt.figure(figsize=(12,8))\n", "sns.barplot(t_y.index[0:50], test_y[0:50], alpha = 0.8, color=color[0])\n", "plt.xlabel('Test ID', fontsize=12)\n", "plt.ylabel('Survived', fontsize=12)\n", "plt.title('Survival or not in testing data', fontsize=15)\n", "plt.show()"]}, {"outputs": [], "metadata": {"_cell_guid": "8bc79a33-4b47-4bae-a8bc-f9b535443974", "_uuid": "adaa433c13728d23ee65907518480346189e49a3", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["#------------------------------Confusion Matrix---------------------------------\n", "cnf_matrix = confusion_matrix(sub_df.Survived.tolist(), test_y)\n", "df_cm = pd.DataFrame(cnf_matrix, index = ['Non Survived', 'Survived'], columns = ['Non Survived', 'Survived'])\n", "plt.figure(figsize = (12,8))\n", "sns.heatmap(df_cm, annot=True)\n", "plt.ylabel('True label', fontsize=12)\n", "plt.xlabel('Predicted label', fontsize=12)\n", "plt.title('Confusion Matrix', fontsize=15)\n", "plt.show()\n", "sensitivity = cnf_matrix[1][1]/(cnf_matrix[1][1]+cnf_matrix[0][1])\n", "specificity = cnf_matrix[0][0]/(cnf_matrix[0][0]+cnf_matrix[1][0])\n", "acc = (cnf_matrix[0][0]+cnf_matrix[1][1])/cnf_matrix.sum()\n", "print('The Sensitivity of Survival is {}%'.format(sensitivity*100))\n", "print('The Specificity of Survival is {}%'.format(specificity*100))\n", "print('The Accuracy is {}%'.format(acc*100))"]}, {"source": ["* **From this figure, we can know the model is good or not**\n", "* The Accuracy is higher than 85%"], "metadata": {"_cell_guid": "2343972e-586b-419d-9eff-2ec1c6b40022", "_uuid": "2904a444b8f45d1c40db6fe722ab50b97946ccf4"}, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "a57568e8-46a5-46e6-8956-213b4f39633b", "_uuid": "a262e748e8d41fb3708357016c9248441f3b6151", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["submissions = test_df['PassengerId'].reset_index()\n", "submissions = pd.merge(submissions, t_y, on='index', how='left')\n", "submissions = submissions.drop(['index'], axis = 1)\n", "submissions.columns = [\"PassengerId\", \"Survived\"]\n", "submissions.to_csv('my_submissions.csv', index=False)"]}, {"outputs": [], "metadata": {"_cell_guid": "223608dd-eddf-49e4-a039-1e7ebc423a74", "_uuid": "92dadf60b78fd9f4b7d66753ba5a287e51edb957", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": []}], "metadata": {"language_info": {"nbconvert_exporter": "python", "name": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "file_extension": ".py", "version": "3.6.1", "pygments_lexer": "ipython3"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat_minor": 1, "nbformat": 4}