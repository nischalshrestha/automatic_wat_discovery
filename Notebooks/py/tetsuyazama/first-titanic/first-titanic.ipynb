{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import re\n\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    \n    if title_search:\n        return title_search.group(1)\n    else:\n        return 'None'\n\ndef preprocess(df):\n    df['Title'] = df['Name'].apply(get_title)\n    df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    df['Title'] = df['Title'].replace('Mlle', 'Miss')\n    df['Title'] = df['Title'].replace('Ms', 'Miss')\n    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n    \n    df['Age'].fillna(-0.5, inplace = True)\n    # 年齢の階層化\n    df['Age_bin'] = pd.cut(df['Age'], bins=[-1,0,5,12,20,40,120], labels=['Unkown','Baby','Children','Teenage','Adult','Elder'])\n    df.drop(['Age'], axis=1, inplace=True)\n    \n    #df['Cabin'].fillna('N', inplace=True)\n    #df['Cabin'] = df['Cabin'].apply(lambda x: x[0])\n    \n    # Embarkedの欠損値補填\n    df['Embarked'].fillna('C', inplace = True)\n    # Fareの欠損値補填\n    #df['Fare'].fillna(-0.5, inplace = True)\n    # 料金の階層化\n    #df['Fare_bin'] = pd.cut(df['Fare'], bins=[-1,0,7.91,14.45,31,120], labels=['Unkown','Low_fare','median_fare','Average_fare','high_fare'])\n    df.drop(['Fare'], axis=1, inplace=True)\n    \n    # 家族サイズ\n    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n    df['FamilySize_bin'] = pd.cut(df['FamilySize'], bins=[0,1,2,4,20], labels=['Single','Small','Large','Fuge'])\n    df.drop(['FamilySize'], axis=1, inplace=True)\n    \n    df['SibSp_bin'] = pd.cut(df['SibSp'], bins=[0,1,5,20], labels=['None','Small','Large'], right=False)\n    df.drop(['SibSp'], axis=1, inplace=True)\n    df['Parch_bin'] = pd.cut(df['Parch'], bins=[0,1,4,20], labels=['None','Small','Large'], right=True)\n    df.drop(['Parch'], axis=1, inplace=True)\n    \n    # 分類(or階層)パラメータの数値化\n    df = pd.get_dummies(\n        df,\n        columns=['Pclass','Sex','Embarked','Age_bin','FamilySize_bin','SibSp_bin','Parch_bin','Title'],\n        prefix=['Pclass','Sex','Embarked','Age_bin','FamilySize_bin','SibSp_bin', 'Parch_bin','Title'],\n        drop_first=False)\n\n    #扱いにくいカラムの削除\n    df.drop(['Name','Ticket','Cabin'],axis=1,inplace=True)\n    \n    df.drop(['Pclass_2','Sex_male','Embarked_Q','Embarked_C','Age_bin_Children','Age_bin_Teenage','SibSp_bin_None','SibSp_bin_Small','SibSp_bin_Large','Parch_bin_Large','Title_Mr','Title_Rare','FamilySize_bin_Single'], axis=1,inplace=True)\n    \n    return df\ndef load_data():\n    train_df = pd.read_csv('../input/train.csv')\n    test_df = pd.read_csv('../input/test.csv')\n    \n    return preprocess(train_df), preprocess(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2dd90d2f3d939caf90d8803c0821b44af7040e5"},"cell_type":"code","source":"train_df, test_df = load_data()\ntrain_df.drop(['PassengerId'],axis=1).corr()\n#print(train_df.values.shape[1])\n#test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"107eb8b25b1cce24dedce24cd0203da0e1c29e54"},"cell_type":"code","source":"sns.heatmap(train_df.drop(['PassengerId'],axis=1).corr(),annot=True,cmap='RdYlGn',linewidths=0.2)\nfig=plt.gcf()\nfig.set_size_inches(20,12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b7acf50ae2f1c50df0c84cd0ce7c36de2126484"},"cell_type":"code","source":"def features_and_label(train_df):\n    label = train_df[\"Survived\"].values\n    features = train_df.drop(['PassengerId','Survived'],axis=1).values\n    \n    return features,label\n\nX_train, y_train = features_and_label(train_df)\n\nprint(X_train)\nprint(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca24ad17376cfe608de3eb3ddde0ced9f7748343"},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nfrom sklearn.svm import SVC\n\nparam_grid = {'kernel': ['rbf'], \n                  'gamma': [ 0.001, 0.01, 0.1, 1],\n                  'C': [1, 10, 50, 100,200,300, 1000]}\n\nmodelsvm = GridSearchCV(SVC(),param_grid = param_grid, cv=5, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\nmodelsvm.fit(X_train,y_train)\n\nprint(modelsvm.best_estimator_)\n\n# Best score\nprint(modelsvm.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5060780e1d24bcc060206963dc11fba3433e9901"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nn_estim=range(100,1000,100)\n\n## Search grid for optimal parameters\nparam_grid = {\"n_estimators\" :n_estim}\n\n\nmodel_rf = GridSearchCV(RandomForestClassifier(),param_grid = param_grid, cv=5, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\nmodel_rf.fit(X_train,y_train)\n\n\n\n# Best score\nprint(model_rf.best_score_)\n\n#best estimator\nmodel_rf.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5b7357d1fefbcb3f78703efe1c3675ce52f66b3"},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\n\nparam_grid = {\n    \"hidden_layer_sizes\":[(100,),(100, 10),(100, 100, 10),(100,100,50,10)],\n    \"max_iter\":[1000],\n    \"early_stopping\":[True],\n    \"batch_size\":[20,50,100,200],\n    \"alpha\":[0.0001,0.0005,0.001]\n}\n\nmodel_nn = GridSearchCV(MLPClassifier(),param_grid = param_grid, cv=5, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\nmodel_nn.fit(X_train,y_train)\n\n\n\n# Best score\nprint(model_nn.best_score_)\n\n#best estimator\nmodel_nn.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5519b4e896fa52d3ca35aae96800fe554601f39"},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import cross_validate\n\nX_test = test_df.drop(['PassengerId'],axis=1).values\nX_test = X_test\n\nestimators = list(zip(['svm','rf','nn'],[modelsvm.best_estimator_,model_rf.best_estimator_,model_nn.best_estimator_]))\nclf = VotingClassifier(estimators,voting='hard')\n\nclf.fit(X_train,y_train)\nprint(clf.score(X_train,y_train))\nprint(cross_validate(clf,X_train,y_train,cv=5))\n\ny_pred = clf.predict(X_test)\n\nsubmission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": y_pred})\n\nprint(submission)\n\nsubmission.to_csv(\"titanic_submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8ef60c3fd9d34c5b8d589aa2da7ed638ec8d42d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}