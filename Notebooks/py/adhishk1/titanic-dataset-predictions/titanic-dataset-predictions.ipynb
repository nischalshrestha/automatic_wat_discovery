{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**Introduction**\n\nThis is my first notebook of machine learning. This kernel is inspired from [Titanic Data Science Solutions](https://www.kaggle.com/startupsci/titanic-data-science-solutions)"},{"metadata":{"trusted":true,"_uuid":"3b1a475fc8ceb8b4400f9c6ec4d3f6a952da8175"},"cell_type":"code","source":"#Importing required Libraries\n#data analysis\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n#visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#machine learning models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"783a303aa99edd31307407bc603a4f7c3d0856cb"},"cell_type":"code","source":"#acquiring the training and testing datasets \ntrain_set = pd.read_csv('../input/train.csv')\ntest_set = pd.read_csv('../input/test.csv')\ncomplete_set = [train_set, test_set]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8ff0be36c4f4848081e8ad26508afc8e82a2c57"},"cell_type":"markdown","source":"**Analyzing the Data**"},{"metadata":{"_uuid":"7301f19132c8c1821e6a872fc4dc6ff47f21c874"},"cell_type":"markdown","source":"Analyzing the training set"},{"metadata":{"trusted":true,"_uuid":"e807374544928d83b2d80ae4b3523bcf4936c1cb"},"cell_type":"code","source":"#preview training data\ntrain_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6c3be7a587f083554a02fb5befab9fb6793b500"},"cell_type":"code","source":"train_set.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"489d1eb9d4fd8c4e448d6618d3870aa0acfa7cfc","scrolled":true},"cell_type":"code","source":"train_set.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"613fb4e7d59ce1f75b591205cc9c0085892d9b17"},"cell_type":"markdown","source":"Taining data has missing values in Age,Cabin and Embarked Columns"},{"metadata":{"trusted":true,"_uuid":"ff578d18bb7ef66d07e0a40f8b66f70dfb1f8a0e"},"cell_type":"code","source":"train_set.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4506d5cd7fdf66b5564abeb7ae0ed0398da1d24"},"cell_type":"markdown","source":"Analyzing Test Set"},{"metadata":{"trusted":true,"_uuid":"901ca6f2db0b01a5c2d5d0e8584e2a9d28bc120c"},"cell_type":"code","source":"#preveiw test data\ntest_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e55a9b97e1ad102eb98b6d278940a72a600a26c"},"cell_type":"code","source":"test_set.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a3ecfe1caea07b5a88d9b10ab21f1502253e88f"},"cell_type":"markdown","source":"Test set has missing values in Age and Cabin columns"},{"metadata":{"trusted":true,"_uuid":"d842e2072a952650c5a5268c7c4f5e2b94e9feac"},"cell_type":"code","source":"test_set.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d2b84de63c022358959c3eef08c7d2b55f5cdf9"},"cell_type":"code","source":"#Describing the correlation between the columns\n# Set figure size with matplotlib\nplt.figure(figsize=(10,6))\nsns.heatmap(train_set.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e52a80d4db3226879010d6152ad8e044d2641044"},"cell_type":"markdown","source":"From the heatmap we can conclude the correlation "},{"metadata":{"_uuid":"edc04ecfb94ec33cec5edd7dc2a6f5e1d56b14d5"},"cell_type":"markdown","source":"Analyzing the realtion between every column with \"Survived\" using plots"},{"metadata":{"trusted":true,"_uuid":"4d93b7ba3ff5d23969f030956b79946984f4c58e"},"cell_type":"code","source":"sns.countplot(x=\"Pclass\",hue=\"Sex\" ,data=train_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c71b3215b8c39f5d04d0f991f1389ac83f15f403"},"cell_type":"code","source":"#Analyzing for Pclass\nsns.barplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=train_set);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e135ed273b5280df68e49e0b13c2da6c89922f8f"},"cell_type":"markdown","source":"From this barplot we can see that survival rate is dependent on Classs (as most of the females survived from Class 1).\nTo confirm this relation we will analyze by pivoting the PClass column"},{"metadata":{"trusted":true,"_uuid":"de8ed4683e323fd4e6a6532f45a546c9efe51a50"},"cell_type":"code","source":"#Pivioting features\ntrain_set[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc2de072a33be74ea26409072dd3521a93070ceb"},"cell_type":"markdown","source":"Here we conclude that most number of people survived from classs 1 and least from class 3"},{"metadata":{"_uuid":"16f31cd87eedac93cbf890fed89ad3a65a6e7b02"},"cell_type":"markdown","source":"Analyzing the relation with Age column"},{"metadata":{"trusted":true,"_uuid":"1534a3dc0f6ba82552ad854ea406fc76e236c0ae"},"cell_type":"code","source":"sns.boxplot(x=\"Survived\", y=\"Age\", hue=\"Sex\", data=train_set);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a2cedddf0b823ecd5a60586b02a2a9b8de5aa9f"},"cell_type":"markdown","source":"We will divide age into bins for getting more valuable insights from the data"},{"metadata":{"trusted":true,"_uuid":"865ddf0b9e94bedee22ebccb52c0e62e06c22725"},"cell_type":"code","source":"X = sns.FacetGrid(train_set, col='Survived')\nX.map(plt.hist, 'Age', bins=20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5827f121b49c692d6669549d4812decfeb26d2e"},"cell_type":"markdown","source":"So we conclude from the above garph that we have to divide age into bins (chnage from continous to discreete type) "},{"metadata":{"_uuid":"dd89981d4fcfdaebdc84fd78afc4db7647d98316"},"cell_type":"markdown","source":"Analyzing the realtion of Sex column"},{"metadata":{"trusted":true,"_uuid":"e1bcc5438e63e1aa81d9b1bb3f077e12c0709114"},"cell_type":"code","source":"sns.countplot(x=\"Sex\" ,data=train_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5774abd2a6a34e37a41e79b1d7d9066d92bac7f0"},"cell_type":"code","source":"sns.barplot(x=\"Sex\", y=\"Survived\", data=train_set);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96cb1c536d97d8dd56dabe3cb17309b9488c459c"},"cell_type":"markdown","source":"As we can see from the above barplot female survival rate is much greater than male survival rate.\nWe will group Sex and Survived columns to get a general idea of survival for each gender."},{"metadata":{"trusted":true,"_uuid":"157ec24f7f65c2ba28ca2ec967f1ed42430ff9e2"},"cell_type":"code","source":"#Pivoting for Sex\ntrain_set[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"16d5a318c771f6abbf55ae58cf6c5653daac07ee"},"cell_type":"markdown","source":"Analyzing the realtion of SibSp and Parch column"},{"metadata":{"trusted":true,"_uuid":"e3b6b75dc81a733de4586b569083f8ba671553f3"},"cell_type":"code","source":"#Analyzing for SibSp\nsns.barplot(x=\"SibSp\", y=\"Survived\", hue=\"Sex\", data=train_set);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc2f0e5eb82b5c71f73e4b30d2cca9513cfb9c0f"},"cell_type":"code","source":"#Analyzing for SibSp\ntrain_set[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6801733fd547727a00e1aa96849f3fe515222314"},"cell_type":"markdown","source":"#Analyzing the realtion with Parch Column"},{"metadata":{"trusted":true,"_uuid":"70abce6d3a1cafe33ba0db21948ad6314eea7eee"},"cell_type":"code","source":"#Analyzing for SibSp\nsns.barplot(x=\"Parch\", y=\"Survived\", data=train_set);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b870d274479d5b8299d229ede43c9d709f99d80"},"cell_type":"code","source":"#Analyzing for Parch\ntrain_set[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1d9c3215d759367c6709a5005946992e09a8d43"},"cell_type":"markdown","source":"Analyzing the realtion with Embarked Column"},{"metadata":{"trusted":true,"_uuid":"af043ea90a82acf6090909807913031d93a4042c"},"cell_type":"code","source":"sns.countplot(x=\"Embarked\",data=train_set);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86f61bfc51d6b712bd591f569707537cba5b5f50"},"cell_type":"markdown","source":"Most passengers embarked from port 'S' i.e Southampton"},{"metadata":{"trusted":true,"_uuid":"ff170aee441d9e8eb5d3856ae99d427e1b95ec17"},"cell_type":"code","source":"sns.barplot(x=\"Embarked\", y=\"Survived\", data=train_set);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c5022e564bb46c97003b0fac9cd47f003012109"},"cell_type":"code","source":"sns.barplot(x=\"Embarked\", y=\"Survived\",hue=\"Sex\", data=train_set);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c555f0866189f40bd73ee5361f1eaa0f8f137a5f"},"cell_type":"code","source":"#Analyzing the realtion between every column with \"Survived\"\n#Analyzing for Embarked\ntrain_set[[\"Embarked\", \"Survived\"]].groupby(['Embarked'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"380c4fcc02134d365671751f7a0f821067e4aecd"},"cell_type":"markdown","source":"Analyzing the realtion with Embarked Column"},{"metadata":{"trusted":true,"_uuid":"a037ec84e03e60771c381c297d4f778d02207ca9"},"cell_type":"code","source":"#Analyzing the realtion between every column with \"Survived\"\n#Analyzing for Fare\nsns.swarmplot(x=\"Survived\", y=\"Fare\",hue='Pclass', data=train_set);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"65bf90038bcc048a7c936a5d061832efd072d191"},"cell_type":"markdown","source":"Here we can see the fare differece of each class "},{"metadata":{"trusted":true,"_uuid":"30ed539f662e6642b90ed51900ad9c0fe9fca10d"},"cell_type":"code","source":"y = sns.FacetGrid(train_set, col='Survived')\ny.map(plt.hist, 'Fare', bins=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5564b593a264cd66e285facb7b149f8ba78168e"},"cell_type":"markdown","source":"We ignore Name, Ticket and Cabin Columns for now, we will deal with them later"},{"metadata":{"_uuid":"45dd7a36bcad5c65b8109986b872fc14009cefea"},"cell_type":"markdown","source":"**Cleaning the Data**"},{"metadata":{"_uuid":"c2f6218514e00fc004d727487308cf35db833c21"},"cell_type":"markdown","source":"First we identify the columns which contains the missing values"},{"metadata":{"trusted":true,"_uuid":"bed642e28247b1825e58edf1d277334646dbef48"},"cell_type":"code","source":"#Total Nuber of missing Values in train _set\ntrain_set.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a2559da7cc651ed3e0e78f3528259373988a4ee5"},"cell_type":"markdown","source":"Dealing with missing values in Age"},{"metadata":{"trusted":true,"_uuid":"d48458d439bccf7b717432dbb888322e34d1297a"},"cell_type":"code","source":"    #complete missing age with median\n    train_set['Age'].fillna(train_set['Age'].median(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddfe79f3069f807f7a30c9844efaa4e6b1ecbbfc"},"cell_type":"code","source":"train_set.Age.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc0ee951bef48258382373af5f75a8829f9e014b"},"cell_type":"markdown","source":"All missing values replaced with median in  Age column of the train_set DataFrame"},{"metadata":{"trusted":true,"_uuid":"350ba380de96f571aee2b858e9688922a640190e"},"cell_type":"code","source":"#complete embarked with mode\ntrain_set['Embarked'].fillna(train_set['Embarked'].mode()[0], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c73aba87188a90989d8fdf3f123152a545a5a61d"},"cell_type":"code","source":"train_set.Embarked.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f71db51c68393a8d8ff8a19e7e3040feae0f3f03"},"cell_type":"markdown","source":"Dealing with missing values in Test Set"},{"metadata":{"trusted":true,"_uuid":"cbe316197343d5d565c617e8b9d3ea66675ccb0f"},"cell_type":"code","source":"test_set.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6491547f214d7ca9cbae22c94566ff4a4fc8681a"},"cell_type":"code","source":"#complete missing age with median\ntest_set['Age'].fillna(test_set['Age'].median(), inplace = True)\n#complete embarked with mode\ntest_set['Embarked'].fillna(test_set['Embarked'].mode()[0], inplace = True)\n#complete missing fare with median\ntest_set['Fare'].fillna(test_set['Fare'].median(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bdec65364e8be75797e4239697dfc7b695f1cba9"},"cell_type":"code","source":"#Total Nuber of missing Values in test_set\ntest_set.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98b484b3acf7bb99c79883ddbd479b4fb3fa7226"},"cell_type":"markdown","source":"**Creating New Features **\n\nWe will create some new features from the exisiting ones in order to represent our data well, and provide a relevant data to our models.\n1. Create FamilySize feature by adding SibSp and Parch\n2. Create IsAlone Feature from FamilySize, i.e if FamilySize is 1 then the person is traveling alone\n3. Create bins for Age and Fare Columns\n4. Create Title feature by extracting title from Name column"},{"metadata":{"trusted":true,"_uuid":"9d1c08a759d8e5b646b253db669e39fc4728b3f5"},"cell_type":"code","source":"#Creating new features in both train_set and test_set\nfor dataset in complete_set:    \n    #Two features combined in one\n    dataset['FamilySize'] = dataset ['SibSp'] + dataset['Parch'] + 1\n\n    dataset['IsAlone'] = 1 #1 means passanger is travelling Alone\n     # now update value of IsAlone wherever FamilySize is greater than 1\n    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0 \n   \n\n    #Regular Expression to split title from name\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n\n    #Continuous variable bins; qcut vs cut: https://stackoverflow.com/questions/30211923/what-is-the-difference-between-pandas-qcut-and-pandas-cut\n    #Fare Bins/Buckets using qcut or frequency bins: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html\n    #Age Bins/Buckets using cut or value bins: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.cut.html\n    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)\n    dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int), 5)\n\n\n    \n#Cleanup Title Column from less frequent Titles\nfor dataset in complete_set:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\n#preview data again\ntrain_set.info()\ntest_set.info()\n\n#for the warning below\n#https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff2540cf815e809bebad29ff53af886881b8a308"},"cell_type":"markdown","source":"**Convert Formats**\nWe will convert categorical data to dummy variables for mathematical analysis. There are multiple ways to encode categorical variables; we will use the sklearn and pandas functions."},{"metadata":{"trusted":true,"_uuid":"2ff1adec593f23ef075a39516901a3d4f1b360da"},"cell_type":"code","source":"#Backup data before converting it to numerical value\ntrain_backup=train_set\ntest_backup=test_set\ncomplete_set_backup=complete_set\n#Convert objects to category using Label Encoder for train_set and test_set\nfrom sklearn.preprocessing import LabelEncoder\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in complete_set:    \n    dataset['Sex'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked'] = label.fit_transform(dataset['Embarked'])\n    dataset['Title'] = label.fit_transform(dataset['Title'])\n    dataset['AgeBin'] = label.fit_transform(dataset['AgeBin'])\n    dataset['FareBin'] = label.fit_transform(dataset['FareBin'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e19e097bfa10c802d4133b8c6b942e39e84c4b7"},"cell_type":"code","source":"train_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30fd53d2a02c289b4460894aa25541f133d3eb8b"},"cell_type":"code","source":"test_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0bf1e5788229a66cd1204aff294d54169cebbc8"},"cell_type":"code","source":"print(train_set.shape)\nprint(test_set.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f8bde70cc767a8fa94495ef44ab9b922971ca468"},"cell_type":"markdown","source":"Input train_set for a model"},{"metadata":{"trusted":true,"_uuid":"f55396bed36f4c08a0f7f775e5c211d1ef7cf907"},"cell_type":"code","source":"train_model=train_set[['Survived','Pclass','Sex','Embarked','IsAlone','Title','FareBin','AgeBin']]\ntrain_model.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d4ee44298c2ee2ce84af813986964f4c0ad8cf9"},"cell_type":"markdown","source":"Input test_set for a model "},{"metadata":{"trusted":true,"_uuid":"b85c9b301598da42706ea6ffc29be6ccf5c87391"},"cell_type":"code","source":"test_model=test_set[['Pclass','Sex','Embarked','IsAlone','Title','FareBin','AgeBin']]\ntest_model.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"402aa4df11e974dc2716bdcb137a76134fe3b389"},"cell_type":"markdown","source":"**Model and Prediction**\nNow we are ready to train a model and predict the required solution. We will use the following regression algorithms:\n\n* Logistic Regression\n* KNN or k-Nearest Neighbors\n* Support Vector Machines\n* Naive Bayes classifier\n* Decision Tree\n* Random Forrest\n* Perceptron \n*  Linear SVC\n* Stochastic Gradient Descent\n* Decision Tree\n* Random Forest"},{"metadata":{"trusted":true,"_uuid":"a7403b9296c465119d899b13d3e7020929059532"},"cell_type":"code","source":"X_train = train_model[['Pclass','Sex','Embarked','IsAlone','Title','FareBin','AgeBin']]\nY_train = train_model[\"Survived\"]\nX_test  = test_model\nX_train.shape, Y_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55d8d4b1a9d581e0b9c05fce0c4dea62839cbc86"},"cell_type":"code","source":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88233c524950ce6af917b7813b0c42d536c2b0b2"},"cell_type":"code","source":"# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a05c5fad28fb72d2fc5f5ee69de57018dd2a2077"},"cell_type":"code","source":"#K nearest neighbours\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c30abb10ee75ebb61f1fbe6d8f1919103d97463b"},"cell_type":"code","source":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70d41a982b3c605ddbc3b440db1bf3f13799b83a"},"cell_type":"code","source":"# Perceptron\nfrom sklearn.linear_model import Perceptron\nperceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\nacc_perceptron","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a472bde9d2db5464e852f79b865eb3c8c640184a"},"cell_type":"code","source":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c4811172eefdc73aba9cd7caefc1701f8235cf3"},"cell_type":"code","source":"# Stochastic Gradient Descent\nfrom sklearn import linear_model\nsgd = linear_model.SGDClassifier(max_iter=1000)\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b0a6e68a2c0dc0eed630f8d106e6981215cd34f"},"cell_type":"code","source":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e25af03c68789f7e1d9f47530553dd4f2ca16ad1"},"cell_type":"code","source":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a43b34c02323af9c277298a9b689a593704e82d5"},"cell_type":"code","source":"#Comparing the scores\nmodels = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43d21f4449bd3ac78be739a0343835e8243d0e38"},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": test_set[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3419537321aa5a5ae4421bed6bfbe41af50d744f"},"cell_type":"code","source":"#Submit output as CSV File\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}