{"cells":[{"metadata":{"_uuid":"3cedf8af3084a13cff571058ec93049a96fd54bf","_cell_guid":"67d70bc4-d4d8-4001-a6b9-ebc492d2af03"},"cell_type":"markdown","source":"# Changes/Improvs to be done:\n- Proper Formatting\n- Adding Title as a Feature\n- HyperParameter tuning"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":false,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sys\nimport sklearn\nimport re\n\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\n\n\n\n\nimport os\nprint(os.listdir(\"../input\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"02bd15d2f9356e792010858c062fc4773ca8dec4","_cell_guid":"95c2042d-64d0-4236-addf-599b7e66935e","trusted":false},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\n\ntoy = train.copy(deep=True)\n\ndata_cleaner = [train,test]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a19c6efa5f7412941816c9665ada6152c7955c1","_cell_guid":"f4fd75e4-eb11-4e94-893c-179ae722df07","trusted":false,"collapsed":true},"cell_type":"code","source":"# print(train.info())\n# print(toy.info())\n\nprint(train.describe())\n\nprint(toy.sample(10))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_uuid":"04330cb7ea009dac9d7cae92262b32a52775245c","_cell_guid":"5d29c586-a52d-4e3d-b7ab-9374013b3a1b","trusted":false,"collapsed":true},"cell_type":"code","source":"print(\"missing values:\")\n\n\nprint(train.isnull().sum())\nprint(test.isnull().sum())\n\nprint(\"cleaning..\")\n\n\nfor dataset in data_cleaner:\n    dataset['Age'].fillna(dataset['Age'].median(), inplace = True)\n    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace = True)\n    dataset['Fare'].fillna(dataset['Fare'].median(),inplace=True)\n    \n    \nprint(train.isnull().sum())\nprint(test.isnull().sum())\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a25b39bc4dbde46d748c4f267290687dc166b3ad","_cell_guid":"7a6b81f8-74f4-4257-b80d-3808c980634c","trusted":false,"collapsed":true},"cell_type":"code","source":"train['has_cabin'] = train['Cabin'].apply(lambda x:0 if type(x) == float else 1)\ntest['has_cabin'] = test['Cabin'].apply(lambda x:0 if type(x) == float else 1)\nprint(train.sample(10))\nprint(test.sample(10))\nprint(data_cleaner)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_uuid":"b9bf274908feb38f8d40d044408f2ac4e6dee45b","_cell_guid":"20ade049-ba93-40ae-8228-e6ca887af01d","trusted":false,"collapsed":true},"cell_type":"code","source":"for dataset in data_cleaner:\n    dataset['FamilySize']  = dataset['SibSp'] + dataset['Parch'] + 1\n    dataset['isAlone'] = 1 \n    dataset['isAlone'].loc[dataset['FamilySize'] > 1] = 0\n    dataset['AgeBin'] = pd.cut(dataset['Age'], 5)\n    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"a6da93f667341974b9a91688f9c9bf7693d479da","_cell_guid":"9dc73dbb-86dd-401a-9db8-4750a7c22677","trusted":false},"cell_type":"code","source":"label = LabelEncoder()\n\nfor dataset in data_cleaner:\n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])\n    dataset['AgeBin_Code'] = label.fit_transform(dataset['AgeBin'])\n    dataset['FareBin_Code'] = label.fit_transform(dataset['FareBin'])","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"0ddd36e486d06dc3d22f5dbbef369c7ca7cc1520","_cell_guid":"32e65db9-3008-498e-a2f2-7243b79302df","trusted":false},"cell_type":"code","source":"for dataset in data_cleaner:\n    dataset['Title'] = dataset['Name'].str.extract('([A-Za-z]+)\\.', expand=False)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"760ecd4e2240c1d4c9d5128ab1dcc644ef47560d","_cell_guid":"298eb49d-323a-4a84-9f19-d8fa82dcfe59","trusted":false},"cell_type":"code","source":"for dataset in data_cleaner:\n    dataset['Title'] = dataset['Title'].replace(['Don', 'Capt', 'Col', 'Major', 'Sir', 'Jonkheer', 'Rev', 'Dr'], 'Honored')\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Dona', 'Mme', 'Countess'], 'Mrs')\n    dataset['Title'] = dataset['Title'].replace(['Mlle', 'Ms'], 'Miss')\n    dataset['Title_Code'] = label.fit_transform(dataset['Title'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"103c85ec0add8b0765f36ce112d6ac12fb6d0b2e","_cell_guid":"062060a5-cc58-49fe-8757-83280803ff96","trusted":false,"collapsed":true},"cell_type":"code","source":"train.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"ed95bcc0ba79664acabb968569becbc779868570","_cell_guid":"92963927-f7aa-4e6e-82f2-8615ad9d8e23","trusted":false},"cell_type":"code","source":"drop_list = ['Cabin','Name','PassengerId', 'Sex', 'Age', 'Fare', 'Ticket', 'Embarked','Title']\ntrain = train.drop(drop_list, axis=1)\n# test = test.drop(drop_list,axis=1)\n\ntrain = train.drop(['AgeBin', 'FareBin'], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8eb0e1dd8aee3a5da2f1959ed6761197ff6e0993","_cell_guid":"267cb32f-89da-425f-a408-0987df849742","trusted":false,"collapsed":true},"cell_type":"code","source":"\ntrain.sample(15)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36dd71e52e5fb00adafed6524cbf7275742b8e97","_cell_guid":"03abd9ab-8ea3-41bb-8cc6-d85a416909cf","trusted":false,"collapsed":true},"cell_type":"code","source":"colormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31d622e8df1d94ccce311759144870a866424bf7","_cell_guid":"6c067e45-ebc7-4de0-961c-b6b94e332818","trusted":false,"collapsed":true},"cell_type":"code","source":"Target = ['Survived']\ntrain_features = ['Pclass', 'SibSp', 'Parch', 'has_cabin', 'FamilySize', 'isAlone', 'Sex_Code', 'Embarked_Code', 'AgeBin_Code', 'FareBin_Code', 'Title_Code']\ndata_train = train[train_features]\ndata_train.head(10)\n\nMLA_predict = train[Target]\nMLA_predict.head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01c8fdc48aaaf71565947aa933a470bf66c2953d","_cell_guid":"6cb99ff9-cd52-4013-a106-2ceb914710c5","trusted":false,"collapsed":true},"cell_type":"code","source":"MLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(),\n    linear_model.Perceptron(),\n    \n    #Navies Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    \n    #Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n    \n    #SVM\n    svm.SVC(probability=True),\n    svm.NuSVC(probability=True),\n    svm.LinearSVC(),\n    \n    #Trees    \n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n    \n    #Discriminant Analysis\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n\n    \n\n    XGBClassifier()    \n    ]\n\n\n\n\ncv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) \n\n\nMLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\nMLA_compare = pd.DataFrame(columns = MLA_columns)\n\nrow_index = 0\nfor alg in MLA:\n\n    \n    MLA_name = alg.__class__.__name__\n    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n    \n    \n    cv_results = model_selection.cross_validate(alg, train[train_features], train[Target], cv  = cv_split)\n\n    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   \n    \n\n    \n    alg.fit(train[train_features], train[Target])\n    MLA_predict[MLA_name] = alg.predict(train[train_features])\n    \n    row_index+=1\n\n    \n\nMLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\nMLA_compare\n#MLA_predict","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df8f42f51ee141b74da54d244c10aaefde467881","_cell_guid":"c0881272-ea5e-4a3e-96d3-88d08c4035df","trusted":false,"collapsed":true},"cell_type":"code","source":"MLA_predict","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73f9d3254d01ad94732c66fcb14c5b13e3e91d9e","_cell_guid":"bdb97c4b-04f5-4066-989f-6657e1982ee4","trusted":false,"collapsed":true},"cell_type":"code","source":"colormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(MLA_predict.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c7882e4b93afd0739c75c2087f91ae393c9c51c","_cell_guid":"43e96ab8-c116-4052-aa52-1faa9e85ed20","trusted":false,"collapsed":true},"cell_type":"code","source":"vote_est = [\n    \n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassifier()),\n    ('gbc', ensemble.GradientBoostingClassifier()),\n    ('rfc', ensemble.RandomForestClassifier()),\n\n    \n    ('gpc', gaussian_process.GaussianProcessClassifier()),\n    \n    \n    ('lr', linear_model.LogisticRegressionCV()),\n    \n    \n    ('bnb', naive_bayes.BernoulliNB()),\n    ('gnb', naive_bayes.GaussianNB()),\n    \n    \n    ('knn', neighbors.KNeighborsClassifier()),\n    \n    \n    ('svc', svm.SVC(probability=True)),\n    \n\n   ('xgb', XGBClassifier())\n\n]\n\n\n\nvote_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')\nvote_hard_cv = model_selection.cross_validate(vote_hard, train[train_features], train[Target], cv  = cv_split)\nvote_hard.fit(train[train_features], train[Target])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e0f9052199f6c37306ebb30cf1e76056660746c","_cell_guid":"7644f2e8-98d5-4f14-a277-f0c8866ff7f8","trusted":false,"collapsed":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"fcf6b624ee96bb6dc8c1ee2f2cc39001a5cb5bb8","_cell_guid":"ab58abe5-87a1-4dc0-a636-2186de9d41c8","trusted":false},"cell_type":"code","source":"df = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df7abeac3bc5dc0040446fe4f73d6523cac3e845","_cell_guid":"a3b6cf48-b27b-4b46-9fc9-9e6f81fb644d","trusted":false,"collapsed":true},"cell_type":"code","source":"test['Survived'] = vote_hard.predict(test[train_features])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15d16682e57c6475d880026c1369c973f844126e","_cell_guid":"2eba7933-7e0e-45a1-98eb-b83ac62d87d6","trusted":false,"collapsed":true},"cell_type":"code","source":"test.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2689c84da944f0c216db2d55bf6a0555c2d376e","_cell_guid":"5e4adf2d-47d2-41d7-bfa4-41705f7e0599","trusted":false,"collapsed":true},"cell_type":"code","source":"submit = test[['PassengerId', 'Survived']]\nsubmit.head(10)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"ec04f65670a876300da8acbd173b68a02d13c2e7","_cell_guid":"8d24c8da-fae7-491c-b954-6510beb973ea","trusted":false},"cell_type":"code","source":"submit.to_csv(\"../working/submit.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}