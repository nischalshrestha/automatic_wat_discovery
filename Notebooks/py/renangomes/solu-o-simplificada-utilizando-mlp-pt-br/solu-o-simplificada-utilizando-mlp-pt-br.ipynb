{"cells":[{"metadata":{"_cell_guid":"ab88d904-9700-4689-9460-c3f40eb83bb4","_uuid":"cd578834ffbe195a6376732c736a535de96420a8"},"cell_type":"markdown","source":"# Titanic: Solução simplificada para Iniciantes utilizando Redes Neurais Densas\n **[Renan Gomes Barreto](https://www.kaggle.com/renangomes)**  -  *Maio, 2018*\n\n![Titanic](https://media.giphy.com/media/Uj3SeuVfg2oCs/giphy.gif)\n\n## Introdução\n\nEste notebook contém uma introdução breve sobre como criar uma rede neural de múltiplas camadas e resolver o problema do Titanic usando um modelo simples no Keras. Modelos Densos, também chamados de Multi-layer perceptrons (MLP), podem ser usados como base e, a partir deles, serem construídos modelos mais complexos.\n\nNeste notebook criaremos um classificador binário utilizando os dados de passageiros do Titanic. Com esses dados, desejamos predizer se o passageiro irá sobreviver ou não ao naufrágio.\n****\nPara resolver problemas com Redes Neurais, assim como qualquer problema de aprendizado de máquina, antes de elaborar uma arquitetura é necessário primeiramente entender o problema e, principalmente, compreender os dados. Esse processo é extenso e compreende muitas vezes a maior parte do trabalho. Dessa forma, esse notebook tem como objetivo introduzir alguns pontos importantes da pirâmide para obtenção de melhores resultados de uma rede neural. O notebook é organizado da seguinte forma:\n\n* [Introdução](#Introdução)\n* [Definição do problema](#Definição-do-problema)\n* [Carregando o dataset](#Carregando-o-dataset)\n* [Pré-processamento](#Pré-processamento)\n* [Implementando a Rede Neural](#Implementando-a-Rede-Neural)\n* [Resultados](#Resultados)\n* [Conclusão](#Conclusão)"},{"metadata":{"_cell_guid":"d96c38b4-dcb0-4b5d-afec-da78f793edea","_uuid":"c70d422ef47ea53cd8ee3c92f8fe465b9b15f42e"},"cell_type":"markdown","source":"## Definição do problema\n\nNesse problema, será utilizado como base de dados informações dos passageiros do Titanic para identificar quais passageiros sobreviveram. No Titanic, uma das razões que causou o naufrágio  foi que não havia botes salva-vidas suficientes para os passageiros e a tripulação. Dentre os passageiros, alguns grupos de pessoas tinham maior probabilidade de sobreviver do que outros, como mulheres, crianças e a classe alta. Dessa forma, o problema consiste em utilizar rede neural para identificar quais pessoas poderiam sobreviver."},{"metadata":{"_cell_guid":"a40e23de-99f3-489a-9e99-4dc27e7aea3b","_uuid":"17b7983dc7f2f77bf76e4d663f590e7da00d2ab2"},"cell_type":"markdown","source":"## Carregando o Dataset"},{"metadata":{"_cell_guid":"b72720f9-ac83-46c8-8204-f88eab2ccd80","_uuid":"dc0311226b830b7482fe58c4b2c105a7dfccb6c7"},"cell_type":"markdown","source":"### Lendo os arquivos do Dataset\n\nPara iniciar, deve-se analisar os atributos de entrada do dataset, seus tipos e o atributo alvo (label/rótulo). Isso pode ser feito através do Pandas, biblioteca de Python específica para análise e pré-processamento de dados."},{"metadata":{"_cell_guid":"4299bf6e-fb96-4ee4-a1a0-4922030a4438","_uuid":"886470fab8c75de23da7c3f722330e2a3b4671d6","trusted":true},"cell_type":"code","source":"import numpy as np\nnp.random.seed(10)\n\nimport pandas as pd \n\ntrain = pd.DataFrame(pd.read_csv(\"../input/train.csv\", index_col=[0], header=0))\ntest  = pd.DataFrame(pd.read_csv(\"../input/test.csv\", index_col=[0], header=0))\ndisplay(train.head())","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"abecdda5-27f3-409b-adf9-106dc6890cb8","_uuid":"94cbf76367bbc96c683c44c13024d1a78c48b981"},"cell_type":"markdown","source":"## Pré-processamento\n\nAs colunas Name, Ticket e Cabin parecem ser características exclusivas do passageiro e por isso iremos descarta-las. Em uma análise mais profunda, certamente utilizaríamos essas colunas para melhorar os dados ou até deduzir dados faltantes."},{"metadata":{"_cell_guid":"c476386f-4c28-4f27-af74-9333dc6a41f0","_uuid":"b39e8f9e76e3ab247430ecd94bc031408757e33d","trusted":true},"cell_type":"code","source":"train.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)\ntest.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)\ndisplay(train.head())","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"1adabffb-f879-4359-bbae-f8ea4ece308c","_uuid":"7832f7a70e2df765a1770f88c4b0877419ba0126"},"cell_type":"markdown","source":"### Tratando os dados faltantes\n\nDados faltantes são um problema grave em aprendizagem de máquina. De alguma forma deveremos trata-los. A forma mais fácil de trata-los é simplesmente excluindo todas as linhas do dataset que possuem esses dados ou substituindo-os por um valor fixo. No nosso caso, para as colunas numéricas Age e Fare, substituímos os dados faltantes pela média. Já as colunas SibSp e Parch tiveram seus dados substituídos por -1."},{"metadata":{"_cell_guid":"a312382d-f2ee-41f9-960f-f18aa3d55b93","_uuid":"b38dc26cf1f5f67e0f3e3f2197d3e4f331bb0701","collapsed":true,"trusted":true},"cell_type":"code","source":"train['Age'].fillna(train['Age'].mean(), inplace=True)\ntrain['Fare'].fillna(train['Fare'].mean(), inplace=True)\ntrain['SibSp'].fillna(-1, inplace=True)\ntrain['Parch'].fillna(-1, inplace=True)\n\ntest['Age'].fillna(train['Age'].mean(), inplace=True)\ntest['Fare'].fillna(train['Fare'].mean(), inplace=True)\ntest['SibSp'].fillna(-1, inplace=True)\ntest['Parch'].fillna(-1, inplace=True)","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"d0b6b66d-a0d9-4560-8813-38e84a9bb185","_uuid":"9d74497d8455d3fbd2eba39c7cc4696da2a0190d"},"cell_type":"markdown","source":"### Codificando as colunas categóricas\n\nAs colunas Pclass, Sex e Embarked parecem ser categóricas. Essas colunas devem ser mapeadas para números e, de preferência, cada possível valor deve se tornar uma nova coluna binária. Isso pode ser feito facilmente utilizando a função get_dummies do pandas."},{"metadata":{"_cell_guid":"682deee3-9270-47b2-aa44-7208f1c33c39","_uuid":"adef72feeefeeb7cb0714718b21430237a3d9059","trusted":true},"cell_type":"code","source":"train = pd.get_dummies(train, dummy_na=True, columns=['Pclass', 'Sex', 'Embarked']).astype(float)\ntest = pd.get_dummies(test, dummy_na=True, columns=['Pclass', 'Sex', 'Embarked']).astype(float)\n\ndisplay(train.head())\ndisplay(test.head())","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"1a2cc0d9-4a85-4f8f-9b92-7f82b7e364cf","_uuid":"55070c4c73c431cf562625225fad847afc16920b"},"cell_type":"markdown","source":"## Implementando a Rede Neural"},{"metadata":{"_cell_guid":"441473cf-3bf2-4c14-81fb-440f54908b9b","_uuid":"53aef0dd7fe5a773f008a671adbf48291098ea21"},"cell_type":"markdown","source":"### Separando os atributos da saída\nOs atributos de saída serão separados. Além disso, separamos o dataset de treinamento original em dois."},{"metadata":{"_cell_guid":"578c8c14-815e-4e6b-8b47-66f2e3925f5e","_uuid":"51a5f4011bc1cba826bf18ae9f4234bd6e74b852","trusted":true},"cell_type":"code","source":"X_train = train.drop(columns=[\"Survived\"])[:-120]\ny_train = train[\"Survived\"][:-120]\n\nX_val = train.drop(columns=[\"Survived\"])[-120:]\ny_val = train[\"Survived\"][-120:]\n\nX_test = test\n\nprint(\"X_train: \", X_train.shape)\nprint(\"y_train: \", y_train.shape)\nprint(\"X_val: \",   X_val.shape)\nprint(\"y_val: \",   y_val.shape)\nprint(\"X_test: \",   X_test.shape)","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"aa77dac8-fd2c-44bb-b680-558163e7170f","_uuid":"3edcb0e351c985bb2f028324322f9f1c475aa370"},"cell_type":"markdown","source":"### Definição do Modelo\n\nCriaremos um modelo simples usando Keras. Sinta-se livre para alterar a quantidade de neurônios, camadas, funções de ativação, etc."},{"metadata":{"_cell_guid":"21babc43-f5dc-461d-aafa-149716dbed01","_uuid":"dc4ec50fc89fe9e6b647ba9779c289cf2ad27466","trusted":true},"cell_type":"code","source":"from keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\n\nmodel = Sequential()\nmodel.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\nmodel.summary()","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"8fdb28a7-b64d-4378-b8d4-0fe16029ffe5","_uuid":"a9b4441e65518f207e9d41f77e9d6cc997543d6b"},"cell_type":"markdown","source":"### Treinamento\n\nTreinaremos a rede por 1750 épocas com batch size de 32. Caso você queira ver estatísticas durante o treinamento, ative o parâmetro verbose."},{"metadata":{"_cell_guid":"965d01c0-30b4-4a60-a572-44d3d63c54b3","_uuid":"c84d109436be19a78f1ca4d416e3b8a97879f76b","trusted":true},"cell_type":"code","source":"import time\n\nepochs = 1750\nstart_time = time.time()\n\nhistory = model.fit(X_train.as_matrix(), y_train.as_matrix(), epochs=epochs, batch_size=32, \n                    validation_data=(X_val.as_matrix(), y_val.as_matrix()), verbose=0, shuffle=True)\n\nprint(\"Tempo gasto: %d segundos\" % (time.time() - start_time), \"\\r\\nÉpocas: %d\" % (epochs))","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"5567f322-ce19-4f94-8773-9af3dd37f5b4","_uuid":"b6403b8e3694f55528f34668fdb0cb5b84246579"},"cell_type":"markdown","source":"### Gráficos da etapa de treinamento"},{"metadata":{"_cell_guid":"253de9cf-fe44-4143-8a68-f958dfc6c3dc","_uuid":"b3b8d3c5d3aa220177d02ce1408d1494240966e7","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(history.history['acc'], color=\"r\")\nplt.plot(history.history['val_acc'], color=\"g\")\nplt.title('Curva de Treinamento')\nplt.ylabel('Acurácia')\nplt.xlabel('Época')\nplt.legend(['Treinamento', 'Validação'], loc='lower right')\nplt.show()\n\nplt.plot(history.history['loss'], color=\"r\")\nplt.plot(history.history['val_loss'], color=\"g\")\nplt.title('Curva de Treinamento')\nplt.ylabel('Erro')\nplt.xlabel('Época')\nplt.legend(['Treinamento', 'Validação'], loc='upper left')\nplt.show()","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"03f47d50-72a9-4526-9fc0-f70ca1660b75","_uuid":"9071b538f6eb645d11f0fd6ed1891333f615c516"},"cell_type":"markdown","source":"## Resultados"},{"metadata":{"_cell_guid":"e1786bed-1a66-494f-8983-79f56fb2d70a","_uuid":"ac427ab8cf5a406c2da7bdc622f2a66996866a41"},"cell_type":"markdown","source":"### Matriz de Confusão - Treinamento e Validação\n\nA fim de entendermos a o resultado do treinamento, utilizaremos as funções accuracy_score e confusion_matrix da biblioteca sklearn.\nLembre-se que as variáveis y_train e X_train são dataframe do Pandas, então, geralmente, vamos ter que utilizar a função as_matrix antes de usa-las."},{"metadata":{"_cell_guid":"afae4d90-d754-40c8-ae3f-66f5368e94ac","_uuid":"db85f0b08e13325e832b4a64842a3329fd9a3655","scrolled":true,"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\nimport numpy as np\n\nprint(\"Acurácia no Dataset de Treinamento:\", accuracy_score(y_train.as_matrix(), np.round(model.predict(X_train.as_matrix()))), \"\\r\\n\")\n\nconfusionMatrixDF = pd.DataFrame( confusion_matrix(y_train.as_matrix(), np.round(model.predict(X_train.as_matrix()))),\n                                 index=('Sobrevivente', 'Vítima'), columns=('Sobrevivente', 'Vítima'))\n\nheatmap = sns.heatmap(confusionMatrixDF, annot=True, fmt=\"d\", cmap=\"Blues\",  vmin=0)\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\nheatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=14)\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()\n\nprint(\"Acurácia no Dataset de Validação:\", accuracy_score(y_val.as_matrix(), np.round(model.predict(X_val.as_matrix()))), \"\\r\\n\")\n\nconfusionMatrixDF = pd.DataFrame( confusion_matrix(y_val.as_matrix(), np.round(model.predict(X_val.as_matrix()))),\n                                 index=('Sobrevivente', 'Vítima'), columns=('Sobrevivente', 'Vítima'))\n\nheatmap = sns.heatmap(confusionMatrixDF, annot=True, fmt=\"d\", cmap=\"Blues\",  vmin=0)\nheatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\nheatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=14)\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","execution_count":19,"outputs":[]},{"metadata":{"_cell_guid":"9813c467-d896-4b21-b2bd-e8daaac73b02","_uuid":"85a133ed39c6f79e5f8da292e324d23c49a60ef7"},"cell_type":"markdown","source":"### Enviando os Resultados para o Kaggle"},{"metadata":{"_cell_guid":"98809b2e-3f9f-4a88-a55e-4a83edf5922e","_uuid":"95f3d9450da03a0d10ed71d762512759c9a4880b","collapsed":true,"trusted":true},"cell_type":"code","source":"y_test_pred = model.predict(X_test.as_matrix())\n\nX_test_submission = X_test.copy()\nX_test_submission['Survived'] = np.round(y_test_pred).astype(int)\nX_test_submission['Survived'].to_csv('submission.csv', header=True)","execution_count":23,"outputs":[]},{"metadata":{"_cell_guid":"d6ce80dc-b39d-4b4f-b96a-87dab4bd7b7e","_uuid":"4c600e3d4b3171267b5205dc53248e94babc794a"},"cell_type":"markdown","source":"## Conclusão\n\nNeste notebook mostramos uma solução simples para o problema do Titanic.\nFoi implementado uma rede neural com duas camadas que obteve uma acurácia satisfatória no dataset de validação."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}