{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a8449b7a-ccb6-740f-4d5d-15e096da8b4e"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "# pandas\n",
        "import pandas as pd\n",
        "from pandas import Series,DataFrame\n",
        "\n",
        "# numpy, matplotlib, seaborn, sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "##from subprocess import check_output\n",
        "##print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "#### import the data\n",
        "test   = pd.read_csv('../input/test.csv')\n",
        "train    = pd.read_csv('../input/train.csv')\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8e708861-7007-5ba4-d0f6-f6f8107bb0e4"
      },
      "outputs": [],
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "75e47d6b-456e-fe42-0822-2fc1217d3cc2"
      },
      "outputs": [],
      "source": [
        "#train.head()\n",
        "#train[train['Survived'] == 1]['Name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d4641363-e52b-5f98-78d9-4203d408e6cf"
      },
      "outputs": [],
      "source": [
        "##train['Ticket_only_number'] = np.where(train['Ticket'].str.isdigit(), 1, 0)\n",
        "train['Ticket_group'] = np.where(train['Ticket'].str.isdigit(), train['Ticket'].astype(str).str[0], train['Ticket'].str[:1])\n",
        "train['Ticket_length'] = train['Ticket'].apply(lambda x: len(x))\n",
        "test['Ticket_group'] = np.where(test['Ticket'].str.isdigit(), test['Ticket'].astype(str).str[0], test['Ticket'].str[:1])\n",
        "test['Ticket_length'] = test['Ticket'].apply(lambda x: len(x))\n",
        "\n",
        "train[\"NameLength\"] = train[\"Name\"].apply(lambda x: len(x))\n",
        "test[\"NameLength\"] = test[\"Name\"].apply(lambda x: len(x))\n",
        "\n",
        "fig, (axis1) = plt.subplots(1,1,figsize=(10,5))\n",
        "\n",
        "ticket_group_mean = train[[\"Ticket_group\", \"Survived\"]].groupby(['Ticket_group'],as_index=False).mean().sort('Survived')\n",
        "sns.barplot(x='Ticket_group', y=\"Survived\", data=ticket_group_mean, palette=\"Set3\", ax=axis1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d7cdbbac-7a43-6099-d9df-1cbd3b4d263e"
      },
      "outputs": [],
      "source": [
        "##train['Ticket_number_details'] = train['Ticket'].apply(lambda x: len(x))\n",
        "###train['Ticket_group'] = np.where(train['Ticket'].str.isdigit(), 'only number', train['Ticket'].str[:1])\n",
        "##\n",
        "##ticket_group_det_mean['number_only'] = np.where(train['Ticket'].str.isdigit(), 1, 0)\n",
        "##train_sample = ticket_group_det_mean[ticket_group_det_mean['number_only'] == 1]\n",
        "##\n",
        "##fig, (axis1, axis2) = plt.subplots(2,1,figsize=(10,10))\n",
        "##\n",
        "##ticket_group_det_mean = train_sample[[\"Ticket_number_details\", \"Survived\"]].groupby(['Ticket_number_details'],as_index=False).mean()\n",
        "##sns.barplot(x='Ticket_number_details', y=\"Survived\", data=train, palette=\"Set3\", ax=axis1)\n",
        "##sns.countplot(x='Ticket_number_details', hue = 'Survived', data=train, palette=\"husl\", ax=axis2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f473e8c3-3212-b5fc-791d-a14963db0906"
      },
      "outputs": [],
      "source": [
        "########## this counts the number of spaces in the Name column\n",
        "import re\n",
        "\n",
        "at = re.compile(r\" \", re.I)\n",
        "def count_spaces(string):\n",
        "    count = 0\n",
        "    for i in at.finditer(string):\n",
        "        count += 1\n",
        "    return count\n",
        "\n",
        "train[\"spaces_in_name\"] = train[\"Name\"].map(count_spaces)\n",
        "test[\"spaces_in_name\"] = test[\"Name\"].map(count_spaces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e00a0510-d4a3-aeb5-01d9-8a4ef68dc36a"
      },
      "outputs": [],
      "source": [
        "# This function returns the title from a name.\n",
        "def title(name):\n",
        "# Search for a title using a regular expression. Titles are made of capital and lowercase letters ending with a period.\n",
        "    find_title = re.search(' ([A-Za-z]+)\\.', name)\n",
        "# Extract and return the title If it exists. \n",
        "    if find_title:\n",
        "        return find_title.group(1)\n",
        "    return \"\"\n",
        "\n",
        "train[\"Title\"] = train[\"Name\"].apply(title)\n",
        "test[\"Title\"] = test[\"Name\"].apply(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5de709a4-c24e-7d76-486b-640a57a10358"
      },
      "outputs": [],
      "source": [
        "#train.head(5)\n",
        "\n",
        "#### here I want a univariate p-value analysis between the target and the variable \n",
        "\n",
        "train['Cabin_first_ltr'] = np.where(train['Cabin'].isnull(), 'Null', 'Not Null')\n",
        "##train['Parch_grouped'] = np.where(train['Parch'] > 0, '1', '0')\n",
        "train['FamilySize'] = train['SibSp'] + train['Parch']\n",
        "train['withfamily'] = np.where(train['FamilySize'] > 0, 1, 0)\n",
        "train['Female'] = np.where(train['Sex'] == 'female', 1, 0)\n",
        "\n",
        "train['miss'] = np.where(train['Name'].str.contains(\"Miss. \"), 1, 0)\n",
        "train['mrs'] = np.where(train['Name'].str.contains(\"Mrs. \"), 1, 0)\n",
        "\n",
        "\n",
        "\n",
        "#df[df['date'].astype(str).str.contains('07311954')]\n",
        "#train['Cabin_number'] = np.where(train['Cabin'].isnull(), 'Null', 'Not Null') #train['Cabin'].str[1:])\n",
        "\n",
        "#train['Cabin_first_ltr'] = train['Cabin'].str[:1]\n",
        "#train['Cabin_first_ltr'][train['Cabin'].isnull()] = 'Null'\n",
        "\n",
        "#df['Age_Group'][df['Age'] > 40] = '>40'\n",
        "\n",
        "fig, (axis1, axis2, axis3, axis4) = plt.subplots(4,1,figsize=(5,15))\n",
        "sns.countplot(x='spaces_in_name', hue = 'Survived', data=train, palette=\"husl\", ax=axis1)\n",
        "sns.countplot(x='mrs', hue = 'Survived', data=train, palette=\"husl\", ax=axis2)\n",
        "#sns.countplot(x='dr', hue = 'Survived', data=train, palette=\"husl\", ax=axis3)\n",
        "\n",
        "#### Look at the % survived \n",
        "mrs_mean = train[[\"mrs\", \"Survived\"]].groupby(['mrs'],as_index=False).mean()\n",
        "sns.barplot(x='mrs', y=\"Survived\", data=mrs_mean, palette=\"Set3\", ax=axis3)\n",
        "\n",
        "miss_mean = train[[\"Ticket_group\", \"Survived\"]].groupby(['Ticket_group'],as_index=False).mean()\n",
        "sns.barplot(x='Ticket_group', y=\"Survived\", data=miss_mean, palette=\"Set3\", ax=axis4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "82d1ca79-10eb-7c9a-db15-80c318fcac34"
      },
      "outputs": [],
      "source": [
        "## to run a random forest we need to make sure the dataset doens't contain any missing values.\n",
        "### does it contain missing values\n",
        "if train.isnull().values.any() == True:\n",
        "    print(\"there are some missing values\")\n",
        "else: \n",
        "    print(\"there are no missing values\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d8057f24-a401-b88f-362e-288ed9132eb2"
      },
      "outputs": [],
      "source": [
        "## Make adjustments to the test dataset to match the train dataset\n",
        "\n",
        "test['Cabin_first_ltr'] = np.where(test['Cabin'].isnull(), 'Null', 'Not Null')\n",
        "test['FamilySize'] = test['SibSp'] + test['Parch']\n",
        "test['withfamily'] = np.where(test['FamilySize'] > 0, 1, 0)\n",
        "test['Female'] = np.where(test['Sex'] == 'female', 1, 0)\n",
        "\n",
        "test['miss'] = np.where(test['Name'].str.contains(\"Miss. \"), 1, 0)\n",
        "test['mrs'] = np.where(test['Name'].str.contains(\"Mrs. \"), 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aed26124-90ce-9018-33f9-1321be3f61df"
      },
      "outputs": [],
      "source": [
        "fig, (axis1) = plt.subplots(1,1, figsize = (5, 5))\n",
        "FamilySize_mean = train[[\"withfamily\", \"Survived\"]].groupby([\"withfamily\"], as_index = False).mean()\n",
        "sns.barplot(x = 'withfamily', y = 'Survived', data = FamilySize_mean, palette = \"Set3\", ax = axis1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1f5b76d9-03fb-1c6a-5279-e882a601a712"
      },
      "outputs": [],
      "source": [
        "##### this removes the missing values\n",
        "from sklearn.base import TransformerMixin\n",
        "class DataFrameImputer(TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
        "            if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n",
        "            index=X.columns)\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        return X.fillna(self.fill)\n",
        "    \n",
        "\n",
        "\n",
        "### this will transfer the categorical variables to floats for the algo\n",
        "def do_treatment(df):\n",
        "    for col in df:\n",
        "        if df[col].dtype == np.dtype('O'):\n",
        "            df[col] = df[col].apply(lambda x : hash(str(x)))\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "347a1d0e-de24-e9f6-0a74-53243908725c"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_imputed = DataFrameImputer().fit_transform(train)\n",
        "test_imputed = DataFrameImputer().fit_transform(test)\n",
        "\n",
        "do_treatment(train_imputed)\n",
        "do_treatment(test_imputed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3bc1ba04-a290-0c5a-46fd-3fae2c4fa063"
      },
      "outputs": [],
      "source": [
        "##train_imputed.head()\n",
        "#### this tells us which format each of the variables are in \n",
        "##train_imputed.columns.to_series().groupby(train_imputed.dtypes).groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a048a09d-ee75-0982-3b6a-9416f31d13be"
      },
      "outputs": [],
      "source": [
        "##train_independent_vars.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9d150d8c-77f0-468a-1cd6-5165ee97d99a"
      },
      "outputs": [],
      "source": [
        "## Make adjustments to the test dataset to match the train dataset\n",
        "\n",
        "test['Cabin_first_ltr'] = np.where(test['Cabin'].isnull(), 'Null', 'Not Null')\n",
        "test['Parch_grouped'] = np.where(test['Parch'] > 0, '1', '0')\n",
        "test['withfamily'] = np.where(test['FamilySize'] > 0, 1, 0)\n",
        "\n",
        "test['miss'] = np.where(test['Name'].str.contains(\"Miss. \"), 1, 0)\n",
        "test['mrs'] = np.where(test['Name'].str.contains(\"Mrs. \"), 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a86dd887-0d74-b785-45a5-29494923ab13"
      },
      "outputs": [],
      "source": [
        "train_imputed['withfamily'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d5c8238d-e6f6-1b55-04cc-eb25d473030b"
      },
      "outputs": [],
      "source": [
        "##### is there any major collinarity between the variables? \n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "train_cols = ['Title', 'NameLength', 'Pclass', 'Female', 'Age', 'Ticket_group', 'Cabin_first_ltr']\n",
        "\n",
        "vals_removed_bc_p_value_too_small = ['Ticket_length', 'withfamily', 'Fare', 'Embarked', 'spaces_in_name']\n",
        "\n",
        "####### \n",
        "logit = sm.Logit(train_imputed['Survived'].astype(float), train_imputed[train_cols].astype(float))\n",
        "result = logit.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d69dad3b-43a3-24c7-b523-c38b36c24311"
      },
      "outputs": [],
      "source": [
        "result.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7d415528-7457-55d3-5214-0490f5f9796f"
      },
      "outputs": [],
      "source": [
        "######## Creating the random forest model \n",
        "# Create the random forest object which will include all the parameters\n",
        "# for the fit\n",
        "forest = RandomForestClassifier(n_estimators = 200, max_features = 'sqrt',\n",
        "                             max_depth = None, verbose = 1, n_jobs = -1)\n",
        "\n",
        "# Fit the training data to the Survived labels and create the decision trees\n",
        "#train_independent_vars = train_imputed.drop(['Survived'], axis = 1)\n",
        "train_independent_vars = train_imputed[['Ticket_length', 'Title', 'NameLength', 'Pclass', 'Female', 'Age', 'withfamily', 'Ticket_group', 'Fare', 'Embarked', 'Cabin_first_ltr', 'spaces_in_name']]\n",
        "train_independent_vars = train_independent_vars\n",
        "\n",
        "train_dependent_vars = train_imputed['Survived']\n",
        "\n",
        "forest = forest.fit(train_independent_vars, train_dependent_vars)\n",
        "\n",
        "# Take the same decision trees and run it on the test data\n",
        "output = forest.predict(train_imputed[['Ticket_length', 'Title', 'NameLength', 'Pclass', 'Female', 'Age', 'withfamily', 'Ticket_group', 'Fare', 'Embarked', 'Cabin_first_ltr', 'spaces_in_name']])\n",
        "\n",
        "### combine the passengerid with the prediction\n",
        "output_df = pd.DataFrame(test_imputed.PassengerId).join(pd.DataFrame(output))\n",
        "output_df.columns = ['PassengerId', 'Survived']\n",
        "#### create the final output dataframe\n",
        "final_output = DataFrame(columns=['PassengerId', 'Survived'])\n",
        "final_output = final_output.append(output_df[['PassengerId', 'Survived']])\n",
        "#### convert to csv\n",
        "final_output.to_csv('output.csv', index = False, header = ['PassengerId', 'Survived'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a2f6519a-9efd-4a01-ddac-35769da9a9fc"
      },
      "outputs": [],
      "source": [
        "#\n",
        "importances = forest.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "\n",
        "for f in indices:\n",
        "    print(train_independent_vars.columns[f], importances[f])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "24950738-d8a6-efb8-1d42-64170bafc1bc"
      },
      "outputs": [],
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1c41d0de-9cab-92fe-e997-afb7e0dbb314"
      },
      "outputs": [],
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "42a2ec75-a11e-6abb-5f6c-6831d46f3731"
      },
      "outputs": [],
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bb4edf3e-e8c7-cf3f-7608-158b5eebf1ca"
      },
      "outputs": [],
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8684b2bd-a045-eb53-7443-72a1cdf69a48"
      },
      "outputs": [],
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "414dac4c-d418-bf74-729f-fb1c25eb083c"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}