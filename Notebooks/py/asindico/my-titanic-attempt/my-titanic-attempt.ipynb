{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "eb56e1bd-d0c4-d406-0fba-8af64fe9bd9c"
      },
      "source": [
        "\n",
        "This data set consists of two files: a CSV containing the training data, including the target values, and a CSV containing the test data which does not contain the target.\n",
        "We are interested to train a model capable of stating whether an unknown individual was likely to survive or not at the titanic disaster.\n",
        "We start out by loading the two training sets and plotting the first 5 rows of the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f2b88160-3625-7eab-0728-ba166b4fa8b6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import Imputer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "train = pd.read_csv(\"../input/train.csv\")\n",
        "test = pd.read_csv(\"../input/test.csv\")\n",
        "test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "62a10f26-8c95-58d0-ffaa-6a28b9b4f263"
      },
      "outputs": [],
      "source": [
        "\n",
        "train.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "db3e1e1b-e9e1-0e7d-e0e8-9e723945c3ec"
      },
      "source": [
        "First of all it is quite clear wi will drop the name as irrelevant. However there is an interesting information we can easily extract from the name: the Title (i.e. Capt., Col., Major., etc.) which may correlate with our target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f1300866-3fa0-a6bb-2b01-15d53705ccd0"
      },
      "outputs": [],
      "source": [
        "train['Title'] = train['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
        "Title_Dictionary = {\n",
        "                        \"Capt\":       0,\n",
        "                        \"Col\":        0,\n",
        "                        \"Major\":      0,\n",
        "                        \"Jonkheer\":   1,\n",
        "                        \"Don\":        1,\n",
        "                        \"Sir\" :       1,\n",
        "                        \"Dr\":         0,\n",
        "                        \"Rev\":        0,\n",
        "                        \"the Countess\":1,\n",
        "                        \"Dona\":       1,\n",
        "                        \"Mme\":        2,\n",
        "                        \"Mlle\":       3,\n",
        "                        \"Ms\":         2,\n",
        "                        \"Mr\" :        4,\n",
        "                        \"Mrs\" :       2,\n",
        "                        \"Miss\" :      3,\n",
        "                        \"Master\" :    5,\n",
        "                        \"Lady\" :      1\n",
        "\n",
        "                        }\n",
        "    \n",
        "train['Title'] = train.Title.map(Title_Dictionary)\n",
        "f,ax1 = plt.subplots()\n",
        "corr = train.corr()\n",
        "sns.heatmap(corr, vmax=1, square=True,ax=ax1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4170edc2-e121-80da-1cfa-3c8c5c26585a"
      },
      "source": [
        "It seems the Survived feature is mainly related to Age, Pclass, Parch and Fare. We may try dropping Name, Ticket, Cabin and PassengerId and SibSp."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "146fce57-391c-a115-b195-9352deadf6bd"
      },
      "outputs": [],
      "source": [
        "fdf = train.drop(['PassengerId','Name','Ticket','Cabin','SibSp'],1)\n",
        "fdf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fbc9e185-d559-f503-8601-a05e32a90902"
      },
      "source": [
        "We can now try to train some supervised models in order to choose the one which better fits with our data. To this end we create a vector with the target information we want to know: the survived vector. Then we drop that column from the original data frame and we get the data frame of features we need to train the model. We turn the Gender and Embarked information from strings to integers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2740e306-e5bc-5ff0-a40d-4d6a100f8d69"
      },
      "outputs": [],
      "source": [
        "survived = fdf['Survived']\n",
        "features = fdf.drop(['Survived'],axis=1)\n",
        "features['Sex'] = features['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
        "features['Embarked'] = features['Embarked'].map( {'S': 0, 'C': 1, 'Q':2},na_action=None )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e07780c8-ace9-0d52-e97f-88157f4326cc"
      },
      "source": [
        "Now we have to deal with not assigned values which are present in Age, Fare and Embarked features. I first tried with an Inputer but I realized there can be a correlation among these data and Gender/PClass/Title. So we can create groups and use the mean values for each group to replace NaN values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "32039c72-795b-9b0a-f37f-f70f71bb0c5e"
      },
      "outputs": [],
      "source": [
        "grouped = features.groupby(['Sex','Pclass','Title'])\n",
        "gm = grouped.median()\n",
        "print(gm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6c9cf204-d6f1-9dd2-91c7-98bb3b65330c"
      },
      "outputs": [],
      "source": [
        "gm['Age'][0]\n",
        "\n",
        "features.Age = features.apply(lambda item : gm['Age'][item['Sex'],item['Pclass'],item['Title']] if np.isnan(item['Age']) else item['Age'], axis=1)\n",
        "features.Age = features['Age'].apply(lambda x: np.log(x + 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "182faf08-614f-2704-1c0d-4634de4fac2e"
      },
      "outputs": [],
      "source": [
        "sns.distplot(features['Age'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2cf78ef4-1e2c-fc2b-b1bb-24f8064f802d"
      },
      "outputs": [],
      "source": [
        "features.Fare = features.apply(lambda item : gm['Fare'][item['Sex'],item['Pclass'],item['Title']] if np.isnan(item['Fare']) else item['Fare'], axis=1)\n",
        "features.Fare = features['Fare'].apply(lambda x: np.log(x + 1))\n",
        "\n",
        "sns.distplot(features['Fare'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c2152afe-f157-c6b0-d999-40521647d8fd"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "features.Embarked = features.apply(lambda item : ceil(gm['Embarked'][item['Sex'],item['Pclass'],item['Title']]) if np.isnan(item['Embarked']) else item['Embarked'], axis=1)\n",
        "#features.Embarked = features['Embarked'].apply(lambda x: np.log(x + 1))\n",
        "\n",
        "sns.distplot(features['Embarked'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7ca1249f-c39e-b898-47cd-6e3bc5ad4212"
      },
      "outputs": [],
      "source": [
        "pclass_dummies = pd.get_dummies(features['Pclass'],prefix=\"Pclass\")\n",
        "embarked_dummies =  pd.get_dummies(features['Embarked'],prefix=\"Embarked\")\n",
        " # adding dummy variables\n",
        "features.drop('Pclass',axis=1,inplace=True)\n",
        "features.drop('Embarked',axis=1,inplace=True)\n",
        "features = pd.concat([features,pclass_dummies],axis=1)\n",
        "features = pd.concat([features,embarked_dummies],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cfffd260-5756-16a7-1a22-70598e8448ec"
      },
      "source": [
        "Now we use the train_test_split function to randomly choose 20% of individuals for test and 80% of individuals for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "be7ce4d9-bdba-5b44-7b40-0847d6b47b7d"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "from sklearn.cross_validation import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import tree\n",
        "from sklearn.svm import SVC\n",
        "import random \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import neighbors\n",
        "from time import time\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, survived, test_size = 0.2, random_state = 0)\n",
        "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
        "print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
        "\n",
        "def train_predict(learner, X_train, y_train, X_test, y_test): \n",
        "    \n",
        "    results = {}\n",
        "    start = time() # Get start time\n",
        "    learner.fit(X_train,y_train)\n",
        "    end = time() # Get end time\n",
        "    results['train_time'] = end-start\n",
        "        \n",
        "    start = time() # Get start time\n",
        "    predictions_test = learner.predict(X_test)\n",
        "    predictions_train = learner.predict(X_train)\n",
        "    end = time() # Get end time\n",
        "    \n",
        "    results['pred_time'] = end-start\n",
        "    results['acc_train'] = accuracy_score(y_train,predictions_train)\n",
        "    results['acc_test'] = accuracy_score(y_test,predictions_test)\n",
        "    results['f_train'] = fbeta_score(y_train,predictions_train,beta=0.5)\n",
        "    results['f_test'] = fbeta_score(y_test,predictions_test,beta=0.5)\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1c4db4d5-770f-086e-c153-25bc73faf4ad"
      },
      "source": [
        "Then we compare three possible models:\n",
        "Gaussian Naive Bayes\n",
        "Decision Tree\n",
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ad59f4c8-bee5-c7dc-413f-bc6353959bcf"
      },
      "outputs": [],
      "source": [
        "\n",
        "clf_A = GaussianNB()\n",
        "clf_B = tree.DecisionTreeClassifier()\n",
        "clf_C = RandomForestClassifier(n_estimators=200,criterion='gini')\n",
        "\n",
        "results = {}\n",
        "for clf in [clf_A, clf_B, clf_C]:\n",
        "    clf_name = clf.__class__.__name__\n",
        "    results[clf_name] = {}\n",
        "    results[clf_name] =  train_predict(clf, X_train, y_train, X_test, y_test)\n",
        "\n",
        "train_time = {}\n",
        "pred_time = {}\n",
        "acc_train = {}\n",
        "acc_test = {}\n",
        "f_train = {}\n",
        "f_test ={}\n",
        "\n",
        "for k in results.keys():\n",
        "    train_time[k] = results[k][\"train_time\"]\n",
        "    pred_time[k] = results[k][\"pred_time\"]\n",
        "    acc_train[k]  = results[k][\"acc_train\"]\n",
        "    acc_test[k]   = results[k][\"acc_test\"]\n",
        "    f_train[k]    = results[k][\"f_train\"]\n",
        "    f_test[k]     = results[k][\"f_test\"]\n",
        "    \n",
        "    \n",
        "\n",
        "f,axarray = plt.subplots(2,2)\n",
        "axarray[0,0].set_title(\"Training time\")\n",
        "axarray[0,0].bar(range(len(train_time)), train_time.values(), align='center')\n",
        "axarray[0,0].set_xticks(range(len(train_time)), train_time.keys())\n",
        "\n",
        "axarray[0,1].set_title(\"Prediction time\")\n",
        "axarray[0,1].bar(range(len(pred_time)), pred_time.values(), align='center')\n",
        "axarray[0,1].set_xticks(range(len(pred_time)), pred_time.keys())\n",
        "\n",
        "axarray[1,0].set_title(\"Accuracy Test\")\n",
        "axarray[1,0].bar(range(len(acc_test)), acc_test.values(), align='center')\n",
        "axarray[1,0].set_xticks(range(len(acc_test)), acc_test.keys())\n",
        "\n",
        "axarray[1,1].set_title(\"F-Score Test\")\n",
        "axarray[1,1].bar(range(len(f_test)), f_test.values(), align='center')\n",
        "axarray[1,1].set_xticks(range(len(f_test)), f_test.keys())\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ddc70837-8e7f-98f5-e9db-7bdb1e4fc61f"
      },
      "source": [
        "Although Random Forest takes far more time than the other two models it performs better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d377e491-e8cd-f8f0-343c-08fc0fac11cb"
      },
      "outputs": [],
      "source": [
        "#clf_C.fit(features,survived)\n",
        "\n",
        "\n",
        "imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
        "test['Title'] = test['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
        "test['Title'] = test.Title.map(Title_Dictionary)\n",
        "\n",
        "test_input = test.drop(['PassengerId','Name','Ticket','Cabin','SibSp'],1)\n",
        "\n",
        "test_input['Sex'] = test_input['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
        "test_input['Embarked'] = test_input['Embarked'].map( {'S': 0, 'C': 1, 'Q':2},na_action=None )\n",
        "test_input['Embarked'] =  imp.fit_transform(test_input['Embarked'].values.reshape(-1,1))\n",
        "\n",
        "test_input.Embarked = test_input.apply(lambda item : ceil(gm['Embarked'][item['Sex'],item['Pclass'],item['Title']]).astype(int) if np.isnan(item['Embarked'].astype(int)) else item['Embarked'], axis=1)\n",
        "\n",
        "test_input.Age = test_input.apply(lambda item : gm['Age'][item['Sex'],item['Pclass'],item['Title']] if np.isnan(item['Age']) else item['Age'], axis=1)\n",
        "test_input.Age = test_input['Age'].apply(lambda x: np.log(x + 1))\n",
        "\n",
        "test_input.Fare = test_input.apply(lambda item : gm['Fare'][item['Sex'],item['Pclass'],item['Title']] if np.isnan(item['Fare']) else item['Fare'], axis=1)\n",
        "test_input.Fare = test_input['Fare'].apply(lambda x: np.log(x + 1))\n",
        "\n",
        "pclass_dummies = pd.get_dummies(test_input['Pclass'],prefix=\"Pclass\")\n",
        "embarked_dummies =  pd.get_dummies(test_input['Embarked'],prefix=\"Embarked\")\n",
        " # adding dummy variables\n",
        "test_input.drop('Pclass',axis=1,inplace=True)\n",
        "test_input.drop('Embarked',axis=1,inplace=True)\n",
        "test_input = pd.concat([test_input,pclass_dummies],axis=1)\n",
        "test_input = pd.concat([test_input,embarked_dummies],axis=1)\n",
        "\n",
        "pd.isnull(test_input).any()\n",
        "\n",
        "#test_input['Fare'] = test_input['Fare'].apply(lambda x: np.log(x + 1))\n",
        "#test_input['Fare'] =  imp.fit_transform(test_input['Fare'].values.reshape(-1,1))\n",
        "\n",
        "\n",
        "\n",
        "#test_input.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6bc9b112-5de5-1188-3591-6bdb2c5472dc"
      },
      "outputs": [],
      "source": [
        "print (\"using {}\".format(clf_C.__class__.__name__))\n",
        "prediction = clf_C.predict(test_input)\n",
        "predition =  prediction.astype(int)\n",
        "submission = pd.DataFrame({\n",
        "        \"PassengerId\": test[\"PassengerId\"],\n",
        "        \"Survived\": prediction.astype(int)\n",
        "    })\n",
        "submission.to_csv('titanic.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "82d7694e-94d7-43d0-fec6-0bd9803b78b9",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}