{"nbformat": 4, "cells": [{"cell_type": "markdown", "source": ["# Titanic: Machine Learning from Disaster\n", "\n", "## Introduction\n", "Titanic is a famous ship that sank on 15 April 1912 after colliding with an iceberg. \n", "There were 2224 passengers and 1502 died making it one of the deadliest disaster of the modern history. <sup>[1]</sup>\n", "\n", "Our job here is to build a model that answers how likely people were to survive this disaster. <br />\n", "The process we'll be as following:\n", "1. Data Exploration and Visualization\n", "2. Feature Engineering\n", "3. Making predictions\n", "4. Tuning hyperparameters\n", "5. Conclusion\n", "\n", "## Source\n", "1. https://en.wikipedia.org/wiki/RMS_Titanic"], "metadata": {"_uuid": "123052080cf98e9c30ba57e748f77c979b73da89", "_cell_guid": "8662e27e-563f-4f15-9596-cc8ecb528e2d"}}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "82a6c30437ee74cae8fd3c8a128e892097914f82", "_cell_guid": "c186f81f-6d92-4a41-8da5-d1e0330d8c06"}, "cell_type": "code", "source": ["# for text patterns\n", "import re\n", "# for math stuff\n", "import numpy as np\n", "# for handling the dataset\n", "import pandas as pd\n", "# for data visualization\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "\n", "# model used for classification\n", "from sklearn.ensemble import RandomForestClassifier\n", "# metric used to measure the performance of the classifier\n", "from sklearn.metrics import accuracy_score\n", "\n", "# for reproducibility\n", "np.random.seed(0)\n", "\n", "sns.set(style=\"white\", context=\"talk\")\n", "%matplotlib inline"], "execution_count": 2}, {"cell_type": "markdown", "source": ["## Data Exploration and Visualization\n", "First of all, let's load and explore the dataset."], "metadata": {"_uuid": "aab90efbd854029f870171435622330ea8448c80", "_cell_guid": "3a947691-951a-4bb2-9688-0d263195af7a"}}, {"outputs": [], "metadata": {"_uuid": "556b871096d505e91633ca21526b64a7adfedd09", "_cell_guid": "fdb902ce-8c7b-4cd3-b61c-b595e6a3dfb6"}, "cell_type": "code", "source": ["train = pd.read_csv('../input/train.csv')\n", "test  = pd.read_csv('../input/test.csv')\n", "\n", "print('train size: {0}; test size: {1}'.format(len(train), len(test)))"], "execution_count": 3}, {"cell_type": "markdown", "source": ["We have a training set with 891 samples and a testing set with 418 samples. <br />\n", "Let's take a preview on training set."], "metadata": {"_uuid": "3ccda5a12bac309c06ab168c30e84c2faf585b62", "_cell_guid": "0b7be446-ba8a-4ea8-9e58-511ec730130e"}}, {"outputs": [], "metadata": {"scrolled": true, "_uuid": "6e2a9473613e94d3ab4ef5c56c80c480ae820ad6", "_cell_guid": "cd1e395c-fbf6-4667-95a1-82e45f8566d0"}, "cell_type": "code", "source": ["train.head()"], "execution_count": 4}, {"cell_type": "markdown", "source": ["Here, we can see that our response variable (label) is **Survived** and it's a categorical variable. <br />\n", "This means that we'll be using a classifier as prediction model.\n", "\n", "The other ones are explanatory variables and there are categorical and continuous variables.\n", "\n", "We can see the feature **Cabin** has NaN values. This is a problem the should be handled. <br />\n", "Let's take an overview on dataset and see the quantity of NaN values."], "metadata": {"_uuid": "9f85375fd4629c85aaecb54d2bed28a64f870069", "_cell_guid": "42aa4a1c-5690-41ec-95b8-5bd6823bc8c8"}}, {"outputs": [], "metadata": {"scrolled": true, "_uuid": "77ec13d39fb06022e81b5b68724f7974558fea8c", "_cell_guid": "6255935f-ef08-4e8c-ae19-36bd069a7457"}, "cell_type": "code", "source": ["print('***TRAINING SET***')\n", "print(train.isnull().sum())\n", "print('\\n***TESTING SET***')\n", "print(test.isnull().sum())"], "execution_count": 5}, {"cell_type": "markdown", "source": ["Now we can see that:\n", "* The feature **Cabin** might be discarded since more than 70% of the data isn't provided.\n", "* The feature **Embarked** has only 2 samples with NaN. We could discard the sample or impute values.\n", "* The feature **Age** has 263 samples with NaN. This is about 20% of the data. Discarding the feature might be pretty much loss of information. So, we should be imputing new values.\n", "\n", "Now, let's plot some graphs in order to get some insight about the dataset. <br />\n", "Our response variable is **Survived**, so let's see the ratio between the Survived and Desceased people."], "metadata": {"_uuid": "09f88d89a137d3acfc604bb130a3bcf14094958d", "_cell_guid": "96966fcb-40c2-4258-a10f-21fb4ef15c26"}}, {"outputs": [], "metadata": {"_uuid": "6cef14f8f298eec36dc28a63f7331625fc17869f", "_cell_guid": "e3429fef-e71b-4470-8528-2213c78c9e73"}, "cell_type": "code", "source": ["plt.title('Survived x Deceased')\n", "sns.countplot(data=train, x='Survived')"], "execution_count": 6}, {"cell_type": "markdown", "source": ["Here we can see that most of the people desceased, but nothing more. <br />\n", "Let's see the survivability rate between genders."], "metadata": {"_uuid": "2acce4d9ace6f5ff57c879732fcb782140a93ef6", "_cell_guid": "4b30b07f-946a-4ae5-846d-d6a0b2f73dc5"}}, {"outputs": [], "metadata": {"scrolled": true, "_uuid": "d7ffd05f9d1272ac5bcbbb60c72f931600859368", "_cell_guid": "8ec72db1-c7cf-49e5-b40d-1a1bc391c6f4"}, "cell_type": "code", "source": ["sns.factorplot(data=train, x='Survived', hue='Sex', kind='count')\n", "plt.title('Survivability between genders')"], "execution_count": 7}, {"cell_type": "markdown", "source": ["Now, we have an interesting insight. Most of the men died on this disaster. <br />\n", "This is due to the \"women and children first\" protocol while loading the safeboats."], "metadata": {"_uuid": "9cc5082b3f33606ddb9d6b4d368836f8f78477bf", "_cell_guid": "d8e576dd-d0de-4339-be94-4c6dee796439"}}, {"outputs": [], "metadata": {"_uuid": "616c0fde7c6b1118fb8f5448f69d58faccfda946", "_cell_guid": "b622230f-9807-4279-bbf3-75e2e2e2fe2a"}, "cell_type": "code", "source": ["fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n", "\n", "sns.countplot(data=train, x='Pclass', hue='Sex', ax=ax1)\n", "ax1.set_title('Survivability between Classes|Gender')\n", "\n", "sns.countplot(data=train, x='Pclass', hue='Survived', ax=ax2)\n", "ax2.set_title('Survivability between Classes')"], "execution_count": 8}, {"outputs": [], "metadata": {"_uuid": "d9a5f8f2e03b2d775f530e61492a9e9613395f4a", "_cell_guid": "cf66697c-0109-4f98-8df0-24cc8a2d15a4"}, "cell_type": "code", "source": ["ax = sns.factorplot(data=train, x='Survived', hue='Sex', col='Pclass', kind='count')\n", "ax.fig.subplots_adjust(top=.8)\n", "ax.fig.suptitle('Survivability between Gender|Class')"], "execution_count": 9}, {"cell_type": "markdown", "source": ["After we factored the plot between classes, it seems that first class were more likely to survive, even though the third class had more passengers. <br />"], "metadata": {"_uuid": "75ed7a52134b49d4edbc6baebab535a5c17471b9", "_cell_guid": "3217b065-87ad-4a42-b653-0b5a73f8568a"}}, {"outputs": [], "metadata": {"scrolled": true, "_uuid": "13a8b8309e073301193b6fe4095482cd4058b128", "_cell_guid": "cd3d44a8-0737-4e81-aea2-01bb5c04c3fa"}, "cell_type": "code", "source": ["# train[(train.SibSp > 0)|(train.Parch > 0)]\n", "# train[((train.SibSp > 0)|(train.Parch > 0))&(train.Pclass == 1)]\n", "train[((train.Parch > 1))&(train.Pclass == 1)]"], "execution_count": 10}, {"outputs": [], "metadata": {"_uuid": "404cf70f9094bb35cdf7a08da33b4fb909a7894b", "_cell_guid": "83cca2c9-3fe4-487e-99e9-c09f5be5ebba"}, "cell_type": "code", "source": ["train[train.Ticket=='CA. 2343']"], "execution_count": 11}, {"cell_type": "markdown", "source": ["An interesting fact is that families generally bought the same ticket. <br />"], "metadata": {"_uuid": "18e66c02645d04cf55b4a82833f3b893ac748433", "_cell_guid": "154a7288-0077-4252-ab95-9e543b7be43b"}}, {"outputs": [], "metadata": {"scrolled": true, "_uuid": "c8c8879220f77c463c6270c0a25d3f84100889c2", "_cell_guid": "fcd02b53-4cfb-4f8a-b9cc-8a9adf51bb50"}, "cell_type": "code", "source": ["# train[train.Ticket=='2666']\n", "# train[train.Ticket=='19950']\n", "train[train.Ticket=='113760']"], "execution_count": 12}, {"cell_type": "markdown", "source": ["And after taking a look on some families, there are cases that:\n", "* The whole family sank together;\n", "* The whole family survived together;\n", "* Only the females of the family survived;"], "metadata": {"_uuid": "d6a72c509a34b8d747ac0c3b9a8c4451efbe3cc2", "_cell_guid": "7bc45bf9-4514-49f1-b033-8bba82156562"}}, {"cell_type": "markdown", "source": ["---\n", "## Feature Engineering\n", "### Dealing with missing values\n", "Before starting the feature engineering, we'll be merging both datasets in one."], "metadata": {"_uuid": "f7273d62d5f88ef340b0cffa46769cc686456cc1", "_cell_guid": "84a59243-366a-499f-a5b8-a6701e145666"}}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "de38a6d82f5e489a656fc1c1f65ff8fc950d3d17", "_cell_guid": "08fb0847-674c-4d48-8413-da5d1ff94ae3"}, "cell_type": "code", "source": ["X, y = train.iloc[:,2:], train.iloc[:,1] # separating the labels"], "execution_count": 13}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "b40a627f629ef8914d174b47f7b9e32c2427d815", "_cell_guid": "0ce5a984-3f5d-40ef-b8c5-993a2cc345c4"}, "cell_type": "code", "source": ["X = pd.concat([X[:], test.iloc[:,1:][:]], ignore_index=True) # merging the datasets"], "execution_count": 14}, {"outputs": [], "metadata": {"scrolled": true, "_uuid": "3c165363360bb34944c29a84e58d22c871ae8419", "_cell_guid": "3ac38017-0504-4403-a5c9-29b05bdc2869"}, "cell_type": "code", "source": ["print('total is {}'.format(len(X)))"], "execution_count": 15}, {"cell_type": "markdown", "source": ["Let's start with the easiest one. <br />\n", "Embarked have only 2 samples with NaN, let's take a look on them."], "metadata": {"_uuid": "a7160d42f9d712c41548fedb0be6f433dc721421", "_cell_guid": "98bdaf1f-524b-403d-912c-6d5b10a1d99c"}}, {"outputs": [], "metadata": {"scrolled": true, "_uuid": "59ebc8d869e4fd5c372aca36b186ad4355ae1979", "_cell_guid": "24fb6bf7-a189-4071-903e-d3554fbcf3ca"}, "cell_type": "code", "source": ["X[X.Embarked.isnull()]"], "execution_count": 16}, {"cell_type": "markdown", "source": ["We can see that both of them are somehow related. <br />\n", "They have the same ticket number, paid the same fare and shared the same cabin. Consequently, they might Embarked from the same place. <br />\n", "We'll running a *Random Forest* here to impute **Embarked** since the classifier requires almost no feature engineering. <br />"], "metadata": {"_uuid": "cbe8fbff380839dd88b051b786b4ace26b8c3399", "_cell_guid": "39341f6a-9cab-406f-852a-9f8b062eb155"}}, {"outputs": [], "metadata": {"scrolled": false, "_uuid": "0bd8f9a30bb5ef00b8f262a1cb2502a89ca5539e", "_cell_guid": "be9df0d1-ded6-4110-8c8a-db1a73c32a9d"}, "cell_type": "code", "source": ["_ = X[~X.Embarked.isnull() & ~X.Fare.isnull()][['Pclass', 'Fare', 'Embarked']].as_matrix()\n", "clf = RandomForestClassifier()\n", "clf.fit(_[:,:2], _[:,2])"], "execution_count": 17}, {"outputs": [], "metadata": {"_uuid": "affcc96112c75e3f1c3f7934c24cadf69e804038", "_cell_guid": "5d0104b6-9003-43d7-903c-38689cd340cd"}, "cell_type": "code", "source": ["clf.predict(X[X.Embarked.isnull()][['Pclass', 'Fare']].as_matrix())"], "execution_count": 18}, {"outputs": [], "metadata": {"collapsed": true, "scrolled": true, "_uuid": "ab30b37f83c0390a8abe0de9085a93bb61f78e41", "_cell_guid": "ea578952-c455-4619-97bc-b0fada9b554d"}, "cell_type": "code", "source": ["X.loc[[61, 829],['Embarked']] = 'S'"], "execution_count": 19}, {"outputs": [], "metadata": {"_uuid": "11bf71969d3908ba04d60d875b65b84531d48361", "_cell_guid": "54a0d6b3-e4fa-41c8-bbe4-66db099b241d"}, "cell_type": "code", "source": ["X.loc[[61, 829]]"], "execution_count": 20}, {"cell_type": "markdown", "source": ["The classifier predicted as they embarked from Southampton, so we'll be imputing 'S' to them.\n", "\n", "The feature **Cabin** should be discarded and I'll be doing some feature engineering on the feature **Name**. <br />\n", "So, let's start by extracting the title from each of them."], "metadata": {"_uuid": "5b8ba4f4e6eb806b6909aad40a568eaa3acb89fe", "_cell_guid": "3ef5cd38-2aa2-40d0-ad8f-b4dde8c48048"}}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "55c961ec2df87d45307210637fb4a29bfd4ee84a", "_cell_guid": "3a390837-4bbd-45cd-b6a6-46f6f2dcd7d7"}, "cell_type": "code", "source": ["del X['Cabin']\n", "# del X['Name']"], "execution_count": 21}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "e2c274fc0339242052dd976a350987cd933322e8", "_cell_guid": "0566f8af-d354-4f93-9600-308a9931399b"}, "cell_type": "code", "source": ["title_ptr = re.compile('\\w+?\\.')\n", "def get_title(s):\n", "    m = title_ptr.search(s)\n", "    return m.group()"], "execution_count": 22}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "7337e2af48091bc6e78fb4438ebdb5bae8e7f8d2", "_cell_guid": "4200d0b4-8f73-4d43-b710-cd735118b3d7"}, "cell_type": "code", "source": ["X['titles'] = X.Name.apply(get_title)"], "execution_count": 23}, {"outputs": [], "metadata": {"_uuid": "40f1df692f6e5d0b37833ea70c137fb7bbc70fdc", "_cell_guid": "10b4e98a-7345-413b-b924-99a5a060eb81"}, "cell_type": "code", "source": ["plt.figure(figsize=(15, 8))\n", "plt.title('Titles')\n", "sns.countplot(data=X, x='titles')"], "execution_count": 24}, {"cell_type": "markdown", "source": ["We can see that there are some titles that is significantly low. So, it might be fine to merge them into one group."], "metadata": {"_uuid": "1e71a410dd72cfe965feb4b2293a324bd286cc75", "_cell_guid": "5ce3e500-f4f9-44d8-b2b4-2040f567f3f5"}}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "e467646c52d1dd57722112b3f8a547d106a895db", "_cell_guid": "eec5cda2-27dd-4119-a872-6da36bb1edb9"}, "cell_type": "code", "source": ["titles = ['Mr.', 'Mrs.', 'Miss.', 'Master.']\n", "def get_title(s):\n", "    m = title_ptr.search(s)\n", "    title = m.group()\n", "    return title if title in titles else 'others'"], "execution_count": 25}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "46624ac41b4a0d690e77bbe241982ff50b62ea6b", "_cell_guid": "49381030-177c-4c3d-8ccb-85e57a812618"}, "cell_type": "code", "source": ["X['titles'] = X.Name.apply(get_title)"], "execution_count": 26}, {"outputs": [], "metadata": {"_uuid": "e7cc1e8e62c5a31eac2e1bd57cd150bbbb58b03b", "_cell_guid": "1b721db4-f12d-43b8-96d3-3f704f1f13f4"}, "cell_type": "code", "source": ["plt.title('Titles')\n", "sns.countplot(data=X, x='titles')"], "execution_count": 27}, {"cell_type": "markdown", "source": ["Now, let's check the feature Fare. <br />\n", "There is only one person with NaN Fare. <br />\n", "It might not be an issue assigning the median of the fare to this sample."], "metadata": {"_uuid": "ab0fecf48d44217205cc2caa67ac410d58938b34", "_cell_guid": "243cd424-f76a-487d-8dd3-18287b5c3c8c"}}, {"outputs": [], "metadata": {"scrolled": true, "_uuid": "b6868efdd319a4e7ecab8cf03b6979e42f8bd7b4", "_cell_guid": "7d4f665b-62bc-42be-852e-47f737c9f2cb"}, "cell_type": "code", "source": ["X[X.Fare.isnull()]"], "execution_count": 28}, {"outputs": [], "metadata": {"_uuid": "10ef821d95064c91805b52e2ee58f49468a166a9", "_cell_guid": "490114de-f811-4251-a03c-e931cffaf5cf"}, "cell_type": "code", "source": ["fare = X[(X.Pclass==3)&(X.Embarked=='S')]['Fare'].median()\n", "X.loc[1043,'Fare'] = fare\n", "X.loc[1043]"], "execution_count": 29}, {"cell_type": "markdown", "source": ["The last feature to impute is Age. <br />\n", "This one is somehow hard to predict. In order to keep the distribution, I'll generate random numbers between the mean. However, we'll be using the title as a guidance."], "metadata": {"_uuid": "41f5361515ce16392fedfdb86a2b2a0591bd19c6", "_cell_guid": "545843bc-5c76-49b0-aa1a-a334fc231b41"}}, {"outputs": [], "metadata": {"scrolled": true, "_uuid": "b8e30ccce542a201f63b5753ee9306419a760d7b", "_cell_guid": "68832dba-e02b-473a-9f6e-7275e8b6d831"}, "cell_type": "code", "source": ["sns.boxplot(data=X[~X.Age.isnull()], x=\"titles\", y='Age')"], "execution_count": 30}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "a8db60776223454482a7f3183dbc315466cd3be5", "_cell_guid": "b2ba2d7a-5cfb-4a44-bc0d-85948f814ab8"}, "cell_type": "code", "source": ["for title in np.unique(X.titles):\n", "    qty  = len(X[(X.Age.isnull()) & (X.titles == title)]) # missing value per title\n", "    mean = X[(~X.Age.isnull()) & (X.titles == title)]['Age'].mean() # mean of non- NaN\n", "    std  = X[(~X.Age.isnull()) & (X.titles == title)]['Age'].std()  # std  of non- NaN\n", "    \n", "    rdm_age = abs(np.random.randn(qty)*std + mean) # Generating random number between the STD\n", "    rdm_age = rdm_age.reshape(-1, 1)\n", "    \n", "    X.loc[X[X.Age.isnull() & (X.titles == title)].index, 'Age'] = rdm_age"], "execution_count": 31}, {"outputs": [], "metadata": {"scrolled": true, "_uuid": "7fe40058484b8860a285e60f111194d7c3fc84df", "_cell_guid": "5fb3166e-7a4e-4e04-b36d-89ce2822527b"}, "cell_type": "code", "source": ["sns.boxplot(data=X[~X.Age.isnull()], x=\"titles\", y='Age')"], "execution_count": 32}, {"cell_type": "markdown", "source": ["Checking the distribution of the feature Age, we see that it didn't changed at all. <br />\n", "Now we don't have any missing value, so we can move on.\n", "\n", "---\n", "### Handling some features\n", "While loading the safeboats, the \"women and children\" were the protocol. So, might be useful to bin the Age in a *child/adult* category. <br />\n", "Let's create a new feature with this in mind."], "metadata": {"_uuid": "540ca7c5babb76542eb3cf02d571f45255bdb14f", "_cell_guid": "b8c59fd1-b722-48c3-8ae8-f439c06cf981"}}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "b27410c22e7224b39c73e52948b9e023189163aa", "_cell_guid": "c992017d-b3c5-4e15-b257-c7d5348198b7"}, "cell_type": "code", "source": ["bins = [0, 18, max(X.Age)]\n", "categories = [1, 0]\n", "X['is_child'] = pd.cut(X.Age, bins, labels=categories)"], "execution_count": 33}, {"cell_type": "markdown", "source": ["The features \"Sex\", \"title\" and \"Embarked\" could be one-hot-encoded in order to improve the performance of the classifier."], "metadata": {"_uuid": "0fdd7a42353c39947428ffc14f0e0d4b104301d6", "_cell_guid": "a1423aff-844a-4a95-a048-85c93ad8e588"}}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "370e4035937dc225748b1deb8181a8285f468e3e", "_cell_guid": "f7559825-22da-41ef-987b-8a83e040f414"}, "cell_type": "code", "source": ["X = pd.concat([X, pd.get_dummies(X[['Sex', 'Embarked', 'titles']])], axis=1)"], "execution_count": 34}, {"cell_type": "raw", "source": ["X['norm_fare'] = np.log(X.Fare.values+1)"], "metadata": {"_uuid": "b0c2e045704df7af13874770d475b18b854683c8", "_cell_guid": "a00906d0-2c89-4a79-a49d-0cdccc24b5ad"}}, {"cell_type": "markdown", "source": ["We could improve the classifier by doing a minmax operation on the feature fare."], "metadata": {"_uuid": "81425608b79f59271c795b2b3a919987e87922ff", "_cell_guid": "2bdbff8a-02d0-4a4a-861a-2d23f8c6cd73"}}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "a11669d3e6f17cca10ec8e70e0ff9c6cbe41db1a", "_cell_guid": "b9533959-a2ea-490e-9f23-951a5c1a66b1"}, "cell_type": "code", "source": ["from sklearn.preprocessing import MinMaxScaler"], "execution_count": 35}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "90913497145e945133b7ae0d524a7801eba927a4", "_cell_guid": "1bc16c43-12fa-4c4c-a65b-edf079ed33a3"}, "cell_type": "code", "source": ["minmax = MinMaxScaler()"], "execution_count": 36}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "2cdecbe0e7286d79216c2e1c49b3ac055127ba7e", "_cell_guid": "e85f8e69-46e8-41ed-be92-64d15fe5a8b6"}, "cell_type": "code", "source": ["X['norm_fare'] = minmax.fit_transform(X.Fare.values.reshape(-1,1))"], "execution_count": 37}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "f244a5cccad400bcd2bfd6ac06ebe5bef4ce9b95", "_cell_guid": "9a436dd0-240b-4d12-9b18-4070eaefadb6"}, "cell_type": "code", "source": ["del X['Sex']\n", "del X['Age']\n", "del X['Embarked']\n", "del X['Ticket']\n", "del X['Name']\n", "del X['Fare']\n", "del X['titles']"], "execution_count": 38}, {"cell_type": "markdown", "source": ["Now let's check our dataset..."], "metadata": {"_uuid": "e5053a88c78d7274fcbdf6ff3900637e65810401", "_cell_guid": "2802631d-eb3b-4cff-9baa-e4f799abd83c"}}, {"outputs": [], "metadata": {"scrolled": true, "_uuid": "db3dccd4eb512ce159e004c03e32a15ee4cb5180", "_cell_guid": "fab34080-7516-4cda-a221-11ca381f4bf8"}, "cell_type": "code", "source": ["X.head()"], "execution_count": 39}, {"cell_type": "markdown", "source": ["---\n", "## Making predictions\n", "Let's separate the dataset between training set and test set."], "metadata": {"_uuid": "8021dab371f5f7cc66c2e851fe47b23a0f863e3d", "_cell_guid": "a0fab143-0259-4a42-bf3c-dc8fddc70109"}}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "8ecf8ad7cb796ef33d4321f77471bfc14503ced4", "_cell_guid": "625c321c-f4e4-423f-ba7c-5659335e3bfb"}, "cell_type": "code", "source": ["from sklearn.model_selection import train_test_split, GridSearchCV\n", "from sklearn.metrics import make_scorer"], "execution_count": 40}, {"outputs": [], "metadata": {"_uuid": "226d8bb82ec835f4003d6296d87ac67318a74c8c", "_cell_guid": "d63f2c72-2196-4e1f-92cf-bf2cfb4b4099"}, "cell_type": "code", "source": ["X_train, X_test = X[:891], X[891:]\n", "print('train size: {0}; test size: {1}'.format(len(X_train), len(X_test)))"], "execution_count": 41}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "eb3eb0c8b86e6f8c2575a4f9a1dfd646057465cd", "_cell_guid": "6bd3ace4-2009-4955-82c1-8a323c2591e8"}, "cell_type": "code", "source": ["xtrain, xtest, ytrain, ytest = train_test_split(X_train, y)"], "execution_count": 42}, {"outputs": [], "metadata": {"_uuid": "be58940b9daf656d155cc8aad89c26e66af03f5f", "_cell_guid": "5120ef6d-ade4-47ec-9fdf-b7c694c72642"}, "cell_type": "code", "source": ["clf = RandomForestClassifier()\n", "clf.fit(xtrain, ytrain)\n", "pred = clf.predict(xtest)\n", "accuracy_score(y_pred=pred, y_true=ytest)"], "execution_count": 43}, {"cell_type": "markdown", "source": ["Without any hyperparameter tuning, the classifier with standard parameters scored an accuracy of 0.8161. <br />\n", "Let's try to improve this score.\n", "## Tuning hyperparameters"], "metadata": {"_uuid": "5c40c2d1c0f2b22d65c14344896be714ff2c7779", "_cell_guid": "61cebcc6-c735-47c2-babe-9e67c36d527e"}}, {"outputs": [], "metadata": {"_uuid": "9a73065b89e58f31209f6202eef03ad997bf32bc", "_cell_guid": "28c7cabd-0ec5-4355-8eb1-59a5ff0ab845"}, "cell_type": "code", "source": ["parameter_candidates = [\n", "  {'n_estimators': [5, 10, 14, 15, 16, 20], 'criterion': ['gini', 'entropy'], \\\n", "   'random_state':[0], \\\n", "   'bootstrap':[True], \\\n", "   'min_samples_split':[2, 4, 6, 8], 'min_samples_leaf':[1, 2, 4, 6, 8], \\\n", "   'max_depth':[2, 4, 5, 6, 8, None], 'warm_start':[True, False]},\n", "\n", "  {'n_estimators': [5, 10, 14, 15, 16, 20], 'criterion': ['gini', 'entropy'], \\\n", "   'random_state':[0], \\\n", "   'bootstrap':[False],\\\n", "   'min_samples_split':[2, 4, 6, 8], 'min_samples_leaf':[1, 2, 4, 6, 8], \\\n", "   'max_depth':[2, 4, 5, 6, 8, None],'warm_start':[True, False]}\n", "]"], "execution_count": 54}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "40fc97d735a15954792b0c4005c8b5757b0933e4", "_cell_guid": "cb87316c-e530-4a30-a01c-62f055e57318"}, "cell_type": "code", "source": ["clf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=parameter_candidates, n_jobs=4, scoring=make_scorer(accuracy_score))"], "execution_count": 55}, {"outputs": [], "metadata": {"scrolled": false, "_uuid": "a3d3b23b25981c8b6266bbf7f53ec7f89739f68a", "_cell_guid": "78aff257-af88-460d-9bd1-c60d124820b1"}, "cell_type": "code", "source": ["clf.fit(xtrain, ytrain)"], "execution_count": 56}, {"outputs": [], "metadata": {"scrolled": false, "_uuid": "3c355720facb4b080031a52f1b1b098964704dfc", "_cell_guid": "bc0281c4-df28-4ed0-b04f-81c1144b1df6"}, "cell_type": "code", "source": ["clf.best_estimator_"], "execution_count": 57}, {"outputs": [], "metadata": {"_uuid": "1a8575d99bd28434f1b222972f981576521ae9b0", "_cell_guid": "4aeb0268-bb24-4dfd-81ac-1fd099b31632"}, "cell_type": "code", "source": ["pred = clf.predict(xtest)\n", "accuracy_score(y_pred=pred, y_true=ytest)"], "execution_count": 58}, {"cell_type": "markdown", "source": ["## Conclusion\n", "After tuning the hyperparameters, the new classifier improved to a score of 0.820. <br />\n", "\n", "No tuning:\n", " * 0.816\n", " * Submission score: 0.72727\n", "\n", "Tuning:\n", " * 0.829\n", " * Submission score: 0.76555"], "metadata": {"_uuid": "6345ca6a335ee26958967c418cdc94e7a6361bcb", "_cell_guid": "660ad6d4-296e-476f-b028-8f5a49fa5cd5"}}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "ddb0c5e0d0bd3c03ac054aa1663a5ffa59ea618b", "_cell_guid": "33580f5b-c40e-4cb7-afe8-34086b42fcdd"}, "cell_type": "code", "source": ["# making the submission\n", "passengerId = np.arange(892, 1310)\n", "\n", "pred = clf.predict(X_test)\n", "\n", "submission = pd.DataFrame({'PassengerId':passengerId, 'Survived':pred}) \n", "submission.to_csv(\"submission.csv\", index=False)"], "execution_count": 59}], "nbformat_minor": 1, "metadata": {"language_info": {"pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "file_extension": ".py", "nbconvert_exporter": "python", "name": "python", "version": "3.6.3"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "varInspector": {"window_display": false, "types_to_exclude": ["module", "function", "builtin_function_or_method", "instance", "_Feature"], "position": {"width": "673px", "height": "247px", "left": "1387px", "right": "20px", "top": "102px"}, "cols": {"lenType": 16, "lenName": 16, "lenVar": 40}, "kernels_config": {"python": {"delete_cmd_postfix": "", "library": "var_list.py", "varRefreshCmd": "print(var_dic_list())", "delete_cmd_prefix": "del "}, "r": {"delete_cmd_postfix": ") ", "library": "var_list.r", "varRefreshCmd": "cat(var_dic_list()) ", "delete_cmd_prefix": "rm("}}}}}