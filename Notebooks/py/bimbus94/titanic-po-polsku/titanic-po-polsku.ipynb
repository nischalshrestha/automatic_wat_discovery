{"cells":[{"metadata":{"_uuid":"6973d355422340f99e6bb8ca9442503350a7bfd5"},"cell_type":"markdown","source":"# 0. Wstep\nNotebook stanowi mój pierwszy własny projekt na Kaggle oprócz tutorialu z ML.\nDotyczy on oczywiście wszystkim znanego zadania Titanica na Kagglu, a więc przewidzenia czy pasażer przeżyje lub czy zginie podczas katastrofy na Titanicu, który zatonął w 1912 roku, w zależności od różnych cech, które zostaną omówione w kolejnym punkcie. Źródła, na których bazowałem podałem na końcu notebooka.\n\n### Spis treści:\n1. Wczytanie danych i wstępny ich przegląd\n2. Oczyszczenie danych, wstępna wizualizacja i wstępny Feature Engineering\n3. Sprawdzenie zależności między zmiennymi\n4. Wstępny model, cross-validation, krzywe uczenia (learning_curves), porównanie różnych modeli i wybór jednego (XGBoosta)\n5. Feature Importance - sprawdzenie jak poszczególne cechy wpływają na wynik, odrzucenie zbędnych\n6. Próba tuningu parametrów XGBoosta z użyciem GridSearchCV\n7. Wnioski\n\n### Stosowane rozwiązania:\nW notebooku przedstawiono różne operacje na danych z pomocą Pandasa, wizualizacje z pomocą Matplotlib oraz Seaborn, liczne operacje z użyciem Sklearn: imputacje pustych danych, normalizacje, skalowanie danych, tworzenie modeli ML, tworzenie cross-validation, operanie i analiza krzywych uczenia,dobór i odrzucenie zmiennych z użyciem feature importance, sprawdzanie ich zależnośći między sobą (heatmapy) oraz ich wpływ na wynik ,modelowanie z użyciem XGBoosta,  próba optymalizacji i  tuning jego parametrów z użyciem GridSeachCV.\n\n### Źródła poza stackoverflow, dokumentacji bibliotek:\n* https://alexiej.github.io/kaggle-titanic/\n* https://machinelearningmastery.com\n* https://github.com/dataworkshop/webinar-titanic\n"},{"metadata":{"_uuid":"80d03626b9031b2a034fc54d0d8f82904bf8747d"},"cell_type":"markdown","source":"# 1 .Wczytanie danych i wstępny ich przegląd i wizualizacja"},{"metadata":{"_uuid":"ec197b52c4373c908755ae84541347f744214054"},"cell_type":"markdown","source":"## 1.1 Import niezbędnych modułów"},{"metadata":{"trusted":true,"_uuid":"a9c9b49ee06a2920b1b52b69243258dea039068f","collapsed":true},"cell_type":"code","source":"import numpy as np #do roznych obliczen\nimport pandas as pd #do operacji na danych\nimport matplotlib.pyplot as plt #do wykresow\nimport seaborn as sns #do jeszcze ladniejszych wykresow\n%matplotlib inline \npd.set_option('display.max_columns', 500)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"## 1.2 Wczytanie danych i złączenie zbiorów"},{"metadata":{"trusted":true,"_uuid":"3e79890a4eac8c45e21c611fbbd6704a43aebca4","collapsed":true},"cell_type":"code","source":"#Wczytujemy dane treningowe i testowe w postaci *.csv.\n#header=0 - informuje, gdzie znajduje się wiersz z nazwami kolumn\n#index_col=0 - informuje, gdzie znajduje się kolumna, po której indeksujemy nasz zbiór\ndf_train = pd.read_csv('../input/train.csv', header=0,index_col=0)\ndf_test = pd.read_csv('../input/test.csv', header=0,index_col=0)\n\n#Polaczenie zbioru treningowego z testowym, by mozna je bylo razem modyfikowac\ndf_all=pd.concat([df_train, df_test], sort=False)\n\n#Nadanie nazw dataframe'om\ndf_train.name='Train Dataset'\ndf_all.name='All Dataset'\ndf_test.name='Test Dataset'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"## 1.3 Wstępny przegląd danych\nPrzyjżyjmy się teraz co zawiera nasz zbiór. Głównym celem jest przewidzenie wartości wartości zmiennej Survival, a więc informacji czy pasażer przeżył, czy też nie, przy użyciu 9-ciu pozostałych zmiennych (predyktorów), które zostały opisane poniżej:\n\n<br>-PassengerID - unikalny numer pasażera\n<br>-Survival - informacja czy dany pasażer przeżył katastrofę, czy też nie. 0 - Nie, 1 - Tak\n<br>-Pclass – klasa | (1 = pierwsza; 2 = druga; 3 = trzecia).\n<br>-Name – imię i nazwisko pasażera.\n<br>-Sex – płeć pasażera.\n<br>-Sibsp – liczba małżonków, lub rodzeństwa na pokładzie.\n<br>-Parch – liczba rodziców, lub dzieci na pokładzie.\n<br>-Ticket – numer biletu.\n<br>-Fare – opłata za bilet.\n<br>-Cabin – kabina.\n<br>-Embarked – port startowy (C = Cherbourg; Q = Queenstown; S = Southampton).\n"},{"metadata":{"_uuid":"95e27c5a68e8bf2f83b11bdbad93799119c96835"},"cell_type":"markdown","source":"### Wyświetlmy teraz podstawowe informacje o datasetcie\n- Przykładowy sampel z 3 wierszami, by zapoznać się z wyglądem datasetu (df.sample(3))\n- Zestawienie typów danych zbioru wraz z nazwami kolumn oraz liczbą wystąpień (df.info())\n- Wymiary datasetu (df.shape)\n- Zestawienie braków w danych (df.isnull().sum())"},{"metadata":{"trusted":true,"_uuid":"079c4c306974a1be694397ac3e094ed84fb60e52","collapsed":true},"cell_type":"code","source":"#Funkcja ulatwiajaca wyswietlanie informacji o zbiorze w konsoli\ndef print_some_info(df):\n    '''Funkcja do wyswietlania informacji o datasecie w formie zbiorczej'''\n    \n    names_print=['Przykladowy sampel', 'Zestawienie nazw kolumn, liczby wystapien i typow danych', 'Wymiar datasetu',\n                 'Brak danych w poszczegolnych kolumnach']\n    n_len=[int((100-len(name))/2) for name in names_print ]\n    \n    print('\\n \\n Zestawienie dla datasetu: '+ '*'*len(df.name) + df.name  + '*'*len(df.name) )\n    \n    print('\\n'+'~'*n_len[0] + names_print[0]  + '~'*n_len[0]+'\\n')\n    print(df.sample(4))\n    print('\\n'+'~'*n_len[1] + names_print[1]  + '~'*n_len[1]+'\\n')\n    print(df.info())\n    print('\\n'+'~'*n_len[2] + names_print[2]  + '~'*n_len[2]+'\\n')\n    print(df.shape)\n    print('\\n'+'~'*n_len[3] + names_print[3]  + '~'*n_len[3]+'\\n')\n    print(df.isnull().sum())\ndf_all.describe\n\n#Wywolanie funkcji dla datesetow\nprint_some_info(df_all)\nprint_some_info(df_train)\nprint_some_info(df_test)\n\n#Inne przydatne funkcje do wstepnej analizy zbioru:\n#df.head(n) #pokazuje n pierwszych wierszy df\n#df.tail(n) #pokazuje n ostatnich wierszy df\n#df.describe() #opis statystyczny\n#df[-5:], df[:10] #filtrowanie po wierszach (5 ostatnich, 10 pierwszych)\n#df[[\"Age\",\"Pclass\"]][5:30] #filtrowanie po wierszach z wyborem kolumn\n#df[(df['Age'] > 5.0) & (df['Age'] < 7.0 ) ] #filtorwanie po kolumnie\n#df[(df['Cabin'].str.contains('B2',na=False)) ] #flitrowanie po tekscie\n#df[df['Embarked'].isnull()] #filtrowanie po pustych wartosciach\n#df.select_dtypes(include=[np.int, np.float]).head() #flitrowanie po typie danych\n#df.groupby(['Pclass','Sex'])['Survived'].sum() # grupowanie po kategorii","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2c26246a41c0e68641da12216167dc65a5af79da"},"cell_type":"markdown","source":"## Po wstępnej analizie można zauważyć, że:\n1.  W zbiorze treningowym brakuje większości (687 z 891) wartości dotyczących zmiennej Cabin (nr kabiny), ale za pewien substytut można informację o klasie Pclass. I zmienną Cabin trzeba będzie usunąć.\n2. Brakuje także części informacji o wieku (dla zbioru treningowego 177 z 891), które trzeba będzie imputować.\n3. Brakuje pojedynczych danych dla zmiennych Ebarked i Fare.\n4.  Zbiór treningowy zawiera kompletne informacja o zmiennej wynikowej (czy ktoś przeżył, czy nie) - Survived, więc nie będzie trzeba wyrzucać wierszy ze zbioru.\n5. Zmienne Sex, Embarked to zmienne kategoryczne i trzeba będzie je odpowiednio zakodować.\n6. Zmienne Age, Fare podane są jako liczby zmiennoprzecinkowy (float64), ale dla późniejszych obliczeń zapewne będzie stworzyć także z nich zmienne kategoryczne i zakodować.\n"},{"metadata":{"_uuid":"c9bf9f3e80e76d9a174d16a4cd2fdcac6672f943"},"cell_type":"markdown","source":"# 2.Oczyszczenie danych, wstępna wizualizacja i wstępny Feature Engineering\nW kolejnym rozdziale przyjżymy się każdej zmiennej, która jest używana do predykcji. Przeprowadzimy wstępną wizualizację, interpretację zmiennej, oczyścimy dane, przeprowadzimy kategoryzację, encoding, odrzucimy zbędne zmienne i przeprowadzimy wstępny Feature Engineering."},{"metadata":{"_uuid":"3184aefd21ed935ace31e870f857a854ac213c3d"},"cell_type":"markdown","source":"## 2.1 Sex - płeć pasażera\nW poniższym podrozdziale przeprowadzono następujące czynności:\n* Sprawdzono jak oznaczone są rodzaje płci i czy są to wartości unikalne, czy trzeba je modyfikować (df_all.Sex.unique())\n* Sprawdzono czy nie występują braki danych w kategorii płci (df_train.Sex.isnull().sum())\n* Sprawdzono liczbę mężczyzn i kobiet w całkowitym zbiorze oraz jaką liczbę ich uratowono (df_train.groupby(['Sex'])['Survived'].sum())\n* Wyplotowano wykres ze stosunkiem jaki udział mężczyzn i kobiet przeżył katastrofę za pomocą Seaborn\n* Podmieniono nazwy okręślające płcie na wartości całkowite (0 - mężczyzna, 1 - kobieta) (df.Sex.replace(['male', 'female'], [0, 1], inplace = True))\n"},{"metadata":{"trusted":true,"_uuid":"144bdfe0c753fc8de57f826c6c75361be122c363","collapsed":true},"cell_type":"code","source":"#Sprawdzam wartosci jakim zakodowana jest plec\nprint('~~~Unikalne wartosci dla kategorii Sex~~~')\nprint(df_all.Sex.unique())\nprint('\\n')\n\n#Sprawdzam czy nie ma brakujacych danych w zbiorze\nprint('~~~Ilosc pustych danych w zbiorze~~~')\nprint(df_train.Sex.isnull().sum())\nprint('\\n')\n\n#Sprawdzam liczbe mezczyzn i kobiet na statku (test+train)\nprint('~~~Liczba mezczyzn i kobiet na statku (test+train)~~~')\nprint(df_all.Sex.value_counts())\nprint('\\n')\n\n#Sprawdzam liczbe mezczyzn i kobiet na statku (tylko train)\nprint('~~~Liczba mezczyzn i kobiet na statku (train)~~~')\nprint(df_train.Sex.value_counts())\nprint('\\n')\n\n#Udzial kobiet i mezczyzn wsrod tych, ktorzy przetrwali\nprint('~~~Liczba mezczyzn i kobiet wsrod uratowanych~~~')\nprint(df_train.groupby(['Sex'])['Survived'].sum())\nprint('\\n')\n\n#Stosunek przezywalnosci kabiet i mezczyzn\nprint('~~~Stosunek przezywalnosc kobiet i mezczyzn~~~')\nprint(df_train.groupby(['Sex'])['Survived'].mean()*100)\nprint('\\n')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed259922d7798dff6d4c254e3deebe720aa0fb2a","_kg_hide-output":false,"collapsed":true},"cell_type":"code","source":"#Plotowanie wykresu z zaleznoscia przyzywalnosci od plci\nplt.figure(figsize=(4,4))\nsns.set_style(\"whitegrid\")\nax = sns.barplot(x=\"Sex\", y=\"Survived\", data=df_train).set(title = 'Stosunek przeżywalności w zależności od płci',\n                                                           xlabel = 'Płeć', ylabel = 'Stosunek przeżywalności',\n                                                           xticklabels=['Mężczyzna', 'Kobieta'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e4b7a9554cc9ddfc3398780efb18100527f61e6","collapsed":true},"cell_type":"code","source":"#Zastapienie nazw plci 'male' przez 0, 'female' przez 1\ndef replace_sex_names_with_code(df):\n    df.Sex.replace(['male', 'female'], [0, 1], inplace = True)\n    return (df)\n\nfor i in [df_all, df_train, df_test]:\n    replace_sex_names_with_code(i)\n\n#Inne sposoby zakodowania danych\n#df_train['_Sex'] = pd.Categorical(df_train.Sex).codes #utworzenie nowej kolumny z zakodowanymi plciami\n#sprawdz get_dummies()\n#dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n#df['sex_cat'] = pd.factorize( df['Sex'] )[0]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"_uuid":"d82b48335e527b95c6ac8a1e3162525d62337456"},"cell_type":"markdown","source":"### Wnioski z kategorii Sex (Płeć)\n* Zmienna płeć odgrywała dużą rolę, jeśli chodzi o przeżycie (Survived). Przeżyło ponad 74% kobiet i tylko niewiele ponad 18% mężczyzn.\n* Jest to istotna zmienna predykcyjna.\n* Wprowadzono encoding, przypisano wartość 0 dla 'male' (mężczyzny) i 1 - 'female' dla kobiety, by modele mogły działać na liczbach\n"},{"metadata":{"_uuid":"9bcf315e3a553d32565427ec72011c33c7cf1cbf"},"cell_type":"markdown","source":"## 2.2 Zmienna Pclass - Klasa, w której podróżował pasażer\n\nPrzebieg działania:\n* Sprawdzenie czy zmienna ma unikalne wartości, czy trzeba ją zakodować\n* Sprawdzenie czy nie ma braków danych\n* Sprawdzenie liczby pasażerów z poszczególnych klas\n* Sprawdzenie stosunku uratowanych w zależności od przynależności do danej klasy oraz płci (w konsoli oraz na wykresach)\n"},{"metadata":{"trusted":true,"_uuid":"1e4d829d2c4d50b9d44c7ca973d569c7a5d8fef9","collapsed":true},"cell_type":"code","source":"#Sprawdzam wartosci jakim zakodowana jest klasa\nprint('~~~Unikalne wartosci dla kategorii Pclass~~~')\nprint(df_all.Pclass.unique())\nprint('\\n')\n\n#Sprawdzam czy nie ma brakujacych danych w zbiorze\nprint('~~~Ilosc pustych danych w zbiorze~~~')\nprint(df_all.Pclass.isnull().sum())\nprint('\\n')\n\n#Liczba pasazerow poszczegolnych klas (zbior train)\nprint('~~~Liczba pasazerow w danej klasie (train)~~~')\nprint(df_train.Pclass.value_counts())\nprint('\\n')\n\n#Udzial poszczegolnych klas wsrod tych, ktorzy przetrwali\nprint('~~~Stosunek uratowanych z poszczegolnych klas~~~')\nprint(df_train.groupby(['Pclass'])['Survived'].mean()*100)\nprint('\\n')\n\n#Udzial poszczegolnych klas wsrod tych, ktorzy przetrwali z uwzglednieniem plci\nprint('~~~Stosunek uratowanych z poszczegolnych klas z uwzglednieniem plci~~~')\nprint(df_train.groupby(['Pclass', 'Sex'])['Survived'].mean()*100)\nprint('\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de7791c2fb518d9def12ff68e076c2b6170f9e59","collapsed":true},"cell_type":"code","source":"#Plotowanie wykresu z zaleznoscia przyzywalnosci od plci\nfig, ax =plt.subplots(1,2, figsize=(10,5))\n#fig(figsize=(4,4))\nsns.set_style(\"whitegrid\")\nsns.barplot(x=\"Pclass\", y=\"Survived\", data=df_train, ax=ax[0]).set(title = 'Stosunek przeżywalności w zależności klasy',\n                                                           xlabel = 'Klasa', ylabel = 'Stosunek przeżywalności')\nsns.barplot(x=\"Pclass\", y=\"Survived\",hue='Sex', data=df_train, ax=ax[1]).set(title = 'Stosunek przeżywalności w zależności klasy i płci',\n                                                           xlabel = 'Płeć i klasa', ylabel = 'Stosunek przeżywalności')\n                                                          ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96a498a5242d784d5041fd174382f409973cc4e4"},"cell_type":"markdown","source":"### Wnioski z analizy zmiennej Pclass\n* Klasa, w której znajdował się pasażer miała znaczny wpływ na szanse uratowania, im wyższa klasa tym większa była szansa (dla zbioru treningowego: 1-klasa 63% przeżyło, 2-klasa 47%, 3-klasa 24%).\n* Im wyższa była klasa tym mniej pasażerów się w niej znajdowało (dla zbioru treningowego)\n* Im wyższa była klasa tym większe szanse na przeżycie mieli także mężczyźni, ale wśród uratowanych dominowały kobiety (1-klasa - ponad 96% kobiet i 36% mężczyzn uratowanych, 2-klasa 92% uratowanych kobiet i tylko 15% mężczyzn, 3-klasa 50% kobiet i 13% mężczyzn uratowanych)\n* Zmienna stanowi ważny predyktor i nie może zostać pominięta.\n* W kolumnie Pclass nie było braków danych, a zmienne wyznaczone są przez liczby 1,2,3 i nie były już poddawne encodingowi."},{"metadata":{"_uuid":"4adaba8ea96c20a5f71a9503bbe6bbcab0e03d62"},"cell_type":"markdown","source":"## 2.3 Zmienna Name i pozyskanie Title"},{"metadata":{"_uuid":"b609e4b7eda553e554d946ae12e82493840c9f1e"},"cell_type":"markdown","source":"### Wstępny przegląd Name (imion i nazwisk)\n* Sprawdzenie czy nie ma braków danych\n* Czy wartości są unikalne\n* Sprawdzenie formy w jakiej występują dane Name"},{"metadata":{"trusted":true,"_uuid":"61a37b7c1ce4771b656b998fc8c2bee789dda8d5","collapsed":true},"cell_type":"code","source":"print('~~~Przykladowy wydruk zmiennej Name~~~')\nprint(df_all.Name.head(4))\nprint('\\n')\n\n#Liczba unikalnych wartosci\nprint('~~~Liczba unikalnych wartosci dla kategorii Age~~~')\nprint(df_all.Name.nunique())\nprint('\\n')\n\n#Powtarzajace sie wartosci\nprint('~~~Powtarzajace sie wartosci~~~')\nprint(df_all[df_all.Name.duplicated(keep=False)])\nprint('\\n')\n\n#Sprawdzam czy nie ma brakujacych danych w zbiorze\nprint('~~~Ilosc pustych danych w zbiorze Name~~~')\nprint(df_all.Name.isnull().sum())\nprint('\\n')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d766e21caf5fd1b1f1f01f0e3d59fc8a1a69a544"},"cell_type":"markdown","source":"#### Z wstępnego przeglądu zmiennej Name (imion i nazwisk) można wywnioskować, że:\n   * nie ma braków w danych\n   * tylko 2 imiona i nazwiska się powtarzają, ale są to różne osoby (inny wiek, inny nr biletu)\n   * pierwszy człon zmiennej Name to nazwisko, więc można jeszcze sprawdzić ilość osób o takim samym nazwisku, czy to rodzina\n   * drugi człon w Name (po przecinku) to tytuł, który może świadczyć o wieku, statusie osoby i wyciągniemy z niego kolejną zmienną (bazując na innych opracowaniach tego datasetu)\n    "},{"metadata":{"_uuid":"8dd28cd42fabbf8c21a37fe4898820d68bc7d3a6"},"cell_type":"markdown","source":"### Sprawdzenie osób o tym samym nazwisku (być może rodzin)\n* Sprawdzenie ile osób ma takie same nazwisko\n* Ile jest podzbiorów o konkretnej liczbie osób o takim samym nazwisku\n* Ilu z tych podgrup się uratowało\n* Jaki był wpływ powtarzalności nazwisk na szanse uratowania"},{"metadata":{"trusted":true,"_uuid":"34773936333ac33199b1a3e6f935bc880f22634c","collapsed":true},"cell_type":"code","source":"#Ze zbioru wyluskuje nazwiska (pierwszy czlon Name), oraz zapisuje je tylko za pomoca malych liter\n#by te same nazwiska nie byly traktowane jako rozne ze wzgledu na wielkosc liter\n#Nastepnie obliczam ile osob nosi takie samo nazwisko i drukuje przylad\nprint('\\n~~~Liczba o tym samym nazwisku (wydruk pierwszych 5)~~~')\nLastNameSum=df_train['Name'].map(lambda x: x.split(',')[0].lower()).value_counts().reset_index().rename(index=str, columns={\"index\": \"_Name\",\"Name\": \"counts\" })\nprint(LastNameSum.head(5))\n\n#Tworze nowa kolumne w DF o nazwie _Name, ktora przechowuje nazwiska pasazerow\ndf_train['_Name']=df_train['Name'].map(lambda x: x.split(',')[0].lower())\ndf_all['_Name']=df_all['Name'].map(lambda x: x.split(',')[0].lower())\n\n#Sprawdzam ile jest podzbiorow o danej liczbie osob, ktore tworza pseudo-rodzine (maja takie samo nazwisko), \n#ile jest pseudo-rodzin o liczbie czlonkow 9,8,7, etc.\nprint('\\n~~~Liczba osob o takim samym nazwisku | Liczba takich przypadkow~~~')\nprint(LastNameSum['counts'].value_counts())\n\n#Tworze zestawienie ilosci osob o takim samym nazwisku i ile osob przetrwalo\nLastNameSum=LastNameSum.sort_values('_Name').reset_index().set_index('_Name')\nLastNameSurvivedSum=df_train.groupby(['_Name'])['Survived'].sum().reset_index()\nLastNameSurvivedSum=LastNameSurvivedSum.sort_values('_Name').reset_index().set_index('_Name')\nLastNameResult = pd.concat([LastNameSum['counts'], LastNameSurvivedSum['Survived']], axis=1, join_axes=[LastNameSum.index]).sort_values('counts', ascending=False)\nprint('\\n~~~Liczba o tym samym nazwisku | Liczba tych co przetrwali (wydruk pierwszych 5)~~~~~~')\nprint(LastNameResult.head(5))\n\n#Tworze zestawienie ile osob jest w pozbiorze o danej wielkosci grupy (liczbie osob o tym samym nazwisku), ile z tych osob przetrwalo\nSurvivedDependLastNameSizeGroup=LastNameResult.groupby(['counts'])['Survived'].sum()\nPeopleNumberDependLastNameSizeGroup=LastNameResult.sort_values('counts')\nPeopleNumberDependLastNameSizeGroup=LastNameResult['counts'].value_counts(sort=False)\nPeopleNumberDependLastNameSizeGroup=PeopleNumberDependLastNameSizeGroup.index*PeopleNumberDependLastNameSizeGroup\nSurvivedPercent=SurvivedDependLastNameSizeGroup/PeopleNumberDependLastNameSizeGroup*100\nLastNameResultWithNumbers = pd.concat([PeopleNumberDependLastNameSizeGroup, SurvivedDependLastNameSizeGroup, SurvivedPercent], axis=1, join_axes=[PeopleNumberDependLastNameSizeGroup.index]).rename(index=str, columns={0: \"All\",1: \"Survived [%]\" })\nprint('\\n~~~Rozmiar grupy o tym samym nazwisku | Wszyscy  | Uratowani | Uratowani w [%]~~~~~~')\nprint(LastNameResultWithNumbers)\n\n#Wykres rozkladu ilosci wszystkich pasazerow oraz tych co przetrwali w zaleznosci ile osob mialo takie samo nazwisko\nax=LastNameResultWithNumbers.plot(kind='bar',y=['All', 'Survived'], label=['Wszyscy', 'Uratowani'])\nplt.legend()\nax.set_xlabel('Liczba osob o takim samym nazwisku')\nax.set_ylabel('Suma osob')\nax.set_title('Rozklad liczby pasazerow o takim samym nazwisku')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c477a2c3a5300222f55f433bafd94fcafecaea4c"},"cell_type":"markdown","source":" #### Z przeglądu nazwisk widoczne jest:\n* Największy udział pasażerów stanowiły osoby, które miały unikalne nazwisko, nie było na pokładzie nikogo innego o takim samym nazwisku. Być może podróżowały same lub  ich rodzina nosiła inne nazwisko. Wśród nich przetrwało około 36%.\n* Największe szanse na przeżycie miały osoby należące do grupy 2-osobowej (52%). Można przypuszczać, że były to małżeństwa, a taki duży  procent uratowanych wynikał ze względu na liczbę uratowanych kobiet.\n* Można zauważyć tendencję (z wyjątkiem grupy 6 osobowej), że im większa liczba osób o takim samym nazwisku, tym mniej było takim osób.\n* Dalsza analiza i tworzenie nowych zmiennych z nazwisk nie będzie prowadzone, bo wiem należało, by sprawdzić, czy osoby były spokrewnione, a ta niejako zawiera się już w zmiennej SibSig, więc dublowalibyśmy dane, także należałoby sprawdzić płeć, a tu dublowalibyśmy zmienną Sex. Analizę przeprowadzono tylko poglądowo i nie będzie dalej używana zmienna z zestawieniem nazwisk.\n"},{"metadata":{"_uuid":"82b8d63803c7639397a0832fd6b1c6144a3dfacf"},"cell_type":"markdown","source":"### Pozyskanie tytułów (Title) z Name, wykorzystanie paternów\n* Pozyskanie tytułów z zmiennej Name\n* Obliczenie średniego wieku dla danego tytułu\n* Sprawdzenie szans na przeżycie w zależności od tytułu\n* Encoding"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"4cc68ff71b4873c27397d3d085b4d46edc8b931b","collapsed":true},"cell_type":"code","source":"#Sprawdzenie liczebnosci osob o konkretnym tytule\ndf_all['_Title']=df_all['Name'].map(lambda x: x.split(', ')[1].split('.')[0].lower() )\nprint('\\n~~~Ilosc osob o danym tytule~~~')\nprint(df_all['_Title'].value_counts())\n\n#Sprawdzenie rozkladu wieku w zaleznosci od tytuly\nprint('\\n~~~Tytul|Srednia|Mediana|Min|Max wieku w zaleznosci od tytulu~~~')\nprint(df_all.groupby('_Title')['Age'].agg([np.mean, np.median, np.min, np.max]))\n\n#Agregacja tytulow i ich zakodowanie\npopular_titles = [\"mr\", \"miss\", \"mrs\", \"master\", \"dr\", \"rev\"]\ndf_all['Title'] = df_all['_Title'].map(lambda x: x if x in popular_titles else \"other\")\ndf_all['Title_encoded'] = pd.factorize( df_all['Title'] )[0]\nprint('\\n~~~Ilosc osob o danym tytule po agregacji~~~')\nprint(df_all['Title'].value_counts())\n\n#Rozklad wieku po agregacji, zebranie mediany wieku, by uzupelnic puste pola w wieku\nprint('\\n~~~Tytul|Srednia|Mediana|Min|Max wieku w zaleznosci od tytulu~~~')\nprint(df_all.groupby('Title')['Age'].agg([np.mean, np.median, np.min, np.max]))\nmissing_ages=df_all.groupby('Title')['Age'].agg([np.mean, np.median, np.min, np.max]).to_dict()['median']\n\n#Sprawdzenie szans przezycia w zaleznosci od tytulu\nprint('\\n~~~Szansa przezycia w zaleznosci od tytulu~~~')\nprint(df_all.groupby('Title')['Survived'].agg([np.mean]))\n\n#Alternatywny sposob wyznaczenie tytulow\n#pat = r\",\\s([^ .]+)\\.?\\s+\"\n#df_all['Title'] =  df_all['Name'].str.extract(pat,expand=True)[0]\n#df_all.groupby('Title')['Title'].count()\n#df_all.loc[df_all['Title'].isin(['Mille','Ms','Lady']),'Title'] = 'Miss'\n#df_all.loc[df_all['Title'].isin(['Mme','Sir']),'Title'] = 'Mrs'\n#df_all.loc[~df_all['Title'].isin(['Miss','Master','Mr','Mrs']),'Title'] = 'Other' # NOT IN\n#df_all['_Title'] = pd.Categorical(df_all.Title).codes\n#df_all.groupby('Title')['Title'].count()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a5135e6dbe81c2748b0fe11630978016e1bbb45"},"cell_type":"markdown","source":"#### Wnioski po analizie tytułów:\n* dominujące tytuły to Mr, Miss, Mrs, Master oraz kilka osób z tytułem Rev, Dr i tylko te tytuły uwzględniamy bez zmian, bo pozostałe występują pojedynczo lub po dwa i podlegają agreacji w grupę other\n* widoczny jest duży rozrzut w wieku dla większości grup\n* Dr - zazwyczaj mężczyzna w sile wieku około 50tki, ale najmłodszy w tej grupie ma tylko 23 lata\n* Master - chłopiec, grupa o medianie równej 4 lata, ale najstarszy ma ponad 14 lat, a najmłodszy jest 4 miesięcznym noworodkiem\n* Miss - określenie panny (?), ale też jako małej dziewczynki, jak i kobiety w podeszłym wieku, mediana wieku 22lata, ale zakres wieku od noworodka (2 miesiące) do starszej kobiety (63lata)\n* Mr - określenie mężczyzny, mediana 29 lat, najmniej 11lat, najwięcej 80lat\n* Mrs - określenie kobiety, mediana 35.5 lat, najmniej 14 lat, nawięcej 76\n* Rev - osoba w średnim wieku, mediana 41.5, najmniej 27, najwięcej 57'\n* Po raz kolejny widoczne, że bycie kobietą gwarantowało dużo większe szanse na przeżycie, bo posiadaczki tytułów Miss oraz Mrs miały odpowiednio prawie 70% oraz ponad 79% szans na przeżycie, duże szanse mieli też mali chłopcy - Master - 58% szans. Najmniej mieli posiadacze tytuły Rev (?) 0% oraz mężczyźni - Master - około 16%\n* Dodatko zebrano mediane wieku, dla tytułu, by uzupełnić brakujące informacje o wieku"},{"metadata":{"_uuid":"53e8ac722b0f3350c21f6a199a834930ee63fb75"},"cell_type":"markdown","source":"## 2.4 Zmienna Age - Wiek\n### Wstępny przegląd"},{"metadata":{"trusted":true,"_uuid":"69030aef48d36119c3a996e7c5ce165a873e1adc","collapsed":true},"cell_type":"code","source":"#Sprawdzam wartosci jakim zakodowana jest klasa\nprint('~~~Unikalne wartosci dla kategorii Age~~~')\nprint(df_all.Age.unique())\nprint('\\n')\n\n#Liczba unikalnych wartosci\nprint('~~~Liczba unikalnych wartosci dla kategorii Age~~~')\nprint(df_all.Age.nunique())\nprint('\\n')\n\n\n#Sprawdzam czy nie ma brakujacych danych w zbiorze\nprint('~~~Ilosc pustych danych w zbiorze Age~~~')\nprint(df_all.Age.isnull().sum())\nprint('\\n')\n\n#Statystyka opisowa \nprint('~~~Statystyka opisowa wieku (Age)~~~')\nprint(df_all.Age.describe())\nprint('\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80a429fd164685551d5b4aa2ba62ae6e9376b291","collapsed":true},"cell_type":"code","source":"#Wyplotowanie histogramu z podzialem na 30 zakresow\nfig, ax=plt.subplots()\nplt_all=plt.hist(df_all['Age'],bins = 30,  range = [0,100],label='Wszyscy')\nplt_survived=plt.hist(df_all[df_all['Survived']==1]['Age'], bins=30, range=[0,100], label='Uratowani')\nplt.legend()\nax.set_xlabel('Wiek')\nax.set_ylabel('Liczba pasazerow')\nax.set_title('Rozklad wieku pasazerow')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08a7de64e71b426a19af0d5d29d78473a00e60ca","collapsed":true},"cell_type":"markdown","source":"### Z wstępnego przeglądu zmiennej Age - wieku:\n* widoczne są znaczne braki w miejscach określających wiek, dlatego konieczne będzie uzupełnienie braków.\n* wartości wieku wyrażone są jako liczby zmiennoprzecinkowe z dokładnośią do 2 miejsc po przecinku oraz występuje prawie 100 różnorodnych wartości. Taki zbiór nie nadaje się do przeprowadzenia treningu. \n* najliczniejszą grupę stanowiły osoby w wieku 20-40 lat i także śmiertelność w tej grupie była największa\n* pojedyncze osoby o wieku powyżej 60 lat, które mogą zaburzać predykcję\n* konieczny podział osób na kilka zakodowanych grup wiekowych"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2a86a9a2b7bd83268ae5b611ff0c4f70d3f72af4"},"cell_type":"markdown","source":"### Uzupełnienie braków w wieku\nWykrzystuje mediane wieku dla danego tytułu"},{"metadata":{"trusted":true,"_uuid":"c1ed66ea4648d8c699c9204822065733318e0772","collapsed":true},"cell_type":"code","source":"#Uzupelniam puste miejsca wiekiem z tytulow\ndf_all['Age'] = df_all.apply( lambda x: x['Age'] if str(x['Age']) != 'nan' else missing_ages[x['Title']], axis=1 )\nprint('\\n~~~Puste miejsca po imputacji w zmiennej Age~~~')\nprint(df_all.Age.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ddab9e0d806f2a4213cf75661b54bacd01edd05c"},"cell_type":"markdown","source":"### Podzial wieku na mniejsze podbiory i zakodowanie\nDzielę zbiór na przedziały wiekowe:\n* 0-3lat\n* 3-8lat\n* 8-15 lat\n* 14-20lat\n* 20-40lat\n* 40-60lat\n* 60-100lat\n<br>Następnie robię encoding grup wiekowych\n"},{"metadata":{"trusted":true,"_uuid":"06a264eb9b40754e61e60ee092690fdd5ca6a127","collapsed":true},"cell_type":"code","source":"#Podzial wieku na podzbiory do ciecia\nage_bins = [0,1, 3, 8, 15, 20,30, 40,60, 100]\ndf_all['Age_cut']=pd.cut(df_all[\"Age\"], bins=age_bins)\n\n#Ilosc osob w danym przedziale wiekowym\nprint('\\n~~~Ilosc osob w danym przedziale wiekowym~~~')\nprint(df_all['Age_cut'].value_counts())\n\n#Szansa przezycia od przedzialu wiekowego\nprint('\\n~~~Szansa przezycia w zaleznosci od przedzialu wieku~~~')\nprint(df_all.groupby('Age_cut')['Survived'].agg(np.mean))\n\n#Encoding grup wiekowych\nage_bins = [0,1, 2,3, 5,8,12, 15,18, 20,25,30,35, 40,50,60, 100]\ndf_all['Age_cut']=pd.cut(df_all[\"Age\"], bins=age_bins)\ndf_all['Age_encoded'] = pd.factorize( df_all['Age_cut'] )[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6bdab1a1b5e39a8822fb9f0976584e4d7487ef97"},"cell_type":"markdown","source":"#### Wnioski z dalszej analizy wieku z podziałem na podzbiory\n* największe szanse na przeżycie miały noworodki 0-1, a później dzieci 3-8 lat\n* najmniejsze szanse mieli ludzie w sile wieku 20-30lat oraz staruszkowie 60-100lat"},{"metadata":{"_uuid":"6cb40af73dcefd6fb0a5396bae1aad96b942bb7a"},"cell_type":"markdown","source":"## 2.5 Sibsp & Parch – liczba małżonków, lub rodzeństwa na pokładzie oraz liczba dzieci/rodziców na pokładzie posłuży wyznaczenie wielkości rodziny Family_size oraz zmiennej IsAlone\n* Na początku sprawdziliśmy, że nie brakuje danych w zmiennych Sibsp oraz Parch, dlatego pominiemy ten pkt\n* Z zmiennej Sibsp i Parch tworzymy zmienną Familiy_size informującą o wielkości rodziny bez uwzględnienia samego pasażera\nFamily_size=Sibsp+Parch\n"},{"metadata":{"trusted":true,"_uuid":"6a50f89d69b90f44c1a0c88791a3de644cb8e9cb","collapsed":true},"cell_type":"code","source":"#Utworzenie nowej zmiennej Family_size\ndf_all['Family_size']=df_all['SibSp']+df_all['Parch']+1\n\nprint('\\n~~~Wielkosc rodziny | Liczba pasazerow~~~')\nprint(df_all.Family_size.value_counts())\n\nprint('\\n~~~Wielkosc rodziny | Szanse na przezycie~~~')\nprint(df_all.groupby('Family_size')['Survived'].mean())\n\n#Utworzenie zmiennej IsAlone informujacej czy pasazer podrozowal sam\ndf_all['IsAlone']=df_all.apply(lambda x: 1 if x['Family_size']==1 else 0, axis=1)\n\nprint('\\n~~~Zaleznosc miedzy podrozowaniem samemu a przezyciem')\nprint(df_all.groupby('IsAlone')['Survived'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d22d44a2783b4770c1e23202b03a9b823c083fc2"},"cell_type":"markdown","source":"### Wnioski z przegladu wielkosci rodziny:\n* najwięcej osób podróżowało samotnie i miało około 30% szans na przeżycie\n* podróżujący rodziną mieli 50% szans na przeżycie\n"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6c4d0adcc0b1c42553e6a317c591e2ab32c0af31"},"cell_type":"markdown","source":"## 2.6 Fare - opłata za bilety\n* statyska opisowa cen biletów\n* przegląd brakujących danych Fare, opis osoby, dla której brakuje tych informacji\n* na podstawie zmiennych Pclass, Age, Embarked ( i osób o podobnych wartościach w tych zmiennych) oszacowanie brakujacej ceny biletu\n* histogram z rozkładem cen biletów"},{"metadata":{"trusted":true,"_uuid":"48994bdeab6e0212873091f7f9bb106b8c763c59","collapsed":true},"cell_type":"code","source":"print('\\n~~~Satystyka opisowa - Fare - Cena biletu~~~')\nprint(df_all.Fare.describe())\n\n#Wydrukowanie informacji o osobie, ktorej ceny biletu brakuje\nprint('\\n~~~Wiersz, w ktorym brakuje ceny biletu~~~')\nprint(df_all[df_all.Fare.isnull()][['Name', 'Pclass', 'Age', 'Embarked']])\n\n#Pozyskanie wartosci klasy, zaokretowania i oplaty\n#missPclass=df_all.loc[df_all.Fare.isnull(), 'Pclass'].values\n#missEmbarked=df_all.loc[df_all.Fare.isnull(), 'Embarked'].values\n#missFare_Age=df_all.loc[df_all.Fare.isnull(), 'Age'].values\n\n#Ceny biletow pasazerow o podobnej specyfice to tego, ktorego ceny brakuje\nprint('\\n~~~Sprawdzenie cen biletow pasazerow w podobnym wieku, klasie i zaokretowaniu~~~')\nval = df_all[(df_all['Pclass'] == 3)&(df_all['Embarked'] == 'S')&(df_all['Age'] > 60.5)][['Age','Fare']];\nprint(val.groupby('Age').agg(['min','max','count','mean','median']))\n\n#Obliczenie sredniej ceny biletow dla osob o podobnej specyfice do brakujacej\nval_mean=val.groupby('Age').agg(np.mean).mean()\nprint('\\n~~~Srednia cena biletu osob o podobnej specyfice={}'.format(val_mean.values))\n\n#Uzupelnieni pustych miejsc\ndf_all.loc[df_all.Fare.isnull(),'Fare']=val_mean.values\n\n\n#Wstawienie danych w konkretnym miejscu\n#df_all.at[1044,'Fare']=val_mean.values\n#df_all['Fare']=df_all.apply(lambda x: x['Fare'] if str(x['Fare']) != 'nan' else val_mean.values, axis=1 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9c334383eec83cad3e2d485117250f9e1b657400"},"cell_type":"markdown","source":"### Dalej przyjżymy się zmiennej Fare:\n* sprawdzimy rozkład Fare\n* zależność między Fare, a innymi zmiennymi\n* wpływ wartości Fare na szansę na przetrwanie (Survived)\n* przeprowadzimy normalizację zmiennej Fare"},{"metadata":{"trusted":true,"_uuid":"d48f13078edfcbde4c9da1f13071c4b578eb783d","collapsed":true},"cell_type":"code","source":"# Skalowanie Fare\nfrom sklearn import preprocessing\ndf_all['_Fare'] = preprocessing.scale(df_all[['Fare']])[:,0]\n#df_all['_Fare'] = preprocessing.normalize(df_all[['Fare']], norm='l2')\n\n#Wyplotowanie histogramu z Fare przed skalowaniem z podzialem na 100 zakresow\nfig, ax=plt.subplots()\nplt_all_fare=plt.hist(df_all['Fare'], bins=100)\nplt_survived_fare=plt.hist(df_all[df_all['Survived']==1]['Fare'], bins=100)\nplt.legend()\nax.set_xlabel('Fare - cena biletu')\nax.set_ylabel('Liczba pasazerow')\nax.set_title('Rozklad cen biletow')\nplt.show()\n\n#Wyplotowanie histogramu z Fare po skalowaniu z podzialem na 100 zakresow\nfig, ax=plt.subplots()\nplt_all_fare=plt.hist(df_all['_Fare'], bins=100)\nplt_survived_fare=plt.hist(df_all[df_all['Survived']==1]['_Fare'], bins=100)\nplt.legend()\nax.set_xlabel('Fare - cena biletu - po skalowaniu')\nax.set_ylabel('Liczba pasazerow')\nax.set_title('Rozklad cen biletow - po skalowaniu')\nplt.show()\n\n#Pociecie na przedzialy, by sprawdzic wplyw ceny biletu na przezycie\nfare_bins = [0,7,10, 20, 30, 50, 70,100,200,600]\ndf_all['Fare_cut']=pd.cut(df_all[\"Fare\"], bins=fare_bins)\n\n#Zakodowanie przedzialow, byc moze poprawia wynik\ndf_all['_Fare_encoded'] = df_all['Fare_cut'].cat.codes\n\n#Ilosc osob w danym przedziale ceny biletu\nprint('\\n~~~Ilosc osob w danym przedziale ceny biletu Fare~~~')\nprint(df_all['Fare_cut'].value_counts())\n\n#Ilosc osob w danym przedziale ceny biletu z uwzglednieniem klasy\nprint('\\n~~~Ilosc osob w danym przedziale ceny biletu Fare z uwzgledniem klasy~~~')\nprint(df_all.groupby('Fare_cut')['Pclass'].value_counts())\n\n#Szansa przezycia od przedzialu cenowego biletu\nprint('\\n~~~Szansa przezycia w zaleznosci od przedzialu cenowego biletu~~~')\nprint(df_all.groupby(['Fare_cut', 'Pclass'])['Survived'].agg(np.mean))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"534e1be975234caa144ee6646ba0d33c4da848dd"},"cell_type":"markdown","source":"#### Wnioski z analizy Fare\n*  największy udział mają bilety w przedziale ceny 7-10\n* mediana ceny biletu wynosi około 14\n* 75% biletów zamyka się w cenie 31\n* można zauważyć, że tanie bilety 0-10 dominują w klasie 3, 10-20 to przedział przejściowy między 3 a 2-gą klasą, a powyżej 30 dominują bilety w pierwszej klasie, przy czym pojawiają się pojedyncze przypadki z 3-klasy, być może są to jakieś bilety grupowe\n* najmniejsze szanse na przetrwanie niosło posiadanie biletu w zakresie 0-10, a powyżej Fare=70 szanse wzrastały pożej 70% (przy założeniu, że podróżowało się w 1-szej klasie\n* utworzono 2 dodatkowe zmienne [  __ Fare] - zawierającą przeskalowane wartości Fare oraz zmienną [_Fare_encoded] zawierającą zakodowane wartości przedziałów Fare, by duże wartości Fare nie wpływały negatywnie na proces treningu\n"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5313270625e9927540d212e3c4b086048453d0bb"},"cell_type":"markdown","source":"## 2.7 Cabin - nr kabiny\n* zmienna Cabin posiada znaczne braki danych\n* przeprowadzimy proces zastąpienie pustych miejsc zmienną = 'missing'\n* oraz dodatkowo wyciągniemy pierwszą literę z nazwy kabiny, bo może ona definiować położenie na statku\n* sprawdzimy jaka jest zależność między nazwą kabiny"},{"metadata":{"trusted":true,"_uuid":"f9529c976f22f4fb8d1d7ebafd3fdca469c69848","collapsed":true},"cell_type":"code","source":"print('\\n~~~Przykladowy wydruk informacji o Cabin~~~')\nprint(df_all.Cabin.sample(4))\n\n#Uzyskanie tylko typow kabin (pierwsz litera) + brakujace nazwane jako missing\ndf_all['_Cabin'] =df_all.Cabin.astype(str).str[0]\ndf_all.loc[df_all._Cabin=='n', '_Cabin']='missing'\n\nprint('\\n~~~Zestawienie typow Cabin (pierwsza litera)')\nprint(df_all._Cabin.value_counts())\n\nprint('\\n~~~Zestawienie typow Cabin i klas')\nprint(df_all.groupby('_Cabin')['Pclass'].value_counts())\n\n#Zakodowanie typow kabin\ndf_all['_Cabin_encoded']=pd.Categorical(df_all['_Cabin']).codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c4ba996f66b9e7b715749a404744472c598df2cf"},"cell_type":"markdown","source":"#### Wnioski z analizy zmiennej Cabin\n* Nazwy kabin w większości posiadają osoby z pierwszej klasy\n* Brakuje danych o kabinie głównie dla 3 klasy\n* Zmienna _Cabin_encoded zawiera zakodowane grupy kabin"},{"metadata":{"trusted":true,"_uuid":"3fe832c9f753412e322605ab38c946efd5402afa"},"cell_type":"markdown","source":"## 2.8 Zmienna Embarked - zaokrętowanie\n* sprawdzenie brakujących danych\n* uzupełnienie brakujących danych, bazująć na podobnych pasażerach\n* sprawdzenie zależności między portem, a klasą, ceną biletu i szansami na przeżycie\n* zakodowanie zmiennych"},{"metadata":{"trusted":true,"_uuid":"311da23c5b9f50bef406f464ccc21308e31b3087","collapsed":true},"cell_type":"code","source":"#Sprawdzam dla jakich wierszy brakuje danych\nprint('\\n~~~Dla jakich wierszy brakuje zmiennej Embarked~~~')\nprint(df_all[df_all.Embarked.isnull()][['Name', 'Fare', 'Pclass', 'Ticket']])\n\n#Jakie zaokretowanie maja osoby o tym samym typie kabiny i podobnej cenie biletu\nprint('\\n~~~Jakie zaokretowanie maja osoby o tym samym typie kabiny i podobnej cenie biletu')\nprint(df_all[(df_all['_Cabin']=='B')&(df_all['Fare']>79)]['Embarked'].value_counts())\n\nprint('\\n~~~Ilosc pasazerow z konkretnych portow z podzialem na klasy')\nprint(df_all.groupby('Embarked')['Pclass'].value_counts())\n\nprint('\\n~~~Zestawienie portow zaokretowania, klasy i mediany ceny biletu~~~')\nprint(df_all.groupby(['Embarked','Pclass'])['Fare'].median())\n\nprint('\\n~~~Zestawienie portow zaokretowania i szans na przezycie~~~')\nprint(df_all.groupby(['Embarked'])['Survived'].mean())\n\nprint('\\n~~~Zestawienie portow zaokretowania i pasazerow w konkretnych typach kabin')\nprint(df_all.groupby(['Embarked'])['_Cabin'].value_counts())\n\n#Zakodowanie zmiennej Embarked - portow za pomoca int-ow\ndf_all['_Embarked_encoded']=pd.Categorical(df_all['Embarked']).codes\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dfe0250e5a8cc2a12ed83c63721a4cd0aece83e6"},"cell_type":"markdown","source":"#### Wnioski z zmienej Embarked - zaokretowania\n* najwięcej pasażerów zaokrętowano w porcie S i byli to pasażerowie głównie 3 klasy, z brakującymi informacjami o kabinie\n* w porcie Q zaokrętowano najmniej pasażerów, głównie 3 klasa, znów braki w informacji o kabinach\n* w porcie C największy udział pasażerów stanowią posiadacze biletu na pierwszą klasę, ale też jest sporo osób z klasy 3, bez informacji o kabinach\n* mediana cen biletów jest podobna dla klasy 2 i 3 we wszystkich portach i oscyluje 12-15 dolarow dla klasy 2 i około 8 dla klasy 3, dla klasy 1 ta wartość ma większą rozbieżność od około 50-90 dolarów, ale może to wynikać z niewielkiej liczby pasażerów pierwszej klasy w portcie Q\n* największe szanse na przeżycie mieli zaokrętowni w porcie C, co może wynikać, z tego że to pasażerowie głównie 1-szej klasy\n* dla portów Q i S wartości szans na przeżycie oscylują między 33-38%\n\n\nWydaje się, że zmienna Embarked nie wniesie nowych zależności i nie wpłynie znacznie na poprawę wyniku predykcji szans na przeżycie."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0af19c97ce620ae44c286032d456765ec519fb9d"},"cell_type":"markdown","source":"## 2.9 Ticket - nr biletu\n* Sprawdzenie  przykładowych biletów\n* Sprawdzenie unikalnej liczby biletów\n* Wprowadznie nowej zmiennej, która zawiera informacje ile osób jeszcze posiada taki sam nr biletu (_TicketCounts)"},{"metadata":{"trusted":true,"_uuid":"c44ac095e334a9ea7e79a8a73b32ed8b727da308","collapsed":true},"cell_type":"code","source":"print('\\n~~~Przykladowe numery biletow~~~')\nprint(df_all.Ticket.sample(5))\n\nprint('\\n~~~Liczba unikalnych nr biletow~~~')\nprint(df_all.Ticket.nunique())\n\n#Zmienna ile osob ma taki sam nr biletu\ndf_all['_TicketCounts'] = df_all.groupby(['Ticket'])['Ticket'].transform('count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"24832e07c85eab12bd88b8e7e23c503622246dc7"},"cell_type":"markdown","source":"#### Wnioski z analizy Ticket:\n* większość pasażerów posiadała unikalny bilet (tylko oni byli do niego przypisani)\n* utworzono pomocniczą zmienną _TicketCounts, która zawiera informacje, kto jeszcze podróżował na takim samym bilecie, a więc świadczy to , że taka osoba nie podróżowała sama\n"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b56fb776d9fbcddbb9cb80202521994a2a46b62e"},"cell_type":"markdown","source":"# 3 Sprawdzenie korelacji między zmiennymi\n"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"3af337952be38648151da1ad432a70057dae07da","collapsed":true},"cell_type":"code","source":"#Wybranie kolumn, ktore beda uzyte do treningu\ncolumns_names=['Survived', 'Pclass', 'Sex', 'Age_encoded', 'SibSp', 'Parch', 'Title_encoded', 'Family_size','IsAlone','_Fare_encoded','_Cabin_encoded', '_Embarked_encoded', '_TicketCounts', '_Fare' ]\n\n#Sprawdzenie korelacji miedzy zmiennymi\ncorr = df_all[columns_names].corr()\n#print(corr)\n\n#Heatmap\nplt.figure(figsize=(8, 8))\nsns.heatmap(corr)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de86cd1c97fb496a055a858386ed2aba724ee97e"},"cell_type":"markdown","source":"#### Wnioski z heatmapy i korelacji\n* widoczne są zależności, które zostały ujawnione już podczas podczas obróbki zmiennych\n* wpływ klasy, ceny bilety, płci, tytułem na zwiększenie szans na przeżycie (wyższa klasa, wyższa cena, kobieta, tytuł związany z kobietą -> większe szanse na przetrwanie)\n* związek między ceną biletu a klasą (wyższa klasa->wyższa cena)\n* zależności, że podróżowanie samemu niosło ze sobą większe ryzko śmierci\n* pozytywna korelacja między ilością podróżnych na jeden bilet, a jego ceną (wyższa cena za więcej osób 0->logiczne)\n* oraz korelacje między zmiennymi i ich nowo utworzonymi pochodnymi (np. wielkość rodziny od ilości dzieci, małżonów, braci etc)\n\n"},{"metadata":{"_uuid":"669544fb265adccf3a86296086aa23de6a20040c"},"cell_type":"markdown","source":"# 4. Wstępna budowa modelu"},{"metadata":{"_uuid":"9e92c6a853672829c3890271a448d249018bca01"},"cell_type":"markdown","source":"## 4.1 Wstępna predykcja, wybranie modelu do dalszej optymalizacji\n* Wybranie i import wstępnych modeli ML do klasyfikacji\n* Wybranie zmiennych do predykcji\n* Wydzielenie zbioru treningowego, podział na zbiór zmiennych predykcyjnych X oraz zmienną przewidywaną Y\n* Przeprowadzenie cross-validation, dla różnych modeli, zbadanie wyniku testowego dla różnych modeli, krzywe treningowe\n* Wybranie modelu do dalszej analizy\n"},{"metadata":{"_uuid":"b115feab9aa0b72367631132a7bd61a86f8e7d4a"},"cell_type":"markdown","source":"### 4.1.1 Wybranie i import różnych modeli ML do klasyfikacji\n* import modeli Logistycznej Regresji,Naive Bayesian, Support Vector Machine do klasyfikacji,  drzewo decyzyjne, las losowy, ,sieci neuronowe,  k-najbliżych sąsiadów, XGBoost\n* utworzenie słównika z różnymi modelami"},{"metadata":{"trusted":true,"_uuid":"d3303f5e417f9f4dee3d2a9643fc6b2aa76b5a27","collapsed":true},"cell_type":"code","source":"#Import roznych modeli ML do testow\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn import linear_model\nfrom xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#Zebranie estymatow w jednym dictionarze\nclassifiers = {\n    'LogisticRegression':  linear_model.LogisticRegression(),\n    'SVC': SVC(class_weight='balanced'),\n    'LinearSVC':  LinearSVC(),\n    'GaussianNB': GaussianNB(),\n    'XGBoost': XGBClassifier(),#max_depth=3, n_estimators=15, subsample=0.8, random_state=2018),\n    'DecisionTree': DecisionTreeClassifier(),\n    'RandomForest': RandomForestClassifier(),#(n_estimators=100),\n    'KNeighbours': KNeighborsClassifier(),\n    'NeuralNetwork': MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a513973f674d898b08ac554b8c83fb214e9440b8"},"cell_type":"markdown","source":"### 4.1.2 Wybranie zmiennych, które będą użyte do wstępnego treningu oraz wydzielenie zbioru treningowego\n* wybrane zmienna do wstępnego treningu: Pclass - klasa, Sex - zakodowana płeć (0,1), Age_encoded - zakodowany wiek, Family_size (zakodowany rozmiar rodziny),  _Fare - przeskalowana wartość ceny biletu, Title_encoded - zakodowany tytuł, IsAlone - czy osoba podróżuje sama (0,1), pozostałe kolumny wstępnie odrzucono, bo zaniżały wynik zarówno podczas wstępnej CV jak i podczas submitu wyniku do rankingu głównego\n* wydzielenie zbioru treningowego z DataFrame zawierającego zbiór treningowu i testowy, które zostały złączone na początku analizy (dataset treningowy zawierał wartość w kolumnie Survived i liczył SURV=891 wierszy, natomiast zbiór testowy nie zawierał tej danej i znajdował się poniżej wiersza 891)\n* podzielenie zbioru na zmienne predykcyjne X z wybranymi zmiennymi oraz zbiór, którego wartość przewidujemy Y zawierający kolumnę Survived"},{"metadata":{"trusted":true,"_uuid":"1a6dcd42adb978b9ccc523377169ed2e0061838f","collapsed":true},"cell_type":"code","source":"#Wybranie kolumn, ktore beda uzyte do wstepnych obliczen\ncols=['Pclass', 'Sex', 'Age_encoded', 'Family_size','_Fare', 'Title_encoded']#, 'IsAlone']#'_Fare_encoded']#,'_Cabin_encoded']\n\n#Wydzielenie zbioru treningowego z polaczonego datasetu\ndef get_train_data(df_all, cols):\n    SURV = 891\n    X = df_all[:SURV][cols] \n    Y = df_all[:SURV]['Survived']\n    return X,Y\n\nX,Y=get_train_data(df_all, cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b84f2211a7de08f1d4cdcdddf90878536dcdf934","collapsed":true},"cell_type":"markdown","source":"### 4.1.3 Definicja modułów i funkcji do treningu i cross-validation\n* Definicja funkcji plot_learning_curve, która odpowiedzialna jest za trening i cross-validation dla różnych rozmiarów zbioru treningowego i wyplotowanie krzywych treningowych i krzywych cross-validation oraz uśrednione wyniki testu\n* Funkcja będzie użyta, by wybrać najlepszy model do dalszych modyfikacji "},{"metadata":{"trusted":true,"_uuid":"0c0150e17e7b560b7fdf9b1abdf4078f4aee4152","collapsed":true},"cell_type":"code","source":"#Chwilowe wylaczenie warningow, zeby nie zaburzaly widoku wykresow\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#Import learning_curve, ktora pozwala na cross-validation (zwraca wyniki dla treningu, \n#testu dla roznych zbiorow treningowych i testowych) z dodatkowym uwzglednieniem rozmiaru zbioru treningowego\nfrom sklearn.model_selection import learning_curve\n\n#Import ShuffleSplit, ktory umozliwa losowe wybranie zbioru treningowego i walidacyjny do CV, z uwzgledniem\n#rozmiaru zbioru walidacyjnego\nfrom sklearn.model_selection import ShuffleSplit\n\n#Funkcja plot_learning_curve odpowiedzialna jest za wyplotowanie wykresow\n#krzywej treningowej oraz krzywej walidacyjnej, wykorzystujac learning_curves,\n#pokazuje jak zmienia sie wynik treningu i CV w zaleznosci od rozmiaru zbioru\n#treningowego, dodatkowo dodany, by zwracala wartosc srednia wyniku dla CV\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5), plot=True):\n    \n    '''Generate a simple plot of the test and training learning'''\n    if plot==True:\n        plt.figure()\n        plt.title(title)\n        if ylim is not None:\n            plt.ylim(*ylim)\n        plt.xlabel(\"Training examples\")\n        plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    if plot==True:\n        plt.grid()\n\n        plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                         train_scores_mean + train_scores_std, alpha=0.1,\n                         color=\"r\")\n        plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                         test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n        plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n                 label=\"Training score\")\n        plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n                 label=\"Cross-validation score\")\n\n        plt.legend(loc=\"best\")\n    return plt, test_scores_mean","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7e14727e16b685dd58d27b22253b4e79f8e28ff"},"cell_type":"markdown","source":"### 4.1.4 Przeprowadzenie cross-validation z różnym rozmiarem zbioru treningowego dla różnych modeli\n* CV dla różnych rozmiarów zbioru treningowe z użycie plot_learning_curves\n* przetestowanie różnych modeli klasyfikacyjnych\n* porównanie wykresów krzywych treningowych i CV dla różnych modeli\n* porównanie wyników uśrednionego wyniku testu z kilku CV dla różnych modeli\n* wybór modelu do dalszego tuningu"},{"metadata":{"trusted":true,"_uuid":"956ee5c89bef008daed6a0467eeb9ba227a34b53","collapsed":true},"cell_type":"code","source":"def test_models(classifiers, X, Y, plot=True):\n    '''Funkcja jako argument przyjmuje rodzaj modelu w slowniku, zbior X oraz zbior Y'''\n    test_score={} #przechowuje usrednione wyniki CV dla roznych modeli\n    for c in classifiers:\n        title = \"Learning Curves \" + c \n        cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0) #CV 100 iteracji z 20% losowym zbiorem testowym\n        estimator = classifiers[c] \n        ax, test_score[c] = plot_learning_curve(estimator, title, X, Y, ylim=(0.7, 1.01), cv=cv, n_jobs=4, plot=plot)\n        if plot==True:\n            plt.show()\n    print('\\n~~~Usrednione wyniki testu dla roznych modeli, z uwzgledniem wielkosci zbioru treningowego do 20% do 100% oraz srednia dla wszystkich treningow~~~')\n    df_scores=pd.DataFrame.from_dict(test_score).T.rename(index=str, columns={0: '20_Train', 1: '40_Train', 2: '60_Train', 3: '80_Train', 4: '100_Train'})\n    df_scores['Mean']=df_scores.mean(numeric_only=True, axis=1)\n    df_scores\n    return df_scores\n\ntest_models(classifiers,X, Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f5818ac669763e93a9a84f03abed554881d3f0d","collapsed":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bbcc10f1d159862a896415048cf52e16829c5fb8"},"cell_type":"markdown","source":"### 4.1.5 Wnioski z powyższego punktu i wybór modelu\n* widoczny znaczny overfitting (przetrenowanie, high variance) dla dla drzewa decyzyjnego i lasu losowego ( znaczna rozbieżność między wynikiem dla treningu i CV)\n* widoczny underfitting (high bias) dla prostych modeli (Regresji Logistycznej (logistic regression), Liniowego SVM (Linear SVC), Naiwnego Bayesiana z rozkładem Gaussa (GausianNB) i sieci neuronowych (neural networks))\n* ciekawie wynik daje K-najbliższych sąsiadów, wydaje się, że jeśli dostępny byłby większy zbiór to mógłby osiągnąć lepszy wynik, jednak dla tego daje około accuracy około 0.8\n* godne uwagi po przyjżeniu się są 2 algorytmy - SVC oraz XGBoost, przy czym w każdym przypadku rozmiaru zbioru treningowego XGBoost uzyskiwał wyższe accuracy oraz jest zwycięskim algorytmem wielku konkurencji na Kaggle, dlatego do dalszej analizy wybierzemy ten algorytm"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"95a8bbb3e91ca73b9ade2121dfaa3b3bb58f9ccc"},"cell_type":"markdown","source":"# 5. Features Importance - wybór zmiennych do dalszych analiz\n* w punkcie 4. przeprowadziliśmy analizę na wybranych kolumnach, których wybór dokonano metodą prób i błędów, teraz jednak dokładnie przyjżymy się wpływowi poszczególnych zmiennych na wynik w XGBoostcie\n* dokonamy wyboru, które zmienne będziemy dalej wykorzystywać"},{"metadata":{"_uuid":"ed59906ff3fb39eddc12b8664ef2f71365ff3108"},"cell_type":"markdown","source":"### 5.1 Załadowanie zbioru z wszystkimi zmiennymi, które mogą być użyte do analizy"},{"metadata":{"trusted":true,"_uuid":"e6928248b14185edcd4bacdbb28737fd6e42b387","collapsed":true},"cell_type":"code","source":"#Wszystkie utworzone, zmodyfikowane, zeskalowane, zakodowane lub pierwotne kolumny(, ktore zawieraja tylko liczby calkowite)\ncols_all=['Pclass', 'Sex', 'Age_encoded', 'Family_size',\n          '_Fare', 'Title_encoded' ,'_Cabin_encoded','_Embarked_encoded',\n          '_TicketCounts', 'SibSp', 'Parch','IsAlone','_Fare_encoded']\n\n#Wydzielenie zbioru treningowego z polaczonego datasetu\nX,Y=get_train_data(df_all, cols_all)\n\n#Wynik XGBoosta dla wszystkich kolumn\nxgb_clas={'XGBoost': XGBClassifier(),}\ntest_models(xgb_clas, X, Y, plot=False)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52834bc0ba25ec169d8915bfff2b238ef436a3fa"},"cell_type":"markdown","source":"### 5.2 Wykres wpływu zmiennych na wynik (Feature Importance)"},{"metadata":{"trusted":true,"_uuid":"45934e5958c7d6b2aa85f6387df230176b029e6f","scrolled":true,"collapsed":true},"cell_type":"code","source":"#Plot Feature Importance korzystajac z wbudowanych funkcji XGBoosta\nfrom numpy import loadtxt\nfrom xgboost import plot_importance\n\n# fit na danych\nmodel = XGBClassifier()\nmodel.fit(X, Y)\n\n# plot feature importance\nplot_importance(model)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"21ebe5827da3798f0e213628ce0ca941293539df"},"cell_type":"markdown","source":"#### Wnioski z powyższego wykresu:\n* Zmienne, które zależą od innych mają niewielke znaczenie i można je wyrzucić\n* Są to SibSp, Parch, IsAlone, które zależą od Family_Size oraz Fare_encoded, które zależy od Fare\n* Największy udział w Feature Importance mają po kolei: Fare, Age_encoded, Title_encoded, Ticet_Counts, Family_size, a więc zmienne, który wartości wahają od -1 do około 10, więc należy sprawdzić, czy nie zaburzają one wyniku przez to, że nie są 0-1\n"},{"metadata":{"_uuid":"a3986bea5b44349f44715bcbc7d8ce0a81beec4a"},"cell_type":"markdown","source":"### 5.3 Wpływ parametrów na accuracy\n* Odrzucam zmienne SibSp, Parch, IsAlone, oraz Fare_encoded, które nie mają mały wpływ na wynik\n* Sprawdzamy, jak uzwględnienie kolejnych zmiennych/ cech wg Feature Importance wpływa na wynik accuracy\n* "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9e0e2eb8b046b4479f94312dbe0f427229f5186f"},"cell_type":"code","source":"#Wszystkie utworzone, zmodyfikowane, zeskalowane, zakodowane lub pierwotne kolumny(, ktore zawieraja tylko liczby calkowite)\ncols_cut1=['Pclass', 'Sex',  'Family_size',\n          '_Fare', 'Title_encoded' ,'_Embarked_encoded'\n          ,'_Cabin_encoded','Age_encoded','_TicketCounts']\n\n#Wydzielenie zbioru treningowego z polaczonego datasetu\nX,Y=get_train_data(df_all, cols_cut1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9dcd09bdd55bb5eecc15c71b74d72ff5f0b51e55","collapsed":true},"cell_type":"code","source":"#Na podstawie https://machinelearningmastery.com/feature-importance-and-feature-selection-with-xgboost-in-python/\n#Zadaniem jest:\n#wyznaczenie feature importance\n#a potem z uzyciem SelectFromModel ze zbioru wybieramy zmienne, ktore sa uzyte do obliczenia accuracy\n#zaczynamy od jednej zmiennej z najwyzszym feature importance, a potem dwie zmienne, 3 zmienne i tak az uzwglednimy wszystkie\n#sprawdzamy jak uwzglednienie kolejnych zmiennych wplywa na accuracy zbiorcze\n\nfrom numpy import sort\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.feature_selection import SelectFromModel\n\n# podzial na train i test\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=7)\n\n# fit na train\nmodel = XGBClassifier()\nmodel.fit(X_train, y_train)\n\n#Drukowanie feature importance wraz z nazwami cech, po sortowaniu, by wiedziec dla czego drukowane sa accuracy\nfeature_importance_with_names=zip(X.columns,model.feature_importances_)\nprint('\\n~~~Posortowane feature importance od najwiekszego do najmniejszego~~~\\n')\nprint(sorted(feature_importance_with_names, key=lambda x: x[1], reverse=True))\nprint ('\\n')\n\n# predykcja i wydruk accuracy\ny_pred = model.predict(X_test)\npredictions = [round(value) for value in y_pred]\naccuracy = accuracy_score(y_test, predictions)\n\nprint('\\n~~~Accuracy z uwzglednieniem wszystkich zmiennych~~~\\n')\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n\nprint('\\n~~~Wynik accuracy w zaleznosci od ilosci uwzglednionych zmiennych~~~\\n')\n\n# posortowanie wg wartosci feture importance\nthresholds = sort(model.feature_importances_)\n\nfor thresh in thresholds:\n    \n    \n    #wybor zmiennych, ktore feature importance jest wyzszy niz threshold\n    #czyli zaczyna od najwiekszej wartosci, ktora spelnia 1 zmienna (_Fare)\n    #potem mniejszy threshold, ktory spelniaja juz 2 zmienne (_Fare i Age_encode)\n    #itd. az uwzgledni wszystkie zmienne\n    #wiec najpierw do obliczen accuracy wykorzystuje 1 zmienna, potem 2,..., a na koniec wszystkie\n    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n    select_X_train = selection.transform(X_train)\n    \n    # train model\n    selection_model = XGBClassifier()\n    selection_model.fit(select_X_train, y_train)\n    \n    # eval model\n    select_X_test = selection.transform(X_test)\n    y_pred = selection_model.predict(select_X_test)\n    \n    #print\n    predictions = [round(value) for value in y_pred]\n    accuracy = accuracy_score(y_test, predictions)\n    print(\"FeatImportance=%.3f, FeatNumber=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))\n\n \n\nxgb_clas={'XGBoost': XGBClassifier()}\ntest_models(xgb_clas, X, Y, plot=False)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"92e789a94ad8851ea67be3eabc63d2aa763e0c57"},"cell_type":"markdown","source":"### Wnioski z wstępnego przeglądu Feature Importance:\n* Odrzucenie zmiennych o niewielkiej wartości Feature Importance przyczyniło się do niewielkiego wzrostu accuracy\n* Przegląd wpływu ilości uwzględnionych cech na accuracy nie daje odpowiedzi, które cechy zmodyfikować, bo np.: uwzględniene oprócz Fare także Age_encoded, powoduje spadek accuracy (przy uwzględnieniu tylko tych 2 cech), ale nie uwzględnienie Age_encoded powoduje znaczny spadek całkowitego accuracy\n* Przyjżymy się wpływowi pojedynczych cech (z pominięciem pozostałych) na accuracy"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bbeaf1c20d683a3f9944893fdbb5fcfbc830dd73"},"cell_type":"markdown","source":"## 5.4 Wpływ pojedynczych zmiennych na accuracy (z pominięciem pozostałych)\n* użyjemy najprostszej metody, a więc przywidywania z uwzględnieniem tylko 1 kolumny\n* przeprowadzimy CV i sprawdzimy accuracy, gdy uwzgledniamy do przewidywnia, tylko konkretna zmienna\n"},{"metadata":{"trusted":true,"_uuid":"a99e26e111200f772b58f16b5e94f2d786fb5b75","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom operator import itemgetter\nfrom sklearn.model_selection import cross_val_score\n\n#Obliczenie accuracy przy uwzglednieniu tylko 1 zmiennej\ndef get_accuracy_for_one_feature(df_all, cols_cut1):\n    score = {}\n    model=XGBClassifier()\n    for i in range(0,len(cols_cut1),1):\n        cols_cut2=[cols_cut1[i]]\n        X,Y=get_train_data(df_all, cols_cut2)    \n        score[cols_cut2[0]]=cross_val_score(model, X, Y, cv=5).mean()\n\n\n    #posortowanie od najwiekszego accuracy do najmniejszego\n    print('\\n~~~Accuracy przy uwzglednieniu tylko jednej zmiennej~~~')\n    return sorted(score.items(), key=itemgetter(1))[::-1]\n    \n\nget_accuracy_for_one_feature(df_all, cols_cut1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d045e25b28d3f170a9a8812b21a842c57417df5f"},"cell_type":"markdown","source":"### Wnioski z uwzglednienia tylko pojedynczych zmiennych\n* Najlepiej z przewidywanie radzą sobie zmienne Title_encoded oraz Sex\n* Pomimo, że _Fare miało wysokie wartości Feature Importance przewiduje tylko w 3 co do kolejności dokładnością, a wartość feature importance tej zmiennej może wynikać z dużych wartości, które przyjmuje -> można znormalizować w 0-1 dodatkowo\n* Zaskakująco dobrze przewiduje zmienna Cabin_encoded, ale może spowodowane znaczną ilością brakujących danych\n* Kiepsko wypada Age_encoded, być może przyjęte przedziały nie są zbyt dobre\n"},{"metadata":{"_uuid":"2436eb4265ffe229fa1a8c6a0a9d7020b8fdbf5a"},"cell_type":"markdown","source":"## 5.5 Ponowna normalizacja Fare\n* normalizacja Fare w zakresie 0-1, by sprawdzić jaki wpływ na uzyskiwany wynik miał jej brak"},{"metadata":{"trusted":true,"_uuid":"089086deb70027ccce049f5f4ad487d06923d1b2","collapsed":true},"cell_type":"code","source":"#Normalizacja Fare w 0-1\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import preprocessing\n\nx = df_all['Fare'].values #returns a numpy array\nx=x.reshape(df_all.shape[0],1)\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(x)\ndf_all['_Fare_norm'] = pd.DataFrame(x_scaled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f101b3da0ab223f4f5e236e2c28b860c0c9cf11","collapsed":true},"cell_type":"code","source":"#Sprawdzenie wyniku accuracy dla pojedynczej zmiennej\ncol_cut_with_fare=cols_cut1.copy()\ncol_cut_with_fare.append('_Fare_norm')\nget_accuracy_for_one_feature(df_all, col_cut_with_fare)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b427928db18162e41b64778ba91a729d996162f2"},"cell_type":"markdown","source":"### Wnioski po normalizacji Fare\n* Uzyskane wyniki są gorsze niż bez normalizacji\n* Wstępnie zawieszamy pomysł Feature Enginneringu i sprawdzamy jak na wynik możemy wpłyną tuningiem modelu XGBoost\n* Do dalszej analizy i tuningu XGBoosta pozostawiono zmienne:"},{"metadata":{"trusted":true,"_uuid":"abe5167bf2cdb5d91a883c0cb629115cabcf26bf","collapsed":true},"cell_type":"code","source":"print('\\n~~~Zmienne pozostawione do dalszego tuningu XGBoosta:~~~\\n')\nprint(cols_cut1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73f080c4247134b5061d05e2a849af4c6bef1424"},"cell_type":"markdown","source":"## 6. Tuning XGBoosta\nZ użyciem GridSearchCV testujemy:\n*  różne maksymalne głębkości drzewa (max_depth)\n* różną ilość drzew (n_estimators)\n* różną min_child_weight"},{"metadata":{"trusted":true,"_uuid":"3955112a20c5400e228ebf51cc87b002e3381b92","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n#zastosowanie tylko ponizszych 5 zmiennych zapewnia wynik na poziomie 0.7894\n#cols_cut12=['Pclass', 'Sex', 'Age_encoded', 'Family_size','_Fare']\n\ncols_cut12=cols_cut1\nX, Y = get_train_data(df_all, cols_cut12)\n\n#Parametry do sprawdzenia i wybrania najlepszych\ncv_params = {'max_depth': [2,3,4,5],\n             'n_estimators': range(10,210,50),\n            'learning_rate': [0.01,0.02,0.05,0.07,0.1]}\n\n#parametry podane do XGBoosta\n#ind_params = {'learning_rate': 0.05, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n#             'objective': 'binary:logistic'}\n\nxgb= XGBClassifier().fit(X, Y)\noptimized_xgb = GridSearchCV(xgb, cv_params, scoring = 'accuracy', cv = 5, n_jobs = -1)\noptimized_xgb.fit(X, Y)\nprint('\\n~~~Accuracy po optymalizacji~~~\\n')\noptimized_xgb.score(X,Y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6733207138b09f2a9c82db8f6edbbc8953981e16"},"cell_type":"markdown","source":"### Utworzenie pliku z predykcją do submitu"},{"metadata":{"trusted":true,"_uuid":"e62d1e40c12a0e9304d666539312fba191393199","collapsed":true},"cell_type":"code","source":"#Predykcja dla wyniku testowego i submit\n#Wyznaczenie zbioru testowego\nSURV = 891\nXp = df_all[SURV:][cols_cut12]\n\n#Utworzenie pliku wynikowego\nresult = pd.DataFrame({'PassengerID': df_all[SURV:].index })\nresult['Survived'] = optimized_xgb.predict(Xp).T.astype(int)\nresult[['PassengerID','Survived']].to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5d22c30ee02443d2d2225791fe1f4f3b779d1c48"},"cell_type":"markdown","source":"### Wnioski z tuningu XGBoosta\n* XGBoost pomimo wyniku około 90% dla zbioru testowego przewiduje około 76-77% -> overfitting\n* Pomimo użycia GridSeachCV nie udało się uzyskać dobrego wyniku, niezbędne jest głębsze zagłębienie się w parametry XGBoosta, bo różnica między zastosowaniem optymalizacji, a jej brak to zaledwie 1% różnicy\n* Jednocześnie zastosowanie tylko 5 zmiennych: Pclass, Sex, Age_encoded, Family_size oraz _Fare zapewniło wynik na poziomie 78.94%, co zapewnia około miejsce w top3000 z hakiem\n* Zatem błąd nadal tkwi w zmiennych, ale na tym zakończymy ten wstępny projekt"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d17acd402431fb94cef9e0fb2d01c1aa66099ca6"},"cell_type":"markdown","source":"# 7. Wnioski\n1. Udało się uzyskać model z accuracy 0.77, przy uwzględnieniu wybranych w punkcie 5.5 zmiennych\n2. Lepszy wynik udało się pomijają większość zmiennych, a zostawiając tylko płeć, klasę podróżnego, zakodowany wiek, wielkość rodziny i przeskalowane ceny biletu - wynik 0.7894\n3. Optymalizacja parametrów XGBoosta za pomocą GridSearchCV zapewniła niewielką 1% poprawę w przypadku wymienionym w pkt 1 i 0% w przypadku z pkt-u 2-ego.\n4. Główny problem tkwi prawdopodobnie w zmiennych i ich podziale, konieczny byłby dalszy Feature Engineering\n5. Jedynymi utworzonymi zmiennymi, które dobrze się sprawdziły było Family_size oraz _Fare (przeskalowane Fare)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}