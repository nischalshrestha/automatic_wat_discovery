{"cells":[{"metadata":{"_cell_guid":"89df1496-db04-482c-8bed-b7697c955ad0","collapsed":true,"_uuid":"a7f8ffe5fe9b667ebfbabed6112f949a91120733","trusted":false},"cell_type":"code","source":"# Commentary on Monday April 16 2018, 9:43pm\n# The first edition was rather simplistic: its predictive features were only \"Female\" and \"Pclass\". \n# Its score when submitted to Kaggle is approximately 0.69856 .\n\n# Now we update the code for more refinement.\n# The predictive features are \"Female\" and \"MasterMiss\" and \"Pclass\".\n# Its score when submitted to Kaggle is approximately 0.67464 .\n\n# Again we update the code for more refinement.\n# The predictive features are \"Female\" and \"MasterMiss\" and \"Embarked\" and \"Pclass\".\n# Its score when submitted to Kaggle is approximately 0.72248 .\n\n# And again we update the code for more refinement.\n# The predictive features are \"ParchBinary\" and Female\" and \"MasterMiss\" and \"Embarked\" and \"Pclass\".\n# Its score when submitted to Kaggle is approximately 0.72727 .\n\n# Yet again we update the code for more refinement.\n# The predictive features are \"Female\" and \"MasterMiss\" and \"SibSpBinary\" and \"ParchBinary\" and \"Embarked\" and \"Pclass\".\n# Its score when submitted to Kaggle is approximately 0.71291.\n\n#Update on May 7, 2018\n#Added new features such as separating the men from the women, and further serparting the men and the boys\n#Also decided to group people by their sex and Pclass, which gave 6 features that were helpful in my prediction\n#Also changed the method of predicting from a singular logistic regression to a voting method\n#The vote takes into account predictions from a logistic regression, k-nearest neighbors, random forest, and XGBoost and Support Vector Machines\n#As of now the highest score I have been able ot achieve is a 0.78947","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1459f3bd-35ff-4694-971d-f5e180fb1f2c","collapsed":true,"_uuid":"f6dc7c1d508d4698497cc699a291d8802c52f36e","trusted":false},"cell_type":"code","source":"# Imports\n\n# pandas\nimport pandas as pd\nfrom pandas import Series,DataFrame\n\n# numpy, matplotlib, seaborn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n## %matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier, ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n#imported xgboost for another machine learning model\nfrom xgboost import XGBClassifier\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"424b0dbd-99b0-4e67-b65c-31a35df8111d","collapsed":true,"_uuid":"2a25183814bf87611c4952f31ddba44a56660dd5","trusted":false},"cell_type":"code","source":"# get titanic & test csv files as a DataFrame\ntitanic_df = pd.read_csv(\"../input/train.csv\")\ntest_df    = pd.read_csv(\"../input/test.csv\")\n\n\n# preview the data\nprint(titanic_df.head())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"64da6fe6-a2ca-4bcb-a22c-436d6e7c03e5","collapsed":true,"_uuid":"10c3e94b62cf4c6d1ac43c0e8c440b0a547a97aa","trusted":false},"cell_type":"code","source":"#see what types of data we are dealing with and how we're going to have to clean or transform this data in order to make our model\ntitanic_df.info()\nprint(\"----------------------------\")\ntest_df.info()\n\n\ntest_df[\"Survived\"] = -1\n\nprint(\"============================\")\ntitanicANDtest_df = pd.concat([titanic_df, test_df], keys=['titanic', 'test'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cd72e237-53ce-4463-9efb-d079b33e7efd","collapsed":true,"_uuid":"5e63e9297e2ff40d288012b6770c25a91470411b","trusted":false},"cell_type":"code","source":"# drop unnecessary columns, these columns won't be useful in analysis and prediction\ntitanic_df = titanic_df.drop(['PassengerId','Ticket','Cabin','Fare'], axis=1)\ntest_df    = test_df.drop(['Ticket','Cabin','Fare'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bafc7082-373c-4a25-a155-8241eb9488c6","collapsed":true,"_uuid":"a8f85e9ed27f27f65e47d95bd2b7855d25abb1a1","trusted":false},"cell_type":"code","source":"float_formatter = lambda x: \"%.5f\" % x\nnp.set_printoptions(formatter={'float_kind':float_formatter})\n\n#$# Nov 19 edit to view the which columns in our dataframe that contain missing values\nprint('Here are the NAN counts of titanic_df')\n#titanic_df['Age'] =  titanic_df['Age'].fillna(999)\n\nprint( titanic_df.isnull().sum(), '\\n' )","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b9b94eb2-7e2c-4560-8ff1-82cdd87c09d3","collapsed":true,"_uuid":"339105c6fe06c428d4e2114753844f0c226b04b2","trusted":false},"cell_type":"code","source":"print('Pclass and Sex are useful factors.')\nprint('Here are pivot tables for survivor sum, passenger count, and mean.\\n')\n\ntable0a = pd.pivot_table(titanic_df, values = 'Survived', \\\n                    index = ['Pclass'], columns=['Sex'], aggfunc=np.sum)\nprint( table0a,'\\n' )\n\ntable0b = pd.pivot_table(titanic_df, values = 'Survived', \\\n                    index = ['Pclass'], columns=['Sex'], aggfunc='count')\nprint( table0b,'\\n' )\n\ntable0c = pd.pivot_table(titanic_df, values = 'Survived', \\\n                    index = ['Pclass'], columns=['Sex'], aggfunc=np.mean)\nprint( table0c,'\\n' )\n\nprint('So we create new columns Female and Male for machine learning.\\n')\n\nsex_dummies_titanic  = pd.get_dummies(titanic_df['Sex'])\nsex_dummies_titanic.columns = ['Female','Male']\n#13April# sex_dummies_titanic.drop(['Male'], axis=1, inplace=True)\ntitanic_df = titanic_df.join(sex_dummies_titanic)\n#$# titanic_df.drop(['Sex'],axis=1,inplace=True)\n\nsex_dummies_test  = pd.get_dummies(test_df['Sex'])\nsex_dummies_test.columns = ['Female','Male']\n#13April# sex_dummies_test.drop(['Male'], axis=1, inplace=True)\ntest_df = test_df.join(sex_dummies_test)\n#$# titanic_df.drop(['Sex'],axis=1,inplace=True)\n\nsex_dummies_titanicANDtest  = pd.get_dummies(titanicANDtest_df['Sex'])\nsex_dummies_titanicANDtest.columns = ['Female','Male']\n#13April# sex_dummies_titanicANDtest.drop(['Male'], axis=1, inplace=True)\ntitanicANDtest_df = titanicANDtest_df.join(sex_dummies_titanicANDtest)\n#$# titanic_df.drop(['Sex'],axis=1,inplace=True)\n\ntitanicANDtest_df.head(5)\n\n\n\npclass_dummies_titanic  = pd.get_dummies(titanic_df['Pclass'])\npclass_dummies_titanic.columns = ['Class1','Class2','Class3']\ntitanic_df    = titanic_df.join(pclass_dummies_titanic)\n\npclass_dummies_test  = pd.get_dummies(test_df['Pclass'])\npclass_dummies_test.columns = ['Class1','Class2','Class3']\ntest_df    = test_df.join(pclass_dummies_test)\n\npclass_dummies_titanicANDtest  = pd.get_dummies(titanicANDtest_df['Pclass'])\npclass_dummies_titanicANDtest.columns = ['Class1','Class2','Class3']\ntitanicANDtest_df    = titanicANDtest_df.join(pclass_dummies_titanicANDtest)\n\ntitanicANDtest_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"25de47e1-df7b-40a6-9cb2-484eaf31db06","collapsed":true,"_uuid":"6bb8d1e433dd0d5e09675b29160234ae254dab40","trusted":false},"cell_type":"code","source":"print('Now from the Name we locate the MasterOrMiss passengers.')\n\ndef get_masterormiss(passenger):\n    name = passenger\n    if (   ('Master' in str(name)) \\\n        or ('Miss'   in str(name)) \\\n        or ('Mlle'   in str(name)) ):\n        return 1\n    else:\n        return 0\n\ntitanic_df['MasterMiss'] = \\\n    titanic_df[['Name']].apply( get_masterormiss, axis=1 )\n\ntest_df['MasterMiss'] = \\\n    test_df[['Name']].apply( get_masterormiss, axis=1 )\n\ntitanicANDtest_df['MasterMiss'] = \\\n    titanicANDtest_df[['Name']].apply( get_masterormiss, axis=1 )\n\n#$# print(titanicANDtest_df.head())\n    \n    \n\nprint('Here are pivot tables for survival by Sex and MasterMiss, by Pclass.\\n')\n\ntable0d = pd.pivot_table(titanic_df, values = 'Survived', \\\n                    index = ['Female', 'MasterMiss'], columns=['Pclass'], \\\n                    aggfunc=np.sum)\nprint( table0d.iloc[::-1],'\\n' ) #$# This hack reverses the order of the rows.\n\ntable0e = pd.pivot_table(titanic_df, values = 'Survived', \\\n                    index = ['Female', 'MasterMiss'], columns=['Pclass'], \\\n                    aggfunc='count')\nprint( table0e.iloc[::-1],'\\n' )\n\ntable0f = pd.pivot_table(titanic_df, values = 'Survived', \\\n                    index = ['Female', 'MasterMiss'], columns=['Pclass'], \\\n                    aggfunc=np.mean)\nprint( table0f.iloc[::-1],'\\n' ) ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d89ace27-3ca6-41a6-82a7-3031b574828a","collapsed":true,"_uuid":"2ef330f379e674521d70a8be18836d6ac2604776","trusted":false},"cell_type":"code","source":"#changed child to include all passengers with the title of master in them\n#this is because unlike miss, master was a term only given to male children\n#so it would make sense to include all masters as children, especially since\n#some passengers with the title master had no age\ndef get_child(passenger):\n    MasterMiss, Age, Sex = passenger\n    if((MasterMiss == 1 and Sex == \"male\") or Age < 16):\n        return 1\n    else:\n        return 0\n\n#applied the get_child function to the titanic and test dataframes\ntitanic_df[\"Child\"] = titanic_df[[\"MasterMiss\", \"Age\", \"Sex\"]].apply(get_child, axis = 1)\ntest_df[\"Child\"] = test_df[[\"MasterMiss\", \"Age\", \"Sex\"]].apply(get_child, axis = 1)\ntitanic_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"773c818d-a32e-480c-8d9f-11fa7e81caf3","collapsed":true,"_uuid":"7bd2a49c604ba5f307af84a7a9f420e864699b0e","trusted":false},"cell_type":"code","source":"#Here I try to separate the men from the male children\n#This is because when classifying males, men had a poor rate of survival\n#However, male children had a good rate of survival\n#So it's important to distinguish the two\ndef man(passenger):\n    sex, child = passenger\n    if(sex == \"male\" and child == 0):\n        return(1)\n    else:\n        return(0)\n\n#aaplied the man function to the titanic and test dataframes\ntitanic_df[\"Man\"] = titanic_df[[\"Sex\", \"Child\"]].apply(man, axis=1)\ntest_df[\"Man\"] = test_df[[\"Sex\", \"Child\"]].apply(man, axis=1)\ntitanic_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c78ec94e-4ce3-4eac-a8d2-23a2938092c9","collapsed":true,"_uuid":"4d6cf908ad48e84c5fccbd4251d3ac878f573847","trusted":false},"cell_type":"code","source":"print('Now Embarked.  Fill the 2 NaNs with S, as ticket-number blocks imply.')\n\ntitanic_df[\"Embarked\"] = titanic_df[\"Embarked\"].fillna(\"S\")\ntitanicANDtest_df[\"Embarked\"] = titanicANDtest_df[\"Embarked\"].fillna(\"S\")\n\n\nembark_dummies_titanic  = pd.get_dummies(titanic_df['Embarked'])\ntitanic_df = titanic_df.join(embark_dummies_titanic)\n\nembark_dummies_test  = pd.get_dummies(test_df['Embarked'])\ntest_df    = test_df.join(embark_dummies_test)\n\nembark_dummies_titanicANDtest  = pd.get_dummies(titanicANDtest_df['Embarked'])\ntitanicANDtest_df = titanicANDtest_df.join(embark_dummies_titanicANDtest)\n\n\nprint('Pivot tables for survival by Sex + MasterMiss, by Pclass + Embark.\\n')\n\ntable0d = pd.pivot_table(titanic_df, values = 'Survived', \\\n                    index = ['Female', 'MasterMiss'], \\\n                    columns=['Embarked', 'Pclass'], \\\n                    aggfunc=np.sum)\nprint( table0d.iloc[::-1],'\\n' ) #$# This hack reverses the order of the rows.\n\ntable0e = pd.pivot_table(titanic_df, values = 'Survived', \\\n                    index = ['Female', 'MasterMiss'], \\\n                    columns=['Embarked', 'Pclass'], \\\n                    aggfunc='count')\nprint( table0e.iloc[::-1],'\\n' )\n\ntable0f = pd.pivot_table(titanic_df, values = 'Survived', \\\n                    index = ['Female', 'MasterMiss'], \\\n                    columns=['Embarked', 'Pclass'], \\\n                    aggfunc=np.mean)\nprint( table0f.iloc[::-1],'\\n' ) ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"21fde07e-24b6-49e8-980b-9f1be6c2d677","collapsed":true,"_uuid":"77010642276a683c8c5b11fef3a5cec57da56aa3","trusted":false},"cell_type":"code","source":"print('Now consider Parch as a binary decision: is the value greater than 0?')\n\n#$# def is_positive(passenger):\n#$#     parch = int(passenger)\n#$#     return 1 if (parch > 0) else 0\n\ntitanic_df['ParchBinary'] = \\\n  titanic_df[['Parch']].apply( (lambda x: int(int(x) > 0) ), axis=1)\n \ntest_df['ParchBinary'] = \\\n  test_df[['Parch']].apply( (lambda x: int(int(x) > 0) ), axis=1)\n \ntitanicANDtest_df['ParchBinary'] = \\\n  titanicANDtest_df[['Parch']].apply( (lambda x: int(int(x) > 0) ), axis=1) \n\n\nprint('Pivot tables: Sex + MasterMiss + ParchBinary, by Pclass + Embark.\\n')\n\ntable0d = pd.pivot_table(titanic_df, values = 'Survived', \\\n                    index = ['ParchBinary', 'Female', 'MasterMiss'], \\\n                    columns=['Embarked', 'Pclass'], \\\n                    aggfunc=np.sum)\nprint( table0d.iloc[::-1],'\\n' ) #$# This hack reverses the order of the rows.\n\ntable0e = pd.pivot_table(titanic_df, values = 'Survived', \\\n                    index = ['ParchBinary', 'Female', 'MasterMiss'], \\\n                    columns=['Embarked', 'Pclass'], \\\n                    aggfunc='count')\nprint( table0e.iloc[::-1],'\\n' )\n\ntable0f = pd.pivot_table(titanic_df, values = 'Survived', \\\n                    index = ['ParchBinary', 'Female', 'MasterMiss'], \\\n                    columns=['Embarked', 'Pclass'], \\\n                    aggfunc=np.mean)\nprint( table0f.iloc[::-1],'\\n' )","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"394d1986-7edb-4af9-935d-47bfc83cd2f4","collapsed":true,"_uuid":"36315f840ca75abbacef5533dc1aef2c859a78ed","trusted":false},"cell_type":"code","source":"print('Now consider SibSp as a binary decision: is the value greater than 0?')\n\ntitanic_df['SibSpBinary'] = \\\n  titanic_df[['SibSp']].apply( (lambda x: int(int(x) > 0) ), axis=1)\n \ntest_df['SibSpBinary'] = \\\n  test_df[['SibSp']].apply( (lambda x: int(int(x) > 0) ), axis=1)\n\ntitanicANDtest_df['SibSpBinary'] = \\\n  titanicANDtest_df[['SibSp']].apply( (lambda x: int(int(x) > 0) ), axis=1)\n\n\nprint('Pivot tables: ParchBinary + SibSpBinary + Sex + MasterMiss, \\\nby Embark + Pclass.\\n')\n\ntable0d = pd.pivot_table(titanic_df, values = 'Survived', \\\n             index = ['Female', 'MasterMiss', 'SibSpBinary', 'ParchBinary'], \\\n             columns=['Pclass', 'Embarked'], \\\n             aggfunc=np.sum)\nprint( table0d.iloc[::-1],'\\n' ) #$# This hack reverses the order of the rows.\n\ntable0e = pd.pivot_table(titanic_df, values = 'Survived', \\\n             index = ['Female', 'MasterMiss', 'SibSpBinary', 'ParchBinary'], \\\n             columns=['Pclass', 'Embarked'], \\\n             aggfunc='count')\nprint( table0e.iloc[::-1],'\\n' )\n\ntable0f = pd.pivot_table(titanic_df, values = 'Survived', \\\n             index = ['Female', 'MasterMiss', 'SibSpBinary', 'ParchBinary'], \\\n             columns=['Pclass', 'Embarked'], \\\n             aggfunc=np.mean )\nprint( table0f.iloc[::-1].round(2),'\\n' )\n\ndef get_family(passenger):\n    SibSpBinary, ParchBinary = passenger\n    return 1 if(SibSpBinary == 1 or ParchBinary ==1) else 0\n\ntitanic_df[\"Family\"] = titanic_df[['SibSpBinary', 'ParchBinary']].apply(get_family, axis=1)\ntest_df[\"Family\"] = test_df[['SibSpBinary', 'ParchBinary']].apply(get_family, axis=1)\n\ndef get_family_size(passenger):\n    SibSp, Parch = passenger\n    return (SibSp + Parch + 1)\n\ntitanic_df[\"FamilySize\"] = titanic_df[['SibSp', 'Parch']].apply(get_family_size, axis=1)\ntest_df[\"FamilySize\"] = test_df[['SibSp', 'Parch']].apply(get_family_size, axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c618f869-bef6-4c69-be74-64dd19fa1bf9","collapsed":true,"_uuid":"b0d33cafcbae5ab6a66d677ef94894f4947fbe38","trusted":false},"cell_type":"code","source":"#goal of this cell is to combine pclass and sex to make a more accurate predictor\n#since the two seem to work better when combined (thanks to Erik Bruin for the idea)\n\ntitanic_df[\"ClassSex\"] = titanic_df[\"Pclass\"].map(str) + titanic_df[\"Sex\"]\ntest_df[\"ClassSex\"] = test_df[\"Pclass\"].map(str) + test_df[\"Sex\"]\n\nclassSex_dummies_titanic = pd.get_dummies(titanic_df[\"ClassSex\"])\nclassSex_dummies_test = pd.get_dummies(test_df[\"ClassSex\"])\n\ntitanic_df = titanic_df.join(classSex_dummies_titanic)\ntest_df = test_df.join(classSex_dummies_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5d853ab2-33c9-402f-81cc-937341f887e4","collapsed":true,"_uuid":"3c6b39f6cb11f4266bb151dea923497d73b36fba","trusted":false},"cell_type":"code","source":"#now to separate the male children from the female children in order to classify each of them\ntitanic_df[\"ChildSex\"] = titanic_df[\"Child\"].map(str) + titanic_df[\"Sex\"]\ntest_df[\"ChildSex\"] = test_df[\"Child\"].map(str) + test_df[\"Sex\"]\n\n#separating into adults male and female and girls and boys\nchild_dummies = pd.get_dummies(titanic_df[\"ChildSex\"])\nchild_dummies.columns = [\"AdultF\",\"AdultM\",\"Girl\",\"Boy\"]\ntitanic_df = titanic_df.join(child_dummies)\n#drop the adults and girls because those aren't what we are looking for\ntitanic_df.drop([\"AdultF\",\"AdultM\",\"Girl\",\"ChildSex\"], axis=1, inplace = True)\n\n#do the same thing for the test dataframe\nchild_dummies_test = pd.get_dummies(test_df[\"ChildSex\"])\nchild_dummies_test.columns = [\"AdultF\",\"AdultM\",\"Girl\",\"Boy\"]\ntest_df = test_df.join(child_dummies_test)\ntest_df.drop([\"AdultF\",\"AdultM\",\"Girl\",\"ChildSex\"], axis=1, inplace = True)\n\n#now that we have Boys separated, we want to sort them by their individual classes\ntitanic_df[\"BoyClass\"] = titanic_df[\"Boy\"].map(str) + titanic_df[\"Pclass\"].map(str)\ntest_df[\"BoyClass\"] = test_df[\"Boy\"].map(str) + test_df[\"Pclass\"].map(str)\n\n#get dummies for people who are boys in classes 1, 2, and 3\nboy_dummies_titanic = pd.get_dummies(titanic_df[\"BoyClass\"])\nboy_dummies_titanic.columns = [\"girl1\",\"girl2\",\"3rdGirls\",\"1stBoys\", \"2ndBoys\", \"3rdBoys\"]\ntitanic_df = titanic_df.join(boy_dummies_titanic)\n#drop every other column that doesn't involve boys\ntitanic_df.drop([\"girl1\",\"girl2\",\"3rdGirls\",\"BoyClass\"], axis = 1, inplace = True)\n\n#do the same thing but on the test dataframe\nboy_dummies_test = pd.get_dummies(test_df[\"BoyClass\"])\nboy_dummies_test.columns = [\"girl1\",\"girl2\",\"3rdGirls\",\"1stBoys\", \"2ndBoys\", \"3rdBoys\"]\ntest_df = test_df.join(boy_dummies_test)\ntest_df.drop([\"girl1\",\"girl2\",\"3rdGirls\",\"BoyClass\"], axis = 1, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"862c04c4-2547-4711-97bb-326bc092c302","collapsed":true,"_uuid":"50cafe957086bae805e1ea05af9450befc88ff80","trusted":false},"cell_type":"code","source":"#myMean = titanic_df[\"Fare\"].mean()\n#print(myMean)\n#test_df[\"Fare\"] = test_df[\"Fare\"].fillna(myMean)\n\n#here is where we drop all the columns that will not be useful in our prediction, given more time, I would like to do something with age\n#I plan on doing that in the future, because I think there is something useful there.\ntitanic_df.drop([\"Name\",\"Sex\",\"Age\",\"Embarked\",\"Male\",\"Parch\", \"SibSp\",\"ParchBinary\",\"SibSpBinary\",\"Pclass\",\"Class1\",\"Class2\",\"Class3\",\"ClassSex\",\"Female\",\"MasterMiss\",\"S\",\"1male\",\"2male\",\"3male\",\"Boy\"], axis=1, inplace=True)\n\ntest_df.drop([\"Name\",\"Sex\",\"Age\",\"Embarked\",\"Male\", \"Survived\",\"Parch\",\"SibSp\",\"ParchBinary\",\"SibSpBinary\",\"Pclass\",\"Class1\",\"Class2\",\"Class3\",\"ClassSex\",\"Female\",\"MasterMiss\",\"S\",\"1male\",\"2male\",\"3male\",\"Boy\"], axis=1, inplace=True)\n\n\ntitanic_df.head()\n# test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b382ea75-dc5f-49a7-b3fc-bb94db77e7ad","collapsed":true,"_uuid":"74917f16ebcf9a7bbca5d213a96c3867301de981"},"cell_type":"markdown","source":"Here are where I create the predictive models that will be used to make the prediction. The models chosen are logistic regression, K-nearest neighbors, random forest\nsupport vector machines and xgboost. I compiled them all together and used a voting prediciton model to make the final prediction."},{"metadata":{"_cell_guid":"eb461250-8126-4302-9666-d78aa7e75405","collapsed":true,"_uuid":"da2a042643013cbe513b7207863c1129e4777d68","trusted":false},"cell_type":"code","source":"X_train = titanic_df.drop(\"Survived\", axis=1)\nY_train = titanic_df[\"Survived\"]\nX_test = test_df.drop(\"PassengerId\", axis=1).copy()\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"710de0e8-9aec-4a78-aa34-768b561836b2","collapsed":true,"_uuid":"887469aa0fa49e85996dcf130fdc89fa2f46cb44","trusted":false},"cell_type":"code","source":"# Logistic Regression\n\nlogreg = LogisticRegression()\n\nlogreg.fit(X_train, Y_train)\n\nY1_pred = logreg.predict(X_test)\n\nlogreg.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bdf89a6e-f86d-4035-9506-1c1796b4d385","collapsed":true,"_uuid":"d8fe80921c7b84be5186452e8282c90044ac99bf","trusted":false},"cell_type":"code","source":"#K Nearest Neighbors with 7 neighbors\nknn = KNeighborsClassifier(n_neighbors = 7)\n\nknn.fit(X_train, Y_train)\n\nY2_pred = knn.predict(X_test)\n\nknn.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1272a8c9-4fa3-4e5e-a6b3-0b3065f58f21","collapsed":true,"_uuid":"e70765174c30ff0efff1fe36b26154d9ff378451","trusted":false},"cell_type":"code","source":"#Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\n\nrandom_forest.fit(X_train, Y_train)\n\nY3_pred = random_forest.predict(X_test)\n\nrandom_forest.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9c8de2ef-51e9-4ade-b0b3-c3bf4922aeb4","collapsed":true,"_uuid":"b21f544e116943ee95c5aa190a64e18a44eb5a96","trusted":false},"cell_type":"code","source":"#Support Vector Machines\n\nsvc = SVC()\n\nsvc.fit(X_train, Y_train)\n\nY4_pred = svc.predict(X_test)\n\nsvc.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ddc9b395-8fc2-40c0-b1c5-6b8f6311da82","collapsed":true,"_uuid":"02c94699e3221cb1a573dd19d51bfcd44e97ff6e","trusted":false},"cell_type":"code","source":"#Naive Bayes wasn't useful in this prediction\n\n#gaussian = GaussianNB()\n\n#gaussian.fit(X_train, Y_train)\n\n#Y5_pred = gaussian.predict(X_test)\n\n#gaussian.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"74e0ac2a-c6e0-4118-b5a6-acdd51b46fae","collapsed":true,"_uuid":"db70398399aca0efa41db5fe139e6d87ea05fd0f","trusted":false},"cell_type":"code","source":"#XGBoost\nxgb = XGBClassifier(base_score = 0.5, booster='gbtree')\n\nxgb.fit(X_train, Y_train)\n\nY6_pred = xgb.predict(X_test)\n\nxgb.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7e2ee175-f5f9-4f04-aa8a-27f937338f55","collapsed":true,"_uuid":"fd863d2d47223d1cd08160d55331a36839eb532d","trusted":false},"cell_type":"code","source":"#voting classifier (hard voting)\nvcr=VotingClassifier(estimators=[('lg',logreg),('xgb',xgb),('rf',random_forest),('knn',knn),('svc',svc)],voting='hard', weights = [1,2,3,2,1])\n\nvcr.fit(X_train, Y_train)\n\nY_pred = vcr.predict(X_test)\n\nprint(\"voting score\",vcr.score(X_train,Y_train))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"84ece6ee-0f59-48cd-a754-a5ecbe2a5054","collapsed":true,"_uuid":"8854fb0fc5906e832c53473d96a3a7f6505c139b","trusted":false},"cell_type":"code","source":"# get Correlation Coefficient for each feature using Logistic Regression\ncoeff_df = DataFrame(titanic_df.columns.delete(0))\ncoeff_df.columns = ['Features']\ncoeff_df[\"Coefficient Estimate\"] = pd.Series(logreg.coef_[0])\n\n# preview\ncoeff_df","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e5e405a5-ae70-44bd-a8ad-0175134078ff","collapsed":true,"_uuid":"50991c532c777461d3f4b5f78b1e5f086d32cba0","trusted":false},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n#        \"Survived\": test_df[\"Survived\"]\n    })\nsubmission.to_csv('titanic.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}