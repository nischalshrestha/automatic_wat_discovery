{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2aa60f5d-53f4-7c28-d299-e01d08dec6f8"
      },
      "source": [
        "This is my first entry on Kaggle. This is based mainly on the two tutorials available here, though I've restructured it a bit and used newer sklearn classes: https://www.dataquest.io/mission/74/getting-started-with-kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "31496a5b-f2a4-db9a-2658-1e009fa87a8a"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import re\n",
        "import operator\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "def convert_enum_to_numbers_from_list(df, column, enums):\n",
        "    value = 0\n",
        "    for enum in enums:\n",
        "        df.loc[df[column] == enum, column] = value\n",
        "        value = value + 1\n",
        "       \n",
        "def convert_enum_to_numbers(df, column):\n",
        "    convert_enum_to_numbers_from_list(df, column, df[column].unique())\n",
        "    \n",
        "def setMissingDataToMedian(df, column):\n",
        "    df[column] = df[column].fillna(df[column].median())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "636d935c-71e1-9fc6-0e81-25ad9f3f39d7"
      },
      "source": [
        "<h1>Look at the data</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "082b112c-ce7f-47f6-36c4-8acddec16795"
      },
      "outputs": [],
      "source": [
        "titanic = pandas.read_csv(\"../input/train.csv\")\n",
        "\n",
        "# Print the first 5 rows of the dataframe.\n",
        "print(titanic.describe()) # gives warning for NaNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7ce71430-0718-8b3d-89c4-3fd091366874"
      },
      "source": [
        "<h1>Deal with missing data</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "80f0c135-bc21-62df-1ab8-746649c72649"
      },
      "outputs": [],
      "source": [
        "def repair_missing_data(df):\n",
        "    setMissingDataToMedian(df, \"Age\")\n",
        "    setMissingDataToMedian(df, \"Fare\")\n",
        "\n",
        "repair_missing_data(titanic)\n",
        "print(titanic.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1a2d11c9-ddd9-e6c3-41b9-c8ae8203e350"
      },
      "source": [
        "<h1>Convert sex to numeric</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0392a0e3-6196-d449-f4b5-1301b1b725ad"
      },
      "outputs": [],
      "source": [
        "print(titanic[\"Sex\"].unique()) # just male and female\n",
        "\n",
        "def convert_sex_column(df):\n",
        "    convert_enum_to_numbers(df, \"Sex\")\n",
        "\n",
        "convert_sex_column(titanic)\n",
        "print(titanic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2761b7a2-fb65-c0b5-9f7f-8a6a860656ae"
      },
      "source": [
        "<h1>Convert embarked port to numeric</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "64550999-6c32-282f-8905-6809e98b7aa7"
      },
      "outputs": [],
      "source": [
        "print(titanic[\"Embarked\"].unique()) # S, C, Q or n/a\n",
        "\n",
        "# shows that there are only 2 passengers (both survivors), so add to the most common class (S)\n",
        "print(titanic[pandas.isnull(titanic['Embarked'])])\n",
        "\n",
        "def convert_embarked_column(df):\n",
        "    df[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")\n",
        "    convert_enum_to_numbers_from_list(df, \"Embarked\", ['S', 'C', 'Q'])\n",
        "\n",
        "convert_embarked_column(titanic)\n",
        "print(titanic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "28470317-f123-53fe-2366-4e27de1d565a"
      },
      "source": [
        "<h1>Make predictions with linear regression</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c3d36f94-c4db-e07b-6512-9104d54d03f7"
      },
      "outputs": [],
      "source": [
        "# The columns we'll use to predict the target\n",
        "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
        "\n",
        "# Initialize our algorithm class\n",
        "alg = LinearRegression()\n",
        "# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.\n",
        "# We set random_state to ensure we get the same splits every time we run this.\n",
        "kf = KFold(n_splits=3)\n",
        "\n",
        "predictions = []\n",
        "for train, test in kf.split(titanic):\n",
        "    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.\n",
        "    train_predictors = titanic[predictors].iloc[train, :]\n",
        "    # The target we're using to train the algorithm.\n",
        "    train_target = titanic[\"Survived\"].iloc[train]\n",
        "    # Training the algorithm using the predictors and target.\n",
        "    alg.fit(train_predictors, train_target)\n",
        "    # We can now make predictions on the test fold\n",
        "    test_predictions = alg.predict(titanic[predictors].iloc[test, :])\n",
        "    predictions.append(test_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d34830b7-4138-1d5b-9833-fcd89820ccf3"
      },
      "source": [
        "<h1>Evaluate error</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d28d40d0-d780-7c2d-7489-fd5f45147a7b"
      },
      "outputs": [],
      "source": [
        "# The predictions are in three separate numpy arrays.  Concatenate them into one.  \n",
        "# We concatenate them on axis 0, as they only have one axis.\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# Map predictions to outcomes (only possible outcomes are 1 and 0)\n",
        "predictions[predictions > 0.5] = 1\n",
        "predictions[predictions <= 0.5] = 0\n",
        "accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
        "\n",
        "print(accuracy) # 78.34%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d1d8d77a-9939-d86b-8c06-6ff77f341997"
      },
      "source": [
        "<h1>Logistic Regression</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ebd2a283-80aa-1626-50f6-7c21a237c962"
      },
      "outputs": [],
      "source": [
        "# Initialize our algorithm\n",
        "alg = LogisticRegression(random_state=1)\n",
        "# Compute the accuracy score for all the cross validation folds.  (much simpler than what we did before!)\n",
        "scores = model_selection.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
        "# Take the mean of the scores (because we have one for each fold)\n",
        "print(scores.mean()) # 78.79%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5c589e5f-678f-e21b-4c4e-1492c7951f00"
      },
      "source": [
        "<h1>Processing The Test Set</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "62f1a572-9420-2b0b-b290-b91a07b96303"
      },
      "outputs": [],
      "source": [
        "titanic_test = pandas.read_csv(\"../input/test.csv\")\n",
        "repair_missing_data(titanic_test)\n",
        "convert_sex_column(titanic_test)\n",
        "convert_embarked_column(titanic_test)\n",
        "print(titanic_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "37c7a965-63a5-36c3-a18f-e13d0b2bcd2f"
      },
      "source": [
        "<h1>Generating A Submission File</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "36800a80-3089-053c-bccd-f5a9cfb2da05"
      },
      "outputs": [],
      "source": [
        "# Train the algorithm using all the training data\n",
        "alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
        "\n",
        "# Make predictions using the test set.\n",
        "predictions = alg.predict(titanic_test[predictors])\n",
        "\n",
        "# Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
        "submission = pandas.DataFrame({\n",
        "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
        "        \"Survived\": predictions\n",
        "    })\n",
        "\n",
        "submission.to_csv(\"titanic.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ae3fd43d-1a55-4f42-1f9b-6e5d71f85cf5"
      },
      "source": [
        "<h1>Implementing A Random Forest</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3b2b4158-d642-ae61-d682-f199b891075d"
      },
      "outputs": [],
      "source": [
        "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
        "alg = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, min_samples_leaf=1)\n",
        "scores = model_selection.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=kf)\n",
        "print(scores.mean()) # 78.56 %"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9b4ae5ae-3675-fcdd-3b0e-98ea8fd076f2"
      },
      "source": [
        "<h1>Parameter Tuning</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1a8eabc9-8c85-e562-c47a-a742c2d4d178"
      },
      "outputs": [],
      "source": [
        "alg = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=4, min_samples_leaf=2)\n",
        "scores = model_selection.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=kf)\n",
        "print(scores.mean()) # 81.59%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d6506e73-617c-689b-10a5-16222f73c72d"
      },
      "source": [
        "<h1>Generating New Features</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8870a151-9358-91fd-45e0-e7b0f3d830b9"
      },
      "outputs": [],
      "source": [
        "def add_new_features(df):\n",
        "    # Generating a familysize column\n",
        "    df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"]\n",
        "    # The .apply method generates a new series\n",
        "    df[\"NameLength\"] = df[\"Name\"].apply(lambda x: len(x))\n",
        "    \n",
        "add_new_features(titanic)\n",
        "add_new_features(titanic_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "08580842-4446-cd0d-ccb3-d3912f8c270d"
      },
      "source": [
        "<h1>Using The Title</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "842a3da0-e665-8399-5e92-5eec58347fd4"
      },
      "outputs": [],
      "source": [
        "# A function to get the title from a name.\n",
        "def get_title(name):\n",
        "    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n",
        "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
        "    # If the title exists, extract and return it.\n",
        "    if title_search:\n",
        "        return title_search.group(1)\n",
        "    return \"\"\n",
        "\n",
        "def add_title_column(df):\n",
        "    # Get all the titles and print how often each one occurs.\n",
        "    titles = df[\"Name\"].apply(get_title)\n",
        "    print(pandas.value_counts(titles))\n",
        "\n",
        "    # Map each title to an integer.  Some titles are very rare, and are compressed into the same codes as other titles.\n",
        "    # This differs from the mapping at dataquest because I have grouped the rare French titles (Mlle and Mme) with their English equivalents,\n",
        "    # and all nobility together (we already have a field for sex)\n",
        "    title_mapping = {\n",
        "        \"Mr\": 1,\n",
        "        \"Miss\": 2,\n",
        "        \"Mlle\": 2,\n",
        "        \"Ms\": 2,\n",
        "        \"Mrs\": 3,\n",
        "        \"Mme\": 3,\n",
        "        \"Master\": 4,\n",
        "        \"Dr\": 5,\n",
        "        \"Rev\": 6,\n",
        "        \"Major\": 7,\n",
        "        \"Col\": 7,\n",
        "        \"Capt\": 7,\n",
        "        \"Don\": 8,\n",
        "        \"Dona\": 8,\n",
        "        \"Sir\": 8,\n",
        "        \"Lady\": 8,\n",
        "        \"Countess\": 8,\n",
        "        \"Jonkheer\": 8}\n",
        "    for k,v in title_mapping.items():\n",
        "        titles[titles == k] = v\n",
        "\n",
        "    # Verify that we converted everything.\n",
        "    print(pandas.value_counts(titles))\n",
        "\n",
        "    # Add in the title column.\n",
        "    df[\"Title\"] = titles\n",
        "\n",
        "add_title_column(titanic)\n",
        "add_title_column(titanic_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "59fde909-947a-18a4-3311-b23556adb0fd"
      },
      "source": [
        "<h1>Family Groups</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f8e3c7ea-0761-3023-d2ef-0148c0a7c181"
      },
      "outputs": [],
      "source": [
        "family_id_mapping = {}\n",
        "\n",
        "# A function to get the id given a row\n",
        "def get_family_id(row):\n",
        "    # Find the last name by splitting on a comma\n",
        "    last_name = row[\"Name\"].split(\",\")[0]\n",
        "    # Create the family id\n",
        "    family_id = \"{0}{1}\".format(last_name, row[\"FamilySize\"])\n",
        "    # Look up the id in the mapping\n",
        "    if family_id not in family_id_mapping:\n",
        "        if len(family_id_mapping) == 0:\n",
        "            current_id = 1\n",
        "        else:\n",
        "            # Get the maximum id from the mapping and add one to it if we don't have an id\n",
        "            current_id = (max(family_id_mapping.items(), key=operator.itemgetter(1))[1] + 1)\n",
        "        family_id_mapping[family_id] = current_id\n",
        "    return family_id_mapping[family_id]\n",
        "\n",
        "def set_family_ids(df):\n",
        "    family_id_mapping = {}\n",
        "    # Get the family ids with the apply method\n",
        "    family_ids = df.apply(get_family_id, axis=1)\n",
        "\n",
        "    # There are a lot of family ids, so we'll compress all of the families under 3 members into one code.\n",
        "    family_ids[titanic[\"FamilySize\"] < 3] = -1\n",
        "\n",
        "    # Print the count of each unique id.\n",
        "    print(pandas.value_counts(family_ids))\n",
        "\n",
        "    df[\"FamilyId\"] = family_ids\n",
        "    \n",
        "set_family_ids(titanic)\n",
        "set_family_ids(titanic_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0a840239-045b-965e-10e3-b15960532f0f"
      },
      "source": [
        "<h1>Finding The Best Features</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0510cb24-9196-58f4-6916-2b0d00b6653c"
      },
      "outputs": [],
      "source": [
        "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\", \"NameLength\"]\n",
        "\n",
        "# Perform feature selection\n",
        "selector = SelectKBest(f_classif, k=5)\n",
        "selector.fit(titanic[predictors], titanic[\"Survived\"])\n",
        "\n",
        "# Get the raw p-values for each feature, and transform from p-values into scores\n",
        "scores = -np.log10(selector.pvalues_)\n",
        "\n",
        "# Plot the scores.  See how \"Pclass\", \"Sex\", \"Title\", and \"Fare\" are the best?\n",
        "plt.bar(range(len(predictors)), scores)\n",
        "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
        "plt.show()\n",
        "\n",
        "# Pick only the best features.\n",
        "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]\n",
        "\n",
        "alg = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=8, min_samples_leaf=4)\n",
        "\n",
        "scores = model_selection.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=kf)\n",
        "print(scores.mean()) # 83.73%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d356002c-8f7e-0cf4-7657-095df1ef2bdb"
      },
      "source": [
        "<h1>Ensembling</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f02404c9-ae8d-1a36-da22-3cfebe5faabc"
      },
      "outputs": [],
      "source": [
        "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]\n",
        "\n",
        "# The algorithms we want to ensemble.\n",
        "# We're using the more linear predictors for the logistic regression, and everything with the gradient boosting classifier.\n",
        "algorithms = [\n",
        "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]],\n",
        "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
        "]\n",
        "\n",
        "def run_algorithms(train, test, test_df):\n",
        "    full_predictions = []\n",
        "    train_target = titanic[\"Survived\"].iloc[train]\n",
        "    for alg, predictors in algorithms:\n",
        "        # Fit the algorithm on the training data.\n",
        "        alg.fit(titanic[predictors].iloc[train,:], train_target)\n",
        "        # Select and predict on the test fold.  \n",
        "        # The .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error.\n",
        "        full_predictions.append(alg.predict_proba(test_df[predictors].iloc[test,:].astype(float))[:,1])\n",
        "    # The gradient boosting classifier generates better predictions, so we weight it higher.\n",
        "    predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
        "    # Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction.\n",
        "    predictions[predictions <= .5] = 0\n",
        "    predictions[predictions > .5] = 1\n",
        "    predictions = predictions.astype(int)\n",
        "    return predictions\n",
        "\n",
        "all_predictions = []\n",
        "for train, test in kf.split(titanic):\n",
        "    all_predictions.append(run_algorithms(train, test, titanic))\n",
        "\n",
        "# Put all the predictions together into one array.\n",
        "all_predictions = np.concatenate(all_predictions, axis=0)\n",
        "\n",
        "# Compute accuracy by comparing to the training data.\n",
        "accuracy = sum(all_predictions[all_predictions == titanic[\"Survived\"]]) / len(all_predictions)\n",
        "print(accuracy) # 82.04%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "dbeeb648-9467-6e3f-f39c-0b95e019c2f4"
      },
      "source": [
        "<h1>Predicting On The Test Set</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b8048da5-6566-d7c5-0e22-f7121e8dc13c"
      },
      "outputs": [],
      "source": [
        "train = range(len(titanic))\n",
        "test = range(len(titanic_test))\n",
        "predictions = run_algorithms(train, test, titanic_test)\n",
        "\n",
        "submission = pandas.DataFrame({\n",
        "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
        "        \"Survived\": predictions\n",
        "    })\n",
        "submission.to_csv(\"titanic2.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}