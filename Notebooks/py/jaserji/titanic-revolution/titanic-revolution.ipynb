{"cells":[{"metadata":{"_uuid":"3b4333d72e2e5e498252914db46776a9bc5a6503"},"cell_type":"markdown","source":"**0. Objective**  \nHello folks!! This is my first \"public\" kernel in kaggle. I am really happy to be part of this community and I hope that we all can learn new things and techniques \"doing and commenting\"\n"},{"metadata":{"_uuid":"7ea3f8a130e5be47ab553d5a7db48f13d638f7fd"},"cell_type":"markdown","source":"**1. Introduction**  \nIn this challenge, we will study the probabilities of survive or die for all Titanic passengers depending in different factors like: Name. Gender, Class, Rate,...\n2. Reading Data\n3. Exploratory Data Analysis and Data Cleaning (Engineernig features)  \n4. Create & Compare ML Models  \n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":"# Loading libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm as cm\nimport string\nimport seaborn as sns\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9f93a4d0e0da64fd866bbd6a274e55c8cc90055"},"cell_type":"markdown","source":"**2. Reading Data**  \nFrom input folder we read training and test datasert"},{"metadata":{"trusted":true,"_uuid":"221346dcd47c257991c42af3f70d351cd57b868a"},"cell_type":"code","source":"# Reading train.csv and taking a look!\nprint(os.listdir(\"../input\"))\ntrain_ori = pd.read_csv(\"../input/train.csv\")\ntrain_ori.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca6f0ee02baa5e5032b64d03084584375c82c074"},"cell_type":"code","source":"# Read test.csv\ntest_ori = pd.read_csv(\"../input/test.csv\")\ntest_ori.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0a472061a22b8a1e2a387b181519f3e476c2318"},"cell_type":"markdown","source":"**3. Exploratory Data Analysis and Data Cleaning**  "},{"metadata":{"_uuid":"4a82bd6904453d41988fcba62dca9fb6b0015793"},"cell_type":"markdown","source":"**3.1 Train and test data set info**  "},{"metadata":{"trusted":true,"_uuid":"632b7ce9eeaeb0792547fe3a1c5f391cecf1c9f2","scrolled":true},"cell_type":"code","source":"train_ori.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b91d81a36084373a99c166c397103e4f09045218"},"cell_type":"code","source":"#We will check NA values in training set\nprint(train_ori.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"037c736c3505e8844cf353202757b4cebd97dd17"},"cell_type":"code","source":"test_ori.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2fbd69939e5221dd12e0c5cd2b4463ce7679998c"},"cell_type":"code","source":"#We will check NA values in test set\nprint(test_ori.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5b97c9fec4176c53a94bf3a55e9b54d82df2a04"},"cell_type":"markdown","source":"For our analysis we are going to use the following variables/columns from training dataset:  \nPclass,\tName, Sex, Age, SibSp, Parch, Fare, Cabin, Embarked"},{"metadata":{"_uuid":"36ac0796a718928a902e474fa2aec2a795eb913c"},"cell_type":"markdown","source":" Fisrtly, I am willing to check the percentage of  survival in the training dataset!!"},{"metadata":{"trusted":true,"_uuid":"75309e22a957daada7eddc3565b00256d9c7049d"},"cell_type":"code","source":"train_ori.Survived.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"16998fb2a4affd5f066488b59e3f1890d8c0e54f"},"cell_type":"markdown","source":"Only the 38% of passengers survived..."},{"metadata":{"_uuid":"7f0e787cb0fe1195f8dd6e70132daa63ffe2c6ce"},"cell_type":"markdown","source":"**3.2. Variables**  \n**3.2.1. Pclass**   \nWe will check how Pclass is correlated with the Survived\n"},{"metadata":{"trusted":true,"_uuid":"0f350ba1ce2e771069ba0991d80b441757e5099b"},"cell_type":"code","source":"#The number of passengers for each Pclass are:  \nsns.countplot(x=\"Pclass\", data=train_ori)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c675ffdf8adc9fe99d584c76c285ca1a73f897ea"},"cell_type":"code","source":"# The percentage of passengers survived for each Pclass:\nsns.catplot(y=\"Survived\", col=\"Pclass\", data=train_ori, kind=\"bar\", ci=None, aspect=.5)\n#sns.catplot(x=\"Sex\", y=\"Survived\", col=\"Pclass\", data=train_ori, kind=\"bar\", ci=None, aspect=.8)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c211dd50c22187e64c201cffbd73d1c3304e55ac"},"cell_type":"markdown","source":"**3.2.2. Name**  \nFrom this column we are going to extract the Title (Engineering feature). The Name column will be dropped from the analysis but before that, we are going to extract the Title information from each passenger and we are going to create a new colum named \"Title\" with this information. The Title is the string between the \", \" and the \".\" characters in the column Name."},{"metadata":{"trusted":true,"_uuid":"80c1c184115d3d6df88e5680565c2160a97d6e79"},"cell_type":"code","source":"train_ori[\"Title\"]=(train_ori[\"Name\"].str.split(', ').str[1]).str.split('. ').str[0]\ntrain_ori.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d1342ba71cf9263817616e3677b6f4a3345a4d6"},"cell_type":"markdown","source":"Once we have created the Title column we can check what we have got in this new column:"},{"metadata":{"trusted":true,"_uuid":"ea9859b9f3042a57125a6591b9937ecaeff177bb"},"cell_type":"code","source":"# The initial different values for Title column are:\nprint(np.unique(np.array(train_ori[\"Title\"])))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b2daed3eba2ba33f58c6ed64b68e94ce194f8e5"},"cell_type":"markdown","source":"The idea is to factorize this column to have only 3 values: [\"Mr\",\"Mrs\",\"Miss\"]. For doing that we have applied the following code:"},{"metadata":{"trusted":true,"_uuid":"4c5499c1ddca2660715bbaa5842170bc71e3f10a"},"cell_type":"code","source":"# Factorize Title column as [\"Mr\",\"Mrs\",\"Miss\"]\n# We will factorize those values for getting only 3 values: Man, married Woman or unmarried Woman\ntrain_ori.loc[(train_ori[\"Title\"] == \"Capt\") | (train_ori[\"Title\"] == \"Col\") | (train_ori[\"Title\"] == \"Don\") | \n              (train_ori[\"Title\"] == \"Jonkheer\") \n    | (train_ori[\"Title\"] == \"Major\") | (train_ori[\"Title\"] == \"Master\") | (train_ori[\"Title\"] == \"Mr\") |\n              (train_ori[\"Title\"] == \"Rev\") | (train_ori[\"Title\"] == \"Sir\")\n    | (train_ori[\"Title\"] == \"th\"),\"Title\"]= \"Mr\"\ntrain_ori.loc[(train_ori[\"Title\"] == \"Lady\") | (train_ori[\"Title\"] == \"Mme\"),\"Title\"] = \"Mrs\"\ntrain_ori.loc[(train_ori[\"Title\"] == \"Mlle\") | (train_ori[\"Title\"] == \"Ms\") ,\"Title\"] = \"Miss\"\ntrain_ori.loc[(train_ori[\"Title\"] == \"Dr\") & (train_ori[\"Sex\"] == \"female\") ,\"Title\"] = \"Mrs\"\ntrain_ori.loc[(train_ori[\"Title\"] == \"Dr\") & (train_ori[\"Sex\"] == \"male\") ,\"Title\"] = \"Mr\"\n\nunique_elements, counts_elements = np.unique(np.array(train_ori[\"Title\"]), return_counts=True)\nprint(unique_elements, counts_elements)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e50c0755cbbdafa73df5ee19e41b7641b3901621"},"cell_type":"code","source":"#The number of passengers for each Title are:  \nsns.countplot(x=\"Title\", data=train_ori)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80091958bd9004165acdbc6d54d7819e30c2ff1e"},"cell_type":"markdown","source":"As we can see in the last output we conclude that we have found: 185 Miss, 578 Mr and 128 Mrs"},{"metadata":{"trusted":true,"_uuid":"3ee34d1c7294afbe76473533d06e78c5a6e46037"},"cell_type":"code","source":"# The percentage of passengers survived for each Title:\nsns.catplot(y=\"Survived\", col=\"Title\", data=train_ori, kind=\"bar\", ci=None, aspect=.5)\n#sns.catplot(x=\"Sex\", y=\"Survived\", col=\"Title\", data=train_ori, kind=\"bar\", ci=None, aspect=.8)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed9f4d8d7a7b4cd8e63789cbae0e741131833db7"},"cell_type":"markdown","source":"**3.2.3. Sex**  \nSex: male or female"},{"metadata":{"_uuid":"8c775f9a998b71b4a616ddccdabe9a233798b151","trusted":true},"cell_type":"code","source":"#The number of passengers for each Sex are:  \nsns.countplot(x=\"Sex\", data=train_ori)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94b35665209dece088f98f3eb892d33a3930af39"},"cell_type":"code","source":"# The percentage of passengers survived for each Sex:\nsns.catplot(y=\"Survived\", col=\"Sex\", data=train_ori, kind=\"bar\", ci=None, aspect=.5)\n#sns.catplot(x=\"Sex\", y=\"Survived\", col=\"Title\", data=train_ori, kind=\"bar\", ci=None, aspect=.8)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0fe99dc1457a5141f8e3820f7b14bace65416eb8"},"cell_type":"markdown","source":"**3.2.4. Age**  \nAge: We will factorize in child, teenagers or adults\nAs we know from 3.1 here we have 177 NaN values. We will use the mean of each Title value for adding this value in the missing observations."},{"metadata":{"trusted":true,"_uuid":"5c28be14c9a2dd621243d8eae29c61cf471fcbbf"},"cell_type":"code","source":"# We calculate the median age per Title column and we will complete with these ages\nmrage=train_ori[train_ori[\"Title\"] == \"Mr\"][\"Age\"].mean()\nmrsage=train_ori[train_ori[\"Title\"] == \"Mrs\"][\"Age\"].mean()\nmissage=train_ori[train_ori[\"Title\"] == \"Miss\"][\"Age\"].mean()\nprint(\"mean age for Mr: \",mrage)\nprint(\"mean age for Mrs: \",mrsage)\nprint(\"mean age for Miss: \",missage)\n\ntrain_ori.loc[train_ori[\"Title\"] == \"Mr\",\"Age\"] = train_ori.loc[train_ori[\"Title\"] == \"Mr\",\"Age\"].fillna(mrage)\ntrain_ori.loc[train_ori[\"Title\"] == \"Mrs\",\"Age\"] = train_ori.loc[train_ori[\"Title\"] == \"Mrs\",\"Age\"].fillna(mrsage)\ntrain_ori.loc[train_ori[\"Title\"] == \"Miss\",\"Age\"] = train_ori.loc[train_ori[\"Title\"] == \"Miss\",\"Age\"].fillna(missage)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23fa6b535110cc0d5d87ac598a1b0a8626ea555f"},"cell_type":"code","source":"train_ori.loc[(train_ori[\"Age\"] >= -0.001) & (train_ori[\"Age\"] < 15),\"Age\"] = 0\ntrain_ori.loc[(train_ori[\"Age\"] >= 15) & (train_ori[\"Age\"] < 18),\"Age\"] = 1\ntrain_ori.loc[(train_ori[\"Age\"] >= 18) ,\"Age\"] = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e41a362438d477e1cc376d6ee87093f9e3ac250"},"cell_type":"code","source":"#The number of passengers for each Age are:  \nsns.countplot(x=\"Age\", data=train_ori)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b79adbab1b61758ca09f5dd4ecd225c02be2c278"},"cell_type":"code","source":"# The percentage of passengers survived for each Age:\nsns.catplot(y=\"Survived\", col=\"Age\", data=train_ori, kind=\"bar\", ci=None, aspect=.5)\n#sns.catplot(x=\"Sex\", y=\"Survived\", col=\"Title\", data=train_ori, kind=\"bar\", ci=None, aspect=.8)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01a9481bb5bcfaf755425882df8cb181ae925645"},"cell_type":"markdown","source":"**3.2.5. SibSp & Parch**  \nNow we are going to combine SibSp and Parch in only one colum: FamilySize = SibSp + Parch + 1 indicanding the family size of each passenger"},{"metadata":{"trusted":true,"_uuid":"dc6a7b03626d80e87920c2d739024bb228411036"},"cell_type":"code","source":"train_ori[\"FamilySize\"]= train_ori[\"SibSp\"] + train_ori[\"Parch\"] + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d79eb0115c08c121c73c2d63b9f3baba7a19ab1"},"cell_type":"code","source":"#The number of passengers for each FamilySize are:  \nsns.countplot(x=\"FamilySize\", data=train_ori)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac03aee3c59c3ade5f503d301e9985b34b0922c5"},"cell_type":"code","source":"# The percentage of passengers survived for each FamilySize:\nsns.catplot(y=\"Survived\", col=\"FamilySize\", data=train_ori, kind=\"bar\", ci=None, aspect=.8)\n#sns.catplot(x=\"Sex\", y=\"Survived\", col=\"Title\", data=train_ori, kind=\"bar\", ci=None, aspect=.8)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38211aa6d41a687c796e81ff3e680ee0220f4b5d"},"cell_type":"markdown","source":"**3.2.6. Fare**  \nwe will investigate if this colums impatcs on the Survived result. Firstable we will check their values for training passengers:"},{"metadata":{"trusted":true,"_uuid":"fdd1a5e85fc55e2acf32667ff34d3f7703274708"},"cell_type":"code","source":"print(\"#of differents Fares:\",len(train_ori[\"Fare\"].unique()))\nprint(\"Max Fare:\",train_ori[\"Fare\"].max())\nprint(\"Min Fare:\",train_ori[\"Fare\"].min())\nprint(\"Mean Fare:\",train_ori[\"Fare\"].mean())\nsns.distplot(train_ori['Fare'],kde=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd23f616537eb303065283ed325c010756468b93"},"cell_type":"markdown","source":"The first observation about Fare is that  most of the values are less that 100. "},{"metadata":{"trusted":true,"_uuid":"8b10d663ebecc9c0304b9001e9efeb48e2278fd9"},"cell_type":"code","source":"plt.scatter(train_ori['Fare'], train_ori['FamilySize'],c=train_ori['Survived'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78d357bc4186b5962ae4075f7161d19576d78123"},"cell_type":"markdown","source":"Besides that, FamilySize seems not depend on the Fare paid for that passenger, then price may be per person."},{"metadata":{"_uuid":"5b2b18c18d732ecc696e78a22afd8ba361b8b8a7"},"cell_type":"markdown","source":"**3.2.7. Cabin**  \nIn this column we have many NaN values (687) in training set. We can asume that they are two categories, one with cabin assgined and other with cabin not assigned. With this information we have created a new column call \"CabinAssigned\""},{"metadata":{"trusted":true,"_uuid":"a88589eb614966dd5f3707fb9d380c33955f8540"},"cell_type":"code","source":"train_ori['CabinAssigned'] = np.where(train_ori.Cabin.isnull(), 0, 1)\ntrain_ori.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e411c4a4123a6f5f59b51a796c0a399242e81948"},"cell_type":"code","source":"sns.countplot(x=\"CabinAssigned\", data=train_ori)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"003286fb4175b1e3f522f3364e65247215af975b"},"cell_type":"code","source":"# The percentage of passengers survived for each CabinAssigned:\nsns.catplot(y=\"Survived\", col=\"CabinAssigned\", data=train_ori, kind=\"bar\", ci=None, aspect=.5)\n#sns.catplot(x=\"Sex\", y=\"Survived\", col=\"CabinAssigned\", data=train_ori, kind=\"bar\", ci=None, aspect=.8)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e58c4b87200cc5125db6bf924c811f5f3f5c882c"},"cell_type":"markdown","source":"**3.2.8. Embarked**  \nEmbarked: Indicating the port where that passenger embarked. In this column there are two NaN values in Training set. For Embarked NA values we will print both observations with NA vlaue in Embarked column, to identify the strategy to fill those values"},{"metadata":{"trusted":true,"_uuid":"17ee4b35aefd8989711afbc0f100aeabad5fa30e"},"cell_type":"code","source":"# For Embarked column NA we will apply logic for avoid the NA value.\ntrain_ori[train_ori[\"Embarked\"].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f56f2e2ead706bb458a22e60dfc8a4dbb673cc1"},"cell_type":"markdown","source":"We will filter the training dataset with the other values for those two observations."},{"metadata":{"trusted":true,"_uuid":"3a41249bcd17289fee5068de6410a3b0d3d8c7b8"},"cell_type":"code","source":"train_ori.loc[(train_ori[\"Age\"] == 2.0) & (train_ori[\"Sex\"] == 'female') & (train_ori[\"FamilySize\"] == 1) & (train_ori[\"Pclass\"] == 1)& (train_ori[\"CabinAssigned\"] == 1) & (train_ori[\"Fare\"] >= 75) & (train_ori[\"Fare\"] <= 85)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c66a7c2445f1c7a2cffd042ef71ef0efc0fd44e"},"cell_type":"markdown","source":"but we cannot find any interesting pattern. Then, we will elimininate these two observations."},{"metadata":{"trusted":true,"_uuid":"d618b59fc22c65f908ce1d1483cfe1aa500f6f5b"},"cell_type":"code","source":"train_ori = train_ori[pd.notnull(train_ori['Embarked'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a17ac6eb68fc50468a001c3f5a6c10098d6fa77a"},"cell_type":"code","source":"sns.countplot(x=\"Embarked\", data=train_ori)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8db011c7b858e10ed67f810d43e1ef6467cc225e"},"cell_type":"code","source":"# The percentage of passengers survived for each Embarked:\nsns.catplot(y=\"Survived\", col=\"Embarked\", data=train_ori, kind=\"bar\", ci=None, aspect=.5)\n#sns.catplot(x=\"Sex\", y=\"Survived\", col=\"Embarked\", data=train_ori, kind=\"bar\", ci=None, aspect=.8)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4270dd99d1451e70f09baad0b73d1c38fc5c4ca1"},"cell_type":"markdown","source":"**3.3. Clean columns**  \nThe next step is to remove some columns that we want to discard because they are not useful for the analysis: \"Name\", \"PasengerId\" ,\"Ticket\", \"Cabin\", \"SibSp\" and \"Parch\""},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"3a1e0c13dc63621274817ae7ae56e79f0147157a"},"cell_type":"code","source":"train = train_ori.drop(['Name','PassengerId','Ticket','SibSp','Cabin','Parch'],axis=1)\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d9f216bf8455f9a8541832fd5591187c178bd2a"},"cell_type":"markdown","source":"**3.4. Factorize columns Embarked, Sex and Title**  "},{"metadata":{"trusted":true,"_uuid":"614e87405062b598475fb7f093c832d82be30eb2"},"cell_type":"code","source":"# Factorize columns \nprint(train.head(10))\ntrain[\"Embarked\"], uniques = pd.factorize(train[\"Embarked\"])\ntrain[\"Sex\"], uniques = pd.factorize(train[\"Sex\"])\ntrain[\"Title\"], uniques = pd.factorize(train[\"Title\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d9015923d5ee2b3ed9c4b3732f3c8831e56db0d"},"cell_type":"markdown","source":"**3.5. For Fare and Ages columns we will get intervals before factoring**"},{"metadata":{"trusted":true,"_uuid":"15e335b01ddfa495713f27d907cee9216c51dba7"},"cell_type":"code","source":"# Get intervals for factoring Fares column\npd.qcut(train[\"Fare\"], 4).value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3fdf171c307a6597f9ec27bb61b759673d728b0d","_kg_hide-input":false},"cell_type":"code","source":"train.loc[(train[\"Fare\"] >= -0.001) & (train[\"Fare\"] < 7.896),\"Fare\"] = 0\ntrain.loc[(train[\"Fare\"] >= 7.896) & (train[\"Fare\"] < 14.454),\"Fare\"] = 1\ntrain.loc[(train[\"Fare\"] >= 14.454) & (train[\"Fare\"] < 31.0),\"Fare\"] = 2\ntrain.loc[(train[\"Fare\"] >= 31.0) ,\"Fare\"] = 3\n\ntrain['Fare'] = train['Fare'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"68c2b75d0d9ab80a1344f3d6ecb823ca8aab151b"},"cell_type":"markdown","source":"**3.6. The final training dataset after cleaning data is shown below**"},{"metadata":{"trusted":true,"_uuid":"9e2877d2a383f3629c1eed64f71ffd2e5481a203"},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af69bd4268d20bdba15bdeb4c2e993ff6f5cfe87"},"cell_type":"code","source":"corr = train.corr()\n\n# Generate a mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n# Draw the heatmap with the mask and correct aspect ratio\n# cmap=cmap,\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"72e7f070a60b1180e357bb5efd553ad5eff91c1d"},"cell_type":"code","source":"train.corr()[\"Survived\"]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5291f0650da2aa1c9ad74c734a736354859b0d4c"},"cell_type":"markdown","source":"**Seeing the matrix correlation we can see that Sex and Title has the biggest correlation with Survived variable**"},{"metadata":{"_uuid":"0566a67ceaa10ba07186f0ae311219a7c8f06ca1"},"cell_type":"markdown","source":"**4. Create & Compare ML Models**  \nNow we are going to create our models. For doing that we are going to create our subsets: Training and Validation dataset. "},{"metadata":{"trusted":true,"_uuid":"2e77b6c6bc7a4c588b21f5239b475a479bdb0046"},"cell_type":"code","source":"train.head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"107e2d873ecac59e5b0484f93688c01efb485240"},"cell_type":"code","source":"# extract most important features and target for cross validation\nfeatures = train.drop(('Survived'), axis=1)\ntarget = train['Survived'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c452161e9eafc2603fb13d570f67f5e52733f9d"},"cell_type":"code","source":"from sklearn import model_selection, ensemble, svm\nimport xgboost as xgb\n\n# initialise classifiers\nrf_clf = ensemble.RandomForestClassifier(n_estimators=100, random_state=0)\net_clf = ensemble.ExtraTreesClassifier(n_estimators=100, random_state=0)\ngb_clf = ensemble.GradientBoostingClassifier(n_estimators=100, random_state=0)\nada_clf = ensemble.AdaBoostClassifier(n_estimators=100, random_state=0)\nsvm_clf = svm.LinearSVC(C=0.1,random_state=0)\nxgb_clf = xgb.XGBClassifier(n_estimators=100)\n\ne_clf = ensemble.VotingClassifier(estimators=[('xgb', xgb_clf), ('rf',rf_clf),\n                                              ('et',et_clf), ('gbc',gb_clf), ('ada',ada_clf), ('svm',svm_clf)])\n\n# score using cross validation\nclf_list = [xgb_clf, rf_clf, et_clf, gb_clf, ada_clf, svm_clf, e_clf]\nname_list = ['XGBoost', 'Random Forest', 'Extra Trees', 'Gradient Boosted', 'AdaBoost', 'Support Vector Machine', 'Ensemble']\n\nfor clf, name in zip(clf_list,name_list) :\n    scores = model_selection.cross_val_score(clf, features, target, cv=10)\n    print(\"Accuracy: %0.2f +/- %0.2f (%s 95%% CI)\" % (scores.mean(), scores.std()*2, name))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3164a0187b302200c98546a393524fee24cd0d46"},"cell_type":"markdown","source":"**We choose SVM for as our predictor:**"},{"metadata":{"trusted":true,"_uuid":"8f5d74db7975740b18199bf1c42f36cadecb224a"},"cell_type":"code","source":"# fit ensemble classifier\nsvm_clf = svm_clf.fit(features,target)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3da8a4b3d0d5f44e2685bcc200b5bb8cc1013cbe"},"cell_type":"markdown","source":"**5. Clean Test Set**"},{"metadata":{"trusted":true,"_uuid":"69bbbe3774e748ad16bd7cf1aeba2d502a9d5f24"},"cell_type":"code","source":"# Process test dataset\n# Create Title column\ntest_ori.head(5)\ntest_ori[\"Title\"]=(test_ori[\"Name\"].str.split(', ').str[1]).str.split('. ').str[0]\n\ntest_ori.loc[(test_ori[\"Title\"] == \"Capt\") | (test_ori[\"Title\"] == \"Col\") | (test_ori[\"Title\"] == \"Don\") | \n              (test_ori[\"Title\"] == \"Jonkheer\") \n    | (test_ori[\"Title\"] == \"Major\") | (test_ori[\"Title\"] == \"Master\") | (test_ori[\"Title\"] == \"Mr\") |\n              (test_ori[\"Title\"] == \"Rev\") | (test_ori[\"Title\"] == \"Sir\")\n    | (test_ori[\"Title\"] == \"th\"),\"Title\"]= \"Mr\"\ntest_ori.loc[(test_ori[\"Title\"] == \"Lady\") | (test_ori[\"Title\"] == \"Mme\"),\"Title\"] = \"Mrs\"\ntest_ori.loc[(test_ori[\"Title\"] == \"Mlle\") | (test_ori[\"Title\"] == \"Ms\") ,\"Title\"] = \"Miss\"\ntest_ori.loc[(test_ori[\"Title\"] == \"Dr\") & (test_ori[\"Sex\"] == \"female\") ,\"Title\"] = \"Mrs\"\ntest_ori.loc[(test_ori[\"Title\"] == \"Dr\") & (test_ori[\"Sex\"] == \"male\") ,\"Title\"] = \"Mr\"\n\ntest_ori[\"FamilySize\"]= test_ori[\"SibSp\"] + test_ori[\"Parch\"]\ntest_ori['CabinAssigned'] = np.where(test_ori.Cabin.isnull(), 0, 1)\ntest_ori = test_ori[pd.notnull(test_ori['Embarked'])]\n\n\ntest = test_ori.drop(['Name','PassengerId','Ticket','Cabin','SibSp','Parch'],axis=1)\n\nprint(test.isnull().sum())\n\n# We calculate the mean age per Title column and we will complete with these ages\nmrage=test[test[\"Title\"] == \"Mr\"][\"Age\"].mean()\nmrsage=test[test[\"Title\"] == \"Mrs\"][\"Age\"].mean()\nmissage=test[test[\"Title\"] == \"Miss\"][\"Age\"].mean()\nprint(\"median age for Mr: \",mrage)\nprint(\"median age for Mrs: \",mrsage)\nprint(\"median age for Miss: \",missage)\n\ntest.loc[test[\"Title\"] == \"Mr\",\"Age\"] = test.loc[test[\"Title\"] == \"Mr\",\"Age\"].fillna(mrage)\ntest.loc[test[\"Title\"] == \"Mrs\",\"Age\"] = test.loc[test[\"Title\"] == \"Mrs\",\"Age\"].fillna(mrsage)\ntest.loc[test[\"Title\"] == \"Miss\",\"Age\"] = test.loc[test[\"Title\"] == \"Miss\",\"Age\"].fillna(missage)\n\ntest[\"Fare\"] = test[\"Fare\"].fillna(0)\n\nprint(test.isnull().sum())\n\ntest[\"Embarked\"], uniques = pd.factorize(test[\"Embarked\"])\ntest[\"Sex\"], uniques = pd.factorize(test[\"Sex\"])\ntest[\"Title\"], uniques = pd.factorize(test[\"Title\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2630289a8194f7b0daadfa5b64ed772415eedbe2"},"cell_type":"code","source":"test.loc[(test[\"Fare\"] >= -0.001) & (test[\"Fare\"] < 7.896),\"Fare\"] = 0\ntest.loc[(test[\"Fare\"] >= 7.896) & (test[\"Fare\"] < 14.454),\"Fare\"] = 1\ntest.loc[(test[\"Fare\"] >= 14.454) & (test[\"Fare\"] < 31.0),\"Fare\"] = 2\ntest.loc[(test[\"Fare\"] >= 31.0) ,\"Fare\"] = 3\n\ntest['Fare'] = test['Fare'].astype(int)\n\ntest.loc[(test[\"Age\"] >= -0.001) & (test[\"Age\"] < 15),\"Age\"] = 0\ntest.loc[(test[\"Age\"] >= 15) & (test[\"Age\"] < 18),\"Age\"] = 1\ntest.loc[(test[\"Age\"] >= 18) ,\"Age\"] = 2\n\ntest['Age'] = test['Age'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0526642bf4b7ec94b5da276f8aa0105ec3074bfc"},"cell_type":"code","source":"# make prediction\nprediction = svm_clf.predict(test)\nprint(\"From the\",prediction.size, \"passengers, we have found\", prediction.sum(),\"survivals\")\npsgid = np.array(range(892,1310)).astype(int)\noutput = pd.DataFrame(prediction, index=psgid, columns = ['Survived'])\noutput.to_csv('submission.csv', index_label = 'PassengerId')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}