{"nbformat_minor": 1, "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"file_extension": ".py", "mimetype": "text/x-python", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "version": "3.6.3", "pygments_lexer": "ipython3"}}, "cells": [{"cell_type": "code", "execution_count": null, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "from sklearn import preprocessing as pp\n", "#Random Forest Classifier\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.metrics import make_scorer, accuracy_score\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.cross_validation import KFold\n", "from sklearn.model_selection import train_test_split\n", "import re\n", "\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "metadata": {"_uuid": "4a4e3df8d282e507024926ff811179eebd8cd177", "_kg_hide-input": true, "collapsed": true, "_cell_guid": "7f69b9a2-56b6-4806-928d-11351a019f69", "scrolled": true}, "outputs": []}, {"cell_type": "code", "execution_count": null, "source": ["#Analysis can be found here\n", "#https://public.tableau.com/profile/shashank.gupta1991#!/vizhome/TitanicPredictions/PclassvsCNTSurvived"], "metadata": {"_uuid": "496bedd89e694d3044305a14271f0669df45d114", "collapsed": true, "_cell_guid": "e5f6c524-b96c-42db-94e6-27c67c4a683a"}, "outputs": []}, {"cell_type": "code", "execution_count": null, "source": ["train_df = pd.read_csv(\"../input/train.csv\")\n", "Y = train_df.Survived\n", "test_df = pd.read_csv(\"../input/test.csv\")\n", "merged = train_df.append(test_df)\n", "#merged.drop(['Survived','PassengerId'],axis=1,inplace=True)\n", "#print(merged.columns)\n", "merged.head()"], "metadata": {"_uuid": "28e426d7ec657ea863363c7346c714aea9544894", "collapsed": true, "_cell_guid": "59c9b35f-8fd2-43e0-b2f2-a7853d630bec"}, "outputs": []}, {"cell_type": "code", "execution_count": null, "source": ["def fillMissingValues(data):\n", "      \n", "    #Filling average of the missing fare pclass\n", "    Pclasses = merged.loc[merged.Fare.isnull()].Pclass.values\n", "    for Pclass in Pclasses:\n", "        df = merged.groupby('Pclass',as_index=False)['Fare'].mean()\n", "        val = df.loc[df.Pclass == Pclass].Fare.values[0]\n", "        data.Fare.fillna(val,inplace=True)\n", "        \n", "    #Partially Filling Missing Cabins\n", "    data = fillMissingCabin(data)\n", "    return data\n", "   \n", "def fillMissingCabin(data):\n", "    grp = data.groupby(['PreTkt','TktNum'])['CabinCode'].unique()\n", "    grp = grp[grp.apply(lambda x: len(x)>1)]\n", "    df = pd.DataFrame(grp)\n", "    #print(df.index.values.tolist())\n", "    df.CabinCode.fillna(np.nan,inplace=True)\n", "    index = df.index.values.tolist()\n", "    CabinCode = df.CabinCode.values.tolist()\n", "    idxMap = {}\n", "    for idx, cc in zip(index,CabinCode):\n", "        if idx[0] != \"NA\":\n", "            if pd.isnull(cc[0]) and pd.notnull(cc[1]):\n", "                idxMap[idx] = cc[1]\n", "            elif pd.isnull(cc[1]) and pd.notnull(cc[0]):\n", "                idxMap[idx] = cc[0]\n", "            if idx in idxMap:\n", "                #print(\"here\")\n", "                data.loc[((data.PreTkt==idx[0]) & (data.TktNum == idx[1]) & (pd.isnull(data.CabinCode))),'CabinCode'] = idxMap[idx]\n", "                \n", "    data.CabinCode.fillna('U',inplace=True)\n", "    data = pd.concat([data,pd.get_dummies(data.CabinCode)],axis=1)\n", "    return data  \n", "    \n", "def processTicket(data):\n", "    regex = re.compile(\"(.*)?( [0-9]+)\")\n", "    data.Ticket = data.Ticket.map(lambda x : x if type(x) != str else x.replace(\".\",\"\").replace(\"/\",\"\"))\n", "    splitTkt = data.Ticket.map(lambda x: x if type(x)!=str else [y.strip().upper().replace(' ',\"\") for y in regex.split(x) if y])\n", "    preTkt = [val[0] if len(val)>1 else \"NA\" for val in splitTkt.values]\n", "    TktNum = [val[1] if len(val) > 1 else val[0] for val in splitTkt.values]\n", "    data['PreTkt'] = pd.Series(preTkt)\n", "    data['TktNum'] = pd.Series(TktNum)\n", "    data.loc[(data.TktNum == 'LINE'),'TktNum'] = '111111'\n", "    data = pd.concat([data,pd.get_dummies(data.PreTkt)],axis=1)\n", "    return data\n", "    \n", "def processSex(data):\n", "    print('Starting sex feature ....')\n", "    #Using OneHotEncoder for Sex\n", "    data = pd.concat([data,pd.get_dummies(data.Sex)],axis=1)\n", "    print('Ending sex feature ....')\n", "    return data\n", "    \n", "def processEmbarked(data):\n", "    print('Starting Embarked feature ....')\n", "    df = data.Embarked.dropna()\n", "    #Filling Most Frequent Value for Embarked\n", "    data.Embarked.fillna(df.value_counts().idxmax(),inplace=True)\n", "    \n", "    #Using OneHotEncoder for Embarked\n", "    columns = ['SE','CE','QE']\n", "    data = pd.concat([data,pd.get_dummies(data.Embarked,columns= columns)],axis=1)\n", "    data = data.rename(columns={'S':'SE','C':'CE','Q':'QE'})\n", "    print('Ending Embarked feature ....')\n", "    return data\n", "    \n", "def processAge(data):\n", "    print('Starting Age feature ....')\n", "    data.Age.fillna(data.Age.median(),inplace=True)\n", "    bins = [0,1,4,12,18,35,55,data.Age.max()]\n", "    group_names = ['Infant','Toddler','Child','Teen','YAdult','MAdult','OAdult']\n", "    data['AgeCat'] = pd.cut(data.Age,bins,labels=group_names)\n", "    data = pd.concat([data,pd.get_dummies(data.AgeCat)],axis=1)\n", "    print('Ending Embarked feature ....')\n", "    return data\n", "\n", "def processFamily(data):\n", "    data['Family'] = data.Parch + data.SibSp\n", "    return data\n", "\n", "def processCabinCode(data):\n", "    data['CabinCode'] = data.Cabin.map(lambda x: x if type(x)!=str else x[0])\n", "    #print(data.CabinCode.value_counts()[data.CabinCode.value_counts() > 0])\n", "    return data\n", "    \n", "def missingValuePct(data):\n", "    print('Starting Missing Value count...')\n", "    #data.replace('NaN',np.NaN)\n", "    columns = list(data.columns)\n", "    \n", "    for col in columns:\n", "        print(\"column : {0} --> missing count : {1}\".format(col,data[col].isnull().sum()))\n", "    \n", "# Choose the type of classifier. \n", "def getClassifier(X_train, y_train):\n", "    clf = RandomForestClassifier()\n", "\n", "    # Choose some parameter combinations to try\n", "    parameters = {'n_estimators': [4, 6, 9], \n", "                  'max_features': ['log2', 'sqrt','auto'], \n", "                  'criterion': ['entropy', 'gini'],\n", "                  'max_depth': [2, 3, 5, 10], \n", "                  'min_samples_split': [2, 3, 5],\n", "                  'min_samples_leaf': [1,5,8]\n", "                 }\n", "\n", "    # Type of scoring used to compare parameter combinations\n", "    acc_scorer = make_scorer(accuracy_score)\n", "\n", "    # Run the grid search\n", "    grid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer)\n", "    grid_obj = grid_obj.fit(X_train, y_train)\n", "\n", "    # Set the clf to the best combination of parameters\n", "    clf = grid_obj.best_estimator_\n", "\n", "    # Fit the best algorithm to the data. \n", "    clf.fit(X_train, y_train)\n", "    return clf\n", "\n", "#10 Folds cross validation\n", "def run_kfold(clf,X,Y):\n", "    kf = KFold(X.shape[0],n_folds=10)\n", "    outcome = []\n", "    fold = 0\n", "    \n", "    for train_index, test_index in kf:\n", "        fold += 1\n", "        X_train, X_test = X.values[train_index], X.values[test_index]\n", "        y_train, y_test = Y.values[train_index], Y.values[test_index]\n", "        clf.fit(X_train, y_train)\n", "        new_predictions = clf.predict(X_test)\n", "        accuracy = accuracy_score(y_test, new_predictions)\n", "        outcome.append(accuracy)\n", "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy))\n", "        \n", "    mean_outcome = np.mean(outcome)\n", "    std_outcome = np.std(outcome)\n", "    print(\"Mean Accuracy: {0}\".format(mean_outcome))\n", "    print(\"STD of Accuracy: {0}\".format(std_outcome))\n", "    \n", "def split_data(X,Y,test_size):\n", "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=test_size,random_state=23)\n", "    return X_train, X_test, y_train, y_test\n", "\n", "def processAll(data):\n", "    data = processEmbarked(data)\n", "    data = processFamily(data)\n", "    data = processCabinCode(data)\n", "    data = processTicket(data)\n", "    data = fillMissingValues(data)\n", "    data = processSex(data)\n", "    data = processAge(data)\n", "    return data"], "metadata": {"_uuid": "d4140af0e2c4f0a84b3c155a684fe4d821c09849", "collapsed": true, "_cell_guid": "064ba902-1833-4bc0-833c-15ec2f56ce91"}, "outputs": []}, {"cell_type": "code", "execution_count": null, "source": ["#Missing Values analysis\n", "missingValuePct(merged)"], "metadata": {"_uuid": "2d0c5b28ca406b92bbeca5bffc03539d9bd97257", "collapsed": true, "_cell_guid": "4986e860-6413-4f52-b7b4-794b3c302cc4"}, "outputs": []}, {"cell_type": "code", "execution_count": null, "source": ["merged = processAll(merged)\n", "train = pd.DataFrame(merged.head(len(train_df)))\n", "test = pd.DataFrame(merged.iloc[len(train_df):])\n", "print(merged.columns)"], "metadata": {"_uuid": "a2ffb558232eef9282067bb293922bd16a66589e", "collapsed": true, "_cell_guid": "1074e700-c27b-43c4-a0f4-c2a13c8d6e44"}, "outputs": []}, {"cell_type": "code", "execution_count": null, "source": ["X = train[['Family', 'Pclass', 'female', 'male', 'CE',\n", "       'QE', 'SE', 'Infant', 'Toddler', 'Child', 'Teen', 'YAdult',\n", "       'MAdult', 'OAdult', 'A4', 'A5', 'AS', 'C', 'CA', 'CASOTON', 'FA', 'FC', 'FCC',\n", "       'NA', 'PC', 'PP', 'PPP', 'SC', 'SCA4', 'SCAH', 'SCAHBASLE', 'SCOW',\n", "       'SCPARIS', 'SOC', 'SOP', 'SOPP', 'SOTONO2', 'SOTONOQ', 'SP', 'STONO2',\n", "       'SWPP', 'WC', 'WEP', 'A', 'B', 'C', 'D', 'E',\n", "       'F', 'G', 'T', 'U',]]\n", "\n", "Y = train.Survived\n", "\n", "sub_test = test[['Family', 'Pclass', 'female', 'male', 'CE',\n", "       'QE', 'SE', 'Infant', 'Toddler', 'Child', 'Teen', 'YAdult',\n", "       'MAdult', 'OAdult', 'A4', 'A5', 'AS', 'C', 'CA', 'CASOTON', 'FA', 'FC', 'FCC',\n", "       'NA', 'PC', 'PP', 'PPP', 'SC', 'SCA4', 'SCAH', 'SCAHBASLE', 'SCOW',\n", "       'SCPARIS', 'SOC', 'SOP', 'SOPP', 'SOTONO2', 'SOTONOQ', 'SP', 'STONO2',\n", "       'SWPP', 'WC', 'WEP', 'A', 'B', 'C', 'D', 'E',\n", "       'F', 'G', 'T', 'U',]]"], "metadata": {"_uuid": "f2a4c0ceb66aac21c552ae137a6408f96a01b0fd", "collapsed": true, "_cell_guid": "3f1601da-2c7a-438e-aa5b-d08f5bc27050"}, "outputs": []}, {"cell_type": "code", "execution_count": null, "source": ["X_train, X_test, y_train, y_test = split_data(X,Y,30)\n", "clf = getClassifier(X_train, y_train)\n", "#run_kfold(clf,X,Y)"], "metadata": {"_uuid": "bed12cafe13f849c3e670a8f1618e4ac5f8d184e", "collapsed": true, "_cell_guid": "b7caa52e-2835-410e-b657-c9d02a468457"}, "outputs": []}, {"cell_type": "code", "execution_count": null, "source": ["#clf.fit(X_train,y_train)\n", "new_predictions = clf.predict(sub_test)\n", "test1_df = pd.DataFrame()\n", "test1_df['PassengerId'] = test.PassengerId\n", "test1_df['Survived'] = pd.Series(new_predictions)\n", "test1_df.Survived = test1_df.Survived.astype(int)\n", "\n", "test1_df.to_csv(\"submission.csv\",index=False)\n", "print(test1_df.head())"], "metadata": {"_uuid": "cc8a4a63d5cce90012a053b465d2a3064c6d188c", "collapsed": true, "_cell_guid": "b08bbb11-7c79-467e-8eba-8180d5981285"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "b3fd501b60aa64671c6d5c5f550511235f2d52f7", "_cell_guid": "0a77ca1f-93e8-4a4c-958e-bccf9c65af0c"}, "source": ["So far i have done following thing:\n", "* Converted Embarked to one hot encoder and used as feature.\n", "* Converted Sex to one hot encoder for feature.\n", "* Included  Pclass, SibSP and Parch in features.\n", "\n", "After doing all this the score is around **77%** on test set.\n", "Even though with the abouve feature i can see that model accuracy is around** 80%** on training data even though i have not included very important feature such as Age.\n", "\n", "Lets see how does model behave when we add Age as feature. But before that i have to deal with missing values."]}, {"cell_type": "markdown", "metadata": {"_uuid": "1d14480ac117247bfdf8e9b1dfcd3b9cbce0be2e", "_cell_guid": "951bb32d-2e02-499f-a445-423a966a8431"}, "source": ["**Ways to Handle Missing Values**\n", "* First thing that comes to my mind is that just take the average of the age and fill the space\n", "* Second option could be to missout rows in which we have missing values. But there are close to 178 missing values in age and since the data set is small, i think its not wise to missout so much information."]}, {"cell_type": "markdown", "metadata": {"_uuid": "aae1e8057adfd1d805eb36d5aead7267139a6d6c", "_cell_guid": "e0cbf602-2f05-4582-89a7-11651f88fa36"}, "source": ["Now that we have taken care of missing ages. Its time to convert Ages to some meaningful feature\n", "Here's how i am going to classify age:\n", "* Infant - 0-1\n", "* Toddler - 1-4\n", "* Child - 5-12\n", "* Teen - 12-18\n", "* Young Adult - 18-35\n", "* Middle Adult - 36- 55\n", "* Old Adult - 56 above"]}], "nbformat": 4}