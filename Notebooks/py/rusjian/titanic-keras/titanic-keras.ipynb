{"nbformat_minor": 1, "cells": [{"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "2058eb51-94c4-44ed-9593-1dda17ec4ecc", "_uuid": "00bf33e4108acac3527f3d5d17f6c5b9e9155f24"}, "source": ["import re\n", "import sklearn\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "import plotly.offline as py\n", "py.init_notebook_mode(connected=True)\n", "import plotly.graph_objs as go\n", "import plotly.tools as tls\n", "import os\n", "import urllib\n", "\n", "import numpy as np\n", "import pandas as pd\n", "import tensorflow as tf\n", "\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "\n", "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n", "from sklearn.svm import SVC\n", "from sklearn.cross_validation import KFold;\n", "from sklearn.model_selection import train_test_split\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "088c2ec5-546e-4433-bc55-1929432043af", "_uuid": "006cc636c49dfe46e3e880dcab13b924118ee644"}, "source": ["# Load in the train and test datasets\n", "train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')\n", "\n", "# Store our passenger ID for easy access\n", "PassengerId = test['PassengerId']\n", "Survived = train['Survived']\n", "\n", "train.head(3)"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "2cdfe4a2-5dbd-4438-8c72-18730cca3467", "_uuid": "7a0b2d90a5ddc4e26b501751d0730776f0620002", "collapsed": true}, "source": ["full_data = [train, test]\n", "\n", "# Some features of my own that I have added in\n", "# Gives the length of the name\n", "train['Name_length'] = train['Name'].apply(len)\n", "test['Name_length'] = test['Name'].apply(len)\n", "# Feature that tells whether a passenger had a cabin on the Titanic\n", "train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n", "test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n", "\n", "# Feature engineering steps taken from Sina\n", "# Create new feature FamilySize as a combination of SibSp and Parch\n", "for dataset in full_data:\n", "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n", "# Create new feature IsAlone from FamilySize\n", "for dataset in full_data:\n", "    dataset['IsAlone'] = 0\n", "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n", "# Remove all NULLS in the Embarked column\n", "for dataset in full_data:\n", "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n", "# Remove all NULLS in the Fare column and create a new feature CategoricalFare\n", "for dataset in full_data:\n", "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n", "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n", "# Create a New feature CategoricalAge\n", "for dataset in full_data:\n", "    age_avg = dataset['Age'].mean()\n", "    age_std = dataset['Age'].std()\n", "    age_null_count = dataset['Age'].isnull().sum()\n", "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n", "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n", "    dataset['Age'] = dataset['Age'].astype(int)\n", "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n", "# Define function to extract titles from passenger names\n", "def get_title(name):\n", "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n", "    # If the title exists, extract and return it.\n", "    if title_search:\n", "        return title_search.group(1)\n", "    return \"\"\n", "# Create a new feature Title, containing the titles of passenger names\n", "for dataset in full_data:\n", "    dataset['Title'] = dataset['Name'].apply(get_title)\n", "# Group all non-common titles into one single grouping \"Rare\"\n", "for dataset in full_data:\n", "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n", "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n", "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n", "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n", "\n", "for dataset in full_data:\n", "    # Mapping Sex\n", "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n", "    \n", "    # Mapping titles\n", "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n", "    dataset['Title'] = dataset['Title'].map(title_mapping)\n", "    dataset['Title'] = dataset['Title'].fillna(0)\n", "    \n", "    # Mapping Embarked\n", "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n", "    \n", "    # Mapping Fare\n", "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n", "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n", "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n", "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n", "    dataset['Fare'] = dataset['Fare'].astype(int)\n", "    \n", "    # Mapping Age\n", "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n", "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n", "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n", "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n", "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4 ;"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "47ca64fb-6bb8-4c20-9b8b-64f107be5e27", "_uuid": "edabed51e8e285e5d41abf9071329e0e65a13b0b", "collapsed": true}, "source": ["# Feature selection\n", "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n", "train = train.drop(drop_elements, axis = 1)\n", "train = train.drop(['Survived', 'CategoricalAge', 'CategoricalFare'], axis = 1)\n", "test  = test.drop(drop_elements, axis = 1)"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "ce64ff17-f687-472e-9837-54cf7484813b", "_uuid": "4a29344811628374b6e30d0c08ca45527c596326"}, "source": ["dataset.head()"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "13a17148-05f3-4f94-af30-7c1495ec8ae8", "_uuid": "6cdd601fcd6e405c96eb753d3c3b8ddeb3ec7818"}, "source": ["train.head()"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "1a2726f2-74f5-47e7-8f57-f3a93104a3b7", "_uuid": "cfd7b0e86faba4515b9e2daae9d297ee0d01abdc", "collapsed": true}, "source": ["x_train = train\n", "x_test = test\n", "y_train = Survived"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["x_train=pd.get_dummies(x_train)\n", "x_test=pd.get_dummies(x_test)\n", "from sklearn.preprocessing import StandardScaler\n", "sc = StandardScaler()\n", "x_train = sc.fit_transform(x_train)\n", "x_test = sc.transform(x_test)"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "080e9ad3-bf00-4920-8cc8-d698ee1c8280", "_uuid": "38a00bd9ff5d01116d9c8b8c5b4f8f23bf3d3b73"}, "source": ["x_train.shape"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "95110956-6a48-42ed-9642-eeba4cb554a2", "_uuid": "07a6a9de30b0a60afe010c9e70525be5d2148f6a"}, "source": ["y_train.shape"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "a1541281-aa0b-4820-9031-0752be4f93ae", "_uuid": "b9797018c621754083edd8c3693abea480c652b5"}, "source": ["import numpy as np\n", "from keras.models import Sequential\n", "from keras.layers import Dense, Dropout\n", "from keras.optimizers import SGD\n", "\n", "\n", "model = Sequential()\n", "model.add(Dense(88, input_dim=11, activation='relu'))\n", "model.add(Dropout(0.5))\n", "model.add(Dense(88, activation='relu'))\n", "model.add(Dropout(0.5))\n", "model.add(Dense(1, activation='sigmoid'))\n", "\n", "model.compile(loss='binary_crossentropy',\n", "              optimizer='adam',\n", "              metrics=['accuracy'])\n", "\n", "model.fit(x_train, y_train,\n", "          epochs=30,\n", "          batch_size=11)\n", "\n"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "1a22c131-bd45-4faa-9555-f71fd96c4f70", "_uuid": "e135a7eab7251dd5d96b76319627f9fb3c34ad0c", "collapsed": true}, "source": ["y_pred = model.predict(x_test)\n", "y_pred = (y_pred > 0.5)\n", "y_pred=y_pred.astype(int)\n", "y_pred=y_pred.reshape(-1)\n", "\n"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "5f405cc7-97f4-4acc-afa6-48cc6ac6e9f5", "_uuid": "e40d2460bd6a3fcd912ef560c2005c5427df850b", "collapsed": true}, "source": ["submission = pd.DataFrame({\"PassengerId\": PassengerId, \"Survived\": y_pred})\n", "submission.to_csv('submission.csv', index=False)\n", "\n"]}], "metadata": {"language_info": {"pygments_lexer": "ipython3", "name": "python", "version": "3.6.3", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "file_extension": ".py"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat": 4}