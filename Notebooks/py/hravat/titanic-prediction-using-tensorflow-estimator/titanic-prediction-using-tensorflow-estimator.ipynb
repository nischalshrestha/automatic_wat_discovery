{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"###Acccuracy improvemeent from 0.55 to 0.61244\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"527748028c88d46ad3cc10bffebed6965e3e0001"},"cell_type":"markdown","source":"Lets read the data and print the first few rows"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"df_main = pd.read_csv(\"../input/train.csv\")\ndf_main['Embarked'].fillna('S', inplace=True)\ndf_main['Pclass'] = df_main['Pclass'].astype(str)\ndf_main = df_main.loc[:,['Survived','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\n#df_main = df_main.dropna(how=\"any\", axis=0)\ndf_main.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a1ca923329282d20e6f71d8fde14aa9242e3d7a"},"cell_type":"markdown","source":"Compute the statistics for necessary columns<br>\nWe will not consider any categorical columns<br>\nWe are particularly interested in min & max values to give an idea of the number of buckets required<br> "},{"metadata":{"_uuid":"fc5ae2ba4ed55f7c5b0a8144840f324a9f9b888f","trusted":false},"cell_type":"code","source":"df_main_stats_summary = df_main.loc[:,['Age','Fare','SibSp','Parch']]\ndf_main_stats_summary.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60a9d530966cffc62fafb15de939240f17096750"},"cell_type":"markdown","source":"Judging from the above values:- <br>\n     1) Age :- 8 buckets<br>\n     2) Fare :-  6 buckets<br>\n     3) SibSP & Parch will be passed as is.\n\nImporting the necessary packages<br>"},{"metadata":{"_uuid":"01e010abfb4bd65f3bab2a8ac3e3517869d79b36","trusted":false},"cell_type":"code","source":"import tensorflow as tf\nimport shutil\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7b9444574f234cda67205926352e9b4074c2596"},"cell_type":"markdown","source":"Lets make the input function to read data as below"},{"metadata":{"_uuid":"93f7d5fcfd816d6cde9576e9e481948b7d8c5bf3","trusted":false},"cell_type":"code","source":"def make_input_fn(df, num_epochs):\n  return tf.estimator.inputs.pandas_input_fn(\n    x = df,\n    y = df['Survived'],\n    batch_size = 10,\n    num_epochs = num_epochs,\n    shuffle = True,\n    queue_capacity = 10,\n    num_threads = 1\n  )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12efa6e8d7a318fc899f5fc7fbad2fcb4b1e64a0"},"cell_type":"markdown","source":"Below is the input function for predictions.<br>\nHere we do not provide labels<br>"},{"metadata":{"_uuid":"4898538fbb505a8049dddb264f5df028de2de52d","trusted":false},"cell_type":"code","source":"def make_prediction_input_fn(df, num_epochs):\n  return tf.estimator.inputs.pandas_input_fn(\n    x = df,\n    y = None,\n    batch_size = 10,\n    num_epochs = num_epochs,\n    shuffle = True,\n    queue_capacity = 10,\n    num_threads = 1  \n  )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c9c19864f0f654a8334e676f687f6817629c2748","trusted":false},"cell_type":"code","source":"Pclass_list =  df_main.Pclass.unique()\nPclass_list","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e0dc05378c2d117238e626997cf7c7209586245","trusted":false},"cell_type":"code","source":"gender_list =  df_main.Sex.unique()\ngender_list","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8cbd486b4f89fdb4a9fd10ae196688b046094e7a","trusted":false},"cell_type":"code","source":"embarked_list =  df_main.Embarked.unique()\nembarked_list ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff22905ba026f5691c9cc8edc3399c56ee0e0c41"},"cell_type":"markdown","source":"Below is the function for feature columns"},{"metadata":{"_uuid":"d55e172fc1f25b7c01c310f60c1d654ea6e28cc6","trusted":false},"cell_type":"code","source":"def make_feature_cols():\n Pclass_categorical_column = tf.feature_column.categorical_column_with_vocabulary_list(\n        key='Pclass',\n        vocabulary_list=Pclass_list)\n    \n Gender_categorical_column = tf.feature_column.categorical_column_with_vocabulary_list(\n        key='Sex',\n        vocabulary_list=gender_list)\n \n Embarked_categorical_column = tf.feature_column.categorical_column_with_vocabulary_list(\n        key='Embarked',\n        #vocabulary_list=embarked_list,\n        vocabulary_list=embarked_list,\n        default_value=0\n        )\n\n\n    \n    \n return [  \n    #Pclass_feature_column =\n    tf.feature_column.embedding_column(Pclass_categorical_column,dimension=3),\n    \n     \n    #gender_feature_column =\n    tf.feature_column.embedding_column(Gender_categorical_column,dimension=2), \n    \n    #age_feature_column =  \n    tf.feature_column.bucketized_column(\n        tf.feature_column.numeric_column('Age',dtype=tf.float32), boundaries = np.arange(0.0, 100 , 10).tolist()\n        ),\n\n    #SibSp_feature_column =  \n    tf.feature_column.numeric_column('SibSp',dtype=tf.float32),\n      \n    #Parch_feature_column =  \n    tf.feature_column.numeric_column('Parch',dtype=tf.float32), \n      \n    #Fare_feature_column =  \n    tf.feature_column.bucketized_column(\n        tf.feature_column.numeric_column('Fare',dtype=tf.float32), boundaries = np.arange(0.0, 700 , 100).tolist()\n    ),\n        \n    #embarked_feature_column =\n    tf.feature_column.embedding_column(Embarked_categorical_column,dimension=3),\n         \n  ]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38b6d96a44066f61f8127c8caa27ccd2d338ba46"},"cell_type":"markdown","source":"We now split the data into Test and training"},{"metadata":{"_uuid":"9c4d6c7b7fa57fcf54784c2ae2b4c2356f3a06b0","trusted":false},"cell_type":"code","source":"np.random.seed(seed=1) #makes result reproducible\nmsk = np.random.rand(len(df_main)) < 0.8\ntraindf = df_main[msk]\nevaldf = df_main[~msk]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fae6cd44d422f0359cbe35d1139b14d774e8c667"},"cell_type":"markdown","source":"Next we build eval specs"},{"metadata":{"trusted":false,"_uuid":"1721b7c23aa8cdf6d5b722293fbda67403f0f72f"},"cell_type":"code","source":"# Create estimator train and evaluate function# Creat \ndef train_and_evaluate(output_dir, num_train_steps):\n    \n    estimator = tf.estimator.DNNClassifier(\n    #model_dir = output_dir,\n    feature_columns=make_feature_cols(),\n    hidden_units=[32,16,4],\n    n_classes=2,    \n    optimizer=tf.train.AdamOptimizer(\n      learning_rate=0.01\n    ))\n    \n    train_spec = tf.estimator.TrainSpec(input_fn = make_input_fn(traindf, 1000), \n                                      max_steps = num_train_steps )\n    \n    eval_spec = tf.estimator.EvalSpec(input_fn = make_input_fn(evaldf, 1), \n                                    steps = 1, \n                                    start_delay_secs = 60, # start evaluating after N seconds, \n                                    throttle_secs = 60 )  # evaluate every N seconds\n    \n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n   \n    return estimator","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"aae3a10cf62176f4ca401a03b354d9fb95428c97"},"cell_type":"code","source":"#OUTDIR = '../Titanic Prediction/Model_Details'\ntf.logging.set_verbosity(tf.logging.INFO)\nshutil.rmtree(OUTDIR, ignore_errors = True)\nestimator = train_and_evaluate(OUTDIR, 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ab9f3a0cf3489598e817da2e802da23a96aa5e2b"},"cell_type":"code","source":"a = estimator.predict(make_prediction_input_fn(evaldf,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"029ebc0f6d2a34d0a80eb9ef297401bfddb96053"},"cell_type":"code","source":"df_test = pd.read_csv(\"../input/test.csv\")\ndf_test['Embarked'].fillna('S', inplace=True)\ndf_test['Pclass'] = df_test['Pclass'].astype(str)\ndf_test = df_test.loc[:,['Survived','Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']]\n#df_main = df_main.dropna(how=\"any\", axis=0)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"51cd749aa3db5af2afc3288afce536447732276d"},"cell_type":"code","source":"test = estimator.predict(make_prediction_input_fn(df_test,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"00b75af6c08bb99e5ee6d74aa1970b9900ad251f"},"cell_type":"code","source":"pred_list = []\n\nfor i in test:\n    for a in i['classes']:\n        pred_list.append(str(a)[1:][1:2])   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"df7f873d59e20e5edf7af4bb2c0a9e608bae426c"},"cell_type":"code","source":"df_submit = pd.read_csv(\"../input/test.csv\")\ndf_submit = pd.DataFrame(df_submit['PassengerId'])\ndf_pred = pd.DataFrame({'Survived':pred_list})\ndf_submit['Survived'] = df_pred\ndf_submit.to_csv('hravat_titanic_pred_titl.csv',sep=',',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"760b6832c95341d758a8e452d9dfdc7f9e89d06f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}