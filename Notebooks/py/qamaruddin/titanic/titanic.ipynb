{"cells":[{"metadata":{"_uuid":"e50bd388286969a0dafab414be1c333fa08e2571"},"cell_type":"markdown","source":"### Video Explainer ( https://www.youtube.com/watch?v=P4rBiyP1xho )"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"collapsed":true},"cell_type":"code","source":"import pandas as pd\nimport h5py\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\n\ndef cat2num_sex(val):\n    if \"male\" == val:\n        return 1\n    else:\n        return 0\n\n\ndef cat2num_embarking(val):\n    if \"C\" == val:\n        return 2\n    elif \"Q\" == val:\n        return 1\n    else:\n        return 0\n\n\ndef preprocess_data(csv_file):\n    df = pd.read_csv(csv_file)\n\n    # Shuffle\n    df = df.sample(frac=1).reset_index(drop=True)\n\n    # Missing Data\n    df['Age'] = df['Age'].fillna(value=df.Age.median())\n\n    # Categorical to Numerical\n    df['Sex'] = df['Sex'].apply(cat2num_sex)\n    df['Embarked'] = df['Embarked'].apply(cat2num_embarking)\n\n    # Normalization\n    scaler = MinMaxScaler()\n    df['Age'] = scaler.fit_transform(np.array(df['Age']).reshape(-1, 1))\n    df['Fare'] = scaler.fit_transform(np.array(df['Fare']).reshape(-1, 1))\n\n    # Columns\n    target_cols = [\"Survived\"]\n    features_cols = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n\n    y_train = df[target_cols]\n    X_train = df[features_cols]\n    \n    # Pairwise Correlation & Covariance\n    print(X_train.Fare.corr(y_train.Survived))\n    print(X_train.Fare.cov(y_train.Survived))\n\n    return X_train, y_train\n\n\ndef wrap_preprocess():\n    X_train, y_train = preprocess_data(\"../input/train.csv\")\n\n    train_size = int(len(y_train) * 0.80)\n\n    with h5py.File(\"dataset-v4.h5\", 'w') as f:\n        f.create_dataset(\"X_train\", data=np.array(X_train[:train_size]))\n        f.create_dataset('y_train', data=np.array(y_train[:train_size]))\n        f.create_dataset(\"X_val\", data=np.array(X_train[train_size:]))\n        f.create_dataset(\"y_val\", data=np.array(y_train[train_size:]))\n\n\nwrap_preprocess()\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, LeakyReLU\n\n\ndef init_model():\n    model = Sequential()\n    model.add(Dense(70, input_dim=7))\n    model.add(Dropout(0.2))\n    model.add(LeakyReLU())\n    model.add(Dense(50, input_dim=10))\n    model.add(Dropout(0.1))\n    model.add(LeakyReLU())\n    model.add(Dense(1, input_dim=10))\n    model.add(Activation('sigmoid'))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"from keras.optimizers import SGD\nfrom keras.callbacks import CSVLogger, ModelCheckpoint\nimport os\nimport h5py\n\n\ndef mkdir_exists(dir):\n    if os.path.exists(dir):\n        return\n    os.mkdir(dir)\n\n\ndef data_reader():\n    with h5py.File(''.join(['dataset-v4.h5']), 'r') as hf:\n        X_train = hf['X_train'].value\n        y_train = hf['y_train'].value\n        X_val = hf['X_val'].value\n        y_val = hf['y_val'].value\n    return X_train, y_train, X_val, y_val\n\n\ndef train():\n    model = init_model()\n\n    sgd = SGD(lr=1e-2, decay=1e-4, momentum=0.9, nesterov=True)\n\n    model.compile(\n        loss='mean_squared_error',\n        optimizer=sgd,\n        metrics=['accuracy']\n    )\n\n    X_train, y_train, X_val, y_val = data_reader()\n\n    mkdir_exists(\"weights\")\n\n    # training & validation\n    history = model.fit(X_train,\n              y_train,\n              batch_size=64,\n              validation_data=(X_val, y_val),\n              epochs=1000,\n              verbose=0,\n              callbacks=[\n                  CSVLogger(\n                      'logs.csv',\n                      append=True\n                  ),\n                  ModelCheckpoint(\n                      'weights/model-ffn.hdf5',\n                      monitor='val_acc',\n                      verbose=0,\n                      mode='min'\n                  )\n              ]\n              )\n    \n    return history\n\n\nhistory = train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"396295d233b517f6b46e037fdada52d0a94989e8"},"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nplt.figure(figsize=(16, 12))\nplt.title(\"Train & Validation Loss\")\nplt.plot(history.history['loss'], label=\"Training Loss\")\nplt.plot(history.history['val_loss'], label=\"Validation Loss\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"277282bca5d6216077b3f0c6234f495d7bc30d78"},"cell_type":"code","source":"plt.figure(figsize=(16, 12))\nplt.title(\"Train & Validation Accuracy\")\nplt.plot(history.history['acc'], label=\"Training Accuracy\")\nplt.plot(history.history['val_acc'], label=\"Validation Accuracy\")\nplt.legend()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}