{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e80cbd16-e6ce-3a74-3fd8-39aa6aae7671"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "25055d30-5063-4ae6-036e-2352d3607211"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "\n",
        "# Tools from scikit-learn\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import copy\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "#from subprocess import check_output\n",
        "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "# Tools for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns # For easy making of difficult graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6f194096-16c7-6fde-0124-ffb886b861bc"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6067e48c-1528-d0a6-3228-09e7a89cd95b"
      },
      "outputs": [],
      "source": [
        "# Read data files\n",
        "import os\n",
        "if os.path.isfile('Titanic_train.csv'):\n",
        "    train = pd.read_csv('Titanic_train.csv')\n",
        "    test = pd.read_csv('Titanic_test.csv')\n",
        "else:\n",
        "    train = pd.read_csv(os.path.join('../input', 'train.csv'))\n",
        "    test = pd.read_csv(os.path.join('../input', 'test.csv'))\n",
        "# Train has 891 inputs\n",
        "# test has 418 inputs\n",
        "# A total of 1309 inputs, and which means that test set is 32% of all data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c5b7982c-a914-29dd-ab5b-62025b07e41d"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9a572a97-d3af-d10f-6202-12b36ffdcec0"
      },
      "outputs": [],
      "source": [
        "# Get stats\n",
        "print(\"\"\"\n",
        "VARIABLE DESCRIPTIONS:\n",
        "survival        Survival\n",
        "                (0 = No; 1 = Yes)\n",
        "pclass          Passenger Class\n",
        "                (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
        "name            Name\n",
        "sex             Sex\n",
        "age             Age\n",
        "sibsp           Number of Siblings/Spouses Aboard\n",
        "parch           Number of Parents/Children Aboard\n",
        "ticket          Ticket Number\n",
        "fare            Passenger Fare\n",
        "cabin           Cabin\n",
        "embarked        Port of Embarkation\n",
        "                (C = Cherbourg; Q = Queenstown; S = Southampton)        \n",
        "                \n",
        "\"\"\")\n",
        "print(train.info())\n",
        "print(test.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cd70296a-7543-1f5e-c779-f972d55a5331"
      },
      "outputs": [],
      "source": [
        "# Show the first entries in data\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "88e6eaa2-b246-9387-c2e2-de4fa1a1df31"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "82eef24a-3e3f-8209-48b2-b4215a11510e"
      },
      "outputs": [],
      "source": [
        "# Lets explore the data\n",
        "print(\"Number of males:\", np.sum(train['Sex']==\"male\"))\n",
        "print(\"Number of females:\", np.sum(train['Sex']==\"female\"))\n",
        "# Test datasets\n",
        "print(np.sum(train['Sex']==\"male\") + np.sum(train['Sex']==\"female\"), train['Sex'].count())\n",
        "train_Sex_male = (train['Sex']==\"male\").astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1aac2e2d-9dcb-1a07-5040-4eb11c845f9b"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4d4584a1-2c94-e739-c485-902e8b360f79"
      },
      "outputs": [],
      "source": [
        "# Make a histogram of age\n",
        "# Some data is missing, so let us make a selection array\n",
        "sel_age_fin = np.isfinite(train['Age'])\n",
        "sel_age_isnan = np.isnan(train['Age'])\n",
        "sel_age_male = train['Sex'][sel_age_fin] == \"male\"\n",
        "sel_age_female = train['Sex'][sel_age_fin] == \"female\"\n",
        "# Now plot, first make bins to classify into\n",
        "bins = np.linspace(0, 99, 30)\n",
        "fig1, ax1 = plt.subplots()\n",
        "n_all, bins_all, patches_all = ax1.hist(train['Age'][sel_age_fin], bins, normed=0, alpha=0.25, label=\"All\")\n",
        "n_male, bins_male, patches_male = ax1.hist(train['Age'][sel_age_fin][sel_age_male], bins, normed=0, alpha=0.75, label=\"male\")\n",
        "n_female, bins_female, patches_female = ax1.hist(train['Age'][sel_age_fin][sel_age_female], bins, normed=0, alpha=0.15, label=\"female\")\n",
        "# Now make labels\n",
        "print(\"Number of age, all:\", len(train['Age'][sel_age_fin]))\n",
        "print(\"Number of age males:\", len(train['Age'][sel_age_fin][sel_age_male]))\n",
        "print(\"Number of age females:\", len(train['Age'][sel_age_fin][sel_age_female]))\n",
        "\n",
        "# Again\n",
        "fig2, ax2 = plt.subplots()\n",
        "n_out, bins_out, patches_out = ax2.hist(\n",
        "    (train['Age'][sel_age_fin], train['Age'][sel_age_fin][sel_age_male], train['Age'][sel_age_fin][sel_age_female]), \n",
        "    bins, alpha=0.75, label=(\"All\", \"male\", \"female\"))\n",
        "\n",
        "ax1.set_title(\"Age histogram\")\n",
        "ax2.set_title(\"Age histogram\")\n",
        "ax1.set_xlabel(\"Age\")\n",
        "ax2.set_xlabel(\"Age\")\n",
        "ax1.set_ylabel(\"Frequency\")\n",
        "ax2.set_ylabel(\"Frequency\")\n",
        "ax1.legend(loc='upper right', shadow=True)\n",
        "ax2.legend(loc='upper right', shadow=True)\n",
        "\n",
        "fig3, ax3 = plt.subplots()\n",
        "n_out_norm, bins_out_norm, patches_out_norm = ax3.hist(\n",
        "    (train['Age'][sel_age_fin], train['Age'][sel_age_fin][sel_age_male], train['Age'][sel_age_fin][sel_age_female]), \n",
        "    bins, normed=1, alpha=0.75, label=(\"All\", \"male\", \"female\"))\n",
        "\n",
        "# Print the bins, and the number for all\n",
        "print(bins_all)\n",
        "print(n_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "41258f8b-b1bd-976a-fefd-21581930ab25"
      },
      "outputs": [],
      "source": [
        "# Make selection of age range\n",
        "sel_age_fin_infant = train['Age'][sel_age_fin] < 4\n",
        "sel_age_fin_child = np.logical_and(4 <= train['Age'][sel_age_fin], train['Age'][sel_age_fin] < 14)\n",
        "sel_age_fin_adult = 14 <= train['Age'][sel_age_fin]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4140d5ac-85fd-abf0-9ceb-00f2506380a4"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3274cae0-ce98-2d26-7632-e4797fd154e8"
      },
      "outputs": [],
      "source": [
        "# Try to see, if there is a relations  ship between age and family\n",
        "f, axarr = plt.subplots(2, sharex=True)\n",
        "axarr[0].scatter(train['Age'], train['SibSp'])\n",
        "axarr[1].scatter(train['Age'], train['Parch'])\n",
        "axarr[0].set_title('Sharing X axis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1fe805cd-2126-5582-7d0d-cfe0daaf311c",
        "collapsed": true
      },
      "outputs": [],
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b67ccf43-4182-0d34-5653-8546c8321e73"
      },
      "outputs": [],
      "source": [
        "# Try to see, if there is a relations  ship between age and fare price\n",
        "f, axarr = plt.subplots(2, sharex=True)\n",
        "axarr[0].scatter(train['Age'][sel_age_fin], train['Fare'][sel_age_fin])\n",
        "axarr[1].scatter(train['Age'][sel_age_fin][sel_age_fin_infant], train['Fare'][sel_age_fin][sel_age_fin_infant])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9a599658-8851-7ab9-a4b9-b31a7d9e3d44"
      },
      "outputs": [],
      "source": [
        "# Not really easy to see relationship between Age and fare price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a1e13a1f-5e7a-656b-0a31-288c3312977e"
      },
      "outputs": [],
      "source": [
        "# Make a new title row.\n",
        "# First remove last name, then select title\n",
        "def name_title(input_arr):\n",
        "    train_Name_Title = input_arr['Name'].apply(lambda x: x.split(',')[-1]).apply(lambda x: x.split('.')[0].strip())\n",
        "    uniques, train_Name_Title_nr = np.unique(train_Name_Title, return_inverse=True)\n",
        "    train_Name_Title_nr = pd.Series(train_Name_Title_nr)\n",
        "    return train_Name_Title, train_Name_Title_nr\n",
        "    \n",
        "train_Name_Title, train_Name_Title_nr = name_title(train)\n",
        "print(train_Name_Title.value_counts())\n",
        "print(train_Name_Title_nr.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f76a62c8-432f-c001-afe9-35c6631acb74"
      },
      "outputs": [],
      "source": [
        "# Let us check relationship between name and age\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(train['Age'][sel_age_fin], train_Name_Title_nr[sel_age_fin])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0e72fac3-3676-a952-98c3-5af6428aff52"
      },
      "outputs": [],
      "source": [
        "# At least \"Master\" is clearly and infant or child. Let us check that.\n",
        "# Everything else than \"Miss\", is an adult.\n",
        "\n",
        "print(\"Is master\", np.sum(train_Name_Title[sel_age_isnan] == \"Master\"))\n",
        "print(train_Name_Title[sel_age_isnan].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c03c3ac4-7919-7268-97c1-71db93975814"
      },
      "outputs": [],
      "source": [
        "# Make a replacement of age\n",
        "def age_rep(input_arr):\n",
        "    train_Name_Title, train_Name_Title_nr = name_title(input_arr)\n",
        "    age_rep = np.asarray(input_arr['Age'])\n",
        "    for index, row in input_arr.iterrows():\n",
        "        if np.isnan(row['Age']):\n",
        "            # Is adult\n",
        "            Name_Title = train_Name_Title[index]\n",
        "            if Name_Title in ['Mr', 'Mrs', 'Dr', ]:\n",
        "                mu, sigma = 35, 10 # mean and standard deviation\n",
        "                age = np.abs(int(np.random.normal(mu, sigma, None)))\n",
        "                age_rep[index] = age\n",
        "                #print(age)\n",
        "            elif Name_Title == \"Miss\":\n",
        "                mu, sigma = 25, 8 # mean and standard deviation\n",
        "                age = np.abs(int(np.random.normal(mu, sigma, None)))\n",
        "                age_rep[index] = age\n",
        "                #print(age)\n",
        "            elif Name_Title == \"Master\":\n",
        "                mu, sigma = 1, 1 # mean and standard deviation\n",
        "                age = np.abs(int(np.random.normal(mu, sigma, None)))\n",
        "                age_rep[index] = age\n",
        "                #print(age)\n",
        "    age_rep_scale = (age_rep / 10).astype(int)\n",
        "    age_rep = pd.Series(age_rep)\n",
        "    age_rep_scale = pd.Series(age_rep_scale)\n",
        "    return age_rep, age_rep_scale\n",
        "\n",
        "train_Age_rep, train_Age_rep_scale = age_rep(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2edb62c9-1548-5300-866d-74692a06d158"
      },
      "outputs": [],
      "source": [
        "# Test for missing age\n",
        "print(np.sum(np.isnan(train_Age_rep)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "343e9378-aaeb-b074-7fd3-be60f08d281d"
      },
      "outputs": [],
      "source": [
        "bins_scale = np.linspace(0, 9, 30)\n",
        "fig4, ax4 = plt.subplots()\n",
        "n_scale, bins_scale, patches_scale = ax4.hist(train_Age_rep_scale, bins_scale, normed=1, alpha=0.75, label=\"All\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "976c8960-fa6b-136c-1ccf-9dc77ac70709"
      },
      "outputs": [],
      "source": [
        "# Try using making seaborn, to use the distributions as violin plots\n",
        "#help(sns.violinplot)\n",
        "sns_data = copy.copy(train)\n",
        "sns_data['Age_rep'] = train_Age_rep\n",
        "# inner, \"box\", \"quartile\", \"point\", \"stick\", None\n",
        "#f, axarr = plt.subplots(2, 2)\n",
        "#sns.violinplot(x=\"Survived\", y=\"Age_rep\", hue=\"Sex\", data=sns_data, split=True, inner=\"box\", ax=axarr[0,0])\n",
        "#sns.violinplot(x=\"Survived\", y=\"Age_rep\", hue=\"Sex\", data=sns_data, split=True, inner=\"quartile\", ax=axarr[0,1])\n",
        "#sns.violinplot(x=\"Survived\", y=\"Age_rep\", hue=\"Sex\", data=sns_data, split=True, inner=\"point\", ax=axarr[1,0])\n",
        "#sns.violinplot(x=\"Survived\", y=\"Age_rep\", hue=\"Sex\", data=sns_data, split=True, inner=\"stick\", ax=axarr[1,1])\n",
        "sns.violinplot(x=\"Survived\", y=\"Age_rep\", hue=\"Sex\", data=sns_data, split=True, inner=\"quartile\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9dc78330-93fd-fee8-85dc-39a4a3b06175"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2f444848-aa88-47c6-3a2d-12c753ec2c25"
      },
      "outputs": [],
      "source": [
        "# Check the histogram of fare prices\n",
        "fig5, ax5 = plt.subplots()\n",
        "n_fare, bins_fare, patches_fare = ax5.hist(train['Fare'], normed=1, alpha=0.75, label=\"Fare\")\n",
        "plt.figure()\n",
        "sns.violinplot(x=\"Survived\", y=\"Fare\", hue=\"Sex\", data=sns_data, split=True, inner=\"quartile\")\n",
        "print(\"Fare equal zero:\", np.sum(sns_data['Fare']==0.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ae306e8c-4662-0420-394d-bf2e3e7c1284"
      },
      "outputs": [],
      "source": [
        "def scale_fare(input_arr):\n",
        "    fare = np.nan_to_num(input_arr['Fare'])\n",
        "    fare_scale = (fare / 50).astype(int)\n",
        "    return fare_scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3f6b08e8-1fb1-719c-d29f-ddec814cdaa6"
      },
      "outputs": [],
      "source": [
        "fare_scale = scale_fare(train)\n",
        "fig6, ax6 = plt.subplots()\n",
        "n_fare_scale, bins_fare_scale, patches_fare_scale = ax6.hist(fare_scale, normed=1, alpha=0.75, label=\"Fare\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "706232fd-fb05-3d37-04ed-2f327dadb280"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3db7c1a7-49f0-c61a-fc6d-83578a0e0fd0"
      },
      "outputs": [],
      "source": [
        "def embarked_nr(input_arr):\n",
        "    Emb = input_arr['Embarked'].astype(str)\n",
        "    uniques, Emb_nr = np.unique(Emb, return_inverse=True)\n",
        "    Emb_nr = pd.Series(Emb_nr)\n",
        "    return Emb, Emb_nr\n",
        "    \n",
        "Emb, Emb_nr = embarked_nr(train)\n",
        "print(Emb.value_counts())\n",
        "print(Emb_nr.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c7de1d28-9a8c-1f00-910e-6f658edc2c3c"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "417c0943-06e9-be3b-da03-d4d8ec81ac53"
      },
      "outputs": [],
      "source": [
        "# Check\n",
        "#for i,val in enumerate(train['Ticket']):\n",
        "#    print(val, \";\", train['Cabin'][i], \";\", train['Survived'][i])\n",
        "# Hard to determine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6421ab5a-7a42-7f97-2a2d-3dbc8a14b506"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "96b8ed66-02bc-fc45-453b-144c59965641"
      },
      "outputs": [],
      "source": [
        "def extract_data(input_arr, include_survived=True, neg_survived=True):\n",
        "    # The passenger class\n",
        "    Pclass = input_arr['Pclass']\n",
        "    # A number for title\n",
        "    train_Name_Title, train_Name_Title_nr = name_title(input_arr)\n",
        "    # If male\n",
        "    train_Sex_male = (input_arr['Sex']==\"male\").astype(int)\n",
        "    # A age, scaled\n",
        "    train_Age_rep, train_Age_rep_scale = age_rep(input_arr)\n",
        "    # The SibSp\n",
        "    SibSp = input_arr['SibSp']\n",
        "    # The Parch\n",
        "    Parch = input_arr['Parch']\n",
        "    # The scaled fare price\n",
        "    fare_scale = scale_fare(input_arr)\n",
        "    # Embarked\n",
        "    Emb, Emb_nr = embarked_nr(input_arr)\n",
        "\n",
        "    # Make data\n",
        "    df = pd.DataFrame(Pclass)\n",
        "    if include_survived:\n",
        "        survived = np.asarray(input_arr['Survived'])\n",
        "        if neg_survived:\n",
        "            survived[survived == 0] = -1\n",
        "        df['Survived'] = survived\n",
        "    df['Male'] = train_Sex_male\n",
        "    df['train_Age_rep_scale'] = train_Age_rep_scale\n",
        "    df['SibSp'] = SibSp\n",
        "    df['Parch'] = Parch\n",
        "    df['fare_scale'] = fare_scale\n",
        "    df['Emb_nr'] = Emb_nr\n",
        "\n",
        "    return df\n",
        "\n",
        "def get_train_val(input_arr=None, perc=0.2):\n",
        "    # Convert to numpy array\n",
        "    mat = input_arr.as_matrix(columns=('Survived', 'Male', 'train_Age_rep_scale', 'SibSp', 'Parch', 'fare_scale', 'Emb_nr'))\n",
        "    # Get the number of rows\n",
        "    nr = mat.shape[0]\n",
        "    # Shuffle data inplace\n",
        "    np.random.shuffle(mat)\n",
        "    # Calculate slice, and split op in validate and train data\n",
        "    slice_i = int(nr*perc)\n",
        "    mat_validate = mat[:slice_i]\n",
        "    mat_train = mat[slice_i:]\n",
        "    # Split up in prediction data, and result data\n",
        "    mat_validate_x = mat_validate[:,1:]\n",
        "    mat_validate_y = mat_validate[:,0]\n",
        "    mat_train_x = mat_train[:,1:]\n",
        "    mat_train_y = mat_train[:,0]\n",
        "    return mat_train_x, mat_train_y, mat_validate_x, mat_validate_y\n",
        "\n",
        "# seed random numbers to make calculation deterministic (just a good practice)\n",
        "np.random.seed(1)\n",
        "\n",
        "# Get the data\n",
        "train_dat = extract_data(train.copy())\n",
        "# Get training and validation data\n",
        "mat_train_x, mat_train_y, mat_validate_x, mat_validate_y = get_train_val(input_arr=train_dat.copy(), perc=0.2)\n",
        "print(\"Matrices\", mat_train_x.shape, mat_train_y.shape, mat_validate_x.shape, mat_validate_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f2d987d3-c760-c966-5ce1-d307a28a503a"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bc194fec-4f15-4d10-b975-e1b3612cca24"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "45fbb0a2-f41e-1f1d-4a78-6af9a4a7bf11"
      },
      "outputs": [],
      "source": [
        "# Make a random hyperplane weight vector\n",
        "def makeHyper(xdata):\n",
        "    w = np.random.randint(1, high=11, size=np.shape(xdata)[-1])\n",
        "    w[0] = 1\n",
        "    return w\n",
        "\n",
        "# Make hypothesis / prediction\n",
        "def hypo(w, x):\n",
        "    dot = np.dot(w,x)\n",
        "    if(dot < 0):\n",
        "        return -1\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "def findBrain(w, xs, ys):\n",
        "    isLearning = True\n",
        "    count = 0\n",
        "    while(isLearning == True):\n",
        "        isLearning = False\n",
        "        # Loop over all rows in data, and adjust weight\n",
        "        for index in range(len(xs)):\n",
        "            predict = hypo(w, xs[index])\n",
        "            result = ys[index]\n",
        "            if(predict != result):\n",
        "                # Update the weight vector\n",
        "                # w is the current weight vector, x is the data, y is the result\n",
        "                # So the values of the weight vector is adjusted up or down, according to the x values\n",
        "                # wNew = w + y*x\n",
        "                w = w + ys[index]*xs[index]\n",
        "                isLearning = True\n",
        "                count += 1\n",
        "                if count > 100000:\n",
        "                    isLearning = False\n",
        "    return w\n",
        "\n",
        "def calcError(w=None, xs=None, ys=None, only_pred=False):\n",
        "    predict_arr = np.zeros(xs.shape[0])\n",
        "    for i in range(len(xs)):\n",
        "        predict = hypo(w, xs[i])\n",
        "        predict_arr[i] = predict\n",
        "    # If only to predict\n",
        "    if only_pred:\n",
        "        return predict_arr.astype(int)\n",
        "    correct = predict_arr == ys\n",
        "    wrong = predict_arr != ys\n",
        "    print(\"Algorithm was wrong: \", np.sum(wrong), \" times\")\n",
        "    print(\"Algorithm was right \", np.sum(correct), \" times\")\n",
        "    print(\"Succesrate: \", float(np.sum(correct))/(len(ys)) * 100)\n",
        "    return predict_arr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b5e6f3f1-1b8f-e8d0-6c36-ee208fd0ae20"
      },
      "source": [
        "# Do perceptron and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "874d1de1-ba67-e5ba-4c6c-4f9e13784891"
      },
      "outputs": [],
      "source": [
        "# seed random numbers to make calculation deterministic (just a good practice)\n",
        "np.random.seed(1)\n",
        "\n",
        "w_start = makeHyper(mat_train_x)\n",
        "print(\"You started with brainvector: \", w_start)\n",
        "w_out =  findBrain(w_start, mat_train_x, mat_train_y)\n",
        "print(\"You ended with brainvector: \", w_out)\n",
        "\n",
        "# Test training\n",
        "print(\"\\nTesting For the training data\")\n",
        "predict_arr = calcError(w_out, mat_train_x, mat_train_y)\n",
        "print(\"\\nTesting For the validation data\")\n",
        "predict_arr = calcError(w_out, mat_validate_x, mat_validate_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0a6cd4e6-ccb5-47f9-97c4-9d65d851d1fd"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "49661f9f-2c13-821c-a1c4-46942ce9b3b5"
      },
      "outputs": [],
      "source": [
        "# Get the test data\n",
        "test_dat = extract_data(test, include_survived=False)\n",
        "# Get training and validation data\n",
        "test_mat = test_dat.as_matrix(columns=('Male', 'train_Age_rep_scale', 'SibSp', 'Parch', 'fare_scale', 'Emb_nr'))\n",
        "# Make ready for submission\n",
        "perceptron_submission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"]})\n",
        "# Predict\n",
        "survived = calcError(w_out, test_mat, only_pred=True)\n",
        "# Replace\n",
        "survived[survived == -1] = 0\n",
        "#print(survived)\n",
        "print(\"\\nNumber of survivals %i/%i\"%(np.sum(survived), len(survived)))\n",
        "perceptron_submission['Survived'] = survived\n",
        "perceptron_submission.head()\n",
        "perceptron_submission.to_csv('Titanic_perceptron_submission.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8655d201-0b44-7cc1-d1fa-5015f9319596"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "44171f9f-32c0-e8a7-eec6-76622873ba99"
      },
      "outputs": [],
      "source": [
        "# Make a random synapsis weight\n",
        "def makeSynapsis(X):\n",
        "    # randomly initialize our weights with mean 0\n",
        "    # syn0: First layer of weights, Synapse 0, connecting l0 to l1.\n",
        "    syn0 = 2*np.random.random(X.shape[::-1]) - 1\n",
        "    # syn1: Second layer of weights, Synapse 1 connecting l1 to l2.\n",
        "    syn1 = 2*np.random.random((X.shape[0], 1)) - 1\n",
        "    syn = [syn0, syn1]\n",
        "    return syn\n",
        "\n",
        "def nonlin(x, scale=1., deriv=False, i=None):\n",
        "    # Prevent overflow\n",
        "    x[x < -709.] = -709.\n",
        "    if(deriv==True):\n",
        "        #return scale*x*(1-x)\n",
        "        return scale*np.exp(-x)/(np.exp(-x)+1)**2\n",
        "    try:\n",
        "        calc = scale*1/(1+np.exp(-x))\n",
        "    except FloatingPointError as e:\n",
        "        print(\"FloatingPointError %s\"%e)\n",
        "        print(\"Iterations nr:%i, xmax=%f, xmin=%f, isnan:%i\"%(i,np.max(x), np.min(x), np.sum(np.isnan(x))))\n",
        "    return calc\n",
        "\n",
        "# Make hypothesis / prediction\n",
        "def hypo_NN(syn, x, scale=1., ret_int=False, i=None):\n",
        "    #Extract tuble\n",
        "    syn0, syn1 = syn\n",
        "    # Feed forward through layers 0, 1, and 2\n",
        "    l0 = x\n",
        "    # Input to l1\n",
        "    l1_in = np.dot(l0, syn0)\n",
        "    l1 = nonlin( l1_in , scale=scale, i=i)\n",
        "    # Input to l2\n",
        "    l2_in = np.dot(l1, syn1)\n",
        "    predict = nonlin( l2_in , scale=scale, i=i)\n",
        "    if(ret_int==True):\n",
        "        return l1, np.rint(predict)\n",
        "    return l1, predict\n",
        "\n",
        "def neural_network(syn=None, X=None, y=None, scale=1, it=60000, verb=False):\n",
        "    for j in range(it):\n",
        "        l1, predict = hypo_NN(syn, X, scale=scale, i=j)\n",
        "        # how much did we miss the target value?\n",
        "        l2_error = y - predict\n",
        "        # print error out\n",
        "        if verb:\n",
        "            if (j% 500) == 0:\n",
        "                print(\"Error:\" + str(np.mean(np.abs(l2_error))))\n",
        "        # in what direction is the target value?\n",
        "        # were we really sure? if so, don't change too much.\n",
        "        l2_delta = l2_error*nonlin(predict, scale=scale, deriv=True)\n",
        "        # how much did each l1 value contribute to the l2 error (according to the weights)?\n",
        "        l1_error = l2_delta.dot(syn[1].T)\n",
        "        # in what direction is the target l1?\n",
        "        # were we really sure? if so, don't change too much.\n",
        "        l1_delta = l1_error * nonlin(l1, scale=scale, deriv=True)\n",
        "        syn[1] += l1.T.dot(l2_delta)\n",
        "        syn[0] += X.T.dot(l1_delta)\n",
        "    # Return synapsis weights\n",
        "    return syn\n",
        "\n",
        "def calcError_NN(syn=None, xs=None, ys=None, scale=1., only_pred=False, pred_arr=None):\n",
        "    if pred_arr is None:\n",
        "        l1, predict_arr = hypo_NN(syn, xs, scale=scale, ret_int=True)\n",
        "    else:\n",
        "        predict_arr = pred_arr\n",
        "    # If only to predict\n",
        "    if only_pred:\n",
        "        return predict_arr\n",
        "    correct = predict_arr == ys\n",
        "    wrong = predict_arr != ys\n",
        "    print(\"Algorithm was wrong: \", np.sum(wrong), \" times\")\n",
        "    print(\"Algorithm was right \", np.sum(correct), \" times\")\n",
        "    print(\"Succesrate: \", float(np.sum(correct))/(len(ys)) * 100)\n",
        "    return predict_arr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "065d0b3d-37d1-1705-24d5-a48fa4315c7b"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5c03d1b8-9b00-cb13-290e-120c78860581"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1)\n",
        "# Make data\n",
        "Xtest = np.array([ [0,0,5],[0,4,4],[3,0,5],[2,1,4] ])\n",
        "ytest = np.array([[0,1,1,0]]).T\n",
        "syn_start = makeSynapsis(Xtest)\n",
        "print(\"Shapes:\", syn_start[0].shape, syn_start[1].shape, Xtest.shape, ytest.shape)\n",
        "syn_out = neural_network(syn=syn_start, X=Xtest, y=ytest, scale=1., it=5000)\n",
        "predict_arr = calcError_NN(syn_out, Xtest, ytest)\n",
        "#print(predict_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "06980269-1748-a265-2c51-597ded975999"
      },
      "outputs": [],
      "source": [
        "sssssclf = MLPClassifier(solver='lbfgs', alpha=1e-7, hidden_layer_sizes=(3, 3), random_state=0)\n",
        "clf.fit(Xtest, np.ravel(ytest))\n",
        "clf_predict_arr = np.array([clf.predict(Xtest)]).T\n",
        "predict_arr = calcError_NN(ys=ytest, pred_arr=clf_predict_arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d97fec2d-37a4-c59f-fd66-2472550f2f3f"
      },
      "source": [
        "# Try NN on data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "40ff347c-eaeb-91a3-e931-67f1d9f97c38"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "# Get the data\n",
        "train_dat_NN = extract_data(train.copy(), neg_survived=False)\n",
        "# Get training and validation data\n",
        "mat_train_x, mat_train_y, mat_validate_x, mat_validate_y = get_train_val(input_arr=train_dat_NN.copy(), perc=0.2)\n",
        "print(\"Matrices\", mat_train_x.shape, mat_train_y.shape, mat_validate_x.shape, mat_validate_y.shape)\n",
        "#train_dat_NN.head()\n",
        "\n",
        "syn_start = makeSynapsis(mat_train_x)\n",
        "# Raise all numpy errors\n",
        "np.seterr(over='raise')\n",
        "print(\"Shapes:\", syn_start[0].shape, syn_start[1].shape, mat_train_x.shape, mat_train_y.shape)\n",
        "if True:\n",
        "    syn_out = neural_network(syn=syn_start, X=mat_train_x, y=np.array([mat_train_y]).T, scale=1., it=50, verb=True)\n",
        "\n",
        "    # Test training\n",
        "    print(\"\\nTesting For the training data\")\n",
        "    predict_arr = calcError_NN(syn_out, mat_train_x, np.array([mat_train_y]).T)\n",
        "    print(\"\\nTesting For the validation data\")\n",
        "    predict_arr = calcError_NN(syn_out, mat_validate_x, np.array([mat_validate_y]).T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c312b4b9-fa99-0d75-1b9e-24d768ccd399"
      },
      "outputs": [],
      "source": [
        "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(6, 4), random_state=0)\n",
        "clf.fit(mat_train_x, mat_train_y)\n",
        "clf_predict_arr = clf.predict(mat_train_x)\n",
        "print(\"\\nTesting For the training data\")\n",
        "predict_arr = calcError_NN(ys=mat_train_y, pred_arr=clf_predict_arr)\n",
        "print(\"\\nTesting For the validation data\")\n",
        "clf_predict_arr = clf.predict(mat_validate_x)\n",
        "predict_arr = calcError_NN(ys=mat_validate_y, pred_arr=clf_predict_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c828d89a-b347-2349-56b9-ce072c3b5574"
      },
      "outputs": [],
      "source": [
        "# Make ready for submission\n",
        "NN_submission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"]})\n",
        "# Predict\n",
        "survived = clf.predict(test_mat)\n",
        "#print(survived)\n",
        "print(\"\\nNumber of survivals %i/%i\"%(np.sum(survived), len(survived)))\n",
        "NN_submission['Survived'] = survived\n",
        "NN_submission.head()\n",
        "NN_submission.to_csv('Titanic_perceptron_submission.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8e765c22-1ac2-ea76-1d73-d743fbfd3a50"
      },
      "outputs": [],
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "973a3421-a429-4059-2f3f-831334f0e6ba"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}