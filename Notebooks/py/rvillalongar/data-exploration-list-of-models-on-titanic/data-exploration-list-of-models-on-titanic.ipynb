{"cells":[{"metadata":{"_uuid":"f087f38511aace9c789cce7599eeb14b64316a3f"},"cell_type":"markdown","source":"![](http://)# Step 0:  Load libraries\n<a id=\"stp0\"></a>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f074903c4fe3e171c391241f21084a33ba471f4"},"cell_type":"markdown","source":"# Step 1: Read all Data\n<a id=\"stp1\"></a>\n\nMerge the train and test data, the idea is to understand what are the quantity of data (all the universe), and how it was the proportion by Sex"},{"metadata":{"trusted":true,"_uuid":"77c2ebcb9abf655bdc2615c940b4c5ab6ccd803b"},"cell_type":"code","source":"#read Train and test data\ntrain = pd.read_csv(\"../input/train.csv\")\n\ntest = pd.read_csv(\"../input/test.csv\")\n\n#concat train and Test data\nall_Data = pd.concat([train.drop('Survived', axis=1), test], axis=0, sort=True)\ngroup_all_data = all_Data.groupby(['Sex'])['PassengerId'].count()\n\nprint('how many people have by sex in all dataset', group_all_data )\nprint()\nprint('Total of: \\n',all_Data.isnull().sum())\n\nprint('Sample of Data \\n')\nprint(all_Data.head(5))\nprint()\n#visualize the null in all dataset \nall_Data_total = all_Data.isnull().sum().sum()\nprint('Quantity persons on Training and Test Data:', all_Data_total)\n\nprint('% People by Sex: \\n', group_all_data*100/all_Data_total)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3fef7c0b60bce350962e52796413b9508cc82aba"},"cell_type":"markdown","source":"### note:\nWe need to take care when construct our model about :\n* Age\n* Cabin\n*  Embarked\n*  Fare\nBecause the are features with Nulls values\n\n# Step 2: Begin to work with the Train Data Analysis\n<a id=\"stp2\"></a>\n\n**We work with Train Data and we launch 3 Action  on the train Dataset **\n1. Info\n2. Describe\n3. show 5 lines"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#show all the columns\npd.options.display.max_columns = None\n\n#print Train Dataset \nprint(train.info())\nprint(train.describe())\nprint(train.head(5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74f8a1923781e75cea70ba8e8486324abe03645c"},"cell_type":"markdown","source":"## General view of Train DataSet"},{"metadata":{"trusted":true,"_uuid":"24a8e29db92ecc410b88db9d99e5443a45758279"},"cell_type":"code","source":"#from pandas.plotting import scatter_matrix\ncol_obj = ['Survived', 'Pclass', 'Age', 'SibSp','Parch', 'Fare']\n#scatter_matrix(train[col_obj], figsize=(12,8))\nsns.pairplot(train.drop('PassengerId', axis=1).dropna(), hue='Survived')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d9ed3ae4794518ff31897465c5bc5fb4bd05317"},"cell_type":"markdown","source":"###  2.1 How many people was on Titanic (train Dataset)** ?\n<a id=\"stp2.1\"></a>"},{"metadata":{"trusted":true,"_uuid":"3daaada610ba1823ab3a6b955108dff9077e3091"},"cell_type":"code","source":"group_s = train.groupby(['Sex'])['PassengerId'].count()\nprint('train data has:', group_s.sum() , ' rows \\n' )\nprint(\"Q by sex (train)\\n \" , group_s)\nprint(\"\\n % train data (train)  \\n\",group_s*100/group_s.sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91f09f46f75c05af879776a3a60762a6b907d8f1"},"cell_type":"markdown","source":"The amount of people  on % by sex is similar on all_data\n\n### 2.2  How many people **Die/Survive**?\n<a id=\"stp2.2\"></a>"},{"metadata":{"trusted":true,"_uuid":"f424e4c9e892daf5aace8afbe0e8638a2e6d1226"},"cell_type":"code","source":"group_svs = train.groupby(['Survived'])['PassengerId'].count()*100/train.groupby(['Survived'])['PassengerId'].count().sum()\nprint('% people Die/survived \\n', group_svs.round(2))\nprint()\ngroup_svs.plot(kind='bar', title='% of survived')\nplt.xticks([0,1], ['Die','Survived'])\nplt.ylabel('percentage')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b565c6921a1cf705fdd5030de329639b2fb14a13"},"cell_type":"markdown","source":"### 2.3 How many people **survive** if we consider  **Sex**?\n<a id=\"stp2.3\"></a>"},{"metadata":{"trusted":true,"_uuid":"3c806c9f57c62dc824a077a6d24893128423aee8"},"cell_type":"code","source":"#group_sur_sex = train.groupby(['Survived','Sex'])['PassengerId'].count()*100/train.groupby(['Survived','Sex'])['PassengerId'].count().sum().sum()\n#print(group_sur_sex.round(2))\n#group_sur_sex.plot(kind='bar',hue=['Survived'])\n#p=group_sur_sex.unstack().plot(kind='bar')\n#plt.title('% survived based on sex')\n#plt.xticks([0,1],['Die','Survived'])\n#plt.show()\n\n(pd.crosstab(train.Survived, train.Sex, margins=True, normalize='all').round(4)*100).style.background_gradient(cmap='summer_r')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb2b590c7ae5f39cee906b795bc8980fe8e151e9"},"cell_type":"markdown","source":"### How many people in each **class ** in %?\n### How many people Die/survived in each **class** in %?"},{"metadata":{"trusted":true,"_uuid":"28f61139715dd0bb75a9e3eb0526ce6d7b850b90"},"cell_type":"code","source":"group_sbc= train.groupby(['Pclass'])['PassengerId'].count()*100/train.groupby(['Pclass'])['PassengerId'].count().sum()\nprint('% people on each Class \\n', group_sbc.round(2))\np = group_sbc.plot(kind='bar')\nplt.title('% survived by Class')\nplt.show()\nctb = pd.crosstab(train.Pclass, train.Survived,  margins=True , normalize='all').round(4)*100\n#ctb.plot(kind='bar')\nctb.style.background_gradient(cmap='summer_r')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a3d5853edd0856c00890ddc7292fb3bf9c64af46"},"cell_type":"markdown","source":"### How many people die and survive in base of each **class & Sex**?"},{"metadata":{"trusted":true,"_uuid":"a6d18b7e29b8653eeb1b44ce7a6cefe732d15fcf"},"cell_type":"code","source":"group_sur_class = train.groupby(['Survived','Pclass','Sex'])['Survived'].count()\n#print(group_sur_class)\n#group_sur_class.unstack().plot(kind='bar')\n\n# % survived by Row'\nctb = pd.crosstab(index = [train.Pclass, train.Sex], columns=train.Survived, normalize='index').round(4)*100\nctb.style.background_gradient(cmap='summer_r')\nctb\n\n# % survived by Class & Sex'\nctb_ = pd.crosstab(index = [train.Pclass, train.Sex], columns=train.Survived, normalize='all').round(4)*100\nctb_.style.background_gradient(cmap='summer_r')#ctb.plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"457623fcf18fbf67d2f19301200c70fab779f32d"},"cell_type":"markdown","source":"**Die/survive on each class by sex**"},{"metadata":{"trusted":true,"_uuid":"b50e06d7587ce67b761ad9f466bc39e0f5af3269"},"cell_type":"code","source":"group_sur_class = train.groupby(['Sex','Survived','Pclass'])['Pclass'].count()\n#print(group_sur_class)\np = group_sur_class.unstack().plot(kind='bar')\nplt.title('Q survived & sex for each Class ')\nplt.show()\n\np = pd.crosstab([train.Sex, train.Survived], train.Pclass, normalize='columns').plot(kind='bar')\nplt.title('% survived & sex in base of the Class ')\nplt.show()\n\n\npd.crosstab([train.Sex, train.Survived], train.Pclass, normalize='columns').style.background_gradient('summer_r')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"59e1f7c15d7a99b7b20d7e9b7d0056eacb36fcbd"},"cell_type":"markdown","source":"## How is Age distribution on Titanic\n\n**The Age Can be  ~ a normal distribution**"},{"metadata":{"trusted":true,"_uuid":"2b30a9681d407fe32248ce1e1dae8d462f535a27"},"cell_type":"code","source":"#sns.distplot(train.Age.dropna())\n#train['Age'].fillna(train['Age'].mean(), inplace=True)\n#f, axes = plt.subplots(1,3, figsize=(18,8))\nsns.distplot(train.Age.dropna(),label='Age')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"568e3a7b683927c1c50b0a665abf51c367402ac3"},"cell_type":"markdown","source":"## How is Age distribution if we consider the Survived & Die "},{"metadata":{"trusted":true,"_uuid":"8aa4daaae4bfd10acfb0b0f6fc389ef7988c711d"},"cell_type":"code","source":"sns.distplot(train.Age.dropna()[train.Survived==True],label='survived', color='green',hist_kws=dict(alpha=0.1))\nsns.distplot(train.Age.dropna()[train.Survived==False], label='Die', color='red',hist_kws=dict(alpha=0.1))\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2945828505b602fdb875929013de509955ee81ca"},"cell_type":"markdown","source":"## How is Age distribution by Class"},{"metadata":{"trusted":true,"_uuid":"9dad4fffc08858c5866e27a302a0c855e5ecb85c"},"cell_type":"code","source":"grid = sns.FacetGrid(train.dropna(), col='Pclass', margin_titles=True)\nbins = np.linspace(0, 70, 10)\ngrid.map(sns.distplot, 'Age', bins=bins)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b11021414e4dd74c0494e62c1911026940673ad7"},"cell_type":"markdown","source":"## How is age distribution on each Class & Die/Survive"},{"metadata":{"trusted":true,"_uuid":"b7af4edb8591d72ba563f0eecd5765a606fc27f4"},"cell_type":"code","source":"f, axes = plt.subplots(2,3, figsize=(18,8))\nplt.subplot(231)\nplt.hist(x=train.Age[train.Pclass==1].dropna())\nplt.title('distribution of Age on Class I')\n\nplt.subplot(232)\nplt.hist(x=train.Age[train.Pclass==2].dropna())\nplt.title('Distribution of Age on Class II')\n\nplt.subplot(233)\nplt.hist(x=train.Age[train.Pclass==3].dropna())\nplt.title('Distribution of Age on Class III')\n\nsns.distplot(train.Age.dropna()[(train.Survived==True) & (train.Pclass==1)],label='surv_class_I', hist=True, color='green', ax=axes[1][0], hist_kws=dict(alpha=0.1))\nsns.distplot(train.Age.dropna()[(train.Survived==False) & (train.Pclass==1)],label='Die_class_I',  hist=True, color='Red', ax=axes[1][0], hist_kws=dict(alpha=0.1))\n\n\nsns.distplot(train.Age.dropna()[(train.Survived==True) & (train.Pclass==2)],label='surv_class_II',  hist=True, color='green', ax=axes[1][1], hist_kws=dict(alpha=0.1))\nsns.distplot(train.Age.dropna()[(train.Survived==False) & (train.Pclass==2)],label='Die_class_II',  hist=True, color='Red', ax=axes[1][1], hist_kws=dict(alpha=0.1))\n\nsns.distplot(train.Age.dropna()[(train.Survived==True) & (train.Pclass==3)],label='surv_class_II',  hist=True, color='green', ax=axes[1][2], hist_kws=dict(alpha=0.1))\nsns.distplot(train.Age.dropna()[(train.Survived==False) & (train.Pclass==3)],label='Die_class_III',  hist=True, color='red', ax=axes[1][2], hist_kws=dict(alpha=0.1))\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f54abd8c7f5340c5f43cab7412d175a33f933e3"},"cell_type":"markdown","source":"## How is survive distriburion depend it on Fare"},{"metadata":{"trusted":true,"_uuid":"98b709821b9c4e55c4af36b7fd4d5bbcb38e1ee2"},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.distplot(train.Fare.dropna(), hist=False, label='All' )\nsns.distplot(train.Fare.dropna()[train.Survived==1], color='green', label='survived', hist=False)\nsns.distplot(train.Fare.dropna()[train.Survived==0], color='red', label='Die', hist=False)\nplt.legend()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e349ebcbcbd0a2942a653d84e9279b850c155c3a"},"cell_type":"markdown","source":"# We are goint to create four categories on Fare\nWe will create 4 class of Fare\n\n1. The low price will be less [0, 100[\n2. Medium [100 to 200[\n3. High [200 to 300[\n4. Ultra [300 , [\n\nThe table will be normalize base on Fare categorie and cross by survived\n\n## HIP: if you are Ultra, Do you have a high chance to survived?"},{"metadata":{"trusted":true,"_uuid":"d7e77634d544906557bdd328fe5f5271eec11ac1"},"cell_type":"code","source":"train['cFare']= train.Fare.apply(lambda r: 'Low' if r <100 else ('Medium' if (r>=100 and r<200) else ('High' if (r>=200 and r<=300) else 'Ultra')  )).astype('category')\n#train.groupby([train.Farex,train.Survived])['PassengerId'].count()\ntrain.cFare.cat.reorder_categories(['Low','Medium','High','Ultra'], inplace=True)\n\n#we create table to CFare cross Survived\nctb = pd.crosstab(train.cFare, train.Survived)\n\n#Normalize data by row, to obtein ratio of survived/die by category of Fare\nctb_Nr = pd.crosstab(train.cFare, train.Survived, normalize='index')\nctb.style.background_gradient('summer_r')\nctb_Nr.plot(kind='bar')\nplt.legend(labels=['D', 'S'])\nplt.title('% Die/Survive base on Category Fare')\n\nprint('table Q values on \\n \\n', ctb)\nprint('\\n')\n# Present the data on %\nprint('table %  row margin values on \\n', ctb_Nr.round(4)*100)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9381f1fac27730f037296f00cd3f27877a715cc2"},"cell_type":"markdown","source":"# Machine learning \n\n## Testing only the numerical values\n0. Import libraries to train models\n1. Divide object & numeric atributes \n2.  Create Pipeline for each model\n3. Test different models one by one.\n4. Automate model in array and Test\n"},{"metadata":{"_uuid":"6166ff199ccbfff03b3b56240ad5d410a5f9563f"},"cell_type":"markdown","source":"###  1. Import libraries to train models "},{"metadata":{"trusted":true,"_uuid":"bf1a295fa20f0fcc6ae4a8e418c758f2405800c2"},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn import preprocessing\nfrom sklearn.pipeline import  Pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nimport numpy as np\n#separar los datos\nfrom sklearn.model_selection import train_test_split\n# modelo Lineales\nfrom sklearn import linear_model\n# Funcion para procesar data\nfrom sklearn.preprocessing import FunctionTransformer","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"68a8a4467ecb57e4e1efac500741595d6786882d"},"cell_type":"markdown","source":"### 2. Select the numeric atributes\n* Create the Target array \n* Create a function transform to select the numerical variables. The idea is to include this selection on a pipeline process\n* Divide the object en Train and Test "},{"metadata":{"trusted":true,"_uuid":"3354fa1e31c1957551e99439f9d7ad40e2fd8766"},"cell_type":"code","source":"# create a target array\ntarget = train.Survived\n#creta a function to get only the numerical data\nget_numeric_data = FunctionTransformer(lambda x: x[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']], validate=False)\n#divide the train.csv on Train an Test Data to test models\nX_train, X_test,y_train, y_test = train_test_split(train, target, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e8de2c95cb196cd9b6eaafad48c99de2feec317"},"cell_type":"markdown","source":"###  Create Pipeline for each model\nOn each pipeline we:\n1. get same attribute on dataframe using function get_numeric_data\n2. Impute on mean values with SimpleImputer\n3. Scale the variable on StandarScaler\n4.  Add a Method \n5. Create the each pipeline\n6. Print the Score"},{"metadata":{"trusted":true,"_uuid":"06e83ce67b82d46fc3bafd765b8894234154e0d8"},"cell_type":"code","source":"#select the imputer and the Strategy\nimp = SimpleImputer(strategy='mean')\n# Scale the Data\nscl = preprocessing.StandardScaler()\n\n# declare\nlg = linear_model.LogisticRegression()\nlsgd = linear_model.SGDClassifier()\nlper = linear_model.Perceptron()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a62fc9c505236da45e548421b962d03de20cea8"},"cell_type":"code","source":"pipeline_lg = Pipeline([('num',get_numeric_data ),('imputer', imp), ('scale', scl), ('lg', lg)])\npipeline_rc = Pipeline([('num',get_numeric_data ),('imputer', imp), ('scale', scl), ('lsgd', lsgd)])\npipeline_pc = Pipeline([('num',get_numeric_data ),('imputer', imp), ('scale', scl), ('per',lper )])\n\npipeline_lg.fit(X_train, y_train)\npipeline_rc.fit(X_train, y_train)\npipeline_pc.fit(X_train, y_train)\n\nprint(pipeline_lg.score(X_test, y_test))\nprint(pipeline_rc.score(X_test, y_test))\nprint(pipeline_pc.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8aac133ff87284749986aaf6956d7c9bc792a558"},"cell_type":"code","source":"#create a list of models\n#add naive and SVM\nfrom sklearn import svm, naive_bayes\nfrom sklearn.metrics import confusion_matrix\n\nmodelo =[\n    #linear\n        linear_model.LogisticRegression(), \n         linear_model.SGDClassifier(), \n         #linear_model.Perceptron(), \n         linear_model.RidgeClassifier(alpha=0.5),\n    #naive\n        naive_bayes.BernoulliNB(),\n        naive_bayes.GaussianNB(),\n    #suport Vector Machine\n        svm.SVC(probability=True),\n    \n    #Tree\n        DecisionTreeClassifier(),\n    #Random Forest\n        RandomForestClassifier(n_estimators=10),\n    #Perceptron\n        linear_model.Perceptron(max_iter=5, tol=None)\n        ]\n\n\n\npdModelos = pd.DataFrame(columns=['modelo NAME', 'Accuracy', 'Modelo', 'pred', 'confM'])\n\n\n\n\n\nrow = 0\nfor m in modelo: \n    pipe = Pipeline([('num',get_numeric_data ),('imputer', imp), ('scale', scl), ('model', m )])   \n    pipe.fit(X_train, y_train)\n    pdModelos.loc[row,'modelo NAME']= m.__class__.__name__\n    pdModelos.loc[row,'Accuracy']= pipe.score(X_test, y_test)\n    pdModelos.loc[row, 'Modelo'] = pipe.steps[3][1]\n    pdModelos.loc[row, 'pred'] = pipe.predict(X_train)\n    pdModelos.loc[row, 'confM']= confusion_matrix(y_train, pdModelos.loc[row, 'pred'])\n    row+=1\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3dd5a19f8f994e6e0a5cbff31cf69c920821a87f"},"cell_type":"code","source":"pdModelos.sort_values('Accuracy', ascending=False, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"680ac0c3acd80a567a7db4a8e86395f47ef0464d"},"cell_type":"code","source":"true_class_names = ['True Survived', 'True Not Survived']\npredicted_class_names = ['Predicted Survived', 'Predicted Not Survived']\n\nm_df = pd.DataFrame(pdModelos.confM[0]/pdModelos.confM[0].sum(axis=1)[:,  np.newaxis], \n                 index=true_class_names,\n                 columns= predicted_class_names)\n\nplt.figure(figsize=(15,5))\nplt.subplot(121)\n\nsns.heatmap(m_df, annot=True)\nprint(m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ef4565f42e04bbb51040e19577b973d5e1963d5"},"cell_type":"code","source":"m = pdModelos.loc[0,'Modelo']\nprint(pipe.steps[3][1])\npred = pipe.predict(test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a2f8b6ea42cf9fb98c024acb1743353388bd4c1"},"cell_type":"code","source":"t = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived':pred} )\n\nfilename = 'titanic_prediction.csv'\n\nt.to_csv(filename, index=False)\n\nprint('Saved file: ' + filename)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}