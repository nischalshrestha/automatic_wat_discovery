{"cells":[{"metadata":{"_uuid":"c7be859e7d2e211b883e7b8bc038f64d368a0fd1"},"cell_type":"markdown","source":"This is my first Kaggle competition! I am just using it to experiment with some models and techniques,  for example I wanted to try out cross-validation but didn't use it to do any tuning."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Import relevant modules\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) \n\n#read the data and take a look at the first few lines\ntrain_data = pd.read_csv(\"../input/train.csv\")\ntest_data = pd.read_csv(\"../input/test.csv\")\ntrain_data.head(20)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"missing_vals_train = (train_data.isnull().sum())\nprint(missing_vals_train[missing_vals_train > 0])\nmissing_vals_test = (test_data.isnull().sum())\nprint(missing_vals_test[missing_vals_test > 0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"665af2f1067f9990d9fde0efbc8e9cc77f627bf6"},"cell_type":"markdown","source":"Since a lot of the cabin data is missing, to simplify things I will drop the cabin column for now. Since age is numeric, imputation can be used to fill in the mean. I will do this later, after one-hot encoding the remaining categorical data.\n\nI also drop name and ticket number as these are non-numeric and I expect them to have limited effect on survival.\n\nUnfortunately there is one passenger in the test data for which the fare data is missing. This can also be imputed."},{"metadata":{"trusted":true,"_uuid":"5f36536057308c8eb84ac2c43ffae8579219c072"},"cell_type":"code","source":"Columns_to_drop = ['Name','Ticket','Cabin','PassengerId']\nreduced_data = train_data.drop(Columns_to_drop, axis=1)\nreduced_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9519921bbd5e4657de1373527563d8d97c2a0657"},"cell_type":"markdown","source":"Now: one-hot encoding for the sex and embarkation point of passengers.\n"},{"metadata":{"trusted":true,"_uuid":"3b6156b11daf079c85770d8b5aa2a532a90bfe94"},"cell_type":"code","source":"OHE_training_data = pd.get_dummies(reduced_data)\nOHE_training_data.head(6)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26642471122bf13c6cc192aaa6863d3429a3902c"},"cell_type":"markdown","source":"Okay need to separate the output from the features."},{"metadata":{"trusted":true,"_uuid":"8e93ac3dee71c0b9479871932d2cf0cab16f52f4"},"cell_type":"code","source":"y_training = OHE_training_data.Survived\nX_training = OHE_training_data.drop('Survived',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0cd89fe6c534378085f5863afb9d77593f26f0cc"},"cell_type":"markdown","source":"Now to make a pipeline that imputes age and then fits using XGBClassifier."},{"metadata":{"trusted":true,"_uuid":"6e7fba2a2d16b9abb724a032ef299fa7993f5257"},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import Imputer\nfrom xgboost import XGBClassifier\n\nXGB_Pipeline = make_pipeline(Imputer(), XGBClassifier(random_state=1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f91eec9c2a116310c2a97e6daf214fc77a8cf5b5"},"cell_type":"markdown","source":"Now to implement cross-validation in order to better compare different models."},{"metadata":{"trusted":true,"_uuid":"689a6c81499f6f5fc60e4f26ea1f17d4ff81e626"},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(XGB_Pipeline, X_training, y_training, scoring='accuracy', cv=5)\nprint(\"mean score over 5 folds is %2f\" %(scores.mean()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5350658bda4ef9e2bdf32ce46b4988501bb643c2"},"cell_type":"markdown","source":"Okay I want to test a few models against eachother, then tune the best one. I am going to use logistic regression, support vector classifier random forest classifier, and XGBoost. For each one I calculate its cross-validation score."},{"metadata":{"trusted":true,"_uuid":"d08d557479f201760e01fbbd5c79feb4ea3493de"},"cell_type":"code","source":"#Import the models and then construct a pipeline for each including imputation\nfrom sklearn.linear_model import LogisticRegression\nLR_Pipeline = make_pipeline(Imputer(), LogisticRegression(random_state=1))\nfrom sklearn.svm import SVC\nSVC_Pipeline = make_pipeline(Imputer(), SVC(random_state=1))\nfrom sklearn.ensemble import RandomForestClassifier\nRF_Pipeline = make_pipeline(Imputer(), RandomForestClassifier(random_state=1))\nfrom xgboost import XGBClassifier\nXGBC_Pipeline = make_pipeline(Imputer(), XGBClassifier(random_state=1))\n\n#Function that takes a model and returns its cross-validation score\ndef cv_score(model):\n    scores = cross_val_score(model, X_training, y_training, scoring='accuracy', cv=5)\n    return scores.mean()\n\n#Calculate cross-validation scores using this function\nCV_scores = pd.DataFrame({'Cross-validation score':[cv_score(LR_Pipeline),cv_score(SVC_Pipeline),cv_score(RF_Pipeline),cv_score(XGBC_Pipeline)]})\nCV_scores.index = ['LR_Pipeline','SVC_Pipeline','RF_Pipeline','XGBC_Pipeline']\nprint(CV_scores)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8884a220f965a224ed0bd3931dfe8e37a47bc59d"},"cell_type":"markdown","source":"Logistic regression and random forest did significantly better than SVC, so I am going to tune these two. Since logistic regression only really has one hyper-parameter, I'm starting with that one."},{"metadata":{"trusted":true,"_uuid":"2f894b90b7e551e9c56bf97bace68d95c58097de"},"cell_type":"code","source":"for C in np.logspace(-4, 4, num=10):\n    LR_Pipeline = make_pipeline(Imputer(), LogisticRegression(random_state=1,C=C))\n    print('For C=%1f, the cross-validation score is %2f' %(C,cv_score(LR_Pipeline)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7670f3c8569cb6c25b99b0fcc848bda8b4d3b4d8"},"cell_type":"markdown","source":"Looks like it didn't do much better than the default. What about using a different penalty (l1-norm instead of l2)?"},{"metadata":{"trusted":true,"_uuid":"bdd0ec14afa0271bc0aa23bc2682037e9af2f9f5"},"cell_type":"code","source":"for C in np.logspace(-4, 4, num=10):\n    LR_Pipeline = make_pipeline(Imputer(), LogisticRegression(random_state=1,C=C,penalty='l1'))\n    print('For C=%1f, the cross-validation score is %2f' %(C,cv_score(LR_Pipeline)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c98170c40e270f979e00449318ea5b557cd089a9"},"cell_type":"markdown","source":"This was worse. Indeed, it seems so far we haven't beaten XGB Classifier with the default parameters"},{"metadata":{"trusted":true,"_uuid":"3b4285a4d6d4f16c11df61c7a8fe758a62e535e3"},"cell_type":"code","source":"reduced_test_data = test_data.drop(Columns_to_drop, axis=1)\nreduced_test_data.head()\nOHE_test_data = pd.get_dummies(reduced_test_data)\nOHE_test_data.head(6)\nXGBC_Pipeline.fit(X_training,y_training)\npredictions = XGBC_Pipeline.predict(OHE_test_data)\nprint(predictions)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d3eec97a80aadc5b3cd06ae8321007f46f1b48d"},"cell_type":"markdown","source":"Now to write these predictions to csv."},{"metadata":{"trusted":true,"_uuid":"a58b1cfaa7ad33f64ce5b4e672c6172cff8691e0"},"cell_type":"code","source":"gender_submission = pd.read_csv(\"../input/gender_submission.csv\")\nprint(gender_submission.head())\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId,\n                       'Survived': predictions})\noutput.head(10)\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfbdad3fc55855cef02046ddce39961cee79a635"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}