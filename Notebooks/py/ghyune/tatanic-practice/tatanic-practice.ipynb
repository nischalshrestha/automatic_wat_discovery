{"cells":[{"metadata":{"_uuid":"46952c9be47fa88b9689710feac12d432c1fdcb4","_cell_guid":"bd058b1a-94f0-49b1-a813-e51798b5fc2e","trusted":false,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input/train.csv\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\ndata_train = pd.read_csv(\"../input/train.csv\")\ndata_test = pd.read_csv(\"../input/test.csv\")\n\ndata_train.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa80f7e2f490dc6c74e75eead895552571dfca41","_cell_guid":"8c026a08-faed-40e2-bbfd-c1fd593b6e3c","trusted":false,"collapsed":true},"cell_type":"code","source":"sns.barplot(x=\"Embarked\", y=\"Survived\",hue=\"Sex\", data=data_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4bcee68d24c91db57e622b60a7e10f35c8384b44","_cell_guid":"9ecb6557-a12f-42c8-b802-d5ab8b9dea84","trusted":false,"collapsed":true},"cell_type":"code","source":"sns.pointplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=data_train,\n              palette={\"male\":\"blue\", \"female\":\"pink\"},\n             markers=[\"*\",\"o\"], linestyle=[\"-\",\"--\"]);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5abe6ba65a77d9212ee944cad422a2f37b32f0ff","_cell_guid":"bc4cd6a6-cb48-4ec1-9630-79ed2e0d1de5","trusted":false,"collapsed":true},"cell_type":"code","source":"data_train[\"Survived\"].value_counts()\n#총 891명\n\ndata_train[\"Survived\"].value_counts(normalize=True)\n#사망 : 생존 = 61.6% : 38.3%\n\nsur_fe = data_train[\"Survived\"][data_train[\"Sex\"] == \"female\"].value_counts(normalize=True)\n# 여자-> 사망 : 생존  = 25%:74%\n\nsur_me = data_train[\"Survived\"][data_train[\"Sex\"] == \"male\"].value_counts(normalize=True)\n# 남자-> 사망 : 생존  = 81%:18%\n#-> 성별로 사망, 생존이 크네\n\nsns.barplot(x=\"Sex\", y=\"Survived\", data=data_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17aca218be7bed06925cf543d47ba049b6ea3433","_cell_guid":"7a39858b-c5d3-4e6c-9f23-5f944316ed89","trusted":false,"collapsed":true},"cell_type":"code","source":"data_train.Fare.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f80fc3087f5a8164c5c860e0a62b7ad066f8682","_cell_guid":"3a64d34e-748e-4dcb-98ac-668e71e9176c","trusted":false,"collapsed":true},"cell_type":"code","source":"def simplify_ages(df):\n    df.Age = df.Age.fillna(-0.5)\n    bins = (-1,0,5,12,18,25,35,60,120)\n    group_names = ['Unknown','Baby', 'Child', 'Teenager', 'Student','Young Adult', 'Adult','Senior']\n    categories = pd.cut(df.Age, bins, labels=group_names)\n    df.Age = categories\n    return df\n\ndef simplify_cabins(df):\n    df.Cabin = df.Cabin.fillna('N')\n    df.Cabin = df.Cabin.apply(lambda x:x[0])\n    return df\n\ndef simplify_fares(df):\n    df.Fare = df.Fare.fillna(-0.5)\n    bins = (-1,0,8,15,31,1000)\n    group_names = ['UnKnown', '1_quartile','2_quartile','3_quartile','4_quartile']\n    categories = pd.cut(df.Fare, bins, labels=group_names)\n    df.Fare = categories\n    return df\n\ndef format_name(df):\n    df['Lname'] = df.Name.apply(lambda x:x.split(' ')[0])\n    df['NamePrefix'] = df.Name.apply(lambda x:x.split(' ')[1])\n    return df\n\ndef drop_features(df):\n    return df.drop(['Ticket','Name', 'Embarked'], axis = 1)\n\ndef transform_features(df):\n    df = simplify_ages(df)\n    df = simplify_cabins(df)\n    df = simplify_fares(df)\n    df = format_name(df)\n    df = drop_features(df)\n    return df\n\ndata_train = transform_features(data_train)\ndata_test = transform_features(data_test)\ndata_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19c4fe82966103fbe11138f378665532f359da69","_cell_guid":"fe0e3095-dd3d-4872-8b9d-1089070749f1","trusted":false,"collapsed":true},"cell_type":"code","source":"sns.barplot(x='Age', y=\"Survived\", hue=\"Sex\",\n            data=data_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b76744c196525de4755a227ae086dfd873718f6a","_cell_guid":"d72db17d-a1d0-40a0-982e-feae8afd7765","trusted":false,"collapsed":true},"cell_type":"code","source":"sns.barplot(x='Cabin', y=\"Survived\", hue=\"Sex\",\n            data=data_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"525de2bdef227a6ab883978843685da09103de41","_cell_guid":"6882099b-23ea-4a1a-a429-004f8943a3dd","trusted":false,"collapsed":true},"cell_type":"code","source":"sns.barplot(x=\"Fare\", y=\"Survived\", hue=\"Sex\",\n            data=data_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd12f092f7cce6d823b415e56f57e048015d0d25","_cell_guid":"b99ca239-4184-47df-8232-56bead51065a","trusted":false,"collapsed":true},"cell_type":"code","source":"from sklearn import preprocessing\ndef encode_features(df_train,df_test):\n    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']\n    df_combined = pd.concat([df_train[features], df_test[features]])\n    \n    for feature in features:\n        le = preprocessing.LabelEncoder()\n        le = le.fit(df_combined[feature])\n        df_train[feature] = le.transform(df_train[feature])\n        df_test[feature] = le.transform(df_test[feature])\n    return df_train, df_test\n\ndata_train, data_test = encode_features(data_train, data_test)\n\ndef scale_df(df):\n    temp_df = df[:]\n    mx_name = max(temp_df[\"Lname\"])\n    mn_name = min(temp_df[\"Lname\"])\n    mx_NamePrefix = max(temp_df[\"NamePrefix\"])\n    mn_NamePrefix = min(temp_df[\"NamePrefix\"])\n    temp_df['Lname'] = temp_df.Lname.apply(lambda x:((x-mn_name)/(mx_name-mn_name)))\n    temp_df['NamePrefix'] = temp_df.NamePrefix.apply(lambda x:((x-mn_NamePrefix)/(mx_NamePrefix-mn_NamePrefix)))\n    return temp_df\ndata_train_tf = scale_df(data_train)\ndata_test_tf = scale_df(data_test)\ndata_train","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a25ed4051af4f872f14f1694232473ff7e7e4f25","_cell_guid":"7455a054-acb2-4044-8e60-44c2c2561607","trusted":false,"collapsed":true},"cell_type":"code","source":"import tensorflow as tf\ntf.reset_default_graph()\nkeep_prob = tf.placeholder(tf.float32)\nx = tf.placeholder(tf.float32,[None, 9])\ny = tf.placeholder(tf.float32,[None, 1])\n\nw1 = tf.get_variable(\"w1\",shape=[9,59],initializer=tf.contrib.layers.xavier_initializer())\nlayer1 = tf.nn.relu(tf.matmul(x,w1))\nlayer1 = tf.nn.dropout(layer1, keep_prob=keep_prob)\n\n#w2 = tf.Variable(tf.random_normal([59,129]))\nw2 = tf.get_variable(\"w2\",shape=[59,129],initializer=tf.contrib.layers.xavier_initializer())\nlayer2 = tf.nn.relu(tf.matmul(layer1,w2))\nlayer2 = tf.nn.dropout(layer2, keep_prob=keep_prob)\n\n#w3 = tf.Variable(tf.random_normal([129,249]))\nw3 = tf.get_variable(\"w3\",shape=[129,249],initializer=tf.contrib.layers.xavier_initializer())\nlayer3 = tf.nn.relu(tf.matmul(layer2,w3))\nlayer3 = tf.nn.dropout(layer3, keep_prob=keep_prob)\n\n#w4 = tf.Variable(tf.random_normal([249,1]))\nw4 = tf.get_variable(\"w4\",shape=[249,349],initializer=tf.contrib.layers.xavier_initializer())\nlayer4 = tf.nn.relu(tf.matmul(layer3,w4))\nlayer4 = tf.nn.dropout(layer4, keep_prob=keep_prob)\n\nw5 = tf.get_variable(\"w5\",shape=[349,1],initializer=tf.contrib.layers.xavier_initializer())\n\nhypothesis = tf.nn.sigmoid(tf.matmul(layer4,w5))\ncost = -tf.reduce_mean(y*tf.log(hypothesis)+(1-y)*tf.log(1-hypothesis))\ntrain = tf.train.GradientDescentOptimizer(learning_rate = 1e-1).minimize(cost)\npredicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\naccuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y),dtype=tf.float32))\n\nsess=tf.Session()\nsess.run(tf.global_variables_initializer())\n\n\nfor step in range(801):\n    hy,cost_val,tt,pred,acc= sess.run([hypothesis,cost,train,predicted,accuracy], \n                                    feed_dict={x:data_train_tf.iloc[:,2:], \n                                               y:data_train.iloc[:,[1]],keep_prob:0.5})\n    if step%100 == 0:\n        print(\"learning\")\n        print(step,cost_val,acc)\n        \ntest_result = pd.read_csv(\"../input/gender_submission.csv\").iloc[:,[1]]\nhh,pp,aa = sess.run([hypothesis,predicted,accuracy],feed_dict={x:scale_df(data_test).iloc[:,1:],\n                                                               y:test_result,keep_prob:1})\nprint(aa)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b40e9077dcf42b3f7b6967ac6e9039e6cb91d68","_cell_guid":"409e34e2-c281-4f35-b592-ba10f2750cde","collapsed":true,"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\n\nclf = RandomForestClassifier()\nclf.fit(data_train_tf.iloc[:,2:], data_train.iloc[:,[1]])\n\npredict = clf.predict(scale_df(data_test).iloc[:,1:])\ntest_result = pd.read_csv(\"../input/gender_submission.csv\").iloc[:,[1]]\nac_score = metrics.accuracy_score(test_result, predict)\ncl_report = metrics.classification_report(test_result, predict)\n\nprint(ac_score)\nprint(cl_report)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}