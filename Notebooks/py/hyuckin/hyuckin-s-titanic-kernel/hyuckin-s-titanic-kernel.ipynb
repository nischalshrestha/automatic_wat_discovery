{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fbac329e-361b-c4a0-3cf3-a48b4d66246c"
      },
      "source": [
        "**Hello! This is my first Kaggle Kernel and my first foray into random forests.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a1616aba-0571-7af6-89cc-c8c4f1d10c9d"
      },
      "source": [
        "This is my first iteration, which is a simple version of the decision tree adapted from the datacamp tutorial.\n",
        "\n",
        "This iteration is a simple decision tree that uses Sex, Age, Passenger Class, and Fare as variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c1291c66-1462-72b7-59a2-5a9485800bd3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import tree\n",
        "\n",
        "# Copy the training and testing data to 'train' and 'test' respectively\n",
        "train = pd.read_csv(\"../input/train.csv\", dtype={\"Age\": np.float64},)\n",
        "test = pd.read_csv(\"../input/test.csv\", dtype={\"Age\": np.float64},)\n",
        "\n",
        "# Impute missing variables with the median value\n",
        "train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\n",
        "test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].median())\n",
        "test[\"Fare\"] = test[\"Fare\"].fillna(test[\"Fare\"].median())\n",
        "\n",
        "# Convert categorical data to discrete integers\n",
        "train.loc[train[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
        "train.loc[train[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
        "test.loc[test[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
        "test.loc[test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
        "\n",
        "# Create arrays to store target and feature values\n",
        "target = train[\"Survived\"].values\n",
        "features1 = train[[\"Sex\", \"Age\", \"Pclass\", \"Fare\"]].values\n",
        "\n",
        "# Create a tree using target and features\n",
        "decTree1 = tree.DecisionTreeClassifier()\n",
        "decTree1 = decTree1.fit(features1, target)\n",
        "print(\"Solution 1 score:\")\n",
        "print(decTree1.score(features1, target))\n",
        "print(\"Feature importances: Sex, Age, Pclass, Fare\")\n",
        "print(decTree1.feature_importances_)\n",
        "\n",
        "# Extract the test feature data\n",
        "test_features1 = test[[\"Sex\", \"Age\", \"Pclass\", \"Fare\"]].values\n",
        "\n",
        "# Make the prediction using the data tree\n",
        "prediction1 = decTree1.predict(test_features1)\n",
        "\n",
        "# Copy the prediction into a DataFrame\n",
        "PassengerId = np.array(test[\"PassengerId\"]).astype(int)\n",
        "solution1 = pd.DataFrame(prediction1, PassengerId, columns = [\"Survived\"])\n",
        "\n",
        "# Export the solution to a csv file\n",
        "solution1.to_csv('solution1.csv', index_label= [\"PassengerId\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "50ca022f-2b20-cd8a-5592-385dd9acbdde"
      },
      "source": [
        "This submission scored a 0.72727 on the public leaderboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4bf99ebf-e6f2-8474-0f9d-f42e061d72ee"
      },
      "source": [
        "I will now take the number of siblings and spouses aboard (SibSp), the number of parents and children aboard (Parch), port of embarkation (Embarked), and Cabin into account. For Cabin, I will assign a 1 if the person had a cabin and a 0 if not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c26fc4ec-5eee-c150-ea24-13270d8e69fc"
      },
      "outputs": [],
      "source": [
        "# Impute missing variables with mode \n",
        "train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n",
        "\n",
        "# Convert categorical data to discrete integers\n",
        "train.loc[train[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
        "train.loc[train[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
        "train.loc[train[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
        "test.loc[test[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
        "test.loc[test[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
        "test.loc[test[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
        "\n",
        "train.loc[pd.notnull(train[\"Cabin\"]), \"Cabin\"] = 1\n",
        "train.loc[pd.isnull(train[\"Cabin\"]), \"Cabin\"] = 0\n",
        "test.loc[pd.notnull(test[\"Cabin\"]), \"Cabin\"] = 1\n",
        "test.loc[pd.isnull(test[\"Cabin\"]), \"Cabin\"] = 0\n",
        "\n",
        "# Create array to store feature values\n",
        "features2 = train[[\"Sex\", \"Age\", \"Pclass\", \"Fare\", \"Embarked\", \"Cabin\", \"SibSp\", \"Parch\"]].values\n",
        "\n",
        "# Create a tree using target and features\n",
        "decTree2 = tree.DecisionTreeClassifier()\n",
        "decTree2 = decTree2.fit(features2, target)\n",
        "print(\"Solution 2 score:\")\n",
        "print(decTree2.score(features2, target))\n",
        "print(\"Feature importances: Sex, Age, Pclass, Fare, Embarked, Cabin, SibSp, Parch\")\n",
        "print(decTree2.feature_importances_)\n",
        "\n",
        "# Extract the test feature data\n",
        "test_features2 = test[[\"Sex\", \"Age\", \"Pclass\", \"Fare\", \"Embarked\", \"Cabin\", \"SibSp\", \"Parch\"]].values\n",
        "\n",
        "# Make the prediction using the data tree\n",
        "prediction2 = decTree2.predict(test_features2)\n",
        "\n",
        "# Copy the prediction into a DataFrame\n",
        "PassengerId = np.array(test[\"PassengerId\"]).astype(int)\n",
        "solution2 = pd.DataFrame(prediction2, PassengerId, columns = [\"Survived\"])\n",
        "\n",
        "# Export the solution to a csv file\n",
        "solution2.to_csv('solution2.csv', index_label= [\"PassengerId\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ffe1a459-5aaf-82a6-3d2e-c9ac9bdb9859"
      },
      "source": [
        "This submission scored a 0.67464 on the public leaderboard, lower than my previous attempt. This suggests that the decision tree overfitted the data, which makes sense as we introduced more features. To reduce the number of features, I will remove \"Embarked,\" which had the lowest feature importance value of  0.013. It also intuitively makes sense that the place of embarkation would not be a major contributive factor to survival. I will also combine \"SibSp\" and \"Parch\" into one variable, \"famSize\". "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "177fa0d7-7d4f-c524-9d47-a41ea0f72637"
      },
      "outputs": [],
      "source": [
        "# Add famSize column to train and test, where famSize = SibSp + Parch\n",
        "train = train.assign(famSize = train[\"SibSp\"] + train[\"Parch\"])\n",
        "test = test.assign(famSize = test[\"SibSp\"] + test[\"Parch\"])\n",
        "\n",
        "# Create array to store feature values\n",
        "features3 = train[[\"Sex\", \"Age\", \"Pclass\", \"Fare\", \"Cabin\", \"famSize\"]].values\n",
        "\n",
        "# Create a tree using target and features\n",
        "decTree3 = tree.DecisionTreeClassifier()\n",
        "decTree3 = decTree3.fit(features3, target)\n",
        "print(\"Solution 3 score:\")\n",
        "print(decTree3.score(features3, target))\n",
        "print(\"Feature importances: Sex, Age, Pclass, Fare, Cabin, famSize\")\n",
        "print(decTree3.feature_importances_)\n",
        "\n",
        "# Extract the test feature data\n",
        "test_features3 = test[[\"Sex\", \"Age\", \"Pclass\", \"Fare\", \"Cabin\", \"famSize\"]].values\n",
        "\n",
        "# Make the prediction using the data tree\n",
        "prediction3 = decTree3.predict(test_features3)\n",
        "\n",
        "# Copy the prediction into a DataFrame\n",
        "PassengerId = np.array(test[\"PassengerId\"]).astype(int)\n",
        "solution3 = pd.DataFrame(prediction3, PassengerId, columns = [\"Survived\"])\n",
        "\n",
        "# Export the solution to a csv file\n",
        "solution3.to_csv('solution3.csv', index_label= [\"PassengerId\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "543951db-016b-a494-45f7-d992134d0646"
      },
      "source": [
        "This submission scored a 0.59809 on the public leaderboard, which suggests that manual feature selection is not productive. I will try again with different sets of features:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ba867c02-1160-51a9-2b8d-d2335a59e6df"
      },
      "source": [
        "Sex, Age, Fare, famSize: 0.64593"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7b5dd5d3-cfe2-2890-4099-2dc2ae158c6a"
      },
      "source": [
        "Sex, Age, Fare: 0.68900"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0d0c353c-e39f-80f9-0c86-d21c6b4b497f"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "59561e48-2701-13bf-8fdf-ae538a3f2630"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}