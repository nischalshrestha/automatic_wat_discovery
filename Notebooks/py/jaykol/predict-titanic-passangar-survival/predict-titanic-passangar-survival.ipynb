{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8f2a8ae3-3b0f-b77f-d7e1-3089321189a8",
        "_active": false
      },
      "source": "***Hi, I'm Jayant Kolhe an IT professional working as ETL developer. My power to visualize data, derive meaning form it and love to python coding has landed me in the word of Data Science. As of today I'm novice in this area, but I'm gearing up really fast and writing this tutorial for my understanding and future reference. Also this tutorial will be very helpful for those who are new to kaggle.\nI assume you have basic knowledge of Python Data Science Toolkit, If not please first grab some basic hands-on with data science toolbox (Numpy, Pandas, Matplotlib, SciPy, Sklearn etc.)***",
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "2367614c-a55f-2d2f-be71-9f5603ca8e11",
        "_active": false,
        "collapsed": false
      },
      "source": "# This script shows you how to make a submission using a few\n# useful Python libraries.\n# It gets a public leaderboard score of 0.76077.\n# Maybe you can tweak it and do better...?\n\nimport pandas as pd\nimport xgboost as xgb\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\n\n# Load the data\ntrain_df = pd.read_csv('../input/train.csv', header=0)\ntest_df = pd.read_csv('../input/test.csv', header=0)\n\n\n# We'll impute missing values using the median for numeric columns and the most\n# common value for string columns.\n# This is based on some nice code by 'sveitser' at http://stackoverflow.com/a/25562948\nfrom sklearn.base import TransformerMixin\nclass DataFrameImputer(TransformerMixin):\n    def fit(self, X, y=None):\n        self.fill = pd.Series([X[c].value_counts().index[0]\n            if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n            index=X.columns)\n        return self\n    def transform(self, X, y=None):\n        return X.fillna(self.fill)\n\nfeature_columns_to_use = ['Pclass','Sex','Age','Fare','Parch']\nnonnumeric_columns = ['Sex']\n\n# Join the features from train and test together before imputing missing values,\n# in case their distribution is slightly different\nbig_X = train_df[feature_columns_to_use].append(test_df[feature_columns_to_use])\nbig_X_imputed = DataFrameImputer().fit_transform(big_X)\n\n# XGBoost doesn't (yet) handle categorical features automatically, so we need to change\n# them to columns of integer values.\n# See http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing for more\n# details and options\nle = LabelEncoder()\nfor feature in nonnumeric_columns:\n    big_X_imputed[feature] = le.fit_transform(big_X_imputed[feature])\n\n# Prepare the inputs for the model\ntrain_X = big_X_imputed[0:train_df.shape[0]].as_matrix()\ntest_X = big_X_imputed[train_df.shape[0]::].as_matrix()\ntrain_y = train_df['Survived']\n\n# You can experiment with many other options here, using the same .fit() and .predict()\n# methods; see http://scikit-learn.org\n# This example uses the current build of XGBoost, from https://github.com/dmlc/xgboost\ngbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(train_X, train_y)\npredictions = gbm.predict(test_X)\n\n# Kaggle needs the submission to have a certain format;\n# see https://www.kaggle.com/c/titanic-gettingStarted/download/gendermodel.csv\n# for an example of what it's supposed to look like.\nsubmission = pd.DataFrame({ 'PassengerId': test_df['PassengerId'],\n                            'Survived': predictions })\nsubmission.to_csv(\"submission.csv\", index=False)",
      "execution_count": 1,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9131513c-ddc6-aa2b-5e42-eb4bd04cabbf",
        "_active": false
      },
      "source": "Introduction\n============",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d0de72a4-45be-db76-6650-14de33f83185",
        "_active": false
      },
      "source": "Welcome to 'Titanic : A comprehensive guide.' Here my focus particularly on providing basic knowledge of data exploration and model building technique and not to create theoretical para-diagram. For this you can follow the source I have mention below or crawl around web to get your work done.   \n\nHere you will learn \nSteps of Data Exploration and Preparation \n  \n 1. Variable Identification\n 2. Uni-variate Analysis\n 3. Bi-variate Analysis\n 4. Missing values treatment\n 5. Variable transformation\n 6. Variable creation\n\nSource  :  [AnalyticsVidhya Data Exploration][1]\n\n\n  [1]: https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0cd3f59b-f931-e03b-a1a5-28cde81c7192",
        "_active": false
      },
      "source": "Steps of Data Exploration and Preparation\n--------------------------------------------",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "57967f74-dd3d-df14-021d-c796e50cc5de",
        "_active": false
      },
      "source": "Remember that the quality of your inputs decide the quality of your output. So, once you have got your business hypothesis ready, it makes sense to spend lot of time and efforts here. Data exploration, cleaning and preparation can take up to 70% of your total project time.\n\nBelow are the steps involved to understand, clean and prepare your data for building your predictive model:\n\n 1. Variable Identification\n 2. Univariate Analysis\n 3. Bi-variate Analysis\n 4. Missing values treatment\n 5. Outlier treatment\n 6. Variable transformation\n 7. Variable creation\n\nFinally, we will need to iterate over steps 4 – 7 multiple times before we come up with our refined model.\n\nLet’s now study each stage in  detail:-",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "df73ba98-c85a-1d39-42b1-c4ee01f7dd7c",
        "_active": false
      },
      "source": "## 1. Variable Identification##",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c3b870bc-8146-c65d-eb46-0f53aee86985",
        "_active": false
      },
      "source": "First, identify **Predictor (Input)** and **Target (output)** variables. Next, identify the data type and category of the variables.\n\nLet's Import required libraries and then our files. [Just import necessary packages and rest we can add any time to our code on the go.]",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e161e210-2678-e764-6e3f-c19b9781a50b",
        "_active": false
      },
      "outputs": [],
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Add packages as required by code below and execute this cell.\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "da16e838-9e2f-97df-e7ea-b1f85a0e3170",
        "_active": false
      },
      "source": "**Great !!!!**\nwe have imported all necessary packages.\nLet's get our hands dirty by importing train and test files to DataFrame",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c5f4af78-0c55-3f07-bf12-9bacbd7f169c",
        "_active": false
      },
      "outputs": [],
      "source": "# Kaggle you need to specify \"../input\" path for all your input files.\n\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8b44ed4a-4206-b6a9-6298-c42f3992b36d",
        "_active": false
      },
      "source": "**lets check 1st few data in our DataFrame**",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "86a301c8-af64-d910-bfee-f8b5271b1152",
        "_active": false
      },
      "outputs": [],
      "source": "train.head()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9f3e1992-756f-ca19-2434-734041eb9666",
        "_active": false
      },
      "outputs": [],
      "source": "test.head()"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fde8bfb8-d747-8a42-6847-b9430049a9ce",
        "_active": false
      },
      "source": "**Surprised!!!!** in test dataset \"Survived\" field missing, you might gess this is the field we need to predict in test dataset.",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "13eea395-1da1-506e-0b63-4f16a512cb8c",
        "_active": false
      },
      "source": "**Target = \"Survived\"**",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0c8f7eae-0165-fb85-e489-ccda58b13fc5",
        "_active": false
      },
      "source": "To predict the \"Survived\" (dependent variable) of a passenger we need to find independent variable over which survival depends.\n\nFollowing are the variables we have been provided, let find \"Survived\"  dependency\n\n 1. 'PassengerId' : It is unique value for each passenger and hence\n    won't contribute to our prediction at all\n 2. 'Pclass' : Passenger class can be deciding factor as people of\n    particular class was preferred for evacuation.\n 3. 'Name' : We may derive our decision based on title given to person\n    name, a higher ranking official may have higher chances of\n    surviving. It is part of future engineering to derive meaning out of\n    names for our survival decision.\n 4. 'Sex' : From titanic movie you can infer easily the females were\n    rescued first and thus 'Sex' plays a vital role to our prediction.\n 5. 'Age' : Age can have impact on our decision making and as we know\n    women was rescued first then they might be rescued along with their\n    child.\n 6. 'SibSp' : Siblings and Spouse, A person with any siblings or spouse\n    on-board does have higher rate of survival?\n 7. 'Parch': Parent and children , A person with parent or child\n    on-board does have higher rate of survival?  'Ticket' : People with\n    same ticket type may be travelling close to each other.\n 8. 'Fare' : Does fare has any impact ?\n 9. 'Cabin' : There is pattern the way Titanic flooded and sank, People\n    from some cabin were first to get dead as they were not having\n    enough time get alerted.\n 10. 'Embarked' : Well person embarked from particular place may have\n     survival chances as staying region allotted to them may be in close\n     proximity.\n\n ",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "50f9d3eb-7629-c831-6f90-0debce473737",
        "_active": false
      },
      "source": "**Good to Go !!!** So we have identified all our predictor variables that can contribute to our 'Survival' prediction. But wait, that's not all, we may not need all those variables and we may need to introduce new derived variables for our prediction. So **keep your finger crossed**. ",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d668a095-97be-72aa-6f81-b8bf1367d675",
        "_active": false
      },
      "source": "Let's characterized the variables by looking at sample data.\n\n**Categorical Data :**\n\n - Pclass : It has only three numeric values 1,2,3.\n - Sex :  Either male or female.\n - Embarked : S, Q, C\n\n**Continuous Data :**\n\n - Age\n - SibSp\n - Parch\n - Fare\n\nWonder How I come to know this, let's explore in next toipic.\n\nTicket and Cabin won't be useful for us, well we come to know shortly why.",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "70ab3125-cca4-23a5-d5e3-1913385b8ca9",
        "_active": false
      },
      "source": "## 2. Let's perform an Univariate Analysis (Analysis on individual variables)##\n\nMethod to perform uni-variate analysis will depend on whether the variable type is categorical or continuous.  In case of continuous variables, we need to understand the central tendency and spread of the variable. For categorical variables, we’ll use frequency table to understand distribution of each category and also we can be interested in finding the percentage of each category. ",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "639cb74f-248c-aee5-811d-d8e5bfeb3bee",
        "_active": false
      },
      "source": "First get train and test dataset info ",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4b845bd4-2703-dce2-1f98-f8a184d15d94",
        "_active": false
      },
      "outputs": [],
      "source": "train.info()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f7cb0fe9-4918-83aa-2124-fdb0a26912fe",
        "_active": false
      },
      "outputs": [],
      "source": "test.info()"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cee681ce-4b58-abd8-3c03-e8473d225b81",
        "_active": false
      },
      "source": "From above info it is clear that there are lot of missing value for **Cabin** and it **won't be useful** for our analysis.",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0607bbaa-d2b0-bcf3-8b78-bad355a8c397",
        "_active": false
      },
      "source": "**Check train data set and find how many survived and dead, it is not necessary but can be useful information when comparing with predicted values.**",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "28791e95-b3b7-1ab6-e777-f01d2b48a0fe",
        "_active": false
      },
      "outputs": [],
      "source": "# Count of People survived and dead\nprint(\"People survived count : \")\nsurvive_cnt = train.Survived.value_counts()\nprint(survive_cnt)\n# We can see out of 891 people in train DataSet only 342 survived and rest are dead\n\n# Let's find surviving percentage \nprint(\"Survived percentage : \")\nsurvive_per = (survive_cnt/survive_cnt.sum()) * 100\nprint(survive_per)\n# only 38.3 percent chance of survival\n\n# Divide figure into two plots having 1 row and 2 columns\nax1 = plt.subplot2grid((1,2),(0,0))\n\n# Define figure size on (x,y) axis\nplt.figsize=(10,5)\n\n# plot survived count to grid 1 (plot 1)\n_ = survive_cnt.plot(kind='bar', ax=ax1)\n_ = plt.title('Survived Count')\n_ = plt.xlabel('Survived')\n_ = plt.ylabel('Count')\nplt.margins(0.04)\n\n# Divide figure into two plots having 1 row and 2 columns\nax2 = plt.subplot2grid((1,2),(0,1))\n\n# plot survived percent to grid 2 (plot 2)\n_ = survive_per.plot(kind='bar', ax=ax2)\n_ = plt.title('Survived Percentage')\n_ = plt.xlabel('Survived')\n_ = plt.ylabel('percentage')\nplt.margins(0.04)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "16a1c3e7-7885-568f-a36b-647a870bc119",
        "_active": false
      },
      "source": "**Lets begin with Pclss univariate analysis**   (Categorical)",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "71fd24e9-9fd3-1ae6-eef8-802559b5e949",
        "_active": false
      },
      "outputs": [],
      "source": "# Cound number of categorical data\nplt.figure(figsize=(8,3))\npclass_cnt = train.Pclass.value_counts()\nprint(pclass_cnt)\n_ = pclass_cnt.plot(kind='barh')\n_ = plt.title('Class Count')\n_ = plt.xlabel('Count')\n_ = plt.ylabel('Pclass')\n# Do you see there are three class available 1,2 and 3."
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d4118d59-6ca7-6bd7-3474-27e87929317d",
        "_active": false
      },
      "source": "**Sex univariate analysis**  (Categorical)",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b20b225d-4263-192b-1f84-b1de7c8d0e9f",
        "_active": false
      },
      "outputs": [],
      "source": "# count the number of male and female\nprint(\"Male Female count : \")\nsex_cnt = train.Sex.value_counts()\nprint(sex_cnt)\n\n# percentage the number of male and female \nprint(\"Male Female percentage : \")\nsex_per = (sex_cnt/sex_cnt.sum()) * 100\nprint(sex_per)\n\n# Divide figure into two plots having 1 row and 2 columns\nax1 = plt.subplot2grid((1,2),(0,0))\n\n# Define figure size on (x,y) axis\nplt.figsize=(10,5)\n\n# plot survived count to grid 1 (plot 1)\n_ = sex_cnt.plot(kind='bar', ax=ax1)\n_ = plt.title('Sex Count')\n_ = plt.xlabel('Sex')\n_ = plt.ylabel('Count')\nplt.margins(0.04)\n\n# Divide figure into two plots having 1 row and 2 columns\nax2 = plt.subplot2grid((1,2),(0,1))\n\n# plot survived percent to grid 2 (plot 2)\n_ = sex_per.plot(kind='bar', ax=ax2)\n_ = plt.title('Sex Percentage')\n_ = plt.xlabel('Sex')\n_ = plt.ylabel('percentage')\nplt.margins(0.04)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7214cc08-2801-7ec4-3ba7-24fa2a92d3ed",
        "_active": false
      },
      "source": "**SibSp and Parch univariate analysis**  ()",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a3609cdd-65ec-1fb2-ce50-92ce70f73a9c",
        "_active": false
      },
      "outputs": [],
      "source": "# Plot for number of sibling and spouse count.\nplt.figsize=(15,3)\nax1 = plt.subplot2grid((1,2),(0,0))\n_ = train.SibSp.value_counts().plot(kind='bar', ax=ax1)\n_ = plt.title('Frequency of Siblings or Spouse on-board',  fontsize=8)\n_ = plt.xlabel('SibSp')\n_ = plt.ylabel('Frequency')\nplt.margins(.04)\n\nplt.figsize=(10,5)\nax2 = plt.subplot2grid((1,2),(0,1))\n_ = train.Parch.value_counts().plot(kind='bar', ax=ax2)\n_ = plt.title('Frequency of Parant or Children on-board', fontsize=8)\n_ = plt.xlabel('Parch')\n_ = plt.ylabel('Frequency')\nplt.margins(.04)\n\n# As there can be any size of family on-board we can call this variables as continuous. \n# (My understanding can be wrong here.)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "492c2aac-66dc-23af-eaaa-2ed46089a1e4",
        "_active": false
      },
      "source": "**Univariate analysis of Age**  (Continuous)",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3975d8cb-5d42-62a3-b70f-1eae25b498be",
        "_active": false
      },
      "outputs": [],
      "source": "# Lets plot Age by dropping null values\n_ = train.Age.dropna().plot(kind='hist', bins=50) \n_ = plt.xlabel('Age')\n# As age is floating point value we condider it in continuous variable catategory.\n# Age 18 to 35 is commomn.\n\n# Get central tendency for Age\nprint('Age average : ',train.Age.dropna().mean())\nprint('Age mode : ',train.Age.dropna().mode())\nprint('Age median : ',train.Age.dropna().median())"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "33736c01-4c31-c10b-199c-935a02b31a28",
        "_active": false
      },
      "source": "**Univariate analysis of Fare**   (Continuous)",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "57538991-e756-03eb-c056-3ae71caec1a9",
        "_active": false
      },
      "outputs": [],
      "source": "# As Fare available in floating point value for time being we will change it to integer and plot\nfare = train.Fare.astype(int)\n_ = sns.boxplot(data=fare)\n_ = plt.title('Fare distribution plot')\n_ = plt.ylabel('Fare')\n# from box plot it is easy to infer most of the people carrying ticket price less than 10 and \n# there are some ouliers (dots in plot) with high ticket value.\n\n# Get central tendency for Fare\nprint('Fare average : ',train.Fare.dropna().mean())\nprint('Fare mode : ',train.Fare.dropna().mode())\nprint('Fare median : ',train.Fare.dropna().median())"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0cecc570-f157-6557-51e6-537dba10aedc",
        "_active": false
      },
      "source": "**Univariate analysis on Embarked**   (Categorical)",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ca72d7d0-446b-7c2a-abf4-9bbf4149d651",
        "_active": false
      },
      "outputs": [],
      "source": "# Plot Embarked frequency\n_ = train.Embarked.value_counts().plot(kind='barh')\n_ = plt.title('Embarked frequency')\n_ = plt.xlabel('Embarked')\n_ = plt.ylabel('Frequency')\n# Embarked = S is most common"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "84270a01-d455-05d8-98a2-6f42eaf3b7f9",
        "_active": false
      },
      "source": "**Before moving to Bi-variate analysis, lets check train and test data feature distribution matches or not**",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "42a6ecc7-2a9f-acf0-7ee1-bce9fad0ee44",
        "_active": false
      },
      "outputs": [],
      "source": "plt.figure(figsize=(10,20))\n\n# distribution of class\nax1 = plt.subplot2grid((4,2),(0,0))\n_ = train['Pclass'].value_counts().plot(kind='barh', color='red', label='train', alpha=.6)\n_ = test['Pclass'].value_counts().plot(kind='barh', color='blue', label='test', alpha=.6)\n_ = ax1.set_title('class distribustion')\n_ = ax1.set_xlabel('Count')\n_ = ax1.set_ylabel('Class')\n_ = ax1.legend()\nplt.margins(0.04, ax=ax1)\n\n# distribution of Sex\nax2 = plt.subplot2grid((4,2),(0,1))\n_ = train['Sex'].value_counts().plot(kind='barh', color='red', label='train', alpha=.6)\n_ = test['Sex'].value_counts().plot(kind='barh', color='blue', label='test', alpha=.6)\n_ = ax2.set_title('Sex distribustion')\n_ = ax2.set_xlabel('Count')\n_ = ax2.legend()\nplt.margins(0.04, ax=ax2)\n\n# distribution of Age\nax3 = plt.subplot2grid((4,2),(1,0))\n_ = train['Age'].value_counts().plot(kind='kde', color='red', label='train', alpha=.6)\n_ = test['Age'].value_counts().plot(kind='kde', color='blue', label='test', alpha=.6)\n_ = ax3.set_title('Age distribustion')\n_ = ax3.set_xlabel('Age')\n_ = ax3.legend()\nplt.margins(0.04, ax=ax3)\n\n# distribution of SibSp\nax4 = plt.subplot2grid((4,2),(1,1))\n_ = train['SibSp'].value_counts().plot(kind='kde', color='red', label='train', alpha=.6)\n_ = test['SibSp'].value_counts().plot(kind='kde', color='blue', label='test', alpha=.6)\n_ = ax4.set_title('SibSp distribustion')\n_ = ax4.set_xlabel('SibSp')\n_ = ax4.legend()\nplt.margins(0.04, ax=ax4)\n\n# distribution of Parch\nax5 = plt.subplot2grid((4,2),(2,0))\n_ = train['Parch'].value_counts().plot(kind='kde', color='red', label='train', alpha=.6)\n_ = test['Parch'].value_counts().plot(kind='kde', color='blue', label='test', alpha=.6)\n_ = ax5.set_title('Parch distribustion')\n_ = ax5.set_xlabel('Parch')\n_ = ax5.legend\nplt.margins(0.04, ax=ax5)\n\n# distribution of Fare\nax6 = plt.subplot2grid((4,2),(2,1))\n_ = train['Fare'].value_counts().plot(kind='kde', color='red', label='train', alpha=.6)\n_ = test['Fare'].value_counts().plot(kind='kde', color='blue', label='test', alpha=.6)\n_ = ax6.set_title('Fare distribustion')\n_ = ax6.set_xlabel('Fare')\n_ = ax6.legend()\nplt.margins(0.04, ax=ax6)\n\n# distribution of Embarked\nax7 = plt.subplot2grid((4,2),(3,0), colspan=2)\n_ = train['Embarked'].value_counts().plot(kind='barh', color='red', label='train', alpha=.6)\n_ = test['Embarked'].value_counts().plot(kind='barh', color='blue', label='test', alpha=.6)\n_ = ax7.set_title('Embarked distribustion')\n_ = ax7.set_xlabel('Count')\n_ = ax7.set_ylabel('Embarked')\n_ = ax7.legend()\nplt.margins(0.04, ax=ax7)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8c1de39b-1e2b-6cce-2498-2d9b1778dd2a",
        "_active": false
      },
      "source": "From above graphs the feature distribution looks good.",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0e4a8bf4-08a3-bc4e-c61d-69cbe13b4259",
        "_active": false
      },
      "source": "## 3. Bi-Variate Analysis ##\n\nBi-variate Analysis finds out the relationship between two variables. We can perform bi-variate analysis for any combination of categorical and continuous variables. The combination can be: Categorical & Categorical, Categorical & Continuous and Continuous & Continuous.",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3a1b6479-a97f-84da-279c-63d43985ed4d",
        "_active": false
      },
      "source": "**Bi-variate analysis of Pclass with Survival**  (Categorical vs Categorical)",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7ff60711-ae94-1f6a-0b88-a3efc9826c18",
        "_active": false
      },
      "outputs": [],
      "source": "# Class with survival\n# It is always better to use stacked chart for bi-variate analysis of categorical vs categorical data.\nfig = plt.figure(figsize=(10,5))\n\nsurvived_dead = pd.DataFrame({'Survived' : train[train.Survived==1].Pclass.value_counts(),\n                         'Dead' : train[train.Survived==0].Pclass.value_counts()\n                        })\n\n_ = survived_dead.plot(kind='bar')\n_ = plt.xlabel('Class')\n_ = plt.ylabel('Frequency')\n_ = plt.title('Class Vs Survived')\n\n# Class 2 and 3 passangar are less likely to survive"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ec12902e-8b05-0248-8fa8-267a297016f6",
        "_active": false
      },
      "source": "**Bi-variate analysis of Sex with Survival**  (Categorical vs Categorical)",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d31295fa-2c1d-96d8-26cd-e86f1f0e16c1",
        "_active": false
      },
      "outputs": [],
      "source": "# Sex with survival\n\nmf_serv = pd.DataFrame(train.Sex)\nmf_serv['Survived'] = train[train.Survived==1].Survived\nmf_serv['Dead'] = train[train.Survived==0].Survived\nmf_serv = mf_serv.sort_values('Sex').groupby('Sex').agg('count')\n_ = mf_serv.plot(kind='bar')\n_ = plt.title('Sex Vs Survived')\n\n#Females are more likely to survive"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7f8508f2-cfe5-8102-970b-a3fde8d216c6",
        "_active": false
      },
      "source": "**Bi-variate analysis of Family with Survival**  (Continuous vs Categorical)",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d60dc1a0-272a-b77e-ae73-46efa7ae06d2",
        "_active": false
      },
      "outputs": [],
      "source": "# Well the passenger with its siblings/ spouse and Prarent/ children form a family and \n# number of family member can decide their survival\n\nfamily = train['SibSp'] + train['Parch'] + 1\nfam_serv = pd.DataFrame({'family':family})\nfam_serv['Survived'] = np.nan\nfam_serv['Dead'] = np.nan\nfam_serv['Survived'] = train[train.Survived==1].Survived\nfam_serv['Dead'] = train[train.Survived==0].Survived\nfam_serv = fam_serv.sort_values('family').groupby('family').agg('count')\n_ = fam_serv.plot(kind='bar')\n_ = plt.title('Family Vs Survived')\n\n# From graph it is quite clear an individual person has minimal chance of survival \n# compared with when he is in accompany with 2 to 4."
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "283eec3f-62d1-e5c2-3a30-0da0db4a4d89",
        "_active": false
      },
      "source": "**Bi-variate analysis of Age with Survival**  (Continuous vs Categorical)",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1caa70e1-fb9d-e4fe-4216-462e8fe30e72",
        "_active": false
      },
      "outputs": [],
      "source": "# Age with survival\n# we will get three columns 1st one will hold Ages 2nd are they survived and 3rd if they dead\n\nage_serv = train[['Survived','Age']]\nfig = sns.FacetGrid(data=age_serv, hue='Survived', aspect=2).map(sns.kdeplot,'Age', shade=True)\n_ = fig.add_legend()\n\n# from fig. we can infer the survival changes of childern are high."
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d6476ca8-d04d-ac24-6049-160b315f53bb",
        "_active": false
      },
      "source": "**Bi-variate analysis of Fare with Survival**  (Continuous vs Categorical)",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5a602595-73f6-9b95-cf67-3b227642bc49",
        "_active": false
      },
      "outputs": [],
      "source": "# In uni-variate analysis we found that Fare has outliers we will try to normalised this\n\nplt.figure(figsize=(8,3))\n\nfare = train.Fare\nfare_norm = np.log(train.Fare.dropna()+1) # added 1 to avoid log(0) as undefine, log(1)=0\nfare_plt = pd.DataFrame({'Fare':fare, 'Fare_norm': fare_norm })\nfare_plt['points'] = np.arange(len(fare))\n\nax1 = plt.subplot2grid((1,2),(0,0))\n_ = fare_plt.plot(kind='scatter',x='Fare', y='points', title='Fare', ax=ax1)\nax2 = plt.subplot2grid((1,2),(0,1))\n_ = fare_plt.plot(kind='scatter',x='Fare_norm', y='points', title='Normalized Fare', ax=ax2)\n\n# Now we will check distribution of Normalized Fare with that of survived\n\n#fare_serv = pd.DataFrame({'Fare' : fare_norm, \n#                          'Survived':train[train.Survived==1].Survived,\n#                          'Dead':train[train.Survived==0].Survived,\n#                         })\n\nfare_serv = pd.DataFrame({'Fare' : fare_norm, 'Survived':train.Survived })\n#ax3 = plt.subplot2grid((2,2),(1,0))\n_ = sns.FacetGrid(data=fare_serv,aspect=2).map(sns.boxplot,'Survived','Fare')\n\n#ax4 = plt.subplot2grid((2,2),(1,1))\nfig = sns.FacetGrid(data=fare_serv,hue='Survived', aspect=2).map(sns.kdeplot,'Fare')\nfig.add_legend()\n# it is clear there is higher chances of survival with normalized fare of 3 to 7. "
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3357589f-297c-8b89-f751-325f3fcaa55b",
        "_active": false
      },
      "source": "**Bi-variate analysis of Embarked with Survival**  (Categorical vs Categorical)",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "645bf36f-f57a-d270-dd34-739a661466df",
        "_active": false
      },
      "outputs": [],
      "source": "# Embarked vs survival\n\nemb_serv = pd.DataFrame(train['Embarked'])\nemb_serv['Survived'] = train[train.Survived==1].Survived\nemb_serv['Dead'] = train[train.Survived==0].Survived\nemb_serv = emb_serv.sort_values('Embarked').groupby('Embarked').agg('count')\nemb_serv.plot(kind='bar')\n\n# Embark doesn't give clear picture of survival, we can consider survival rate of embarked=C is higher"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "eff2d83d-db60-31ef-f123-d20bf1ba8dfa",
        "_active": false
      },
      "source": "## 4. Missing Value Treatment ##",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8eab8ad8-30d6-89eb-d473-88f2b8187ffa",
        "_active": false
      },
      "source": "Join both train and test dataset, it will simplify data cleanup process",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4e0a9a24-f2cc-953f-5036-04199d69232b",
        "_active": false
      },
      "outputs": [],
      "source": "full = pd.concat([train,test], ignore_index=True)\nfull.head()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "590ec001-2a09-3a1c-f99f-2d0eda48f0e8",
        "_active": false
      },
      "outputs": [],
      "source": "full.tail()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a9e0d14b-fe2f-df72-f002-c6f49ba66eae",
        "_active": false
      },
      "outputs": [],
      "source": "# get missing count for each field\nfull.isnull().sum()\n# total entries are 1309 and we can see data is missing for Age, Embarked and Fare predictors."
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "05c0f2e4-881a-0cab-7525-90bde439a422",
        "_active": false
      },
      "source": "**Missing Embarked** ",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "66699853-051c-c12d-7771-b438dd6b6aa2",
        "_active": false
      },
      "outputs": [],
      "source": "# Filing missing Embarked\n\n# We have two option to fill missing value either by using most common value for categorical data \n# or by finding the relation of Embarked with other predictors \n# It will be advisable to use 2nd approach as we can fill more accurate data and can increase the \n# accuracy of prediction.\n\n# let consider Embarked dependency on other variables.\n\nprint(full[full.Embarked.isnull()])\n\nEmbrk_fill = full[['Embarked','Pclass','Fare']]\nEmbrk_fill['Fare'] = Embrk_fill['Fare'].dropna().astype(int)\n_ = Embrk_fill.boxplot(by=['Embarked','Pclass'])\n# draw horizontal line through y=80 \n_ = plt.axhline(y=80)\n# Set missing value to C as we can clearly see y=80 has better intersection through Embarked=C and Pclass=1\nfull.Embarked.fillna('C', inplace=True)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "76be00c3-47dd-83ab-970a-7e326599cd8d",
        "_active": false
      },
      "outputs": [],
      "source": "full.isnull().sum()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3ec0bf5b-b75e-9166-c465-1fe4f5f52265",
        "_active": false
      },
      "outputs": [],
      "source": "1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8bb268b6-011a-2b87-158e-58ab30191fd9",
        "_active": false
      },
      "outputs": [],
      "source": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8f88a2cb-0661-b960-8166-0208a02f2d9a",
        "_active": false
      },
      "outputs": [],
      "source": "# Fill Embarked\ntrain[train.Embarked.isnull()]\n\n# Check Fare,Pclass and Embarked trend\nEmbrk_fare = train[['Embarked','Pclass','Fare']]\nEmbrk_fare['Fare'] = Embrk_fare.Fare.astype(int)\n#Embrk_fare = Embrk_fare.sort_values('Fare').groupby(['Embarked','Fare']).agg('count').reset_index()\nEmbrk_fare.boxplot(by=['Embarked','Pclass'])\nplt.axhline(y=80, color='green')\n\n_ = train.set_value(train.Embarked.isnull(),'Embarked','C')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "faf1ae49-e323-a494-ed0e-9ef3b7919e6f",
        "_active": false
      },
      "outputs": [],
      "source": "# fill missing fare\nfrom collections import Counter\ntest[test.Fare.isnull()]\ncommon_fare = Counter(test[(test.Pclass==3) & (test.Embarked=='S')].Fare.sort_values().dropna().astype(int)).most_common(5)\nobsr_mul = [fare[0]*fare[1] for fare in common_fare]\nobsr_num = [fare[1] for fare in common_fare]\nnew_fare = sum(obsr_mul)/sum(obsr_num)\nnew_fare\n_ = test.set_value(test.Fare.isnull(),'Fare',new_fare)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "db56b8d3-c338-b82b-44a9-f202fcc2bddc",
        "_active": false
      },
      "outputs": [],
      "source": "# fill age\nplt.figure(figsize=(8,5))\n\ntrain_mean = train.Age.mean()\ntrain_std  = train.Age.std()\ntest_mean = test.Age.mean()\ntest_std  = test.Age.std()\nprint(train_mean,train_std)\nprint(test_mean,test_std)\n\nax1 = plt.subplot2grid((2,1),(0,0))\ntrain_copy = train.copy()\ntrain_copy.Age.hist(bins=70)\ndel(train_copy)\n\ntest_age = np.random.randint(low=train_mean-train_std,\n                             high=train_mean+train_std,\n                             size=train.Age.isnull().sum()\n                            )\n_ = train.set_value(train.Age.isnull(), 'Age', test_age)\n\ntrain_age = np.random.randint(low=test_mean-test_std,\n                              high=test_mean+test_std,\n                              size=test.Age.isnull().sum()\n                             )\n\n_ = test.set_value(test.Age.isnull(), 'Age', train_age)\nax2 = plt.subplot2grid((2,1),(1,0))\ntrain.Age.hist(bins=70)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "919a496b-dcd3-7a2e-82ac-db2638ea6044",
        "_active": false
      },
      "source": "## Feature Engineering  ##",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ca33416a-26ec-1131-535e-079cffd7dd18",
        "_active": false
      },
      "outputs": [],
      "source": "# Set numeric value for Sex\n# 1 for male and 0 for female\n\ntrain['Sex_n'] = np.nan\n_ = train.set_value(train.Sex=='male','Sex_n',1)\n_ = train.set_value(train.Sex!='male','Sex_n',0)\n\ntest['Sex_n'] = np.nan\n_ = test.set_value(test.Sex=='male','Sex_n',1)\n_ = test.set_value(test.Sex!='male','Sex_n',0)\n\ntrain['Sex_n'] = train['Sex_n'].astype(int)\ntest['Sex_n'] = test['Sex_n'].astype(int)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "838884fe-9685-5f08-b5f1-e16eec2a0336",
        "_active": false
      },
      "outputs": [],
      "source": "# Set normalized value for Fare\ntrain['Fare_n'] = np.nan\ntest['Fare_n'] = np.nan\n_ = train.set_value(train.index,'Fare_n',train.Fare.astype(int))\n_ = test.set_value(test.index,'Fare_n',test.Fare.astype(int))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2ee8a40d-2eca-b1e3-72f1-2c96a598c476",
        "_active": false
      },
      "outputs": [],
      "source": "# Set numeric values for Embarked\n# S=0, C=1 and Q=2\ntrain['Embarked_n'] = np.nan\n_ = train.set_value(train.Embarked=='S','Embarked_n',0)\n_ = train.set_value(train.Embarked=='C','Embarked_n',1)\n_ = train.set_value(train.Embarked=='Q','Embarked_n',0)\n\ntest['Embarked_n'] = np.nan\n_ = test.set_value(test.Embarked=='S','Embarked_n',0)\n_ = test.set_value(test.Embarked=='C','Embarked_n',1)\n_ = test.set_value(test.Embarked=='Q','Embarked_n',0)\n\ntrain['Embarked_n'] = train['Embarked_n'].astype(int)\ntest['Embarked_n'] = test['Embarked_n'].astype(int)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "96f6ff15-7ce2-652e-a41e-6561762969a2",
        "_active": false
      },
      "outputs": [],
      "source": "# create copy of pclass\ntrain['class'] = train['Pclass']\ntest['class'] = test['Pclass']"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b20bb830-8e68-a272-3872-63755c9ed3ef",
        "_active": false
      },
      "outputs": [],
      "source": "# create variable taht list male fimale and child\n# male=0, female=1, child=2\ntrain['MFC'] = np.nan\n_ = train.set_value((train.Sex=='male') & (train.Age>18), 'MFC', 0)\n_ = train.set_value((train.Sex!='male') & (train.Age>18), 'MFC', 1)\n_ = train.set_value(train.Age<=18, 'MFC', 2)\n\ntest['MFC'] = np.nan\n_ = test.set_value((test.Sex=='male') & (test.Age>18), 'MFC', 0)\n_ = test.set_value((test.Sex!='male') & (test.Age>18), 'MFC', 1)\n_ = test.set_value(test.Age<=18, 'MFC', 2)\n\ntrain['MFC'] = train['MFC'].astype(int)\ntest['MFC'] = test['MFC'].astype(int)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c3e0aa96-dfd3-7fcd-9153-396ba619c357",
        "_active": false
      },
      "outputs": [],
      "source": "# setup family count\n# 'low',0 for count =1, 'med',1 for count =(2,3,4), 'high',2 for count>4 \ntrain['family'] = np.nan\ntest['family'] = np.nan\ntrain['family'] = (train['SibSp'] + train['Parch'] + 1).astype(int)\ntest['family'] = (test['SibSp'] + test['Parch'] + 1).astype(int)\n\n\ntrain['family_size'] = 1\n_ = train.set_value(train['family']==1,'family_size',0)\n_ = train.set_value(train['family']>4,'family_size',2)\ntest['family_size'] = 1\n_ = test.set_value(test['family']==1,'family_size',0)\n_ = test.set_value(test['family']>4,'family_size',2)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "22b0d16d-962d-5d02-4bb3-4fb2c0203e4f",
        "_active": false
      },
      "source": "## Random Forest ##",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "42a15886-2570-cef0-52df-24b2763299d6",
        "_active": false
      },
      "outputs": [],
      "source": "train.info()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5378fd72-ff5c-e0f2-98a4-7d708e998e65",
        "_active": false
      },
      "outputs": [],
      "source": "from sklearn.ensemble import RandomForestClassifier\n\ntrain_features = train[['Sex_n','class','family_size']]\ntest_features = test[['Sex_n','class','family_size']]\ntrain_target = train.Survived\nrand_forest = RandomForestClassifier(n_estimators=100,#random_state=42, #criterion='entropy', \n                                     min_samples_split=2, #oob_score=True, min_samples_leaf=12\n                                     max_depth= 10\n                                    )\nrand_forest = rand_forest.fit(train_features,train_target)\npredicted = rand_forest.predict(test_features)\nprint(rand_forest.score(train_features,train_target))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d26d6a56-3587-a963-8250-a7a50ec0be47",
        "_active": false
      },
      "outputs": [],
      "source": "# write predicted values for submission\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": predicted\n    })\nsubmission.to_csv('Predicted_Survival.csv', index=False)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5c9df17b-28f1-2f10-b202-96a20679f20c",
        "_active": false
      },
      "outputs": [],
      "source": "rand_forest.feature_importances_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "05b72916-fa49-6583-6f63-d445256ec801",
        "_active": false
      },
      "outputs": [],
      "source": "array([ 0.59298075,  0.05196973,  0.24705396,  0.10799557])"
    }
  ]
}