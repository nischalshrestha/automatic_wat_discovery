{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"version": "3.6.3", "file_extension": ".py", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "name": "python", "nbconvert_exporter": "python"}}, "nbformat": 4, "cells": [{"metadata": {"_cell_guid": "67320079-651f-4668-ba31-b44499a6ceee", "_uuid": "72f452a55eaa2cfc159e844173838fcc2d2284c5"}, "cell_type": "code", "execution_count": null, "source": ["import pandas as pd\n", "import numpy as np\n", "from sklearn.preprocessing import RobustScaler\n", "import keras\n", "from keras import backend as K\n", "from keras.models import Sequential\n", "from keras.models import Model\n", "from keras.layers.core import Dense, Dropout, Activation, Reshape\n", "from keras.layers import Input\n", "from keras.layers.normalization import BatchNormalization\n", "from keras.optimizers import Adam\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "%matplotlib inline\n", "\n", "# fix random seed for reproducibility\n", "RANDOM_STATE = 7\n", "np.random.seed(RANDOM_STATE)"], "outputs": []}, {"metadata": {"_cell_guid": "19d395c3-b331-4b30-9a2c-bd549836384d", "_uuid": "40b68f9474e16f4471976cbb9481fad2f9143617"}, "cell_type": "code", "execution_count": null, "source": ["train = pd.read_csv('../input/train.csv',dtype={'Age': np.float32, 'Fare': np.float32})\n", "# get rid of the useless cols\n", "train.drop(['PassengerId', 'Ticket'], axis=1, inplace=True)\n", "\n", "train.info()\n", "train.head()"], "outputs": []}, {"metadata": {"_cell_guid": "b8c305f6-63e6-4537-8add-95ce847b5a76", "_uuid": "28df25eede8d7d743a2013b5b6f61514238d78bc"}, "cell_type": "markdown", "source": ["You will notice that each name has a title in it ! This can be a simple Miss. or Mrs. but it can be sometimes something more sophisticated like Master, Sir or Dona. In that case, we might introduce an additional information about the social status by simply parsing the name and extracting the title."]}, {"metadata": {"_cell_guid": "b15dd6b1-e249-4a3a-b47b-547688eaa9ab", "_uuid": "88b73c5266215a7d56afc81bf11fbd566a4a2802"}, "cell_type": "code", "execution_count": null, "source": ["def add_titles(dataFrame):\n", "    # we extract the title from each name\n", "    dataFrame['Title'] = dataFrame['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n", "    # a map of more aggregated titles\n", "    Title_Dictionary = {\n", "                        \"Capt\":       \"Officer\",\n", "                        \"Col\":        \"Officer\",\n", "                        \"Major\":      \"Officer\",\n", "                        \"Dr\":         \"Officer\",\n", "                        \"Rev\":        \"Officer\",\n", "                        \"Jonkheer\":   \"Royalty\",\n", "                        \"Don\":        \"Royalty\",\n", "                        \"Sir\" :       \"Royalty\",\n", "                        \"the Countess\":\"Royalty\",\n", "                        \"Dona\":       \"Royalty\",\n", "                        \"Lady\" :      \"Royalty\",\n", "                        \"Mr\" :        \"Mr\",\n", "                        \"Mme\":        \"Mrs\",\n", "                        \"Ms\":         \"Mrs\",\n", "                        \"Mrs\" :       \"Mrs\",\n", "                        \"Mlle\":       \"Miss\",\n", "                        \"Miss\" :      \"Miss\",\n", "                        \"Master\" :    \"Master\"\n", "                        }    \n", "    # we map each title\n", "    dataFrame['Title'] = dataFrame.Title.map(Title_Dictionary)\n", "\n", "add_titles(train)\n", "train.drop(['Name'], axis=1, inplace=True)\n", "train.head()"], "outputs": []}, {"metadata": {"_cell_guid": "3ff493c3-cabd-4116-a6e0-227ae0e9d78e", "_uuid": "95432e11ede29b9885dfb26c34981afc29d1bba8"}, "cell_type": "code", "execution_count": null, "source": ["train['Age'].isnull().sum()\n", "# there are 173 other missing ages, fill with random int\n", "#age_mean = train['Age'].mean()\n", "#age_std = train['Age'].std()\n", "#filling = np.random.randint(age_mean-age_std, age_mean+age_std, size=nan_num)\n", "#train.loc[train['Age'].isnull(), 'Age'] = filling\n", "#nan_num = train['Age'].isnull().sum()\n", "\n", "#look into the age col\n", "s = sns.FacetGrid(train,hue='Survived',aspect=3)\n", "s.map(sns.kdeplot,'Age',shade=True)\n", "s.set(xlim=(0,train['Age'].max()))\n", "s.add_legend()"], "outputs": []}, {"metadata": {"_cell_guid": "37d2ad40-1a72-4911-9e8e-ab371e8e4db0", "_uuid": "83eba28fe042bcb7219da2f72ba8eb2597aba968"}, "cell_type": "code", "execution_count": null, "source": ["# Combine Sibsp and Parch features to Family feature\n", "# check\n", "print(train['SibSp'].value_counts(dropna=False))\n", "print(train['Parch'].value_counts(dropna=False))\n", "\n", "sns.factorplot('SibSp','Survived',data=train,size=5)\n", "sns.factorplot('Parch','Survived',data=train,size=5)\n", "\n", "'''through the plot, we suggest that with more family member, the survival rate will drop, we can create the new col\n", "add up the parch and sibsp to check our theory''' \n", "train['Family'] = train['SibSp'] + train['Parch']\n", "sns.factorplot('Family','Survived',data=train,size=5)\n", "\n", "train.drop(['SibSp','Parch'],axis=1,inplace=True)"], "outputs": []}, {"metadata": {"_cell_guid": "f46d7eb0-b84e-4cf1-be64-4c824d358ff6", "_uuid": "265c66528257461e478656133eb75f315a4c24ed"}, "cell_type": "code", "execution_count": null, "source": ["# fare research\n", "train.Fare.isnull().sum()\n", "sns.factorplot('Survived','Fare',data=train,size=5)\n", "#according to the plot, smaller fare has higher survival rate"], "outputs": []}, {"metadata": {"collapsed": true, "_cell_guid": "62048dab-500a-4ec3-8c80-b02469d5f721", "_uuid": "57d7070daa35f800b65915191995a9fd843544fe"}, "cell_type": "code", "execution_count": null, "source": ["#Cabin feature research\n", "# checking missing val, 687 out of 891 are missing, drop this col\n", "train.Cabin.value_counts(dropna=False)\n", "train.drop('Cabin',axis=1,inplace=True)"], "outputs": []}, {"metadata": {"_cell_guid": "74305ebf-e3ea-431f-8b6e-52ba089f3bd9", "_uuid": "c5e9c83f34f9f4e5e69be6263297816815c4786a"}, "cell_type": "code", "execution_count": null, "source": ["#Embark feature search\n", "# 2 missing value\n", "train.Embarked.value_counts(dropna=False)\n", "# fill the majority val,'s', into missing val col\n", "train['Embarked'].fillna('S',inplace=True)\n", "\n", "sns.factorplot('Embarked','Survived',data=train,size=6)\n", "# c has higher survival rate"], "outputs": []}, {"metadata": {"collapsed": true, "_kg_hide-output": false, "_cell_guid": "b483c8e9-7152-4752-8a11-90462ff40881", "_uuid": "ff8f1b12f7f0f5719449ef62ab29b06ee77a8df9"}, "cell_type": "code", "execution_count": null, "source": ["# Define a few feature preparation helpers\n", "def normalize(df, column):\n", "    series = df[column]\n", "    min = series.min()\n", "    max = series.max()\n", "    if (min==max):\n", "        print(series.name + ' has only one value and should be removed.')\n", "    scaler = RobustScaler()\n", "    x = scaler.fit_transform(series.values.reshape(-1,1)).reshape(-1)\n", "    df[column] = pd.Series(x)\n", "    return scaler\n", "\n", "def transform(df, column, scaler):\n", "    series = df[column]\n", "    x = scaler.transform(series.values.reshape(-1,1)).reshape(-1)\n", "    df[column] = pd.Series(x)\n", "\n", "def encode_one_hot(df, column, axis=1):\n", "    x = df.join(pd.get_dummies(df[column], prefix=column, sparse=True))\n", "    x.drop(column, axis=axis, inplace=True)\n", "    return x\n", "\n", "def FeaturesImportances(X_train, y_train, featureNames):\n", "    from sklearn.ensemble import RandomForestClassifier\n", "    from sklearn.feature_selection import SelectFromModel\n", "    rfr = RandomForestClassifier()\n", "    rfr.fit(X_train, y_train)\n", "\n", "    sfm = SelectFromModel(rfr, prefit=True, threshold=0)\n", "    selected = sfm.get_support()\n", "    names = featureNames[selected]\n", "    scores = rfr.feature_importances_[selected]\n", "    importances = pd.DataFrame({'feature':names,'importance':np.round(scores,5)})\n", "    importances = importances.sort_values('importance').set_index('feature')\n", "    #importances.to_csv(\"importances.csv\")\n", "    #print(\"Selected {} features\".format(len(names)))\n", "    #print(importances)\n", "    #importances.plot.bar()\n", "    importances.plot(kind='barh', figsize=(20, 20))\n", "    #plt.show()\n", "    return sfm"], "outputs": []}, {"metadata": {"_cell_guid": "da0c3550-6aa0-4fe2-8d0b-f2f2d170117f", "_uuid": "ef8b3745ecbcd534d4d8acdc537d5e7291d84fc8"}, "cell_type": "code", "execution_count": null, "source": ["#Encoding training features\n", "\n", "print(\"Encoding Pclass categorical features...\")\n", "train = encode_one_hot(train, 'Pclass')\n", "print(\"Encoding Sex categorical features...\")\n", "train = encode_one_hot(train, 'Sex')\n", "print(\"Encoding Embarked categorical features...\")\n", "train = encode_one_hot(train, 'Embarked')\n", "print(\"Encoding Title categorical features...\")\n", "train = encode_one_hot(train, 'Title')\n", "\n", "#scale only numeric features\n", "print(\"scaling numeric features...\")\n", "#ageScaler = normalize(train, \"Age\")\n", "fareScaler = normalize(train, \"Fare\")\n", "familyScaler = normalize(train, \"Family\")"], "outputs": []}, {"metadata": {"_cell_guid": "a13f5bd9-8f89-40d7-a61a-74a8da9d6bc3", "_uuid": "0cbf3378117f5624fbc192bc6dac1670ed3eb3ed"}, "cell_type": "code", "execution_count": null, "source": ["# Train age prediction model to predict missing ages\n", "def getAgePredictionModel(dataFrame):\n", "    def CreateModel(X):\n", "        ip = Input(shape=(X.shape[1],))\n", "        x_list = [ip]\n", "\n", "        x = Dense(128, use_bias=False)(ip)\n", "        x = BatchNormalization()(x)\n", "        x = Activation('relu')(x)\n", "        x = Dropout(0.5)(x)\n", "\n", "        x_list.append(x)\n", "        x = keras.layers.concatenate(x_list)    \n", "        x = Dense(64, use_bias=False)(x)    \n", "        x = BatchNormalization()(x)\n", "        x = Activation('relu')(x)\n", "        x = Dropout(0.5)(x)\n", "\n", "        x_list.append(x)\n", "        x = keras.layers.concatenate(x_list)    \n", "        x = Dense(32, use_bias=False)(x)    \n", "        x = BatchNormalization()(x)\n", "        x = Activation('relu')(x)\n", "        x = Dropout(0.5)(x)\n", "\n", "        op = Dense(1)(x)\n", "\n", "        model = Model(inputs=ip, outputs=op)\n", "        adam = Adam(lr=0.05,)\n", "        model.compile(loss='mean_squared_error', optimizer=adam, metrics=['MAE'])\n", "        return model\n", "\n", "    trainCpy = dataFrame[dataFrame['Age'].isnull()==False]\n", "    age = trainCpy['Age']\n", "    trainCpy.drop(['Age'], axis=1, inplace=True)\n", "    if 'Survived' in trainCpy.columns:\n", "        trainCpy.drop('Survived', axis=1, inplace=True)\n", "    trainCpy.head()\n", "\n", "    model = CreateModel(trainCpy)\n", "\n", "    print(\"Training age model...\")\n", "    model.fit(trainCpy.as_matrix(), age.values, epochs=500, batch_size=32, verbose=0)\n", "    return model\n", "\n", "def fillMissingAges(dataFrame, agePredictionModel):\n", "    #predict missing ages\n", "    tmp = dataFrame[dataFrame['Age'].isnull()==True]\n", "    tmp.drop('Age', axis=1, inplace=True)\n", "    if 'Survived' in tmp.columns:\n", "        tmp.drop('Survived', axis=1, inplace=True)\n", "    age_pred = agePredictionModel.predict(tmp.as_matrix())\n", "    #fill missing ages\n", "    dataFrame.loc[dataFrame['Age'].isnull(), 'Age'] = age_pred\n", "    return dataFrame\n", "\n", "agePredictionModel = getAgePredictionModel(train)\n", "fillMissingAges(train, agePredictionModel)\n", "\n", "#look into the age col\n", "s = sns.FacetGrid(train, hue='Survived', aspect=3)\n", "s.map(sns.kdeplot,'Age',shade=True)\n", "s.set(xlim=(0,train['Age'].max()))\n", "s.add_legend()\n", "\n", "#nomalize age\n", "ageScaler = normalize(train, \"Age\")\n", "\n", "y = train['Survived']\n", "train.drop('Survived', axis=1, inplace=True)\n", "X = train"], "outputs": []}, {"metadata": {"_kg_hide-output": false, "_cell_guid": "03cb5a4b-d27d-43e9-ba40-4bb1f55dd9e5", "_uuid": "eb4b416ef97f24bf3c55e440fbe1687091140366"}, "cell_type": "code", "execution_count": null, "source": ["# Check feature importances, I keep all the features in X because it has only\n", "# a few feautures.\n", "FeaturesImportances(X, y, X.columns.values)"], "outputs": []}, {"metadata": {"collapsed": true, "_cell_guid": "22f383e1-a556-46b8-b46b-1c58c34bc4fd", "_uuid": "282a7ea1df2038beef97e5331fefe4742735eb85"}, "cell_type": "code", "execution_count": null, "source": ["def DenseNet(X_train):\n", "    ip = Input(shape=(X_train.shape[1],))\n", "    x_list = [ip]\n", "    \n", "    x = Dense(128, use_bias=False)(ip)\n", "    x = BatchNormalization()(x)\n", "    x = Activation('relu')(x)\n", "    x = Dropout(0.5)(x)\n", "\n", "    x_list.append(x)\n", "    x = keras.layers.concatenate(x_list)    \n", "    x = Dense(128, use_bias=False)(x)    \n", "    x = BatchNormalization()(x)\n", "    x = Activation('relu')(x)\n", "    x = Dropout(0.5)(x)\n", "\n", "    x_list.append(x)\n", "    x = keras.layers.concatenate(x_list)    \n", "    x = Dense(64, use_bias=False)(x)    \n", "    x = BatchNormalization()(x)\n", "    x = Activation('relu')(x)\n", "    x = Dropout(0.5)(x)\n", "\n", "    x_list.append(x)\n", "    x = keras.layers.concatenate(x_list)    \n", "    x = Dense(64, use_bias=False)(x)    \n", "    x = BatchNormalization()(x)\n", "    x = Activation('relu')(x)\n", "    x = Dropout(0.5)(x)\n", "\n", "    x_list.append(x)\n", "    x = keras.layers.concatenate(x_list)    \n", "    x = Dense(32, use_bias=False)(x)    \n", "    x = BatchNormalization()(x)\n", "    x = Activation('relu')(x)\n", "    x = Dropout(0.5)(x)\n", "\n", "    x_list.append(x)\n", "    x = keras.layers.concatenate(x_list)    \n", "    x = Dense(32, use_bias=False)(x)    \n", "    x = BatchNormalization()(x)\n", "    x = Activation('relu')(x)\n", "    x = Dropout(0.5)(x)\n", "\n", "    x_list.append(x)\n", "    x = keras.layers.concatenate(x_list)    \n", "    x = Dense(16, use_bias=False)(x)    \n", "    x = BatchNormalization()(x)\n", "    x = Activation('relu')(x)\n", "    x = Dropout(0.5)(x)\n", "    \n", "    x_list.append(x)\n", "    x = keras.layers.concatenate(x_list)    \n", "    x = Dense(16, use_bias=False)(ip)\n", "    x = BatchNormalization()(x)\n", "    x = Activation('relu')(x)\n", "    x = Dropout(0.5)(x)    \n", "    \n", "    op = Dense(1, activation='sigmoid')(x)\n", "\n", "    model = Model(inputs=ip, outputs=op)\n", "    adam = Adam(lr=0.05,)\n", "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n", "    return model\n", "\n", "model = DenseNet(X)"], "outputs": []}, {"metadata": {"collapsed": true, "_cell_guid": "f51c5216-bda8-4ee6-b4c2-d0f3227fdebb", "_uuid": "eedf0168f0b4024f24719ca2967be543fdf59c54"}, "cell_type": "code", "execution_count": null, "source": ["# Training plots\n", "from IPython import display\n", "plt.rcParams['figure.figsize'] = (10, 10)\n", "class PlotTraining(keras.callbacks.Callback):\n", "    def on_train_begin(self, logs={}):\n", "        self.i = 0\n", "        self.x = []\n", "        self.losses = []\n", "        self.val_losses = []\n", "        self.accs = []\n", "        self.val_accs = []\n", "\n", "        f, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True)\n", "        self.fig = f\n", "        self.ax1 = ax1\n", "        self.ax2 = ax2\n", "\n", "    def on_epoch_end(self, epoch, logs={}):        \n", "        if (self.i%100==0):\n", "            self.x.append(self.i)\n", "            self.losses.append(logs.get('loss'))\n", "            self.val_losses.append(logs.get('val_loss'))\n", "            self.accs.append(logs.get('acc'))\n", "            self.val_accs.append(logs.get('val_acc'))\n", "\n", "            display.clear_output(wait=True)\n", "            self.ax1.clear()\n", "            self.ax1.plot(self.x, self.losses, label=\"Train\")\n", "            self.ax1.plot(self.x, self.val_losses, label=\"Validation\")\n", "            self.ax1.set_ylabel('Loss')\n", "            self.ax1.legend()\n", "\n", "            self.ax2.clear()\n", "            self.ax2.plot(self.x, self.accs, label=\"Train\")\n", "            self.ax2.plot(self.x, self.val_accs, label=\"Validation\")\n", "            self.ax2.set_ylabel('Accuracy')\n", "            self.ax2.set_xlabel('Epoch')\n", "            self.ax2.legend()\n", "            display.display(plt.gcf())\n", "        self.i += 1\n", "\n", "trainCallback = PlotTraining()"], "outputs": []}, {"metadata": {"scrolled": false, "_cell_guid": "02d2e7d8-8885-4d12-8d9d-7b60a257d0fa", "_uuid": "c88baaa1a12f7310036d6404fec7f3886da80ce3"}, "cell_type": "code", "execution_count": null, "source": ["# Train the model with 40000 epochs\n", "EPOCHS = 40000\n", "BATCH_SIZE = 64\n", "print(\"Training..., it may take 1 hour or 2.\")\n", "model.fit(X.as_matrix(), y.values, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0,\n", "          validation_split=0.1,\n", "          callbacks=[trainCallback])\n", "# evaluate the model\n", "scores = model.evaluate(X.as_matrix(), y.values, verbose=0)\n", "print(\"%s: %.3f%%\" % (model.metrics_names[1], scores[1]*100))"], "outputs": []}, {"metadata": {"scrolled": false, "_cell_guid": "addf88a8-52ee-4bd2-aa63-00ad96a6d83b", "_uuid": "2e34c631ed45d2499c902d034fbf80d71389f47d"}, "cell_type": "code", "execution_count": null, "source": ["# Predicting with test data\n", "test = pd.read_csv('../input/test.csv',dtype={'Age': np.float32,'Fare': np.float32})\n", "passengerId = test['PassengerId']\n", "\n", "#add title\n", "add_titles(test)\n", "#test.drop(['Name'], axis=1, inplace=True)\n", "test.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n", "\n", "#dealing missing fare\n", "test['Fare'].fillna(test['Fare'].median(), inplace=True)\n", "\n", "#create Family feature\n", "test['Family'] = test['SibSp'] + test['Parch']\n", "test.drop(['SibSp','Parch'],axis=1,inplace=True)\n", "test.drop('Cabin',axis=1,inplace=True)\n", "\n", "#dealing missing Embarked\n", "test['Embarked'].fillna('S',inplace=True)\n", "\n", "# encoding test features\n", "test = encode_one_hot(test, 'Pclass')\n", "test = encode_one_hot(test, 'Sex')\n", "test = encode_one_hot(test, 'Embarked')\n", "test = encode_one_hot(test, 'Title')\n", "transform(test, \"Fare\", fareScaler)\n", "transform(test, \"Family\", familyScaler)\n", "\n", "# dealing the missing age\n", "agePredictionModel = getAgePredictionModel(test)\n", "fillMissingAges(test, agePredictionModel)\n", "test['Age'].isnull().sum()\n", "transform(test, \"Age\", ageScaler)\n", "\n", "X_test = test\n", "# Make sure X_test and X have the same dimentions in same sequence so that X_test fits the input of model\n", "X.columns == X_test.columns\n", "\n", "y_pred = model.predict(X_test.as_matrix())\n", "y_pred = (y_pred > 0.5).astype('int32')"], "outputs": []}, {"metadata": {"scrolled": true, "_cell_guid": "467520f9-1723-414d-a422-3dd275d3bfd9", "_uuid": "6eeab1f0d3be5faf9c8ab915c30d1d7e1c7b6eac"}, "cell_type": "code", "execution_count": null, "source": ["#submit\n", "submission = pd.DataFrame({\n", "        \"PassengerId\": passengerId,\n", "        \"Survived\": y_pred.reshape(-1)\n", "    })\n", "print(submission['Survived'].value_counts(dropna=False))\n", "submission.to_csv(\"prediction.csv\", index=False)\n", "print(\"Submitted.\")"], "outputs": []}], "nbformat_minor": 1}