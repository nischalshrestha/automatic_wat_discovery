{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "abe02687-c33c-45a2-dddc-9820667c273a"
      },
      "source": [
        "# Table of Contents\n",
        "* [Background](#Background)\n",
        "* [Key Questions](#Key-Questions)\n",
        "* [Findings and Conclusions](#Find\u200bings-and-Conclusions)\n",
        "* [Load and Preview Data](#Load-and-Preview-Data)\n",
        "\t* [Variable Descriptions](#Variable-Descriptions)\n",
        "* [Data Wrangling and Exploration](#Data-Wrangling-and-Exploration)\n",
        "\t* [Get a High-level View](#High-level-View)\n",
        "\t* [High-level Summary](#High-level-Summary)\n",
        "\t* [Remove Redundant Columns and Replace Missing Values](#Remove-Redundant-Columns-and-Replace-Missing-Values)\n",
        "\t* [Explore Correlations](#Explore-Correlations)\n",
        "* [Prediction](#Prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e720accd-b83f-9516-5e0b-480d3206def9"
      },
      "source": [
        "# Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e43e1663-c8bf-f9b2-287c-f91cc7e61eca"
      },
      "source": [
        "This is the final project of [Udacity Intro to Data Analysis][1] course. In the following analysis, I will predict which passenger will survive in the [Titanic tragedy][2]. \u200bBased on the given data of survivors, I explore similar characteristics of survivors to find out what types of passengers \u200bare more likely to survive. The final step is to make a prediction on the unknown passenger data to see if they can survive.\n",
        "\n",
        "[1]:https://www.udacity.com/course/intro-to-data-analysis--ud170\n",
        "[2]:https://en.wikipedia.org/wiki/Sinking_of_the_RMS_Titanic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6c4ce7d2-277f-c994-ef44-c2c8e4429768"
      },
      "source": [
        "# Key Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "88a2b242-6d05-be4f-6baf-81831dc2cf83"
      },
      "source": [
        " 1. How do I choose what kind of data to include in the model? \n",
        " 2. How do I choose which model to use? \n",
        " 3. How do I optimize this model for better prediction?\u200b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8e708acd-dd8f-8e9b-4c54-3024a298fd5d"
      },
      "source": [
        "# Findings and Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5fe1af2c-6699-db4a-fbbc-41c622a60827"
      },
      "source": [
        "After exploring the dataset a bit, I discovered potential correlations between variables such as gender and survival. For the sake of simplicity, I chose a simple Logistic Regression for modeling. It yields ~75% accuracy in the unknown test data. I.e. given any unknown passenger, the model is able to successfully predict it's survival 3 out of 4 passengers.\n",
        "\n",
        "Here are a few things to note in the model:\n",
        "\n",
        "- As I've discovered some \"correlations\",  no solid statistics analysis was performed to imply any causality between variables.\n",
        "- I found a specific age interval in the training dataset that showed significantly different survival rate. Survival rate drops significantly if someone is older than 10. \n",
        "- Having some (1~3) family members on the ship are likely to increase the survival rate. However having too many or traveling alone is likely to decrease someone's chance of survival.\u200b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e06af556-93f2-0a7e-8cd7-a02e63325dd5"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "\n",
        "# pandas\n",
        "import pandas as pd\n",
        "from pandas import Series,DataFrame\n",
        "\n",
        "# numpy, matplotlib, seaborn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid',{'axes.grid' : False})\n",
        "sns.set_context(rc = {'patch.linewidth': 0.0})\n",
        "bar_settings = {'color': sns.xkcd_rgb['grey'], 'ci': None}\n",
        "color_settings = {'color': sns.xkcd_rgb['grey']}\n",
        "%matplotlib inline\n",
        "\n",
        "# machine learning\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bf5b8b9c-d011-ec24-9291-1a36e77d8e1c"
      },
      "source": [
        "# Load and Preview Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bcbee8fc-7d27-325f-b855-07225a27e820"
      },
      "outputs": [],
      "source": [
        "# get titanic training dataset & test csv files as a DataFrame\n",
        "train_df = pd.read_csv('../input/train.csv')\n",
        "test_df  = pd.read_csv('../input/test.csv')\n",
        "\n",
        "# preview the data\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "dc3db646-f1a8-3fa7-d949-c50082dbae8c"
      },
      "source": [
        "## Variable Description\u200b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f1e6acf7-0d5d-5063-6a0b-4e27994fb0af"
      },
      "source": [
        "|Header Name|Descriptions|\n",
        "|-----------|------------|\n",
        "|Survived   | Survival (0 = No; 1 = Yes)\n",
        "|Pclass     |Passenger Class  (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
        "|Name       |Name\n",
        "|Sex        |Sex\n",
        "|Age        |Age\n",
        "|SibSp      |Number of Siblings/Spouses Aboard\n",
        "|Parch      |Number of Parents/Children\u200b Aboard\n",
        "|Ticket     |Ticket Number\n",
        "|Fare       |Passenger Fare\n",
        "|Cabin      |Cabin\n",
        "|Embarked   |Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7b318a1d-f606-8559-761a-66a82120ee7c"
      },
      "outputs": [],
      "source": [
        "train_df.info()\n",
        "print(\"----------------------------\")\n",
        "test_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a29fda1a-9163-3a14-68ee-6fb5643c7f76"
      },
      "source": [
        "# Data Wrangling and Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "363f0341-b8e9-0253-9344-62813b9a44c0"
      },
      "source": [
        "## High-level View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4edf89d1-b195-00ac-92bb-ad9ac97ddedd"
      },
      "outputs": [],
      "source": [
        "## Survived - Survival (0 = No; 1 = Yes)\n",
        "\n",
        "total_passengers = train_df['Survived'].count()\n",
        "survived_passengers = train_df['Survived'].sum()\n",
        "survived_ratio = survived_passengers/total_passengers\n",
        "\n",
        "print('Passengers in training data:',total_passengers)\n",
        "print('% of survivors:',(survived_ratio*100).round(1),'%')\n",
        "\n",
        "# A horizontal line of average survival rate\n",
        "\n",
        "def avg_survived(survived_ratio):\n",
        "    print(plt.axhline(y=survived_ratio,ls=\":\", c='.5'))\n",
        "    print(plt.legend(['Avg. survival rate'],loc='center right'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "83c2466c-44f5-a8ea-a7c4-f38914397da6"
      },
      "outputs": [],
      "source": [
        "# Pclass - Survival (0 = No; 1 = Yes)\n",
        "\n",
        "print('Number of passengers in each class: ',train_df.groupby('Pclass').count()['PassengerId'])\n",
        "sns.barplot('Pclass','Survived', data=train_df, **bar_settings)\n",
        "avg_survived(survived_ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "59e3fe49-1919-3359-ed8b-6cdcaeb17605"
      },
      "outputs": [],
      "source": [
        "#Sex\n",
        "\n",
        "sns.barplot('Sex','Survived', data=train_df,**bar_settings)\n",
        "avg_survived(survived_ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8206146c-2cf7-1c72-6b3c-ee8e019d8dff"
      },
      "outputs": [],
      "source": [
        "#Age\n",
        "initial_age_values = train_df['Age'].copy().dropna().astype(int)\n",
        "plt.hist(initial_age_values,**color_settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8317d391-411e-6fe0-8f3a-80668dfac107"
      },
      "outputs": [],
      "source": [
        "# Family - SibSp & Parch\n",
        "fig_family, (axis1,axis2) = plt.subplots(1,2)\n",
        "\n",
        "# f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
        "# ax1.plot(x, y)\n",
        "# ax1.set_title('Sharing Y axis')\n",
        "# ax2.scatter(x, y\n",
        "avg_sibsp_survived = train_df.groupby('SibSp',as_index=False)['SibSp','Survived'].mean()\n",
        "avg_parch_survived = train_df.groupby('Parch',as_index=False)['Parch','Survived'].mean()\n",
        "\n",
        "sns.barplot(x='SibSp',y='Survived', data=avg_sibsp_survived, ax=axis1, **bar_settings)\n",
        "sns.barplot(x='Parch',y='Survived', data=avg_parch_survived, ax=axis2, **bar_settings)\n",
        "avg_survived(survived_ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3a94efce-d018-0d6e-8553-0d0b32c333ea"
      },
      "outputs": [],
      "source": [
        "# Ticket\n",
        "# It seems like there are a lot of different tickets and they don't follow clear patterns\n",
        "\n",
        "# unique_tickets = train_df.groupby(['Ticket'], as_index=False)['PassengerId'].count()\n",
        "# unique_tickets.rename(columns={'PassengerId':'Counts'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d845eb82-11c8-93bc-b1ff-cbb87733cc66"
      },
      "outputs": [],
      "source": [
        "# Fare\n",
        "\n",
        "fare_boxplt = sns.boxplot(x=train_df['Fare'],fliersize=3,**color_settings)\n",
        "fare_boxplt.set(xlim=(0, 250))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "875ee67f-dfa2-7a62-a38b-b5079a8b8d3d"
      },
      "outputs": [],
      "source": [
        "# Cabin\n",
        "\n",
        "print('# of non-NAN or non-null values: ', train_df['Cabin'].count())\n",
        "print('Total number of rows: ', len(train_df['Cabin']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2eec4dbd-fbd9-b82d-ef84-403d0302340c"
      },
      "outputs": [],
      "source": [
        "# Embarked\n",
        "\n",
        "train_df.groupby(['Embarked'])['PassengerId'].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4255f29e-0ee8-f03a-7937-87feabf9a6b6"
      },
      "source": [
        "## High-level Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "85b0f33b-b0c6-9ebd-bc5e-b22708920e08"
      },
      "source": [
        "Before diving deeper, here are a few things to note:\n",
        "- Some columns are probably redundant for analysis, I can drop them:\n",
        "\n",
        "|Column Name|Reason|\n",
        "|-----------|------|\n",
        "|PassengerId| No practical meaning \n",
        "|Ticket     | No information is provided to explain different ticket numbers\n",
        "|Cabin      | Too many NaN values\n",
        " \n",
        "- For the sake of simplicity, I also want to drop the following columns because *intuitively* I don't think these variables are useful in prediction. I could be wrong, though.\n",
        "\n",
        "|Column Name|Reason|\n",
        "|-----------|------|\n",
        "|Name       |SibSp and Parch data should be enough in this simple prediction|\n",
        "|Embarked   | Logically speaking, the port chosen shouldn't affect chances of survival\n",
        "\n",
        "- Missing values in *Age* and *Fare* column in train_df/test_df\n",
        "\n",
        "- Without knowing the exact causal relations  between variables, I noticed some potential correlations to explore further:\n",
        "\n",
        "Survived v.s. Pclass/Fare\n",
        "\n",
        "Survived v.s. Sex\n",
        "\n",
        "Survived v.s. SibSp/Parch\n",
        "\n",
        "Survived v.s  Age\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "96a82eb0-6688-698e-8ae8-7f93e1e96a0d"
      },
      "source": [
        "## Remove Redundant Columns and Replace Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f79bc847-7280-78d8-2454-48c0305ef281"
      },
      "outputs": [],
      "source": [
        "# Remove redundant columns\n",
        "\n",
        "train_df.drop(['PassengerId','Ticket','Cabin','Name','Embarked'],axis=1,inplace=True)\n",
        "test_df.drop(['Ticket','Cabin','Name','Embarked'],axis=1,inplace=True)\n",
        "\n",
        "train_df.info()\n",
        "print(\"----------------------------\")\n",
        "test_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c75dd771-6178-cbfd-27b2-dbd57a85f2c2"
      },
      "outputs": [],
      "source": [
        "# Replace missing values in Age column\n",
        "\n",
        "# Generate random age numbers between (mean - std) & (mean + std) for missing age values\n",
        "train_age_mean = train_df['Age'].mean()\n",
        "test_age_mean = test_df['Age'].mean()\n",
        "\n",
        "train_age_std = train_df['Age'].std()\n",
        "test_age_std = test_df['Age'].std()\n",
        "\n",
        "# count # of NaN values\n",
        "train_count_nan_age = train_df['Age'].isnull().sum()\n",
        "test_count_nan_age = test_df['Age'].isnull().sum()\n",
        "\n",
        "rand_train = np.random.randint(train_age_mean - train_age_std, train_age_mean + train_age_std, size=train_count_nan_age) \n",
        "rand_test = np.random.randint(test_age_mean - test_age_std, test_age_mean + test_age_std, size=test_count_nan_age) \n",
        "\n",
        "# Replace initial NaN values with new set of random numbers\n",
        "train_df['Age'].loc[train_df['Age'].isnull()] = rand_train\n",
        "test_df['Age'].loc[test_df['Age'].isnull()] = rand_test\n",
        "\n",
        "# Convert from float to int\n",
        "train_df['Age'] = train_df['Age'].astype(int)\n",
        "test_df['Age'] = test_df['Age'].astype(int)\n",
        "\n",
        "# Plot original age values and new age values\n",
        "\n",
        "fig, (axes1, axes2) = plt.subplots(nrows=1,ncols=2, figsize=(15,5))\n",
        "\n",
        "axes1.set_title('Initial Age Values')\n",
        "axes2.set_title('New Age Values - NaN Replaced')\n",
        "axes1.set_ylim(0,250)\n",
        "\n",
        "axes1.hist(initial_age_values, **color_settings)\n",
        "axes2.hist(train_df['Age'], color=sns.xkcd_rgb['light grey'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3ebcb06c-614a-520c-e0e5-0f31cc2c6490"
      },
      "outputs": [],
      "source": [
        "# Replace missing values in Fare column\n",
        "\n",
        "# Only need to replace one missing value in Fare column at test_df\n",
        "test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)\n",
        "\n",
        "# Convert from float to int\n",
        "train_df['Fare'] = train_df['Fare'].astype(int)\n",
        "test_df['Fare'] = train_df['Fare'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a05ed405-ce72-45d6-8991-5709b0817937"
      },
      "outputs": [],
      "source": [
        "# Take a quick look at current dataset\n",
        "\n",
        "# train_df.info()\n",
        "# print(\"----------------------------\")\n",
        "# test_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1171ca2f-f1d0-81d1-6f01-e47d385c7e0d"
      },
      "source": [
        "## Explore Correlations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9a232726-fde1-8366-4c39-e51d29e6f49c"
      },
      "outputs": [],
      "source": [
        "# Survived v.s. Pclass/Fare\n",
        "# Create dummy variables for Pclass column, & drop 3rd class as the base column\n",
        "\n",
        "train_pclass_dummies = pd.get_dummies(train_df['Pclass'])\n",
        "test_pclass_dummies = pd.get_dummies(test_df['Pclass'])\n",
        "\n",
        "train_pclass_dummies.columns = ['Class1','Class2','Class3']\n",
        "test_pclass_dummies.columns = ['Class1','Class2','Class3']\n",
        "\n",
        "train_pclass_dummies.drop('Class3',axis=1,inplace=True)\n",
        "test_pclass_dummies.drop('Class3',axis=1,inplace=True)\n",
        "\n",
        "# Merge new dummy variables into origional dataset\n",
        "train_df = train_df.join(train_pclass_dummies)\n",
        "test_df = test_df.join(test_pclass_dummies)\n",
        "\n",
        "# We don't need Pclass column now\n",
        "train_df.drop('Pclass', axis=1, inplace=True)\n",
        "test_df.drop('Pclass', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2da2a61e-d97b-42d3-89c5-0d5d0ee520f7"
      },
      "outputs": [],
      "source": [
        "# Correlation between fare and survival\n",
        "# Bubble size = # of people in that group\n",
        "\n",
        "fare_range = np.arange(0,300,20)\n",
        "fare_groups = pd.cut(train_df['Fare'], fare_range)\n",
        "grouped_fare = train_df.groupby(fare_groups)['Survived'].mean()\n",
        "\n",
        "# count()*3 -> just to make the bubble size bigger\n",
        "num_people_fare_groups = train_df.groupby(fare_groups)['Survived'].count()*3\n",
        "plt.scatter(fare_range[:len(fare_range)-1], grouped_fare, s=num_people_fare_groups.tolist(), **color_settings)\n",
        "plt.xlim(-20,300)\n",
        "avg_survived(survived_ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ded95407-6018-0085-6a0f-e894785f70a3"
      },
      "outputs": [],
      "source": [
        "# Survived v.s. Sex\n",
        "# Survived v.s. Age\n",
        "\n",
        "# Chance of survival is higher for female\n",
        "# Now we want to explore the chance of  survival across different age groups\n",
        "# Bubble size = # of people in that group\n",
        "\n",
        "age_range = np.arange(0,100,10)\n",
        "\n",
        "train_df_male_sex = train_df[train_df.Sex == 'male']\n",
        "train_df_female_sex = train_df[train_df.Sex == 'female']\n",
        "\n",
        "age_groups_male = pd.cut(train_df_male_sex['Age'], age_range, include_lowest=True)\n",
        "age_groups_female = pd.cut(train_df_female_sex['Age'], age_range, include_lowest=True)\n",
        "\n",
        "grouped_age_male = train_df_male_sex.groupby(age_groups_male)['Survived'].mean()\n",
        "grouped_age_female = train_df_female_sex.groupby(age_groups_female)['Survived'].mean()\n",
        "\n",
        "# *3 to make the bubble larger\n",
        "num_people_age_groups_male = train_df_male_sex.groupby(age_groups_male)['Survived'].count()*3\n",
        "num_people_age_groups_female = train_df_female_sex.groupby(age_groups_female)['Survived'].count()*3\n",
        "\n",
        "plt.scatter(age_range[:len(age_range)-1], grouped_age_male, s=num_people_age_groups_male.tolist(), color=sns.xkcd_rgb['light grey'])\n",
        "plt.scatter(age_range[:len(age_range)-1], grouped_age_female, s=num_people_age_groups_female.tolist(), **color_settings)\n",
        "\n",
        "avg_survived(survived_ratio)\n",
        "plt.xlim(-2,80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "45c313a4-b6ed-8eed-3b4d-6ee213680492"
      },
      "source": [
        "As we can see from the scatter chart above, passengers below 10 can be classified as the same group. Passengers above 10 can be classified as another two gro\u200bups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2f5de163-10bf-e97d-4d10-6c775861007f"
      },
      "outputs": [],
      "source": [
        "def passengers(passenger):\n",
        "    age, sex = passenger\n",
        "    if age <= 10:\n",
        "        return 'child'\n",
        "    else:\n",
        "        return sex\n",
        "\n",
        "train_df['Person'] = train_df[['Age','Sex']].apply(passengers, axis=1)\n",
        "test_df['Person'] = test_df[['Age','Sex']].apply(passengers, axis=1)\n",
        "\n",
        "# Create dummy variables for Person column\n",
        "\n",
        "person_dummies_train = pd.get_dummies(train_df['Person'])\n",
        "person_dummies_test = pd.get_dummies(test_df['Person'])\n",
        "\n",
        "person_dummies_train.columns = ['Child','Female','Male']\n",
        "person_dummies_test.columns = ['Child','Female','Male']\n",
        "\n",
        "# Merge dummy variables into initial dataset\n",
        "\n",
        "train_df = train_df.join(person_dummies_train)\n",
        "test_df = test_df.join(person_dummies_test)\n",
        "\n",
        "# Plot survival rate of Child, Female and Male\n",
        "train_mean_person_survived = train_df.groupby('Person', as_index=False)['Person','Survived'].mean()\n",
        "sns.barplot(x=['Child','Female','Male'],y=train_mean_person_survived['Survived'], **bar_settings)\n",
        "avg_survived(survived_ratio)\n",
        "\n",
        "# drop Person and Sex column as we don't need it anymore\n",
        "\n",
        "train_df.drop('Person', axis=1, inplace=True)\n",
        "test_df.drop('Person', axis=1, inplace=True)\n",
        "\n",
        "train_df.drop('Sex', axis=1, inplace=True)\n",
        "test_df.drop('Sex', axis=1, inplace=True)\n",
        "\n",
        "# Drop Male as the base column\n",
        "\n",
        "train_df.drop('Male', axis=1, inplace=True)\n",
        "test_df.drop('Male', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fcd1be34-4774-5a63-2b30-7aebe511175f"
      },
      "outputs": [],
      "source": [
        "# Survived v.s. SibSp/Parch\n",
        "\n",
        "train_df['Family'] = train_df['SibSp'] + train_df['Parch']\n",
        "test_df['Family'] = test_df['SibSp'] + test_df['Parch']\n",
        "\n",
        "train_mean_survived_with_family = train_df.groupby('Family', as_index=False)['Family','Survived'].mean()\n",
        "\n",
        "plt.scatter(x='Family', y='Survived', data=train_mean_survived_with_family, **color_settings)\n",
        "plt.xticks(np.arange(0,11,1))\n",
        "avg_survived(survived_ratio)\n",
        "\n",
        "# Drop SibSp and Parch column as we don't need them\n",
        "\n",
        "train_df.drop(['SibSp','Parch'], axis=1, inplace=True)\n",
        "test_df.drop(['SibSp','Parch'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ae0c7ffd-4c1a-3248-5c12-3c48e3661905"
      },
      "source": [
        "From the chart above we can somehow identify three groups: \n",
        "- Alone (single passenger)\n",
        "- With_family (family members < 4)\n",
        "- With_big_family (family members >=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1e2cb58-24ae-2dbc-9a63-924b5661ec7e"
      },
      "outputs": [],
      "source": [
        "# Transform family member counts into categorical data\n",
        "\n",
        "train_df['Family'].loc[train_df['Family'] == 0] = 'Alone'\n",
        "train_df['Family'].loc[train_df['Family'].isin([1,2,3])] = 'With_family'\n",
        "train_df['Family'].loc[train_df['Family'].isin(np.arange(4,11,1))] = 'With_big_family'\n",
        "\n",
        "test_df['Family'].loc[test_df['Family'] == 0] = 'Alone'\n",
        "test_df['Family'].loc[test_df['Family'].isin([1,2,3])] = 'With_family'\n",
        "test_df['Family'].loc[test_df['Family'].isin(np.arange(4,11,1))] = 'With_big_family'\n",
        "\n",
        "# Get dummy variables and merge with initial dataset\n",
        "family_dummies_train = pd.get_dummies(train_df['Family'])\n",
        "train_df = train_df.join(family_dummies_train)\n",
        "\n",
        "family_dummies_test = pd.get_dummies(test_df['Family'])\n",
        "test_df = test_df.join(family_dummies_train)\n",
        "\n",
        "# Drop Family column as we already have dummy variables\n",
        "# Drop Alone as the base column\n",
        "\n",
        "train_df.drop('Family', axis=1, inplace=True)\n",
        "test_df.drop('Family', axis=1, inplace=True)\n",
        "\n",
        "train_df.drop('Alone', axis=1, inplace=True)\n",
        "test_df.drop('Alone', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9a2c2085-7f6a-78a1-a9dd-a4c28471d8aa"
      },
      "outputs": [],
      "source": [
        "# train_df.info()\n",
        "# train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c5959a41-a221-5239-d685-85004e2b8ef5"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4aa28a00-3a50-ad7c-61cb-d825be443634"
      },
      "outputs": [],
      "source": [
        "# Define training and testing sets\n",
        "\n",
        "X_train = train_df.drop(\"Survived\",axis=1)\n",
        "Y_train = train_df[\"Survived\"]\n",
        "X_test  = test_df.drop(\"PassengerId\",axis=1).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8d20b978-920e-f761-30aa-c42246db6668"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "logreg.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = logreg.predict(X_test)\n",
        "\n",
        "logreg.score(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "22b58fbb-986e-758b-b068-9696f65c56b0"
      },
      "outputs": [],
      "source": [
        "# Get Correlation Coefficient for each feature using Logistic Regression\n",
        "coeff_df = DataFrame(train_df.columns.delete(0))\n",
        "coeff_df.columns = ['Features']\n",
        "coeff_df['Coefficient Estimate'] = pd.Series(logreg.coef_[0])\n",
        "\n",
        "# preview\n",
        "coeff_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6f7eb39d-310e-33dd-35f7-7937d2ac4e9f"
      },
      "outputs": [],
      "source": [
        "\n",
        "submission = pd.DataFrame({\n",
        "        \"PassengerId\": test_df[\"PassengerId\"],\n",
        "        \"Survived\": Y_pred\n",
        "    })\n",
        "submission.to_csv('titanic_Luke.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}