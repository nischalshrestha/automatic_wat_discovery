{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7caa2c1b-5066-4944-1b5b-f8a593e01fad"
      },
      "source": [
        "#0. INTRODUCTION\n",
        "\n",
        "First project in Kaggle.\n",
        "\n",
        " - Framework and most code taken from https://www.kaggle.com/omarelgabry/titanic/a-journey-through-titanic by Omar El Gabry\n",
        " - Some ideas and code taken from https://www.kaggle.com/arthurtok/titanic/introduction-to-ensembling-stacking-in-python by Anisotropic\n",
        " - Plan is: clean up, add visuals and comments, document the code in more detail.\n",
        "\n",
        "Personal note: I've worked in Epidemiology (Public Health) for many years. Now getting into Data Science. I can use help!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "09af92d4-1f21-6ea7-5a40-31d213d19c3e"
      },
      "source": [
        "#1. LIBRARIES AND DATA FILES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cfdaacbc-23a3-423d-8d4d-120939ac7383"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "# pandas\n",
        "import pandas as pd\n",
        "from pandas import Series,DataFrame\n",
        "\n",
        "# numpy, matplotlib, seaborn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "%matplotlib inline\n",
        "\n",
        "# machine learning\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# some other libraries loaded by Anisotropic\n",
        "import re\n",
        "import sklearn\n",
        "import xgboost as xgb\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "import plotly.tools as tls\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from sklearn.cross_validation import KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3ab4c525-a5cb-4183-9468-c1dd005c4c78"
      },
      "outputs": [],
      "source": [
        "# get titanic & test csv files as a DataFrame\n",
        "titanic_df = pd.read_csv(\"../input/train.csv\")\n",
        "test_df    = pd.read_csv(\"../input/test.csv\")\n",
        "\n",
        "# preview the data\n",
        "titanic_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "86179af8-3cb4-4661-84ea-addd2c7679d4"
      },
      "outputs": [],
      "source": [
        "full_data = [titanic_df, test_df]\n",
        "\n",
        "for dataset in full_data:\n",
        "    titanic_df.info()\n",
        "    print(\"----------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7faffa7c-9776-43fb-9c01-786630f237ab"
      },
      "outputs": [],
      "source": [
        "# Store our passenger ID for easy access, in order to then create the submission file (see Anisotropic)\n",
        "PassengerId = test_df['PassengerId']\n",
        "\n",
        "# drop unnecessary columns, these columns won't be useful in analysis and prediction\n",
        "# Will keep Name as Title can be used to define a new feature, as per Anisotropic's\n",
        "# https://www.kaggle.com/arthurtok/titanic/introduction-to-ensembling-stacking-in-python\n",
        "\n",
        "titanic_df = titanic_df.drop(['PassengerId','Ticket'], axis=1)\n",
        "test_df    = test_df.drop(['Ticket'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1441ec8-7d77-4a69-990b-26e0b1e89b68"
      },
      "outputs": [],
      "source": [
        "# Embarked\n",
        "\n",
        "# only in titanic_df, fill the two missing values with the most occurred value, which is \"S\".\n",
        "titanic_df[\"Embarked\"] = titanic_df[\"Embarked\"].fillna(\"S\")\n",
        "\n",
        "# plot\n",
        "sns.factorplot('Embarked','Survived', data=titanic_df,size=4,aspect=3)\n",
        "\n",
        "fig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(15,5))\n",
        "\n",
        "# sns.factorplot('Embarked',data=titanic_df,kind='count',order=['S','C','Q'],ax=axis1)\n",
        "# sns.factorplot('Survived',hue=\"Embarked\",data=titanic_df,kind='count',order=[1,0],ax=axis2)\n",
        "sns.countplot(x='Embarked', data=titanic_df, ax=axis1)\n",
        "sns.countplot(x='Survived', hue=\"Embarked\", data=titanic_df, order=[1,0], ax=axis2)\n",
        "\n",
        "# group by embarked, and get the mean for survived passengers for each value in Embarked\n",
        "embark_perc = titanic_df[[\"Embarked\", \"Survived\"]].groupby(['Embarked'],as_index=False).mean()\n",
        "sns.barplot(x='Embarked', y='Survived', data=embark_perc,order=['S','C','Q'],ax=axis3)\n",
        "\n",
        "# Either to consider Embarked column in predictions,\n",
        "# and remove \"S\" dummy variable, \n",
        "# and leave \"C\" & \"Q\", since they seem to have a good rate for Survival.\n",
        "\n",
        "# OR, don't create dummy variables for Embarked column, just drop it, \n",
        "# because logically, Embarked doesn't seem to be useful in prediction.\n",
        "\n",
        "embark_dummies_titanic  = pd.get_dummies(titanic_df['Embarked'])\n",
        "embark_dummies_titanic.drop(['S'], axis=1, inplace=True)\n",
        "\n",
        "embark_dummies_test  = pd.get_dummies(test_df['Embarked'])\n",
        "embark_dummies_test.drop(['S'], axis=1, inplace=True)\n",
        "\n",
        "titanic_df = titanic_df.join(embark_dummies_titanic)\n",
        "test_df    = test_df.join(embark_dummies_test)\n",
        "\n",
        "# not dropped as Anisotropic uses them\n",
        "#titanic_df.drop(['Embarked'], axis=1,inplace=True)\n",
        "#test_df.drop(['Embarked'], axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1a9e2e1-1718-4e6a-b037-a2c1eca1c003"
      },
      "outputs": [],
      "source": [
        "# Fare\n",
        "\n",
        "# only for test_df, since there is a missing \"Fare\" values\n",
        "test_df[\"Fare\"].fillna(test_df[\"Fare\"].median(), inplace=True)\n",
        "\n",
        "# convert from float to int\n",
        "titanic_df['Fare'] = titanic_df['Fare'].astype(int)\n",
        "test_df['Fare']    = test_df['Fare'].astype(int)\n",
        "\n",
        "# get fare for survived & didn't survive passengers \n",
        "fare_not_survived = titanic_df[\"Fare\"][titanic_df[\"Survived\"] == 0]\n",
        "fare_survived     = titanic_df[\"Fare\"][titanic_df[\"Survived\"] == 1]\n",
        "\n",
        "# get average and std for fare of survived/not survived passengers\n",
        "average_fare = DataFrame([fare_not_survived.mean(), fare_survived.mean()])\n",
        "std_fare     = DataFrame([fare_not_survived.std(), fare_survived.std()])\n",
        "\n",
        "# plot\n",
        "titanic_df['Fare'].plot(kind='hist', figsize=(15,3),bins=100, xlim=(0,50))\n",
        "\n",
        "average_fare.index.names = std_fare.index.names = [\"Survived\"]\n",
        "average_fare.plot(yerr=std_fare,kind='bar',legend=False)\n",
        "\n",
        "# create new feature: CategoricalFare\n",
        "titanic_df['CategoricalFare'] = pd.qcut(titanic_df['Fare'], 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "22ab0b38-6285-4d65-bb3e-dc923caed94b"
      },
      "outputs": [],
      "source": [
        "# Age \n",
        "\n",
        "fig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,4))\n",
        "axis1.set_title('Original Age values - Titanic')\n",
        "axis2.set_title('New Age values - Titanic')\n",
        "\n",
        "# axis3.set_title('Original Age values - Test')\n",
        "# axis4.set_title('New Age values - Test')\n",
        "\n",
        "# get average, std, and number of NaN values in titanic_df\n",
        "average_age_titanic   = titanic_df[\"Age\"].mean()\n",
        "std_age_titanic       = titanic_df[\"Age\"].std()\n",
        "count_nan_age_titanic = titanic_df[\"Age\"].isnull().sum()\n",
        "\n",
        "# get average, std, and number of NaN values in test_df\n",
        "average_age_test   = test_df[\"Age\"].mean()\n",
        "std_age_test       = test_df[\"Age\"].std()\n",
        "count_nan_age_test = test_df[\"Age\"].isnull().sum()\n",
        "\n",
        "# generate random numbers between (mean - std) & (mean + std)\n",
        "rand_1 = np.random.randint(average_age_titanic - std_age_titanic, average_age_titanic + std_age_titanic, size = count_nan_age_titanic)\n",
        "rand_2 = np.random.randint(average_age_test - std_age_test, average_age_test + std_age_test, size = count_nan_age_test)\n",
        "\n",
        "# plot original Age values\n",
        "# NOTE: drop all null values, and convert to int\n",
        "titanic_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)\n",
        "# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)\n",
        "\n",
        "# fill NaN values in Age column with random values generated\n",
        "titanic_df[\"Age\"][np.isnan(titanic_df[\"Age\"])] = rand_1\n",
        "test_df[\"Age\"][np.isnan(test_df[\"Age\"])] = rand_2\n",
        "\n",
        "# convert from float to int\n",
        "titanic_df['Age'] = titanic_df['Age'].astype(int)\n",
        "test_df['Age']    = test_df['Age'].astype(int)\n",
        "        \n",
        "# plot new Age Values\n",
        "titanic_df['Age'].hist(bins=70, ax=axis2)\n",
        "# test_df['Age'].hist(bins=70, ax=axis4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "952009ab-555c-46f8-b419-182f2de39ca0"
      },
      "outputs": [],
      "source": [
        "# .... continue with plot Age column\n",
        "\n",
        "# peaks for survived/not survived passengers by their age\n",
        "facet = sns.FacetGrid(titanic_df, hue=\"Survived\",aspect=4)\n",
        "facet.map(sns.kdeplot,'Age',shade= True)\n",
        "facet.set(xlim=(0, titanic_df['Age'].max()))\n",
        "facet.add_legend()\n",
        "\n",
        "# average survived passengers by age\n",
        "fig, axis1 = plt.subplots(1,1,figsize=(18,4))\n",
        "average_age = titanic_df[[\"Age\", \"Survived\"]].groupby(['Age'],as_index=False).mean()\n",
        "sns.barplot(x='Age', y='Survived', data=average_age)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ef0f0c9d-6b45-4cb0-9026-86b764084398"
      },
      "outputs": [],
      "source": [
        "# Cabin\n",
        "# It has a lot of NaN values, so it won't cause a remarkable impact on prediction\n",
        "# but we keep it because Anisotropic does use it\n",
        "#titanic_df.drop(\"Cabin\",axis=1,inplace=True)\n",
        "#test_df.drop(\"Cabin\",axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a89c93bb-e45b-44ce-8dee-430f584f4ed4"
      },
      "outputs": [],
      "source": [
        "# Family\n",
        "\n",
        "# Instead of having two columns Parch & SibSp, \n",
        "# we can have only one column represent if the passenger had any family member aboard or not,\n",
        "# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.\n",
        "titanic_df['Family'] =  titanic_df[\"Parch\"] + titanic_df[\"SibSp\"]\n",
        "titanic_df['Family'].loc[titanic_df['Family'] > 0] = 1\n",
        "titanic_df['Family'].loc[titanic_df['Family'] == 0] = 0\n",
        "\n",
        "test_df['Family'] =  test_df[\"Parch\"] + test_df[\"SibSp\"]\n",
        "test_df['Family'].loc[test_df['Family'] > 0] = 1\n",
        "test_df['Family'].loc[test_df['Family'] == 0] = 0\n",
        "\n",
        "# drop Parch & SibSp\n",
        "# we keep them, as Anisotropic does use them\n",
        "#titanic_df = titanic_df.drop(['SibSp','Parch'], axis=1)\n",
        "#test_df    = test_df.drop(['SibSp','Parch'], axis=1)\n",
        "\n",
        "# plot\n",
        "fig, (axis1,axis2) = plt.subplots(1,2,sharex=True,figsize=(10,5))\n",
        "\n",
        "# sns.factorplot('Family',data=titanic_df,kind='count',ax=axis1)\n",
        "sns.countplot(x='Family', data=titanic_df, order=[1,0], ax=axis1)\n",
        "\n",
        "# average of survived for those who had/didn't have any family member\n",
        "family_perc = titanic_df[[\"Family\", \"Survived\"]].groupby(['Family'],as_index=False).mean()\n",
        "sns.barplot(x='Family', y='Survived', data=family_perc, order=[1,0], ax=axis2)\n",
        "\n",
        "axis1.set_xticklabels([\"With Family\",\"Alone\"], rotation=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "23c2f140-1dc0-48cd-a6e1-9786510b2606"
      },
      "outputs": [],
      "source": [
        "# Sex\n",
        "\n",
        "# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.\n",
        "# So, we can classify passengers as males, females, and child\n",
        "def get_person(passenger):\n",
        "    age,sex = passenger\n",
        "    return 'child' if age < 16 else sex\n",
        "    \n",
        "titanic_df['Person'] = titanic_df[['Age','Sex']].apply(get_person,axis=1)\n",
        "test_df['Person']    = test_df[['Age','Sex']].apply(get_person,axis=1)\n",
        "\n",
        "# No need to use Sex column since we created Person column\n",
        "# don't drop because Anisotropic uses it\n",
        "#titanic_df.drop(['Sex'],axis=1,inplace=True)\n",
        "#test_df.drop(['Sex'],axis=1,inplace=True)\n",
        "\n",
        "# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers\n",
        "person_dummies_titanic  = pd.get_dummies(titanic_df['Person'])\n",
        "person_dummies_titanic.columns = ['Child','Female','Male']\n",
        "person_dummies_titanic.drop(['Male'], axis=1, inplace=True)\n",
        "\n",
        "person_dummies_test  = pd.get_dummies(test_df['Person'])\n",
        "person_dummies_test.columns = ['Child','Female','Male']\n",
        "person_dummies_test.drop(['Male'], axis=1, inplace=True)\n",
        "\n",
        "titanic_df = titanic_df.join(person_dummies_titanic)\n",
        "test_df    = test_df.join(person_dummies_test)\n",
        "\n",
        "fig, (axis1,axis2) = plt.subplots(1,2,figsize=(10,5))\n",
        "\n",
        "# sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)\n",
        "sns.countplot(x='Person', data=titanic_df, ax=axis1)\n",
        "\n",
        "# average of survived for each Person(male, female, or child)\n",
        "person_perc = titanic_df[[\"Person\", \"Survived\"]].groupby(['Person'],as_index=False).mean()\n",
        "sns.barplot(x='Person', y='Survived', data=person_perc, ax=axis2, order=['male','female','child'])\n",
        "\n",
        "titanic_df.drop(['Person'],axis=1,inplace=True)\n",
        "test_df.drop(['Person'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0f126c1f-74b8-4063-8ac0-f44e6b8fc0bd"
      },
      "outputs": [],
      "source": [
        "# Pclass\n",
        "\n",
        "# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])\n",
        "sns.factorplot('Pclass','Survived',order=[1,2,3], data=titanic_df,size=5)\n",
        "\n",
        "# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers\n",
        "pclass_dummies_titanic  = pd.get_dummies(titanic_df['Pclass'])\n",
        "pclass_dummies_titanic.columns = ['Class_1','Class_2','Class_3']\n",
        "pclass_dummies_titanic.drop(['Class_3'], axis=1, inplace=True)\n",
        "\n",
        "pclass_dummies_test  = pd.get_dummies(test_df['Pclass'])\n",
        "pclass_dummies_test.columns = ['Class_1','Class_2','Class_3']\n",
        "pclass_dummies_test.drop(['Class_3'], axis=1, inplace=True)\n",
        "\n",
        "titanic_df.drop(['Pclass'],axis=1,inplace=True)\n",
        "test_df.drop(['Pclass'],axis=1,inplace=True)\n",
        "\n",
        "titanic_df = titanic_df.join(pclass_dummies_titanic)\n",
        "test_df    = test_df.join(pclass_dummies_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "79e601ef-6f7f-de0f-9656-4097bbce7e18"
      },
      "outputs": [],
      "source": [
        "# this cell taken from Anisotropic\n",
        "\n",
        "full_data = [titanic_df, test_df]\n",
        "\n",
        "# Some features of my own that I have added in\n",
        "# Gives the length of the name\n",
        "titanic_df['Name_length'] = titanic_df['Name'].apply(len)\n",
        "test_df['Name_length'] = test_df['Name'].apply(len)\n",
        "# Feature that tells whether a passenger had a cabin on the Titanic\n",
        "titanic_df['Has_Cabin'] = titanic_df[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
        "test_df['Has_Cabin'] = test_df[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
        "\n",
        "# Feature engineering steps taken from Sina\n",
        "# Create new feature FamilySize as a combination of SibSp and Parch\n",
        "for dataset in full_data:\n",
        "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
        "# Create new feature IsAlone from FamilySize\n",
        "for dataset in full_data:\n",
        "    dataset['IsAlone'] = 0\n",
        "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
        "# Remove all NULLS in the Embarked column\n",
        "for dataset in full_data:\n",
        "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
        "# Remove all NULLS in the Fare column and create a new feature CategoricalFare\n",
        "for dataset in full_data:\n",
        "    dataset['Fare'] = dataset['Fare'].fillna(titanic_df['Fare'].median())\n",
        "titanic_df['CategoricalFare'] = pd.qcut(titanic_df['Fare'], 4)\n",
        "# Create a New feature CategoricalAge\n",
        "for dataset in full_data:\n",
        "    age_avg = dataset['Age'].mean()\n",
        "    age_std = dataset['Age'].std()\n",
        "    age_null_count = dataset['Age'].isnull().sum()\n",
        "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
        "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
        "    dataset['Age'] = dataset['Age'].astype(int)\n",
        "titanic_df['CategoricalAge'] = pd.cut(titanic_df['Age'], 5)\n",
        "# Define function to extract titles from passenger names\n",
        "def get_title(name):\n",
        "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
        "    # If the title exists, extract and return it.\n",
        "    if title_search:\n",
        "        return title_search.group(1)\n",
        "    return \"\"\n",
        "# Create a new feature Title, containing the titles of passenger names\n",
        "for dataset in full_data:\n",
        "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
        "# Group all non-common titles into one single grouping \"Rare\"\n",
        "for dataset in full_data:\n",
        "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "\n",
        "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
        "\n",
        "for dataset in full_data:\n",
        "    # Mapping Sex\n",
        "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
        "    \n",
        "    # Mapping titles\n",
        "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
        "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
        "    dataset['Title'] = dataset['Title'].fillna(0)\n",
        "    \n",
        "    # Mapping Embarked\n",
        "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
        "    \n",
        "    # Mapping Fare\n",
        "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
        "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
        "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
        "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
        "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
        "    \n",
        "    # Mapping Age\n",
        "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
        "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
        "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
        "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
        "    dataset.loc[ dataset['Age'] > 64, 'Age'] ;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "133e6807-959d-21a2-8b56-961238140328"
      },
      "outputs": [],
      "source": [
        "#titanic_df.info()\n",
        "#print(\"---\")\n",
        "#test_df.info()\n",
        "\n",
        "# Feature selection, adapted from Anisotropic\n",
        "drop_elements = ['Name', 'Cabin', 'CategoricalFare', 'CategoricalAge']\n",
        "titanic_df = titanic_df.drop(drop_elements, axis = 1)\n",
        "drop_elements = ['Name', 'Cabin']\n",
        "test_df = test_df.drop(drop_elements, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cf214f45-190c-dbc2-c285-371806b6dfd7"
      },
      "outputs": [],
      "source": [
        "#visualization from Anisotropic\n",
        "#parson correlation heatmap, shows \"family size\" and \"parents and children\" are correlated, but not the others\n",
        "\n",
        "#doesn't work \"could not convert string to float: '[0, 7]'\",\n",
        "#which probably means I need to convert all strings to numbers of some kind\n",
        "#titanic_df.head(3)\n",
        "#drop_elements = ['Name', 'Cabin']\n",
        "#titanic_df = titanic_df.drop(drop_elements, axis = 1)\n",
        "#PClass is needed in next cell\n",
        "\n",
        "#titanic_df.head(3)\n",
        "\n",
        "colormap = plt.cm.viridis\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
        "sns.heatmap(titanic_df.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "350de64c-786f-a480-ab13-56199ccbf9fe"
      },
      "outputs": [],
      "source": [
        "#visualization from Anisotropic\n",
        "#pairplots\n",
        "\n",
        "g = sns.pairplot(titanic_df[[u'Survived', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n",
        "       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,\n",
        "       diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) ) #u'Pclass' was in long list\n",
        "g.set(xticklabels=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5214295a-19cf-44b5-abe2-8989a0ed9670"
      },
      "outputs": [],
      "source": [
        "# define training and testing sets\n",
        "\n",
        "X_train = titanic_df.drop(\"Survived\",axis=1)\n",
        "Y_train = titanic_df[\"Survived\"]\n",
        "X_test  = test_df.drop(\"PassengerId\",axis=1).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0d0e4bfa-1e65-990f-343c-c65110f96d54"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2b5424c0-196f-4d23-b1b8-1b10ac27be10"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "logreg.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = logreg.predict(X_test)\n",
        "\n",
        "logreg.score(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "74988880-7f9e-45f4-b6b7-f7fd43a63f95"
      },
      "outputs": [],
      "source": [
        "# Support Vector Machines\n",
        "\n",
        "svc = SVC()\n",
        "\n",
        "svc.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = svc.predict(X_test)\n",
        "\n",
        "svc.score(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0f8b05ff-c21e-4e0e-975d-21af19c6b6b3"
      },
      "outputs": [],
      "source": [
        "# Random Forests\n",
        "\n",
        "random_forest = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "random_forest.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = random_forest.predict(X_test)\n",
        "\n",
        "random_forest.score(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "499918bf-8ba4-4a79-b8d8-4c26ece9a3b8"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors = 3)\n",
        "\n",
        "knn.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = knn.predict(X_test)\n",
        "\n",
        "knn.score(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "15801b79-73c3-4fa4-b8be-21d32645a403"
      },
      "outputs": [],
      "source": [
        "# Gaussian Naive Bayes\n",
        "\n",
        "gaussian = GaussianNB()\n",
        "\n",
        "gaussian.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = gaussian.predict(X_test)\n",
        "\n",
        "gaussian.score(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "26dd2732-b34f-4177-8786-8794537494e1"
      },
      "outputs": [],
      "source": [
        "# get Correlation Coefficient for each feature using Logistic Regression\n",
        "coeff_df = DataFrame(titanic_df.columns.delete(0))\n",
        "coeff_df.columns = ['Features']\n",
        "coeff_df[\"Coefficient Estimate\"] = pd.Series(logreg.coef_[0])\n",
        "\n",
        "# preview\n",
        "coeff_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bf28672b-9264-4d5a-95f8-47effc0e2e4c"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({\n",
        "        \"PassengerId\": test_df[\"PassengerId\"],\n",
        "        \"Survived\": Y_pred\n",
        "    })\n",
        "submission.to_csv('titanic.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}