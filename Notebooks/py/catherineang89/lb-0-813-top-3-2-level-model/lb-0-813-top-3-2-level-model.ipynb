{"metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"version": "3.6.1", "nbconvert_exporter": "python", "name": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "pygments_lexer": "ipython3", "file_extension": ".py"}}, "cells": [{"metadata": {"trusted": true, "_uuid": "249c29102925c00a9a7739661ae96bc2b7c8b05a", "collapsed": true}, "outputs": [], "execution_count": null, "source": "import numpy as np #\nimport pandas as pd \nimport string\nimport json\nfrom patsy import dmatrices\nfrom operator import itemgetter\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier, ExtraTreesClassifier,AdaBoostClassifier\nfrom sklearn.model_selection import cross_val_score \nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import preprocessing\nfrom sklearn.metrics import classification_report\nfrom sklearn.externals import joblib\nimport xgboost as xgb\n", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "7b119b2bf6786c92d25086067966df3ab197663b", "collapsed": true}, "outputs": [], "execution_count": null, "source": "train_df=pd.read_csv(\"../input/train.csv\")\ntest_df=pd.read_csv(\"../input/test.csv\")\nseed= 42", "cell_type": "code"}, {"metadata": {"_uuid": "84a0bc7a1ef5cbf9f21df68b03cf7da617ae8d18"}, "outputs": [], "execution_count": null, "source": "## 1. Set up basic funcitons ", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_uuid": "519b8c834f620ed6a4f6977254373e13919bfa2e", "collapsed": true}, "outputs": [], "execution_count": null, "source": "#report grid search score for finding the best parameters \ndef report(grid_scores, n_top=3):\n    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n    for i, score in enumerate(top_scores):\n        print(\"Model with rank: {0}\".format(i + 1))\n        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n              score.mean_validation_score,\n              np.std(score.cv_validation_scores)))\n        print(\"Parameters: {0}\".format(score.parameters))\n        print(\"\")", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "939d39b5118c00beab43a99a850793548daf0fc1", "collapsed": true}, "outputs": [], "execution_count": null, "source": "#substring function for finding titles in name columns \ndef substrings_in_string(big_string, substrings):\n    for substring in substrings:\n        if big_string.find(substring) != -1:\n            return substring\n    print (big_string)\n    return np.nan", "cell_type": "code"}, {"metadata": {"_uuid": "a1e7f7698ab52b42ecdfb9adc8d066498089dcac"}, "outputs": [], "execution_count": null, "source": "### Encapsulate data cleaning and formating function", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_uuid": "fede06a0450e6749f563aabf1c6a5725e2e6e717", "collapsed": true}, "outputs": [], "execution_count": null, "source": "le = preprocessing.LabelEncoder()\nenc=preprocessing.OneHotEncoder()", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "30d0dad10fbaa9bbde2e4bcbab4577f971615ec0", "collapsed": true}, "outputs": [], "execution_count": null, "source": "def clean_and_munge_data(df):\n    df.Fare = df.Fare.map(lambda x: np.nan if x==0 else x)\n    #title list \n    title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev',\n                'Dr', 'Ms', 'Mlle','Col', 'Capt', 'Mme', 'Countess',\n                'Don', 'Jonkheer']\n    df['Title']=df['Name'].map(lambda x: substrings_in_string(x, title_list))\n    \n    #replace mapped title into different catogories \n    def replace_titles(x):\n        title=x['Title']\n        if title in ['Mr','Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col']:\n            return 'Mr'\n        elif title in ['Master']:\n            return 'Master'\n        elif title in ['Countess', 'Mme','Mrs']:\n            return 'Mrs'\n        elif title in ['Mlle', 'Ms','Miss']:\n            return 'Miss'\n        elif title =='Dr':\n            if x['Sex']=='Male':\n                return 'Mr'\n            else:\n                return 'Mrs'\n        elif title =='':\n            if x['Sex']=='Male':\n                return 'Master'\n            else:\n                return 'Miss'\n        else:\n            return title\n    \n    #new feature title \n    df['Title']=df.apply(replace_titles, axis=1)\n\n    #new feature family size\n    df['Family_Size']=df['SibSp']+df['Parch']\n    df['Family']=df['SibSp']*df['Parch']\n\n    #Handling missing value in Fare \n    #fill in missing fare with median value based on which class they are \n    df.loc[ (df.Fare.isnull())&(df.Pclass==1),'Fare'] =np.median(df[df['Pclass'] == 1]['Fare'].dropna())\n    df.loc[ (df.Fare.isnull())&(df.Pclass==2),'Fare'] =np.median( df[df['Pclass'] == 2]['Fare'].dropna())\n    df.loc[ (df.Fare.isnull())&(df.Pclass==3),'Fare'] = np.median(df[df['Pclass'] == 3]['Fare'].dropna())\n    \n    #mapping set to gender \n    df['Gender'] = df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n    \n    #fill age with mean age base on different title \n    df['AgeFill']=df['Age']\n    mean_ages = np.zeros(4)\n    mean_ages[0]=np.average(df[df['Title'] == 'Miss']['Age'].dropna())\n    mean_ages[1]=np.average(df[df['Title'] == 'Mrs']['Age'].dropna())\n    mean_ages[2]=np.average(df[df['Title'] == 'Mr']['Age'].dropna())\n    mean_ages[3]=np.average(df[df['Title'] == 'Master']['Age'].dropna())\n    df.loc[ (df.Age.isnull()) & (df.Title == 'Miss') ,'AgeFill'] = mean_ages[0]\n    df.loc[ (df.Age.isnull()) & (df.Title == 'Mrs') ,'AgeFill'] = mean_ages[1]\n    df.loc[ (df.Age.isnull()) & (df.Title == 'Mr') ,'AgeFill'] = mean_ages[2]\n    df.loc[ (df.Age.isnull()) & (df.Title == 'Master') ,'AgeFill'] = mean_ages[3]\n    \n    #new feature age category \n    #better to transform continuse age value into different age bin \n    df['AgeCat']=df['AgeFill']\n    df.loc[ (df.AgeFill<=10) ,'AgeCat'] = 'child'\n    df.loc[ (df.AgeFill>60),'AgeCat'] = 'aged'\n    df.loc[ (df.AgeFill>10) & (df.AgeFill <=30) ,'AgeCat'] = 'adult'\n    df.loc[ (df.AgeFill>30) & (df.AgeFill <=60) ,'AgeCat'] = 'senior'\n\n    df.Embarked = df.Embarked.fillna('S')\n\n    df.loc[ df.Cabin.isnull()==True,'Cabin'] = 0.5\n    df.loc[ df.Cabin.isnull()==False,'Cabin'] = 1.5\n\n    df['Fare_Per_Person']=df['Fare']/(df['Family_Size']+1)\n\n    #new feature based on two highly relevant feature age and pclass \n    #create new features \n    df['AgeClass']=df['AgeFill']*df['Pclass']\n    df['ClassFare']=df['Pclass']*df['Fare_Per_Person']\n\n    \n    df['HighLow']=df['Pclass']\n    df.loc[ (df.Fare_Per_Person<8) ,'HighLow'] = 'Low'\n    df.loc[ (df.Fare_Per_Person>=8) ,'HighLow'] = 'High'\n\n    le.fit(df['Sex'] )\n    x_sex=le.transform(df['Sex'])\n    df['Sex']=x_sex.astype(np.float)\n\n    le.fit( df['Ticket'])\n    x_Ticket=le.transform( df['Ticket'])\n    df['Ticket']=x_Ticket.astype(np.float)\n\n    le.fit(df['Title'])\n    x_title=le.transform(df['Title'])\n    df['Title'] =x_title.astype(np.float)\n\n    le.fit(df['HighLow'])\n    x_hl=le.transform(df['HighLow'])\n    df['HighLow']=x_hl.astype(np.float)\n\n    le.fit(df['AgeCat'])\n    x_age=le.transform(df['AgeCat'])\n    df['AgeCat'] =x_age.astype(np.float)\n\n    le.fit(df['Embarked'])\n    x_emb=le.transform(df['Embarked'])\n    df['Embarked']=x_emb.astype(np.float)\n\n    df = df.drop(['PassengerId','Name','Age','Cabin'], axis=1) #remove Name,Age and PassengerId\n    return df\n", "cell_type": "code"}, {"metadata": {"_uuid": "b5c9f0b7981d3334e7fbff323b988b8040636424"}, "outputs": [], "execution_count": null, "source": "## 2. Cleaning training data ", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_uuid": "21d94e524272d15ecec9ea4277f2b8c15acb91ba", "collapsed": true}, "outputs": [], "execution_count": null, "source": "train_df_feature = clean_and_munge_data(train_df)", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "3a25faab3bb6f4f719a87da7b1d891518b06221e"}, "outputs": [], "execution_count": null, "source": "formula_ml='Survived~Pclass+C(Title)+Sex+C(AgeCat)+Fare_Per_Person+Fare+Family_Size' \n\ny_train, x_train = dmatrices(formula_ml, data=train_df_feature, return_type='dataframe')\ny_train = np.asarray(y_train).ravel()\nprint (y_train.shape,x_train.shape)", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "110082ef0c3ccfe03c824775f3cf261e5e129ab1"}, "outputs": [], "execution_count": null, "source": "# feature_train = pd.concat([x_train,y_train], axis=1)\n# print(feature_train.shape)", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "51f015aab1fa6ba4624658513cbf27c5f6736334", "collapsed": true}, "outputs": [], "execution_count": null, "source": "#feature_train.to_csv(\"data/baseline_feature.csv\", index=False)", "cell_type": "code"}, {"metadata": {"_uuid": "f77af975b28cd21636819f9321472d876389fe09"}, "outputs": [], "execution_count": null, "source": "## 3. Split training and testing data", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_uuid": "feec80dc99b1e427c6e102e5be0e9cbf37c5024d", "collapsed": true}, "outputs": [], "execution_count": null, "source": "X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size=0.2,random_state=seed)", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "3e42741b5307bfcfd2e17b847ae7add0ef73c0c0"}, "outputs": [], "execution_count": null, "source": "print(\"x_trian shape\",X_train.shape)\nprint(\"Y_train shape\",Y_train.shape)\nprint(\"X_test shape\",X_test.shape)\nprint(\"Y_test shape\",Y_test.shape)", "cell_type": "code"}, {"metadata": {"_uuid": "f03c5e95b3646bc0773e66ce272bc55399c49727"}, "outputs": [], "execution_count": null, "source": "## 4. Setup model ", "cell_type": "markdown"}, {"metadata": {"_uuid": "5c14ba0d643d40ea72b4bc7a08f6c2f6f727caf9"}, "outputs": [], "execution_count": null, "source": "Used gridsearch to find the best parameters for each different model, delete the repetitive code. \nIf anyone is interested , you could do the gridsearch yourself to find the best tuning parameters", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_uuid": "5775e166ee6747c00ec025550a337527832ffaf3", "collapsed": true}, "outputs": [], "execution_count": null, "source": "#Regression Tree \nrf_clf=RandomForestClassifier(n_estimators=500, criterion='entropy', max_depth=5, min_samples_split=2,\n                           min_samples_leaf=1, max_features='auto',    bootstrap=False, oob_score=False, \n                           n_jobs=1, random_state=seed,verbose=0)\n\n\n#Ada Boosting use gridsearch find best parameters\nada_clf = AdaBoostClassifier(random_state=seed, n_estimators=50,algorithm='SAMME',learning_rate=0.75 )\n\n#Extra Trees \net_clf = ExtraTreesClassifier(n_estimators=500, max_features= 'sqrt',max_depth=8,criterion='entropy',\n                              n_jobs = 50,random_state =seed, verbose =0)\n\n\n#Gradient Boosting \ngbm_clf = GradientBoostingClassifier(learning_rate=0.1,n_estimators=50,min_samples_split=2,max_depth=5,\n                                     min_samples_leaf=5,max_features='sqrt',\n                                     loss='exponential',random_state=42,verbose=0)\n\n\n\n#SVC\n# svc_params = {\n#     'kernel' : ['linear'],\n#     'C' : [0.025],\n#     'gamma':[0.001, 0.01, 0.1]\n#     }\n# svc_clf=SVC()\n\n", "cell_type": "code"}, {"metadata": {"_uuid": "4eec3ddd1610b5989afe45c814a888d270164d67"}, "outputs": [], "execution_count": null, "source": "**Delete SVC, it is too slow on my computer, but you are free to try it yourself~~**", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_uuid": "373c4a90172c007879bb57b270345fed736a5713"}, "outputs": [], "execution_count": null, "source": "%pdb", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "140421c0443dd0ff0cd39ca59c220875e1a01aed", "collapsed": true}, "outputs": [], "execution_count": null, "source": "stratifiedCV = StratifiedShuffleSplit(n_splits = 10, test_size=0.2, random_state =0)\nparam_grid = dict( )\ndef grid_cv(clf,name):\n    grid_search = GridSearchCV(clf,verbose = 3, param_grid = param_grid,scoring ='accuracy', cv = stratifiedCV)\n    grid_search.fit(X_train,Y_train)\n    #print(name, \"Best Params:\" + str(grid_search.best_params_))\n    print(name, \"Best Score:\" + str(grid_search.best_score_))\n    print('-----grid search end------------')\n    print ('on all train set')\n    scores = cross_val_score(grid_search.best_estimator_, x_train, y_train,cv=3,scoring='accuracy')\n    print (scores.mean(),scores)\n    print ('on test set')\n    scores = cross_val_score(grid_search.best_estimator_, X_test, Y_test,cv=3,scoring='accuracy')\n    print (scores.mean(),scores)\n#     predictions\n#     predictions = grid_search.best_estimator_.predict(feature_test)\n    \n    return grid_search.best_estimator_\n", "cell_type": "code"}, {"metadata": {"_uuid": "eadc3692afaf6ba565dc149b3f545a0a75a157af", "collapsed": true}, "outputs": [], "execution_count": null, "source": "## 5. Preparing testing data", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_uuid": "53780d5dc0203f8db853dd34b33080856d314a31"}, "outputs": [], "execution_count": null, "source": "feature_test=clean_and_munge_data(test_df)\nprint(feature_test.shape)", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "10c14e31dcda3722e89f8dfa1b67c433c947f2aa"}, "outputs": [], "execution_count": null, "source": "from patsy import dmatrix\nformula_ml='Pclass+C(Title)+Sex+C(AgeCat)+Fare_Per_Person+Fare+Family_Size' \nfeature_test = dmatrix(formula_ml, data=feature_test, return_type='dataframe')\nprint (feature_test.shape)", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "8ea244f34fbe71c1c4de79e136b8acc4ce541faa", "collapsed": true}, "outputs": [], "execution_count": null, "source": "#feature_test.to_csv(\"data/baseline_feature_test.csv\", index=False)", "cell_type": "code"}, {"metadata": {"_uuid": "8ac3d119d88c9aad6ee4f64c1dc627f0c0402a5e"}, "outputs": [], "execution_count": null, "source": "## 6. Runing first level prediction", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_uuid": "ce01830dc0c636aca657f7e216d198915888e5b3"}, "outputs": [], "execution_count": null, "source": "print (feature_test.shape)\nprint (x_train.shape)", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "7fafd57b96f5b15c17c8b6cda4f3e158203a12b6"}, "outputs": [], "execution_count": null, "source": "print (y_train.shape)", "cell_type": "code"}, {"metadata": {"_uuid": "fd46263b969ece260e0859658ce06ef4b09426cc"}, "outputs": [], "execution_count": null, "source": "### 6.1  Random Forest", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_uuid": "47c9fc47036333511fee556c9a85cb5e27cca476"}, "outputs": [], "execution_count": null, "source": "#Ramdom Forest \nrf_estimator = grid_cv(rf_clf, 'randomForest')  ", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "07d78b236ce6ed0e92b16fb5bee1d6a309028772"}, "outputs": [], "execution_count": null, "source": "rf_train_predict = rf_estimator.predict(x_train).reshape(-1, 1)\nrf_predict = rf_estimator.predict(feature_test).reshape(-1, 1)\nprint(rf_train_predict.shape)\nprint(rf_predict.shape)", "cell_type": "code"}, {"metadata": {"_uuid": "1d30f05aceb1e46c0cf33036b6b48e023ecd6aa8"}, "outputs": [], "execution_count": null, "source": "### 6.2 **Ada Boosting **", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_uuid": "07450cfdcf646eb491cb785ff44ff04fa6e1aa24"}, "outputs": [], "execution_count": null, "source": "ada_estimator = grid_cv(ada_clf, 'AdaBoosting')  ", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "9078ea07de01d688972b18a24f3c6d5b0f28f4f0"}, "outputs": [], "execution_count": null, "source": "ada_train_predict = ada_estimator.predict(x_train).reshape(-1, 1)\nada_predict = ada_estimator.predict(feature_test).reshape(-1, 1)\nprint(ada_train_predict.shape)\nprint(ada_predict.shape)", "cell_type": "code"}, {"metadata": {"_uuid": "0846f2b449fcd762cda5aa477cfb22a03ea2d90f"}, "outputs": [], "execution_count": null, "source": "### 6.3 **Gradient Boosting Model**", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_uuid": "fdf356287b2e7cf92c7da2b37d2f1187ffebe149"}, "outputs": [], "execution_count": null, "source": "gbm_estimator=grid_cv(gbm_clf,\"GradientBoosting\")", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "26d953ad73b239791954145b4c291c77d8768ba2"}, "outputs": [], "execution_count": null, "source": "gbm_train_predict = gbm_estimator.predict(x_train).reshape(-1, 1)\ngbm_predict = gbm_estimator.predict(feature_test).reshape(-1, 1)\nprint(gbm_train_predict.shape)\nprint(gbm_predict.shape)", "cell_type": "code"}, {"metadata": {"_uuid": "6f89ae4a8f4d790cf951e21bad2d38b1385d4526"}, "outputs": [], "execution_count": null, "source": "### 6.4 Extra Tree ", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_uuid": "01b751370645ef1865eb80a435cb986c5703950b"}, "outputs": [], "execution_count": null, "source": "et_estimator = grid_cv(et_clf,\"ExtraTree\")", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "4efc7059af6bbca1f1a7b48d7ca919b22d7152c1"}, "outputs": [], "execution_count": null, "source": "et_train_predict = et_estimator.predict(x_train).reshape(-1, 1)\net_predict = et_estimator.predict(feature_test).reshape(-1, 1)\nprint(et_train_predict.shape)\nprint(et_predict.shape)", "cell_type": "code"}, {"metadata": {"_uuid": "f07d3d2bb9530c11a9514076c64c917611fd01ea"}, "outputs": [], "execution_count": null, "source": "## 7. Second level xgboost model", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_uuid": "aa79edb9b8fa9b0cc633b0e0b61e4bb0b5ea66c8", "collapsed": true}, "outputs": [], "execution_count": null, "source": "ada_predict_change = ada_predict.ravel()", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "b1e7a1d0aa91d4546d875cb8edfa4f2966936866", "collapsed": true}, "outputs": [], "execution_count": null, "source": "x_train = np.concatenate((rf_train_predict, gbm_train_predict,ada_train_predict, et_train_predict), axis=1)\nx_test = np.concatenate(( rf_predict, gbm_predict,ada_predict, et_predict), axis=1)\n\nxgb_clf = xgb.XGBClassifier(n_estimators=2000,max_depth=4,min_child_weight=2,gamma=0.9,colsample_bytree=0.8,\n                              objective='binary:logistic', nthread=-1,scale_pos_weight=1).fit(x_train,y_train)\nxgb_prediction = xgb_clf.predict(x_test)", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "71dc81f365c82e3a2a7d80c49626ea661a59b509"}, "outputs": [], "execution_count": null, "source": "PassengerId = test_df['PassengerId']\nStackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId,\n                            'Survived': xgb_prediction.astype(np.int32) })\nStackingSubmission.to_csv(\"baselineCVSubmission.csv\", index=False)", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "d4dd99e81ae1e3a2831ae7f23bad2928a1efec24", "collapsed": true}, "outputs": [], "execution_count": null, "source": "", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "482fe793683e5980ba1b1deb8becbf998f0c5e90", "collapsed": true}, "outputs": [], "execution_count": null, "source": "", "cell_type": "code"}], "nbformat": 4, "nbformat_minor": 1}