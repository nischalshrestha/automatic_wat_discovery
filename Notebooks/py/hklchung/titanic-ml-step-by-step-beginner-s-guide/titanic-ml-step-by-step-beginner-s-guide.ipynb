{"metadata": {"language_info": {"version": "3.6.3", "mimetype": "text/x-python", "name": "python", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "file_extension": ".py"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat": 4, "cells": [{"metadata": {}, "cell_type": "code", "outputs": [], "source": ["# Import libraries necessary for this project\n", "import numpy as np\n", "import pandas as pd\n", "from sklearn.preprocessing import MinMaxScaler\n", "from sklearn.preprocessing import Imputer\n", "from sklearn.cross_validation import train_test_split\n", "from sklearn import svm\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.metrics import accuracy_score\n", "from sklearn.metrics import f1_score\n", "from sklearn.grid_search import GridSearchCV\n", "from sklearn.metrics import fbeta_score, make_scorer"], "execution_count": 1}, {"metadata": {}, "cell_type": "code", "outputs": [], "source": ["# EXPLORING THE DATA\n", "# Load the wholesale customers dataset\n", "data = pd.read_csv(\"../input/train.csv\")\n", "test_data = pd.read_csv(\"../input/test.csv\")\n", "full_set = data.append(test_data)\n", "full_set.set_index('PassengerId', inplace = True)\n", "full_set = full_set.drop('Ticket', axis=1)\n", "print(\"The titanic dataset has {} samples with {} features each.\".format(*data.shape))\n", "\n", "# simple data exploration\n", "n_survivors = (data['Survived']==1).sum()\n", "n_fatalities = (data['Survived']==0).sum()\n", "\n", "survived_percent = float(n_survivors) / len(data) * 100\n", "print(\"Percentage of passengers who survived the titanic disaster: {:.2f}%\".format(survived_percent))"], "execution_count": 4}, {"metadata": {"collapsed": true}, "cell_type": "code", "outputs": [], "source": ["# DATA PRE-PROCESSING\n", "# define a simple function for feature engineering with the names\n", "def get_title(string):\n", "    string = string.split(\", \")[1].strip()\n", "    string = string.split(\" \")[0].strip()\n", "    return string\n", "\n", "full_set['Name'] = full_set.apply(lambda row: get_title(row['Name']), axis=1)"], "execution_count": 5}, {"metadata": {}, "cell_type": "code", "outputs": [], "source": ["# DATA PRE-PROCESSING\n", "# check if any continuous features (numerical) are skewed\n", "data['Age'].hist()\n", "data['SibSp'].hist()\n", "data['Fare'].hist()\n", "data['Parch'].hist()"], "execution_count": 6}, {"metadata": {"collapsed": true}, "cell_type": "code", "outputs": [], "source": ["# DATA PRE-PROCESSING\n", "# split the data into features and target variable\n", "survive_raw = full_set['Survived']\n", "features_raw = full_set.drop('Survived', axis=1)"], "execution_count": 7}, {"metadata": {"collapsed": true}, "cell_type": "code", "outputs": [], "source": ["# DATA PRE-PROCESSING\n", "# imputation (get rid of the nan)\n", "num_features_raw = ['Age', 'SibSp', 'Fare', 'Parch']\n", "num_imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n", "features_raw[num_features_raw] = num_imp.fit_transform(features_raw[num_features_raw])\n", "\n", "features_raw['Cabin'].fillna('U', inplace=True)\n", "features_raw['Embarked'].fillna('U', inplace=True)\n", "\n", "def get_cabin(cabin):\n", "    cabin = cabin[0]\n", "    return cabin\n", "\n", "features_raw['Cabin'] = features_raw.apply(lambda row: get_cabin(row['Cabin']), axis=1)\n", "features_raw.isnull().sum()\n", "\n", "features_raw_drop_na = features_raw.dropna(axis=0, how='any')"], "execution_count": 8}, {"metadata": {"collapsed": true}, "cell_type": "code", "outputs": [], "source": ["# DATA PRE-PROCESSING\n", "# log transform the skewed data\n", "skewed = ['Age', 'SibSp', 'Fare', 'Parch']\n", "features_log_transformed = pd.DataFrame(data = features_raw_drop_na)\n", "features_log_transformed[skewed] = features_raw_drop_na[skewed].apply(lambda x: np.log(x + 1))"], "execution_count": 9}, {"metadata": {"collapsed": true}, "cell_type": "code", "outputs": [], "source": ["# DATA PRE-PROCESSING\n", "# normalizing numerical features\n", "scaler = MinMaxScaler()\n", "numerical = ['Age', 'SibSp', 'Fare', 'Parch']\n", "features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\n", "features_log_minmax_transform[numerical] = scaler.fit_transform(features_log_transformed[numerical])"], "execution_count": 10}, {"metadata": {"collapsed": true}, "cell_type": "code", "outputs": [], "source": ["# DATA PRE-PROCESSING\n", "# creating the final feature set\n", "cat_features_raw = ['Pclass', 'Name', 'Sex', 'Cabin', 'Embarked']\n", "\n", "final_cat_features = pd.get_dummies(features_log_minmax_transform[cat_features_raw])\n", "final_num_features = features_log_minmax_transform[skewed]\n", "final_features = pd.concat([final_cat_features, final_num_features], axis = 1)"], "execution_count": 11}, {"metadata": {"collapsed": true}, "cell_type": "code", "outputs": [], "source": ["# DATA PRE-PROCESSING\n", "# now that we have done feature engineering with both train and test data, we need to split them apart again\n", "train_features = final_features[:len(data.index)]\n", "train_target = survive_raw[:len(data.index)]\n", "\n", "test_features = final_features[len(data.index):]"], "execution_count": 12}, {"metadata": {}, "cell_type": "code", "outputs": [], "source": ["# DATA PRE-PROCESSING\n", "# shuffle and split the data into training and cross-validation sets\n", "X_train, X_test, y_train, y_test = train_test_split(train_features, train_target, test_size = 0.2, random_state = 0)\n", "\n", "# Show the results of the split\n", "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n", "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"], "execution_count": 14}, {"metadata": {}, "cell_type": "code", "outputs": [], "source": ["# NAIVE PREDICTOR PERFORMANCE\n", "# if we chose a model that always predict '1' (i.e. passenger survives) then what is the model's accuracy and F-score?\n", "accuracy = float(np.sum(survive_raw == 1))/len(survive_raw)\n", "recall = 1\n", "precision = accuracy\n", "\n", "beta = 0.5\n", "fscore = (1 + beta**2) * (precision*recall) / ((beta**2 * precision) + recall)\n", "\n", "# print the results \n", "print(\"Naive Predictor: [Accuracy score: {:.4f}, F-score: {:.4f}]\".format(accuracy, fscore))"], "execution_count": 17}, {"metadata": {}, "cell_type": "code", "outputs": [], "source": ["# ML IMPLEMENTATION\n", "# first we call our DT classifier function\n", "clf1 = DecisionTreeClassifier(random_state=0)\n", "# train our DT classifier with the training data\n", "clf1.fit(X_train, y_train)\n", "# make predictions with CV\n", "clf1_predictions = clf1.predict(X_test)\n", "# find accuracy and f1 score of our DT model\n", "DT_accuracy = accuracy_score(y_test, clf1_predictions)\n", "DT_F1 = f1_score(y_test, clf1_predictions)\n", "# print the results \n", "print(\"Decision Tree Predictor: [Accuracy score: {:.4f}, F-score: {:.4f}]\".format(DT_accuracy, DT_F1))\n", "\n", "# we repeat the above process with another learner\n", "# first we call our SVM classifier function\n", "clf2 = svm.SVC(random_state=0)\n", "# train our SVM classifier with the training data\n", "clf2.fit(X_train, y_train)\n", "# make predictions with CV\n", "clf2_predictions = clf2.predict(X_test)\n", "# find accuracy and f1 score of our SVM model\n", "SVM_accuracy = accuracy_score(y_test, clf2_predictions)\n", "SVM_F1 = f1_score(y_test, clf2_predictions)\n", "# print the results \n", "print(\"SVM Predictor: [Accuracy score: {:.4f}, F-score: {:.4f}]\".format(SVM_accuracy, SVM_F1))\n", "\n", "# we repeat the above process with a third learner\n", "# first we call our SVM classifier function\n", "clf3 = KNeighborsClassifier()\n", "# train our DT classifier with the training data\n", "clf3.fit(X_train, y_train)\n", "# make predictions with CV\n", "clf3_predictions = clf3.predict(X_test)\n", "# find accuracy and f1 score of our DT model\n", "kNN_accuracy = accuracy_score(y_test, clf3_predictions)\n", "kNN_F1 = f1_score(y_test, clf3_predictions)\n", "# print the results \n", "print(\"kNN Predictor: [Accuracy score: {:.4f}, F-score: {:.4f}]\".format(kNN_accuracy, kNN_F1))"], "execution_count": 19}, {"metadata": {"collapsed": true}, "cell_type": "code", "outputs": [], "source": ["# GRID SEARCH\n", "# after we have found the best performing model, we can run grid-search to make the model perform even better\n", "# set our classifier as the best performing classifier\n", "clf = clf3\n", "# choose some parameters for gridsearch\n", "parameters = {'n_neighbors':[3, 5, 7], 'weights':['uniform', 'distance']}\n", "# make an fbeta score scoring object\n", "scorer = make_scorer(fbeta_score, beta=0.5)\n", "# perform grid search on the classifier using 'scorer' as the scoring method using gridsearch\n", "grid_obj = GridSearchCV(estimator=clf, param_grid=parameters, scoring = scorer)\n", "# fit the grid search object to the training data and find the optimal parameters\n", "grid_fit = grid_obj.fit(X_train, y_train)\n", "# get the estimator\n", "best_clf = grid_fit.best_estimator_\n", "# make predictions using the new optimized model\n", "best_predictions = best_clf.predict(X_test)\n", "\n", "# find accuracy and f1 score of our optimized kNN model\n", "kNN_optimized_accuracy = accuracy_score(y_test, best_predictions)\n", "kNN_optimized_F1 = f1_score(y_test, best_predictions)"], "execution_count": 20}, {"metadata": {}, "cell_type": "code", "outputs": [], "source": ["# MODEL EVALUATION\n", "# print results of the benchmark, un-optimized and the optimized models\n", "print(\"Naive predictor:\")\n", "print(\"[Accuracy score: {:.4f}, F-score: {:.4f}]\".format(accuracy, fscore))\n", "print(\"Un-optimized kNN:\")\n", "print(\"[Accuracy score: {:.4f}, F-score: {:.4f}]\".format(kNN_accuracy, kNN_F1))\n", "print(\"Optimized kNN:\")\n", "print(\"[Accuracy score: {:.4f}, F-score: {:.4f}]\".format(kNN_optimized_accuracy, kNN_optimized_F1))"], "execution_count": 21}, {"metadata": {}, "cell_type": "code", "outputs": [], "source": ["# MAKE TEST PREDICTION\n", "# finally we have our 'perfect' model and it is time to make predictions for our test set\n", "output = best_clf.predict(test_features).astype(int)\n", "df_output = pd.DataFrame()\n", "aux = pd.read_csv(\"../input/test.csv\")\n", "df_output['PassengerId'] = aux['PassengerId']\n", "df_output['Survived'] = output\n", "df_output[['PassengerId','Survived']].to_csv('output.csv',index=False)"], "execution_count": 23}], "nbformat_minor": 1}