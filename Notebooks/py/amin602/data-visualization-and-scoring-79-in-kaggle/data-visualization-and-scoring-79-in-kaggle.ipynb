{"cells":[{"metadata":{"_uuid":"ac41d5cfb5fcedeeca27aa0bc3889df8aea24a55"},"cell_type":"markdown","source":"### this notebook is the way to strengthen yourself with visualization using seaborn and matplotlib for a better data story telling .\n### at the final lines we applied machine learning to got a percentage of 79%"},{"metadata":{"_uuid":"dc6196a402567816f794862b83ab0f24b7934048"},"cell_type":"markdown","source":"## if you find this notebook a bit hard in some points please visit [my first notebook](https://www.kaggle.com/amin602/titanic-solution-using-data-analysis) for total beginners to get  started  with data science and machine learning."},{"metadata":{"_uuid":"a5875c7cce8dd7b968de1f6be2367436ef8850d3"},"cell_type":"markdown","source":"## Goal\nIt is your job to predict if a passenger survived the sinking of the Titanic or not. \nFor each PassengerId in the test set, you must predict a 0 or 1 value for the Survived variable.\n\n## Data Dictionary\n\nVariable\tDefinition\tKey\nsurvival\tSurvival\t0 = No, 1 = Yes\npclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd\nsex\tSex\t\nAge\tAge in years\t\nsibsp\t# of siblings / spouses aboard the Titanic\t\nparch\t# of parents / children aboard the Titanic\t\nticket\tTicket number\t\nfare\tPassenger fare\t\ncabin\tCabin number\t\nembarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n\n## Variable Notes\npclass: A proxy for socio-economic status (SES)\n1st = Upper\n2nd = Middle\n3rd = Lower\n\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nsibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc√©s were ignored)\n\nparch: The dataset defines family relations in this way...\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them."},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"ce62b8ffa2c530981b80870379b19b35332fe658"},"cell_type":"code","source":"x=1 # hello from the other side :|","execution_count":2,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"608d848382647ac05ed33b4df82f3d289217482c"},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport sklearn\nimport seaborn as sns \nimport matplotlib.pyplot as plt \n%matplotlib inline \nfrom sklearn.linear_model import LogisticRegression","execution_count":3,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"c41fa7b4345e3d676d5db7963005c677200715c1"},"cell_type":"code","source":"plt.rc(\"font\", size=14)\nsns.set(style=\"dark\") #white background style for seaborn plots\nsns.set(style=\"whitegrid\", color_codes=True)#style=\"whitegrid\"","execution_count":4,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"c8864c1e19654e8ca7f27cdc782cec0966d1f8ec"},"cell_type":"code","source":"training_data = pd.read_csv('../input/train.csv')\ntesting_data = pd.read_csv('../input/test.csv')","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d55df50a3669b260649de970125eb5b933186d1f","collapsed":true},"cell_type":"code","source":"training_data.head()","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a446853dd820d8892b84e49f03bc0cc434cbe5f","collapsed":true},"cell_type":"code","source":"training_data.head()","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b529da2c05c65a595f9d43904f08da812527211","collapsed":true},"cell_type":"code","source":"a,ax=plt.subplots(figsize=(9,9))\nsns.heatmap(training_data.corr(),annot=True,linewidths=0.5,fmt='.1f',ax=ax)\n#there is correlation between survived and (Pclass,Fare,parch,age)","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"611b8c6a0ec0edf9df203f13efd1dd939f16b61f"},"cell_type":"markdown","source":"### making one data frame to make the variables changes to everything  "},{"metadata":{"trusted":true,"_uuid":"40d6d63c133a6e1979990035cf2cf484ef345dce","collapsed":true},"cell_type":"code","source":"training_data_length=len(training_data)# for splitting later to the origional state \nprint('the length of the training data is :',training_data_length)\ndf=pd.concat(objs=[training_data,testing_data],axis=0).copy()\ndf=df.reset_index(drop=True)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5252ba942c536dc7fd808f024a995a5fcfa75232","collapsed":true},"cell_type":"code","source":"df.head(2)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b05e352539a0e454d9570a731d2ae44201da4b7","collapsed":true},"cell_type":"code","source":"print('the Cabins unique values count is :',len(training_data['Cabin'].unique()))\nprint('the null values on Cabin equal:',pd.isnull(training_data['Cabin']).sum())","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"9b6c0349ff66c76c4800e89ca11b2c4037aa93ce"},"cell_type":"markdown","source":"## filling the only null value on Fare,changing the (Sex,Cabins,Embarked) to numbers, reducing the tickets unique values"},{"metadata":{"trusted":true,"_uuid":"7a2c011526b9d5687a69ccbf9728ff4520722a72","collapsed":true},"cell_type":"code","source":"#filling the Fare nans(which is just one row)\ndf.loc[pd.isnull(df['Fare'])==True,'Fare']=df.Fare.median()\n\n#converting male to 1 , female to 0\ndf.loc[df['Sex']=='male','Sex'],df.loc[df['Sex']=='female','Sex']=1,0\n\n#renaming the data 'Cabins' from Characters to numbers\n\ndf.Cabin.fillna(8,inplace=True) \ndf.loc[df.Cabin.str.contains('T',na=False),'Cabin']=8 #the only Cabin that have T in all of the data \n\n# from A to 1, from B to 2 , etc..\na=list('ABCDEFG') ; b=list(range(1,len(a)+1))  \nfor x in range(len(a)):\n    df.loc[df.Cabin.str.contains(a[x],na=False),'Cabin']=b[x]\n    \n    \n#reducing the Tickets unique vales         \nprint('the Ticket length befor the change is :',len(df.Ticket.unique()))\nunique_tickets=df.Ticket.unique()\nfor x in range((len(df)-1)):\n    unique_tickets=df.loc[x,'Ticket'].split(' ')\n    if(len(unique_tickets)==1):\n        \n        if unique_tickets[0]=='1'or'2'or'3'or'4'or'5'or'6'or'7'or'8'or'9':\n            unique_tickets=(unique_tickets[0][0]+unique_tickets[0][1]+unique_tickets[0][2])\n            \n        else:\n            pass\n        \n    elif len(unique_tickets)==2:\n        unique_tickets=unique_tickets[0]\n\n    elif len(unique_tickets)==3 :\n        unique_tickets=unique_tickets[0]\n    df.loc[x,'Ticket']=unique_tickets\n\n#chaging the 'Embarked' into numbers \n    \ndf['Embarked']=df['Embarked'].replace('S',np.int32(1))\ndf['Embarked']=df['Embarked'].replace('Q',np.int32(2))\ndf['Embarked']=df['Embarked'].replace('C',np.int32(3))\n\n\nprint('the Ticket length after the change is  :',len(df.Ticket.unique()))\nprint('how the Tickets numbers look like after the change :',unique_tickets[0:4])\nprint('the unique Cabin values are :',df['Cabin'].unique())\nprint('the unique Pclass values are :',df['Pclass'].unique())","execution_count":12,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27102528f72532e4df6d06b29a06d8448f5f3847","collapsed":true},"cell_type":"code","source":"df.head(2)","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"ce6f8040310c97b32f375771dab85e925a58ea7d"},"cell_type":"markdown","source":"### ### Calssifying the names into \"a useful feature\" ('Title')"},{"metadata":{"trusted":true,"_uuid":"8a3c564c902ed2bd03934573d8191d8d4cbb56d8","collapsed":true},"cell_type":"code","source":"# Define get_title function to extract titles from passenger names\nimport re\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    \n    # If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1) # 1 to erase the space befor the title\n    return \"\"\n\n#testing it..\nprint(get_title('Braund, Mr. Owen Harris'))\n#working\n\n# Create a new feature 'Title' that contains the titles of passenger names\n\n\ndf['Title'] = df['Name'].apply(get_title)\ndel df['Name'] # delete the origional column 'Name' since we don't need it anymore \n\ndf['Title'] = df['Title'].replace('Mlle', 'Miss')\ndf['Title'] = df['Title'].replace('Ms', 'Miss')\ndf['Title'] = df['Title'].replace('Mme', 'Mrs') ","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"2bed7673653a6d40a5aba238b05a7b5f2cc3bc43"},"cell_type":"markdown","source":"### does the title mean anything anyways ? "},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"636968f7c36812ee0165296621abbaea6a0bb9c3","collapsed":true},"cell_type":"code","source":"df.groupby(['Sex','Pclass','Title']).aggregate(np.median).head(10)  # groub them by the features and get the median value\n# so the title actually matters !\n#( but survived changes the value when Pclass changes: as you can see Miss survival changed when she was on Pclass 1 and 2 )\n# we have to search ages by using the 3 of them ('Sex','Pclass','Title')","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"309a5287a1da73a5b494389a9f741d2d9c3a81c0"},"cell_type":"markdown","source":"### well, it does ! so we will use it to help us fill the na values on the 'Age' column "},{"metadata":{"_uuid":"0823203f17b5d6a0e7bf9959062559378fde2812"},"cell_type":"markdown","source":"### filling the 'Age'(given the Pclass,Sex,Title) and the 'Embarked' nans "},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"ec078a592ca2fe931ab7cce5caaa806b23dbd926"},"cell_type":"code","source":"# filling the Age nans by using the 3 features \nfor a in df.Sex.unique():\n        for b in df.Pclass.unique():\n            for c in df.loc[(df['Sex']==a) & (df['Pclass']==b),'Title'].unique():\n                # get the median Age of the not-null Ages that fit the condition \n                the_median=df.loc[(pd.notnull(df['Age'])) & (df['Pclass']==b) &\n                                       (df['Sex']==a) & (df['Title']==c),'Age'].median()\n\n               # set the median Age on the null Ages that fit the condition \n                df.loc[(pd.isnull(df['Age'])) & (df['Pclass']==b) & \n                                  (df['Sex']==a) &(df['Title']==c),'Age']=the_median\n\n#filling the nans on the 'Embarked'\n#df.loc[pd.isnull(df['Embarked'])]#61,829 # less than training_data_length(891) so the nulls on the training data \n# dropping them \ndf=df.drop((df.index[pd.isnull(df['Embarked'])])) #61,829\ntraining_data_length=training_data_length-2                 \n\n#(df[pd.isnull(df['Age'])])#no nulls \n#df[pd.isnull(df['Embarked'])]#no nulls ","execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f300a18bdab0e606a592c5c980b4e809b0e393c","collapsed":true},"cell_type":"code","source":"df.columns","execution_count":17,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"7d415b7dabf616def23cb4f13bd9158d95ee1192","collapsed":true},"cell_type":"code","source":"for i in df.columns:\n     print ('for the column %s :'%i,df[i].unique())\n    ","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"d348db7c5422c35a0acd1f174ef79149c2414972"},"cell_type":"markdown","source":"### looking at the unique values for the columns "},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"4010248c9df38862d60be3c88798a379a7843388","collapsed":true},"cell_type":"code","source":"print('survived : ', df.Survived.unique())\nprint('Sex : ',df.Sex.unique())  # 1 for male , 0 for female \nprint('Pclass : ',df.Pclass.unique())#Ticket class\nprint('SibSp :',df.SibSp.unique())# of siblings / spouses aboard the Titanic\nprint('Embarked : ',df.Embarked.unique()) # Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\nprint('Parch : ',df.Parch.unique())# of parents / children aboard the Titanic\nprint('Cabin :',df.Cabin.unique())\nprint('Age :',df.Age.unique())\n#print(df['Fare']) # the ticket cost  # bad idea ... (alot of unique values)\n# the only nans are the survived on the testing data ","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"10884a6efbcb03c56341d288275f4cec0dfd230f"},"cell_type":"markdown","source":"## plots to show the relationship with survival rate and some columns "},{"metadata":{"trusted":true,"_uuid":"e70fee9e83d787d8b0e7839201ca976e0314ff3e","collapsed":true},"cell_type":"code","source":"fig,ax=plt.subplots(1,5,figsize=(17,5))\nsns.barplot(df['Embarked'],df['Survived'],ci=False,ax=ax[0])\nsns.barplot(df['SibSp'],df['Survived'],ci=False,ax=ax[1]);ax[1].set_ylabel('')\nsns.barplot(df['Parch'],df['Survived'],ci=False,ax=ax[2]);ax[2].set_ylabel('')\n\ndf['relations']=df['SibSp']+df['Parch']\nsns.barplot(df['relations'],df['Survived'],ci=False,ax=ax[3]);ax[3].set_ylabel('')\n\nax[4].hist2d(x=training_data['Survived'],y=training_data['Pclass']);ax[4].set_title('Survival and death desity due to Pclass')\n\nprint('so having relations have an effective percentage of the survival ')","execution_count":20,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9d886618a29eacea4d248863364dc0788e5c1c1","collapsed":true},"cell_type":"code","source":"df[:training_data_length].head(2)","execution_count":21,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"679cc741835d9440307b97bdbc5d30d66e4c748b","collapsed":true},"cell_type":"code","source":"fig,ax=plt.subplots(1,5,figsize=(18,4))\nsns.barplot(df['Cabin'],df['Survived']==1,ci=False,ax=ax[0]); ax[0].set_title('who survived');ax[0].set_ylabel(' ')\nsns.barplot(df['Cabin'],df['Survived']==0,ci=False,ax=ax[1]); ax[1].set_title('who didn\\'t survive');ax[1].set_ylabel(' ')\n#df.Sex.plot('hist')\nax[2].hist(df.Sex);ax[2].set_title('the sex count')\nax[3].hist(training_data.Survived);ax[3].set_title('the Survived count on training data ')\nax[4].scatter(df['Pclass'],df['Cabin'],s=200) # s : the size of the dotts\nax[4].set_xlabel('The Pclass');ax[4].set_ylabel('Cabins');ax[4].set_title('Pclass regression  in cabins')","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"42e600536ee4b947ff4c089741c7e19ab4305753"},"cell_type":"markdown","source":"# Sex vs Cabins vs Survival "},{"metadata":{"trusted":true,"_uuid":"e0b95af4f98009451272a9036a54b76494319540","collapsed":true},"cell_type":"code","source":"fig,ax=plt.subplots(2,2,figsize=(6,6))\nfig.suptitle('plotting the Sex vs (putted Cabins) vs survival')\nsns.countplot('Cabin',data=df.loc[((df.Cabin!=8) & (df.Sex==0) & (df.Survived==0))],ax=ax[0,0]);ax[0,0].set_ylabel('didn\\'t survive count');ax[0,0].set_xlabel('');ax[0,0].set_title('females')\nsns.countplot('Cabin',data=df.loc[((df.Cabin!=8) & (df.Sex==1)& (df.Survived==0))],ax=ax[0,1]);ax[0,1].set_ylabel('');ax[0,1].set_xlabel('');ax[0,1].set_title('males')\nsns.countplot('Cabin',data=df.loc[((df.Cabin!=8) & (df.Sex==0)& (df.Survived==1))],ax=ax[1,0]);ax[1,0].set_ylabel('Survival count');ax[1,0].set_xlabel('')\nsns.countplot('Cabin',data=df.loc[((df.Cabin!=8) & (df.Sex==1)& (df.Survived==1))],ax=ax[1,1]);ax[1,1].set_ylabel('');ax[1,1].set_xlabel('')","execution_count":23,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"83eaf635b7081c0fefb4d210ce378d4795a9b0b9"},"cell_type":"code","source":"# making a dataFrame to plot the people who didn't Survive\ntemp=df[:training_data_length]\ntemp2=temp.copy() # replace 0 to 1 and 1 to 0 for the plotting \ntemp2['Survived']=temp2['Survived'].replace(0,np.int32(2))\ntemp2['Survived']=temp2['Survived'].replace(1,np.int32(0))\ntemp2['Survived']=temp2['Survived'].replace(2,np.int32(1))\ntemp2['Age_Classification']=(temp2.loc[:,'Age']/40).astype(int)","execution_count":24,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f59456d617d75071db5cc52f6edfce3747331f3a","collapsed":true},"cell_type":"code","source":"temp=df[:training_data_length] # i made it because there is nulls on the age for the training \nfig,ax=plt.subplots(1,4,figsize=(18,6))\n\na=sns.regplot(data=temp,x='Age',y='Survived',ci=False,order=5,ax=ax[0])\na.set(xlim=(0.43, 70),ylim=(0,1.1))\nw=sns.barplot(temp['Age'],temp['Survived']==1,ci=None,ax=ax[1]) # survived !\nw.set(ylabel='Survived')\n\n\nw=sns.barplot(temp['Age'],temp['Survived']==0,ci=None,ax=ax[2])\nw.set( ylabel='didn\\'t survive')\na=sns.regplot(data=temp2,x='Age',y='Survived',ci=False,order=5,ax=ax[3])#,set_ylabel('dd'))\na.set_ylabel('didn\\'t survive')\na.set(xlim=(0.43, 70),ylim=(0,1.1))\n#a.legend(['survived','didn\\'t survive'])# ","execution_count":25,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"b40aee0075abf12013bc12c8b874b9bff97a28a5","collapsed":true},"cell_type":"code","source":"print(np.max(temp.Age))\nprint(np.min(temp.Age))","execution_count":26,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6068e6d8c60b5a1ac47077eb8bf6116b66e56d0b","collapsed":true},"cell_type":"code","source":"sns.distplot(temp['Age'][temp['Survived']==1],label='Survived', hist=False)\nsns.distplot(temp['Age'][temp['Survived']==0], hist=False,label='Didn\\'t survive')","execution_count":27,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e25ce9247f8efb3085b8237faf81d2ba537e8a1e","collapsed":true},"cell_type":"code","source":"grid =sns.FacetGrid(training_data,row='Survived',col='Sex',margin_titles=True) # FaceGrid : it makes the histograms ready in seaborn \n                                                # margin_titles : to make the titles show on like its a data frames ( on the side and top )\ngrid.map(plt.hist,'Pclass')","execution_count":28,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84f7478a8aa3901ea18a60757a2e179fa3d4cc87","collapsed":true},"cell_type":"code","source":"# is the titanic movie right about the captin death tho ? \ndf[df['Title']=='Capt']\n#the captin of the titanic didn't survive...\n# well, that was sad lol ","execution_count":29,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"3e6f95ac9d7bb034e2e57b25a941af7b2856980b"},"cell_type":"code","source":"#plt.scatter(training_data['Survived'],training_data['Fare'])\n# and ladies and gentlements , we take from this plot that the people who payed about 500 pounds simply survived (at least in the training data )\n# unhash code to see it with your eyes","execution_count":30,"outputs":[]},{"metadata":{"_uuid":"cac334ede3383ed0b8bd3d355da01f7190c29ff7"},"cell_type":"markdown","source":"### making dummies for training and testing data (for 'Title','Cabin','Pclass','Embarked')"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"8184b4f8171adbe450c5e9b5205e1a4acf819ded"},"cell_type":"code","source":"dummies_titles = pd.get_dummies(df['Title'],prefix='Title')\ndf = pd.concat([df,dummies_titles],axis=1)\n\n\ndummies_titles = pd.get_dummies(df['Cabin'],prefix='Cabin')\ndf = pd.concat([df,dummies_titles],axis=1)\n\n\ndummies_titles = pd.get_dummies(df['Pclass'],prefix='Pclass')\ndf = pd.concat([df,dummies_titles],axis=1)\n\n\ndummies_titles = pd.get_dummies(df['Embarked'],prefix='Embarked')\ndf = pd.concat([df,dummies_titles],axis=1)\n\n# deleting the columns that we changed \ndel df['Title'] ; del df['Cabin'] ; del df['Pclass'] ; del df['Embarked']\ndel df['PassengerId']\n\ndel df['Ticket']\n","execution_count":31,"outputs":[]},{"metadata":{"_uuid":"58fbbeacc58326bd74e4c048535658ee18b89828"},"cell_type":"markdown","source":"### getting the training data and testing data to their normal form"},{"metadata":{"trusted":true,"_uuid":"b184d127791917feb45f818fbc2e197062dfb197","collapsed":true},"cell_type":"code","source":"training_data = df[:training_data_length].copy()\ntraining_data=training_data.reset_index(drop=True)\n\ntesting_data = df[training_data_length:].copy()\ntesting_data=testing_data.reset_index(drop=True)\n\ndel testing_data['Survived'] # it is generated as nan by the first concat (while gathering the data )\n\nprint ('the length of the training data is ',len(training_data.columns)) # the normal columns and the \"Survived\" column\nprint (' the length of the testing data is ',len(testing_data.columns))","execution_count":32,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"e768dbda3069dd853c7443542e4254bd13848156"},"cell_type":"code","source":"del training_data['Cabin_8']\ndel testing_data['Cabin_8']\n\n\ntraining_x=training_data.copy()\ndel training_x['Survived']\ntraining_y =training_data['Survived'].copy()\n\ntesting=testing_data.copy()","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7d38300b4e268a078a4ecc394a27aa2a9e4fb9f","collapsed":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogistic=LogisticRegression()\nss=logistic.fit(training_x,training_y)\nresult=logistic.predict(testing)\n\nprint(result[:3]) # ok,everything is good\n\ndf=pd.concat([pd.read_csv('../input/test.csv',usecols=[0]),pd.DataFrame({'Survived':result})],axis=1).set_index('PassengerId')\ndf.Survived=df.Survived.astype(int)\n\ndf.to_csv('result.csv')\n# and from that we got 0.78947 on kaggle ","execution_count":34,"outputs":[]},{"metadata":{"_uuid":"546513c3a06498f68186857697b8c2b6e65a226e"},"cell_type":"markdown","source":"### so from here we just check the other models (maybe some model can do better )"},{"metadata":{"trusted":true,"_uuid":"368c172ac11957860a4f9ddb04fdfcba2675b4f3","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\nfrom sklearn.linear_model import LogisticRegression\nlogistic =LogisticRegression()\n\nfrom sklearn.neighbors import KNeighborsClassifier\nkNeibours=KNeighborsClassifier(n_neighbors=3)\n\nfrom sklearn.tree import DecisionTreeClassifier\ntree=DecisionTreeClassifier()\n\nfrom sklearn.tree import DecisionTreeRegressor\nregressor=DecisionTreeRegressor()\n\nfrom sklearn.ensemble import RandomForestClassifier\nforest=RandomForestClassifier()\n\nfrom sklearn.linear_model import LinearRegression\nlinearRegression=LinearRegression()\n\nfrom sklearn.svm import SVR\nsvr=SVR()\n\nfrom sklearn.svm import SVC\nsvc=SVC()\n\n\nlogistic_scores=cross_val_score(logistic,training_x,training_y,cv=5)\nkNeibours_scores=cross_val_score(kNeibours,training_x,training_y,cv=5)\ntree_scores=cross_val_score(tree,training_x,training_y,cv=5)\nforest_scores=cross_val_score(forest,training_x,training_y,cv=5)\nlinearRegression_scores=cross_val_score(linearRegression,training_x,training_y,cv=5)\nsvc_scores=cross_val_score(svc,training_x,training_y,cv=5)\nsvr_scores=cross_val_score(svr,training_x,training_y,cv=5)\n\n\nprint ('the logistic_scores accuracy score is ',np.average(logistic_scores))\nprint ('kNeibours_scores accuracy score is ',np.average(kNeibours_scores))\nprint ('the tree_scores accuracy score is ',np.average(tree_scores))\nprint ('the forest_scores accuracy score is ',np.average(forest_scores))\nprint ('the linearRegression_scores accuracy score is ',np.average(linearRegression_scores))\nprint ('the svc_scores accuracy score is ',np.average(svc_scores))\nprint ('the svr_scores accuracy score is ',np.average(svr_scores))","execution_count":35,"outputs":[]},{"metadata":{"_uuid":"1cc3db6ca6cd9571451e4a8314618a478a51f74d"},"cell_type":"markdown","source":"### LogisticRegressionand, forest and the tree  are the best here !  "},{"metadata":{"_uuid":"d1c0d69557e64fa99ae3c1f8899e728dbe21653b"},"cell_type":"markdown","source":"# from here we see that our logistic regression is the best one of them and the others have less accuracy."},{"metadata":{"_uuid":"b14b4baa751890297d1af52758c1bffa0dea63c1"},"cell_type":"markdown","source":"# how to plot the importance of the columns ?! "},{"metadata":{"trusted":true,"_uuid":"5c3bcd198334c8c8ca6f0c651a8abd2e80622eee","collapsed":true},"cell_type":"code","source":"from sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression\n\nlogistic =LogisticRegression()\nlogistic = logistic.fit(training_x, training_y)\n\n# print(logistic.transform)\n\n\na=logistic.coef_\nb=training_x.columns\na[0]=np.abs(a[0]) # getting the absoulte values so we get the strong relations despite if it's a negative or positive relation\n\na=pd.DataFrame()\na['Title']=training_x.columns\na['Values']=logistic.coef_[0]\na.sort_values('Values')\na.set_index('Title', inplace=True)\na.sort_values(by=['Values'], ascending=True, inplace=True)\na.plot(kind='barh', figsize=(10,10))\n# so it got the age as a really bad feature because it is basically not catagorical .... \n# so as you know the decision trees ADORE the catagorical data since it is build on such logic .... \n# it basically can't use the age because it will overfit when it uses it so that sucks for it :) ","execution_count":37,"outputs":[]},{"metadata":{"_uuid":"de10907a09f2055a2b7232972ec0df65c6151e6f"},"cell_type":"markdown","source":"### the important features for Random Forest Classifier"},{"metadata":{"trusted":true,"_uuid":"984d7231cb4d2a0dc7e37857dd8c242598f7f62f","collapsed":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectFromModel\nclf = RandomForestClassifier(n_estimators=5)#, max_features='sqrt')\nclf = clf.fit(training_x, training_y)\n\nfeatures = pd.DataFrame()\nfeatures['feature'] = training_x.columns\nfeatures['importance'] = clf.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)\n\nfeatures.plot(kind='barh', figsize=(10,10))","execution_count":38,"outputs":[]},{"metadata":{"_uuid":"d09242d81188a51ddc7e3df30397e8a118db9ed9"},"cell_type":"markdown","source":"### so the final result that we got to is : \n- we noticed that the best model for such a problem is LogisticRegression because of the continuous data and that it has a critical importance on the dataset\n"},{"metadata":{"trusted":true,"_uuid":"925a4d3e29ba5faa8a4dbf10639c4c4a1474a11f","collapsed":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogistic=LogisticRegression()\nss=logistic.fit(training_x,training_y)\nresult=logistic.predict(testing)\n\nprint(result[:3]) # ok,everything is good\n\n\n\ndf=pd.concat([pd.read_csv('../input/test.csv',usecols=[0]),pd.DataFrame({'Survived':result})],axis=1).set_index('PassengerId')\ndf.Survived=df.Survived.astype(int)\n\ndf.to_csv('result.csv')\n# and from that we got 0.78947 on kaggle ","execution_count":39,"outputs":[]},{"metadata":{"_uuid":"80db2f6bba34dc52c2ae98ada5091f29dca2ade1"},"cell_type":"markdown","source":"## i uploaded the result file from this code  and got 0.78947% accuracy for doing the simple steps above "},{"metadata":{"_uuid":"38a2466ad0ecf445e16096b20c3478f25aa112e0"},"cell_type":"markdown","source":"# please upvote the kernal if you find it useful !"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}