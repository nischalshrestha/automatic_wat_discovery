{"nbformat_minor": 1, "cells": [{"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "42fce36060c7f1956fa3f60b9f55137cb13c91e8", "_cell_guid": "a5068dbb-6c46-4401-9978-682e5df67859"}, "outputs": [], "source": ["import tensorflow as tf\n", "import numpy as np\n", "import pandas as pd\n", "import seaborn as sns\n", "\n", "import warnings\n", "warnings.filterwarnings('ignore')"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "49f387c025f27111ca9e9fe024affaee7c2c5759", "collapsed": true, "_cell_guid": "c89e5a2d-146b-4d3a-9ee2-d9754222203e"}, "outputs": [], "source": ["train = pd.read_csv(\"../input/train.csv\")\n", "test = pd.read_csv(\"../input/test.csv\")"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "2e8ee0000187d71fcdf04dc1fc966dbd47a065d2", "_cell_guid": "b537a72e-fda1-4c73-acdc-1f184b3e61cc"}, "outputs": [], "source": ["train = train.drop(['PassengerId', 'Parch', 'Ticket', 'Cabin', 'Embarked'], axis = 1)\n", "test = test.drop(['Parch', 'Ticket', 'Cabin', 'Embarked'], axis = 1)\n", "test.describe(include=\"all\")"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "a97b2b5135e96815f7022b40a389b2ad49f6db03", "_cell_guid": "8af03d48-ca6a-4daa-abe3-f0108ba520cf"}, "outputs": [], "source": ["# create a combined group of both datasets\n", "combine = [train, test]\n", "\n", "#extract a title for each Name in the train and test datasets\n", "for dataset in combine:\n", "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n", "\n", "for dataset in combine:\n", "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Capt', 'Col',\n", "    'Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n", "    \n", "    dataset['Title'] = dataset['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\n", "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n", "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n", "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n", "    \n", "#map each of the title groups to a numerical value\n", "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 6}\n", "for dataset in combine:\n", "    dataset['Title'] = dataset['Title'].map(title_mapping)\n", "    dataset['Title'] = dataset['Title'].fillna(0)\n", "    \n", "train.describe(include=\"all\")"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "cd932a495128503b861354db16bf70ed9a359d6b", "collapsed": true, "_cell_guid": "46708982-4cf0-4de3-87a8-75f6ce20a7c7"}, "outputs": [], "source": ["#sort the ages into logical categories\n", "train[\"Age\"] = train[\"Age\"].fillna(-0.5)\n", "test[\"Age\"] = test[\"Age\"].fillna(-0.5)\n", "bins = [-1, 0, 5, 12, 18, 24, 35, 60, np.inf]\n", "labels = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n", "train['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = labels)\n", "test['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = labels)\n", "\n", "mr_age = train[train[\"Title\"] == 1][\"AgeGroup\"].mode() #Young Adult\n", "miss_age = train[train[\"Title\"] == 2][\"AgeGroup\"].mode() #Student\n", "mrs_age = train[train[\"Title\"] == 3][\"AgeGroup\"].mode() #Adult\n", "master_age = train[train[\"Title\"] == 4][\"AgeGroup\"].mode() #Baby\n", "royal_age = train[train[\"Title\"] == 5][\"AgeGroup\"].mode() #Adult\n", "rare_age = train[train[\"Title\"] == 6][\"AgeGroup\"].mode() #Adult\n", "\n", "age_title_mapping = {1: \"Young Adult\", 2: \"Student\", 3: \"Adult\", 4: \"Baby\", 5: \"Adult\", 6: \"Adult\"}\n", "\n", "for x in range(len(train[\"AgeGroup\"])):\n", "    if train[\"AgeGroup\"][x] == \"Unknown\":\n", "        train[\"AgeGroup\"][x] = age_title_mapping[train[\"Title\"][x]]\n", "        \n", "for x in range(len(test[\"AgeGroup\"])):\n", "    if test[\"AgeGroup\"][x] == \"Unknown\":\n", "        test[\"AgeGroup\"][x] = age_title_mapping[test[\"Title\"][x]]\n", "        \n", "age_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\n", "train['AgeGroup'] = train['AgeGroup'].map(age_mapping)\n", "test['AgeGroup'] = test['AgeGroup'].map(age_mapping)\n", "\n", "train.head()\n", "\n", "#dropping the Age feature for now, might change\n", "train = train.drop(['Age'], axis = 1)\n", "test = test.drop(['Age'], axis = 1)"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "932b8acf613ba20c65f7c4d89bc70ead89158a5f", "collapsed": true, "_cell_guid": "6000a9cd-cc67-4c8c-afcb-e3507d1f0374"}, "outputs": [], "source": ["for x in range(len(test[\"Fare\"])):\n", "    if pd.isnull(test[\"Fare\"][x]):\n", "        pclass = test[\"Pclass\"][x] #Pclass = 3\n", "        test[\"Fare\"][x] = round(train[train[\"Pclass\"] == pclass][\"Fare\"].mean(), 4)\n", "        \n", "#map Fare values into groups of numerical values\n", "train['FareBand'] = pd.qcut(train['Fare'], 4, labels = [1, 2, 3, 4])\n", "test['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1, 2, 3, 4])\n", "\n", "#drop Fare values\n", "train = train.drop(['Fare'], axis = 1)\n", "test = test.drop(['Fare'], axis = 1)"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "a70fcc33bc8a0aa36b29dc0fa49aaae4c080eae2", "_cell_guid": "2a53b41e-2e7f-43c9-8e8f-6c261ed97db5"}, "outputs": [], "source": ["test.describe(include=\"all\")"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "3d3edc421d2640a9a7eab0a61ab43d0498012e2e", "collapsed": true, "_cell_guid": "d67a00c3-2f12-4239-8b1b-260d5d1a5323"}, "outputs": [], "source": ["train = train.drop([\"Title\", \"Name\"], axis = 1)\n", "test = test.drop([\"Title\", \"Name\"], axis = 1)"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "c50048d19098db3e5d90f56cac7dc4ff40faad9d", "_cell_guid": "3ebe9874-4dc6-4177-bd37-4ce0b35ca62b"}, "outputs": [], "source": ["sex_mapping = {'male': 0, 'female': 1}\n", "train['Sex'] = train['Sex'].map(sex_mapping)\n", "test['Sex'] = test['Sex'].map(sex_mapping)\n", "\n", "train.head()"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "243fae1adf79520ed806d30b3e90c9f750f68a99", "_cell_guid": "5de1df97-c250-46e9-95f7-d98eeb24a057"}, "outputs": [], "source": ["X = tf.placeholder(np.float32, [None, 5])\n", "Y = tf.placeholder(np.float32, [None, 1])\n", "\n", "def xavier_init(n_inputs, n_outputs, uniform=True):\n", "    if uniform:\n", "        init_range = tf.sqrt(6.0 / (n_inputs + n_outputs))\n", "        return tf.random_uniform_initializer(-init_range, init_range)\n", "    else:\n", "        stddev = tf.sqrt(3.0 / (n_inputs + n_outputs))\n", "        return tf.truncated_normal_initializer(stddev=stddev)\n", "\n", "W1 = tf.get_variable(\"W1\", shape=[5, 40], initializer=xavier_init(5, 40))\n", "W2 = tf.get_variable(\"W2\", shape=[40, 40], initializer=xavier_init(40, 40))\n", "W3 = tf.get_variable(\"W3\", shape=[40, 1], initializer=xavier_init(40, 1))\n", "\n", "B1 = tf.Variable(tf.random_normal([40]))\n", "B2 = tf.Variable(tf.random_normal([40]))\n", "B3 = tf.Variable(tf.random_normal([1]))\n", "\n", "keep_prob = tf.placeholder(tf.float32)\n", "\n", "L1 = tf.nn.relu(tf.add(tf.matmul(X, W1), B1))\n", "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n", "L2 = tf.nn.relu(tf.add(tf.matmul(L1, W2), B2))\n", "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n", "hypothesis = tf.add(tf.matmul(L2, W3), B3)"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "0de7e59c7de87f02bb984cf961219479156453f2", "collapsed": true, "_cell_guid": "fc99f492-79fa-403d-862f-1feeec9a0b1f"}, "outputs": [], "source": ["cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=hypothesis, labels=Y))"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "9403c3cd8a9c8d18560783dcd4ffa1104a58a907", "_cell_guid": "07fc9d27-7052-4f5a-9437-f031c2581a98"}, "outputs": [], "source": ["learning_rate = 0.0005\n", "\n", "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n", "\n", "init = tf.initialize_all_variables()"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "1792b5713bbcc3be8e977d4e55066e97ed804151", "collapsed": true, "_cell_guid": "1451cf6d-b23c-47b1-8934-cc2a7c443bfb"}, "outputs": [], "source": ["trainY = pd.DataFrame(train[\"Survived\"])"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "8289fe16737b91f935baea9f35279ce7c9262d07", "collapsed": true, "_cell_guid": "58185bbd-de53-425e-81b4-75e99d09ea8b"}, "outputs": [], "source": ["train = train.drop([\"Survived\"], axis = 1)"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "53bcdab4b6b0e7462a49dbf6ef00d5c694d03544", "_cell_guid": "d9feae8d-7f58-4d12-9d98-3ce46b198099"}, "outputs": [], "source": ["trainx = np.array(train, dtype=np.float32)\n", "trainy = np.array(trainY, dtype=np.float32)\n", "\n", "print(trainy.dtype)"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "3f020d452ba78b645ab2da202179c333a45426e7", "collapsed": true, "_cell_guid": "e630270b-cf6b-4a0f-9ad2-ac2f5ab900fa"}, "outputs": [], "source": ["predict = (tf.nn.sigmoid(hypothesis) > 0.5)\n", "correct_prediction = tf.equal(predict, (Y > 0.5))\n", "\n", "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n", "\n", "testx = test.drop([\"PassengerId\"], axis = 1)\n", "testx = np.array(testx, dtype = np.float32)"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "fdf590dbd7606c631233bdc2c3c21186fa515fd1", "_cell_guid": "70b277c2-10d6-4513-a7c0-4fef1ba38ba3"}, "outputs": [], "source": ["sess = tf.Session()\n", "sess.run(init)\n", "feed = {X: trainx, Y: trainy, keep_prob: 0.8}\n", "    \n", "for step in range(10001):\n", "    sess.run(optimizer, feed_dict=feed)\n", "        \n", "    if step % 100 == 0:\n", "        print(step, sess.run([cost, accuracy], feed_dict=feed))"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "efa93f092df2e629807f27d30e2330969b7a46bb", "_cell_guid": "ec3ec0e1-f928-49a1-9c50-12cc921012ac"}, "outputs": [], "source": ["predicted = sess.run(predict, feed_dict={X: testx, keep_prob: 0.8})\n", "\n", "sol = pd.DataFrame()\n", "sol['PassengerId'] = test['PassengerId']\n", "sol['Survived'] = pd.Series(predicted.reshape(-1)).map({True:1, False:0})\n", "print(sol)\n", "sol.to_csv('solution3.csv', index=False)"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["ans = pd.read_csv(\"../input/gender_submission.csv\")\n", "acc_array = np.where(sol[\"Survived\"] == ans[\"Survived\"], 1, 0)\n", "print(np.mean(acc_array, axis = 0))"]}], "metadata": {"language_info": {"version": "3.6.3", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "name": "python"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "nbformat": 4}