{"cells": [{"cell_type": "markdown", "metadata": {"_cell_guid": "913dccf8-e346-4de3-83ae-27bd62910f44", "_uuid": "253eb1f61ad072015b2ef7426db57c7a2ec2d398"}, "source": ["**Python script** for ***Titanic: Machine learning from disaster*** made in ***PyCharm***.\n", "Notes before running the script :\n", "-> Download the script and change the location to where you have the **train.csv** and **test.csv **of the dataset from Kaggle.\n", "-> Similar changes to be made in the ***submission***.\n", "-> Just uncomment the lines in order to run the code. eg- ***Plots***\n", "\n", "Final notes:\n", "-> Newbie here. I tried my best to comment things for easy explanation.\n", "-> Not familiar with Jupyter notebook style.(Personally use ***PyCharm***)\n", "-> If any questions please ask in comments section. I'll try my best to answer it. (***For Newbies***)\n", "-> All type of suggestions are welcomed.\n", "\n", "**Kindly ignore the output of notebook.**"]}, {"cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "3d12c447-d86f-4a60-999b-c5c0927fd9b9", "_uuid": "462c87ede27ee7f1f9bb790880cd63b66ce2ecd2"}, "source": ["# $ 0 U l $ h ! f T 3 r\n", "\n", "# IMPORT BASIC LIBRARIES\n", "\n", "import numpy as np\n", "\n", "import pandas as pd\n", "pd.set_option('display.height', 2000)\n", "pd.set_option('display.max_rows', 2000)\n", "pd.set_option('display.max_columns', 2000)\n", "pd.set_option('display.width', 2000)\n", "pd.set_option('display.max_colwidth', -1)\n", "\n", "import matplotlib\n", "from matplotlib import pyplot as plt\n", "matplotlib.style.use('ggplot')\n", "\n", "import seaborn as sns\n", "\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "\n", "# DATA LOAD\n", "train_set = pd.read_csv(\"/home/vic/Desktop/Kaggle/Titanic/train.csv\")\n", "test_set = pd.read_csv(\"/home/vic/Desktop/Kaggle/Titanic/test.csv\")\n", "\n", "# DATA CHECK\n", "\"\"\"print(train_set.describe())\n", "print(train_set.describe(include=[\"object\"]))\n", "print(train_set.columns)\n", "print(train_set.shape)\n", "print(test_set.describe())\n", "print(test_set.describe(include=[\"object\"]))\n", "print(test_set.columns)\n", "print(test_set.shape)\n", "print(train_set.head())\"\"\"\n", "\n", "\n", "# SETTING TARGET\n", "target = train_set.Survived\n", "\n", "# DROPPING UNNECCESSARY FEATS\n", "train_set.drop([\"PassengerId\",\"Survived\",\"Ticket\"],axis=1,inplace=True)\n", "test_pas_id = test_set.PassengerId\n", "test_set.drop([\"PassengerId\",\"Ticket\"],axis=1,inplace=True)\n", "# print(test_pas_id.head())\n", "\n", "# NUMERIC FEATS AND CATEGORICAL FEATS\n", "train_numfeats = train_set.select_dtypes(exclude=[\"object\"]).columns\n", "test_numfeats = test_set.select_dtypes(exclude=[\"object\"]).columns\n", "train_catfeats = train_set.select_dtypes(include=[\"object\"]).columns\n", "test_catfeats = test_set.select_dtypes(include=[\"object\"]).columns\n", "\n", "\n", "# ADDING AND DELETING FEATURES\n", "train_set[\"Familysize\"] = train_set[\"Parch\"] + train_set[\"SibSp\"]\n", "train_set.drop([\"SibSp\",\"Parch\"],axis=1,inplace=True)\n", "test_set[\"Familysize\"] = test_set[\"Parch\"] + test_set[\"SibSp\"]\n", "test_set.drop([\"SibSp\",\"Parch\"],axis=1,inplace=True)\n", "\n", "# NUMERIC FEATS AND CATEGORICAL FEATS\n", "train_numfeats = train_set.select_dtypes(exclude=[\"object\"]).columns\n", "test_numfeats = test_set.select_dtypes(exclude=[\"object\"]).columns\n", "train_catfeats = train_set.select_dtypes(include=[\"object\"]).columns\n", "test_catfeats = test_set.select_dtypes(include=[\"object\"]).columns\n", "\n", "# CHECKING NULL FEATS\n", "# print(train_set.isnull().sum())\n", "# print(test_set.isnull().sum())\n", "\n", "# PLOT TO CHECK HOW TO FILL MISSING VALUES\n", "# train_set[\"Age\"].hist(bins=15,color=\"teal\",alpha=0.8)\n", "# sns.countplot(x=\"Embarked\",data=train_set,palette=\"Set2\")\n", "# train_set[\"Fare\"].hist(bins=15,color=\"teal\",alpha=0.8)\n", "# plt.show()\n", "\n", "\n", "# DEALING WITH FEATS\n", "train_set[\"Age\"].fillna(train_set[\"Age\"].median(),inplace=True)\n", "train_set[\"Embarked\"].fillna(\"S\",inplace=True)\n", "train_set.drop([\"Cabin\"],axis=1,inplace=True)\n", "test_set[\"Age\"].fillna(train_set[\"Age\"].median(),inplace=True)\n", "test_set[\"Embarked\"].fillna(\"S\",inplace=True)\n", "test_set[\"Fare\"].fillna(train_set[\"Fare\"].median(),inplace=True)\n", "test_set.drop([\"Cabin\"],axis=1,inplace=True)\n", "\n", "# CHECKING FEATS AGAIN AFTER PROCESSING\n", "# print(train_set.isnull().sum())\n", "# print(test_set.isnull().sum())\n", "\n", "\n", "# NUMERIC FEATS AND CATEGORICAL FEATS\n", "train_numfeats = train_set.select_dtypes(exclude=[\"object\"]).columns\n", "test_numfeats = test_set.select_dtypes(exclude=[\"object\"]).columns\n", "train_catfeats = train_set.select_dtypes(include=[\"object\"]).columns\n", "test_catfeats = test_set.select_dtypes(include=[\"object\"]).columns\n", "print(train_numfeats)\n", "print(train_catfeats)\n", "\n", "# DEALING WITH NAMES\n", "replacement = {\n", "    'Don': 0,\n", "    'Rev': 0,\n", "    'Jonkheer': 0,\n", "    'Capt': 0,\n", "    'Mr': 1,\n", "    'Dr': 2,\n", "    'Col': 3,\n", "    'Major': 3,\n", "    'Master': 4,\n", "    'Miss': 5,\n", "    'Mrs': 6,\n", "    'Mme': 7,\n", "    'Ms': 7,\n", "    'Mlle': 7,\n", "    'Sir': 7,\n", "    'Lady': 7,\n", "    'the Countess': 7\n", "}\n", "\n", "train_set[\"Name\"] = train_set[\"Name\"].map(lambda name:name.split(',')[1].split('.')[0].strip())\n", "# print(train_set[\"Name\"].unique())\n", "train_set[\"Name\"] = train_set[\"Name\"].apply(lambda x: replacement.get(x))\n", "# print(train_set[\"Name\"].head())\n", "test_set[\"Name\"] = test_set[\"Name\"].map(lambda name:name.split(',')[1].split('.')[0].strip())\n", "# print(test_set[\"Name\"].unique())\n", "test_set[\"Name\"] = test_set[\"Name\"].apply(lambda x: replacement.get(x))\n", "# print(test_set[\"Name\"].head())\n", "\n", "# DEALING WITH SEX\n", "replacement1 = {\n", "    \"male\":1,\n", "    \"female\":0\n", "}\n", "\n", "train_set[\"Sex\"] = train_set[\"Sex\"].apply(lambda x: replacement1.get(x))\n", "test_set[\"Sex\"] = test_set[\"Sex\"].apply(lambda x: replacement1.get(x))\n", "# print(train_set[\"Sex\"].head())\n", "# print(test_set[\"Sex\"].head())\n", "\n", "# DEALING WITH EMBARKED\n", "# print(train_set[\"Embarked\"].unique())\n", "replacement2 = {\n", "    \"S\":0,\n", "    \"C\":1,\n", "    \"Q\":2\n", "}\n", "\n", "train_set[\"Embarked\"] = train_set[\"Embarked\"].apply(lambda x: replacement2.get(x))\n", "test_set[\"Embarked\"] = test_set[\"Embarked\"].apply(lambda x: replacement2.get(x))\n", "# print(train_set[\"Embarked\"].head())\n", "# print(test_set[\"Embarked\"].head())\n", "\n", "# THERE IS NAN VALUE IN TEST SET\n", "test_set[\"Name\"].fillna(test_set[\"Name\"].mode()[0],inplace=True)\n", "\n", "# SCALING ATTRIBUTES\n", "from sklearn.preprocessing import StandardScaler\n", "train_set[\"Pclass\"] = StandardScaler().fit_transform(train_set[\"Pclass\"].values.reshape(-1,1))\n", "test_set[\"Pclass\"] = StandardScaler().fit_transform(test_set[\"Pclass\"].values.reshape(-1,1))\n", "train_set[\"Age\"] = StandardScaler().fit_transform(train_set[\"Age\"].values.reshape(-1,1))\n", "test_set[\"Age\"] = StandardScaler().fit_transform(test_set[\"Age\"].values.reshape(-1,1))\n", "train_set[\"Fare\"] = StandardScaler().fit_transform(train_set[\"Fare\"].values.reshape(-1,1))\n", "test_set[\"Fare\"] = StandardScaler().fit_transform(test_set[\"Fare\"].values.reshape(-1,1))\n", "train_set[\"Familysize\"] = StandardScaler().fit_transform(train_set[\"Familysize\"].values.reshape(-1,1))\n", "test_set[\"Familysize\"] = StandardScaler().fit_transform(test_set[\"Familysize\"].values.reshape(-1,1))\n", "train_set[\"Name\"] = StandardScaler().fit_transform(train_set[\"Name\"].values.reshape(-1,1))\n", "test_set[\"Name\"] = StandardScaler().fit_transform(test_set[\"Name\"].values.reshape(-1,1))\n", "train_set[\"Sex\"] = StandardScaler().fit_transform(train_set[\"Sex\"].values.reshape(-1,1))\n", "test_set[\"Sex\"] = StandardScaler().fit_transform(test_set[\"Sex\"].values.reshape(-1,1))\n", "train_set[\"Embarked\"] = StandardScaler().fit_transform(train_set[\"Embarked\"].values.reshape(-1,1))\n", "test_set[\"Embarked\"] = StandardScaler().fit_transform(test_set[\"Embarked\"].values.reshape(-1,1))\n", "\n", "# print(train_set.isnull().sum())\n", "# print(test_set.isnull().sum())\n", "\n", "\n", "# MODELLING\n", "from xgboost import XGBClassifier\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.ensemble import RandomForestClassifier\n", "rf = RandomForestClassifier()\n", "param_grid = {\"n_estimators\":[250],\"max_depth\":[8]}\n", "\n", "clf = GridSearchCV(rf,param_grid=param_grid,cv=10,n_jobs=-1)\n", "clf.fit(train_set,target)\n", "print(clf.best_score_)\n", "pred = clf.predict(test_set)\n", "\n", "\n", "# SUBMISSION\n", "submission = pd.DataFrame({\"PassengerId\":test_pas_id,\"Survived\":pred})\n", "submission.to_csv(\"/home/vic/Desktop/Kaggle/Titanic/final2.csv\",index=False)"], "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"pygments_lexer": "ipython3", "nbconvert_exporter": "python", "name": "python", "version": "3.6.4", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python"}}, "nbformat_minor": 1, "nbformat": 4}