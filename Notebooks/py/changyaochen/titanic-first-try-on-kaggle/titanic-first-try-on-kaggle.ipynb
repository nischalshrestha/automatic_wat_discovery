{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d260d52c-ff39-3bb0-8de6-4598ca370e2c"
      },
      "source": [
        "## Data inspection\n",
        "Let's get started! First of all, let me take a look at the structure of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b6441a67-321b-3674-6bae-504cc8a12d80"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import bokeh.plotting as bkp  # for nice plotting\n",
        "import bokeh.charts as bkc  # for nice plotting\n",
        "import bokeh.models as bkm  # for nice plotting\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "df = pd.read_csv('../input/train.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "173be35e-8d56-b5d3-cd57-5da44cd7d7a4"
      },
      "source": [
        "- *Survived*\n",
        "\n",
        "Keep in mind that our target (predicted value) is whether a passenger will survive. Therefore, the first question is that, how many people have survived?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "32e38821-69fc-9dfc-7b93-8e216a4768cd"
      },
      "outputs": [],
      "source": [
        "df['Survived'].value_counts(dropna = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "223a6c93-beb2-085f-5ede-e2429feb86d8"
      },
      "source": [
        "This is a simple enough math so that I don't the computer to do it for me: out of the 891 total passengers shown in this dataset, 342 survived, and the survival rate is 0.384.  It also reveals that there is no missing entry in this column.  \n",
        "\n",
        "Note that, there are multiple features for each passenger, and part (or all) of them can be used to build the model. Therefore, we might want to take a closer look at each of them. \n",
        "\n",
        "- *Pclass*\n",
        "\n",
        "First, let's take a look how many passengers survived according to Pclass:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "45d7e717-9c9f-aae5-48ac-3b11f88d6d0a"
      },
      "outputs": [],
      "source": [
        "# Pclass \n",
        "survived_pclass = df.groupby('Pclass')['Survived'].value_counts().unstack()\n",
        "survived_pclass['Rate'] = survived_pclass[1]/(survived_pclass[1] + survived_pclass[0])\n",
        "survived_pclass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "796b0d39-8478-abf0-d102-ec6e879ce2e4"
      },
      "source": [
        "How does it look graphically?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6bd0bd63-2bf7-2e44-d316-8777290591e0"
      },
      "outputs": [],
      "source": [
        "bkp.output_notebook()\n",
        "bar1 = bkc.Bar(df, values = 'Survived', label = 'Pclass', agg = 'count',\n",
        "            tools='pan,box_zoom,reset,resize,save,hover', \n",
        "               stack=bkc.attributes.cat(columns='Survived', sort=False), \n",
        "            legend='top_left', plot_width=600, plot_height=300)\n",
        "hover = bar1.select(dict(type = bkm.HoverTool))\n",
        "hover.tooltips = dict([(\"Num\", \"@height{int}\")])\n",
        "bar1.yaxis.axis_label = 'Number of passengers'\n",
        "bkp.show(bar1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6b21ae88-283d-a0d5-c3a1-00a8edf1d2f8"
      },
      "source": [
        "Apparently, passengers from higher classes are more likely to survive, both in terms of number and percentage. Furthermore, the survival rates for Pclass 1 and 3 are all quite different from 0.5, hence, 'quite pure'. In another word, during prediction, if I see a passenger is from Pclass 1(3), I would likely to bet he/she will (not) survive. We should take this into account into our future models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8356f270-5cfe-4474-1d95-b3eb591542ce"
      },
      "source": [
        "- *Name*\n",
        "\n",
        "The next column in the data is 'Name'. What information that we can possibly get from them? Humm.. how about the titles? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ade9d820-f642-5534-462c-2a5137f9aadb"
      },
      "outputs": [],
      "source": [
        "# Name\n",
        "import re\n",
        "title = df['Name'].map(lambda x: re.split('[,.]', x)[1].strip())\n",
        "df['Title'] = title\n",
        "survived_title = df['Survived'].groupby(df['Title']).value_counts().unstack()\n",
        "survived_title.fillna(0, inplace=True)\n",
        "survived_title['Rate'] = survived_title[1]/survived_title.sum(axis=1)\n",
        "survived_title.sort_values(by='Rate', ascending=False, inplace=True)\n",
        "survived_title"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1d1f051-0d48-172c-4e64-bef868b36a58"
      },
      "source": [
        "- *Gender*\n",
        "\n",
        "Next let's take a look at the survivors' age distribution, grouped by gender."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8ad7d497-482f-d346-94ca-fd4e9ae992f9"
      },
      "outputs": [],
      "source": [
        "# gender (or sex)\n",
        "survived_sex = df.groupby('Sex')['Survived'].value_counts().unstack()\n",
        "survived_sex['Rate'] = survived_sex[1]/(survived_sex.sum(axis=1))\n",
        "survived_sex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3e53c7a8-936f-330f-100e-665982053f81"
      },
      "source": [
        "Apparently, ladies are much more likely to survive, than the gentlemen. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d740b158-fa04-0c37-d718-d3bb3654d917"
      },
      "source": [
        "- *Age*\n",
        "\n",
        "Next up, let's take a look at how the age will affect one's chance to survive.. Note that there are many missing values in Age entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6a2dfdaa-3be4-6b32-0408-9284d5bb5d64"
      },
      "outputs": [],
      "source": [
        "# age histogram of survivors\n",
        "survived_age = df[['Survived', 'Age', 'Sex']].copy()\n",
        "survived_age['Survived'] = survived_age['Survived'].astype(int)\n",
        "print('Total number of NAs in Age: {}'.format(survived_age['Age'].isnull().sum()))\n",
        "survived_age.dropna(inplace=True)\n",
        "hist1 = bkc.Histogram(survived_age, values = 'Age', color = 'Sex', bins = 50,\n",
        "                     plot_width=600, plot_height=300)\n",
        "bkp.show(hist1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6e6c5b24-b7da-650f-49e6-9b2c52b056ac"
      },
      "source": [
        "- *SibSp and Parch* \n",
        "\n",
        "How the family size will affect the survival?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fdf7efa0-cf1c-0e14-30ce-4e8b55bda39d"
      },
      "outputs": [],
      "source": [
        "# SibSp and Parch\n",
        "survived_sibsp = df['Survived'].groupby(df['SibSp']).value_counts().unstack()\n",
        "survived_sibsp.fillna(0, inplace=True)\n",
        "survived_sibsp['Rate'] = survived_sibsp[1]/survived_sibsp.sum(axis=1)\n",
        "survived_sibsp.sort_values(by='Rate', ascending=False, inplace=True)\n",
        "print(survived_sibsp)\n",
        "print('Total number of NAs in SibSp: {}'.format(df['SibSp'].isnull().sum()))\n",
        "\n",
        "# Parch\n",
        "survived_parch = df['Survived'].groupby(df['Parch']).value_counts().unstack()\n",
        "survived_parch.fillna(0, inplace=True)\n",
        "survived_parch['Rate'] = survived_parch[1]/survived_parch.sum(axis=1)\n",
        "survived_parch.sort_values(by='Rate', ascending=False, inplace=True)\n",
        "print('\\n', survived_parch)\n",
        "print('Total number of NAs in Parch: {}'.format(df['Parch'].isnull().sum()))\n",
        "\n",
        "# family size\n",
        "df['Family Size'] = df['SibSp'] + df['Parch']\n",
        "survived_family = df['Survived'].groupby(df['Family Size']).value_counts().unstack()\n",
        "survived_family.fillna(0, inplace=True)\n",
        "survived_family['Rate'] = survived_family[1]/survived_family.sum(axis=1)\n",
        "survived_family.sort_values(by='Rate', ascending=False, inplace=True)\n",
        "print('\\n', survived_family)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2778c271-aae9-1b52-dd9d-5c2d983e856d"
      },
      "source": [
        "- *Fare*\n",
        "\n",
        "We also notice that there is a large range in ticket fare, thus we are interested to see how much you can pay to survive... for the illustrative purpose, I will through the age into the mix..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "880cbc9b-62ab-2032-27c4-6960404eb50b"
      },
      "outputs": [],
      "source": [
        "# Fare\n",
        "p = bkc.Scatter(df, x = 'Fare', y = 'Age', color = 'Survived',\n",
        "                plot_width = 700, plot_height = 500, legend = 'top_right')\n",
        "bkp.show(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "30c1049f-1aa5-cb39-a142-1ab9f0d43980"
      },
      "source": [
        "- *Cabin*\n",
        "\n",
        "How about cabin? Naturally, one would this feature would have a great impact on the final survival rate. However, there are many missing values in the entries. Furthermore, the structure of the cabin number is in the form of letter + number. In order to get a better sense, I will need to strip these two values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fb687155-679f-3cd9-ee03-c82cd03ebfca"
      },
      "outputs": [],
      "source": [
        "# cabin\n",
        "print('Total number of non-NAs in Cabin: {}'.format(df['Cabin'].notnull().sum()))\n",
        "print('Total number of NAs in Cabin: {}'.format(df['Cabin'].isnull().sum()))\n",
        "cabin = df[['Survived', 'Cabin']].copy()\n",
        "cabin.dropna(inplace=True)\n",
        "def find_num(x):\n",
        "    result = re.search('([0-9]+)', x)\n",
        "    if result:\n",
        "        return result.group()\n",
        "    else:\n",
        "        return '0'\n",
        "cabin['Header'] = cabin['Cabin'].map(lambda x: re.findall('[A-Z]', x)[0])\n",
        "cabin['Number'] = cabin['Cabin'].map(find_num)\n",
        "survived_cabin_h = cabin['Survived'].groupby(cabin['Header']).value_counts().unstack()\n",
        "survived_cabin_h.fillna(0, inplace=True)\n",
        "survived_cabin_h['Rate'] = survived_cabin_h[1]/survived_cabin_h.sum(axis=1)\n",
        "survived_cabin_h.sort_values(by='Rate', inplace=True, ascending=False)\n",
        "print(survived_cabin_h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "aabf808f-2f74-347a-4902-2a7b7cca1e10"
      },
      "source": [
        "- *Embarked*\n",
        "\n",
        "How about the feature Embarked? Maybe the passengers are allocated to different parts of the ship, which affect their final survival chance?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1ac1c52b-1bbd-78a5-331c-39c61573aef8"
      },
      "outputs": [],
      "source": [
        "# Embarked\n",
        "survived_embarked = df['Survived'].groupby(df['Embarked']).value_counts().unstack()\n",
        "survived_embarked.fillna(0, inplace=True)\n",
        "survived_embarked['Rate'] = survived_embarked[1]/survived_embarked.sum(axis=1)\n",
        "survived_embarked.sort_values(by='Rate', ascending=False, inplace=True)\n",
        "print(survived_embarked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6cd276b0-5a5d-1ca1-1b3d-d6b18f1e3222"
      },
      "source": [
        "## Data wrangling\n",
        "We note that there are many missing values in the features Age (177), Cabin (687), and Embarked (2). We need to take care of them before we can build a model. Additionally, since we are going to use sklearn, we need to convert the categorical features to numbers. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7841cb00-14b0-dcba-20fc-57645591ce23"
      },
      "outputs": [],
      "source": [
        "# how many na values for each column?\n",
        "print(df.isnull().sum())\n",
        "df_clean = df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "03b25dae-181a-c635-b93b-e16e0de0f078"
      },
      "source": [
        "- *Age*\n",
        "\n",
        "There are 177 missing entries in Age, too many that I can't afford to throw those rows away. Therefore, the question becomes, how to fill these missing values intelligently?\n",
        "\n",
        "One method will be to fill all the 177 missing values with same number, for example, 0, or the mean age of the rest of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9198f5e2-f61f-0a3f-3c20-2d3309a052ff"
      },
      "outputs": [],
      "source": [
        "age_mean = df[df['Age'].notnull()]['Age'].mean()\n",
        "df_clean.loc[df['Age'].isnull(), 'Age'] = age_mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4c7fbf70-d75e-0ae2-fa04-9f3f30dfa58c"
      },
      "source": [
        "Can we do it more cleverly? For example, if we look at the row with a missing age, we could look at how many siblings or parents / children this particular passenger has. Then if (a big if) we can find the ages of his/her family, then we might be a clever way to guess the age of that passenger. However, this sounds like a solution would take many lines to present, hence I will stick with the average age. \n",
        "\n",
        "With the further modeling in mind, I can further bin the ages into just few ranges:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "086d9bb8-beb6-818d-ce67-6b7c7d5d12d6"
      },
      "outputs": [],
      "source": [
        "bins = [0, 20, 40, 60, 80, 100]\n",
        "df_clean['Age range'] = pd.cut(df_clean['Age'], bins, labels=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e2a8477b-169d-9eaf-9113-6ca2c93d7b08"
      },
      "source": [
        "- *Cabin*\n",
        "\n",
        "The next feature with many missing values is Cabin. From the entries that with Cabin values, it seems that the \"header\" of the Cabin can be a good indicator of the survival chance. For example, if the Cabin value starts with B, C, D, E, F, I would guess a higher chance of survival. How is the survival results looks for the passengers without a Cabin record?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0088f1e7-d41b-e57f-3206-562d03526a9d"
      },
      "outputs": [],
      "source": [
        "df[df['Cabin'].isnull()]['Survived'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d564b957-7022-1930-4354-8085cedfa853"
      },
      "source": [
        "What I can do, is to fill all the missing Cabin values with a distinct header, say, 'X'. Then I will carry this information for later modeling step. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "77221419-3c93-986f-352e-3137b689cd4a"
      },
      "outputs": [],
      "source": [
        "df_clean.loc[df_clean['Cabin'].isnull(), 'Cabin'] = 'X000'\n",
        "df_clean['Cabin_h'] = df_clean['Cabin'].map(lambda x: x[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9a3f4e5b-8782-bdc2-e103-15913e8ff509"
      },
      "source": [
        "- *Embarked*\n",
        "\n",
        "There are only 2 rows with missing Embarked values, therefore, I will fill them with the most frequent value, S. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "641d090f-0307-f050-1ccd-874a41c85250"
      },
      "outputs": [],
      "source": [
        "df_clean.loc[df['Embarked'].isnull(), 'Embarked'] = 'S'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1b8aa31d-5440-6389-13fc-45bafffa5087"
      },
      "source": [
        "Let's do a final check to make sure there is no missing value anywhere. Looking good!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "056185e1-32c8-3261-dc64-2a4d6bbde043"
      },
      "outputs": [],
      "source": [
        "df_clean.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "09a6c206-e256-4718-f25e-7e3522b6d4df"
      },
      "source": [
        "Before we proceed, let's take a close look at those categorical features, and ask the question: are there too many different categories? If so, shall we group some of them?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cadc4b72-accf-3146-cf1a-38e22cae284b"
      },
      "outputs": [],
      "source": [
        "df_clean.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0787a2d6-a8df-bae5-f27e-ce2a96593dd2"
      },
      "outputs": [],
      "source": [
        "df_clean['Cabin_h'].value_counts()\n",
        "df_clean['Title'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6d337691-1518-49f4-438a-562b0b411353"
      },
      "source": [
        "It seems, there are only three dominant categories in the 'Title' feature (a derived feature), therefore, I will group all but the three title."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "34511cbf-4202-e695-be04-ef5ae8ddf879"
      },
      "outputs": [],
      "source": [
        "# group titles\n",
        "def group_title(x):\n",
        "    if x not in ['Mr', 'Miss', 'Mrs']:\n",
        "        return 'Other'\n",
        "    else:\n",
        "        return x\n",
        "df_clean['Title'] = df_clean['Title'].map(group_title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bcf93808-9918-40b7-4f2a-125ac7600abe"
      },
      "source": [
        "## Model building\n",
        "The goal of the model is to predict whether a passenger will survive. Let's first establish some baseline for the prediction. \n",
        "The first crudest, and meaningless one: everyone will survive (or die), what's the accuracy?\n",
        "Well, the ratio between survived passengers and total passengers is 342/(342+549) = 0.383. Therefore if the model says everyone dies, the accuracy will be 1 - 0.383 = **0.617**. This is **baseline 1**.\n",
        "\n",
        "We also know that, the survival percentage of female passengers is higher than that of male passengers. So what if guess: all female will survive (or equivalently, all male will die)? Let's take a look at what's the ratio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a1c0e0c8-d4b7-6749-ab02-8e879ff7c608"
      },
      "outputs": [],
      "source": [
        "df['Survived'].groupby([df['Sex'], df['Survived']]).count().unstack()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e797fd14-c8d2-199f-dc2f-7aff3eb5dfb5"
      },
      "source": [
        "The survival rate for female is 233/(233+81) = 0.742, and the death rate for male is 468/(468+109) = 0.811. Let's say, in the prediction, the chance to encounter a male or a female is 50-50, then the accuracy for this model is 0.742*0.5 + 0.811*0.5 = **0.777**. This is **baseline 2**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "01c88ac6-b592-b97a-e4f7-7c24b77fa4ec"
      },
      "source": [
        "The accuracy of any realistic model, should at least beat these baselines. Let's start!\n",
        "Let me first partition the original data into training set and test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a3a3cd33-66f9-2b58-4e56-85907e0cc544"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# make a copy, for no reason...\n",
        "df_clean_run = df_clean.copy()\n",
        "# do the OneHot encoding\n",
        "# the added derived features are 'Age range', 'Family Size', 'Cabin_h', 'Title'\n",
        "df_clean_run = pd.get_dummies(df_clean_run, columns=['Sex', 'Cabin_h', 'Pclass', 'Embarked', 'Title'])\n",
        "# initilize the classifier\n",
        "clf = RandomForestClassifier(n_estimators=1000, max_depth=5)\n",
        "# split the training set, for x-validation\n",
        "train, test = train_test_split(df_clean_run, test_size = 0.2)\n",
        "features = train.columns.tolist()\n",
        "remove_list = ['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin', \n",
        "               'Age range', 'SibSp', 'Parch']\n",
        "for item in remove_list:\n",
        "    features.remove(item)\n",
        "print(features, '\\n')\n",
        "clf.fit(train[features], train['Survived'])\n",
        "importances = [(f, i) for f, i in zip(features, clf.feature_importances_)]\n",
        "importances.sort(key = lambda x: x[1], reverse=True)\n",
        "#for f, i in importances:\n",
        "#    print('Importance: {:>10}:{:4.3f}'.format(f, i))\n",
        "print('\\nTraining Accurancy: {:<30}'.format(clf.score(train[features], train['Survived'])))\n",
        "print('Test Accurancy: {:<30}'.format(clf.score(test[features], test['Survived'])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c5d3e7d9-7718-0fa2-c510-16321546c0c7"
      },
      "source": [
        "## Medel prediction\n",
        "\n",
        "Now I am ready to take on the test dataset. There are three preprocessing steps I need perform on the testing dataset (order matters):\n",
        "\n",
        "1. Fill the missing values\n",
        "2. Add the derived features\n",
        "3. OneHot encoding\n",
        "\n",
        "After the OneHot encoding, I also need to check whether there is any difference between the test dataset features, and the training dataset features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f914bfc1-7a9a-fe10-9617-b030a7fc18e8"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv('../input/test.csv')\n",
        "test_df_clean = test_df.copy()\n",
        "# preprocessing\n",
        "# fill missing values\n",
        "test_df_clean.isnull().sum()\n",
        "age_mean = test_df[test_df['Age'].notnull()]['Age'].mean()\n",
        "test_df_clean.loc[test_df['Age'].isnull(), 'Age'] = age_mean\n",
        "test_df_clean.loc[test_df_clean['Cabin'].isnull(), 'Cabin'] = 'X000'\n",
        "test_df_clean['Cabin_h'] = test_df_clean['Cabin'].map(lambda x: x[0])\n",
        "test_df_clean.loc[test_df_clean['Fare'].isnull(), 'Fare'] = test_df[test_df['Fare'].notnull()]['Fare'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e8cd565b-eae3-8ede-83d0-a3e19622f78d"
      },
      "outputs": [],
      "source": [
        "# 2. Add derived features\n",
        "# the added derived features are 'Age range', 'Family Size', 'Cabin_h', 'Title'\n",
        "test_df_clean['Age range'] = pd.cut(test_df_clean['Age'], bins, labels=False)\n",
        "test_df_clean['Family Size'] = test_df_clean['SibSp'] + test_df_clean['Parch']\n",
        "test_df_clean['Cabin_h'] = test_df_clean['Cabin'].map(lambda x: x[0])\n",
        "test_df_clean['Title'] = test_df_clean['Name'].map(lambda x: re.split('[,.]', x)[1].strip())\n",
        "test_df_clean['Title'] = test_df_clean['Title'].map(group_title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "525160e9-2565-42e9-a2d7-08774a040ff7"
      },
      "outputs": [],
      "source": [
        "# OneHot encoding\n",
        "test_df_clean = pd.get_dummies(test_df_clean, columns=['Sex', 'Cabin_h', 'Pclass', 'Embarked', 'Title'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f43d5486-4cea-0adb-a371-c87c95af6295"
      },
      "outputs": [],
      "source": [
        "# check for possible missing features\n",
        "for fe in features:\n",
        "    if fe not in test_df_clean.columns.tolist():\n",
        "        test_df_clean[fe] = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c60dea07-3498-651a-ed1a-bb70e4259232"
      },
      "outputs": [],
      "source": [
        "# predict!\n",
        "output = clf.predict(test_df_clean[features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1cf51d48-d76b-ad65-ebfa-c03c763b97a3"
      },
      "outputs": [],
      "source": [
        "df_submit = test_df_clean[['PassengerId']].copy()\n",
        "df_submit['Survived'] = pd.Series(output)\n",
        "df_submit.to_csv('output.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d17bb4d5-e744-b631-d869-230bf8c2d840"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}