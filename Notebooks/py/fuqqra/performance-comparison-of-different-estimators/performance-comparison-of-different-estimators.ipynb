{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "345b3fc7-fb92-3715-8164-9e41ff0b2658"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import style\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn import cross_validation\n",
        "\n",
        "style.use('fivethirtyeight')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "21d64068-6c63-ed99-706c-5423a5dd45ab"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('../input/train.csv')\n",
        "test = pd.read_csv('../input/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e85f7399-66fa-619a-4aa1-dea744af05d2"
      },
      "outputs": [],
      "source": [
        "#Drop the un-necasary columns:\n",
        "train.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], inplace=True, axis=1)\n",
        "test.drop(['Name', 'Ticket', 'Cabin'], inplace=True, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2fda1072-75cb-4037-a67b-d2755bdbbc0f"
      },
      "outputs": [],
      "source": [
        "# Check the count of values to see the missing values from both datasets:\n",
        "print (train.info())\n",
        "print ('=================================----------------')\n",
        "print (test.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "27b66b9f-08ec-93b4-8129-df578ce8ca6b"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7fed8e4f-19b3-79fd-9032-b9916f729eaf"
      },
      "source": [
        "### 1- Embarked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "83168b4f-fd16-f2b0-2e6c-7b7a21d07104"
      },
      "outputs": [],
      "source": [
        "#Checking the embarkment values count to fill the nan.\n",
        "train.Embarked.value_counts(), test.Embarked.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cd3f22a0-d006-a65a-2278-0c2445f51d4c"
      },
      "outputs": [],
      "source": [
        "#fill the missing values with the most redudant one.\n",
        "train.Embarked.fillna('S', inplace=True)\n",
        "test.Embarked.fillna('S', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "58d84b0e-68a2-f5a0-e8ba-75c769dbc40d"
      },
      "outputs": [],
      "source": [
        "#Relation between embarkment and Survival:\n",
        "sns.countplot('Embarked', hue='Survived', data=train)\n",
        "sns.factorplot('Embarked', 'Survived', data=train, size=3, aspect=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c1a2a19c-07ae-5b9a-8813-35dbafd4d973"
      },
      "outputs": [],
      "source": [
        "#create dummy variable for Embarked feature for our model:\n",
        "train = pd.concat([train, pd.get_dummies(train.Embarked, prefix='embark')], axis=1)\n",
        "train.drop('Embarked', inplace=True, axis=1)\n",
        "test = pd.concat([test, pd.get_dummies(test.Embarked, prefix='embark')], axis=1)\n",
        "test.drop('Embarked', inplace=True, axis=1)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1a1916ae-700a-bd8b-4c36-99197ba33d41"
      },
      "source": [
        "### 2- Fare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "578aac24-db31-1261-769d-6dcfbe2603d3"
      },
      "outputs": [],
      "source": [
        "#Fare\n",
        "train.Fare.mean(), train.Fare.median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e6aba6b1-40a0-5e84-25e0-2fb24b190ef2"
      },
      "outputs": [],
      "source": [
        "#lets fill it with mean value\n",
        "train.Fare.fillna(train.Fare.mean(), inplace=True)\n",
        "test.Fare.fillna(test.Fare.mean(), inplace=True)\n",
        "\n",
        "train.Fare.hist()\n",
        "print ('Spread of Fare:')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0eebdb2d-deef-cb48-1d15-9da95f6d6bb9"
      },
      "source": [
        "### 3- Age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6f050b9c-9b92-b96a-3962-ca2f47fe4852"
      },
      "outputs": [],
      "source": [
        "train.Age.mean(), train.Age.median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "070474e6-e469-8aeb-f981-e5d8b9a272ec"
      },
      "outputs": [],
      "source": [
        "train_age_mean = train.Age.mean()\n",
        "train_age_std = train.Age.std()\n",
        "train_age_count = train.Age.isnull().sum()\n",
        "\n",
        "test_age_mean = test.Age.mean()\n",
        "test_age_std = test.Age.std()\n",
        "test_age_count = test.Age.isnull().sum()\n",
        "\n",
        "rand_1 = np.random.randint(train_age_mean - train_age_std, train_age_mean + train_age_std, size=train_age_count)\n",
        "rand_2 = np.random.randint(test_age_mean - test_age_std, test_age_mean + test_age_std, size=test_age_count)\n",
        "\n",
        "train.Age[np.isnan(train.Age)] = rand_1\n",
        "test.Age[np.isnan(test.Age)] = rand_2\n",
        "\n",
        "train['Age'] = train.Age.astype(int)\n",
        "test['Age'] = test.Age.astype(int)\n",
        "\n",
        "#fill in the missing age values using the median value.\n",
        "train.Age.hist()\n",
        "print ('Age spread: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e3a6a589-0da0-6af5-6ffa-dd046e27e3c0"
      },
      "outputs": [],
      "source": [
        "# Plotting to undertanding the relation ship between age and survival rate:\n",
        "\n",
        "face_age = sns.FacetGrid(train, hue='Survived', size=3,aspect=3)\n",
        "face_age.map(sns.kdeplot, 'Age', shade=True)\n",
        "face_age.set(xlim=(0, train.Age.max()))\n",
        "face_age.add_legend()\n",
        "\n",
        "plt.subplots(1,1, figsize=(10,4))\n",
        "average_age = train[['Age', 'Survived']].groupby(['Age'], as_index=False).mean()\n",
        "sns.barplot('Age', 'Survived', data=average_age)\n",
        "plt.xticks(rotation=90)\n",
        "print ('Age survival relation: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9af0dabb-2b68-3db4-0822-f7ccddb40b37"
      },
      "source": [
        "## 4- Family ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "32cb15bb-e926-5657-964d-7b2bcd3d8929"
      },
      "outputs": [],
      "source": [
        "# combing the parents children count and siblings count for each person to get the family size:\n",
        "train['Family'] = train.Parch + train.SibSp\n",
        "test['Family'] = test.Parch + test.SibSp\n",
        "\n",
        "#making the values to boolean, i.e. if no family member family is 0 else 1.\n",
        "train.Family.loc[train.Family > 0] = 1\n",
        "train.Family.loc[train.Family == 0] = 0\n",
        "\n",
        "test.Family.loc[test.Family > 0] = 1\n",
        "test.Family.loc[test.Family == 0] = 0\n",
        "\n",
        "#Drop the original features since they are not required any more:\n",
        "train.drop(['Parch', 'SibSp'], inplace=True, axis=1)\n",
        "test.drop(['Parch', 'SibSp'], inplace=True, axis=1)\n",
        "\n",
        "#relation between family and survival rate:\n",
        "sns.countplot('Family', hue='Survived', data=train)\n",
        "\n",
        "print ('Family survival rate: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c8d937d1-8fd1-5bb4-cc92-fcfe9c4386c7"
      },
      "source": [
        "## 5- Gender ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "794e9dff-27ad-31a4-47c1-36428f78fa09"
      },
      "outputs": [],
      "source": [
        "#There is a chance that more children survived the disaster, therefore lets put three categories\n",
        "#i.e. male, female and childre with age less then 17\n",
        "\n",
        "def check_child(age_gender):\n",
        "    age, sex = age_gender\n",
        "    return 'child' if age < 17 else sex\n",
        "\n",
        "train['Person'] = train[['Age', 'Sex']].apply(check_child, axis=1)\n",
        "test['Person'] = test[['Age', 'Sex']].apply(check_child, axis=1)\n",
        "\n",
        "#creating dummies the new person feature for our model\n",
        "train = pd.concat([train, pd.get_dummies(train.Person, prefix='person')], axis=1)\n",
        "test = pd.concat([test, pd.get_dummies(test.Person, prefix='person')], axis=1)\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "61a81de5-8851-8b50-8a17-8b3657a6a8c7"
      },
      "outputs": [],
      "source": [
        "# Check the spread of each person and their survival rate:\n",
        "\n",
        "_, (ax1, ax2, ax3) = plt.subplots(3,1, figsize=(10,12))\n",
        "\n",
        "#spread\n",
        "sns.countplot('Person', data=train, ax=ax1)\n",
        "\n",
        "#survival\n",
        "sns.countplot('Person', hue='Survived', data=train, ax=ax2)\n",
        "\n",
        "#mean-survival\n",
        "person_survival = train[['Person', 'Survived']].groupby(['Person'], as_index=False).mean()\n",
        "sns.barplot('Person', 'Survived', data=person_survival, ax=ax3)\n",
        "\n",
        "#Drop the original features, they are no more needed.\n",
        "train.drop(['Sex', 'Person'], inplace=True, axis=1)\n",
        "test.drop(['Sex', 'Person'], inplace=True, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "93937673-3b2d-12ba-3115-46b908d3ffdc"
      },
      "source": [
        "### 6- Pclass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a6036ad8-c670-55be-095e-31554867811b"
      },
      "outputs": [],
      "source": [
        "# There might be strong realtion between survival rate and the traveling class of a person.\n",
        "# plot\n",
        "sns.countplot('Pclass', hue='Survived', data=train)\n",
        "\n",
        "#create dummy variable for out model\n",
        "train = pd.concat([train, pd.get_dummies(train.Pclass, prefix='pclass')], axis=1)\n",
        "test = pd.concat([test, pd.get_dummies(test.Pclass, prefix='pclass')], axis=1)\n",
        "\n",
        "#drop original feature:\n",
        "train.drop('Pclass', inplace=True, axis=1)\n",
        "test.drop('Pclass', inplace=True, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4dace2cc-a1f8-c5c7-f4f5-1864f8eafc7c"
      },
      "source": [
        "# Modal Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e15ead33-82f0-9547-83b6-f99c3cd53ea3"
      },
      "outputs": [],
      "source": [
        "#seperate the features and target:\n",
        "X = train.drop('Survived', axis=1)\n",
        "y = train.Survived\n",
        "#split the data to evalute the model:\n",
        "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, random_state=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "67d250db-71a7-8280-7fef-c7d2fc4b773d"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d52f559d-1ff3-4226-955a-897b52c87df1"
      },
      "outputs": [],
      "source": [
        "#Logit regression will simply classify the data set using l2 regularization:\n",
        "logreg = LogisticRegression(C=1, penalty='l2').fit(X_train, y_train)\n",
        "logreg.score(X_train, y_train), logreg.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eeebfa33-6517-0e36-2091-ed7cae89edd4"
      },
      "outputs": [],
      "source": [
        "#The coefficient found for each feature, this slightly tells \n",
        "#which feature tells more about survival and death:\n",
        "plt.plot(logreg.coef_.T, 'o')\n",
        "plt.xticks(range(X.shape[1]), X.columns, rotation=90)\n",
        "print ('Coefficients found using Logistic regression: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "24b9a78b-939e-602e-0904-315e7fb18d22"
      },
      "source": [
        "### Decision tree:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ba3441ea-ae3d-4569-0b55-0b3e145c95cb"
      },
      "outputs": [],
      "source": [
        "#Decision trees will give more accurate result since it calculates the score from eah feature multiple times\n",
        "#Pre-prunning has been applied here to avoid over fitting\n",
        "dtree = DecisionTreeClassifier(random_state=0, max_depth=3).fit(X_train, y_train)\n",
        "dtree.score(X_train, y_train), dtree.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6edf1f18-6441-ae3e-4baa-d5dec4edcc21"
      },
      "outputs": [],
      "source": [
        "#Check out the feature importance taken into account by Decision tree.\n",
        "\n",
        "plt.plot(dtree.feature_importances_, 'o')\n",
        "plt.xticks(range(X.shape[1]), X.columns, rotation=90)\n",
        "print ('Feature Importance in Decision trees: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8b47a0fd-e164-3d2e-1823-d92be46c464b"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "32399333-5c6c-a391-954c-bddd5104a407"
      },
      "outputs": [],
      "source": [
        "# Using ensemble techinque will cause imporvment in result. Here the max depth is again changed.\n",
        "\n",
        "rf = RandomForestClassifier(random_state=0, max_depth=4).fit(X_train, y_train)\n",
        "rf.score(X_train, y_train), rf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1353e563-6025-6de4-1d86-730ea6a46a73"
      },
      "outputs": [],
      "source": [
        "# Feature importance by random forest, here more features are taken into account.\n",
        "\n",
        "plt.plot(rf.feature_importances_, 'o')\n",
        "plt.xticks(range(X.shape[1]), X_train.columns, rotation=90)\n",
        "print ('Feature Importance in Random Forest: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2b1a8815-a462-c496-35d3-fc1c309cee83"
      },
      "source": [
        "### Gradient Booster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a9591422-2de3-e861-4aa4-d1746f2ae537"
      },
      "outputs": [],
      "source": [
        "#This is will give more accuracy since it learn from the mistakes of the previous trees.\n",
        "#Pre-prunning is used here to avoid over fitting and for better accuracy.\n",
        "\n",
        "gb = GradientBoostingClassifier(learning_rate=0.1, random_state=0, max_depth=1).fit(X_train, y_train)\n",
        "gb.score(X_train, y_train), gb.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3bbdf136-139f-3913-9b3f-4a58eab1a583"
      },
      "outputs": [],
      "source": [
        "#Feature importance for the gb\n",
        "\n",
        "plt.plot(gb.feature_importances_, 'o')\n",
        "plt.xticks(range(X.shape[1]), X_train.columns, rotation =90)\n",
        "print ('Feature Importance in Gradient Booster: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bfb4fd01-cc8e-a080-af20-63af6035c40d"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "312cbeff-9ef6-aad7-cb39-a2fb8f1b4e2b"
      },
      "outputs": [],
      "source": [
        "pred = test.drop('PassengerId', axis=1)\n",
        "prediction = gb.predict(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b5d90a06-7d83-eb72-83e9-543e3b963261"
      },
      "outputs": [],
      "source": [
        "output = pd.DataFrame({\n",
        "        'PassengerId': test.PassengerId,\n",
        "        'Survived': prediction\n",
        "    })\n",
        "output.to_csv('result.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}