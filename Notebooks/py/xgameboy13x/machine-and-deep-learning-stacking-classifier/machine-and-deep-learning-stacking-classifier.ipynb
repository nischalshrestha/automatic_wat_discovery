{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "aa0a3fa7-29a5-ea80-1ef7-f55df2d1639d"
      },
      "source": [
        "**Titanic: Using Machine and Deep Learning**\n",
        "\n",
        "This is my attempt to create good classifier to predict survival rate of passengers. I was inspired by Anisotropic and his notebook(link bellow). \n",
        "\n",
        "In this notebook I will use scikit-learn and Keras(tensorflow backend) libraries to do this task :) .\n",
        "\n",
        "[Introduction to ensembling/stacking in python][1]\n",
        "\n",
        "\n",
        "  [1]: https://www.kaggle.com/arthurtok/titanic/introduction-to-ensembling-stacking-in-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6d4734e4-3c54-49a3-96aa-22b8436bb704"
      },
      "source": [
        "First step as usual in Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fbd2b946-10fb-191e-2b56-996a2caf2ee6"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import ExtraTreesClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.cross_validation import KFold\n",
        "import xgboost as xgb\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, LSTM, \\\n",
        "                            BatchNormalization\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d5060b8e-06a0-f58e-6fba-4ce90de09a28"
      },
      "outputs": [],
      "source": [
        "# From here starts the Anisotropic code\n",
        "train = pd.read_csv('../input/train.csv')\n",
        "test = pd.read_csv('../input/test.csv')\n",
        "PassengerId = test['PassengerId']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3b184c72-e7cf-2bfc-3d3d-781a2825a654"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bafa7ff7-fa2a-4f2c-63a7-d92cfbf0cd8b"
      },
      "outputs": [],
      "source": [
        "full_data = [train, test]\n",
        "\n",
        "# Some features of my own that I have added in\n",
        "# Gives the length of the name\n",
        "train['Name_length'] = train['Name'].apply(len)\n",
        "test['Name_length'] = test['Name'].apply(len)\n",
        "# Feature that tells whether a passenger had a cabin on the Titanic\n",
        "train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
        "test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
        "\n",
        "# Feature engineering steps taken from Sina\n",
        "# Create new feature FamilySize as a combination of SibSp and Parch\n",
        "for dataset in full_data:\n",
        "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
        "# Create new feature IsAlone from FamilySize\n",
        "for dataset in full_data:\n",
        "    dataset['IsAlone'] = 0\n",
        "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
        "# Remove all NULLS in the Embarked column\n",
        "for dataset in full_data:\n",
        "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
        "# Remove all NULLS in the Fare column and create a new feature CategoricalFare\n",
        "for dataset in full_data:\n",
        "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
        "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
        "# Create a New feature CategoricalAge\n",
        "for dataset in full_data:\n",
        "    age_avg = dataset['Age'].mean()\n",
        "    age_std = dataset['Age'].std()\n",
        "    age_null_count = dataset['Age'].isnull().sum()\n",
        "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
        "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
        "    dataset['Age'] = dataset['Age'].astype(int)\n",
        "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
        "# Define function to extract titles from passenger names\n",
        "def get_title(name):\n",
        "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
        "    # If the title exists, extract and return it.\n",
        "    if title_search:\n",
        "        return title_search.group(1)\n",
        "    return \"\"\n",
        "# Create a new feature Title, containing the titles of passenger names\n",
        "for dataset in full_data:\n",
        "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
        "# Group all non-common titles into one single grouping \"Rare\"\n",
        "for dataset in full_data:\n",
        "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "\n",
        "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
        "\n",
        "for dataset in full_data:\n",
        "    # Mapping Sex\n",
        "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
        "    \n",
        "    # Mapping titles\n",
        "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
        "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
        "    dataset['Title'] = dataset['Title'].fillna(0)\n",
        "    \n",
        "    # Mapping Embarked\n",
        "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
        "    \n",
        "    # Mapping Fare\n",
        "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
        "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
        "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
        "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
        "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
        "    \n",
        "    # Mapping Age\n",
        "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
        "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
        "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
        "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
        "    dataset.loc[ dataset['Age'] > 64, 'Age'] ;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5275157b-aaa1-e5ed-2b8d-1de2d664e972"
      },
      "outputs": [],
      "source": [
        "# Feature selection\n",
        "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
        "train = train.drop(drop_elements, axis = 1)\n",
        "train = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
        "test  = test.drop(drop_elements, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f3d8ec1e-721f-90e8-16b5-76e09407f6ee"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4f3deb65-b9e0-125f-cc5b-d55dc60505c0"
      },
      "outputs": [],
      "source": [
        "# Some useful parameters which will come in handy later on\n",
        "ntrain = train.shape[0]\n",
        "ntest = test.shape[0]\n",
        "SEED = 42 # for reproducibility\n",
        "NFOLDS = 5 # set folds for out-of-fold prediction\n",
        "kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "583b920b-5cf6-52f5-5af4-4ab20c31da3b"
      },
      "outputs": [],
      "source": [
        "def get_oof(clf, x_train, y_train, x_test):\n",
        "    oof_train = np.zeros((ntrain,))\n",
        "    oof_test = np.zeros((ntest,))\n",
        "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
        "\n",
        "    for i, (train_index, test_index) in enumerate(kf):\n",
        "        x_tr = x_train[train_index]\n",
        "        y_tr = y_train[train_index]\n",
        "        x_te = x_train[test_index]\n",
        "\n",
        "        clf.fit(x_tr, y_tr)\n",
        "\n",
        "        oof_train[test_index] = clf.predict(x_te)\n",
        "        test = clf.predict(x_test)\n",
        "        test = test.flatten() #  -> HERE i need to flatten because NN return (nbsamples,1) shape predicts\n",
        "        oof_test_skf[i, :] = test\n",
        "\n",
        "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
        "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1c3212bb-1567-e3af-bcf0-cd9bc094cb94"
      },
      "outputs": [],
      "source": [
        "y_train = train['Survived'].ravel()\n",
        "train = train.drop(['Survived'], axis=1)\n",
        "x_train = train.values # Creates an array of the train data\n",
        "x_test = test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "740f049f-77c4-b744-9436-3b430287a28b"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cbe8ff0e-5094-db72-8750-6934a053e2a1"
      },
      "outputs": [],
      "source": [
        "\"\"\"This is main code for building neural network. I had to use Sequential layer. I will explain cell lower.\n",
        "   In this network I use activation function 'tanh' except last layer which is 'sigmoid'.\n",
        "   Feel free to experiment with this function.\"\"\"\n",
        "def create_NN(shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(16, init='he_uniform', input_shape=(shape,)))\n",
        "    model.add(Activation('tanh'))\n",
        "    #model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(8, init='he_normal'))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, init='normal', activation='sigmoid'))\n",
        "    \n",
        "    opt = Adam()    \n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "79d4c96c-9af4-0463-fa11-7834758637c8"
      },
      "outputs": [],
      "source": [
        "# Classifiers\n",
        "\"\"\"You can 'wrap' your neural network to use scikit-learn function on it. \n",
        "   To make this work you need to create NN with Sequential layer because it has method 'predict classes'.\n",
        "   Without this method your classifier net won't work.\"\"\"\n",
        "\n",
        "et_clf = ExtraTreesClassifier(n_jobs=-1, n_estimators=500, warm_start=True,\n",
        "                                max_depth=6, min_samples_leaf=2, random_state=SEED)\n",
        "\n",
        "dt_clf = DecisionTreeClassifier(max_depth=6, min_samples_leaf=2, max_features='sqrt',\n",
        "                                random_state=SEED)\n",
        "\n",
        "ada_clf = AdaBoostClassifier(n_estimators=500, learning_rate=0.5, random_state=SEED)\n",
        "\n",
        "\"\"\"If you want to check the accuracy or loss change verbose value to 1 o 2, or 3\"\"\"\n",
        "est_clf = KerasClassifier(build_fn=create_NN, nb_epoch=100, \n",
        "                          batch_size=5, verbose=0, shape=x_train.shape[1])\n",
        "\n",
        "svc_clf = SVC(C=0.5, random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "69e8f015-85bc-3796-67da-46caaa26d8dd"
      },
      "outputs": [],
      "source": [
        "et_oof_train, et_oof_test = get_oof(et_clf, x_train, y_train, x_test)\n",
        "dt_oof_train, dt_oof_test = get_oof(dt_clf, x_train, y_train, x_test)\n",
        "ada_oof_train, ada_oof_test = get_oof(ada_clf, x_train, y_train, x_test)\n",
        "est_oof_train, est_oof_test = get_oof(est_clf, x_train, y_train, x_test)\n",
        "svc_oof_train, svc_oof_test = get_oof(svc_clf,x_train, y_train, x_test)\n",
        "\n",
        "print(\"Finished!!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "29ea3025-c449-c739-23d6-60958c51c075"
      },
      "outputs": [],
      "source": [
        "est_pred = est_clf.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9a70c801-93fc-149d-b372-cc5cd3d0f891"
      },
      "outputs": [],
      "source": [
        "base_predictions_train = pd.DataFrame( {'DecisionTree': dt_oof_train.ravel(),\n",
        "     'ExtraTrees': et_oof_train.ravel(),\n",
        "     'AdaBoost': ada_oof_train.ravel(),\n",
        "     'Neural Network': est_oof_train.ravel(),\n",
        "     'SVC': svc_oof_train.ravel()\n",
        "    })\n",
        "base_predictions_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "91f61fe4-7b71-bd23-37e0-3fdb7fd7a6dc"
      },
      "outputs": [],
      "source": [
        "colormap = plt.cm.viridis\n",
        "plt.figure(figsize=(12,12))\n",
        "sns.heatmap(base_predictions_train.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, \n",
        "            cmap=colormap, linecolor='white', annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8e84f73e-5d14-3ebf-b95e-059781e0362d"
      },
      "outputs": [],
      "source": [
        "x_train = np.concatenate((et_oof_train, dt_oof_train, ada_oof_train, est_oof_train, svc_oof_train), axis=1)\n",
        "x_test = np.concatenate(( et_oof_test, dt_oof_test, ada_oof_test, est_oof_test, svc_oof_test), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3725e08f-4315-0925-e272-2ff9d163f0e6"
      },
      "outputs": [],
      "source": [
        "x_train.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ff139969-bc1b-22be-f51b-d1cfcdd4b376"
      },
      "outputs": [],
      "source": [
        "\"\"\"You can use the same function to build another neural network. \n",
        "   You can make fucntion more elastic using keyword arguments in definition.\n",
        "   After that you can pass kwargs valuse into KerasClassifier\"\"\"\n",
        "estimator = KerasClassifier(build_fn=create_NN, nb_epoch=100, \n",
        "                          batch_size=5, verbose=2, shape=x_train.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c12ca634-52d3-b47a-512b-8415f5934962"
      },
      "outputs": [],
      "source": [
        "estimator.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2f07aacd-a8c4-54aa-6309-81c7956f6715"
      },
      "outputs": [],
      "source": [
        "net_pred = estimator.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "af1cc068-bd77-57a2-b4af-546b07945298"
      },
      "outputs": [],
      "source": [
        "gbm = xgb.XGBClassifier(\n",
        "    #learning_rate = 0.02,\n",
        " n_estimators= 2000,\n",
        " max_depth= 4,\n",
        " min_child_weight= 2,\n",
        " #gamma=1,\n",
        " gamma=0.9,                        \n",
        " subsample=0.8,\n",
        " colsample_bytree=0.8,\n",
        " objective= 'binary:logistic',\n",
        " nthread= -1,\n",
        " scale_pos_weight=1).fit(x_train, y_train)\n",
        "predictions = gbm.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e31158eb-4409-cc4c-9aa8-59cd447487bf"
      },
      "outputs": [],
      "source": [
        "net_pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e98ec192-17b4-fc4f-cfec-dcff804c5b4f"
      },
      "outputs": [],
      "source": [
        "predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "165475fb-d5f2-bea4-3d0b-7bbf05bdc940"
      },
      "outputs": [],
      "source": [
        "net_pred = net_pred.reshape(net_pred.shape[0],)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d154b18c-1e48-3dea-2742-2d2358acfbd1"
      },
      "outputs": [],
      "source": [
        "StackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId,\n",
        "                            'Survived': predictions })\n",
        "StackingSubmission.to_csv(\"StackingSubmission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a5f7bfe6-0505-1453-40fe-a2f0db4d52be"
      },
      "outputs": [],
      "source": [
        "StackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId,\n",
        "                            'Survived': net_pred})\n",
        "StackingSubmission.to_csv(\"NetStackingSubmission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f1677a75-8b39-9a3e-03f7-6c5f73302f31"
      },
      "outputs": [],
      "source": [
        "est_pred = est_pred.flatten()\n",
        "StackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId,\n",
        "                            'Survived': est_pred})\n",
        "StackingSubmission.to_csv(\"EstStackingSubmission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "28ac950f-bc71-01a3-ca84-f8ecb0c70d07"
      },
      "source": [
        "**For now one**\n",
        "That is it right now. Later(if I will have some time) I will try to get higher accuracy score by doing e.g. feature extraction or dimensionality reduction(hope it will work :| )."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9745b626-76ea-2e00-759d-c1cdcaf961cd"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}