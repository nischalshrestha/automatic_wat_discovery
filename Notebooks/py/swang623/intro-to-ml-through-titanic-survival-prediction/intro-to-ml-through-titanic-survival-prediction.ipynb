{"nbformat": 4, "nbformat_minor": 1, "metadata": {"language_info": {"version": "3.6.4", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "cells": [{"cell_type": "markdown", "metadata": {"_cell_guid": "60c35bfb-359a-49bf-b119-bf5aeb9eceb2", "_uuid": "8027f6e7dee32dbd21d7cd461604303c9ef53c8a"}, "source": ["__Reference__\n", "\n", "This notebook referenced the following Kaggle Kernels:\n", "-  [Nadin Tamer, Titanic Survival Predictions (Beginner)](https://www.kaggle.com/nadintamer/titanic-survival-predictions-beginner)\n", "-  [Omar El Gabry, A Journey through Titanic](https://www.kaggle.com/omarelgabry/a-journey-through-titanic)\n", "-  [Anisotropic, Introduction to Ensembling/Stacking in Python](https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python)\n", "- [Sina, Titanic best working Classifier](https://www.kaggle.com/sinakhorami/titanic-best-working-classifier)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "2190a220-ac34-4549-a422-4644db0ed4d0", "_uuid": "b91e80d8635e896b8851cd052e56afa614b20786"}, "source": ["## Introduction to Machine Learning through Titanic Project\n", "\n", "###  Critical Steps\n", "1. Importing & Exploring Necessary Libraries\n", "2. Read in Data\n", "3. Feature Exploration\n", "4. Data Manipulation\n", "5. Running Machine Learning Algorithms\n", "6. Creating Submission File to Kaggle"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "bdae2086-dbb9-449f-a796-ecd9b5174f27", "_uuid": "2ac5e8e671a54af34d224820a256964e81a74a7c"}, "source": ["# 1. Import Libraries"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "04cf6722-386d-417b-9826-a46b9ffa9fe4", "collapsed": true, "_uuid": "d45f4a58c6f3054f9da697327c465424f9e7330b"}, "execution_count": null, "source": ["# Data Analysis Libraries\n", "import numpy as np\n", "import pandas as pd\n", "\n", "# Data Visualization Libraries\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "%matplotlib inline\n", "\n", "# Machine Learning Libraries\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.svm import SVC\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.ensemble import GradientBoostingClassifier"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "1aeade1a-5daa-479e-bf26-1e7686b2d580", "_uuid": "6f2317efff784729d6faff4c5d7f7b1b78c1c931"}, "source": ["# 2. Read in Data"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "176983e1-532c-4ded-a506-eb6ed27e33d0", "collapsed": true, "_uuid": "46138d9e659b367f6f4fc0578164a3cb4277052c"}, "execution_count": null, "source": ["train = pd.read_csv(\"../input/train.csv\")\n", "test = pd.read_csv(\"../input/test.csv\")"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "02f8a5dc-1fc3-4a33-81a6-85f3e63cf39c", "_uuid": "e9ddcb75310e609f5ece7ed3fd2f19cbad94c630"}, "source": ["# 3. Feature Exploration\n", "\n", "In this step, we will get a basic sense of the data and visualize the features to figure out which ones are relevant for the analysis."]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "30262269-6ba4-4f14-9b04-a2978669ac33", "_uuid": "9ca5234ee67b46bb601fb8f60a5af7e025a92a3b"}, "execution_count": null, "source": ["# A basic look at the training data\n", "train.sample(5)"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "cd96a59f-fdca-492d-8bf0-05612adfa019", "_uuid": "52e13714e0011658e5c7a60a1c05012978290b5d"}, "execution_count": null, "source": ["# Summary of the training data\n", "train.describe(include = \"all\")"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "06ce185f-1c5d-4bd2-b2aa-d43f26a14bef", "scrolled": false, "_uuid": "3847162e1c8255083825854642e309e9df4b5170"}, "execution_count": null, "source": ["# Get a clearer understanding of data types and missing values\n", "train.info()\n", "print('***************************************************')\n", "test.info()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "94c8ddee-4f94-49c4-a3cb-36b088c396fa", "_uuid": "79c8b3d5815a1dc714ec875e6a4fe31cd2656a7d"}, "source": ["## 3.1 Pclass"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "3eeb9f9b-62b7-4b80-8c69-bcd184ad8303", "_uuid": "b7ae451697e95c7c802730836a3e7fd01cda86eb"}, "execution_count": null, "source": ["# Explore if survival rate depends on passenger class\n", "sns.barplot(x = \"Pclass\", y = \"Survived\", data = train)\n", "train[[\"Pclass\", \"Survived\"]].groupby([\"Pclass\"], as_index = False).mean()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "79d1531c-195e-48cf-9a82-01f4c1785663", "_uuid": "9a432f593be2d1eb6c94df0dfd0314dec7bfce98"}, "source": ["There seems to be a significant difference in survival rate for passengers in different classes. This feature should go into the model."]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "cb051c90-c0c7-40c8-a94d-a35c8f6cc97a", "_uuid": "ceb81a17ac17a989aba53e1d7edac74ebef39825"}, "source": ["## 3.2 Sex"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "fbf527ed-25bc-4ebe-a217-2c564c4380ad", "scrolled": true, "_uuid": "890f5810b8e499cd71e4dbd25f60c043900cf646"}, "execution_count": null, "source": ["# Explore if survival rate depends on passenger gender\n", "sns.barplot(x = \"Sex\", y = \"Survived\", data = train)\n", "train[[\"Sex\", \"Survived\"]].groupby([\"Sex\"], as_index = False).mean()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "5bf389bd-c909-4b27-b994-60923d974601", "_uuid": "9b28a0f2aeac9e4d4833731c1243b91fb997afe6"}, "source": ["Sex should definitely go into the model as well."]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "71aea022-8031-4cb6-949c-3a96058a6eb4", "_uuid": "c7262691a4d470b5511d2c5e85818d61e91a0de9"}, "source": ["## 3.3 Age "]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "e14f67f9-7bc8-49a0-866e-9dc52382b851", "_uuid": "03ccafe913df52a63571e8170ed686a13aa67fdf"}, "execution_count": null, "source": ["# Age is a continuous variable with 20% of the data missing. \n", "# We will first look at the distribution\n", "sns.distplot(train[\"Age\"].dropna(), bins = 70, kde = False)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "542506f9-d37e-40af-924d-253de0d4a6be", "_uuid": "a9258526982acf6c4e57e410564131a626caab4d"}, "source": ["- Age is not normally distributed so we cannot simply generate random numbers following a normal distribution to fill in the missing numbers. \n", "- Instead of treating age as a continuous variable, it might be better to categorize age intervals since one year difference in age would probably not determine if the person survive.\n", "- In the next section, we will come up ways to fill in the missing value and categorize age."]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "5bafe9d0-0852-42cc-beab-96ae22ec4cc9", "_uuid": "e98c051920c1236f618cfbd725e6a803606ed1cf"}, "source": ["## 3.3 SibSp"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "72a96cd7-98cf-4f73-92ba-0bb55bd0e5dc", "scrolled": false, "_uuid": "c84fe879b18428d08f96e6d24e090b1682df2da3"}, "execution_count": null, "source": ["# Explore if survival rate depends on the number of siblings/spouses abroad the Titanic\n", "sns.barplot(x = \"SibSp\", y = \"Survived\", data = train)\n", "sibsp = pd.DataFrame()\n", "sibsp[\"Survived Mean\"] = train[[\"SibSp\", \"Survived\"]].groupby([\"SibSp\"], as_index = False).mean()[\"Survived\"]\n", "sibsp[\"Count\"] = train[[\"SibSp\", \"Survived\"]].groupby([\"SibSp\"], as_index = False).count()[\"Survived\"]\n", "sibsp[\"STD\"] = train[[\"SibSp\", \"Survived\"]].groupby([\"SibSp\"], as_index = False).std()[\"Survived\"]\n", "print(sibsp)\n", "train[(train[\"SibSp\"] == 5)|(train[\"SibSp\"] == 8)]"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "e21e89e2-0b3a-40c6-8db9-1652cc9d4a36", "_uuid": "62e54360d40986e75a02986e82c2e1ab9a3d017a"}, "source": ["- In the next step, we will group \"SibSp\" into [0, 1, 2 or more]\n", "- It is surprising that none of the members in the two families with 5 and 8 SibSp survived. Looking at the available \"Age\" data points, it seems that most of them are kids. It would be a good idea to fill in the rest ages as \"teenagers\" or \"kids\". However, there are only 7 records that needs to be filled in in this way so in this analysis, we will not treat them differently. "]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "66df6041-8ffb-4750-8223-8aa9a881b2d6", "_uuid": "dd6ec8cd30667ffa2e69fd935380d4f5ee516de3"}, "source": ["## 3.4 Parch"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "6698d603-866d-4708-b49a-efc707260138", "_uuid": "c2e61412427e739ff3d751009e86d6ddb57ac53d"}, "execution_count": null, "source": ["# Explore if survival rate depends on the number of parents/children abroad the Titanic\n", "sns.barplot(x = \"Parch\", y = \"Survived\", data = train)\n", "sibsp[\"Survived Mean\"] = train[[\"Parch\", \"Survived\"]].groupby([\"Parch\"], as_index = False).mean()[\"Survived\"]\n", "sibsp[\"Count\"] = train[[\"Parch\", \"Survived\"]].groupby([\"Parch\"], as_index = False).count()[\"Survived\"]\n", "sibsp[\"STD\"] = train[[\"Parch\", \"Survived\"]].groupby([\"Parch\"], as_index = False).std()[\"Survived\"]\n", "print(sibsp)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "3d3c29a8-bc00-4664-8c05-8ba4f73dc261", "_uuid": "d9c78586c630c6509208dac25ec7c9aacbe18175"}, "source": ["- In the next step, we will group \"Parch\" into [0, 1, 2 or more]"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "5c399d37-ccf0-4dae-aee9-24ade24f3ba5", "_uuid": "524cf03901849babe59994d47e0b6f034cbc3c07"}, "source": ["## 3.5 Fare"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "2e1d15d8-88d1-4ec0-a8ee-46775f7b7c2b", "_uuid": "07734e4ea4c2ea193a13546d52feaed7e745e8c3"}, "execution_count": null, "source": ["# See the distribution of Fare\n", "#sns.distplot(train[\"Fare\"][train[\"Pclass\"]==1].dropna(), bins = 10, kde = False)\n", "print(train[[\"Fare\", \"Survived\"]].dropna().groupby([\"Survived\"]).count())\n", "fare_hist = sns.FacetGrid(train, col=\"Survived\")\n", "fare_hist = fare_hist.map(plt.hist, \"Fare\")\n", "\n", "train[[\"Fare\", \"Survived\"]].dropna().groupby([\"Survived\"]).median()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "7ddf2488-eff8-42ab-9623-a66b228a1b33", "_uuid": "ff24344dbd256e4a3988c3b9b6b7132d9bb58317"}, "source": ["- The outputs above indicate that the distribution of fare for the group who survived and the group who did not is different. So we will include fare in the model.\n", "- We will also categorize fare."]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "db73c384-f632-4146-9b67-dcf20c6b76d9", "_uuid": "b2c7db3c79ee2d79719d47c44c1bd771d82b3cf8"}, "source": ["## 3.6 Cabin"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "93c12506-a7a6-4f23-a8ac-c3ff56a3298f", "scrolled": true, "_uuid": "f343cf2b42c33b556040784205eb4fa2d1a468e5"}, "execution_count": null, "source": ["# There are many missing values in this colomn\n", "(train[\"Survived\"][train[\"Cabin\"].isnull()].count())/(train[\"Cabin\"].count())"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "d5827104-c8b8-42af-a484-4eef0de211f7", "_uuid": "5448f0174094179e793f53d6a2d3880a3278672a"}, "source": ["- Since there are much more missing values than available values, we will leave this variable out from the model."]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "336d68c5-248c-4e89-bc42-44ba5dfa1d98", "_uuid": "24e0c6234df896784fbf462d526e8be018e1d643"}, "source": ["## 3.7 Embarked"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "031c1171-7f96-46a7-b10c-63ac1ea1369e", "_uuid": "67809fd8f3587a1da45195cfbd4752e8c30430f7"}, "execution_count": null, "source": ["# Explore if survival rate depends on the port passenger embarked\n", "sns.barplot(x = \"Embarked\", y = \"Survived\", data = train)\n", "train[[\"Survived\", \"Embarked\"]].groupby([\"Embarked\"]).mean()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "39261fb7-be85-41f0-8877-c85070c8df94", "_uuid": "d16bffe521ae7c13d0f91f6505f091f349253be9"}, "source": ["- We will keep this variable in our model."]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "dc53960a-1b96-4c2d-bbcc-c9b0401ffdf7", "_uuid": "c8a4fa416e49fddc89ac9d66a41555ab507810a4"}, "source": ["## Insights from Feature Exploration & Next Steps\n", "- Some variables may not have valuable information and can be dropped from the dataset.\n", "- Missing values in both the training dataset and testing dataset should be addressed.\n", "- Continuous variables should be categorized."]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "d7a9b57a-a507-4bb2-9da8-4126384ba4cb", "collapsed": true, "_uuid": "cc7fc2962acef7bb6967c2eab0aa09356ff2dc70"}, "source": ["# 4. Data Manipulation"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "894aaf5b-108e-4858-b3b5-ea7b4ff6b4c9", "collapsed": true, "_uuid": "af76354722c2a68e55ab9f2378e8d755fd699f65"}, "source": ["## 4.1 Dropping Unnecessary Variables\n", "\n", "From the outputs above, we get a basic sense of the variables and it is intuitive that \"PassengerId\", \"Name\"and \"Ticket\" are not likely to be valuable for the analysis. Therefore, we will drop these variables from both the training and testing dataset. \n", "\n", "From the summary statistics, we also realize that the column \"cabin\" has too many missing values to draw information from. We will also exclude this column from the datasets."]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "38178bdc-d2c1-4332-9370-eb9c7fff7567", "collapsed": true, "_uuid": "7221ec4516c5bc09f8bb288dc2b2a6cc0f90240d"}, "execution_count": null, "source": ["PassengerId = test['PassengerId']\n", "train = train.drop([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], axis = 1)\n", "test = test.drop([\"PassengerId\",\"Name\", \"Ticket\", \"Cabin\"], axis = 1)"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "4ce16fd6-ea77-4ff4-a8f5-c16fef6e5f54", "collapsed": true, "_uuid": "856119fc24971160edd52990a27a6fc6bc508071"}, "execution_count": null, "source": ["#train.info()\n", "#print('***************************************************')\n", "#test.info()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "fdd086a3-b227-4291-b91f-c24336267055", "_uuid": "30386a4e85ba80bfba7263814856d990e12ffa35"}, "source": ["## 4.2 Dealing with Missing Values\n", "\n", "There are two variabels with missing values in the training dataset: \"Age\" and \"Embarked\""]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "dd662773-8912-4bd4-8148-d9cc829d8232", "collapsed": true, "_uuid": "dbdad4f6998a115f21db9765ec4f9aacfa5eb9e1"}, "source": [" ## *4.2.1 Embarked -- categorical data* \n", " \n", " ### It's common to replace missing values of a categorical variable with mode. We will find the count for each unique values and replace is with the most appeared value."]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "60c1de71-1e21-46be-bd47-969d63612054", "scrolled": true, "_uuid": "d600bf75aa41c7f4615147418faf5403ca7d9324"}, "execution_count": null, "source": ["print(train[\"Embarked\"].unique())\n", "print(train.groupby([\"Embarked\"])[\"Survived\"].count().reset_index())\n", "train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n", "train.groupby([\"Embarked\"])[\"Survived\"].count().reset_index()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "c2349fa0-4e1b-4297-a58d-a539951e016e", "_uuid": "8929cf9e82d1803fd8d4bab08d7d7be4669eda4c"}, "source": ["## *4.2.2 Age*\n", "\n", "### About 20% of the \"Age\" column is missing. As inspied by *A Journey through Titanic*, we will replace missing values with random numbers between (mean - std) and (mean + std)"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "88750c9d-64a8-448d-af4a-be1fb6f3e3e5", "_uuid": "6f833b3910636d62efe3eb4244275a158cf90730"}, "execution_count": null, "source": ["# Calculate mean and standard deviation of \"Age\" column\n", "train_mean = train[\"Age\"].mean()\n", "train_std = train[\"Age\"].std()\n", "test_mean = test[\"Age\"].mean()\n", "test_std = test[\"Age\"].std()\n", "\n", "# Count missing values\n", "count_na_train = train[\"Age\"].isnull().sum()\n", "count_na_test = test[\"Age\"].isnull().sum()\n", "\n", "# generate random numbers\n", "np.random.seed(66)\n", "train_rand = np.random.randint(train_mean - train_std, train_mean + train_std, size = count_na_train)\n", "test_rand = np.random.randint(test_mean - test_std, test_mean + test_std, size = count_na_test)\n", "\n", "# Fill missing values with random numbers\n", "train[\"Age\"][np.isnan(train[\"Age\"])] = train_rand\n", "test[\"Age\"][np.isnan(test[\"Age\"])] = test_rand\n", "\n", "# Convert into int\n", "train[\"Age\"] = train[\"Age\"].astype(int)\n", "test[\"Age\"] = test[\"Age\"].astype(int)\n"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "89e4ff83-d669-4405-93da-79374a0b45b8", "_uuid": "53a7ff2038de700501ada47ba6e05afe2620f873"}, "source": ["## *4.2.3 Fare*\n", "\n", "### There is one missing value for fare in the test data. We will simply replace it with the median"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "03ec0afd-0dcd-40f9-9ef5-a823548ee94a", "collapsed": true, "_uuid": "dd684aaa618d7a19f8a644bc65cf16eac2c52530"}, "execution_count": null, "source": ["test[\"Fare\"] = test[\"Fare\"].fillna(test[\"Fare\"].median())"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "78055fbe-9384-49e6-a62b-1d884c2a157f", "collapsed": true, "scrolled": false, "_uuid": "79198c77c55e2ad1433fd9f707dd1e404cf34938"}, "execution_count": null, "source": ["# Confirm that all missing values are taken care of\n", "#train.info()\n", "#print('***************************************************')\n", "#test.info()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "ea616b86-ce91-4cac-bd78-a6428052d1bf", "_uuid": "d87c10fac934a012f32eecf8e39ad796d83acbaf"}, "source": ["## 4.3 Categorize Numeric Values"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "19b095df-e109-4f44-abb3-dde3b4be4f3f", "_uuid": "2ea4284b8093d2de6f2438f3618f8a51d17f5c0a"}, "source": ["## 4.3.1 Age"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "e8a8fc6f-1d42-481a-9818-ade470f77635", "_uuid": "e6714e175407f6cc96591af0a7a1fa50a302f350"}, "execution_count": null, "source": ["# Map Age to categorical groups\n", "train.loc[train[\"Age\"] <= 16, \"age_c\"] = \"1\"\n", "train.loc[(train[\"Age\"] <= 32)&(train[\"Age\"] > 16), \"age_c\"] = \"2\"\n", "train.loc[(train[\"Age\"] > 32)&(train[\"Age\"] <= 48), \"age_c\"] = \"3\"\n", "train.loc[(train[\"Age\"] > 48)&(train[\"Age\"] <= 64), \"age_c\"] = \"4\"\n", "train.loc[(train[\"Age\"] > 64), \"age_c\"] = \"5\"\n", "\n", "test.loc[test[\"Age\"] <= 16, \"age_c\"] = \"1\"\n", "test.loc[(test[\"Age\"] <= 32)&(test[\"Age\"] > 16), \"age_c\"] = \"2\"\n", "test.loc[(test[\"Age\"] > 32)&(test[\"Age\"] <= 48), \"age_c\"] = \"3\"\n", "test.loc[(test[\"Age\"] > 48)&(test[\"Age\"] <= 64), \"age_c\"] = \"4\"\n", "test.loc[(test[\"Age\"] > 64), \"age_c\"] = \"5\"\n", "\n", "train[[\"age_c\",\"Survived\"]].groupby([\"age_c\"]).mean()"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "dad5acf0-1ce8-4ad6-abf0-7a11ee807798", "collapsed": true, "_uuid": "1a1de97b82a88f3a371e9e10278bc3a876eb522b"}, "execution_count": null, "source": ["# set up two new dataframes for the final model\n", "m_train = train\n", "m_test = test\n", "\n", "#m_train.info()\n", "#print('***************************************************')\n", "#m_test.info()"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "fbc60848-6e5b-4d95-9940-d810ea20bb98", "_uuid": "2c3219d23656fb27b5c689535b7179f706f8aee9"}, "execution_count": null, "source": ["# Generate Dummy Variable for Age\n", "# Dropped the first one to avoid multicollinearity\n", "#age_dummy_train = pd.get_dummies(train[\"age_c\"], drop_first = True)\n", "#age_dummy_test = pd.get_dummies(test[\"age_c\"], drop_first = True)\n", "\n", "# Concatenate Age dummy with the original training dataset\n", "#m_train = pd.concat([m_train, age_dummy_train], axis = 1)\n", "#m_test = pd.concat([m_test, age_dummy_test], axis = 1)\n", "\n", "# Drop original Age and age_c\n", "#m_train = m_train.drop([\"age_c\", \"Age\"], axis = 1)\n", "#m_test = m_test.drop([\"age_c\", \"Age\"], axis = 1)\n", "\n", "#m_train.sample(5)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "238c212f-8d04-49f3-8ee7-d645f7aca22e", "collapsed": true, "_uuid": "f6ef8e1bb10c2992e9398b2725292c42a5151c8c"}, "source": ["## 4.3.2 SibSp\n", "\n", "Categorize into 0,1,2 or more"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "a43c0aa1-f1da-48fb-963e-e3d3ba152713", "_uuid": "8f8a5117bb7155bf118052f4c56c55b9ca2c85d0"}, "execution_count": null, "source": ["# Map SibSp into categories\n", "train.loc[train[\"SibSp\"] == 0, \"sib_c\"] = \"0\"\n", "train.loc[train[\"SibSp\"] == 1, \"sib_c\"] = \"1\"\n", "train.loc[train[\"SibSp\"] >1 , \"sib_c\"] = \"2\"\n", "\n", "test.loc[test[\"SibSp\"] == 0, \"sib_c\"] = \"0\"\n", "test.loc[test[\"SibSp\"] == 1, \"sib_c\"] = \"1\"\n", "test.loc[test[\"SibSp\"] >1 , \"sib_c\"] = \"2\"\n", "\n", "# Generate Dummy Variable\n", "#sib_dummy_train = pd.get_dummies(train[\"sib_c\"], drop_first = True)\n", "#sib_dummy_test = pd.get_dummies(test[\"sib_c\"], drop_first = True)\n", "\n", "\n", "# Append sib_dummy to m-train\n", "#m_train = pd.concat([m_train, sib_dummy_train], axis = 1)\n", "#m_train = m_train.drop([\"SibSp\"], axis = 1)\n", "\n", "#m_test = pd.concat([m_test, sib_dummy_test], axis = 1)\n", "#m_test = m_test.drop([\"SibSp\"], axis = 1)\n", "\n", "#m_train.sample(5)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "86869d70-03e2-4409-b677-35c5f30cbd17", "_uuid": "cfd240787cb6175510fbd1abe4664173eaf89fb4"}, "source": ["## 4.3.3 Parch\n", "\n", "Categorize into 0,1, 2 and more"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "740f40e7-bf4a-4f2c-9af6-6171b82739e9", "_uuid": "28292330963f987021a4d59a2b1029af8c8cc81f"}, "execution_count": null, "source": ["# Map Parch into categories\n", "train.loc[train[\"Parch\"] == 0, \"pc_c\"] = \"0\"\n", "train.loc[train[\"Parch\"] == 1, \"pc_c\"] = \"1\"\n", "train.loc[train[\"Parch\"] >1 , \"pc_c\"] = \"2\"\n", "\n", "test.loc[test[\"Parch\"] == 0, \"pc_c\"] = \"0\"\n", "test.loc[test[\"Parch\"] == 1, \"pc_c\"] = \"1\"\n", "test.loc[test[\"Parch\"] >1 , \"pc_c\"] = \"2\"\n", "\n", "# Generate Dummy Variable\n", "#pc_dummy_train = pd.get_dummies(train[\"pc_c\"], drop_first = True)\n", "#pc_dummy_test = pd.get_dummies(test[\"pc_c\"], drop_first = True)\n", "\n", "\n", "# Append sib_dummy to m-train/m-test\n", "#m_train = pd.concat([m_train, pc_dummy_train], axis = 1)\n", "#m_train = m_train.drop([\"Parch\"], axis = 1)\n", "\n", "#m_test = pd.concat([m_test, pc_dummy_test], axis = 1)\n", "#m_test = m_test.drop([\"Parch\"], axis = 1)\n", "\n", "#m_train.sample(5)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "8ee787c7-4b40-4eb8-a05a-71a3fcc7d348", "_uuid": "e47a20118d2659ebe7ddf9d079e3ba4a9b833b25"}, "source": ["## 4.3.4 Fare"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "6fd34a33-f4e8-40e5-a4f5-c2196b4f2980", "_uuid": "a9c4185798097152fd4887e4b869dc7b6514b1ad"}, "execution_count": null, "source": ["# Map fare values into categories\n", "train[\"fare_c\"] = pd.qcut(train[\"Fare\"], 4, labels = [\"1\", \"2\", \"3\",\"4\"])\n", "test[\"fare_c\"] = pd.qcut(test[\"Fare\"], 4, labels = [\"1\", \"2\", \"3\",\"4\"])\n", "\n", "# Generate dummy variables for both train and test\n", "#fare_dummy_train = pd.get_dummies(train[\"fare_c\"], drop_first = True)\n", "#fare_dummy_test = pd.get_dummies(test[\"fare_c\"], drop_first = True)\n", "\n", "# Append dummy variables to the original data frames\n", "#m_train = pd.concat([m_train, fare_dummy_train], axis = 1)\n", "#m_train = m_train.drop([\"Fare\"], axis = 1)\n", "\n", "#m_test = pd.concat([m_test, fare_dummy_test], axis = 1)\n", "#m_test = m_test.drop([\"Fare\"], axis = 1)\n", "\n", "#m_train.sample(5)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "22d97180-dea3-4bb2-bea4-9b38ef482626", "_uuid": "5704216689edf8769509ce0b67b0ff5bfa71cbf6"}, "source": ["## 4.4 Assign numerical values to categorical variables"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "83e13901-5f9e-4ab4-bd1b-864030c27a36", "collapsed": true, "_uuid": "ef468cd647223b5961f79ef667f0c90589eeec34"}, "source": ["## 4.4.1 Sex"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "d55ff971-921a-4fcc-8b2e-6d47574545e6", "_uuid": "d48efc5837c2bb8bda39ea3bbbf915ae3dad3112"}, "execution_count": null, "source": ["train.loc[train[\"Sex\"] == \"male\", \"sex_c\"] = \"0\"\n", "train.loc[train[\"Sex\"] == \"female\", \"sex_c\"] = \"1\"\n", "\n", "test.loc[test[\"Sex\"] == \"male\", \"sex_c\"] = \"0\"\n", "test.loc[test[\"Sex\"] == \"female\", \"sex_c\"] = \"1\"\n", "\n", "# Generate dummy variables for both train and test\n", "#sex_dummy_train = pd.get_dummies(train[\"Sex\"], drop_first = True)\n", "#sex_dummy_test = pd.get_dummies(test[\"Sex\"], drop_first = True)\n", "\n", "# Append dummy variables to the original data frames\n", "#m_train = pd.concat([m_train, sex_dummy_train], axis = 1)\n", "#m_train = m_train.drop([\"Sex\"], axis = 1)\n", "\n", "#m_test = pd.concat([m_test, sex_dummy_test], axis = 1)\n", "#m_test = m_test.drop([\"Sex\"], axis = 1)\n", "\n", "#m_train.sample(5)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "9f8c2ab9-7986-4dab-8115-53d0dde7bb49", "_uuid": "e991b0eaa9819658ebed8ca1461156ad35f954b3"}, "source": ["## 4.4.2 Embarked"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "43d87d06-0005-4403-ba92-dce40688bbdf", "_uuid": "af52eecb55069f31399a8dd0446c02ac38f455c4"}, "execution_count": null, "source": ["train.loc[train[\"Embarked\"] == \"S\", \"emk_c\"] = \"0\"\n", "train.loc[train[\"Embarked\"] == \"Q\", \"emk_c\"] = \"1\"\n", "train.loc[train[\"Embarked\"] == \"C\", \"emk_c\"] = \"2\"\n", "\n", "test.loc[test[\"Embarked\"] == \"S\", \"emk_c\"] = \"0\"\n", "test.loc[test[\"Embarked\"] == \"Q\", \"emk_c\"] = \"1\"\n", "test.loc[test[\"Embarked\"] == \"C\", \"emk_c\"] = \"2\"\n", "\n", "# Generate dummy variables for both train and test\n", "#emk_dummy_train = pd.get_dummies(train[\"Embarked\"], drop_first = True)\n", "#emk_dummy_test = pd.get_dummies(test[\"Embarked\"], drop_first = True)\n", "\n", "# Append dummy variables to the original data frames\n", "#m_train = pd.concat([m_train, emk_dummy_train], axis = 1)\n", "#m_train = m_train.drop([\"Embarked\"], axis = 1)\n", "\n", "#m_test = pd.concat([m_test, emk_dummy_test], axis = 1)\n", "#m_test = m_test.drop([\"Embarked\"], axis = 1)\n", "\n", "#m_train.sample(5)\n", "\n", "train.sample(5)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "5953784e-0526-46d4-b088-a0ead1bb650b", "_uuid": "33ac85d3aa6132e7b59aad59f81ca091de5f1334"}, "source": ["## 4.4.3 Pclass"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "fc35ec62-aaee-446c-8745-24c7c47c473d", "_uuid": "9d73254f83c1a5b0dc5d292446a7948a3e4080cf"}, "execution_count": null, "source": ["# Map Parch into categories\n", "#train.loc[train[\"Pclass\"] == 1, \"class_c\"] = \"class1\"\n", "#train.loc[train[\"Pclass\"] == 2, \"class_c\"] = \"class2\"\n", "#train.loc[train[\"Pclass\"] == 3, \"class_c\"] = \"class3\"\n", "\n", "#test.loc[train[\"Pclass\"] == 1, \"class_c\"] = \"class1\"\n", "#test.loc[train[\"Pclass\"] == 2, \"class_c\"] = \"class2\"\n", "#test.loc[train[\"Pclass\"] == 3, \"class_c\"] = \"class3\"\n", "\n", "# Generate dummy variables for both train and test\n", "#class_dummy_train = pd.get_dummies(train[\"class_c\"], drop_first = True)\n", "#class_dummy_test = pd.get_dummies(test[\"class_c\"], drop_first = True)\n", "\n", "# Append dummy variables to the original data frames\n", "#m_train = pd.concat([m_train, class_dummy_train], axis = 1)\n", "#m_train = m_train.drop([\"Pclass\"], axis = 1)\n", "\n", "#m_test = pd.concat([m_test, class_dummy_test], axis = 1)\n", "#m_test = m_test.drop([\"Pclass\"], axis = 1)\n", "\n", "#m_train.sample(5)"]}, {"cell_type": "code", "outputs": [], "metadata": {}, "execution_count": null, "source": ["# Drop non-numeric categorical variables\n", "train = train.drop([\"Embarked\",\"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"], axis = 1)\n", "test = test.drop([\"Embarked\",\"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"], axis = 1)"]}, {"cell_type": "code", "outputs": [], "metadata": {}, "execution_count": null, "source": ["train.sample(5)"]}, {"cell_type": "code", "outputs": [], "metadata": {}, "execution_count": null, "source": ["test.sample(5)"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "0f4cfa6e-7bae-4b99-85ae-9d7d03e4f1f6", "_uuid": "e01e6432765327760dc91438275b1f2bf2c2908b"}, "execution_count": null, "source": ["# Check dataset status before modelling\n", "train.info()\n", "print('***************************************************')\n", "test.info()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "4e2ca79e-6212-4594-8ec6-402b47cab6be", "_uuid": "1fc7ac8ccb340018b3495966a86eef8075ee4171"}, "source": ["# 5. Running Machine Learning Algorithms\n", "\n", "The datasets are finally ready for modeling!!!\n", "\n", "We will explore the following models:\n", "- Gaussian Naive Bayes\n", "- Logistics Regression\n", "- Support Vector Machine\n", "- Decision Tree Classifier\n", "- Random Forest Classifier\n", "- K-Nearest Neighbors\n", "\n", "* Note that all parameters are set as default as of 1/10/2018; To be adjusted"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "f90dfa18-ef84-46c5-9805-3828f88d6e64", "collapsed": true, "_uuid": "d11f2b4b20b4f4cc99b9d36607113d87be070ecc"}, "execution_count": null, "source": ["# As inspired by Nadin, we will use 80% of the data for training,\n", "# and the rest 20% to test the accuracy of the model\n", "\n", "predictors = train.drop([\"Survived\"], axis = 1)\n", "target = train[\"Survived\"]\n", "x_train, x_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.2, random_state = 0)"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "2e27cefe-ec88-46a5-ae1a-7844ce2bd2fa", "_uuid": "2ca92dd083b57aaa950c7adf6887ec83305147dd"}, "execution_count": null, "source": ["# Gaussian Naive Bayes\n", "gaussian = GaussianNB()\n", "gaussian.fit(x_train, y_train)\n", "# y_pred = gaussian.predict(x_val)\n", "acc_gaussian = gaussian.score(x_val, y_val)\n", "acc_gaussian"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "8209436a-30f2-46d3-8987-e09749716d5a", "_uuid": "3207dc41c968f4ccfa9e74b652ba114c5cd443d5"}, "execution_count": null, "source": ["# Logistic Regression\n", "logreg = LogisticRegression()\n", "logreg.fit(x_train, y_train)\n", "#y_pred = logreg.predict(x_val)\n", "acc_logreg = logreg.score(x_val, y_val)\n", "acc_logreg"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "84927e93-e454-4d51-a0f2-4638498b5a4b", "_uuid": "f6e0532558385c63108f1763ffddd6a261afdde9"}, "execution_count": null, "source": ["# Support Vector Machine\n", "svc = SVC()\n", "svc.fit(x_train, y_train)\n", "#y_pred = logreg.predict(x_val)\n", "acc_svc = svc.score(x_val, y_val)\n", "acc_svc"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "c97f9e84-c82b-41db-8db4-49240be27a06", "_uuid": "bd59e5901bc68d216a19c1c5b288eb995f4d435a"}, "execution_count": null, "source": ["# Decision Tree Classifier\n", "decisiontree = DecisionTreeClassifier()\n", "decisiontree.fit(x_train, y_train)\n", "#y_pred = decisiontree.predict(x_val)\n", "acc_decisiontree = decisiontree.score(x_val, y_val)\n", "acc_decisiontree"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "c00a0bbd-4081-4397-a0eb-0d7af81858e9", "_uuid": "27a59e388e1c5798e75273226572e292417268f1"}, "execution_count": null, "source": ["# Random Forest Classifier\n", "randomforest = RandomForestClassifier()\n", "randomforest.fit(x_train, y_train)\n", "#y_pred = randomforest.predict(x_val)\n", "acc_randomforest = randomforest.score(x_val, y_val)\n", "acc_randomforest"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "49de7f13-3b04-4b7a-bcbb-b10e95126bf5", "_uuid": "f960d4a3e986324bbf27c204846424c1046c048e"}, "execution_count": null, "source": ["# K-Nearest Neighbors\n", "knn = KNeighborsClassifier()\n", "knn.fit(x_train, y_train)\n", "#y_pred = knn.predict(x_val)\n", "acc_knn = knn.score(x_val, y_val)\n", "acc_knn"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "71626c94-3464-4db9-8cc5-ef65bb829d92", "_uuid": "119457650db6daf8f466120c167bbc78ff2cfe15"}, "source": ["Based on the outputs above, Random Forest seems to work the best."]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "d1e79487-a883-4852-bfd7-0227277dbe50", "_uuid": "66548c8d7ef44689b440f4a9f8227ecba2a4e9dd"}, "source": ["# 6. Create a Submission File\n"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "b6edb1ed-39de-4afb-94c3-2d2cfbb7df8f", "_uuid": "d5cd1392af980a57ecad6f7ab9190bd5594ad726"}, "execution_count": null, "source": ["# Generate Predictions\n", "prediction = randomforest.predict(test)\n", "\n", "submission_titanic = pd.DataFrame({ 'PassengerId': PassengerId,\n", "                            'Survived': prediction })\n", "#print(submission_titanic)\n", "submission_titanic.to_csv(\"submission_titanic.csv\", index = False)"]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "source": []}]}