{"cells":[{"metadata":{"scrolled":true,"trusted":true,"_uuid":"608dd3d863f02e18d2e490ae8d7b110b3115b1cb"},"cell_type":"code","source":"# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n#path=\"E:\\surya\\work\\kaggle titanic dataset\"\n#os.chdir(path)\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbb223c89aefd9ebc18cbcc86a6ed37aa5189488"},"cell_type":"code","source":"print (os.listdir(os.getcwd()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b995ee37e2a934659c51eda42bddb4a3792f48de"},"cell_type":"code","source":"#Step 1: Dataset Exploration","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9e5bcb9c74b37875b6dab55c5b3176a869e447d"},"cell_type":"code","source":"print (\"\\ntotal number of datapoints : 891\")\nprint (\"\\nnumber of useful features available : 9\")\nprint (\"\\nname of the passenger is not used as a feature.\")\nprint (\"\\ncabin number has many missing values\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78e2893bd96017b18014867e469a46d6ffd99b0d"},"cell_type":"code","source":"#reading training dataset\nfeature_list=['PassengerId','Pclass','Name','Sex', 'Age','SibSp','Parch',\n                                                   'Ticket','Fare','Cabin','Embarked']\ndf_train_features=pd.read_csv(\"../input/train.csv\",usecols=feature_list)\ndf_train_labels=pd.read_csv(\"../input/train.csv\",usecols=['Survived'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"fae7297598724610b6589048ba6922f80cf17a1b"},"cell_type":"code","source":"df_train_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f0ba017d402a15609f6c449f8da586b46488ac3"},"cell_type":"code","source":"df_train_labels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8aa48edc563494b7dd5b89aed3a17998f9a5dfc"},"cell_type":"code","source":"#DATA PRE-PROCESSING\n\n#replacing 'male' with 1 and 'female' with 0 in the 'sex' column\ndf_train_features=df_train_features.replace('male',1)\ndf_train_features=df_train_features.replace('female',0)\n\n#extracting the numerical part of the ticket number\nc=5\nfor s in df_train_features.iloc[:,7]:\n    if isinstance(s,str):\n        value=[int(s) for s in s.split(' ') if s.isdigit()]\n        if (len(value)!=0):\n            tktnum=value[0]\n        else:\n            tktnum=-1\n        if (c>0):\n            c-=1\n        df_train_features=df_train_features.replace(s,tktnum)\n\n#In 'embarked' column, replacing 'S' by 1,'C' by 2 and 'Q' by 3\ndf_train_features=df_train_features.replace({\"S\":1,\"C\":2,\"Q\":3})\n\n#Extracting only the surnames\nfor s in df_train_features.iloc[:,2]:\n    if (len(s)!=0):\n        value=[s for s in s.split(',')]\n        surname=value[0]\n    df_train_features=df_train_features.replace(s,surname)\n\n#finding the list of unique surnames present and assigning them a numerical value\nls=df_train_features.Name.unique()\ndf_train_features=df_train_features.replace(ls,range(len(ls)))\n\n#For cases where a passenger has more than one cabin number, extra features will be added. \n#If a person has two cabins, then 4 features will be added. 2 for alpha. part and 2 for numerical part.    \n#splitting cabin number in two parts: cabin1 : contains the alphabetical part and cabin2 : contains the numerical part\n\n#first let us find the maximum number of cabins a passenger has.\nMax=0\nfor s in df_train_features.iloc[:,9]:\n    if isinstance(s,str):\n        value=[s for s in s.split(' ')]\n        if (Max<len(value)):\n            Max=len(value)\nprint ('maximum number of cabins a passenger has : ',Max)\n\n#now let us add the required number of features with default values for each row. Later on the value of a row will be changed as \n#'needed'\nx=range(Max)\nfor i in x:\n    df_train_features.loc[:,'ap'+str(i)]=-1\n    df_train_features.loc[:,'np'+str(i)]=-1\n    feature_list.append('ap'+str(i))\n    feature_list.append('np'+str(i))\n#now let us fill in the apprpriate values in these new columns\nap=11\nnp=12\nrowin=0\n\nfor s in df_train_features.iloc[:,9]:\n    if isinstance(s,str):\n        #print (s)\n        #print (type(s))\n        value=[s for s in s.split(' ')]\n        for cn in value:\n            #print (cn[0])\n            #print (cn[1:])\n            #print (ap)\n            df_train_features.iloc[rowin,ap]=ord(cn[0])\n            if (cn[1:]!=''):\n                df_train_features.iloc[rowin,np]=int(cn[1:])\n            else:\n                df_train_features.iloc[rowin,np]=-1\n            ap+=2\n            np+=2\n    ap=11\n    np=12\n    rowin+=1\n    \n            \n#finally removing the original 'cabin' column\ndf_train_features=df_train_features.drop(columns=['Cabin'])\n#removing from features list as well\ndel feature_list[feature_list.index('Cabin')]\n\n#replacing all the missing values in age column by mean age\nmean_age=df_train_features['Age'].mean()\ndf_train_features['Age']=df_train_features['Age'].fillna(mean_age)\n\n#there are two nan values present in 'Embarked' column. we are replacing it with median value\nmedian=df_train_features['Embarked'].median()\ndf_train_features['Embarked']=df_train_features['Embarked'].fillna(median)\n\n\n\n\n\n            \n            \n            \n\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"20a7f24c94285be97ad554b652ddd5e52b2a3407"},"cell_type":"code","source":"df_train_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab45e08be945e1682e41e9da41887ff59c5d7a21"},"cell_type":"code","source":"#Converting dataframe to numpy arrays for further use\nX=df_train_features.values\ny=df_train_labels.values\nprint (X.shape)\nprint (y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4b71080e5078ad737735be50a8f0f93401855a2"},"cell_type":"code","source":"#Step 2: OPTIMIZE FEATURE SELECTION/ENGINEERING","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77a207ea828fcd9d4bb5f4393614baa7b3c197ab"},"cell_type":"code","source":"#First, let us do feature scalling so that no feature gets more importance simply based on it's numerical value\n#feature scalling\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nX=scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"b9bdab4a9c7cf6b02ca8a6b142878074b37309fb"},"cell_type":"code","source":"X[0:5]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"200e667dd47bda26c8e1e490cf45624325d0f6d1"},"cell_type":"code","source":"print (y[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98d541d042a0a959ca3f24f47ad039553857e4a4"},"cell_type":"code","source":"len(y)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"85c8b6b7722c805c8e15fb8b36b321870e1cabc7"},"cell_type":"code","source":"new=[]\nfor i in y:\n    for j in i:\n        new.append(j)\nprint (new[:5])\ny=new","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"f03e7415d1eb33f5e186704ba4f971ce552b65d3"},"cell_type":"code","source":"#now let us find the importance of all features using selectkpercentile\nfrom sklearn.feature_selection import SelectPercentile, f_classif\nselector = SelectPercentile(f_classif, percentile=40)#highest accuracy .80 (approx.) from decision tree classifier\n#                                                                                                   at this percentile\nselector.fit(X,y)\nX_new=selector.transform(X)\nprint ('shape of X_new ',X_new.shape)\ntry:\n    X_points = range(X.shape[1])\nexcept IndexError:\n    X_points = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"991333078d4b5b11ec3dec6b94da781304a3ad23"},"cell_type":"code","source":"#checking out the scores of the features\nscore=selector.scores_.tolist()\nnames=list(df_train_features)\nnew=zip(names,score)\nfor i in new:\n    print (i[0],\" score = {:8.2f}\".format(i[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c763fb72a36a7c549cfa1f4a755570e64ac3407c"},"cell_type":"code","source":"plt.bar(X_points , selector.scores_, width=.2,\n        label=r'Univariate score ($-Log(p_{value})$)', color='darkorange',\n        edgecolor='black')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2424255720f5c1443c648f4c85cd1ed1942c61ab"},"cell_type":"code","source":"#STEP 3:Trying out a variety of classifiers and tuning them as well ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b02d9af47191472f4063099a42a49fb658af8479"},"cell_type":"code","source":"#Splitting data into training and testing set\nfrom sklearn.cross_validation import train_test_split\nfeatures_train, features_test, labels_train, labels_test = train_test_split(X_new, y, test_size=0.30, random_state=42)\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b71015fdcff857767d292b1680757c956908621b"},"cell_type":"code","source":"#Trial 1: Decision Tree Classifier \n\nfrom sklearn.tree import DecisionTreeClassifier\n\nparameters={'criterion':('gini','entropy'),'splitter':('best','random')}\ndtc = DecisionTreeClassifier()\nclf=GridSearchCV(dtc,parameters)\n\nclf.fit(features_train, labels_train)\n\nprint(\"Best estimator found by grid search:\")\nprint(clf.best_estimator_)\npred=clf.predict(features_test)\nprint (\"\\naccuracy_score : \",accuracy_score(labels_test,pred))\nprint ('\\nprecision : \\n',precision_score(labels_test,pred))\nprint ('\\nrecall : \\n',recall_score(labels_test,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39ccd0259121eb89d5309f12bb5aaa6cd736bf5b"},"cell_type":"code","source":"#Trial 2: SVC\nfrom sklearn.svm import SVC\n\nparameters={'C':(0.1,1,10,100),'kernel':('linear','rbf','poly')}\nsvc=SVC()\nclf=GridSearchCV(svc,parameters)\n\nclf.fit(features_train, labels_train)\n\nprint(\"Best estimator found by grid search:\")\nprint(clf.best_estimator_)\npred=clf.predict(features_test)\nprint (\"\\naccuracy_score : \",accuracy_score(labels_test,pred))\nprint ('\\nprecision : \\n',precision_score(labels_test,pred))\nprint ('\\nrecall : \\n',recall_score(labels_test,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6292388375860b4ffcca7a7ba53c292782ae40e2"},"cell_type":"code","source":"#Trial 3: Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\n\nclf = GaussianNB()\nclf.fit(features_train, labels_train)\n\npred=clf.predict(features_test)\nprint (\"\\naccuracy_score : \",accuracy_score(labels_test,pred))\nprint ('\\nprecision : \\n',precision_score(labels_test,pred))\nprint ('\\nrecall : \\n',recall_score(labels_test,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9cb959a0f57d6ccb995f347acac2534c13757bd"},"cell_type":"code","source":"#Now that we've got our final trained algorithm DTC, we we'll retrain it again.\n#This time with the entire training dataset.\nsvc = SVC(C=100,kernel='linear')\nsvc.fit(X_new, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08a050b9672cd42251bd1ffacd58427eb117656c"},"cell_type":"code","source":"#now let us import data from test file and predict the survival\nfeature_list=['PassengerId','Pclass','Name','Sex', 'Age','SibSp','Parch',\n                                                   'Ticket','Fare','Cabin','Embarked']\ndf_test_features=pd.read_csv(\"../input/test.csv\",usecols=feature_list)\n\n#data-preprocessing\n#DATA PRE-PROCESSING\n\n#replacing 'male' with 1 and 'female' with 0 in the 'sex' column\ndf_test_features=df_test_features.replace('male',1)\ndf_test_features=df_test_features.replace('female',0)\n\n#extracting the numerical part of the ticket number\nc=5\nfor s in df_test_features.iloc[:,7]:\n    if isinstance(s,str):\n        value=[int(s) for s in s.split(' ') if s.isdigit()]\n        if (len(value)!=0):\n            tktnum=value[0]\n        else:\n            tktnum=-1\n        if (c>0):\n            c-=1\n        df_test_features=df_test_features.replace(s,tktnum)\n\n#In 'embarked' column, replacing 'S' by 1,'C' by 2 and 'Q' by 3\ndf_test_features=df_test_features.replace({\"S\":1,\"C\":2,\"Q\":3})\n\n#Extracting only the surnames\nfor s in df_test_features.iloc[:,2]:\n    if (len(s)!=0):\n        value=[s for s in s.split(',')]\n        surname=value[0]\n    df_test_features=df_test_features.replace(s,surname)\n\n#finding the list of unique surnames present and assigning them a numerical value\nls=df_test_features.Name.unique()\ndf_test_features=df_test_features.replace(ls,range(len(ls)))\n\n#For cases where a passenger has more than one cabin number, extra features will be added. \n#If a person has two cabins, then 4 features will be added. 2 for alpha. part and 2 for numerical part.    \n#splitting cabin number in two parts: cabin1 : contains the alphabetical part and cabin2 : contains the numerical part\n\n#first let us find the maximum number of cabins a passenger has.\nMax=0\nfor s in df_test_features.iloc[:,9]:\n    if isinstance(s,str):\n        value=[s for s in s.split(' ')]\n        if (Max<len(value)):\n            Max=len(value)\nprint ('maximum number of cabins a passenger has : ',Max)\n\n#now let us add the required number of features with default values for each row. Later on the value of a row will be changed as \n#'needed'\nx=range(Max)\nfor i in x:\n    df_test_features.loc[:,'ap'+str(i)]=-1\n    df_test_features.loc[:,'np'+str(i)]=-1\n    feature_list.append('ap'+str(i))\n    feature_list.append('np'+str(i))\n#now let us fill in the apprpriate values in these new columns\nap=11\nnp=12\nrowin=0\n\nfor s in df_test_features.iloc[:,9]:\n    if isinstance(s,str):\n        #print (s)\n        #print (type(s))\n        value=[s for s in s.split(' ')]\n        for cn in value:\n            #print (cn[0])\n            #print (cn[1:])\n            #print (ap)\n            df_test_features.iloc[rowin,ap]=ord(cn[0])\n            if (cn[1:]!=''):\n                df_test_features.iloc[rowin,np]=int(cn[1:])\n            else:\n                df_test_features.iloc[rowin,np]=-1\n            ap+=2\n            np+=2\n    ap=11\n    np=12\n    rowin+=1\n    \n            \n#finally removing the original 'cabin' column\ndf_test_features=df_test_features.drop(columns=['Cabin'])\n#removing from features list as well\ndel feature_list[feature_list.index('Cabin')]\n\n#replacing all the missing values in age column by mean age\nmean_age=df_test_features['Age'].mean()\ndf_test_features['Age']=df_test_features['Age'].fillna(mean_age)\n\n#there are two nan values present in 'Embarked' column. we are replacing it with median value\nmedian=df_test_features['Embarked'].median()\ndf_test_features['Embarked']=df_test_features['Embarked'].fillna(median)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7555507f89433a6e0ace536fa967135ab682d97"},"cell_type":"code","source":"#checking for any NAN values left\nl=[]\nfor i in feature_list:\n    x=df_test_features[i].isnull().sum().sum()\n    if x>0:\n        print (x)\n        l.append(i)\nfor i in l:\n    print (i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fb1135b0c9e6a78ada4f4b4083703f5f6a7b0b6"},"cell_type":"code","source":"avg_fare=df_test_features['Fare'].mean()\ndf_test_features['Fare']=df_test_features['Fare'].fillna(avg_fare)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57889e8a900bc4af7ceb837cb8ddbb422ee44694"},"cell_type":"code","source":"X=df_test_features.values\nprint (X.shape)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"ce9f23f3127e9f76c2cff6519e5e9278422c150b"},"cell_type":"code","source":"#Converting dataframe to numpy arrays for further use\n\n\n#First, let us do feature scalling so that no feature gets more importance simply based on it's numerical value\n#feature scalling\nfrom sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nX=scaler.fit_transform(X)\n\n#using previously selected features\nX_new=selector.transform(X)\nprint ('shape of X_new ',X_new.shape)\ntry:\n    X_points = range(X.shape[1])\nexcept IndexError:\n    X_points = 1\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31c0aadc78e7179bd3b6f432a00acb22a5e2d13c"},"cell_type":"code","source":"# Decision Tree Classifier \n\npred=svc.predict(X_new)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"fadd6dddca04b3cf17d6adb6ab8289af4e52a3e8"},"cell_type":"code","source":"print (pred.shape)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"ab55440b8fa44a9353848ff289f1268ce515142a"},"cell_type":"code","source":"x =range(892,1310)\n#creating the submission file\nsubmission=pd.DataFrame({'PassengerId':x,'Survived':pred})\nsubmission.to_csv(path_or_buf='submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15fab5a0c349a94b5546e9b0c276de504fe838fa"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}