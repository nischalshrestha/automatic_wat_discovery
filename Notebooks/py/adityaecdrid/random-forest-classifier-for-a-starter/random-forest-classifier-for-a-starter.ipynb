{"cells":[{"metadata":{"_cell_guid":"99db660a-119b-4720-b7db-7e3ebbb80d80","_uuid":"d390300d4c49a69634911ae2f56d770cac96c232","_execution_state":"idle","collapsed":true,"trusted":false},"cell_type":"code","source":"# Imports\n\n# pandas\nimport pandas as pd\nfrom pandas import Series,DataFrame\n\n# numpy, matplotlib, seaborn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"29d2c2ce-cb68-40fc-928e-60af3b8c8958","_uuid":"39f37ec345fdabbc16e109345a1ae5b591bbddc0","collapsed":true,"trusted":false},"cell_type":"code","source":"# get titanic & test csv files as a DataFrame\ntitanic_df = pd.read_csv(\"../input/train.csv\")\ntest_df    = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b3d18fa2-bab7-4a8c-89c5-a7f57a7b808b","_uuid":"07b7d5f4d5ac989164ddec4d7ca05cf29677d8db","trusted":false,"collapsed":true},"cell_type":"code","source":"# preview the data\ntitanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d6d425da-9c2d-4de3-94c7-9d83b236a814","_uuid":"385207a7ae040a51fe47e38bee31f58fefe26ef2","trusted":false,"collapsed":true},"cell_type":"code","source":"print(titanic_df.info())\nprint(\"----------------------------\")\nprint(test_df.info())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8342ac2c-a07c-495f-bec4-30acf480a6ab","_uuid":"835f484bb1c50eb4c193604bb49ddbf4afcb2e6e","collapsed":true,"trusted":false},"cell_type":"code","source":"# drop unnecessary columns, these columns won't be useful in analysis and prediction\ntitanic_df = titanic_df.drop(['PassengerId','Name','Ticket'], axis=1)\ntest_df    = test_df.drop(['Name','Ticket'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6b9f0b1b-cf91-400a-8cc4-180b502f4390","_uuid":"ac3845694f67af7e85367422c759496d37b65244","trusted":false,"collapsed":true},"cell_type":"code","source":"# Embarked\n\n# only in titanic_df, fill the two missing values with the most occurred value, which is \"S\".\ntitanic_df[\"Embarked\"] = titanic_df[\"Embarked\"].fillna(\"S\")\n\n# plot\nsns.factorplot('Embarked','Survived', data=titanic_df,size=4,aspect=3)\n\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(15,5))\n\nsns.countplot(x='Embarked', data=titanic_df, ax=axis1)\nsns.countplot(x='Survived', hue=\"Embarked\", data=titanic_df, order=[1,0], ax=axis2)\n\n# group by embarked, and get the mean for survived passengers for each value in Embarked\nembark_perc = titanic_df[[\"Embarked\", \"Survived\"]].groupby(['Embarked'],as_index=False).mean()\nsns.barplot(x='Embarked', y='Survived', data=embark_perc,order=['S','C','Q'],ax=axis3)\n\n# Either to consider Embarked column in predictions,\n# and remove \"S\" dummy variable, \n# and leave \"C\" & \"Q\", since they seem to have a good rate for Survival.\n\n# OR, don't create dummy variables for Embarked column, just drop it, \n# because logically, Embarked doesn't seem to be useful in prediction.\n\nembark_dummies_titanic  = pd.get_dummies(titanic_df['Embarked'])\nembark_dummies_titanic.drop(['S'], axis=1, inplace=True)\n\nembark_dummies_test  = pd.get_dummies(test_df['Embarked'])\nembark_dummies_test.drop(['S'], axis=1, inplace=True)\n\ntitanic_df = titanic_df.join(embark_dummies_titanic)\ntest_df    = test_df.join(embark_dummies_test)\n\ntitanic_df.drop(['Embarked'], axis=1,inplace=True)\ntest_df.drop(['Embarked'], axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e8d6cb8e-dd37-4856-a9c8-13062bb04c5c","_uuid":"44b111e103736c3f7207b9ad44fcb372319d2db2","trusted":false,"collapsed":true},"cell_type":"code","source":"# Fare\n# only for test_df, since there is a missing \"Fare\" values\ntest_df[\"Fare\"].fillna(test_df[\"Fare\"].mean(), inplace=True)\n\n# convert from float to int\ntitanic_df['Fare'] = titanic_df['Fare'].astype(int)\ntest_df['Fare']    = test_df['Fare'].astype(int)\n\n# get fare for survived & didn't survive passengers \nfare_not_survived = titanic_df[\"Fare\"][titanic_df[\"Survived\"] == 0]\nfare_survived     = titanic_df[\"Fare\"][titanic_df[\"Survived\"] == 1]\n\n# get average and std for fare of survived/not survived passengers\navgerage_fare = DataFrame([fare_not_survived.mean(), fare_survived.mean()])\nstd_fare      = DataFrame([fare_not_survived.std(), fare_survived.std()])\n\n# plot\ntitanic_df['Fare'].plot(kind='hist', figsize=(15,3),bins=100, xlim=(0,50))\n\navgerage_fare.index.names = std_fare.index.names = [\"Survived\"]\navgerage_fare.plot(yerr=std_fare,kind='bar',legend=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fdc1708f-5fbd-4f25-a2d3-191a84e66a29","_uuid":"fd58413b3fdfe7e8b4454c52822af1a1cc32d8d7","collapsed":true,"trusted":false},"cell_type":"code","source":"# Cabin\n# It has a lot of NaN values, so it won't cause a remarkable impact on prediction in this simple model\ntitanic_df.drop(\"Cabin\",axis=1,inplace=True)\ntest_df.drop(\"Cabin\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"088600e9-ca97-4dc0-b776-86f8e840ef85","_uuid":"0225a6a73f121a5244e812501e5fe66b8d8384e9","trusted":false,"collapsed":true},"cell_type":"code","source":"# Age \n# get average, std, and number of NaN values in titanic_df\naverage_age_titanic   = titanic_df[\"Age\"].mean()\nstd_age_titanic       = titanic_df[\"Age\"].std()\ncount_nan_age_titanic = titanic_df[\"Age\"].isnull().sum()\n\n# get average, std, and number of NaN values in test_df\naverage_age_test   = test_df[\"Age\"].mean()\nstd_age_test       = test_df[\"Age\"].std()\ncount_nan_age_test = test_df[\"Age\"].isnull().sum()\n\n# generate random numbers between (mean - std) & (mean + std)\nrand_1 = np.random.randint(average_age_titanic - std_age_titanic, average_age_titanic + std_age_titanic, size = count_nan_age_titanic)\nrand_2 = np.random.randint(average_age_test - std_age_test, average_age_test + std_age_test, size = count_nan_age_test)\n\n# drop all null values, and convert to int\ntitanic_df['Age'].dropna().astype(int)\n# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)\n\n# fill NaN values in Age column with random values generated\ntitanic_df[\"Age\"][np.isnan(titanic_df[\"Age\"])] = rand_1\ntest_df[\"Age\"][np.isnan(test_df[\"Age\"])] = rand_2\n\n# convert from float to int\ntitanic_df['Age'] = titanic_df['Age'].astype(int)\ntest_df['Age']    = test_df['Age'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cdfb5464-2f89-4dc4-872c-d429dcf4b8f2","_uuid":"14e53e412fe95b255c4c66f07bacdcaa70ad7dd9","trusted":false,"collapsed":true},"cell_type":"code","source":"# Sex\n\n# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.\n# So, we can classify passengers as males, females, and child\ndef get_person(passenger):\n    age,sex = passenger\n    return 'child' if age < 16 else sex\n    \ntitanic_df['Person'] = titanic_df[['Age','Sex']].apply(get_person,axis=1)\ntest_df['Person']    = test_df[['Age','Sex']].apply(get_person,axis=1)\n\n# No need to use Sex column since we created Person column\ntitanic_df.drop(['Sex'],axis=1,inplace=True)\ntest_df.drop(['Sex'],axis=1,inplace=True)\n\n# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers\nperson_dummies_titanic  = pd.get_dummies(titanic_df['Person'])\nperson_dummies_titanic.columns = ['Child','Female','Male']\nperson_dummies_titanic.drop(['Male'], axis=1, inplace=True)\n\nperson_dummies_test  = pd.get_dummies(test_df['Person'])\nperson_dummies_test.columns = ['Child','Female','Male']\nperson_dummies_test.drop(['Male'], axis=1, inplace=True)\n\ntitanic_df = titanic_df.join(person_dummies_titanic)\ntest_df    = test_df.join(person_dummies_test)\n\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(10,5))\n\nsns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)\n#sns.countplot(x='Person', data=titanic_df, ax=axis1)\n\n# average of survived for each Person(male, female, or child)\nperson_perc = titanic_df[[\"Person\", \"Survived\"]].groupby(['Person'],as_index=False).mean()\nsns.barplot(x='Person', y='Survived', data=person_perc, ax=axis2, order=['male','female','child'])\n\ntitanic_df.drop(['Person'],axis=1,inplace=True)\ntest_df.drop(['Person'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"20d906f4-4450-4037-b466-d3d31da10479","_uuid":"01285817befba9347f29c4f5912b62f53367233a","collapsed":true,"trusted":false},"cell_type":"code","source":"# define training and testing sets\n\nX_train = titanic_df.drop(\"Survived\",axis=1)\nY_train = titanic_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\",axis=1).copy()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8a882725-e7c4-432b-9e4e-659de4600303","_uuid":"46f5bbf67834889b41c707137c3c6f49f57af950","trusted":false,"collapsed":true},"cell_type":"code","source":"# Logistic Regression\n\nlogreg = LogisticRegression()\n\nlogreg.fit(X_train, Y_train)\n\nY_pred = logreg.predict(X_test)\n\nlogreg.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fb5babf3-8937-4db7-b120-b742e14da44f","_uuid":"74150267911cd39f786ebfd86d553fee902ebc9c","trusted":false,"collapsed":true},"cell_type":"code","source":"#Support Vector Machines\n\nsvc = SVC()\n\nsvc.fit(X_train, Y_train)\n\nY_pred = svc.predict(X_test)\n\nsvc.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"27476379-e949-4480-a282-8138c8f04580","_uuid":"9bc380c6ccbed68592e8e708c9fb45c14915680a","trusted":false,"collapsed":true},"cell_type":"code","source":"# Random Forests\n\nrandom_forest = RandomForestClassifier(n_estimators=100,oob_score=True,max_features=5)\n\nrandom_forest.fit(X_train, Y_train)\n\nY_pred = random_forest.predict(X_test)\n\nrandom_forest.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"814d095d-1780-4c0e-bf0e-0caef25a46ee","_uuid":"a62a8ae6baac52c88b34a8c5ec83cb85589f59b5","trusted":false,"collapsed":true},"cell_type":"code","source":"random_forest.get_params,random_forest.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ef553cf8-e958-4029-979c-52ef181c7153","_uuid":"894860dbf49f2cf1e7c63b230d5b228db2ace9c0","trusted":false,"collapsed":true},"cell_type":"code","source":"# Gradient Boosts\ngrad_boost = GradientBoostingClassifier(n_estimators=1000)\ngrad_boost.fit(X_train, Y_train)\nY_pred = grad_boost.predict(X_test)\ngrad_boost.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"46d42b4d-88c0-41db-868e-2f6466e5284a","_uuid":"bcb6ca9da42e0f6647a2e87d4f4ce157de16af13","trusted":false,"collapsed":true},"cell_type":"code","source":"# get Correlation Coefficient for each feature using Logistic Regression\ncoeff_df = DataFrame(titanic_df.columns.delete(0))\ncoeff_df.columns = ['Features']\ncoeff_df[\"Coefficient Estimate\"] = pd.Series(logreg.coef_[0])\n\n# preview\ncoeff_df","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"12b2eed7-68c5-48ca-9c19-3d4301ea4ca8","_uuid":"3974e5e4ec2681fd99f42e6b5a730d44ab84dbd2","collapsed":true,"trusted":false},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('titanic.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","version":"3.6.4","mimetype":"text/x-python","pygments_lexer":"ipython3","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}