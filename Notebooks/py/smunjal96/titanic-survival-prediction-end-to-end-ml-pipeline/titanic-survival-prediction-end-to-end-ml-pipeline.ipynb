{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ac51b485-dd2c-42d6-1063-30f13cf3447b",
        "_active": false
      },
      "source": "## Introduction\n\n**_Poonam Ligade_**\n\n*27th Dec 2016*\n\nI am are trying to find out how many people on titanic survived from disaster.\n\nHere goes Titanic Survival Prediction End to End ML Pipeline  \n\n 1) **Introduction**\n\n 1. Import Libraries\n 2. Load data\n 3. Run Statistical summeries\n 4. Figure out missing value columns\n\n \n \n2) **Visualizations**\n\n 1. Correlation with target variable\n\n\n3) **Missing values imputation**\n\n 1. train data Missing columns- Embarked,Age,Cabin\n 2. test data Missing columns- Age and Fare\n \n\n4) **Feature Engineering**\n\n 1. Calculate total family size\n 2. Get title from name\n 3. Find out which deck passenger belonged to\n 4. Dealing with Categorical Variables\n     * Label encoding\n 5. Feature Scaling\n\n\n5) **Prediction**\n\n 1. Split into training & test sets\n 2. Build the model\n 3. Feature importance\n 4. Predictions\n 5. Ensembling : Majority voting\n\n6) **Submission**",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b08fc249-4282-b9df-caf1-8812ccc3c88a",
        "_active": false
      },
      "source": "Import libraries\n================",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ca368e06-2fa2-9a36-1193-72f7a9c752f2",
        "_active": false
      },
      "outputs": [],
      "source": "# We can use the pandas library in python to read in the csv file.\nimport pandas as pd\n#for numerical computaions we can use numpy library\nimport numpy as np",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "41422d21-5c02-9fd3-c2fb-6a3de9f5e6a0",
        "_active": false
      },
      "source": "Load train & test data\n======================",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e4ab5e1b-0da0-3d9e-b53e-79a17633ca0b",
        "_active": false
      },
      "outputs": [],
      "source": "# This creates a pandas dataframe and assigns it to the titanic variable.\ntitanic = pd.read_csv(\"../input/train.csv\")\n# Print the first 5 rows of the dataframe.\ntitanic.head()",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b258ce7d-c480-28aa-edca-7cc1fedc2bd3",
        "_active": false
      },
      "outputs": [],
      "source": "titanic_test = pd.read_csv(\"../input/test.csv\")\n#transpose\ntitanic_test.head().T\n#note their is no Survived column here which is our target varible we are trying to predict",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cf2a8459-1472-09c1-7c52-0a94f4b07561",
        "_active": false
      },
      "outputs": [],
      "source": "#shape command will give number of rows/samples/examples and number of columns/features/predictors in dataset\n#(rows,columns)\ntitanic.shape",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5426fa8f-0323-33c4-f16b-13bece60f111",
        "_active": false
      },
      "outputs": [],
      "source": "#Describe gives statistical information about numerical columns in the dataset\ntitanic.describe()\n#you can check from count if there are missing vales in columns, here age has got missing values",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e3ecec9e-b1b6-f16a-9e1f-81f100e3ec85",
        "_active": false
      },
      "outputs": [],
      "source": "#info method provides information about dataset like \n#total values in each column, null/not null, datatype, memory occupied etc\ntitanic.info()",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1f252150-c25f-ca25-e981-116fcdd18afc",
        "_active": false
      },
      "outputs": [],
      "source": "#lets see if there are any more columns with missing values \ntitanic.isnull().sum()",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "acd3b9aa-6d66-f572-05fe-85f9c11ba8a8",
        "_active": false
      },
      "source": "**yes even Embarked and cabin has missing values.**",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "45ef8d0c-e417-b9d5-df59-8af551bc9b22",
        "_active": false
      },
      "outputs": [],
      "source": "#how about test set??\ntitanic_test.isnull().sum()",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8e9ebd25-beb4-1cae-31a9-6dec5ad2fba5",
        "_active": false
      },
      "source": "**Age, Fare and cabin has missing values.\nwe will see how to fill missing values next.**",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0cecf155-c3de-71b4-8438-a607071892dc",
        "_active": false
      },
      "source": "Visualizations\n==============",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7ab94597-9a8d-513f-0a57-22ba0568b1e0",
        "_active": false,
        "collapsed": false
      },
      "outputs": [],
      "source": "%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(font_scale=1)\n\npd.options.display.mpl_style = 'default'\ntitanic.hist(bins=10,figsize=(9,7),grid=False)",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5fd08b45-dcef-0c2e-853c-7e739a67b8f7",
        "_active": false
      },
      "source": "**we can see that Age and Fare are measured on very different scaling. So we need to do feature scaling before predictions.**",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6475eac5-337b-b723-6917-613bf61e438c",
        "_active": false
      },
      "outputs": [],
      "source": "g = sns.FacetGrid(titanic, col=\"Sex\", row=\"Survived\", margin_titles=True)\ng.map(plt.hist, \"Age\",color=\"purple\")",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "71adfcb6-e71d-60bc-a0d3-ee4ff1c9c404",
        "_active": false
      },
      "outputs": [],
      "source": "g = sns.FacetGrid(titanic, hue=\"Survived\", col=\"Pclass\", margin_titles=True,\n                  palette={1:\"seagreen\", 0:\"gray\"})\ng=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9bfbe633-b249-e7cb-2fde-4ec2b9097b3f",
        "_active": false
      },
      "outputs": [],
      "source": "g = sns.FacetGrid(titanic, hue=\"Survived\", col=\"Sex\", margin_titles=True,\n                palette=\"Set1\",hue_kws=dict(marker=[\"^\", \"v\"]))\ng.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\nplt.subplots_adjust(top=0.8)\ng.fig.suptitle('Survival by Gender , Age and Fare')",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "551673fc-d91a-623a-41f0-5eebe3567ce1",
        "_active": false
      },
      "outputs": [],
      "source": "titanic.Embarked.value_counts().plot(kind='bar', alpha=0.55)\nplt.title(\"Passengers per boarding location\")",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3d4403b1-daef-2333-5d89-276f25444316",
        "_active": false
      },
      "outputs": [],
      "source": "sns.factorplot(x = 'Embarked',y=\"Survived\", data = titanic,color=\"r\")",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c496b777-ca8e-5b3c-af76-5ad8d63b7c95",
        "_active": false
      },
      "outputs": [],
      "source": "sns.set(font_scale=1)\ng = sns.factorplot(x=\"Sex\", y=\"Survived\", col=\"Pclass\",\n                    data=titanic, saturation=.5,\n                    kind=\"bar\", ci=None, aspect=.6)\n(g.set_axis_labels(\"\", \"Survival Rate\")\n    .set_xticklabels([\"Men\", \"Women\"])\n    .set_titles(\"{col_name} {col_var}\")\n    .set(ylim=(0, 1))\n    .despine(left=True))  \nplt.subplots_adjust(top=0.8)\ng.fig.suptitle('How many Men and Women Survived by Passenger Class')",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9b046b29-4116-da22-18df-36b7459e68a1",
        "_active": false
      },
      "outputs": [],
      "source": "ax = sns.boxplot(x=\"Survived\", y=\"Age\", \n                data=titanic)\nax = sns.stripplot(x=\"Survived\", y=\"Age\",\n                   data=titanic, jitter=True,\n                   edgecolor=\"gray\")\nsns.plt.title(\"Survival by Age\",fontsize=12)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2ab7ea3f-ec34-0419-6ac0-b20379a25a49",
        "_active": false
      },
      "outputs": [],
      "source": "titanic.Age[titanic.Pclass == 1].plot(kind='kde')    \ntitanic.Age[titanic.Pclass == 2].plot(kind='kde')\ntitanic.Age[titanic.Pclass == 3].plot(kind='kde')\n # plots an axis lable\nplt.xlabel(\"Age\")    \nplt.title(\"Age Distribution within classes\")\n# sets our legend for our graph.\nplt.legend(('1st Class', '2nd Class','3rd Class'),loc='best') ",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2937ff19-58b1-e044-1254-b5b00e87496c",
        "_active": false
      },
      "outputs": [],
      "source": "corr=titanic.corr()#[\"Survived\"]\nplt.figure(figsize=(10, 10))\n\nsns.heatmap(corr, vmax=1, square=True,annot=True,cmap='cubehelix')\nplt.title('Correlation between features')",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c1206942-e525-d6fc-e47b-0c1bfd5de79c",
        "_active": false
      },
      "outputs": [],
      "source": "#correlation of features with target variable\ntitanic.corr()[\"Survived\"]",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c7dd332b-d578-a4c2-6b7a-86412f4da80d",
        "_active": false
      },
      "source": "**Looks like Pclass has got highest negative correlation with \"Survived\" followed by Fare, Parch and Age** ",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b287eec7-bcdb-c034-9246-d07e806d3b40",
        "_active": false
      },
      "outputs": [],
      "source": "g = sns.factorplot(x=\"Age\", y=\"Embarked\",\n                    hue=\"Sex\", row=\"Pclass\",\n                    data=titanic[titanic.Embarked.notnull()],\n                    orient=\"h\", size=2, aspect=3.5, \n                   palette={'male':\"purple\", 'female':\"blue\"},\n                    kind=\"violin\", split=True, cut=0, bw=.2)",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "db0d041c-8f3a-bc68-42fb-1c8fd6a5addf",
        "_active": false
      },
      "source": "Missing Value Imputation\n========================\n\n**Its important to fill missing values, because some machine learning algorithms can't accept them eg SVM.**\n\n*But filling missing values with mean/median/mode is also a prediction which may not be 100% accurate, instead you can use models like Decision Trees and Random Forest which handle missing values very well.*",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7e9f9bac-8e0b-d2b9-4d6d-164266d6f237",
        "_active": false
      },
      "source": "**Embarked Column**",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9cef6611-7c95-8a85-0bba-3074e80e46ad",
        "_active": false
      },
      "outputs": [],
      "source": "#Lets check which rows have null Embarked column\ntitanic[titanic['Embarked'].isnull()]",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "882ac871-7370-9b1f-c4c3-f2bb96e6c484",
        "_active": false
      },
      "source": "**PassengerId 62 and 830** have missing embarked values\n\nBoth have ***Passenger class 1*** and ***fare $80.***\n\nLets plot a graph to visualize and try to guess from where they embarked",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "258a79df-363e-3f98-233d-e0be38decdc7",
        "_active": false
      },
      "outputs": [],
      "source": "sns.boxplot(x=\"Embarked\", y=\"Fare\", hue=\"Pclass\", data=titanic)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0246b387-93c3-fd51-4263-034d1580b774",
        "_active": false
      },
      "outputs": [],
      "source": "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna('C')",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7dc1044b-d0bb-91e3-8254-22f35a88dbb1",
        "_active": false
      },
      "source": "We can see that for ***1st class*** median line is coming around ***fare $80*** for ***embarked*** value ***'C'***.\nSo we can replace NA values in Embarked column with 'C'",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ba29dd0b-2809-6dfe-311b-fbf36f649691",
        "_active": false
      },
      "outputs": [],
      "source": "#there is an empty fare column in test set\ntitanic_test.describe()",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ef40043e-b71a-55a4-6d76-bb153ee46167",
        "_active": false
      },
      "source": "***Fare Column***",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b12ef788-b106-65b3-4c41-b9074037ccf5",
        "_active": false
      },
      "outputs": [],
      "source": "titanic_test[titanic_test['Fare'].isnull()]",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bdc9992f-8505-c75c-e851-b9ee44028338",
        "_active": false
      },
      "outputs": [],
      "source": "#we can replace missing value in fare by taking median of all fares of those passengers \n#who share 3rd Passenger class and Embarked from 'S' \ndef fill_missing_fare(df):\n    median_fare=df[(df['Pclass'] == 3) & (df['Embarked'] == 'S')]['Fare'].median()\n#'S'\n       #print(median_fare)\n    df[\"Fare\"] = df[\"Fare\"].fillna(median_fare)\n    return df\n\ntitanic_test=fill_missing_fare(titanic_test)",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5233c2f0-2516-47ca-28e6-b95a5ffaed4b",
        "_active": false
      },
      "source": "Feature Engineering\n===================",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4556983b-1b5a-3443-0eba-f72131ec9f5a",
        "_active": false
      },
      "source": "***Deck- Where exactly were passenger on the ship?***",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d063ebb6-4ad3-5669-fd20-eda5a80d4ab1",
        "_active": false
      },
      "outputs": [],
      "source": "titanic[\"Deck\"]=titanic.Cabin.str[0]\ntitanic_test[\"Deck\"]=titanic_test.Cabin.str[0]\ntitanic[\"Deck\"].unique() # 0 is for null values",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d7107678-4293-5996-9dbd-16e3ba1d39d1",
        "_active": false
      },
      "outputs": [],
      "source": "g = sns.factorplot(\"Survived\", col=\"Deck\", col_wrap=4,\n                    data=titanic[titanic.Deck.notnull()],\n                    kind=\"count\", size=2.5, aspect=.8)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "313b4c34-73aa-be03-e88b-81de3d089b80",
        "_active": false
      },
      "outputs": [],
      "source": "titanic = titanic.assign(Deck=titanic.Deck.astype(object)).sort(\"Deck\")\ng = sns.FacetGrid(titanic, col=\"Pclass\", sharex=False,\n                  gridspec_kws={\"width_ratios\": [5, 3, 3]})\ng.map(sns.boxplot, \"Deck\", \"Age\");",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e18f90fe-d145-9ca1-f309-b8d256ae500e",
        "_active": false
      },
      "outputs": [],
      "source": "titanic.Deck.fillna('Z', inplace=True)\ntitanic_test.Deck.fillna('Z', inplace=True)\ntitanic[\"Deck\"].unique() # Z is for null values",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4e74d0c4-2165-90be-bdf0-17e81d180dd4",
        "_active": false
      },
      "source": "***How Big is your family?***",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aa04d676-b171-a229-c235-e68b2cd4c394",
        "_active": false
      },
      "outputs": [],
      "source": "# Create a family size variable including the passenger themselves\ntitanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]+1\ntitanic_test[\"FamilySize\"] = titanic_test[\"SibSp\"] + titanic_test[\"Parch\"]+1\nprint(titanic[\"FamilySize\"].value_counts())",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d0f690fd-b09e-2e3b-43dd-02818c06c6f9",
        "_active": false
      },
      "outputs": [],
      "source": "# Discretize family size\ntitanic.loc[titanic[\"FamilySize\"] == 1, \"FsizeD\"] = 'singleton'\ntitanic.loc[(titanic[\"FamilySize\"] > 1)  &  (titanic[\"FamilySize\"] < 5) , \"FsizeD\"] = 'small'\ntitanic.loc[titanic[\"FamilySize\"] >4, \"FsizeD\"] = 'large'\n\ntitanic_test.loc[titanic_test[\"FamilySize\"] == 1, \"FsizeD\"] = 'singleton'\ntitanic_test.loc[(titanic_test[\"FamilySize\"] >1) & (titanic_test[\"FamilySize\"] <5) , \"FsizeD\"] = 'small'\ntitanic_test.loc[titanic_test[\"FamilySize\"] >4, \"FsizeD\"] = 'large'\nprint(titanic[\"FsizeD\"].unique())\nprint(titanic[\"FsizeD\"].value_counts())",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dfb39182-d1e1-1a96-68dc-60728687a548",
        "_active": false
      },
      "outputs": [],
      "source": "sns.factorplot(x=\"FsizeD\", y=\"Survived\", data=titanic)",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2f29644d-d862-c207-9699-cba9dc2917d1",
        "_active": false
      },
      "source": "***Do you have longer names?***",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e10d62f7-c270-01c1-3d09-605b995bba80",
        "_active": false
      },
      "outputs": [],
      "source": "#Create feture for length of name \n# The .apply method generates a new series\ntitanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))\n\ntitanic_test[\"NameLength\"] = titanic_test[\"Name\"].apply(lambda x: len(x))\n#print(titanic[\"NameLength\"].value_counts())\n'''\ntitanic.loc[titanic[\"NameLength\"]>37 , \"NlengthD\"] = 'long'\ntitanic.loc[titanic[\"NameLength\"]<38 , \"NlengthD\"] = 'short'\n\ntitanic_test.loc[titanic_test[\"NameLength\"]>37 , \"NlengthD\"] = 'long'\ntitanic_test.loc[titanic_test[\"NameLength\"]<38 , \"NlengthD\"] = 'short'\n'''\n\nbins = [0, 20, 40, 57, 85]\ngroup_names = ['short', 'okay', 'good', 'long']\ntitanic['NlengthD'] = pd.cut(titanic['NameLength'], bins, labels=group_names)\ntitanic_test['NlengthD'] = pd.cut(titanic_test['NameLength'], bins, labels=group_names)\n\nsns.factorplot(x=\"NlengthD\", y=\"Survived\", data=titanic)\nprint(titanic[\"NlengthD\"].unique())",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "39368ec9-a8be-b5d1-b208-b8674a4be8f8",
        "_active": false
      },
      "source": "***Whats in the name?***",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "179a8eb2-e927-92fa-e33f-57215c5cb2b9",
        "_active": false
      },
      "outputs": [],
      "source": "import re\n\n#A function to get the title from a name.\ndef get_title(name):\n    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    #If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\n#Get all the titles and print how often each one occurs.\ntitles = titanic[\"Name\"].apply(get_title)\nprint(pd.value_counts(titles))\n\n\n#Add in the title column.\ntitanic[\"Title\"] = titles\n\n# Titles with very low cell counts to be combined to \"rare\" level\nrare_title = ['Dona', 'Lady', 'Countess','Capt', 'Col', 'Don', \n                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']\n\n# Also reassign mlle, ms, and mme accordingly\ntitanic.loc[titanic[\"Title\"] == \"Mlle\", \"Title\"] = 'Miss'\ntitanic.loc[titanic[\"Title\"] == \"Ms\", \"Title\"] = 'Miss'\ntitanic.loc[titanic[\"Title\"] == \"Mme\", \"Title\"] = 'Mrs'\ntitanic.loc[titanic[\"Title\"] == \"Dona\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Lady\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Countess\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Capt\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Col\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Don\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Major\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Rev\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Sir\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Jonkheer\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Dr\", \"Title\"] = 'Rare Title'\n\n#titanic.loc[titanic[\"Title\"].isin(['Dona', 'Lady', 'Countess','Capt', 'Col', 'Don', \n#                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']), \"Title\"] = 'Rare Title'\n\n#titanic[titanic['Title'].isin(['Dona', 'Lady', 'Countess'])]\n#titanic.query(\"Title in ('Dona', 'Lady', 'Countess')\")\n\ntitanic[\"Title\"].value_counts()\n\n\ntitles = titanic_test[\"Name\"].apply(get_title)\nprint(pd.value_counts(titles))\n\n#Add in the title column.\ntitanic_test[\"Title\"] = titles\n\n# Titles with very low cell counts to be combined to \"rare\" level\nrare_title = ['Dona', 'Lady', 'Countess','Capt', 'Col', 'Don', \n                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']\n\n# Also reassign mlle, ms, and mme accordingly\ntitanic_test.loc[titanic_test[\"Title\"] == \"Mlle\", \"Title\"] = 'Miss'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Ms\", \"Title\"] = 'Miss'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Mme\", \"Title\"] = 'Mrs'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Dona\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Lady\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Countess\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Capt\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Col\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Don\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Major\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Rev\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Sir\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Jonkheer\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Dr\", \"Title\"] = 'Rare Title'\n\ntitanic_test[\"Title\"].value_counts()",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6b198853-1885-585b-ae20-054116b0a5d3",
        "_active": false
      },
      "source": "***Ticket column***",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a4b7f87f-b33d-de30-8924-e1d432cd0f9f",
        "_active": false
      },
      "outputs": [],
      "source": "titanic[\"Ticket\"].tail()",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "547cea2d-409f-40f0-3f9e-78eef0c53666",
        "_active": false
      },
      "outputs": [],
      "source": "titanic[\"TicketNumber\"] = titanic[\"Ticket\"].str.extract('(\\d{2,})', expand=True)\ntitanic[\"TicketNumber\"] = titanic[\"TicketNumber\"].apply(pd.to_numeric)\n\n\ntitanic_test[\"TicketNumber\"] = titanic_test[\"Ticket\"].str.extract('(\\d{2,})', expand=True)\ntitanic_test[\"TicketNumber\"] = titanic_test[\"TicketNumber\"].apply(pd.to_numeric)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7d44754c-24a3-0dad-3ec8-2c1ee1d9a2aa",
        "_active": false
      },
      "outputs": [],
      "source": "#some rows in ticket column dont have numeric value so we got NaN there\ntitanic[titanic[\"TicketNumber\"].isnull()]",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "43df4f5b-e871-4bf0-b2d4-2b9f65fa38ec",
        "_active": false
      },
      "outputs": [],
      "source": "titanic.TicketNumber.fillna(titanic[\"TicketNumber\"].median(), inplace=True)\ntitanic_test.TicketNumber.fillna(titanic_test[\"TicketNumber\"].median(), inplace=True)",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "062dec4a-6e51-910c-18cc-3f343a51f542",
        "_active": false
      },
      "source": "Convert Categorical variables into Numerical ones\n=================================================",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "539e9eaa-7b17-2e4e-d433-133e6b7ab91b",
        "_active": false
      },
      "outputs": [],
      "source": "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n\nlabelEnc=LabelEncoder()\n\ncat_vars=['Embarked','Sex',\"Title\",\"FsizeD\",\"NlengthD\",'Deck']\nfor col in cat_vars:\n    titanic[col]=labelEnc.fit_transform(titanic[col])\n    titanic_test[col]=labelEnc.fit_transform(titanic_test[col])\n\ntitanic.head()",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "361f67a8-fa29-eb74-12d9-806dd27a5655",
        "_active": false
      },
      "source": "***Age Column***\n\nAge seems to be promising feature.\nSo it doesnt make sense to simply fill null values out with median/mean/mode.\n\nWe will use ***Random Forest*** algorithm to predict ages. ",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "749e5a8c-eaa6-4e65-3ffb-9c463cc55be1",
        "_active": false
      },
      "outputs": [],
      "source": "with sns.plotting_context(\"notebook\",font_scale=1.5):\n    sns.set_style(\"whitegrid\")\n    sns.distplot(titanic[\"Age\"].dropna(),\n                 bins=80,\n                 kde=False,\n                 color=\"red\")\n    sns.plt.title(\"Age Distribution\")\n    plt.ylabel(\"Count\")",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1fd4adce-c3c2-9857-7bd5-aa92e7839096",
        "_active": false
      },
      "outputs": [],
      "source": "from sklearn.ensemble import RandomForestRegressor\n#predicting missing values in age using Random Forest\ndef fill_missing_age(df):\n    \n    #Feature set\n    age_df = df[['Age','Embarked','Fare', 'Parch', 'SibSp',\n                 'TicketNumber', 'Title','Pclass','FamilySize',\n                 'FsizeD','NameLength',\"NlengthD\",'Deck']]\n    # Split sets into train and test\n    train  = age_df.loc[ (df.Age.notnull()) ]# known Age values\n    test = age_df.loc[ (df.Age.isnull()) ]# null Ages\n    \n    # All age values are stored in a target array\n    y = train.values[:, 0]\n    \n    # All the other values are stored in the feature array\n    X = train.values[:, 1::]\n    \n    # Create and fit a model\n    rtr = RandomForestRegressor(n_estimators=2000, n_jobs=-1)\n    rtr.fit(X, y)\n    \n    # Use the fitted model to predict the missing values\n    predictedAges = rtr.predict(test.values[:, 1::])\n    \n    # Assign those predictions to the full data set\n    df.loc[ (df.Age.isnull()), 'Age' ] = predictedAges \n    \n    return df",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fae9d082-458a-4f94-1ac5-70b1e9ab8e6e",
        "_active": false
      },
      "outputs": [],
      "source": "titanic=fill_missing_age(titanic)\ntitanic_test=fill_missing_age(titanic_test)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "28e70904-dcd9-158c-eb2c-3c114c6fc166",
        "_active": false
      },
      "outputs": [],
      "source": "with sns.plotting_context(\"notebook\",font_scale=1.5):\n    sns.set_style(\"whitegrid\")\n    sns.distplot(titanic[\"Age\"].dropna(),\n                 bins=80,\n                 kde=False,\n                 color=\"tomato\")\n    sns.plt.title(\"Age Distribution\")\n    plt.ylabel(\"Count\")\n    plt.xlim((15,100))",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e3ea673a-769a-de7b-a95b-5105c3bec1ef",
        "_active": false
      },
      "source": "Feature Scaling\n===============\n\nWe can see that Age, Fare are measured on different scales, so we need to do Feature Scaling first before we proceed with predictions.",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e32e691e-1d4b-f9b8-c0b6-bf422879679b",
        "_active": false
      },
      "outputs": [],
      "source": "from sklearn import preprocessing\n\nstd_scale = preprocessing.StandardScaler().fit(titanic[['Age', 'Fare']])\ndf_std = std_scale.transform(titanic[['Age', 'Fare']])\n\n\nstd_scale = preprocessing.StandardScaler().fit(titanic_test[['Age', 'Fare']])\ndf_std = std_scale.transform(titanic_test[['Age', 'Fare']])",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1322bdd4-2438-b77f-1489-21a319a92883",
        "_active": false
      },
      "source": "Correlation of features with target \n=======================",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c66dd526-36a1-f3b2-ed34-4ecfe02bca69",
        "_active": false
      },
      "outputs": [],
      "source": "titanic.corr()[\"Survived\"]",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "dc110fb3-3ac8-f68e-af62-c4d9caef0271",
        "_active": false
      },
      "source": "Predict Survival\n================",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ef0672f1-9b05-e0d0-6d6b-6334704fbb77",
        "_active": false
      },
      "outputs": [],
      "source": "# Import the linear regression class\nfrom sklearn.linear_model import LinearRegression\n# Sklearn also has a helper that makes it easy to do cross validation\nfrom sklearn.cross_validation import KFold\n\n# The columns we'll use to predict the target\npredictors = [\"Pclass\", \"Sex\", \"Age\",\"SibSp\", \"Parch\", \"Fare\",\n              \"Embarked\",\"NlengthD\", \"FsizeD\", \"Title\",\"Deck\"]\ntarget=\"Survived\"\n# Initialize our algorithm class\nalg = LinearRegression()\n\n# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.\n# We set random_state to ensure we get the same splits every time we run this.\nkf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n\npredictions = []",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "425ab117-b2ea-72d5-651b-15ed0d2f14f8",
        "_active": false
      },
      "outputs": [],
      "source": "for train, test in kf:\n    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.\n    train_predictors = (titanic[predictors].iloc[train,:])\n    # The target we're using to train the algorithm.\n    train_target = titanic[target].iloc[train]\n    # Training the algorithm using the predictors and target.\n    alg.fit(train_predictors, train_target)\n    # We can now make predictions on the test fold\n    test_predictions = alg.predict(titanic[predictors].iloc[test,:])\n    predictions.append(test_predictions)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e4aacd69-0228-3a8e-5f94-a5e52f834e59",
        "_active": false
      },
      "outputs": [],
      "source": "predictions = np.concatenate(predictions, axis=0)\n# Map predictions to outcomes (only possible outcomes are 1 and 0)\npredictions[predictions > .5] = 1\npredictions[predictions <=.5] = 0\n\n\naccuracy=sum(titanic[\"Survived\"]==predictions)/len(titanic[\"Survived\"])\naccuracy",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c4332e05-2db0-88ff-0a3a-e4d2d5cbb861",
        "_active": false
      },
      "outputs": [],
      "source": "from sklearn import cross_validation\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import ShuffleSplit\n\npredictors = [\"Pclass\", \"Sex\", \"Fare\", \"Embarked\",\"Deck\",\"Age\",\n              \"FsizeD\", \"NlengthD\",\"Title\",\"Parch\"]\n\n# Initialize our algorithm\nlr = LogisticRegression(random_state=1)\n# Compute the accuracy score for all the cross validation folds.\ncv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=50)\n\nscores = cross_val_score(lr, titanic[predictors], \n                                          titanic[\"Survived\"],scoring='f1', cv=cv)\n# Take the mean of the scores (because we have one for each fold)\nprint(scores.mean())",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0eedacc0-6a3f-d35c-ab71-0da403d5d773",
        "_active": false
      },
      "outputs": [],
      "source": "from sklearn import cross_validation\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.cross_validation import KFold\nfrom sklearn.model_selection import cross_val_predict\n\nimport numpy as np\npredictors = [\"Pclass\", \"Sex\", \"Age\",\n              \"Fare\",\"NlengthD\",\"NameLength\", \"FsizeD\", \"Title\",\"Deck\"]\n\n# Initialize our algorithm with the default paramters\n# n_estimators is the number of trees we want to make\n# min_samples_split is the minimum number of rows we need to make a split\n# min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends (the bottom points of the tree)\nrf = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, \n                            min_samples_leaf=1)\nkf = KFold(titanic.shape[0], n_folds=5, random_state=1)\ncv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=50)\n\npredictions = cross_validation.cross_val_predict(rf, titanic[predictors],titanic[\"Survived\"],cv=kf)\npredictions = pd.Series(predictions)\nscores = cross_val_score(rf, titanic[predictors], titanic[\"Survived\"],\n                                          scoring='f1', cv=kf)\n# Take the mean of the scores (because we have one for each fold)\nprint(scores.mean())",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d86a3faa-d10b-5b4f-54c8-583e11a5da8d",
        "_active": false
      },
      "outputs": [],
      "source": "predictors = [\"Pclass\", \"Sex\", \"Age\",\n              \"Fare\",\"NlengthD\",\"NameLength\", \"FsizeD\", \"Title\",\"Deck\",\"TicketNumber\"]\nrf = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=9,min_samples_split=6, min_samples_leaf=4)\nrf.fit(titanic[predictors],titanic[\"Survived\"])\nkf = KFold(titanic.shape[0], n_folds=5, random_state=1)\npredictions = cross_validation.cross_val_predict(rf, titanic[predictors],titanic[\"Survived\"],cv=kf)\npredictions = pd.Series(predictions)\nscores = cross_val_score(rf, titanic[predictors], titanic[\"Survived\"],scoring='f1', cv=kf)\n# Take the mean of the scores (because we have one for each fold)\nprint(scores.mean())",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b4a08e76-1dfe-468b-d3f8-a6198c59b7bb",
        "_active": false
      },
      "source": "Important features\n==================",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2567e540-6c3c-0f17-46ce-7f204f0da8fc",
        "_active": false
      },
      "outputs": [],
      "source": "importances=rf.feature_importances_\nstd = np.std([rf.feature_importances_ for tree in rf.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1]\nsorted_important_features=[]\nfor i in indices:\n    sorted_important_features.append(predictors[i])\n#predictors=titanic.columns\nplt.figure()\nplt.title(\"Feature Importances By Random Forest Model\")\nplt.bar(range(np.size(predictors)), importances[indices],\n       color=\"r\", yerr=std[indices], align=\"center\")\nplt.xticks(range(np.size(predictors)), sorted_important_features, rotation='vertical')\n\nplt.xlim([-1, np.size(predictors)])\nplt.show()",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "440b4b19-c73b-00cf-8263-ae42daddb889",
        "_active": false
      },
      "outputs": [],
      "source": "import numpy as np\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.cross_validation import KFold\n%matplotlib inline\nimport matplotlib.pyplot as plt\n#predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\",\n #             \"FsizeD\", \"Embarked\", \"NlengthD\",\"Deck\",\"TicketNumber\"]\npredictors = [\"Pclass\", \"Sex\", \"Age\",\n              \"Fare\",\"NlengthD\", \"FsizeD\",\"NameLength\",\"Deck\",\"Embarked\"]\n# Perform feature selection\nselector = SelectKBest(f_classif, k=5)\nselector.fit(titanic[predictors], titanic[\"Survived\"])\n\n# Get the raw p-values for each feature, and transform from p-values into scores\nscores = -np.log10(selector.pvalues_)\n\nindices = np.argsort(scores)[::-1]\n\nsorted_important_features=[]\nfor i in indices:\n    sorted_important_features.append(predictors[i])\n\nplt.figure()\nplt.title(\"Feature Importances By SelectKBest\")\nplt.bar(range(np.size(predictors)), scores[indices],\n       color=\"seagreen\", yerr=std[indices], align=\"center\")\nplt.xticks(range(np.size(predictors)), sorted_important_features, rotation='vertical')\n\nplt.xlim([-1, np.size(predictors)])\nplt.show()",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7b54f7e1-2c1a-5568-bfc1-e6dd70990678",
        "_active": false
      },
      "outputs": [],
      "source": "from sklearn import cross_validation\nfrom sklearn.linear_model import LogisticRegression\npredictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\",\"NlengthD\",\n              \"FsizeD\", \"Title\",\"Deck\"]\n\n# Initialize our algorithm\nlr = LogisticRegression(random_state=1)\n# Compute the accuracy score for all the cross validation folds.  \ncv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=50)\nscores = cross_val_score(lr, titanic[predictors], titanic[\"Survived\"], scoring='f1',cv=cv)\nprint(scores.mean())",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "892414ea-998b-21c6-85a8-86c8e0c71127",
        "_active": false
      },
      "outputs": [],
      "source": "from sklearn.ensemble import AdaBoostClassifier\npredictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\",\"NlengthD\",\n              \"FsizeD\", \"Title\",\"Deck\",\"TicketNumber\"]\nadb=AdaBoostClassifier()\nadb.fit(titanic[predictors],titanic[\"Survived\"])\ncv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=50)\nscores = cross_val_score(adb, titanic[predictors], titanic[\"Survived\"], scoring='f1',cv=cv)\nprint(scores.mean())",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "deb63887-1f64-482d-3ad6-bd5179a8448a",
        "_active": false
      },
      "source": "Maximum Voting ensemble and Submission\n=======",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5b98fa41-2376-096f-8dff-525e521c1973",
        "_active": false
      },
      "outputs": [],
      "source": "predictions=[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\",\"NlengthD\",\n              \"FsizeD\", \"Title\",\"Deck\",\"NameLength\",\"TicketNumber\"]\nfrom sklearn.ensemble import VotingClassifier\neclf1 = VotingClassifier(estimators=[\n        ('lr', lr), ('rf', rf), ('adb', adb)], voting='soft')\neclf1 = eclf1.fit(titanic[predictors], titanic[\"Survived\"])\npredictions=eclf1.predict(titanic[predictors])\npredictions\n\ntest_predictions=eclf1.predict(titanic_test[predictors])\n\ntest_predictions=test_predictions.astype(int)\nsubmission = pd.DataFrame({\n        \"PassengerId\": titanic_test[\"PassengerId\"],\n        \"Survived\": test_predictions\n    })\n\nsubmission.to_csv(\"titanic_submission.csv\", index=False)",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "141131e6-ccc2-c5fb-f1d7-43ca7f121703",
        "_active": false
      },
      "source": "***To do: stacking!. Watch this space…***",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0f6cee21-6591-453b-1afa-867fec86cdfb",
        "_active": false
      },
      "source": "***Hope you find it useful. :)***",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    }
  ]
}