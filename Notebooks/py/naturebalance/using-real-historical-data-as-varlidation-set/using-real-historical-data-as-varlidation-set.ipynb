{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom keras import models \nfrom keras import layers\n\nfrom keras import regularizers\n\nfrom sklearn.metrics import accuracy_score\n\nimport os\nprint(os.listdir(\"../input/\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0631db0fcca25742d34d657190695d8753eee22"},"cell_type":"markdown","source":"I am going to imput real historical data as Validation set, so we could get real accuracy without submit.\nThat maybe will give us some new insight, at least that save a lot of time."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#import train and test CSV files\ntrain = pd.read_csv(\"../input/titanic/train.csv\")\ntest = pd.read_csv(\"../input/titanic/test.csv\")\n#import real historical data.\nhistory=pd.read_csv(\"../input/test-dataset/TitanicHistory.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eeb33df29538230f22c81fccaeb3b0dbf2b257fd"},"cell_type":"code","source":"#this is real data on history\nhistory['Survived']=history['Survived'].map({\"No\":0,\"Yes\":1})\nhistory[['Name','Survived']].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db4a1dea0301ce5a3692bd74414641df56d9db93"},"cell_type":"markdown","source":"We don't split validation set from train.\nWe use history data as validation set.\nmaybe this try will give us something different."},{"metadata":{"trusted":true,"_uuid":"071939c0d05a00ed6c7d6bee023f35ccae339e18"},"cell_type":"code","source":"#combine historical data with test\ntestWithHistory=pd.merge(test,history[['Name','Survived']],on='Name', how = 'left')\ntestWithHistory.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15bdb9203a8d8be7a30a20d70d446f262dc1f606"},"cell_type":"code","source":"train['Mark']='train'\ntestWithHistory['Mark']='test'\n#combine train and test for convenience, making them easy for feature engineer\ndataInput=pd.concat([train,testWithHistory])\ndataPrepare=dataInput.copy(deep=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b5546fc9a43715fc03a88095fc345832057ac9c"},"cell_type":"code","source":"#let's see the null situation.\nprint(pd.isnull(test).sum())\nprint(pd.isnull(train).sum())\nprint(pd.isnull(dataPrepare).sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4cd392cb1d2139d8acba138a3de1ece9a3d9f2d0"},"cell_type":"markdown","source":"Age feature will fill null with 0 because deep net could recognize 0 if we leave enough space.\nEnough space means we make move everyting close to 0 equal 1 , \nthen let deep net see the difference:\n0 as null \n1 still means age\n"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"572b6821967172df43f809b5ebd33b93d801072a"},"cell_type":"code","source":"dataPrepare['Age'][dataPrepare['Age']<1]=1\n\ndataPrepare['Age']=dataPrepare['Age'].fillna(0)\ndataPrepare['Age']=dataPrepare['Age'].astype('float32')\n\ndataPrepare['Age']=dataPrepare['Age']\ndataPrepare.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ec90cfa46c053907dfa0051d5e9474c930cb101"},"cell_type":"markdown","source":"Let's change some char to number."},{"metadata":{"trusted":true,"_uuid":"05cabdfadc5f89b075c2a0cb89031ee4384838e4"},"cell_type":"code","source":"dataPrepare['Sex']=dataPrepare['Sex'].map({\"male\":1,\"female\":2})\ndataPrepare['Sex'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0e3e1bd65833bddf446f48cf9f1de0a0d24cef8"},"cell_type":"code","source":"dataPrepare['Embarked']=dataPrepare['Embarked'].map({\"S\":1,\"C\":2,\"Q\":3})\ndataPrepare['Embarked']=dataPrepare['Embarked'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25392bbc8d3d67c032ff9dcd5bf11ac9e2d5bebb"},"cell_type":"code","source":"#exact title from name\ndataPrepare['Title'] = dataPrepare.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\ndataPrepare['Title']=dataPrepare['Title'].map({\"Mr\":1,\"Miss\":2,\"Mrs\":3,\"Master\":4})\ndataPrepare['Title']=dataPrepare['Title'].fillna(0)\ndataPrepare['Title']=dataPrepare['Title'].astype('int8')\ndataPrepare['Title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8366b51842b2d52c38f557a057140bd5b36bcd82"},"cell_type":"markdown","source":"Now we move on model part.\nsome nominal feature should be convert use dummy() or something like that,  but may be deep net could understand if I give it more layers.\nso Let's try"},{"metadata":{"trusted":true,"_uuid":"5f91aa3d534e2bb8866c134236e373e7ebd02070"},"cell_type":"code","source":"dataPrepare.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3669f72740c99d56128f70fbecb026229190d01"},"cell_type":"code","source":"selectColumns=['PassengerId', 'Embarked', 'Title', 'Age', 'Fare', 'Mark','Parch',\n        'Pclass', 'Sex', 'SibSp', 'Survived']\ndataPrepare[selectColumns].head()\ndataPrepare['Fare']=dataPrepare['Fare'].fillna(0)\nprint(pd.isnull(dataPrepare[selectColumns]).sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04ee87d91110a1808aa1a61b12049faf894e4ac1"},"cell_type":"code","source":"dataPrepare[selectColumns].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2ca85ba90aca38c4758ac3fb72d7d31fe476fa8"},"cell_type":"code","source":"#set train and validation set.\n#as previous mentioned, we use historical data as Validation set.\n#let's what will give us.\ntrain_input=dataPrepare[dataPrepare['Mark']=='train']\nvalidation_input=dataPrepare[dataPrepare['Mark']=='test']\nvalidation_input=validation_input[validation_input['Survived'].notnull()]\nfeatureColumns=[ 'Age','Title','Embarked', 'Fare','Parch','Pclass', 'Sex', 'SibSp']\n\nx=train_input[featureColumns].values\ny=train_input['Survived'].values\n\nx_val=validation_input[featureColumns].values\ny_val=validation_input['Survived'].values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d959b9ce7ee98d45556d7971e5f3916abf3f682e"},"cell_type":"code","source":"#keras deep net\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(10, activation='relu', input_shape=(len(featureColumns),))) \nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.Dense(10, activation='relu')) \nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.Dense(10, activation='relu')) \nmodel.add(layers.Dropout(0.1))\n\nmodel.add(layers.Dense(10, activation='relu')) \nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.Dense(10, activation='relu')) \nmodel.add(layers.Dropout(0.1))\nmodel.add(layers.Dense(1, activation='sigmoid',))\n\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"250885e8c8ce4bdd72833571189f0960fbead3fe"},"cell_type":"code","source":"history = model.fit(x, y, epochs=100,\nbatch_size=32, validation_data=(x_val, y_val),verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06025be4b9341cedf42c0bc0f07efeb6424bbb19"},"cell_type":"code","source":"history_dict = history.history\nimport matplotlib.pyplot as plt\nhistory_dict = history.history \nloss_values = history_dict['loss'] \nval_loss_values = history_dict['val_loss']\nepochs = range(1, len(loss_values) + 1)\nplt.plot(epochs, loss_values, 'bo', label='Training loss') \nplt.plot(epochs, val_loss_values, 'b', label='Validation loss') \nplt.title('Training and validation loss') \nplt.xlabel('Epochs') \nplt.ylabel('Loss') \nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09b2cac895ee1c1eace45cea0cc8665d735f314b"},"cell_type":"code","source":"plt.clf()\nacc = history_dict['acc'] \nval_acc = history_dict['val_acc']\nplt.plot(epochs, acc, 'bo', label='Training acc') \nplt.plot(epochs, val_acc, 'b', label='Validation acc') \nplt.title('Training and validation accuracy') \nplt.xlabel('Epochs') \nplt.ylabel('Accuracy') \nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de5f5ceecd3b51e810a0afd7edf147a866f0dc81"},"cell_type":"code","source":"y_pred = model.predict(x_val)\nacc_randomforest = round(accuracy_score(np.where(y_pred<0.5,0,1), y_val) * 100, 2)\nprint(acc_randomforest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce99159344264a719ed80716e3a7a62dc9a56ec5"},"cell_type":"code","source":"# Random Forest as reference\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(x, y)\ny_pred = randomforest.predict(x_val)\nacc_randomforest = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_randomforest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80acfa8dc63e500cd5f8a2f8d53d78f5e6b70df2"},"cell_type":"code","source":"# Gradient Boosting Classifier as reference\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier()\ngbk.fit(x, y)\ny_pred = gbk.predict(x_val)\nacc_gbk = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_gbk)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64645acce19a96fc4e44941dd5d2368ee31411d8"},"cell_type":"code","source":"#submit upload and you will see that equal the accuracy of this notebook. \nids = test['PassengerId']\npredits=dataPrepare[dataPrepare['Mark']=='test']\npredits=predits[featureColumns].values\npredictions = model.predict(predits)\npredictions=np.where(predictions<0.5,0,1)\npredictions=pd.Series(predictions.reshape(418))\n\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput['Survived']=output['Survived'].astype('int8')\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}