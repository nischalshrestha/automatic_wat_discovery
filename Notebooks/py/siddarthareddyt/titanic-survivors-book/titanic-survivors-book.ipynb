{"metadata": {"language_info": {"nbconvert_exporter": "python", "mimetype": "text/x-python", "name": "python", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.3", "file_extension": ".py"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "nbformat": 4, "cells": [{"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "529887d6-c525-49bf-bd1b-758b33529372", "scrolled": true, "collapsed": true, "_uuid": "a0893ed1c9d36a84e0d93611674ca649337478f0"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "import sklearn.feature_selection\n", "from sklearn.feature_selection import RFECV\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.preprocessing import minmax_scale\n", "from sklearn.svm import SVC\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.model_selection import StratifiedShuffleSplit\n", "from sklearn.model_selection import ShuffleSplit\n", "import keras\n", "from keras.models import Sequential\n", "from keras.layers import Dense\n", "from sklearn import tree\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\",\".\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "02dc1fd8-70db-406c-aae7-eb5b5dee8c16", "collapsed": true, "_uuid": "22a694f943fdc07b24dbea6815b6091c7e4509a2"}, "source": ["train = pd.read_csv(\"../input/train.csv\")\n", "holdout = pd.read_csv(\"../input/test.csv\")\n", "\n", "#no. of null embed columns\n", "train.isnull().sum()\n", "\n", "#some stats of the datasets\n", "train.describe()\n", "holdout.describe()\n"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "2315660c-9ffc-4dec-ad46-c65f3741cb98", "collapsed": true, "_uuid": "85a35a923e585b1ae3084c8b2b833aa1f3b09fe3"}, "source": ["#data exploration\n", "\n", "#survival vs gender indicates females have more chances of surviving\n", "gender_pivot = train.pivot_table(index=\"Sex\",values=\"Survived\")\n", "gender_pivot.plot.bar()\n", "plt.show()\n", "\n", "\n", "#pclass vs survived indicates class 1 and class 2 people are more likely to survive\n", "class_pivot = train.pivot_table(index=\"Pclass\", values=\"Survived\")\n", "class_pivot.plot.bar()\n", "plt.show()\n", "\n", "#Family size vs survived\n", "family_cols = [\"SibSp\",\"Parch\",\"Survived\"]\n", "family = train[family_cols].copy()\n", "family['familysize'] = family[[\"SibSp\",\"Parch\"]].sum(axis=1)\n", "familySize = family[[\"SibSp\",\"Parch\"]].sum(axis=1)\n", "family[\"isalone\"] = np.where(familySize>=1, 1, 0)\n", "family_pivot = family.pivot_table(index=\"familysize\",values=\"Survived\")\n", "isalone_pivot = family.pivot_table(index=\"isalone\", values=\"Survived\")\n", "isalone_pivot.plot.bar(ylim=(0,1),yticks=np.arange(0,1,.1))\n", "family_pivot.plot.bar(ylim=(0,1),yticks=np.arange(0,1,.1))\n", "plt.show()"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "c66ecde5-d573-4e6d-aff7-bc893ce6c32d", "collapsed": true, "_uuid": "fcf89e5c7fe989fd78dc08f15fe842a87f3bf944"}, "source": ["#data preprocessing\n", "train[\"Fare\"] = train[\"Fare\"].fillna(train[\"Fare\"].mean())\n", "train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n", "\n", "holdout[\"Fare\"] = holdout[\"Fare\"].fillna(train[\"Fare\"].mean())\n", "holdout[\"Embarked\"] = holdout[\"Embarked\"].fillna(\"S\")\n", "\n", "train[\"Age\"] = train[\"Age\"].fillna(-0.5)\n", "holdout[\"Age\"] = holdout[\"Age\"].fillna(-0.5)\n", "\n", "train.head(2)\n", "holdout.head(2)\n", "\n"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "c09f9431-3117-4c46-ab24-8b0adae8a7e4", "collapsed": true, "_uuid": "8ed71b99db2092b215e64b5d3bd62d8ee69551bc"}, "source": ["#feature engineering\n", "\n", "#categorize age\n", "cuts = [-1,0,5,12,18,35,60,100]\n", "labels = [\"Missing\",\"Infant\",\"Child\",\"Teenager\",\"Young Adult\",\"Adult\",\"Senior\"]\n", "train[\"Age_categories\"] = pd.cut(train[\"Age\"],cuts,labels=labels)\n", "holdout[\"Age_categories\"] = pd.cut(holdout[\"Age\"],cuts,labels=labels)\n", "\n", "#categorize fare\n", "fare_cuts = [-1,12,50,100,1000]\n", "fare_labels = [\"0-12\",\"12-50\",\"50-100\",\"100+\"]\n", "train[\"Fare_categories\"] = pd.cut(train[\"Fare\"],fare_cuts,labels=fare_labels)\n", "holdout[\"Fare_categories\"] = pd.cut(holdout[\"Fare\"],fare_cuts,labels=fare_labels)\n", "\n", "\n", "#categorize cabin types\n", "\n", "train[\"Cabin_type\"] = train[\"Cabin\"].str[0]\n", "train[\"Cabin_type\"] = train[\"Cabin_type\"].fillna(\"Unknown\")\n", "train = train.drop('Cabin',axis=1)\n", "\n", "holdout[\"Cabin_type\"] = holdout[\"Cabin\"].str[0]\n", "holdout[\"Cabin_type\"] = holdout[\"Cabin_type\"].fillna(\"Unknown\")\n", "holdout = holdout.drop('Cabin',axis=1)\n", "\n", "#engineer Title feature\n", "titles = {\n", "        \"Mr\" :         \"Mr\",\n", "        \"Mme\":         \"Mrs\",\n", "        \"Ms\":          \"Mrs\",\n", "        \"Mrs\" :        \"Mrs\",\n", "        \"Master\" :     \"Master\",\n", "        \"Mlle\":        \"Miss\",\n", "        \"Miss\" :       \"Miss\",\n", "        \"Capt\":        \"Officer\",\n", "        \"Col\":         \"Officer\",\n", "        \"Major\":       \"Officer\",\n", "        \"Dr\":          \"Officer\",\n", "        \"Rev\":         \"Officer\",\n", "        \"Jonkheer\":    \"Royalty\",\n", "        \"Don\":         \"Royalty\",\n", "        \"Sir\" :        \"Royalty\",\n", "        \"Countess\":    \"Royalty\",\n", "        \"Dona\":        \"Royalty\",\n", "        \"Lady\" :       \"Royalty\"\n", "    }\n", "train_titles = train[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n", "train[\"Title\"] = train_titles.map(titles)\n", "\n", "holdout_titles = holdout[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n", "holdout[\"Title\"] = holdout_titles.map(titles)\n", "\n", "#engineer isalone\n", "familySize_train = train[[\"SibSp\",\"Parch\"]].sum(axis=1)\n", "train[\"isalone\"] = np.where(familySize_train>=1, 1, 0)\n", "\n", "familySize_holdout = holdout[[\"SibSp\",\"Parch\"]].sum(axis=1)\n", "holdout[\"isalone\"] = np.where(familySize_holdout>=1, 1, 0)\n", "\n", "\n", "#dummy variables for all the categorical features\n", "def get_dummies(df, column_name):\n", "    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n", "    df = pd.concat([df,dummies],axis=1)\n", "    return df\n", "\n", "columnNames = [\"Age_categories\", \"Pclass\", \"Sex\", \"Fare_categories\", \"Title\", \"Cabin_type\", \"Embarked\"]\n", "\n", "for column in columnNames:\n", "    dummies_train = pd.get_dummies(train[column],prefix=column)\n", "    train = pd.concat([train,dummies_train],axis=1)\n", "    \n", "    dummies_holdout = pd.get_dummies(holdout[column],prefix=column)\n", "    holdout = pd.concat([holdout,dummies_holdout],axis=1)\n", "    \n", "train.head(5)\n", "holdout.head(5)\n", "\n", "print(holdout.columns)\n", "\n"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "b8ebb01e-9e82-4aac-9d93-30e6466a24fa", "collapsed": true, "_uuid": "40bc1239d7717ca2a3521c015f33637d49eb9b7d"}, "source": ["columns = ['Age_categories_Missing', 'Age_categories_Infant',\n", "       'Age_categories_Child', 'Age_categories_Teenager',\n", "       'Age_categories_Young Adult', 'Age_categories_Adult',\n", "       'Age_categories_Senior', 'Pclass_1', 'Pclass_2', 'Pclass_3',\n", "       'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S',\n", "       'Fare_categories_0-12',\n", "       'Fare_categories_12-50','Fare_categories_50-100', 'Fare_categories_100+',\n", "       'Title_Master', 'Title_Miss', 'Title_Mr','Title_Mrs', 'Title_Officer',\n", "       'Title_Royalty', 'Cabin_type_A','Cabin_type_B', 'Cabin_type_C', 'Cabin_type_D',\n", "       'Cabin_type_E','Cabin_type_F', 'Cabin_type_G', 'Cabin_type_Unknown', 'isalone']\n", "\n", "#model-selection\n", "def get_model(df, features):\n", "    \n", "    train_X = df[features]\n", "    train_y = df[\"Survived\"]\n", "    \n", "    cv = ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0)\n", "    model_params = [\n", "            {\n", "                    \"name\": \"RandomForestClassifier\",\n", "                    \"estimator\": RandomForestClassifier(random_state=0),\n", "                    \"hyperparameters\":\n", "                        {\n", "                                \"n_estimators\": [20,25, 35, 40,45, 50, 55, 60, 65, 70, 75],\n", "                                \"criterion\": [\"entropy\", \"gini\"],\n", "                                \"max_features\": [\"log2\", \"sqrt\"],\n", "                                \"min_samples_leaf\": [1, 5, 8],\n", "                                \"min_samples_split\": [2, 3, 5]\n", "                        }\n", "            },\n", "            {\n", "                    \"name\": \"DecisionTreeClassifier\",\n", "                    \"estimator\": tree.DecisionTreeClassifier(),\n", "                    \"hyperparameters\":\n", "                        {\n", "                                \"criterion\": [\"entropy\", \"gini\"],\n", "                                \"max_depth\": [None, 2,4,6,8,10, 12, 14, 16],\n", "                                'min_samples_split': [2,3,4,5,10,.03,.05,.1],\n", "                                \"max_features\": [None, \"auto\"],\n", "                                \"min_samples_leaf\": [1,2,3,4,5,10,12, .5, .03,.05,.1]\n", "                        }\n", "            },\n", "            {\n", "                    \"name\": \"KernelSVMClassifier\",\n", "                    \"estimator\": SVC(random_state=0),\n", "                    \"hyperparameters\":\n", "                        {\n", "                                \"kernel\": [\"rbf\"],\n", "                                \"C\": np.logspace(-9, 3, 13),\n", "                                \"gamma\": np.logspace(-9, 3, 13)\n", "                        }\n", "            } ,\n", "            {\n", "                    \"name\": \"KNeighborsClassifier\",\n", "                    \"estimator\": KNeighborsClassifier(),\n", "                    \"hyperparameters\":\n", "                        {\n", "                                \"n_neighbors\": range(1,20,2),\n", "                                \"weights\": [\"distance\", \"uniform\"],\n", "                                \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n", "                                \"p\": [1,2]\n", "                        }\n", "            },\n", "            {\n", "                    \"name\": \"LogisticRegressionClassifier\",\n", "                    \"estimator\": LogisticRegression(),\n", "                    \"hyperparameters\":\n", "                        {\n", "                                \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n", "                        }\n", "            }          \n", "            ]\n", "    models = []\n", "    for model in model_params:\n", "        print(model[\"name\"])\n", "        grid = GridSearchCV(model[\"estimator\"], \n", "                            param_grid=model[\"hyperparameters\"], \n", "                            cv=10)\n", "        grid.fit(train_X, train_y)\n", "        \n", "        model_att = {\n", "                \"model\": grid.best_estimator_, \n", "                \"best_params\": grid.best_params_, \n", "                \"best_score\": grid.best_score_,\n", "                \"grid\": grid\n", "                }\n", "        models.append(model_att)\n", "        print(\"Evaluated model and its params: \")\n", "        print(grid.best_params_)\n", "        print(grid.best_score_)\n", "    return models\n", "\n", "#Artificial Neural Network\n", "def ann_model(df, features):\n", "    classifier = Sequential()\n", "    classifier.add(Dense(input_dim=len(features), units=15, activation=\"relu\", kernel_initializer=\"uniform\"))\n", "    \n", "    classifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu'))\n", "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n", "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n", "    \n", "    train_X = df[features]\n", "    train_y = df[\"Survived\"]\n", "    classifier.fit(np.array(train_X), np.array(train_y), batch_size = 10, epochs = 100)\n", "    return classifier\n", "\n", "#feature selection using RFECV\n", "def get_features(df, columns, model=None):\n", "    newDf = df.copy()\n", "    newDf = newDf.select_dtypes(['number'])\n", "    newDf = newDf.dropna(axis=1, how='any')\n", "    \n", "    #dropColumns = [\"PassengerId\", \"Survived\"]\n", "    #newDf = newDf.drop(dropColumns, axis = 1)\n", "    \n", "    all_X = newDf[columns]\n", "    all_y = df[\"Survived\"]\n", "    \n", "    cv = StratifiedShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0)\n", "    if model == None:\n", "        classifier = tree.DecisionTreeClassifier(\n", "                criterion=\"entropy\",\n", "                max_depth=10,\n", "                max_features='auto',\n", "                max_leaf_nodes=None,\n", "                min_impurity_decrease = 0.0,\n", "                min_samples_leaf = 10,\n", "                min_samples_split = 3\n", "                )\n", "    else:\n", "        classifier = model\n", "    selector = RFECV(classifier, scoring = 'roc_auc', cv=cv, step = 1)\n", "    selector.fit(all_X,all_y)\n", "    rfecv_columns = all_X.columns[selector.support_]\n", "    return rfecv_columns\n", "\n", "models = get_model(train, columns)\n", "\n", "#select the best one based on its index from console\n", "best_grid = models[0][\"grid\"]\n", "best_classifier = models[0][\"model\"]\n", "best_params = models[0][\"best_params\"]\n", "\n", "rfecv_features = get_features(train, columns, best_classifier)\n", "print(len(rfecv_features))\n", "print(rfecv_features)\n", "\n", "models = get_model(train, rfecv_features)\n", "best_classifier = models[0][\"model\"]\n", "\n", "predictions = best_classifier.predict(holdout[rfecv_features])\n", "\n", "sub = {\"PassengerId\": holdout[\"PassengerId\"], \"Survived\": predictions}\n", "submission = pd.DataFrame(sub)\n", "submission.to_csv(path_or_buf=\"Submission.csv\", index=False, header=True)\n", "\n"], "cell_type": "code"}], "nbformat_minor": 1}