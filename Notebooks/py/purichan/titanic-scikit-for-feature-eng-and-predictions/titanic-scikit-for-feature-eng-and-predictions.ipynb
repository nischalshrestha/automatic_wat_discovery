{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":false,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib \n\n#Read the data and input them in Dataframes\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\n#print(train_df.describe(), test_df.describe())\n#print(train_df.head(10),test_df.head(10))\n\n#Handle missing values in age\ntrain_df['Age']= train_df['Age'].fillna(-1)\ntest_df['Age']= train_df['Age'].fillna(-1)\n\n#Feature Extrtaction\n#Making \"Age brackets\" instead of age values\nage_bins = [-1, 0, 10, 20, 30, 40, 50, 60, 70, 100]\nage_labels = ['Missing', '0-10', '10-20', '20-30', '30-40', '40-50', '50-60', '60-70', 'Over 70']\n\ntrain_df['Age_bins'] = pd.cut(train_df['Age'],bins = age_bins, labels = age_labels, include_lowest = True)\ntest_df['Age_bins'] = pd.cut(train_df['Age'],bins = age_bins, labels = age_labels, include_lowest = True)\n\n#for fare bins, we need to find the max value to partition it appropriately\nmax = train_df.loc[train_df['Fare'].idxmax()]\ntest_max = test_df.loc[test_df['Fare'].idxmax()]\n#print(test_max)\n\nfare_bins = [0, 30, 50, 100, 200, 513]\nfare_labels = ['Under 30', 'Upto 50', 'Upto 100', 'Upto 200', 'Over 200']\n\ntrain_df['Fare_bins'] = pd.cut(train_df['Fare'], bins=fare_bins, labels=fare_labels, include_lowest=True)\ntest_df['Fare_bins'] = pd.cut(test_df['Fare'], bins=fare_bins, labels=fare_labels, include_lowest=True)\n\n#Extracting salutations from names\nsplit_salutation = train_df['Name'].str.split()\ntrain_df['Salutation'] = split_salutation.str[1]\ntest_split_salutation = test_df['Name'].str.split()\ntest_df['Salutation'] = test_split_salutation.str[1]\n\n#print(train_df['Salutation'].unique())\n#Bucketing Misc as 'other'\ntrain_df['Salutation'] = train_df['Salutation'].replace(['Planke,','Don.','Rev.','Billiard,','der','Walle,','Dr.','Pelsmaeker,','Mulder,','Steen,','Carlo,','Mme.','Impe,','Ms.','Major','Gordon,','Messemaeker,','Mlle.','Col.','Capt.','Velde,','the','Shawah,','Jonkheer.','Melkebeke,','Cruyssen,', 'Khalil,', 'y'], 'Other')\ntest_df['Salutation'] = test_df['Salutation'].replace(['Planke,','Don.','Rev.','Billiard,','der','Walle,','Dr.','Pelsmaeker,','Mulder,','Steen,','Carlo,','Mme.','Impe,','Ms.','Major','Gordon,','Messemaeker,','Mlle.','Col.','Capt.','Velde,','the','Shawah,','Jonkheer.','Melkebeke,','Cruyssen,', 'Khalil,', 'y'], 'Other')\n\n#Is Cabin a worthwhile feature?\ntrain_df['Cabin_wing'] = train_df['Cabin'].astype(str).str[0]\ntest_df['Cabin_wing'] = test_df['Cabin'].astype(str).str[0]\n#print(train_df['Cabin_wing'].head(20))\n#Maybe next version?\n\n#Encoding - Changing categorical or groups and values to integers \n#Ex : Female - 0, Male 1, Age groups get their own integers from 0 to 8\n#Doing this for sex, age, fare, cabin, salutation\n\nfrom sklearn.preprocessing import LabelEncoder\nenc = LabelEncoder()\ntrain_df['Sex_code'] = enc.fit_transform(train_df['Sex'])\ntrain_df['Age_code'] = enc.fit_transform(train_df['Age_bins'])\ntrain_df['Fare_code'] = enc.fit_transform(train_df['Fare_bins'].astype(str))\ntrain_df['Salutation'] = enc.fit_transform(train_df['Salutation'].astype(str))\n\ntest_df['Sex_code'] = enc.fit_transform(test_df['Sex'])\ntest_df['Age_code'] = enc.fit_transform(test_df['Age_bins'])\ntest_df['Fare_code'] = enc.fit_transform(test_df['Fare_bins'].astype(str))\ntest_df['Salutation'] = enc.fit_transform(test_df['Salutation'].astype(str))\ntest_df['Salutation'] = enc.fit_transform(test_df['Salutation'].astype(str))\n#print(train_df, test_df)\n\n#Handle missing values\n#print(train_df.isna(), test_df.isna())\ntrain_df.dropna()\ntest_df.dropna()\n\n#Model testing\n#gathering all imports from sklearn\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_score\n\n#trying logistic regression \nlr = LogisticRegression()\n\n#columns to test it on\ncolumns = ['Pclass', 'Age_code', 'Sex_code', 'Parch', 'Salutation']\nall_X = train_df[columns]\nall_y = train_df['Survived']\n#Dividing train and test data to test accuracy of models before putting it on test data\ntrain_X, test_X, train_y, test_y = train_test_split(all_X, all_y, test_size=0.2,random_state=0)\n\n#testing logistic regression\nlr.fit(train_X, train_y)\nlr_predictions = lr.predict(test_X)\nlr_accuracy = accuracy_score(test_y, lr_predictions)\nlr_conf_matrix = confusion_matrix(test_y, lr_predictions)\nlr_scores = cross_val_score(lr, all_X, all_y, cv=10)\nlr_mean_scores = np.mean(lr_scores)\n#print('Linear Regression', lr_accuracy, lr_mean_scores)\n\nmodelTest = pd.DataFrame([['Linear Regression', lr_accuracy, lr_mean_scores]])\n\n#Model Selection\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\n\n#Random Forest Classification\nclf = RandomForestClassifier(max_depth=2, random_state=0)\nclf.fit(train_X, train_y)\n#print(clf.feature_importances_)\n\nclf_predictions = clf.predict(test_X)\nclf_accuracy = accuracy_score(test_y, clf_predictions)\nclf_scores = cross_val_score(clf, all_X, all_y, cv=10)\nclf_mean_scores = np.mean(clf_scores)\n\nrandomforest = pd.DataFrame([['Random Forest', clf_accuracy, clf_mean_scores]])\nmodelTest = modelTest.append(randomforest)\n\n#Perceptron\nperc = Perceptron(max_iter=1)\nperc.fit(train_X, train_y)\nperc_predictions = perc.predict(test_X)\nperc_accuracy = accuracy_score(test_y, perc_predictions)\nperc_scores = cross_val_score(perc, all_X, all_y, cv=10)\nperc_mean_scores = np.mean(perc_scores)\nperceptron = pd.DataFrame([['Perceptron', perc_accuracy, perc_mean_scores]])\nmodelTest = modelTest.append(perceptron)\n\n#Decision Tree Classifier\ndtc = DecisionTreeClassifier()\ndtc.fit(train_X, train_y)\ndtc_predictions = dtc.predict(test_X)\ndtc_accuracy = accuracy_score(test_y, dtc_predictions)\ndtc_scores = cross_val_score(dtc, all_X, all_y, cv=10)\ndtc_mean_scores = np.mean(dtc_scores)\ndecisiontree = pd.DataFrame([['Decision Trees', dtc_accuracy, dtc_mean_scores]])\nmodelTest = modelTest.append(decisiontree)\n\n#K Neighbor\nknc = KNeighborsClassifier()\nknc.fit(train_X, train_y)\nknc_predictions = knc.predict(test_X)\nknc_accuracy = accuracy_score(test_y, knc_predictions)\nknc_scores = cross_val_score(knc, all_X, all_y, cv=10)\nknc_mean_scores = np.mean(knc_scores)\nknclass = pd.DataFrame([['K neighbour', knc_accuracy, knc_mean_scores]])\nmodelTest = modelTest.append(knclass)\n\n##Stochastic Gradient Descent classifier\nsgdc = SGDClassifier(max_iter = 5)\nsgdc.fit(train_X, train_y)\nsgdc_predictions = sgdc.predict(test_X)\nsgdc_accuracy = accuracy_score(test_y, sgdc_predictions)\nsgdc_scores = cross_val_score(sgdc, all_X, all_y, cv=10)\nsgdc_mean_scores = np.mean(sgdc_scores)\nsgdclass = pd.DataFrame([['SGDC', sgdc_accuracy, sgdc_mean_scores]])\nmodelTest = modelTest.append(sgdclass)\n\nmodelTest.columns = ['Model Name', 'Accuracy', 'Mean Scores']\nprint(modelTest)\n\n##Applying test data\nnew_X = test_df[columns]\nclf.fit(train_X, train_y)\nnew_clf_predictions = clf.predict(new_X)\n\npass_id = test_df['PassengerId']\nresult = pd.DataFrame({ 'PassengerId' : pass_id, 'Survived': new_clf_predictions })\nresult.to_csv('titanic-results.csv')\n\nprint(result.head(20))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4556694a0f36987733c14a5b49415c7059dc7c1e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}