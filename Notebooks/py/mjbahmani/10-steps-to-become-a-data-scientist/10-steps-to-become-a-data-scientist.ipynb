{"cells":[{"metadata":{"_uuid":"9f550639a0754f42a243e5785d895d24ba655515"},"cell_type":"markdown","source":"\n<img src=\"http://s9.picofile.com/file/8338833934/DS.png\"/>"},{"metadata":{"_uuid":"e02d495da0fb0ad24e0341e91848f4c4cfc35bdb"},"cell_type":"markdown","source":"\n\n---------------------------------------------------------------------\nFork and Run this kernel on GitHub:\n> #### [ GitHub](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist)\n\n\n-------------------------------------------------------------------------------------------------------------\n <b>I hope you find this kernel helpful and some <font color=\"red\"> UPVOTES</font> would be very much appreciated<b/>\n \n -----------\n"},{"metadata":{"_uuid":"85b27cf82d3023fd69c338df2be7afb2d7afaf32"},"cell_type":"markdown","source":" <a id=\"top\"></a> <br>\n**Notebook Content**\n\n [Introduction](#Introduction)\n1. [Python](#Python)\n1. [Python Packages](#Python Packages)\n1. [Mathematics and Linear Algebra](#Mathematics and Linear Algebra)\n1. [Programming & Analysis Tools](#Programming & Analysis Tools)\n1. [Big Data](#Big Data)\n1. [Data visualization](#Data visualization)\n1. [Data Cleaning](#Data Cleaning)\n1. [How to solve Problem?](#How to solve Problem?)\n1. [Machine Learning](#Machine Learning)\n1. [Deep Learning](#Deep Learning)"},{"metadata":{"_uuid":"ada06bdafb4dbf2d86d81da323000aa7999b3344"},"cell_type":"markdown","source":" ## <div align=\"center\">  10 Steps to Become a Data Scientist</div>\n <div align=\"center\">**quite practical and far from any theoretical concepts**</div>\n<div style=\"text-align:center\">last update: <b>11/20/2018</b></div>"},{"metadata":{"_uuid":"2a77b410b99632c4d99b652c226178cb1ff10b51"},"cell_type":"markdown","source":" <a id=\"Introduction\"></a> <br>\n# Introduction\nIf you Read and Follow **Job Ads** to hire a machine learning expert or a data scientist, you find that some skills you should have to get the job. In this Kernel, I want to review **10 skills** that are essentials to get the job. In fact, this kernel is a reference for **10 other kernels**, which you can learn with them,  all of the skills that you need. \n\n**Ready to learn**! you will learn 10 skills as data scientist: [Machine Learning](https://www.kaggle.com/mjbahmani/a-comprehensive-ml-workflow-with-python), [Deep Learning](https://www.kaggle.com/mjbahmani/top-5-deep-learning-frameworks-tutorial), [Data Cleaning](https://www.kaggle.com/mjbahmani/a-data-science-framework-for-quora), [EDA](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-2), [Learn Python](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-1), [Learn python packages](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-2) such as Numpy, Pandas, Seaborn, Matplotlib, Plotly, Tensorfolw, Theano...., [Linear Algebra](https://www.kaggle.com/mjbahmani/linear-algebra-for-data-scientists), [Big Data](https://www.kaggle.com/mjbahmani/a-data-science-framework-for-quora), Analysis Tools and solve real problem for instance predict house prices.\n###### [go to top](#top)"},{"metadata":{"_uuid":"5efeff35ad9951e40551d0763eaf26f08bb4119e"},"cell_type":"markdown","source":" <a id=\"1\"></a> <br>\n# 1-Python\n\nfor Reading this section **please** fork and upvote  this kernel:\n\n[numpy-pandas-matplotlib-seaborn-scikit-learn](https://www.kaggle.com/mjbahmani/numpy-pandas-matplotlib-seaborn-scikit-learn)\n# 1-1 Why you should use python?\n\nAs **machine learning engineer** I would like to compare 4 machine learning programming languages(tools). Let's take this a bit deeper. Since most of us are concerned with ML and analysis being a big part of why we are using these programs. I want to list a few advantages and disadvantages of each for who want to start learning them as a data scientist.\n## 1-1-1 R\nR is a language and environment for statistical computing and graphics. It is a GNU project which is similar to the S language and environment which was developed at Bell Laboratories (formerly AT&amp;T, now Lucent Technologies) by **John Chambers** and colleagues. **R** can be considered as a different implementation of S. There are some important differences, but much code written for S runs unaltered under R.\n\n### 1-1-1-1 Advantages of R \n\n* End To End development to execution (some brokers packages allows execution, IB)\n* Rapid development speed (60% fewer lines vs python, ~500% less than C)\n* A large number of Open Source Packages\n* Mature quantitative trading packages( quantstrat, quantmod, performanceanalyitics, xts)\n* Largest Community\n* Can integrate into C++/C with rcpp\n\n### 1-1-1-2 Disadvantages of R \n\n* Slow vs Python especially in iterative loops and non vectorized functions\n* Worse plotting than python and difficult to implement interactive charts\n* Limited capabilities in creating stand-alone applications\n\n## 1-1-2 Python\n\nPython is an interpreted high-level programming language for general-purpose programming. Created by Guido van Rossum and first released in 1991, Python has a design philosophy that emphasizes code readability, notably using significant whitespace. It provides constructs that enable clear programming on both small and large scales.\n\n### 1-1-2-1Advantages\n\n* End To End development to execution (some brokers packages allows execution, IB)\n* Open source packages( Pandas, Numpy, scipy) \n* Trading Packages(zipline, pybacktest, pyalgotrade)\n* best for general programming and application development\n* can be a \"glue\" language to connect R, C++, and others (python)\n* Fastest general speed especially in iterative loops\n\n### 1-1-2-2 Disadvantages\n\n* immature packages especially trading packages\n* some packages are not compatible with others or contain overlap\n* smaller community than R in finance\n* More code required for same operations vs R or Matlab\n* Silent errors that can take a very long time to track down (even with visual debuggers / IDE)\n\n## 1-1-3 MATLAB\n\n**MATLAB (matrix laboratory)** is a multi-paradigm numerical computing environment. A proprietary programming language developed by MathWorks, MATLAB allows matrix manipulations, plotting of functions and data, implementation of algorithms, a creation of user interfaces, and interfacing with programs written in other languages, including C, C++, C#, Java, Fortran, and Python.\nAlthough MATLAB is intended primarily for numerical computing, an optional toolbox uses the MuPAD symbolic engine, allowing access to symbolic computing abilities. An additional package, Simulink, adds graphical multi-domain simulation and model-based design for dynamic and embedded systems.\n\n### 1-1-3-1 Advantages\n\n1. Fastest mathematical and computational platform especially vectorized operations/ linear matrix algebra \n1. Commercial level packages for all fields of mathematics and trading\n1. Very short scripts considering the high integration of all packages\n1. Best visualization of plots and interactive charts\n1. Well tested and supported due to it being a commercial product\n1. Easy to manage multithreaded support and garbage collection\n1. Best debugger\n\n### 1-1-3-2 Disadvantages\n\n1. Can not execute - must be translated into another language\n1. Expensive ~1000 per license and 50+ per additional individual package\n1. Can not integrate well with other languages\n1. Hard to detect biases in trading systems (it was built for math and engineering simulations) so extensive testing may be required. EG. look ahead bias\n1. Worst performance for iterative loops\n1. Can not develop stand-alone applications at all.\n\n## 1-1-4 Octave\n\nOctave is sort of the GNU answer to the commercial language MATLAB. That is, it is a scripting matrix language, and has a syntax that is about 95% compatible with MATLAB. It's a language designed by engineers, and thus is heavily loaded with routines commonly used by engineers. It has many of the same time series analysis routines, statistics routines, file commands, and plotting commands of the MATLAB language.\n\n### 1-1-4-1 Advantages\n\n1. First of all, there is no robust Octave compiler available and this is not really necessary either since the software can be installed free of charge.\n1. Looking at the language element the two packages are identical except for some particularities like nested functions. Octave is under constant active development and every deviation from the Matlab syntax is treated as a bug or at least an issue to be resolved.\n1. There are also plenty of toolboxes available for octave and as long as a program does not require graphical output there is a good chance that it runs under Octave just like under Matlab without considerable modification.\n1. Graphics capabilities are clearly an advantage of Matlab. The latest versions include a GUI designer on top of excellent visualization features.\n1. Octave uses either GNU Plot or JHandles as graphics packages, where the latter is somehow closer to what Matlab provides. However, there are no Octave equivalents to a GUI designer and the visualization mechanisms are somehow limited and not Matlab compatible.\n1. The same holds for an integrated development environment. There is a project called QTOctave but it is still at an early stage.\n1. Looking at the collaborate efforts taking place around the Octave community it is likely that this software will soon provide better and possibly even compatible graphics and GUI capabilities and it is well worth a look before buying Matlab.\n\n### 1-1-4-2 Disadvantages\n\n1. it just a free open source of MATLAB and don't bring us anything new\n\n## 1-2 Conclusion\n\nWe can now see a number of comparisons already made by other sources.\n\n<img src='https://media.licdn.com/dms/image/C4E12AQHC8vSsbqji1A/article-inline_image-shrink_1500_2232/0?e=1543449600&amp;v=beta&amp;t=lUVejbr2Lwdz9hZuYmVY3upQB2B4ZIjJsP6eiwvrW0A'>\n<img src='https://media.licdn.com/dms/image/C4E12AQEH61x6adp36A/article-inline_image-shrink_1000_1488/0?e=1543449600&amp;v=beta&amp;t=EJdx7dx7UMFnOpc5QndIulg9GI2Fd1NyAouEM6s945Q'>\n\n\n\nTo sum up, there are several tools for data scientist and machine learning engineer in the below chart you can see which one is more popular than others.\n<img src='https://media.licdn.com/dms/image/C4D12AQGPCHd41RDuzg/article-inline_image-shrink_1000_1488/0?e=1543449600&amp;v=beta&amp;t=aksgcN2r_TRkBKgaxYbLh-rZHsMa8xqXiBm-oravz-k'>\n[reference](https://www.linkedin.com/pulse/r-vs-python-matlab-octave-mohamadjavad-mj-bahmani/)\n\n \n  \n  [Download paper](https://github.com/mjbahmani/Machine-Learning-Workflow-with-Python/blob/master/Ebooks/R%20vs%20Python%20vs%20MATLAB%20%20vs%20Octave.pdf)\n  ###### [go to top](#top)"},{"metadata":{"_uuid":"1a8697f93952e076f6f949997676d40518d7b5a6"},"cell_type":"markdown","source":"<a id=\"11\"></a> <br>\n# 2-Python Packages\n1. Numpy\n1. Pandas\n1. Matplotlib\n1. Seaborn\n1. TensorFlow\n1. NLTK\n1. Sklearn\n\n<img src=\"http://s8.picofile.com/file/8338227868/packages.png\">\n\nfor Reading this section **please** fork and upvote  this kernel:\n\n\n\n1. [The data scientist's toolbox tutorial 1](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-1)\n\n1. [The data scientist's toolbox tutorial 2](https://www.kaggle.com/mjbahmani/the-data-scientist-s-toolbox-tutorial-2)\n###### [go to top](#top)"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"38d94abd1c1dae4294d41e4ba94fcb7b1e9f29d6"},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pylab as pylab\nimport matplotlib.pyplot as plt\nfrom pandas import get_dummies\nimport matplotlib as mpl\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport warnings\nimport sklearn\nimport scipy\nimport numpy\nimport json\nimport sys\nimport csv\nimport os\n\n\nprint('matplotlib: {}'.format(matplotlib.__version__))\nprint('sklearn: {}'.format(sklearn.__version__))\nprint('scipy: {}'.format(scipy.__version__))\nprint('seaborn: {}'.format(sns.__version__))\nprint('pandas: {}'.format(pd.__version__))\nprint('numpy: {}'.format(np.__version__))\nprint('Python: {}'.format(sys.version))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad8fa54ba57aa4a336080eb044109702c743d7a0"},"cell_type":"markdown","source":"<a id=\"Mathematics and Linear Algebra\"></a> <br>\n##  3- Mathematics and Linear Algebra\nLinear algebra is the branch of mathematics that deals with vector spaces. good understanding of Linear Algebra is intrinsic to analyze Machine Learning algorithms, especially for Deep Learning where so much happens behind the curtain.you have my word that I will try to keep mathematical formulas & derivations out of this completely mathematical topic and I try to cover all of subject that you need as data scientist.\n\n<img src=\" https://s3.amazonaws.com/www.mathnasium.com/upload/824/images/algebra.jpg \" height=\"300\" width=\"300\">\n\nfor Reading this section **please** fork and upvote  this kernel:\n\n[Linear Algebra for Data Scientists](https://www.kaggle.com/mjbahmani/linear-algebra-in-60-minutes)\n###### [go to top](#top)"},{"metadata":{"_uuid":"697ba206ad7adf4d99814cb1d89375b745eaba19"},"cell_type":"markdown","source":"<a id=\"Programming & Analysis Tools\"></a> <br>\n## 4- Programming & Analysis Tools\n\n* **RapidMiner**:\n\nRapidMiner (RM) was originally started in 2006 as an open-source stand-alone software named Rapid-I. Over the years, they have given it the name of RapidMiner and also attained ~35Mn USD in funding. The tool is open-source for old version (below v6) but the latest versions come in a 14-day trial period and licensed after that.\n\nRM covers the entire life-cycle of prediction modeling, starting from data preparation to model building and finally validation and deployment. The GUI is based on a block-diagram approach, something very similar to Matlab Simulink. There are predefined blocks which act as plug and play devices. You just have to connect them in the right manner and a large variety of algorithms can be run without a single line of code. On top of this, they allow custom R and Python scripts to be integrated into the system.\n\nThere current product offerings include the following:\n\n1. RapidMiner Studio: A stand-alone software which can be used for data preparation, visualization and statistical modeling\n1. RapidMiner Server: It is an enterprise-grade environment with central repositories which allow easy team work, project management and model deployment\n1. RapidMiner Radoop: Implements big-data analytics capabilities centered around Hadoop\n1. RapidMiner Cloud: A cloud-based repository which allows easy sharing of information among various devices\nRM is currently being used in various industries including automotive, banking, insurance, life Sciences, manufacturing, oil and gas, retail, telecommunication and utilities.\n\n* **DataRobot**:\n\nDataRobot (DR) is a highly automated machine learning platform built by all time best Kagglers including Jeremy Achin, Thoman DeGodoy and Owen Zhang. Their platform claims to have obviated the need for data scientists. This is evident from a phrase from their website – “Data science requires math and stats aptitude, programming skills, and business knowledge. With DataRobot, you bring the business knowledge and data, and our cutting-edge automation takes care of the rest.”\n\nDR proclaims to have the following benefits:\n\n1. Model Optimization\nPlatform automatically detects the best data pre-processing and feature engineering by employing text mining, variable type detection, encoding, imputation, scaling, transformation, etc.\nHyper-parameters are automatically chosen depending on the error-metric and the validation set score\n1. Parallel Processing\nComputation is divided over thousands of multi-core servers\nUses distributed algorithms to scale to large data sets\n1. Deployment\nEasy deployment facilities with just a few clicks (no need to write any new code)\n1. For Software Engineers\nPython SDK and APIs available for quick integration of models into tools and softwares.\n\n**BigML**:\n\nBigML provides a good GUI which takes the user through 6 steps as following:\n\n1. Sources: use various sources of information\n1. Datasets: use the defined sources to create a dataset\n1. Models: make predictive models\n1. Predictions: generate predictions based on the model\n1. Ensembles: create ensemble of various models\n1. Evaluation: very model against validation sets\nThese processes will obviously iterate in different orders. The BigML platform provides nice visualizations of results and has algorithms for solving classification, regression, clustering, anomaly detection and association discovery problems. They offer several packages bundled together in monthly, quarterly and yearly subscriptions. They even offer a free package but the size of the dataset you can upload is limited to 16MB.\n\n**Google Cloud AutoML**:\n\nCloud AutoML is part of Google’s Machine Learning suite offerings that enables people with limited ML expertise to build high quality models. The first product, as part of the Cloud AutoML portfolio, is Cloud AutoML Vision. This service makes it simpler to train image recognition models. It has a drag-and-drop interface that let’s the user upload images, train the model, and then deploy those models directly on Google Cloud.\n\nCloud AutoML Vision is built on Google’s transfer learning and neural architecture search technologies (among others). This tool is already being used by a lot of organizations. Check out this article to see two amazing real-life examples of AutoML in action, and how it’s producing better results than any other tool.\n\n**Paxata**:\n\nPaxata is one of the few organizations which focus on data cleaning and preparation, and not the machine learning or statistical modeling part. It is an MS Excel-like application that is easy to use. It also provides visual guidance making it easy to bring together data, find and fix dirty or missing data, and share and re-use data projects across teams. Like the other tools mentioned in this article, Paxata eliminates coding or scripting, hence overcoming technical barriers involved in handling data.\n\nPaxata platform follows the following process:\n\nAdd Data: use a wide range of sources to acquire data\n1. Explore: perform data exploration using powerful visuals allowing the user to easily identify gaps in data\nClean+Change: perform data cleaning using steps like imputation, normalization of similar values using NLP, detecting duplicates\n1. Shape: make pivots on data, perform grouping and aggregation\nShare+Govern: allows sharing and collaborating across teams with strong authentication and authorization in place\nCombine: a proprietary technology called SmartFusion allows combining data frames with 1 click as it automatically detects the best combination possible; multiple data sets can be combined into a single AnswerSet\n1. BI Tools: allows easy visualization of the final AnswerSet in commonly used BI tools; also allows easy iterations between data preprocessing and visualization\nPraxata has set its foot in financial services, consumer goods and networking domains. It might be a good tool to use if your work requires extensive data cleaning.\n\n**Microsoft Azure ML Studio**\n\nWhen there are so many big name players in this field, how could Microsoft lag behind? The Azure ML Studio is a simple yet powerful browser based ML platform. It has a visual drag-and-drop environment where there is no requirement of coding. They have published comprehensive tutorials and sample experiments for newcomers to get the hang of the tool quickly. It employs a simple five step process:\n\n1. Import your dataset\n1. Perform data cleaning and other preprocessing steps, if necessary\n1. Split the data into training and testing sets\n1. Apply built-in ML algorithms to train your model\n1. Score your model and get your predictions!\n**Amazon Lex**:\n\nAmazon Lex provides an easy-to-use console for building your own chatbot in a matter of minutes. You can build conversational interfaces in your applications or website using Lex. All you need to do is supply a few phrases and Amazon Lex does the rest! It builds a complete Natural Language model using which a customer can interact with your app, using both voice and text.\n\nIt also comes with built-in integration with the Amazon Web Services (AWS) platform. Amazon Lex is a fully managed service so as your user engagement increases, you don’t need to worry about provisioning hardware and managing infrastructure to improve your bot experience.\n\nIn this section, we have discussed **various** initiatives working towards automating various aspects of solving a data science problem. Some of them are in a nascent research stage, some are open-source and others are already being used in the industry with millions in funding. All of these pose a potential threat to the job of a data scientist, which is expected to grow in the near future. These tools are best suited for people who are not familiar with programming & coding.\n###### [go to top](#top)"},{"metadata":{"_uuid":"00f5c5ce80c7e302e83f0ea9b451dfaae7aa52cf"},"cell_type":"markdown","source":"<a id=\"Big Data\"></a> <br>\n## 5- Big Data\n\nfor Reading this section **please** fork and upvote  this kernel:\n\n[A-Comprehensive-Deep-Learning-Workflow-with-Python](https://www.kaggle.com/mjbahmani/a-comprehensive-deep-learning-workflow-with-python)\n"},{"metadata":{"_uuid":"33bb9c265bef5e4474dcac0638cc632b5532f1ce"},"cell_type":"markdown","source":"<a id=\"Data Visualization\"></a> <br>\n## 6- Data Visualization\nfor Reading this section **please** fork and upvote  this kernel:\n\n[Exploratory Data Analysis for Meta Kaggle Dataset](https://www.kaggle.com/mjbahmani/exploratory-data-analysis-for-meta-kaggle-dataset)"},{"metadata":{"_uuid":"9bf1d9444651e2756c4fa4d71914ec20d621305e"},"cell_type":"markdown","source":"<a id=\"Data Cleaning\"></a> <br>\n## 7- Data Cleaning\nfor Reading this section **please** fork and upvote  this kernel:\n\n[A-Comprehensive-Deep-Learning-Workflow-with-Python](https://www.kaggle.com/mjbahmani/a-comprehensive-deep-learning-workflow-with-python)"},{"metadata":{"_uuid":"8720a4ddaab64e4bff226bed9e4e200dc9b94913"},"cell_type":"markdown","source":"<a id=\"How to solve Problem?\"></a> <br>\n## 8- How to solve Problem?\nIf you have already read some [machine learning books](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist/tree/master/Ebooks). You have noticed that there are different ways to stream data into machine learning.\n\nmost of these books share the following steps (checklist):\n*   Define the Problem(Look at the big picture)\n*   Specify Inputs & Outputs\n*   Data Collection\n*   Exploratory data analysis\n*   Data Preprocessing\n*   Model Design, Training, and Offline Evaluation\n*   Model Deployment, Online Evaluation, and Monitoring\n*   Model Maintenance, Diagnosis, and Retraining\n\n**You can see my workflow in the below image** :\n <img src=\"http://s9.picofile.com/file/8338227634/workflow.png\" />\n## 8-1 Real world Application Vs Competitions\nJust a simple comparison between real-world apps with competitions:\n<img src=\"http://s9.picofile.com/file/8339956300/reallife.png\" height=\"600\" width=\"500\" />\n**you should\tfeel free\tto\tadapt \tthis\tchecklist \tto\tyour needs**\n \n## 8-2 Problem Definition\nI think one of the important things when you start a new machine learning project is Defining your problem. that means you should understand business problem.( **Problem Formalization**)\n\nProblem Definition has four steps that have illustrated in the picture below:\n<img src=\"http://s8.picofile.com/file/8338227734/ProblemDefination.png\">\n \n### 8-2-1 Problem Feature\nThe sinking of the Titanic is one of the most infamous shipwrecks in history. **On April 15, 1912**, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing **1502 out of 2224** passengers and crew. That's why the name DieTanic. This is a very unforgetable disaster that no one in the world can forget.\n\nIt took about $7.5 million to build the Titanic and it sunk under the ocean due to collision. The Titanic Dataset is a very good dataset for begineers to start a journey in data science and participate in competitions in Kaggle.\n\nwe will use the classic titanic data set. This dataset contains information about **11 different variables**:\n<img src=\"http://s9.picofile.com/file/8340453092/Titanic_feature.png\" height=\"500\" width=\"500\">\n\n* Survival\n* Pclass\n* Name\n* Sex\n* Age\n* SibSp\n* Parch\n* Ticket\n* Fare\n* Cabin\n* Embarked\n\n### 8-2-2 Aim\n\nIt is your job to predict if a passenger survived the sinking of the Titanic or not.  For each PassengerId in the test set, you must predict a 0 or 1 value for the Survived variable.\n\n \n### 8-2-3 Variables\n\n1.  **Age** ==>> Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\n2. **Sibsp** ==>> The dataset defines family relations in this way...\n\n    a. Sibling = brother, sister, stepbrother, stepsister\n\n    b. Spouse = husband, wife (mistresses and fiancés were ignored)\n\n3. **Parch** ==>> The dataset defines family relations in this way...\n\n    a. Parent = mother, father\n\n    b. Child = daughter, son, stepdaughter, stepson\n\n    c. Some children travelled only with a nanny, therefore parch=0 for them.\n\n4. **Pclass** ==>> A proxy for socio-economic status (SES)\n\n    * 1st = Upper\n    * 2nd = Middle\n    * 3rd = Lower\n    \n5. **Embarked** ==>> nominal datatype \n6. **Name** ==>> nominal datatype . It could be used in feature engineering to derive the gender from title\n7. **Sex** ==>>  nominal datatype \n8. **Ticket** ==>> that have no impact on the outcome variable. Thus, they will be excluded from analysis\n9. **Cabin** ==>>  is a nominal datatype that can be used in feature engineering\n11. **Fare** ==>>  Indicating the fare\n12. **PassengerID ** ==>> have no impact on the outcome variable. Thus, it will be excluded from analysis\n11. **Survival** is ==>> **[dependent variable](http://www.dailysmarty.com/posts/difference-between-independent-and-dependent-variables-in-machine-learning)** , 0 or 1\n\n\n**<< Note >>**\n\n> You must answer the following question:\nHow does your company expact to use and benfit from your model.\n###### [Go to top](#top)"},{"metadata":{"_uuid":"d4f8718cc7e1a8fc60a3815b55a2ab9a5eeef4f9"},"cell_type":"markdown","source":"<a id=\"Machine learning\"></a> <br>\n## 9- Machine learning  \nfor Reading this section **please** fork and upvote  this kernel:\n\n[A Comprehensive ML Workflow with Python](https://www.kaggle.com/mjbahmani/a-comprehensive-ml-workflow-with-python)\n\n"},{"metadata":{"_uuid":"3544d2fd1490f646f2f1c0fd4271f9a8745d2e36"},"cell_type":"markdown","source":"<a id=\"Deep Learning\"></a> <br>\n##  10- Deep Learning\n\nfor Reading this section **please** fork and upvote  this kernel:\n\n[A-Comprehensive-Deep-Learning-Workflow-with-Python](https://www.kaggle.com/mjbahmani/a-comprehensive-deep-learning-workflow-with-python)\n\n---------------------------\n"},{"metadata":{"_uuid":"ebdc3b3e54b35a96ef9a76244e1214beb168c823"},"cell_type":"markdown","source":"<a id=\"Introducing other sources\"></a> <br>\n## 11- Introducing other sources\nIn this section I introduce additional resources for further study.\n## 11-1 papers\nYou may not like these 10 steps or have an idea other than this!!! But I just want to list 10 steps that I consider to be the most important thing to do, and surely other skills are needed for the Data Scientist. here I listed some papers around the internet Which can help everyone better understand the work process!!\n\n1- [10-steps-to-become-data-scientist-in-2018](https://dzone.com/articles/10-steps-to-become-data-scientist-in-2018)\n\n2- [10-steps-to-become-a-data-scientist](http://techtowntraining.com/resources/tools-resources/10-steps-to-become-a-data-scientist)\n\n3- [ultimate-learning-path-becoming-data-scientist-2018](https://www.analyticsvidhya.com/blog/2018/01/ultimate-learning-\npath-becoming-data-scientist-2018/)\n\n4- [become-a-data-scientist](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist)\n## 11-2 Books\nThere are plenty of E-books(free). here is **10 free machine learning Ebooks** that can make your dreams come true [4]:\n\n1. [Probability and Statistics for Programmers](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist/tree/master/Ebooks)\n2. [Bayesian Reasoning and Machine Learning](http://web4.cs.ucl.ac.uk/staff/D.Barber/textbook/091117.pdf)\n2. [An Introduction to Statistical Learning](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist/tree/master/Ebooks)\n2. [Understanding Machine Learning](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/index.html)\n2. [A Programmer’s Guide to Data Mining](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist/tree/master/Ebooks)\n2. [Mining of Massive Datasets](http://infolab.stanford.edu/~ullman/mmds/book.pdf)\n2. [A Brief Introduction to Neural Networks](http://www.dkriesel.com/_media/science/neuronalenetze-en-zeta2-2col-dkrieselcom.pdf)\n2. [Deep Learning](http://www.deeplearningbook.org/)\n2. [Natural Language Processing with Python](https://www.researchgate.net/publication/220691633_Natural_Language_Processing_with_Python)\n2. [Machine Learning Yearning](http://www.mlyearning.org/)\n\n## 11-3 cheat sheets\nData Science is an ever-growing field, there are numerous tools & techniques to remember. It is not possible for anyone to remember all the functions, operations and formulas of each concept. That’s why we have cheat sheets.\n1. [Quick Guide to learn Python for Data Science ](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist/tree/master/cheatsheets)\n1. [Python for Data Science Cheat sheet ](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist/tree/master/cheatsheets)\n1. [Python For Data Science Cheat Sheet NumPy ](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist/tree/master/cheatsheets)\n1. [Exploratory Data Analysis in Python ](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist/tree/master/cheatsheets)\n1. [Data Visualisation in Python ](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist/tree/master/cheatsheets ](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Python_Bokeh_Cheat_Sheet.pdf)\n1. [Cheat Sheet: Scikit Learn ](https://www.analyticsvidhya.com/infographics/Scikit-Learn-Infographic.pdf)\n1. [Steps To Perform Text Data Cleaning in Python](https://www.analyticsvidhya.com/blog/2015/06/quick-guide-text-data-cleaning-python/)\n1. [Probability Basics  Cheat Sheet](http://www.sas.upenn.edu/~astocker/lab/teaching-files/PSYC739-2016/probability_cheatsheet.pdf)\n1. [Probability cheat sheet for distribution](http://www.cs.elte.hu/~mesti/valszam/kepletek)"},{"metadata":{"_uuid":"3065412feed4f072e90154bb3eaed0fc3504d88d","collapsed":true},"cell_type":"markdown","source":"<a id=\"References\"></a> <br>\n## References:\n1. [Coursera](https://www.coursera.org/specializations/data-science-python)\n1. [Hands-On Machine Learning with Scikit-Learn and TensorFlow](http://shop.oreilly.com/product/0636920052289.do)\n1. [Top 28 Cheat Sheets for Machine Learning, Data Science, Probability, SQL & Big Data](https://www.analyticsvidhya.com/blog/2017/02/top-28-cheat-sheets-for-machine-learning-data-science-probability-sql-big-data/)\n1. [ GitHub](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist)\n"},{"metadata":{"_uuid":"edb768e0b3390ec29acab20593948c3f3bbf5bba","collapsed":true},"cell_type":"markdown","source":"---------------------------------------------------------------------\nFork and Run this kernel on GitHub:\n> ###### [ GitHub](https://github.com/mjbahmani/10-steps-to-become-a-data-scientist)\n\n \n\n-------------------------------------------------------------------------------------------------------------\n <b>I hope you find this kernel helpful and some <font color=\"red\">UPVOTES</font> would be very much appreciated</b>\n \n -----------"},{"metadata":{"_uuid":"e07313484155d573b97e7d21e6be7a60dc6768e3","collapsed":true},"cell_type":"markdown","source":"## Not completed yet!!!\n\n**Update every two days**\n###### [go to top](#top)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}