{"nbformat": 4, "cells": [{"source": ["# Deep Learning from Start to Finish with Keras\n", "\n", "This notebook covers the basic Deep Learning with Keras.\n", "\n", "### Steps Covered\n", "\n", "1. Importing  a DataFrame\n", "2. Cleanup and Transform the Data\n", "3. Split Training and Test Sets\n", "4. Train and optimize \n", "5. Prediction\n", "\n", "### Background and Credits\n", "\n", "I just completed very first course of Deep Learning Specialization at Coursera (more info here https://www.coursera.org/specializations/deep-learning) few weeks ago, and like to see how to apply what I learn to \"actual work\", this is my very first attempt using Keras for NN for Titanic prediction.\n", "\n", "I have use andrefer the following projects/Books for my prediction:\n", "1.  \"Machine Learning from Start to Finish with Scikit-Learn\" https://www.kaggle.com/jeffd23/scikit-learn-ml-from-start-to-finish\n", "2. \"Deep Learning with Python\" from Manning, https://www.manning.com/books/deep-learning-with-python\n", "\n"], "metadata": {"_cell_guid": "70a2567b-104a-4aa5-92d6-d01c5acfa1ba", "_uuid": "6e2f7002d643692ebfab5263156a884e0e8ae253"}, "cell_type": "markdown"}, {"source": ["### Step 1 Import the Dataframe\n", "1. Import all necessary library \n", "2. Import the data, for both training_set, and testing_set\n", "3. Split the dataset to X Input data set(i.e. 'Sex', 'Cabin', 'Fares and etc), and our Prediction-Y label, i.e. if a passenger Survived field\n", "4. I decide to drop PassengerId, Name and Ticket fields, as I don't think our training model will benefits from these fields"], "metadata": {}, "cell_type": "markdown"}, {"source": ["import numpy as np\n", "import pandas as pd\n", "\n", "from keras import models\n", "from keras import layers\n", "from keras import optimizers\n", "from keras import losses \n", "from keras import metrics\n", "\n", "import matplotlib.pyplot as plt"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["training_set = pd.read_csv('../input/train.csv')\n", "testing_set = pd.read_csv('../input/test.csv')\n", "\n", "x_train = training_set.drop(['PassengerId','Name','Ticket','Survived'], axis=1)\n", "y_train = training_set['Survived']\n", "\n", "x_test = testing_set.drop(['PassengerId','Name','Ticket'], axis=1)"], "outputs": [], "metadata": {"_kg_hide-output": false}, "execution_count": null, "cell_type": "code"}, {"source": ["x_train['Age'] = x_train['Age'].fillna(x_train['Age'].mean())\n", "x_test['Age'] = x_test['Age'].fillna(x_test['Age'].mean())"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["### Step 2 Cleanup and Transform the Data\n", "\n", "Transform all categorial values into numeric value for both Training and Testing data set\n"], "metadata": {}, "cell_type": "markdown"}, {"source": ["def simplify_ages(df):\n", "    #df['Age'] = df['Age'].fillna(-0.5)\n", "    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n", "    group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n", "    categories = pd.cut(df['Age'], bins, labels=group_names)\n", "    df['Age'] = categories.cat.codes \n", "    return df\n", "\n", "def simplify_cabins(df):\n", "    df['Cabin'] = df['Cabin'].fillna('N')\n", "    df['Cabin'] = df['Cabin'].apply(lambda x: x[0])\n", "    df['Cabin'] =  pd.Categorical(df['Cabin'])\n", "    df['Cabin'] = df['Cabin'].cat.codes \n", "    return df\n", "\n", "def simplify_fares(df):\n", "    df['Fare'] = df.Fare.fillna(-0.5)\n", "    bins = (-1, 0, 8, 15, 31, 1000)\n", "    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n", "    categories = pd.cut(df['Fare'], bins, labels=group_names)\n", "    df['Fare'] = categories.cat.codes \n", "    return df\n", "\n", "def simplify_sex(df):\n", "    df['Sex'] = pd.Categorical(df['Sex'])\n", "    df['Sex'] = df['Sex'].cat.codes \n", "    return df\n", "\n", "def simplify_embarked(df):\n", "    df['Embarked'] = pd.Categorical(df['Embarked'])\n", "    df['Embarked'] = df['Embarked'].cat.codes + 1\n", "    return df\n", "\n", "def transform_features(df):\n", "    df = simplify_ages(df)\n", "    df = simplify_cabins(df)\n", "    df = simplify_fares(df)\n", "    df = simplify_sex(df)\n", "    df = simplify_embarked(df)\n", "    return df\n"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["transform_features(x_train)\n", "transform_features(x_test)"], "outputs": [], "metadata": {"_kg_hide-output": true}, "execution_count": null, "cell_type": "code"}, {"source": ["### Step 3 Build the NN model using Keras\n", "\n", " 3 Layers, first 2 layers with 32 hidden value with \"Relu\" activation function\n", " Last layer with Sigmoid activation function"], "metadata": {}, "cell_type": "markdown"}, {"source": ["model = models.Sequential()\n", "model.add(layers.Dense(32, activation='relu', \n", "                       input_shape=(8,)))\n", "model.add(layers.Dense(32, activation='relu'))\n", "model.add(layers.Dense(16, activation='relu'))\n", "#model.add(layers.Dense(8, activation='relu'))\n", "model.add(layers.Dense(1, activation='sigmoid'))\n", "\n", "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n", "             loss=losses.binary_crossentropy,\n", "             metrics=[metrics.binary_accuracy])"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["### Step 3.1 Split the training data set with validation set, and run the model\n", "\n", "Default validation set size is 50"], "metadata": {}, "cell_type": "markdown"}, {"source": ["y_train = np.asarray(y_train)\n", "x_train = np.asarray(x_train)\n", "x_test = np.asarray(x_test)\n", "\n", "validation_size = 200\n", "\n", "x_val = x_train[:validation_size]\n", "partial_x_train = x_train[validation_size:]\n", "\n", "y_val = y_train[:validation_size]\n", "partial_y_train = y_train[validation_size:]"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["history = model.fit(partial_x_train, partial_y_train, epochs=30, validation_data=(x_val, y_val))"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["#### Step 3.2 Plot accuracy and loss for both training and validation set, to check the model optimization level"], "metadata": {}, "cell_type": "markdown"}, {"source": ["acc = history.history['binary_accuracy']\n", "val_acc = history.history['val_binary_accuracy']\n", "loss = history.history['loss']\n", "val_loss = history.history['val_loss']\n", "\n", "epochs = range(1, len(acc) + 1)\n", "plt.plot(epochs, loss, 'bo', label='Training loss')\n", "plt.plot(epochs, val_loss,'b', label='Validation loss')\n", "\n", "plt.legend()\n", "plt.xlabel('Epochs')\n", "plt.ylabel('Loss')\n", "plt.show()"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["plt.clf()\n", "\n", "epochs = range(1, len(acc) + 1)\n", "plt.plot(epochs, acc, 'bo', label='Training Acc')\n", "plt.plot(epochs, val_acc,'b', label='Validation Acc')\n", "plt.legend()\n", "plt.xlabel('Epochs')\n", "plt.ylabel('Acc')\n", "plt.show()"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["### Step 4 Optimization\n", "\n", "Repeat Step 3 multiple times till we find best model for this dataset. \n", "Example:\n", "\n", "- Will adding more hidden units or additional hidden layer help? \n", "- what if I change my activation function? \n", "- increase/decrease my learning rate?\n", "- Will increase number of Epochs help?"], "metadata": {}, "cell_type": "markdown"}, {"source": ["### Step 5 Predict the actual Test Data"], "metadata": {}, "cell_type": "markdown"}, {"source": ["predictions = model.predict_classes(x_test)\n", "ids = testing_set['PassengerId'].copy()\n", "new_output = ids.to_frame()\n", "new_output[\"Survived\"]=predictions\n", "new_output.head(10)\n"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["new_output.to_csv(\"my_submission.csv\",index=False)"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": [], "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}], "nbformat_minor": 1, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "version": "3.6.1", "name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python"}}}