{"nbformat_minor": 0, "nbformat": 4, "cells": [{"outputs": [], "metadata": {"_uuid": "240c46f76b34b650503487b40c9901fff9c11a12", "_cell_guid": "25b1e1db-8bc5-7029-f719-91da523bd121"}, "cell_type": "markdown", "source": "## Introduction ##\n\nThis is my first work of machine learning. the notebook is written in python.", "execution_count": null}, {"outputs": [], "metadata": {"_execution_state": "idle", "collapsed": false, "_uuid": "0421b12f31e1506c3c0a4e3f9d289e40b35215ed", "_cell_guid": "7a23526b-fc58-4a03-8439-1c855e8436b0"}, "cell_type": "markdown", "source": "First I import libs + load data. \nI also prepare bigger passengers group by combine test and train data. So I can study correlation between data. ", "execution_count": null}, {"outputs": [], "metadata": {"_execution_state": "idle", "collapsed": false, "_uuid": "65f550010fc505f379914e40f266b6a878c45a63", "_cell_guid": "74bfd013-b508-4704-b61d-87d071e15b3a"}, "cell_type": "markdown", "source": "Import libs", "execution_count": null}, {"outputs": [], "metadata": {"_execution_state": "idle", "collapsed": false, "trusted": false, "_uuid": "1e351f167a54e2d3cae574adb5fef3dc3487c424", "_cell_guid": "fd3815d5-dd39-4d93-ab68-7e02274e6f7d"}, "cell_type": "code", "source": "import numpy as np\nimport pandas as pd\nimport re as re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\n\nfrom scipy.stats import norm", "execution_count": 1}, {"outputs": [], "metadata": {"_execution_state": "idle", "collapsed": false, "_uuid": "ce9ea610f9294983e96f3fdf23717fa32a0a1e01", "_cell_guid": "e0afc963-3724-4713-b50e-c2454fdd90b9"}, "cell_type": "markdown", "source": "Load data", "execution_count": null}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_uuid": "21f916959fbad1344cf138a8fe0e30ed45e46cb2", "_cell_guid": "2ce68358-02ec-556d-ba88-e773a50bc18b"}, "cell_type": "code", "source": "train = pd.read_csv('../input/train.csv', header = 0, dtype={'Age': np.float64})\ntest  = pd.read_csv('../input/test.csv' , header = 0, dtype={'Age': np.float64})", "execution_count": 2}, {"outputs": [], "metadata": {"_execution_state": "idle", "collapsed": false, "_uuid": "b2513f727d85bd3358d4e10bd6a10000bc8de615", "_cell_guid": "8407cb88-c55c-48b4-ac1f-30f954e65ff7"}, "cell_type": "markdown", "source": "Check missing data", "execution_count": null}, {"outputs": [], "metadata": {"_execution_state": "idle", "collapsed": false, "trusted": false, "_uuid": "9ed7dd48e90b505d52780e84e34d70ce8784f341", "_cell_guid": "1c56226a-7651-4555-ac4e-f4d99ba82408"}, "cell_type": "code", "source": "#missing train data\n\ntotal = train.isnull().sum().sort_values(ascending=False)\npercent = (train.isnull().sum()/train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)", "execution_count": 3}, {"outputs": [], "metadata": {"_execution_state": "idle", "collapsed": false, "trusted": false, "_uuid": "555568d9789ea10eca243a5f3caf5a204519e0b1", "_cell_guid": "1be706a2-d30b-47df-9b8d-1aafc50dbdd7"}, "cell_type": "code", "source": "\n#missing test data\n\ntotal = test.isnull().sum().sort_values(ascending=False)\npercent = (test.isnull().sum()/test.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)", "execution_count": 4}, {"outputs": [], "metadata": {"_execution_state": "idle", "collapsed": false, "_uuid": "41f0b65b60b563d84957868fae9c593042761ae5", "_cell_guid": "5d6b9566-be2c-49ad-be02-f455df30d9a6"}, "cell_type": "markdown", "source": "## Prepare data calculation ##", "execution_count": null}, {"outputs": [], "metadata": {"_execution_state": "idle", "collapsed": false, "trusted": false, "_uuid": "23e5a47528a17050f4e4562f5faf49013a916731", "_cell_guid": "f796edd8-2973-4f2e-bc85-dffbf93fe53d"}, "cell_type": "code", "source": "# for debug purpose\ndef die(error_message):\n    raise Exception(error_message)\n\n\n# cabin transform\ndef cabin_value(cabin):\n    if str(cabin) == 'nan':\n        return str('0')\n    else:\n        return ord(cabin[0]) - ord('A') + 1\n\n\n# transform gender to numeric [male, female, child]\ndef sex_value(sex, age):\n    if age < 17:\n        return 2\n    elif sex == 'male':\n        return 0\n    else:\n        return 1\n\n\n# Port\ndef embark_value(em):\n    if em == 'C':\n        return 3\n    elif em == 'Q':\n        return 2\n    elif em == 'S':\n        return 1\n    else:\n        return 0\n\n\n# Could of family member siblings + parents\ndef family_size(sib, par):\n    return sib + par + 1\n\n\n# Has any family member on board\ndef is_alone(family_size):\n    if family_size > 1:\n        return 1\n    else:\n        return 0\n\n\n# Reverse p_class\ndef p_class(p_class):\n    return (1 - p_class) + 3\n\n\n# fill nan Age by random and make groups\nage_avg = train['Age'].mean()\nage_std = train['Age'].std()\nage_null_count = train['Age'].isnull().sum()\nage_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n\n\ndef age_groups(age):\n    if(np.isnan(age)):\n        age = np.random.choice(age_random_list, 1)\n        age = age[0]\n    age = int(age)\n    if(age <= 8):\n        return 6\n    if(age <= 18):\n        return 5\n    if(age <= 25):\n        return 4\n    elif(age <= 32):\n        return 3\n    elif(age <= 48):\n        return 2\n    elif(age <= 64):\n        return 1\n    else:\n        return 0\n\n\n# fill nan Fare by random and make groups\ndef fare_groups(fare):\n    if(np.isnan(fare)):\n        fare = 0\n    fare = int(fare)\n    if(fare <= 8):\n        return 0\n    if(fare <= 14):\n        return 1\n    if(fare <= 31):\n        return 2\n    elif(fare <= 51):\n        return 4\n    else:\n        return 5\n\n\n# get title from name and remap to have less dencity\n\ntitle_map = {\n    \"Capt\": \"Officer\",\n    \"Col\": \"Officer\",\n    \"Major\": \"Officer\",\n    \"Dr\": \"Officer\",\n    \"Rev\": \"Officer\",\n    \"Jonkheer\": \"Royalty\",\n    \"Don\": \"Royalty\",\n    \"Sir\": \"Royalty\",\n    \"the Countess\": \"Royalty\",\n    \"Dona\": \"Royalty\",\n    \"Mme\": \"Mrs\",\n    \"Mlle\": \"Miss\",\n    \"Ms\": \"Mrs\",\n    \"Mr\": \"Mr\",\n    \"Mrs\": \"Mrs\",\n    \"Miss\": \"Miss\",\n    \"Master\": \"Master\",\n    \"Lady\": \"Royalty\"\n}\ntitle_string_map = {\n    'Mrs': 4,\n    'Miss': 3,\n    'Master': 2,\n    'Mr': 1\n}\n\n\ndef title_value(df):\n    df['Title'] = df.apply(lambda row: row['Name'].split(',')[1].split('.')[0].strip(), axis=1).map(title_map)\n    df['Title'] = df['Title'].map(title_map)\n    df['Title'] = df['Title'].map(title_string_map)\n    df['Title'] = df[\"Title\"].fillna(0)\n\n    return df\n\n\n# features function\ndef titan_feature(model):\n    df = model.copy()\n\n    df['Embarked'] = df[\"Embarked\"].fillna(\"S\")\n\n    df = title_value(df)\n\n    df['AgeGroup'] = df['Age'].apply(lambda x: age_groups(x))\n    df['FareGroup'] = df['Fare'].apply(lambda x: fare_groups(x))\n    \n    df['Pclass'] = df['Pclass'].apply(lambda x: p_class(x))\n    df['Person'] = df.apply(lambda row: sex_value(row['Sex'], row['Age']), axis=1)\n    df['Pclass-Person'] = df.apply(lambda row: row['Pclass'] * row['Person'], axis=1)\n    \n    \n    df['Cabin'] = df['Cabin'].apply(lambda x: cabin_value(x))\n    df['Embarked'] = df['Embarked'].apply(lambda x: embark_value(x))\n    df['FamilySize'] = df.apply(lambda row: family_size(row['SibSp'], row['Parch']), axis=1)\n    df['IsAlone'] = df.apply(lambda row: is_alone(row['FamilySize']), axis=1)\n    return df\n\n\ntrain_features = titan_feature(train)\ntrain_features = train_features[['Survived', 'Pclass-Person', 'Pclass', 'AgeGroup', 'FareGroup', 'Person', 'IsAlone', 'Embarked', 'Title']]\n\ntest_features = titan_feature(test)\ntest_features = test_features[['Pclass', 'AgeGroup', 'FareGroup', 'Person', 'IsAlone', 'Embarked', 'Title']]", "execution_count": 11}, {"outputs": [], "metadata": {"_execution_state": "idle", "collapsed": false, "_uuid": "da999bd758125093a4b007d98afa110afb351b73", "_cell_guid": "4e515cae-9e04-430d-b374-890e453e1908"}, "cell_type": "markdown", "source": "## Data visualizations ##\nWe can check how our data correlate between each other.", "execution_count": null}, {"outputs": [], "metadata": {"_execution_state": "idle", "collapsed": false, "trusted": false, "_uuid": "d89a1bc8e39942d51050cdc47c32cc17b7b5445d", "_cell_guid": "37a05130-be7a-40f1-ba0f-83623ed35dc6"}, "cell_type": "code", "source": "#correlation matrix\ncorrmat = train_features.corr()\nk = 15 #number of variables for heatmap\ncols = corrmat.nlargest(k, 'Survived')['Survived'].index\ncm = np.corrcoef(train_features[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()", "execution_count": 12}, {"outputs": [], "metadata": {"_execution_state": "idle", "collapsed": false, "_uuid": "da0aa4a8c3915b422b7703b354cc8b80aed46464", "_cell_guid": "e4a29d72-c73b-4d88-8ca1-ab2b8c907f5b"}, "cell_type": "markdown", "source": "See final data before testing", "execution_count": null}, {"outputs": [], "metadata": {"_execution_state": "idle", "collapsed": false, "trusted": false, "_uuid": "e43dcf3acaf6f346bab576edc9e13cb717a9643a", "_cell_guid": "ac465671-4477-4a83-95e2-9775c55c75f9"}, "cell_type": "code", "source": "train_features.head(10)", "execution_count": 7}, {"outputs": [], "metadata": {"_execution_state": "idle", "collapsed": false, "_uuid": "e3fe4910c464932cf3b824fc5f5e67c2387726bf", "_cell_guid": "4c0e63aa-40d9-4573-b53b-579e28ca3e04"}, "cell_type": "markdown", "source": "## Testing ##\nTest by common classifiers and see best restults", "execution_count": null}, {"outputs": [], "metadata": {"_execution_state": "idle", "collapsed": false, "trusted": false, "_uuid": "66eee74abf81b18510453d4ba28f27b56d1f0256", "_cell_guid": "f014aac1-a22b-4af1-9125-7820893c77ce"}, "cell_type": "code", "source": "# TRAINING\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(n_estimators=100),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    GaussianNB(),\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis(),\n    LogisticRegression()\n]\n\nclassifiers_score = {}\nbest_acc = 0\nsss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n\n# define training and testing sets\ntrain_data_all = train_features.drop(\"Survived\", axis=1)\ntrain_result_all = train_features[\"Survived\"]\nfor train_data_index, train_result_index in sss.split(train_data_all, train_result_all):\n    train_data_splitted, test_data_splitted = train_data_all.iloc[train_data_index], train_data_all.iloc[train_result_index]\n    train_results_splitted, test_results_splitted = train_result_all.iloc[train_data_index], train_result_all.iloc[train_result_index]\n\n    for classifier in classifiers:\n            name = classifier.__class__.__name__\n            classifier.fit(train_data_splitted, train_results_splitted)\n            train_predictions = classifier.predict(test_data_splitted)\n            acc = accuracy_score(test_results_splitted.values, train_predictions) * 100\n            if name in classifiers_score:\n                classifiers_score[name]['score'] += acc\n            else:\n                classifiers_score[name] = {}\n                classifiers_score[name]['score'] = acc\n                classifiers_score[name]['classifier'] = classifier\n\n\nmodels_score = pd.DataFrame(columns=('Model', 'Score'))\nbest_acc = 0\n\nfor classifier in classifiers_score:\n    acc = classifiers_score[classifier]['score']/10\n    models_score.loc[classifier] = [classifier, acc]\n    if(best_acc < acc):\n        best_acc = acc\n        best_classifier = classifiers_score[classifier]['classifier']\n\nprint(models_score.sort_values(by='Score', ascending=False))", "execution_count": 8}, {"outputs": [], "metadata": {"_uuid": "95f55e36c3967d1d852491ff6a509b2281935321", "_cell_guid": "438585cf-b7ad-73ba-49aa-87688ff21233"}, "cell_type": "markdown", "source": "# Prediction #\nnow we can use best classifier to predict our result data.", "execution_count": null}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_uuid": "86f377ae2ac528e2a8a6c4f45018baf1a8a5fd54", "_cell_guid": "24967b57-732b-7180-bfd5-005beff75974"}, "cell_type": "code", "source": "X_train = train_features.drop(\"Survived\",axis=1)\nY_train = train_features[\"Survived\"]\nX_test  = test_features.copy()\n\nbest_classifier.fit(X_train, Y_train)\nresults = best_classifier.predict(X_test)\n\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": results\n    })\n\nsubmission.to_csv('results.csv', index=False)\nprint(submission)", "execution_count": 9}], "metadata": {"_change_revision": 0, "_is_fork": false, "language_info": {"pygments_lexer": "ipython3", "nbconvert_exporter": "python", "version": "3.6.1", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python", "mimetype": "text/x-python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}}