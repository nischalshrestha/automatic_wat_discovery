{"nbformat_minor": 0, "cells": [{"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "8471c9e37f26cc475bed2f176e8e087cf96d0f5e", "collapsed": false}, "source": "# Import\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectKBest, chi2", "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "6b311a1992b1929397c32977677331bac4b1857e", "collapsed": false}, "source": "# Import the data and separate the target \n\ntrain_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\ny = train_df['Survived'].values\nidentity = test_df[\"PassengerId\"]\ntrain_df = train_df.drop([\"Survived\"], axis=1)\n\ntrain_df.head()", "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "ed9f3e66cee8fbee64a613c9f1bcd0eb037fbd78", "collapsed": false}, "source": "# Find the missing data\n\ndef findna(df, colname):\n    name = [x for x in globals() if globals()[x] is df][0]\n    fnl = df.loc[df[colname].isnull(), colname]\n    if (fnl.shape[0] != 0):\n        print(name, \"/\", colname, \":  \", fnl.shape)\n\n\nfor df in train_df, test_df:\n    for colname in df.columns.values:\n        findna(df, colname)", "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "24994fa6d688ce5c6756a0717545aea6b86f9db5", "collapsed": false}, "source": "# Use the most commun value for missing embarked\n\nfillembark = train_df[\"Embarked\"].mode()[0]\ntrain_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(fillembark)", "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "1fd2dac58e06d758781ee0ee444e9273ec99c249", "collapsed": false}, "source": "'''\n1. Mark people with missing data for Age or Cabin\n2. Extract regular informations from Name, Ticket and Cabin.\n'N' will mark missing data and 'R' or 'Rare' unusual ones\n'''\n\nfor df in [train_df, test_df]:\n        df[\"WithAge\"] = 1\n        df[\"WithCabin\"] = 1\n        df.loc[df['Age'].isnull(), 'WithAge'] = 0\n        df.loc[df['Cabin'].isnull(), 'WithCabin'] = 0\n        df[\"Title\"] = df.Name.str.extract(' ([A-Za-z]+)\\.',\n                                          expand=False)\n        df[\"Title\"] = df[\"Title\"].replace('Mlle', 'Miss')\n        df[\"Title\"] = df[\"Title\"].replace('Ms', 'Miss')\n        df[\"Title\"] = df[\"Title\"].replace('Mme', 'Mrs')\n        df.loc[~df.Title.isin(['Mr', 'Miss', 'Master',\n                               'Mrs']), 'Title'] = 'Rare'\n        df[\"TyTicket\"] = df.Ticket.str.extract('([A-Za-z])', expand=False)\n        df[\"TyCabin\"] = df.Cabin.str.extract('([A-Za-z])', expand=False)\n        df.loc[df['TyTicket'].isnull(), 'TyTicket'] = 'N'\n        df.loc[~df.TyTicket.isin(['S', 'P', 'C', 'N']), 'TyTicket'] = 'R'\n        df.loc[df['TyCabin'].isnull(), 'TyCabin'] = 'N'\n        df.loc[~df.TyCabin.isin(['C', 'B', 'N']), 'TyCabin'] = 'R'", "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "8d9cb4db060d2b27672967e3bd2477d23fc3d7a3", "collapsed": false}, "source": "'''\nFill missing age and fare values based on Sex and Class\nMedian are obtain with x_all that contains both training and test data\n'''\n\nx_all = pd.concat([train_df, test_df], axis=0)\n\nfor clss in list(x_all[\"Pclass\"].unique()):\n    for gender in list(x_all[\"Sex\"].unique()):\n        stdfare = x_all.loc[(x_all[\"Pclass\"] == clss) &\n                            (x_all[\"Sex\"] == gender),\n                            'Fare'].median()\n        stdage = x_all.loc[(x_all[\"Pclass\"] == clss) &\n                           (x_all[\"Sex\"] == gender),\n                           'Age'].median()\n        \n        for df in [train_df, test_df]:\n            df.loc[(df[\"Pclass\"] == clss) &\n                   (df[\"Sex\"] == gender),\n                   'Age'] = df.loc[(df[\"Pclass\"] == clss) &\n                                   (df[\"Sex\"] == gender),\n                                   'Age'].fillna(stdage)\n            df.loc[(df[\"Pclass\"] == clss) &\n                   (df[\"Sex\"] == gender),\n                   'Fare'] = df.loc[(df[\"Pclass\"] == clss) &\n                                    (df[\"Sex\"] == gender),\n                                    'Fare'].fillna(stdfare)\n            \n        print(\"Class \", clss, \"  &  \", \"Gender \", gender, \"Fare \", stdfare,\n              \"Age\", stdage)", "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "e29dd6a7fc9bd20e59008d31ff002367d41d11cf", "collapsed": false}, "source": "# Drop \"useless\" columns\n\ntrain_df = train_df.drop([\"Cabin\", \"PassengerId\",\n                          \"Ticket\", \"Name\"], axis=1)\ntest_df = test_df.drop([\"Cabin\", \"PassengerId\", \"Ticket\",\n                        \"Name\"], axis=1)\ntrain_df.head()", "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "ba8acadaee70c01b2d005aeb35d3a4307c6bc14b", "collapsed": false}, "source": "# Encode categorical values with LabelEncoder\n\nlbl_enc = preprocessing.LabelEncoder()\nfor col in [\"Title\", \"TyTicket\", \"TyCabin\", \"Sex\", \"Embarked\"]:\n    lbl_enc.fit(train_df[col])\n    train_df[col] = lbl_enc.transform(train_df[col])\n    test_df[col] = lbl_enc.transform(test_df[col])", "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "d4c22121cb503d3e69d4264968f4581375be80a8", "collapsed": false}, "source": "# Use OneHotEncoder on non binary categorical values\n\nhot = preprocessing.OneHotEncoder(categorical_features=[True, False, False,\n                                                        False, False, False,\n                                                        True, False, False,\n                                                        True, True, True],\n                                  sparse=False)\n\nhot.fit(np.concatenate((train_df, test_df)))\ntrain_df = hot.transform(train_df)\ntest_df = hot.transform(test_df)\n\n\n# Prepare for feature selection (22 seemed to work well)\n\nskb = SelectKBest(chi2, k = 22)", "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "be261ad7aca57c0621140a02b4214e039f6045e9", "collapsed": false}, "source": "# Define the number of validation run and the data frame with the results\n\nnbloop = 5\naccuracy_df = pd.DataFrame({'BaseSv': np.zeros(nbloop),\n                            'Param1': np.zeros(nbloop),\n                            'Param2': np.zeros(nbloop)})\n\nnbseed = np.random.randint(1, 100)", "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "f40cbbc43d8614badb262d86530ee42ec628a918", "collapsed": false}, "source": "'''\nFor Each validation run:\n    1. Split data with train_test_split \n    2. Select best features with SelectKBest and chi2\n    3. Perfrom cross validation with GridSearchCV to select best \n       hyperparameters of random forest\n'''\n\nfor k in range(nbloop):\n    \n    x_fit, x_val, y_fit, y_val = train_test_split(train_df, y,\n                                                  test_size=0.3,\n                                                  stratify=y,\n                                                  random_state=k + nbseed)\n    \n    skb.fit(x_fit, y_fit)\n    x_fit = skb.transform(x_fit)\n    x_val = skb.transform(x_val)   \n    \n    param_grid = {'n_estimators': [90, 120],\n                  'max_depth': [11, 15],\n                  'min_samples_split': [10],\n                  'min_samples_leaf': [1],\n                  'max_features': ['log2']}\n    \n    rf = RandomForestClassifier()\n    clf = GridSearchCV(rf, param_grid, cv=5)\n    \n    \n    clf.fit(x_fit, y_fit)\n    y_pred = clf.predict(x_val)\n    acc = accuracy_score(y_pred, y_val)\n    accuracy_df.loc[k, 'BaseSv'] = acc\n    accuracy_df.loc[k, 'Param1'] = clf.best_params_['n_estimators']\n    accuracy_df.loc[k, 'Param2'] = clf.best_params_['max_depth']", "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "7ab32fbe3ee0fc646d2a61ac1f93f32025f1c351", "collapsed": false}, "source": "# Check results\n\nprint(accuracy_df)\nprint(\"\\n\")\nprint(accuracy_df.describe())\nprint(\"\\n END\")", "outputs": [], "cell_type": "code"}], "metadata": {"language_info": {"pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python", "nbconvert_exporter": "python", "mimetype": "text/x-python", "version": "3.6.0", "file_extension": ".py"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat": 4}