{"cells":[{"metadata":{"trusted":true,"_uuid":"54e05f2f7482b7a5da71064dfdca6d8434d4b558"},"cell_type":"code","source":"# imports\nimport pandas as pd\nimport matplotlib.pyplot as mlp\nimport seaborn as sns\nimport numpy as np\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c0ed69e1634a9a6740a3a8e5c073266e556a698"},"cell_type":"code","source":"#get train and test data\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79247f345cf648aa3e3ef471f2d757397b3deac4"},"cell_type":"code","source":"train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"747f0b1d65d936a961c0434ea1ca2e3317e6d460"},"cell_type":"code","source":"train.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cc79a090c1c3d4f6676e64ff9a1395473e2c1f5"},"cell_type":"code","source":"train.info()\nprint('-'*42)\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"365547dcfc83a46d990b9c1603298d1243dcff87"},"cell_type":"markdown","source":"Age has about 200 nulls and cabin has about 700 it is unlikely that cabin can be useable without causing bias those passengers who cabin was recorded, but age can likely be patched up with averges. So cabin will be dropped from the data in both train and test. Additionally there are 2 passengers with nulls for embarked, if they survive the cabin drops I will decide whether to avg the embarked for their class, age, or ticket, or just drop them."},{"metadata":{"trusted":true,"_uuid":"00da5d80950c1693e8b792dfff68e3bb87051fcd"},"cell_type":"code","source":"#drop Cabin from both dfs as well as passenger id bc we do not need a second index\ntrain.drop(['Cabin'], axis = 1, inplace = True)\ntest.drop(['Cabin'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ffaaff9fa31781508619bafb77bd1b3324f4337e"},"cell_type":"code","source":"#graph a hist of age\nsns.set_style('whitegrid')\ntrain['Age'].hist(bins = 50)\nmlp.xlabel('Age')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c42756d5ec26a126807db3e07700571b0a2af038"},"cell_type":"code","source":"# plot a boxplot of the avg ages of the three classes\nmlp.figure(figsize = (12, 7))\nsns.boxplot(x = 'Pclass', y = 'Age', data = train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60977cdae6a6679045579c402c543dbf2e4bf715"},"cell_type":"code","source":"#Create a function that replaces nulls in the age culumn with the average of that passenger's class\n\ndef impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n\n        if Pclass == 1:\n            return 37\n\n        elif Pclass == 2:\n            return 29\n\n        else:\n            return 24\n\n    else:\n        return Age","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0928e855b8813a89433b0225abf988ffde733980"},"cell_type":"code","source":"#replace null ages\ntrain['Age'] = train[['Age','Pclass']].apply(impute_age,axis=1)\ntest['Age'] = test[['Age','Pclass']].apply(impute_age,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d3bfe45f267f41172c926ea170ef59a0f8c9a5f"},"cell_type":"code","source":"train.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f83f9c4bd469556908b7165bf6dd24de4624b410"},"cell_type":"code","source":"# drop the embarked nulls\ntrain.dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0410594c584f26e33eb7464baaefbf7f3a657bbc"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0558ef63cb3e4b02361c3922b9fc2f34fae965d"},"cell_type":"markdown","source":"Remaining issues are the categorical columns that still have text like sex, embarked, ticket, and name. Name might be an issue although the titels of the people ma be useful in some way. Ticket is an issue because there are some repeats but most are unique and they all contain letters and numbers."},{"metadata":{"trusted":true,"_uuid":"cb4b8c87c84f67fd24c4ab15fccc23f1998fdb89"},"cell_type":"code","source":"#replace sex and embarked characters with categorical columns using pd.get_dummies\nSex=pd.get_dummies(train[['Sex']], drop_first = True)\nSex2=pd.get_dummies(test[['Sex']], drop_first = True)\n\ndef embarked_enumerator(cols):\n    embarked = cols[0] \n    \n    if embarked == 'Q':\n        return 0\n    elif embarked == 'S':\n        return 1\n    else:\n        return 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b651b73eb3fe29c1b45dc947ced40adfb18c9a3"},"cell_type":"code","source":"train['Embarked'] = train[['Embarked','Pclass']].apply(embarked_enumerator,axis=1)\ntest['Embarked'] = test[['Embarked','Pclass']].apply(embarked_enumerator,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12b8cb78218e560ad3cf0b838e3dd6f668b03938"},"cell_type":"code","source":"#remove old Sex and Embarked columns\ntrain.drop(['Sex'],axis=1,inplace=True)\ntest.drop(['Sex'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a6cd92d6b8f8b0184627f44bd2a010d0260210a"},"cell_type":"code","source":"#concatonate the new versions of embarked and sex with train and test\ntrain = pd.concat([train, Sex], axis = 1)\ntest = pd.concat([test, Sex2], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c66ec2cf4f1ae30602d346b826f28e64d359484"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88a4609d8bb300b64baf54c722e5289ecd39f774"},"cell_type":"code","source":"#extract the prefix of each passenger from their name\nBoth = [train, test]\n\nfor dataframe in Both:\n    dataframe['Prefix'] = dataframe.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6828e8ff35d9cf3784d96d5105c7e7f172846f26"},"cell_type":"code","source":"train.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba1f81bb43795f7dd65c893614921afdd5313451"},"cell_type":"code","source":"pd.crosstab(train['Prefix'], train['Sex_male'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80c974fbb6365f58eb4e9e3ef7541ad929ad44f0"},"cell_type":"markdown","source":"Many of these preifxed are repeats of the same thing simply abbreviated differently like miss and ms., others are too rare to keep as their own category so it would be best to consolidate names before getting dummies again"},{"metadata":{"trusted":true,"_uuid":"4c45876ae1d0c7cdc8374021ab107fc0fd49ada4"},"cell_type":"code","source":"#replace similar names with a single name, and take uncommon names and replace them with the unusual tag\nfor dataframe in Both:\n    dataframe['Prefix'] = dataframe['Prefix'].replace(['Countess', 'Lady','Capt', 'Don',\\\n \t'Col', 'Dr', 'Rev', 'Major', 'Dona', 'Sir', 'Johnkeer'], 'Unusual')\n    \n    dataframe['Prefix'] = dataframe['Prefix'].replace(['Mlle', 'Ms'], 'Miss')\n    dataframe['Prefix'] = dataframe['Prefix'].replace('Mme', 'Mrs')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7193da76744ec3674da407fe0e374affac8f59a1"},"cell_type":"code","source":"#now that there are fewer categories of names we can get dummies for the prefix column\ndef prefix_enumerator(cols):\n    prefix = cols[0] \n    \n    if prefix == 'Master':\n        return 0\n    elif prefix == 'Miss':\n        return 1\n    elif prefix=='Mr':\n        return 5\n    elif prefix=='Mrs':\n        return 3\n    else:\n        return 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6eec43c07dc3c3f92e5536421eaba144e10fa82"},"cell_type":"code","source":"train['Prefix'] = train[['Prefix','Pclass']].apply(prefix_enumerator,axis=1)\ntest['Prefix'] = test[['Prefix','Pclass']].apply(prefix_enumerator,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"035feb4f75bb57a4971885e82e483c4545a2546c"},"cell_type":"code","source":"#now we can drop name as it is not needed anymore\ntrain.drop('Name', axis = 1, inplace = True)\ntest.drop('Name', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f7dae8751b15e5aebeb814ce51c36a2d103218b"},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a35c708924648cd1b332cace33909e95c4aa36b"},"cell_type":"code","source":"# Parch and SibSp both measure family size, and since equating siblings to\n#spouses and parents to children eliminates a lot of the good the columns could do alone we might as well combine them\n\ntrain['Fammems'] = train['Parch'] + train['SibSp']\ntest['Fammems'] = test['Parch'] + test['SibSp']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2476bf5e7bfbe43a8aad4b35fda06d1937300bfe"},"cell_type":"code","source":"train.drop(['SibSp', 'Parch'], axis=1, inplace=True)\ntest.drop(['SibSp', 'Parch'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e8c6106991463b02ce0686075d3a09455bb583b"},"cell_type":"markdown","source":"Age is a continuous feature that might cause correlations to bne found between random age numbers that dont exist, dumbing down the ages to various age groupings would make it much easier"},{"metadata":{"trusted":true,"_uuid":"d78b88c2f8d627b1d7a47db4fb748fd0be2f7fd0"},"cell_type":"code","source":"#Create a function that replaces age numbers with more categorical age bands\n\ndef age_bander(cols):\n    Age = cols[0]\n    \n    if Age < 16:\n        return 0\n    elif Age >= 16 and Age < 32:\n        return 1\n    elif Age >= 32 and Age < 48:\n        return 2\n    elif Age >= 48 and Age < 64:\n        return 3\n    else:\n        return Age","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6d89d3ba707e21068db95e4eabda4ce81515ca5"},"cell_type":"code","source":"train['Age'] = train[['Age','Pclass']].apply(age_bander,axis=1)\ntest['Age'] = test[['Age','Pclass']].apply(age_bander,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7147c4a28785f616d0f45cdfbc27db1d156e748f"},"cell_type":"code","source":"train.drop(['Ticket'], axis = 1, inplace = True)\ntest.drop(['Ticket'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa4c1cd8b7170f0c71e1b5acc77cc1808f3bbf8c"},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c319b6069dc1aefb9693b2a41590775bf79725a"},"cell_type":"code","source":"train['Fare'].describe(percentiles = [.15, .30, .45, .60, .75, .90])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63729282df5fb90966eedb431114b4282e5c51f2"},"cell_type":"code","source":"#Create a function that replaces fare numbers with more categorical fare bands\n\ndef fare_bander(cols):\n    Fare = cols[0]\n    \n    if Fare < 7.76:\n        return 0\n    elif Fare >= 7.76 and Fare < 8.06:\n        return 1\n    elif Fare >= 8.06 and Fare < 13:\n        return 2\n    elif Fare >= 13 and Fare < 14.4543:\n        return 3\n    elif Fare >= 14.4543 and Fare < 21.076:\n        return 4\n    elif Fare >= 21.076 and Fare < 31:\n        return 5\n    else:\n        return Fare","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c8bf87e4f59711afc5a4daab72b28c12fe831dd"},"cell_type":"code","source":"train['FareBand'] = train[['Fare','Pclass']].apply(fare_bander,axis=1)\ntest['FareBand'] = test[['Fare','Pclass']].apply(fare_bander,axis=1)\ntrain.drop('Fare', axis = 1, inplace = True)\ntest.drop('Fare', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6f71a1cca334b1ba42460dc68c9c753f5e7f894"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31296001192a6ed8ee163cde4b98373e7266552f"},"cell_type":"markdown","source":"Now we can do some actual learning with our fixed up data."},{"metadata":{"trusted":true,"_uuid":"c419ef06578261039a56a79f5c2e6b3575a1979c"},"cell_type":"code","source":"X = train.drop('Survived', axis = 1) \ny = train['Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37c5f68a604674e96c7d87bbc73092257d46fc21"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3dbdaf87ff6896a99bd49b1184f45e1711c8e32e"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train.drop(['Survived', 'PassengerId'], axis = 1, inplace = False), train['Survived'],\n                                                    test_size=0.33, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d595c8f0eb85f50103e55fe11640138ab5e86377"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29693dbc25b7b51649a378d73baf25579e885a7b"},"cell_type":"code","source":"# Logistic Regression\n\nlregr = LogisticRegression()\nlregr.fit(X_train, y_train)\nY_pred = lregr.predict(X_test)\nacc_lregr = round(lregr.score(X_test, y_test) * 100, 2)\nacc_lregr\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3df34d63cc74caab2b92a0c2b20ac712033e9013"},"cell_type":"code","source":"#get the correlation of each feature using the logistic regression just done, thanks to Manav Seghal, \n# https://www.kaggle.com/startupsci/titanic-data-science-solutions\n\n#create a dataframe of all of the column titles from train\ncoeff=pd.DataFrame(train.columns.delete(0))\n#rename the column to Feature\ncoeff.columns=['Feature']\n#create a correlation column in coeff which contains the coefficient from the above linear regression for each feature\ncoeff['Correlation']=pd.Series(lregr.coef_[0])\n#sort the coefficients in descending order\ncoeff.sort_values(by='Correlation', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c2c039ded0046e11ead60596c3fef81e29ec9e2"},"cell_type":"markdown","source":"Now we can try a whole bunch of methods to see which seem to work best before we try ensembling or boosting"},{"metadata":{"trusted":true,"_uuid":"60843a540a577f8e4c1ce5937facba8b8aef2fd8"},"cell_type":"code","source":"from sklearn import svm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e784533f763f82ddddee08afba8904e9657f85ba"},"cell_type":"code","source":"# Support Vector Classifier\nsvc = svm.SVC()\n\nsvc.fit(X_train, y_train)\nY_pred = svc.predict(X_test)\nSVC_acc = round(svc.score(X_test, y_test) * 100, 2)\nSVC_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad3a030c3b1da1ef3aab46ee4158332d6206dcef"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a62f6771a708f34670355df9642e7f8e245fb3a"},"cell_type":"code","source":"# KNN classifier\n\nKNNc = KNeighborsClassifier(n_neighbors=5)\nKNNc.fit(X_train, y_train)\ny_pred=KNNc.predict(X_test)\nKNNc_acc = round(KNNc.score(X_test, y_test)*100, 2)\nKNNc_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df2fb82957468de89309c6db01ebbe323ee898de"},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"441a1f82ab5fc3d53d655bb1e5bc4d1b63e0366a"},"cell_type":"code","source":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, y_train)\ny_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_test, y_test) * 100, 2)\nacc_gaussian\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a58516f747ac4ea0328ba025b1767abd9e3e201"},"cell_type":"code","source":"from sklearn.linear_model import Perceptron","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"394aa6af5cd1010e8fca498ec4a70d499663f3b6"},"cell_type":"code","source":"# Perceptron\n\nptron = Perceptron()\nptron.fit(X_train, y_train)\ny_pred = ptron.predict(X_test)\nacc_perceptron = round(ptron.score(X_test, y_test) * 100, 2)\nacc_perceptron","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e919a94b42efe628b7bb5caee577f26a385905d9"},"cell_type":"code","source":"# Linear SVC\n\nlinear_svc = svm.LinearSVC()\nlinear_svc.fit(X_train, y_train)\ny_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_test, y_test) * 100, 2)\nacc_linear_svc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16d7594a9321ad6e4553964dd7d2bb9e5af0bbaa"},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0302a77fb5c02e933031f7466bf09e143e949706"},"cell_type":"code","source":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_test, y_test) * 100, 2)\nacc_sgd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bf97aa2b3f2adf16ec21ace194f8b7aaebf381b"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7bf3156433c432b213a6602b1bd375e6ba11902"},"cell_type":"code","source":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, y_train)\ny_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_test, y_test) * 100, 2)\nacc_decision_tree\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07cf9ce8fd15d89e81cb8ff601633a848baba170"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30a51e9a6de856a11c0ee6ead8b75a91ac85728c"},"cell_type":"code","source":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=131)\nrandom_forest.fit(X_train, y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, y_train)\nacc_random_forest = round(random_forest.score(X_test, y_test) * 100, 2)\nacc_random_forest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"441d988427fcc52c118ad5da17a349f5cf23de11"},"cell_type":"code","source":"# now to compare all the models\n\nmodels = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [SVC_acc, KNNc_acc, acc_lregr, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8f7e706ad960b133c3bec3e8f5c786b4726173f"},"cell_type":"code","source":"import xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2143bcb2f05c841a4645ee015cc30caec30ad29"},"cell_type":"code","source":"booster = xgb.XGBClassifier(max_depth = 3, n_estimators= 100, learning_rate= 0.1)\nbooster.fit(X_train, y_train)\nbooster.predict(X_test)\nbooster_acc=round(booster.score(X_test, y_test) * 100, 2)\nbooster_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb20ca51c1723a3775cc0c6081526f8ca8230337"},"cell_type":"code","source":"# try different learning rates, estimator amounts, and max depths to see how good our booster can get\na = [3,5,10,15,20]\nb = [50,100,150,200,250,300]\nc = [0.1, 0.33, 0.5,0.75, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8696632821f980dca1450e1e4d2830a3a754fb7f"},"cell_type":"code","source":"for num in range(0, len(b)):\n    for dig in range(0,len(a)):\n        for elem in range(0, len(c)):\n            booster = xgb.XGBClassifier(max_depth = a[dig], n_estimators= b[num], learning_rate= c[elem])\n            booster.fit(X_train, y_train)\n            booster.predict(X_test)\n            booster_acc=round(booster.score(X_test, y_test) * 100, 2)\n            print(booster_acc, 'depth = {}, estimators = {}, rate = {}'.format(a[dig], b[num], c[elem]))\n            print('-'*40)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"401eecfb81acc32b93e555d279c68c31fbde6b09"},"cell_type":"code","source":"submission_ex = pd.read_csv('../input/gender_submission.csv')\nsubmission_ex.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ceea08049207949177517486b3b9785d565e49cd"},"cell_type":"markdown","source":"Now all we have to do is choose the best couple models and submit with them."},{"metadata":{"trusted":true,"_uuid":"81d20223bd35d8ae75e0ab6305f83191e2e4fa4b"},"cell_type":"code","source":"booster = xgb.XGBClassifier(max_depth = 5, n_estimators= 50, learning_rate=0.5)\nbooster.fit(X.drop('PassengerId', axis = 1), y)\nboost_preds = booster.predict(test.drop(['PassengerId'], axis = 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0332c5dcc4573081b0df15f0e651ee0d7e4de025"},"cell_type":"code","source":"booster_submission = pd.DataFrame(data = test['PassengerId'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5893f614f775508e77e7402edc464c45744b2f08"},"cell_type":"code","source":"booster_submission['Survived'] = boost_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1b4d1decf691b49b75c398202933acde02f3260"},"cell_type":"code","source":"booster_submission.to_csv(path_or_buf='booster_submission', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a517e5f70febf67ab294706251f6df94b339a42b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea6d7143656ccaac0e9c567434c8f0750750e7bf"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb2619977c919799fe3f51dd7dcc29289f90a322"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf9e66c7f4a3c5d5fb39f033ff956fdc58ca0062"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7ad20a32be0cfbeddc818f9b3974f21aecad30c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"207cc5467ad314d01bd105e7ff9ae78faae8df2e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aaad1e97ed6a26028f7da6d83d14ad47d5cd73a8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfc155f227b6e38306fc213b494121e0dae0883b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1bfc6d7d39ef617c3f79d34cd6679f86e521c54"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c86c79650bbd7a42973f0f7349aa7734058d538"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}