{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0f638d0cc8ea7864dc4395f4dc7e5a938b6d9de"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc4c7a900f2ccdadfe1a3108cefa50db9f5cf30a"},"cell_type":"code","source":"#Show where nulls are in columns for train set\nprint(\"-- Train Nulls --\")\nprint(\"Survived Null Count: \" + str(sum(train['Survived'].isna())))\nprint(\"PClass Null Count: \" + str(sum(train['Pclass'].isna())))\nprint(\"Sex Null Count: \" + str(sum(train['Sex'].isna())))\nprint(\"Age Null Count: \" + str(sum(train['Age'].isna())))\nprint(\"SibSp Null Count: \" + str(sum(train['SibSp'].isna())))\nprint(\"Parch Null Count: \" + str(sum(train['Parch'].isna())))\nprint(\"Ticket Null Count: \" + str(sum(train['Ticket'].isna())))\nprint(\"Fare Null Count: \" + str(sum(train['Fare'].isna())))\nprint(\"Cabin Null Count: \" + str(sum(train['Cabin'].isna())))\nprint(\"Embarked Null Count: \" + str(sum(train['Embarked'].isna())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25b4287bb2a1a0be2550528d67d5bb99796950b4"},"cell_type":"code","source":"males = train[train['Sex']=='male']\nprint(\"Males who don't show an Age: \" + str(sum(males['Age'].isna())))\nfemalecount = 177-sum(males['Age'].isna())\nprint(\"Females who don't show an Age: \" + str(femalecount))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"182559fe8ec2c314e89f8aacc29585468859e1cb"},"cell_type":"code","source":"#Show Number representation for Age split by Gender to replace Nans\nprint(\"Median Male Age: \" + str(males[['Age']].median(axis=0)))\nfemales = train[train['Sex']=='female']\nprint(\"Median Female Age: \" + str(females[['Age']].median(axis=0)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f020721e4c0c2caea9143cdea77a32be41db161a","scrolled":true},"cell_type":"code","source":"#Fill nulls with medians by sex\nmalenoage = train.loc[(train['Age'].isna()) & (train['Sex']=='male')]\nrows = malenoage.index\ntrain.loc[rows,'Age'] = 29\nfemalenoage= train.loc[(train['Age'].isna()) & (train['Sex']=='female')]\nrows2=femalenoage.index\ntrain.loc[rows2,'Age'] = 27\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d71efe03025d651bf072ea410eca6fbc8dce920"},"cell_type":"code","source":"#Check nulls for Embarked\ntrain[train['Embarked'].isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb62b547bc99ec2ec4921825b85158a715b983d9"},"cell_type":"code","source":"#View if order of tickets relates to Embarked location\ntrain[(train['Ticket']>'113500') & (train['Ticket']<'113600')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34a5a2558581a41625f92d527f333354245ba46c"},"cell_type":"code","source":"#See how common the values are, as S is very present above, C is rare, and Q is non-existent\nfor x in train.Embarked.unique():\n    train.loc[train['Embarked']==x].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b3e980333bfb14c0169255877f4aa5f829349c5"},"cell_type":"code","source":"#plot numerical correlations\ntrain.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"474a53801280bcf9a0e93b0b979666bf56b1b462","scrolled":true},"cell_type":"code","source":"#Extract title from name using regex\ntrain['Title'] = train.Name.str.extract(', (\\w{1,})\\.')\ntrain.Title","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2bc8d6565c4f153467afbe43ddde7f242f903ae9"},"cell_type":"code","source":"#The regex didn't catch one row, so I replaced it manually\ntrain[train.Title.isna()]\ntrain.loc[759,'Title'] = 'Countess'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1346612f0e983b8a2b2098d2d01da6ffcad36f4"},"cell_type":"code","source":"#Examine Family Features Parch and SibSp\ntrain[['Parch','SibSp']].describe()\n\nimport seaborn as sns\n\nsns.distplot(train[['SibSp']])\n\n#Chart shows that both SibSp and Parch have tons of 0, and many smaller families with a some rare large families","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f26438229bb6145c431eab1fffadba81205150ae"},"cell_type":"code","source":"train[['Parch','Survived']].groupby(['Parch']).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d26b49795327e68c41df6a200ec0ef70d62cfc33"},"cell_type":"code","source":"train[['SibSp','Survived']].groupby(['SibSp']).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c328404e8e905eab73fc8392a600a5fe303a33c5"},"cell_type":"code","source":"#Calculate total party size including self\ntrain['FamilySize']=1+train['SibSp']+train['Parch']\ntrain[['FamilySize','Survived']].groupby(['FamilySize']).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96147e67733fd5a684c58d22e6019304ec0e6de7"},"cell_type":"code","source":"train.Pclass.hist(train.FamilySize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da44628f637dc2ddbbd27efaf2a1dcbdcfd48df1"},"cell_type":"code","source":"train.FamilySize.hist(train.Pclass)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad7c8fa506fb8398b076f70c5c686491cc476b46"},"cell_type":"code","source":"train[['FamilySize','Pclass','Survived']].groupby(['FamilySize','Pclass']).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66e38df6d5f6ee7cef88b7d3436e1fce96ecef7a"},"cell_type":"code","source":"train[(train['FamilySize']==3) | (train['FamilySize']==4)].Age.hist(figsize=(70,30), bins=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bf6d5392253670516f2e1068298101e1da09cc5"},"cell_type":"code","source":"Survivors = train[train['Survived']==1]\nFamilySurvivors = Survivors[(Survivors['FamilySize']==3) | (Survivors['FamilySize']==4)]\nFamilySurvivors.Age.hist(figsize=(70,30), bins=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6c8ab60a8a9b2f57cab1b45a01b455dacd90569"},"cell_type":"code","source":"#According to the above table, Larger families may be drastically separated by also comparing the class they rode in.\n#IE. First class large families survive, but poorer third class families do poorly. \n#It also appears that 3-4 size families survived at higher rates. But from the above charts, only the youngest and \n#oldest members benefited from the higher rate of survival\n#Kids below 10 were likely the most protected group - and likely went with their mothers in most cases\nAverageFamilies = train.loc[(train['FamilySize']>2) & (train['FamilySize']<5)]\nAverageFamilies.Survived.mean() # 61% Survival vs. Population 38% Survival\nAverageFamiliesWithoutDad = AverageFamilies.loc[((train['Age']>20) & (train['Sex']=='female') | (train['Age']<19))]\nAverageFamiliesWithoutDad.Survived.mean() #77.4% Survival rate vs. 61% Survival with older males\nAverageFamiliesWithoutDad.groupby('Pclass').Survived.mean() #1st and 2nd Class sported >90% Survival Rates\nAverageFamilies.loc[(AverageFamilies['Sex']=='male') & (AverageFamilies['Age']>18)].Survived.mean() #20% Survival Rate for these men\ntrain.loc[(train['Age']<1)].Survived.mean() #Babies survived at higher rates - 100%\ntrain.loc[(train['Age']>1) & (train['Age']<16)].Survived.mean() #Kids between 1-16 survived at ~54% rates\ntrain.loc[(train['Age']>40)].Survived.mean() #Older parties don't show any specifically higher levels of survival rate\n\n#Create new columns for findings - Save the women and children!\ntrain['NonPoorMothersAndChildren']= 0\ntrain.loc[((train['Pclass']<3) & (train['FamilySize']>2) & (train['FamilySize']<5) & ((train['Age']>20) & (train['Sex']=='female') | (train['Age']<19))),'NonPoorMothersAndChildren']=1\ntrain['IsBaby'] = 0\ntrain.loc[train['Age']<1,'IsBaby']=1\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ab3ec11b4d6612ca4e0b401460b2f109d548ce8"},"cell_type":"code","source":"#Let's explore the Titles feature\ntrain.groupby('Title').Survived.mean() #The captain goes down with the ship!\ntrain[['Title','Pclass','Survived']].groupby(['Title','Pclass']).Survived.mean()\n# I didn't discover anything too useful here that would be a feature to add in and not cause overfitting","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ebe493614efd222f431d460e4e1bdb00adc4374"},"cell_type":"code","source":"#Let's explore Fare costs\ntrain['Fare'].hist() #This was the original graph that helped me understand why a fare of 50 and above would be a good starting place\ntrain.loc[train['Fare']>50].Survived.mean() #68% survival rate Expensive Tickets\ntrain.loc[train['Fare']<10].Survived.mean() #19% survival rate Cheap Tickets\ntrain.loc[train['Fare']<50,'Fare'].hist()\n\n#Let's make some categories!\ntrain['CheapTickets'] = 0\ntrain.loc[train['Fare']<10,'CheapTickets'] = 1\ntrain['ExpensiveTickets'] = 0\ntrain.loc[train['Fare']>50,'ExpensiveTickets'] = 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41e69ed2e89265cb9f0f5abf21d49e75b5275c90","scrolled":true},"cell_type":"code","source":"#Let's explore Embarked location\ntrain.groupby('Embarked').Survived.mean()\n#Very interesting... People who embarked at C have significantly higher survival rates at 58%\n\ntrain.groupby(['Embarked','Pclass']).Name.count()\n#It appears that this is because most passengers who embarked at C were 1st class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bae108abbf3071c9b6fce875df3cb5263c59056"},"cell_type":"code","source":"#Let's explore the cabin column\ntrain.loc[train['Cabin'].isna()].Survived.mean() #Those with no cabin have a 30% Survival Rate\ntrain.loc[train['Cabin'].notnull()].Survived.mean() #People with a cabin show a 67% Survival Rate\ntrain['HasCabin'] = 0\ntrain.loc[train['Cabin'].notnull(),'HasCabin'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c292db08aa048b56565f2c75ce88d4fb3e23d326"},"cell_type":"code","source":"#Let's turn our categorical features into numerical features with dummies\ntrain[['C','Q','S']] = pd.get_dummies(train['Embarked'])\ntrain[['1Class','2Class','3Class']] = pd.get_dummies(train['Pclass'])\ntrain[['Male','Female']] = pd.get_dummies(train['Sex'])\ntrain[['Captain','Colonel','Countess','Don','Dr','Jonkheer','Lady','Major','Master','Miss','Mlle','Mme','Mr','Mrs','Ms','Rev','Sir']] = pd.get_dummies(train['Title'])\n#['Mr', 'Mrs', 'Miss', 'Master', 'Ms', 'Col', 'Rev', 'Dr', 'Dona'] are the titles in Test set\n# So -'Captain', -'Countess', 'Don', 'Jonkheer', -'Lady', -'Major', -'Mme', -'Mlle', -'Sir' are not in the Test set\n# We will have to group values accordingly\ntrain['MilitaryTitle'] = 0\ntrain.loc[((train['Colonel']==1) | (train['Captain']==1) | (train['Major']==1)),'MilitaryTitle'] = 1\ntrain['FemaleTitle'] = 0\ntrain.loc[((train['Mrs']==1) | (train['Ms']==1) | (train['Miss']==1) | (train['Lady']==1) | (train['Countess']==1)),'FemaleTitle'] = 1\ntrain['RareTitle'] = 0\ntrain.loc[(train['Jonkheer']==1) | (train['Don']==1),'RareTitle'] = 1\n#Drop columns that are no longer useful\ntrain = train.drop(['PassengerId','Embarked','Pclass','Sex','Cabin','Ticket','SibSp','Parch','Name','Title', 'Captain', 'Countess', 'Don', 'Jonkheer', 'Lady', 'Major', 'Mme', 'Mlle', 'Sir', 'Dr','Miss', 'Mr', 'Mrs', 'Ms', 'Colonel'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d67125df5625dea4856ecb5ed928df49f55b2813"},"cell_type":"code","source":"#Look at this beauty!\ntrain.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6dc819b1cbdc124cf4e760a2e10b7f2f4662fdb4"},"cell_type":"code","source":"#Now let's try some ML - For first round we will be using \n#RandomForestClassifier - It will be very useful considering that this data is very colinear\n\n#First, we need to split the data into train/test\nfrom sklearn.model_selection import train_test_split\ny=train['Survived']\nX = train.drop('Survived',axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrfclf = RandomForestClassifier(n_estimators=500)\n\nrfclf.fit(X_train, y_train)\nrfclf.score(X_test, y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"198e03f5610426d8525397fbad67c871c7087c89"},"cell_type":"code","source":"#Generally, after Random Forest do Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n\nlogclf = LogisticRegression(solver='lbfgs', max_iter=1000)\n\nlogclf.fit(X_train, y_train)\nlogclf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f42db10ab2178e02cfb2216a6ec86015ae9521db"},"cell_type":"code","source":"#Try Gradient Boosting\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ngbclf = GradientBoostingClassifier(n_estimators=500)\n\ngbclf.fit(X_train, y_train)\ngbclf.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66d47ac2bfdc61d9dd98de354c06699c99ac9e9e"},"cell_type":"code","source":"#Try AdaBoost\nfrom sklearn.ensemble import AdaBoostClassifier\n\nabclf = AdaBoostClassifier(n_estimators=500)\n\nabclf.fit(X_train, y_train)\nabclf.score(X_test,y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4aee73bac0a44a62f6316a9e1d9d0bac69eb6c47"},"cell_type":"code","source":"#Try Support Vector Classifier\nfrom sklearn.svm import SVC\n\nsvc = SVC(gamma='auto')\n\nsvc.fit(X_train, y_train)\nsvc.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e3b5e8f6698e7f2954a38e89c04e26e7389f06f"},"cell_type":"code","source":"rfclf_features = rfclf.fit(X_train,y_train).feature_importances_\nlogclf_features = logclf.fit(X_train,y_train).coef_\nabclf_features = abclf.fit(X_train,y_train).feature_importances_\ngbclf_features = gbclf.fit(X_train,y_train).feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b42b928bb813f2adadae592941c8c0148ca99d36"},"cell_type":"code","source":"# Plot feature importance from Random Forest\ncols = X_test.columns.values\nplt.scatter(cols,rfclf_features)\nplt.plot()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ee32c0b8e6208692688a0399bd8429d75943fe9"},"cell_type":"code","source":"# Plot feature importance from Logistic Regression\nplt.scatter(cols,logclf_features)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e8efc46eb29f2fe19e7ed3aadc9232676e0b92d"},"cell_type":"code","source":"# Plot feature importance from AdaBoost\nplt.scatter(cols,abclf_features)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e661252bd3fba983cc1f22c6819cc00fa0887bee"},"cell_type":"code","source":"# Plot feature importance from Gradient Boosting\nplt.scatter(cols,gbclf_features)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53c7f86fe4021db4b44283c3d22719f989214592"},"cell_type":"code","source":"print(\"-- Test Nulls --\")\nprint(\"PClass Null Count: \" + str(sum(test['Pclass'].isna())))\nprint(\"Sex Null Count: \" + str(sum(test['Sex'].isna())))\nprint(\"Age Null Count: \" + str(sum(test['Age'].isna())))\nprint(\"SibSp Null Count: \" + str(sum(test['SibSp'].isna())))\nprint(\"Parch Null Count: \" + str(sum(test['Parch'].isna())))\nprint(\"Ticket Null Count: \" + str(sum(test['Ticket'].isna())))\nprint(\"Fare Null Count: \" + str(sum(test['Fare'].isna())))\nprint(\"Cabin Null Count: \" + str(sum(test['Cabin'].isna())))\nprint(\"Embarked Null Count: \" + str(sum(test['Embarked'].isna())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"707c1e40bd55d8d0fe01c4391ac8f72b20a9ace4"},"cell_type":"code","source":"males = test[test['Sex']=='male']\nprint(\"Males who don't show an Age: \" + str(sum(males['Age'].isna())))\nprint(\"Median of Men's Age: \" + str(males.Age.median()))\nfemales = test[test['Sex']=='female']\nprint(\"Females who don't show an Age: \" + str(sum(females['Age'].isna())))\nprint(\"Median of Women's Age: \" + str(females.Age.median()))\n#Since both are 27, replace both regardless of gender\ntest.loc[test['Age'].isna(),'Age'] = 27\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73383dfd6a04e3e93e0c43ff0228031a823a6064"},"cell_type":"code","source":"#Check nulls for Embarked\ntest[test['Fare'].isna()]\n\n#This is for a person from 3rd class who embarked at Southampton\n#test.loc[(test['Pclass']==3)&(test['Embarked']=='S')].Fare.mean() # mean fare was 13.91\n\ntest.loc[test['Fare'].isna(),'Fare'] = 13.91","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a9f43c59eee92127c29d0a24fbca2dd3c866cba"},"cell_type":"code","source":"#Create dummies for HasCabin \ntest['HasCabin'] = 0\ntest.loc[test['Cabin'].notnull(),'HasCabin'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"caf97f0aa12dc4e509d28f54760253fd65b2ce77"},"cell_type":"code","source":"#Extract title from name using regex\ntest['Title'] = test.Name.str.extract(', (\\w{1,})\\.')\ntest.loc[test['Title'].isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec2b8b27bff735394dec48733c3a33659529950b"},"cell_type":"code","source":"#Calculate total party size including self\ntest['FamilySize']=1+test['SibSp']+test['Parch']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94d722462d876309e3962f32353f012acdde5329"},"cell_type":"code","source":"# Save the women and children!\ntest['NonPoorMothersAndChildren']= 0\ntest.loc[((test['Pclass']<3) & (test['FamilySize']>2) & (test['FamilySize']<5) & ((test['Age']>20) & (test['Sex']=='female') | (test['Age']<19))),'NonPoorMothersAndChildren']=1\ntest['IsBaby'] = 0\ntest.loc[test['Age']<1,'IsBaby']=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4715c6356648babe1cbf6215f3b7d6a775d50f01"},"cell_type":"code","source":"#Let's make some more categories!\ntest['CheapTickets'] = 0\ntest.loc[test['Fare']<10,'CheapTickets'] = 1\ntest['ExpensiveTickets'] = 0\ntest.loc[test['Fare']>50,'ExpensiveTickets'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe29f70fb49eb7af06b83cc5c9fdaa394aa22463"},"cell_type":"code","source":"# Adjust for cabins\ntest['HasCabin'] = 0\ntest.loc[test['Cabin'].notnull(),'HasCabin'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"098709b999e1a1368263e53f68987a0df64c200f"},"cell_type":"code","source":"#Let's turn our last categorical features into numerical features with dummies\ntest[['C','Q','S']] = pd.get_dummies(test['Embarked'])\ntest[['1Class','2Class','3Class']] = pd.get_dummies(test['Pclass'])\ntest[['Male','Female']] = pd.get_dummies(test['Sex'])\ntest[['Mr', 'Mrs', 'Miss', 'Master', 'Ms', 'Colonel', 'Rev', 'Dr', 'Dona']] = pd.get_dummies(test['Title'])\n\n#['Mr', 'Mrs', 'Miss', 'Master', 'Ms', 'Col', 'Rev', 'Dr', 'Dona'] are the titles in Test set\n# So -'Captain', -'Countess', 'Don', 'Jonkheer', -'Lady', -'Major', -'Mme', -'Mlle', -'Sir' are not in the Test set\n# We will have to group values accordingly\ntest['MilitaryTitle'] = 0\ntest.loc[((test['Colonel']==1)),'MilitaryTitle'] = 1\ntest['FemaleTitle'] = 0\ntest.loc[((test['Mrs']==1) | (test['Ms']==1) | (test['Miss']==1) | (test['Dona']==1)),'FemaleTitle'] = 1\ntest['RareTitle'] = 0\n          \n#Drop columns that are no longer useful\ntest = test.drop(['PassengerId','Embarked','Pclass','Sex','Cabin','Ticket','SibSp','Parch','Name','Title','Miss', 'Mr', 'Mrs', 'Ms', 'Colonel', 'Dona', 'Dr'], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa7804e148024e34837e9a6a2d3486a9ff4cb6d4"},"cell_type":"code","source":"test = test.sort_index(axis=1)\ntrain = train.sort_index(axis=1)\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"555f110ebe12a12105d5e8546b14ad373cd9fbb4"},"cell_type":"code","source":"'''#Produce Logistic Regression Results for the Test Data\nlogclf = LogisticRegression(solver='lbfgs', max_iter=1000)\ny_train = train[['Survived']]\nX_train = train.drop('Survived', axis=1)\nlogclf.fit(X_train, y_train)\n\ntest_results = logclf.predict(test)\ntest_results.mean()'''\n\n#Produce Random Forest Results for the Test Data\nrfclf = RandomForestClassifier(n_estimators=500)\ny_train = train[['Survived']]\nX_train = train.drop('Survived', axis=1)\nrfclf.fit(X_train, y_train)\n\ntest_results = rfclf.predict(test)\ntest_results.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7b7cf857720837b283268c00bf5a91f9b051691","_kg_hide-output":true},"cell_type":"code","source":"submission = pd.DataFrame(test_results)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"trusted":true,"_uuid":"39ca89825fb8ff5f975a50e538d4ffeb11fbdbe9"},"cell_type":"code","source":"submission.to_csv('titanicsubmission1.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98405ad844015b7e29bdaa2b3ae1fea08fedd72b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4aa8ea0cb7ce6dcc2e1fde598141865618aff712"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c01573064c60567a38668c86aef4597ea5fcb2fc"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}