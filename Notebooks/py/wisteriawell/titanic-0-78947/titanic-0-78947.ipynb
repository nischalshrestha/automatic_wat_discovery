{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"print('Reading Data...\\n')\ntrain_raw  = pd.read_csv('../input/train.csv')\ntest_raw   = pd.read_csv('../input/test.csv')\ntrain  = train_raw.copy(deep = True)\ntest = test_raw.copy(deep = True)\ndata = pd.concat([train, test], ignore_index=True)\ntrain_len = len(train)\ntest_len = len(test)\n\nprint('Shape of train : {}'.format(train.shape))\nprint('Shape of test  : {}'.format(test.shape))\nprint('Shape of data  : {}'.format(data.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"cdcce0cc986d229151ba6382fd420aebba03b195"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0d67b580b75a0a6557142f453b7e1398c9c2231"},"cell_type":"code","source":"print('data with null values:\\n', data.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8c4e5aad3e50f257cbd6bb1c406e6fa965a2f34"},"cell_type":"markdown","source":"\n## データ分析\n\n史実によれば、\n\n1.  **ウィメン・アンド・チルドレン・ファースト**。女性と子供が優先的に救助された。*(Sex, Age)*\n2.  **優先的に救助されたのは一等、二等船室客**。三等船室客はアメリカ合衆国移民法の理由により物理的にも隔離された状態になっていた。*(Pclass)*\n\nとのこと。ちなみに、三等船室には英語が話せる人がそもそも少なかったため、助かった人は英語が話せる人が多かったとも。\n念のためデータで確認してみる。"},{"metadata":{"trusted":true,"_uuid":"6782bfb256429b28a05637f5ad7c8a24a61954e8"},"cell_type":"code","source":"plt.figure(figsize=[10, 10])\nplt.subplot(221)\nsns.barplot('Sex','Survived',data=data)\nplt.subplot(222)\nsns.barplot('Pclass','Survived',data=data, hue='Sex')\n\nsns.FacetGrid(data=data, hue='Survived', aspect=3).map(sns.kdeplot, 'Age', shade=True)\nplt.ylabel('Passenger Density')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ec3c632c9ff062b85069def9fe60555505bf4cf"},"cell_type":"markdown","source":"## データ分析(Cabin, Fare, Embarked)\n\n### Cabin :\n\n　全データ1,309件のうち、欠落データが1,014件(77.46%)もある。\n\n　有効な分析ができないと思われるため、**除外することにする**。\n\n### Fare :\n\n　船賃は船室のクラスと同一乗船人数で決まる（同じチケット番号の人は同じ船賃になっている）。\n\n　結果的にPclass次第となるため、**除外することにする**。\n\n\n### Embarked :\n\n　常識的に考えると、乗船地自体が生死に直接関係したとは考え難い。\n\n　なお、タイタニックの航路は以下の通り（Wikipediaより）。\n\n　![Wikipediaより](https://upload.wikimedia.org/wikipedia/commons/5/51/Titanic_voyage_map.png)\n\n　一方で、乗船地毎の生存率を取るとC(herbourg)が最も高く見えるが、\n \n　これはCherbougから乗船した客に一等、二等船室客の割合が多かったことが原因と思われる。\n \n　また、S(outhampton)が最も低いのは、Southamptonから乗船した客に男性の割合が多かったことが原因と思われる。\n  \n　そのため、乗船地（Embarked）も**除外することにする**。\n "},{"metadata":{"trusted":true,"_uuid":"02aa868616f6f88aebbe6b7038cbe8e311e881bd"},"cell_type":"code","source":"plt.figure(figsize=[15,10])\nplt.subplot(331)\nsns.barplot('Embarked','Survived',data=data)\nplt.subplot(332)\nsns.countplot('Embarked',data=data, hue='Pclass')\nplt.subplot(333)\nsns.countplot('Embarked',data=data, hue='Sex')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d254a9bbea71af88a80e950f8c937c5b144e752"},"cell_type":"code","source":"data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\ndata['FamilySizeBin'] = pd.cut(data['FamilySize'], [0, 1, 4, 11])\n\nplt.figure(figsize=[10,10])\nplt.subplot(221)\nsns.barplot('Parch', 'Survived', data=data)\nplt.subplot(222)\nsns.barplot('SibSp', 'Survived', data=data)\nplt.subplot(223)\nsns.barplot('FamilySize', 'Survived', data=data)\nplt.subplot(224)\nsns.barplot('FamilySizeBin', 'Survived', data=data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5265268d73666a3c0787b20ff892febda34a03c0"},"cell_type":"code","source":"data['Title']  = data.Name.str.extract(' ([A-Za-z]+)\\.', expand=False) \n\n# 特徴量のうち、\"Mr\", \"Master\", \"Mrs\", \"Miss\"を残してその他を\"Misc\"とする\nprint(data['Title'].value_counts())\ntitle_min = 20\ntitle_names = (data['Title'].value_counts() < title_min)\ndata['Title'] = data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n\nplt.figure(figsize=[10, 10])\nplt.subplot(221)\nsns.barplot('Title', 'Survived', data=data)\nplt.subplot(222)\nsns.barplot('Title', 'Age', data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d35b42fe8b71cc5853f858ea6a9d2a8a45840c82"},"cell_type":"code","source":"GroupByTitle = data.groupby(['Title']).mean()\nAgeGroupLabel = GroupByTitle['Age']\nAgeGroupLabel\ndata['Age'].fillna(data['Title'].apply(lambda x: AgeGroupLabel.loc[x]), inplace = True)\n\nsns.FacetGrid(data=data, hue='Survived', aspect=3).map(sns.kdeplot, 'Age', shade=True)\nplt.ylabel('Passenger Density')\nplt.legend()\nplt.show()\n\nplt.figure(figsize=[5, 5])\ndata['AgeBin'] = pd.cut(data['Age'], [0, 4, 8, 16, 100])\nsns.barplot('AgeBin', 'Survived', data=data)\nplt.show","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69320e1fafb94355790f91aa467148d0025f5f05","collapsed":true},"cell_type":"code","source":"le = LabelEncoder()\n\ndata['Sex_Code'] = le.fit_transform(data['Sex'])\ndata['FamilySizeBin_Code'] = le.fit_transform(data['FamilySizeBin'])\ndata['Title_Code'] = le.fit_transform(data['Title'])\ndata['AgeBin_Code'] = le.fit_transform(data['AgeBin'])\n\ndrop_column = ['Age',\n                        'AgeBin',\n                        'Sex',\n                        'FamilySizeBin',\n                        'Title',\n                        'Cabin',\n                        'Embarked', \n                        'Fare', \n                        'Ticket',\n                        'Name', \n                        'Parch',\n                        'SibSp', \n                        'FamilySize',\n                        'PassengerId']\n\ndata.drop(drop_column, axis=1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7344a5524877386133595a55b1a794066cb7ded8"},"cell_type":"code","source":"colormap = plt.cm.viridis\nplt.figure(figsize=(12,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(data.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8beef2c169d9abb9231074611e4a7e49e961eb57","collapsed":true},"cell_type":"code","source":"data = pd.get_dummies(data, columns=['Pclass','Sex_Code', 'FamilySizeBin_Code','Title_Code', 'AgeBin_Code'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ea904505b3f1b26a1a7340fe5194ab7b1f72521e"},"cell_type":"code","source":"train_df = data.drop(['Survived'], axis=1)\ntest_df = data['Survived']\ntrain_values = train_df.values\ntest_values = test_df.values\n\ntrain_X_ALL = train_values[:train_len, :]\ntrain_y_ALL = test_values[:train_len].astype(int)\n\npred_X = train_values[train_len:, :]\n\n(train_X, test_X ,train_y, test_y) = train_test_split(train_X_ALL, train_y_ALL, test_size = 0.25, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c25c26629db565520d461c2cb495e7a4479b2a6"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn import grid_search\nfrom sklearn.grid_search import GridSearchCV\n\nparameters = {\n        'n_estimators'      : [10,25,50,75,100],\n        'random_state'      : [0],\n        'n_jobs'            : [4],\n        'min_samples_split' : [5, 10, 15, 20, 25, 30],\n        'max_depth'         : [5, 10, 15, 20, 25, 30]\n}\n\n#clf = grid_search.GridSearchCV(RandomForestClassifier(), parameters)\n#clf.fit(train_X, train_y) \n#print(clf.best_estimator_)\n\nrfc = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=15, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0, min_impurity_split=None,\n            min_samples_leaf=1, min_samples_split=20,\n            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,\n            oob_score=False, random_state=0, verbose=0, warm_start=False)\nrfc.fit(train_X, train_y)\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nstratifiedkfold = StratifiedKFold(n_splits=5)\nprint('Cross-validation scores: \\n{}'.format(cross_val_score(rfc, train_X_ALL, train_y_ALL, cv=stratifiedkfold)))\n\ntrain_size = np.arange(15, 446, step=30)\n\nfrom sklearn.model_selection import learning_curve\ntrain_sizes, train_scores, valid_scores = learning_curve(rfc, train_X_ALL, train_y_ALL, train_sizes=train_size, cv=3)\nplt.figure\nplt.plot(train_sizes, train_scores, label='train')\nplt.plot(train_sizes, valid_scores, label='valid')\nplt.legend()\nplt.show\n\nfeatures = train_df.columns\nimportances = rfc.feature_importances_\nindices = np.argsort(importances)\n\nplt.figure()\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), features[indices])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"09d1fc850e8fe51d1da793d1efb6cffa0aac1366"},"cell_type":"code","source":"Y_pred = rfc.predict(pred_X)\n\nsubmission = pd.DataFrame({\n        \"PassengerId\": test_raw[\"PassengerId\"].astype(int),\n        \"Survived\": Y_pred\n    })\n\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7789288504e8d63e85f89bd62983db850b9bbe25"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}