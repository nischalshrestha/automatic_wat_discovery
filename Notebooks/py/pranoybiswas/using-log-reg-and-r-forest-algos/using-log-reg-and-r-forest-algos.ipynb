{"nbformat_minor": 1, "cells": [{"cell_type": "markdown", "execution_count": null, "source": "**Heavily based on the wonderful Kernel  by Omar Gabry**: https://www.kaggle.com/omarelgabry/a-journey-through-titanic \n", "outputs": [], "metadata": {"_cell_guid": "8119b9e3-a9a6-40e1-8d17-99f730dd57ec", "_execution_state": "idle", "_uuid": "a72f9117ac2f700cf0d7305d40286539bd7ce27f"}}, {"cell_type": "code", "outputs": [], "source": "# pandas\nimport pandas as pd\nfrom pandas import Series,DataFrame\n\n# numpy, matplotlib, seaborn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier", "execution_count": null, "metadata": {"_cell_guid": "fea1d431-0a5b-4549-b4ca-5d16cba01dd0", "_execution_state": "idle", "collapsed": true, "_uuid": "13540c6f2187cf1bcb0df1880223ed81273217e4", "trusted": false}}, {"cell_type": "code", "outputs": [], "source": "# get titanic & test csv files as a DataFrame\ntitanic_df = pd.read_csv(\"../input/train.csv\")\ntest_df    = pd.read_csv(\"../input/test.csv\")\n\n# preview the data\ntitanic_df\n", "execution_count": null, "metadata": {"_cell_guid": "f179a122-95ef-4aa0-9ebe-ac6e612360bc", "_execution_state": "idle", "collapsed": true, "_uuid": "aa8e7e3a46c20662361c519f2850b2b60fe0025c", "trusted": false}}, {"cell_type": "markdown", "execution_count": null, "source": "**Drop unnecessary columns, these columns won't be useful in analysis and prediction**", "outputs": [], "metadata": {"_cell_guid": "c18abd46-4c11-4916-bbde-ddc3c4d2ba23", "_uuid": "418dacf47b7a5d131f6f020cba8bd1e8748c2121"}}, {"cell_type": "code", "outputs": [], "source": "\ntitanic_df = titanic_df.drop(['PassengerId','Name','Ticket','Embarked','Cabin'], axis=1)\ntest_df    = test_df.drop(['Name','Ticket','Embarked','Cabin'], axis=1)\n\ntitanic_df.head()\n", "execution_count": null, "metadata": {"_cell_guid": "05bf59a9-7e7c-4923-9b24-2c521b8475c3", "_execution_state": "idle", "collapsed": true, "_uuid": "16563d5cecac1dd0bc2f2f7ddcc12c485fe8b4e5", "trusted": false, "scrolled": false}}, {"cell_type": "markdown", "execution_count": null, "source": "**Filling up of missing values and creating Family column**", "outputs": [], "metadata": {"_cell_guid": "93733f87-dad6-4fdf-abad-f4d1ff838349", "_uuid": "55eff774a72dd60088e55511cd701cf2d1f94dae"}}, {"cell_type": "code", "outputs": [], "source": "\n\n# Fare\n\n# only for test_df, since there is a missing \"Fare\" values\ntest_df[\"Fare\"].fillna(test_df[\"Fare\"].median(), inplace=True)\n\n# convert from float to int\ntitanic_df['Fare'] = titanic_df['Fare'].astype(int)\ntest_df['Fare']    = test_df['Fare'].astype(int)\n\n# Family\n\n# Instead of having two columns Parch & SibSp, \n# we can have only one column represent if the passenger had any family member aboard or not,\n# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.\ntitanic_df['Family'] =  titanic_df[\"Parch\"] + titanic_df[\"SibSp\"]\ntitanic_df['Family'].loc[titanic_df['Family'] > 0] = 1\ntitanic_df['Family'].loc[titanic_df['Family'] == 0] = 0\n\ntest_df['Family'] =  test_df[\"Parch\"] + test_df[\"SibSp\"]\ntest_df['Family'].loc[test_df['Family'] > 0] = 1\ntest_df['Family'].loc[test_df['Family'] == 0] = 0\n\n# drop Parch & SibSp\ntitanic_df = titanic_df.drop(['SibSp','Parch'], axis=1)\ntest_df    = test_df.drop(['SibSp','Parch'], axis=1)\n\n\n", "execution_count": null, "metadata": {"_cell_guid": "2c02b690-e638-48c2-8518-01e9c96b3413", "_execution_state": "idle", "collapsed": true, "_uuid": "4f548f7b5a02f07fc30c235525939fa32daa7edf", "trusted": false}}, {"cell_type": "markdown", "execution_count": null, "source": "Converting categorical variables Sex and Pclass into numerical values.", "outputs": [], "metadata": {"_cell_guid": "56193a4c-d638-430d-9b8a-3d9d34f1b784", "_uuid": "e402db2270f2e381e516f375c8824fd39ee2931c"}}, {"cell_type": "code", "outputs": [], "source": "# Sex\n\n# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.\n# So, we can classify passengers as males, females, and child\ndef get_person(passenger):\n    age,sex = passenger\n    return 'child' if age < 16 else sex\n    \ntitanic_df['Person'] = titanic_df[['Age','Sex']].apply(get_person,axis=1)\ntest_df['Person']    = test_df[['Age','Sex']].apply(get_person,axis=1)\n\n# No need to use Sex column since we created Person column\ntitanic_df.drop(['Sex'],axis=1,inplace=True)\ntest_df.drop(['Sex'],axis=1,inplace=True)\n\n# create dummy variables for Person column\nperson_dummies_titanic  = pd.get_dummies(titanic_df['Person'])\nperson_dummies_titanic.columns = ['Child','Female','Male']\nperson_dummies_test  = pd.get_dummies(test_df['Person'])\nperson_dummies_test.columns = ['Child','Female','Male']\ntitanic_df = titanic_df.join(person_dummies_titanic)\ntest_df    = test_df.join(person_dummies_test)\n\ntitanic_df.drop(['Person'],axis=1,inplace=True)\ntest_df.drop(['Person'],axis=1,inplace=True)\n\n# Pclass\n\n# create dummy variables for Pclass column\npclass_dummies_titanic  = pd.get_dummies(titanic_df['Pclass'])\npclass_dummies_titanic.columns = ['Class_1','Class_2','Class_3']\npclass_dummies_test  = pd.get_dummies(test_df['Pclass'])\npclass_dummies_test.columns = ['Class_1','Class_2','Class_3']\n\ntitanic_df.drop(['Pclass'],axis=1,inplace=True)\ntest_df.drop(['Pclass'],axis=1,inplace=True)\n\ntitanic_df = titanic_df.join(pclass_dummies_titanic)\ntest_df    = test_df.join(pclass_dummies_test)\n\ntitanic_df.head()", "execution_count": null, "metadata": {"_cell_guid": "dc445bd1-6f95-4c89-8286-78efc27a7c80", "_execution_state": "idle", "collapsed": true, "_uuid": "fcd0b541bd6b50c3cf4875c512a64fcc8057a390", "trusted": false}}, {"cell_type": "markdown", "execution_count": null, "source": "**Age Column**:\n\nPredicting missing age values using Random Forest. \nCheers to Poonam Ligade's kernel for the following sections: https://www.kaggle.com/poonaml/titanic-survival-prediction-end-to-end-ml-pipeline ", "outputs": [], "metadata": {"_cell_guid": "1e0b1ec3-110e-46dd-aca5-073968ac4237", "_uuid": "2d42e75bd44145f7786ba9a3d6b369d8e2e88db3"}}, {"cell_type": "code", "outputs": [], "source": "from sklearn.ensemble import RandomForestRegressor\n#predicting missing values in age using Random Forest\ndef fill_missing_age(df):\n    \n    #Feature set\n    age_df = df[['Age','Fare', 'Family','Child','Female','Male','Class_1','Class_2','Class_3']]\n    # Split sets into train and test\n    train  = age_df.loc[ (df.Age.notnull()) ]# known Age values\n    test = age_df.loc[ (df.Age.isnull()) ]# null Ages\n    \n    # All age values are stored in a target array\n    y = train.values[:, 0]\n    \n    # All the other values are stored in the feature array\n    X = train.values[:, 1::]\n    \n    # Create and fit a model\n    rtr = RandomForestRegressor(n_estimators=2000, n_jobs=-1)\n    rtr.fit(X, y)\n    \n    # Use the fitted model to predict the missing values\n    predictedAges = rtr.predict(test.values[:, 1::])\n    \n    # Assign those predictions to the full data set\n    df.loc[ (df.Age.isnull()), 'Age' ] = predictedAges \n    \n    return df\n\ntitanic_df=fill_missing_age(titanic_df)\ntest_df=fill_missing_age(test_df)\n\ntitanic_df\n", "execution_count": null, "metadata": {"_cell_guid": "1caeae6f-4bad-4b55-a56e-56c786775444", "_uuid": "d9ac334df0b8793fcc4bddb69ea555d49eeedf7a", "collapsed": true, "trusted": false}}, {"cell_type": "markdown", "execution_count": null, "source": "**Feature Scaling**", "outputs": [], "metadata": {"_cell_guid": "e0aebc4a-e610-45e9-8e65-ce41b5e5f089", "_uuid": "1ba692c4132b0cfa8c07ce195bbc18113110b445"}}, {"cell_type": "code", "outputs": [], "source": "from sklearn import preprocessing\n\nstd_scale = preprocessing.StandardScaler().fit(titanic_df[['Age', 'Fare']])\ntitanic_df[['Age', 'Fare']] = std_scale.transform(titanic_df[['Age', 'Fare']])\n\n\nstd_scale = preprocessing.StandardScaler().fit(test_df[['Age', 'Fare']])\ntest_df[['Age', 'Fare']] = std_scale.transform(test_df[['Age', 'Fare']])\n\ntitanic_df.head()", "execution_count": null, "metadata": {"_cell_guid": "1540d840-3670-45c4-ba70-17887ae1cbb8", "_uuid": "3db8c9107ba06ef9e674cab7d8401b49a5b33645", "collapsed": true, "trusted": false}}, {"cell_type": "code", "outputs": [], "source": "# define training and testing sets\n\nX_train = titanic_df.drop(\"Survived\",axis=1)\nY_train = titanic_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\",axis=1).copy()", "execution_count": null, "metadata": {"_cell_guid": "dcd12c64-5f35-4dec-bed3-a4503cc9af57", "_execution_state": "idle", "collapsed": true, "_uuid": "ae8b049fb58bd7468510fd55c611325c67004791", "trusted": false}}, {"cell_type": "markdown", "execution_count": null, "source": "**Applying Logistic Regression and Random Forest and using cross-validation for scoring.**\n\n*Logistic regression actually performed better in the leaderboard, 76% score compared to 74% when applying Random Forest.*", "outputs": [], "metadata": {"_uuid": "d921a428118014d3ecd09ec89e52fc4ee212168f"}}, {"cell_type": "code", "outputs": [], "source": "# Logistic Regression\nfrom sklearn import cross_validation\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import ShuffleSplit\n\nlogreg = LogisticRegression()\n\nlogreg.fit(X_train, Y_train)\n\nY_pred = logreg.predict(X_test)\n\n# Compute the accuracy score for all the cross validation folds.\ncv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=50)\n\nscores = cross_val_score(logreg, X_train, Y_train,scoring='f1', cv=cv)\n\nscores.mean()", "execution_count": null, "metadata": {"_cell_guid": "773ea074-9f32-4db8-9fc8-66e99bba5811", "_execution_state": "idle", "collapsed": true, "_uuid": "a54da2e19bda6a1e4c4d7b4759ca3cd4901834f1", "trusted": false}}, {"cell_type": "code", "outputs": [], "source": "# Random Forests\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\n\nrandom_forest.fit(X_train, Y_train)\n\nY_pred = random_forest.predict(X_test)\n\n# Compute the accuracy score for all the cross validation folds.\ncv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=50)\n\nscores = cross_val_score(random_forest, X_train, Y_train,scoring='f1', cv=cv)\n\nscores.mean()", "execution_count": null, "metadata": {"_cell_guid": "1aa0635f-631b-4fa9-bbaf-7bd53e6b81e6", "_execution_state": "idle", "collapsed": true, "_uuid": "0bc4947bcba522e5b95045656a610f66de93b813", "trusted": false}}, {"cell_type": "code", "outputs": [], "source": "submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('titanic.csv', index=False)", "execution_count": null, "metadata": {"_cell_guid": "84b4010c-1e1d-4c3b-8a3c-3987057d24c6", "_execution_state": "idle", "collapsed": true, "_uuid": "40eeb5584fe24774c2abb2011fed73919e8dde38", "trusted": false}}], "nbformat": 4, "metadata": {"language_info": {"version": "3.6.1", "nbconvert_exporter": "python", "name": "python", "file_extension": ".py", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}}