{"cells": [{"execution_count": null, "metadata": {"trusted": false, "_cell_guid": "7f6bbc8a-e8f1-2454-3541-80f531a7a094", "_uuid": "a6e3d7a133c4a09e250382466bbf3c552d8cf45a"}, "cell_type": "code", "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.", "outputs": []}, {"execution_count": null, "metadata": {"trusted": false, "_execution_state": "idle", "_uuid": "c0ccc50dc75745c521740dfd9ba8178f6049a0ca", "_cell_guid": "abaf9b81-fe64-073a-5646-b99d981e0557"}, "cell_type": "code", "source": "#Load packages\n\nimport pandas as pd\nfrom sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nimport matplotlib.pyplot as plt\nimport numpy as np", "outputs": []}, {"execution_count": null, "metadata": {"trusted": false, "_execution_state": "idle", "_uuid": "5ba99eeceda76a7be9e691464bc1918c7302ea1c", "_cell_guid": "43703b32-6849-187f-3cec-763d9750d265"}, "cell_type": "code", "source": ["#Import CSVs\n", "titanicTrain_X = pd.read_csv('../input/train.csv')\n", "titanicTest_X = pd.read_csv('../input/test.csv')\n", "\n", "#Split Train into X and y\n", "titanicTrain_y = titanicTrain_X['Survived']\n", "titanicTrain_X = titanicTrain_X.drop('Survived', axis=1)\n", "\n", "#Name the dataframes\n", "titanicTrain_y.name = 'titanicTrain_y'\n", "titanicTrain_X.name = 'titanicTrain_X'\n", "titanicTest_X.name = 'titanicTest_X'\n", "\n", "#Place datasets into lists\n", "observationSets = [titanicTrain_X, titanicTest_X]\n", "\n", "#general statistics on both data sets\n", "for dataset in observationSets:\n", "    print( dataset.describe() ) # results of the print indicate AGE will need NAs cleaned\n", "   "], "outputs": []}, {"execution_count": null, "metadata": {"trusted": false, "_execution_state": "idle", "_uuid": "a3f9eb8353b4f12123a9751e84b71a86712bb5d9", "_cell_guid": "4a4b7059-414f-e015-3355-5912d6b66c85"}, "cell_type": "code", "source": ["#Sort Passengers into age groups\n", "\n", "for dataset in observationSets:\n", "    dataset['Age'] = dataset['Age'].fillna(dataset['Age'].mean())\n", "    ageBins = [0, 10, 20, 60, 125]\n", "    ageBinValues = [0, 1, 2, 3]\n", "    dataset['Age'] = pd.cut(dataset['Age'], ageBins, labels = ageBinValues)\n", "    "], "outputs": []}, {"execution_count": null, "metadata": {"trusted": false, "_cell_guid": "6984bcfa-6081-1f87-6dea-eeb3b9153aa2", "_uuid": "1c6c1657043a93592127118a2835a52f32bb6367"}, "cell_type": "code", "source": ["#Change female and male to binary. Female = 0, male = 1\n", "\n", "for dataset in observationSets:\n", "    dataset['Sex'] = dataset['Sex'].map({'female': 0, 'male': 1})\n", "    "], "outputs": []}, {"execution_count": null, "metadata": {"trusted": false, "_cell_guid": "31e442a4-382a-0ca4-d983-eea8a325ad42", "_uuid": "c5b0d2ea7a07004500395770a3effac8aad21773"}, "cell_type": "code", "source": "#Fix the NA values for Parent and Siblings counts by setting NAs to 0\n\nfor dataset in observationSets:\n    dataset['Parch'] = dataset['Parch'] .fillna(0)\n    dataset['SibSp'] = dataset['SibSp'] .fillna(0)", "outputs": []}, {"execution_count": null, "metadata": {"trusted": false, "_cell_guid": "0654789b-72fa-9ce0-8592-7078b41f0b96", "_uuid": "dcafc7891dbe9a970690aeb757cf3f17cdf85c4f"}, "cell_type": "code", "source": "#Transform Embarked to numeric values. Fill Na embarked to 0. \n\nfor dataset in observationSets:\n    dataset['Embarked'] = dataset['Embarked'].fillna(0)\n    dataset['Embarked'] = dataset['Embarked'].map({0:0, 'S':1, 'Q':2, 'C':3}).astype(int)", "outputs": []}, {"execution_count": null, "metadata": {"trusted": false, "_cell_guid": "87fb6eec-1d79-33b7-47a3-3a9c83c88cef", "_uuid": "e39d12ff5551363fdc227cf20fd5e2115c69529d"}, "cell_type": "code", "source": "#Remove less useful columns\n#  Name: Could potentially extract Mr. Mrs. and Miss. Perhaps a Mrs. is more likely \n#        to survive since they could have kids\n#  Ticket: Not in a standard easily parsable format\n#  Fare: This data is alread fairly well represented in Pclass\n#  Cabin: Contains a lot of nulls and im nut sure what i should do with them without \n#         altering the learning\nfor dataset in observationSets:\n    dataset.drop(['PassengerId', 'Name', 'Ticket', 'Fare', 'Cabin'], axis = 1, inplace = True)", "outputs": []}, {"execution_count": null, "metadata": {"trusted": false, "_cell_guid": "779c7232-64a6-b3d4-9386-09f115a56030", "_uuid": "870876170d034864fe3be298a39563c1498f21bd"}, "cell_type": "code", "source": "#Titanic Train Data\nfor dataset in observationSets:\n    print(dataset.name)\n    print(dataset.head())", "outputs": []}, {"execution_count": null, "metadata": {"trusted": false, "_cell_guid": "646bf04c-57f6-acde-b346-a28a2d90610d", "_uuid": "0398f4f5cebee51a7923cd21c3ec53d8d0b8096c"}, "cell_type": "code", "source": "#Check for Null Values\n\nprint( pd.isnull(titanicTest_X).sum() > 0 )\n\nprint( pd.isnull(titanicTrain_X).sum() > 0 )\n", "outputs": []}, {"execution_count": null, "metadata": {"trusted": false, "_cell_guid": "161d096d-2d95-8888-c766-f8ffca9438c6", "_uuid": "c7db1fe83bf6a1c4d096a6bee4f86a163d6b1e14"}, "cell_type": "code", "source": "titanicTest_X.info()\nprint(\"----------------------------\")\ntitanicTrain_X.info()", "outputs": []}, {"execution_count": null, "metadata": {"trusted": false, "_cell_guid": "f6d0ce89-af00-0676-b5b7-72148ad1b5e0", "_uuid": "bcadcc74b43d2c8079a38772d0cb2fdc42f61465"}, "cell_type": "code", "source": "#Starting with Linear Support Vector Classification First since i am performing classification on \n#less than 100k observations\n\n#print(titanicTrain_X.shape)\n#print(titanicTrain_y.shape)\n\nlinearClassifier = svm.LinearSVC()\nlinearClassifier = linearClassifier.fit(titanicTrain_X, titanicTrain_y)\n\nlinearClassifier.score(titanicTrain_X, titanicTrain_y) \nprediction = linearClassifier.predict(titanicTest_X) \n\ntitanicTest = pd.read_csv('../input/test.csv')\nSubmission = pd.DataFrame({\n        \"PassengerId\": titanicTest[\"PassengerId\"],\n        \"Survived\": prediction\n    })\nSubmission.to_csv(\"LinearClassifierSubmissionPrediction.csv\", index=False)", "outputs": []}, {"execution_count": null, "metadata": {"trusted": false, "_cell_guid": "1af2abff-2ddc-9bfd-ed4b-02294a8ffd52", "_uuid": "2f24914fce1c2b70cab80f668456778d6dda25e5"}, "cell_type": "code", "source": "# Next i'm going to try out KNearestNeighbors\n\nneighbors = [ 1, 3, 5, 7]\n\nfor k in neighbors:\n    kNeibrs = KNeighborsClassifier(n_neighbors = k)\n    kNeibrs.fit(titanicTrain_X, titanicTrain_y)\n    print( kNeibrs.score(titanicTrain_X, titanicTrain_y))\n    \n#5 nearest neighbors seems to fit the training data the best\n\nkNeigbrs = KNeighborsClassifier(n_neighbors = 5)\nprediction = kNeibrs.predict(titanicTest_X)\n\ntitanicTest = pd.read_csv('../input/test.csv')\nSubmission = pd.DataFrame({\n        \"PassengerId\": titanicTest[\"PassengerId\"],\n        \"Survived\": prediction\n    })\nSubmission.to_csv(\"KNeighborsSubmissionPrediction.csv\", index=False)\n", "outputs": []}, {"execution_count": null, "metadata": {"trusted": false, "_cell_guid": "261b7631-73bd-f4dd-4ac6-5bc5f2ba9091", "_uuid": "23ee96341c093693b4fa08e416b39fbbd14fb1f7"}, "cell_type": "code", "source": "", "outputs": []}], "nbformat": 4, "metadata": {"language_info": {"version": "3.6.1", "mimetype": "text/x-python", "file_extension": ".py", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "name": "python"}, "_change_revision": 0, "_is_fork": false, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat_minor": 0}