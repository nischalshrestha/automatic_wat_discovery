{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d9c11bb2-0874-af78-3519-bc48c36bde5f"
      },
      "outputs": [],
      "source": [
        "# List of libraries used \n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from IPython.display import display # Allows the use of display() for DataFrames\n",
        "from sklearn.preprocessing import LabelEncoder   # Used for label encoding the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9dfff8f1-d912-c936-dd6d-7cbd1faac10b"
      },
      "outputs": [],
      "source": [
        "#Import the data\n",
        "data_train = '../input/train.csv'\n",
        "data_train_df = pd.read_csv(data_train)\n",
        "\n",
        "\n",
        "data_test = '../input/test.csv'\n",
        "data_test_df = pd.read_csv(data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b427dd70-8849-34e1-b4db-42d3f03798ab"
      },
      "outputs": [],
      "source": [
        "# Find missing data\n",
        "data_train_df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "13bb49fa-0e02-ff3b-c4ec-c16dd08bfadc"
      },
      "outputs": [],
      "source": [
        "#Using data_train_df.info() we can observe that Age, Cabin, Embarked have missing values\n",
        "#lets analyze Age \n",
        "#reference - http://seaborn.pydata.org/generated/seaborn.FacetGrid.html\n",
        "\n",
        "sns.set(style=\"ticks\", color_codes=True)\n",
        "g = sns.FacetGrid(data_train_df, col=\"Sex\", row=\"Survived\")\n",
        "g = g.map(plt.hist, \"Age\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "06b777aa-8d7d-b15a-e304-ed2b8a58959a"
      },
      "outputs": [],
      "source": [
        "#Lets Analyze Embarked missing values\n",
        "#data_train_df[data_train_df['Embarked'].isnull()]\n",
        "data_train_df[data_train_df['Fare'] > 70.0]\n",
        "#&& data_train_df['Cabin']=='B28']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d7b6d4da-988e-a769-b76c-8bd593b13fdb"
      },
      "outputs": [],
      "source": [
        "# Import the data\n",
        "data_train = '../input/train.csv'\n",
        "data_train_df = pd.read_csv(data_train)\n",
        "\n",
        "data_test = '../input/test.csv'\n",
        "data_test_df = pd.read_csv(data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6fbaaf2a-8622-7cb9-8d07-2808ecab961e"
      },
      "outputs": [],
      "source": [
        "# Find missing data \n",
        "data_train_df.info()\n",
        "# Print Missing data\n",
        "print(\"Age, Cabin, Embarked have missing values\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5b2311d4-21e3-5d2d-5f59-3a14f5f6eaf0"
      },
      "outputs": [],
      "source": [
        "# Analyze missing values in Embarked column\n",
        "\n",
        "#  Lets check which rows have null Embarked column\n",
        "#data_train_df[data_train_df['Embarked'].isnull()]\n",
        "\n",
        "#data_train_df[data_train_df['Name'].str.contains('Martha')]\n",
        "#data_train_df[(data_train_df['Fare'] > 50) & (data_train_df['Age'] > 37) & (data_train_df['Survived']==1 ) & \n",
        "#              (data_train_df['Pclass']== 1 ) &  (data_train_df['Cabin'].str.contains('B')) ]\n",
        "#data_train_df[data_train_df['Ticket'] == 113572]\n",
        "data_train_df[data_train_df['Ticket']==111361]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "16f1a284-c8af-5275-5a2d-06138d61f6d8"
      },
      "outputs": [],
      "source": [
        "#Segregate and trim the data\n",
        "\n",
        "# Apply Label encoding\n",
        "data_train_df['Embarked'] = data_train_df['Embarked'].astype(str)\n",
        "data_train_df['Cabin'] = data_train_df['Cabin'].astype(str)\n",
        "\n",
        "data_test_df['Embarked'] = data_test_df['Embarked'].astype(str)\n",
        "data_test_df['Cabin'] = data_test_df['Cabin'].astype(str)\n",
        "\n",
        "le = LabelEncoder()\n",
        "data_train_df = data_train_df.apply(LabelEncoder().fit_transform)\n",
        "#display(data_train_df)\n",
        "\n",
        "data_test_df = data_test_df.apply(LabelEncoder().fit_transform)\n",
        "#display(data_test_df)\n",
        "\n",
        "data_train_df_survived = data_train_df['Survived']\n",
        "\n",
        "#returns a numpy array\n",
        "data_train_df_trim = data_train_df.drop(['Survived','Name','PassengerId'], axis=1).values\n",
        "data_test_df_trim = data_test_df.drop(['Name','PassengerId'], axis=1).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a0ef79ce-6061-d39b-f316-b8ca8d8c38c3"
      },
      "outputs": [],
      "source": [
        "#Normalize data \n",
        "min_max_scaler = preprocessing.MinMaxScaler()   # Used for normalized of the data\n",
        "data_train_df_trim_scaled = min_max_scaler.fit_transform(data_train_df_trim)\n",
        "data_train_df_trim_scaled = pd.DataFrame(data_train_df_trim_scaled)\n",
        "\n",
        "data_test_df_trim_scaled = min_max_scaler.fit_transform(data_test_df_trim)\n",
        "data_test_df_trim_scaled = pd.DataFrame(data_test_df_trim_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ef008218-5a32-ed63-9f3a-92215702cd2e"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_predict, cross_val_score, KFold\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "def implement_randomForestClassifier(X_train,y_train,X_test,number_of_estimators=10,max_depth=None, \n",
        "                  minimum_samples_split=2,minimum_samples_leaf=1,random_number=42):\n",
        "    \"\"\"\n",
        "    This function fits and transforms data using \n",
        "    Random Forest Classifier technique and \n",
        "    returns the mean of y_pred value\n",
        "    \"\"\"\n",
        "    clf = RandomForestClassifier(n_estimators=number_of_estimators,min_samples_split=minimum_samples_split,\n",
        "                                  min_samples_leaf=minimum_samples_leaf,random_state=random_number)\n",
        "    kf = KFold(n_splits=3, random_state=2)\n",
        "    cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\n",
        "    predictions = cross_val_predict(clf, X_train,y_train,cv=kf)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    \n",
        "    scores = cross_val_score(clf, X_train, y_train,scoring='f1', cv=kf)\n",
        "    print(scores.mean())\n",
        "    \n",
        "    '''\n",
        "    Plot the features wrt their importance\n",
        "    '''\n",
        "    \n",
        "    importances = clf.feature_importances_\n",
        "    std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
        "             axis=0)\n",
        "    indices = np.argsort(importances)[::-1]\n",
        "    \n",
        "    # Print the feature ranking\n",
        "    print(\"Feature ranking:\")\n",
        "    for f in range(X_train.shape[1]):\n",
        "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
        "    \n",
        "    # Plot the feature importances of the forest\n",
        "    plt.figure()\n",
        "    plt.title(\"Feature importances\")\n",
        "    plt.bar(range(X_train.shape[1]), importances[indices],\n",
        "       color=\"r\", yerr=std[indices], align=\"center\")\n",
        "    plt.xticks(range(X_train.shape[1]), indices)\n",
        "    plt.xlim([-1, X_train.shape[1]])\n",
        "    plt.show()\n",
        "    \n",
        "    '''\n",
        "    Return the mean of predicted scores\n",
        "    '''\n",
        "    \n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "95830474-5c7b-95fb-7e73-d07a0e2e905d"
      },
      "outputs": [],
      "source": [
        "#Finding optimum estimator in case of RFC\n",
        "#reference - https://matthew-nm.github.io/pages/projects/gender04_content.html\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "def calculate_optimum_estimator_rfc(X_train,y_train,X_test,y_test,interval=5):\n",
        "    error_rate = []\n",
        "    nvals = range(1,800,interval) # test a range of total trees to aggregate\n",
        "\n",
        "    for i in nvals:\n",
        "        rfc = RandomForestClassifier(n_estimators=i)\n",
        "        rfc.fit(X_train,y_train)\n",
        "        y_pred_i = rfc.predict(X_test)\n",
        "        error_rate.append(np.mean(y_pred_i != y_test))\n",
        "\n",
        "\n",
        "\n",
        "    plt.plot(nvals, error_rate, color='blue', linestyle='dashed', marker='o',\n",
        "             markerfacecolor='red', markersize=10)\n",
        "    plt.title('Error Rate vs. Number of Predictors')\n",
        "    plt.xlabel('Number of Predictors')\n",
        "    plt.ylabel('Error Rate')\n",
        "\n",
        "    # Determine location of best performance\n",
        "    nloc = error_rate.index(min(error_rate))\n",
        "    print('Lowest error of %s occurs at n=%s.' % (error_rate[nloc], nvals[nloc]))\n",
        "    return nvals[nloc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "da675313-d8b7-a570-e71e-b43ea5b0b3a4"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data_train_df_trim_scaled,data_train_df_survived,test_size=0.2, random_state=42)\n",
        "optimum_value = calculate_optimum_estimator_rfc(X_train,y_train,X_test,y_test,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c6b9f977-30f5-bb79-7e3f-25b0d13e21a0"
      },
      "outputs": [],
      "source": [
        "y_pred = implement_randomForestClassifier(data_train_df_trim_scaled,data_train_df_survived,\n",
        "                       data_test_df_trim_scaled,101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "51d0ae9b-4fd1-43fe-6987-ddb460f1d06e"
      },
      "outputs": [],
      "source": [
        "data_test_v1 = pd.read_csv(data_test)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "        \"PassengerId\": data_test_v1[\"PassengerId\"],\n",
        "        \"Survived\": y_pred\n",
        "    })\n",
        "\n",
        "submission.to_csv(\"titanic_submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "18634bef-6c72-0a83-adc4-8685579265f6"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}