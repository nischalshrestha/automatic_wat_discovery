{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"np.random.seed(0)\n#Creating variables for train_data and test_data\ntrain_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')\n\n#Describing train_data to see if there are any missing values.\ntrain_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73f595d4b0a64e65eec1420fd65a1a56e1e62de9"},"cell_type":"markdown","source":"# Cleaning The Data"},{"metadata":{"trusted":true,"_uuid":"497aafebc7f1b58bafd1e01a2350e99a86f7a26b"},"cell_type":"code","source":"#As we can see there are some missing values in 'Age', let's inspect the data\ntrain_data['Age'].head(20)\n\n#As suspected 'Age' has NaN values. To fix them we can substitute the ages with the mean age which is 29.69, roughly 30.\ntrain_data['Age'] = train_data['Age'].fillna(30.0)\ntest_data['Age'] = test_data['Age'].fillna(30.0)\n\n#There are also NaN values in test_data's 'Fare' column. We'll just replace it with the mean fare as well.\ntest_data['Fare'] = test_data['Fare'].fillna(30.0)\n\n#For our model to work, we will also need to change the age to numeric values.\n#We'll use a simple convention where female=1, male=0\ntrain_data['Sex'] = train_data['Sex'].replace('male',0)\ntrain_data['Sex'] = train_data['Sex'].replace('female',1)\ntest_data['Sex'] = test_data['Sex'].replace('male',0)\ntest_data['Sex'] = test_data['Sex'].replace('female',1)\n        \n#Let's describe the data now\ntest_data.describe()\n#train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98370b2b254145675aeb37512961fc4f4bd3209f"},"cell_type":"code","source":"#Looks like we've fixed the 'Age' column and we're back to 891 values. The mean is also not as changed as it could have been.\n\n#Let's print all columns to find the prediction target\ntrain_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e1ea5041224726811fd20cc818606f75841a9eb"},"cell_type":"code","source":"#It's clear we're looking at the 'Survived' column when we're looking to make predictions.\n\ny = train_data.Survived","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a6694b7198a8e38a1e5dfe02ee9762ce37c3c51"},"cell_type":"markdown","source":"# Creating X\n\nLet's start defining our X now. We can see that most columns would affect the survival rate of the passengers.\n\nLet's say the following columns affect the survival rate. Namely,\n\n* Pclass\n* Sex\n* Age\n* SibSp\n* Parch\n* Fare\n\nThe reason I've chosen to ignore ticket, cabin, and embarked is because none of them are of obvious significance. The fare is included because more affluent people could have access to better cabins and facilities. In general, affluent people would have larger chances because of their position in the hierarchy. This isn't true but an assumption on my part.\n"},{"metadata":{"trusted":true,"_uuid":"2df1763c1b2fe6cae596e7a485d815f10a708102"},"cell_type":"code","source":"#Let's define X\n\nfeatures = ['Pclass','Sex','Age','SibSp','Parch','Fare']\n\nX = train_data[features]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2c3fb8137d2f46e7316c7a58b4de3d386ebf9c0"},"cell_type":"markdown","source":"# Reviewing The Data"},{"metadata":{"trusted":true,"_uuid":"81e20df59ea9ec0e58877237e55910adbd38f33c"},"cell_type":"code","source":"#Let's review X before we proceed\n\nprint(X.describe())\nprint(\"\\n\")\nprint(X.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8e15963586e6c9cbde2141588d68ebcfb4dee07"},"cell_type":"markdown","source":"# Splitting The Data"},{"metadata":{"trusted":true,"_uuid":"cd0c652198a3cef6eedfa3da2f6e7fddccb5365b"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1, test_size = 0.15)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ba748d3f5173d7999e4639dbcedd3f2abcc8416"},"cell_type":"markdown","source":"# Get The Maximum Number of Leaf Nodes"},{"metadata":{"trusted":true,"_uuid":"55fd792474938fcc5476b78d5a4482ba24a148b2"},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\n\ndef get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n    model = RandomForestRegressor(max_leaf_nodes=max_leaf_nodes, random_state=1)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n\nleaf_nodes = [5, 25, 50, 100, 250, 500, 1000, 2000]\n\nfor node in leaf_nodes:\n    print(node, get_mae(node,train_X,val_X,train_y,val_y))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98fb1496e058ad60bce90b61ef6876e8b438fb27"},"cell_type":"markdown","source":"# Building The Model Using Random Forests"},{"metadata":{"trusted":true,"_uuid":"ea4dee41587c74d2b89a9463658bf92e73dee275"},"cell_type":"code","source":"titanic_model = RandomForestRegressor(random_state=1, max_leaf_nodes = 50)\n\ntitanic_model.fit(train_X,train_y)\nprediction = titanic_model.predict(val_X)\nval_mae = mean_absolute_error(val_y,prediction)\n\nprint(val_mae)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a085dde8c69f9572eeb0ec640acbfa309fcf155"},"cell_type":"markdown","source":"# Making The Predictions"},{"metadata":{"trusted":true,"_uuid":"1ab39e1da81ec9a8d7d38e05259208dc177b15d6"},"cell_type":"code","source":"final_X = test_data[features]\nfinal_predictions = titanic_model.predict(final_X)\nfinal_predictions = np.round(final_predictions)\nfinal_predictions = final_predictions.astype(int)\nprint(final_predictions[1:10])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92d3c9aeb99028680ab093c07ab8ee81bdd27162"},"cell_type":"markdown","source":"# Creating the submission"},{"metadata":{"trusted":true,"_uuid":"93e039656240249282833cbc70b99a168e1e14c8"},"cell_type":"code","source":"#creating the object\nsubmission = pd.DataFrame({\n    'PassengerId':test_data['PassengerId'],\n    'Survived':final_predictions\n})\nprint(submission.head())\nsubmission.to_csv('titanic_submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}