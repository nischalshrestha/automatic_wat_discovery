{"cells":[{"metadata":{"_uuid":"7a796f2d7b27418d3f72e610d0feab558c58b9a3","_cell_guid":"7e0dffa8-1f16-49c3-92e0-0e1de2807549"},"cell_type":"markdown","source":" # 1. Introduction"},{"metadata":{"_uuid":"8f6560973c583a9fc9699e310a10430af666f329","_cell_guid":"5d53ef11-40b4-4570-be46-6045fff81c97"},"cell_type":"markdown","source":"This is my first approach to a kaggle competition and it's still work in progress. So comments and critical feedback are welcome."},{"metadata":{"_uuid":"50e9777907981df33cbf39aa329657dfcf7fc897","_cell_guid":"035c1f04-ff2f-4c93-ab40-bf5e44d607ee"},"cell_type":"markdown","source":"## Contents:\n\n#### Part 1 (Introduction)\nLoading the dataset and starting to get familiar with it\n\n#### Part 2 (Analysis Section)\nExploratory analysis and finding patterns and trends\n\n#### Part 3 (Clean and transform data)\n* handling missing and incorrect values\n* creating new features and dropping insignificant ones\n* transforming data for machine learning algorithms to able to deal with it\n\n#### Part 4 (Model training)\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":false,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use('seaborn-darkgrid')\n\nimport os\nprint(os.listdir(\"../input\"))\n\n%matplotlib inline\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/train.csv\")\ndf_test = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc9b8a0151a1d0dc5801390c6453c18458ed613a","_cell_guid":"a9b47861-fd8d-4f0f-91d5-73653f291cf7","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57b797406ad02f77afc55cebf5d731dda0a9ec70","_cell_guid":"d9874298-55ef-42cb-859c-bca40be40345","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b16c7b3fd7e76b6ec7a93179088b07f710dbb6fa","_cell_guid":"e66907a3-22fd-4f28-b2f5-e3cb71c65682","trusted":false,"collapsed":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80186eb464cc70267793dbaadfa0227eba0fae2c","_cell_guid":"9f17151b-c887-4d39-896c-254078dc14b5","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d285c36c13ef06ef9f6bd0238116369cdbc4751","_cell_guid":"4223a2f1-2cc4-45b0-a8f7-08e8d86620e7"},"cell_type":"markdown","source":"**Summary**\n\nWe do have the following features in the dataset:"},{"metadata":{"_uuid":"a5b3dbb5d2392dd17b30497b56578913645a12c1","_cell_guid":"741423b2-e508-424a-a930-a70c5e326354","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train.columns.values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d177714551297ea69a9130aa9e97987c9c35141","_cell_guid":"fbe58ed9-a02f-48bb-9d65-27c52218cbe1"},"cell_type":"markdown","source":"# 2. Analysis section\n## Identify Features\n\nFirst we want to identify in which category each variable falls. We can classify data into two different types: categorical and numerical.\n\n**Categorical features:**\n\nOrdinal:\n* Embarked\n\nNominal:\n* Survived\n* Sex\n* Pclass\n\n**Numerical features:**\n\nDiscrete:\n* SibSp\n* Parch\n\nContinuous:\n* Age\n* Fare\n\n**Other variables:**\n\nWe can drop the PassengerId, Ticket and Cabin Column from the dataset since they add no value to the analysis. We still need the PassengerId in the test dataset though.\n\nMaybe the Name column can still be used to extract some useful features."},{"metadata":{"_uuid":"b62b6acbdebc9e39c2bbeb42afe186be2e1cfe55","collapsed":true,"_cell_guid":"8b54956c-f392-46fb-a0f4-08dc3062b989","trusted":false},"cell_type":"code","source":"# dropping the columns 'PassengerId', 'Ticket' and 'Cabin'\ndf_train = df_train.drop(['PassengerId', 'Ticket', 'Cabin'], axis=1)\ndf_test = df_test.drop(['Ticket', 'Cabin'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8cd0d09e28da81251e32f8c3033a4ac3c68a8933","_cell_guid":"1a2f4c0b-15ce-4803-a58f-1dee810b2e7b"},"cell_type":"markdown","source":"## Analysis\n\nWe will now analyze the dataset and decide which features to include in the model training. The different steps are all the same for each variable: Analysis, Observations and Decision."},{"metadata":{"_uuid":"7aafae2baf0e9505a04a4c5df0aa7c058edddd5a","_cell_guid":"ce97c627-0ef6-45fd-8126-12729fc5d1f7"},"cell_type":"markdown","source":"### Age\n#### Analysis\nWe will start by analyzing how many values are missing in the dataset for the column 'Age'.\nAfter that we will create a simple visualization to see how our data is distributed. "},{"metadata":{"_uuid":"ab05bc28efb346930c5010325c78e096ee5b6720","_cell_guid":"7532dec2-44ec-48d6-a970-e98714882973","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train['Age'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b10d476c523c6a9e0a2bf58babc891d6e8cf7ef","_cell_guid":"e0ab7509-3ff4-4067-a2b0-09ea85c3abd6"},"cell_type":"markdown","source":"There are 177 missing values. We might need to replace them in later stages of the Analysis.\nWe will now create two histograms of \"Age\" for the two possible values of \"Survived\"."},{"metadata":{"_uuid":"b2441baf782d6e6639b4b127bde9f7a0ab1a9c9f","_cell_guid":"0d041726-ec78-4737-a9ab-d5c91ad161ae","trusted":false,"collapsed":true},"cell_type":"code","source":"g = sns.FacetGrid(df_train, col=\"Survived\")\ng.map(plt.hist, 'Age', bins = 15);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a872d51eb1ab5feec75eba15a10058cdcd847f65","_cell_guid":"3a146558-6b7d-4bfc-b9cc-5c9d46e29049"},"cell_type":"markdown","source":"#### Observations\n* We have to deal with missing values\n* Most passengers are between 15 and 30 years of age\n* Most passengers between  15 and 30 years did not survive\n* Infants hav a high rate of survival\n\n#### Decision\n* keep Age for model training\n* clean Age column, replace missing values\n* perform binning on Age column"},{"metadata":{"_uuid":"552af9509d8739947132c4f6d9007adae8ceafc8","_cell_guid":"41a113de-a851-40a8-9027-dddbc5583caf"},"cell_type":"markdown","source":"### Pclass\n#### Analysis"},{"metadata":{"_uuid":"f68a5129c178c8e76d9980825e9627f2986ce79a","_cell_guid":"9a5afc23-440a-491c-9b08-20289cc14e17","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train['Pclass'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bdfcbdcfbbd308342d868680c78bdbc4fa7f7434","_cell_guid":"3eec8fc8-3497-4db0-a66e-46c479edabd1","trusted":false,"collapsed":true},"cell_type":"code","source":"pd.crosstab(df_train.Pclass, df_train.Survived, margins=True).style.background_gradient(cmap='summer_r')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7bdc9a1fe6ddeac26976d25ffa808608904c24a","_cell_guid":"533cb7aa-d4c6-4cf2-8fd5-c5c67468167d","trusted":false,"collapsed":true},"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize=(11,8))\ndf_train['Pclass'].value_counts().plot.bar(color=['#045FB4'], ax=ax[0])\nax[0].set_title('Number of passenger by Pclass')\nax[0].set_ylabel('Count')\nax[0]\nsns.countplot('Pclass', hue='Survived', data=df_train, ax=ax[1])\nax[1].set_title('Survived vs. Dead by Pclass')\n\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cbde322f3974a45bbb910af3aefa2119c66f8c86","_cell_guid":"646a58a0-4b43-40c4-b612-36ab70c68ec8"},"cell_type":"markdown","source":"* no missing values\n* most passengers traveled third class\n* only in the first class the number of survivors was greater than the number of dead\n* the survival rate for the third class was really low\n\n#### Decision\n* keep Pclass for model training, since it clearly had an effect on the likeliness to survive\n"},{"metadata":{"_uuid":"779da643d7b5171b5bffa64db92bb6d4b9fd3602","_cell_guid":"90622eb4-6e58-4d90-800c-c2274dd0a38b"},"cell_type":"markdown","source":"### Embarked\n#### Analysis"},{"metadata":{"_uuid":"891d9c594f2424aace66bab6443275062d47a854","_cell_guid":"b5cdc04a-cd6f-4c8a-a3a0-e8f50c0313e8","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train['Embarked'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"694239ca9d2253e575c663916381b45882a4b2d4","_cell_guid":"832b807f-b781-49a5-a253-3d25251a79e6","trusted":false,"collapsed":true},"cell_type":"code","source":"pd.crosstab(df_train.Embarked, df_train.Survived ,margins=True).style.background_gradient(cmap='summer_r')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c76e1934206eddfb71a456e131c8797c4869ba38","_cell_guid":"d502b66e-39fb-4318-bef5-a14815782f61","trusted":false,"collapsed":true},"cell_type":"code","source":"f, ax = plt.subplots(1, 2, figsize=(11,8))\ndf_train['Embarked'].value_counts().plot.bar(color=['#045FB4'], ax=ax[0])\nax[0].set_title('Number of passenger by Embarked')\nax[0].set_ylabel('Count')\nsns.countplot('Embarked', hue='Survived', data=df_train, ax=ax[1])\nax[1].set_title('Survived vs. Dead by Embarked')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd5c9cd19e9c5210b68b140b9aedae4d8f463c82","_cell_guid":"d55a14ff-edd1-4ab4-8b1d-193c51079184"},"cell_type":"markdown","source":"Looks like the location where passengers embarked the ship correlates with wether a passenger survived or not. Let's see, if it also correlates with the passenger class."},{"metadata":{"_uuid":"1bdc1c4436bce6cefd359c25ac1e9a17fece0886","_cell_guid":"ca5c1249-4d2d-4482-bccd-889412600b99","trusted":false,"collapsed":true},"cell_type":"code","source":"sns.countplot('Embarked', hue=\"Pclass\", data=df_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b982491db90764462387eb3eeb2f5eede27dfed","_cell_guid":"c91f495a-b741-4e7a-893a-3c7ed521265b"},"cell_type":"markdown","source":"#### Observations\n* only two missing values\n* very many passengers who embarked in location C perished\n\n#### Decision\n* keep Embarked column for model training\n* transform variable to a numberical\n* fill in missing values"},{"metadata":{"_uuid":"1b5e7ac8b23789cd750e1c64bb0901f636b07975","_cell_guid":"2fc273ca-0c9c-42fa-9305-3b4b20e97268"},"cell_type":"markdown","source":"### Sex\n#### Analysis"},{"metadata":{"_uuid":"287f212d5e387132cb0ce87b13712df875df79af","_cell_guid":"faa8a4b1-2eb1-4d8d-8902-eac1dad27b7b","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train['Sex'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab614fa8b87bfb37379688ef3c42e50640efe461","_cell_guid":"395be683-d9ae-4d58-886b-4a1029e0a0f5","trusted":false,"collapsed":true},"cell_type":"code","source":"pd.crosstab(df_train.Sex, df_train.Survived).style.background_gradient(cmap='summer_r')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d347ad7e244f343158846a26e5bc42b47a45966a","_cell_guid":"c2da7b4a-3043-4755-a222-7ed4f3807c71","trusted":false,"collapsed":true},"cell_type":"code","source":"sns.countplot('Sex', hue=\"Survived\", data=df_train);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a792d71000fbfffef0fd95708f156f3eb463959c","_cell_guid":"de172c47-fcd3-4ecb-851e-cd098e6fbe7f"},"cell_type":"markdown","source":"#### Observations\n* it can clearly be seen, that the survival rate among female passengers is much higher than for male passengers\n#### Decision\n* keep Sex for model training\n* transform to numerical"},{"metadata":{"_uuid":"4a3ffa47cd40af348bd4b530fb18b2e9cea9de2b","_cell_guid":"fe7339e0-6d1b-430d-8f52-3a2e3ac0549d"},"cell_type":"markdown","source":"### Fare\n#### Analysis"},{"metadata":{"_uuid":"2fda6240bb265d046cb2b87d7598a4152e5d0ffc","_cell_guid":"623f784c-18f9-40aa-8b28-f053915f8f21","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train['Fare'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a38f6fdab86c1b27158d7d2926996f6b54e6b3b0","_cell_guid":"ef6a52f4-71c5-4a30-b034-227a9b347f40","trusted":false,"collapsed":true},"cell_type":"code","source":"f, ax = plt.subplots(1, 3, figsize=(18,8))\nsns.distplot(df_train[df_train['Pclass'] == 1]['Fare'], kde=False, ax=ax[0])\nax[0].set_title('Fares in Pclass 1')\nsns.distplot(df_train[df_train['Pclass'] == 2]['Fare'], kde=False, ax=ax[1])\nax[1].set_title('Fares in Pclass 2')\nsns.distplot(df_train[df_train['Pclass'] == 3]['Fare'], kde=False, ax=ax[2])\nax[2].set_title('Fares in Pclass 3')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed04c5d8ba99066b6add4bb38b2e7f69584bb6c6","_cell_guid":"64083325-9667-4a01-94d7-fabac14f76d5"},"cell_type":"markdown","source":"#### Observations\n* Fares in Pclass increase for higher Pclass\n#### Decision\n* transform to discrete value using binning and decide later if it will be useful for model training"},{"metadata":{"_uuid":"b58bceea20a0914136ff7bd8b096b6a01938bc4b","_cell_guid":"98245528-cade-40e4-99a1-1be3f8e9ea13"},"cell_type":"markdown","source":"### SibSp\n#### Analysis"},{"metadata":{"_uuid":"e64628b34d1547d2d2b5b9b4094c1f3cd9f10183","_cell_guid":"f23d40d7-8110-4793-8c77-6589e2597b27","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train['SibSp'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b317e825c823374dd8e8488a8331acf9ebf62c3","_cell_guid":"831c937b-0007-4f4e-8f32-ac70f780176f","trusted":false,"collapsed":true},"cell_type":"code","source":"pd.crosstab(df_train.SibSp, df_train.Survived).style.background_gradient(cmap='summer_r')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56a67428106fd99486f3783cfddcef1053ec8e6f","_cell_guid":"ad332a7a-50e7-4361-915f-2cf17ae926e0","trusted":false,"collapsed":true},"cell_type":"code","source":"sns.barplot('SibSp', 'Survived', data = df_train, errwidth=0);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3f77f4d63cba3277f05e047ede8fcaf67f5bc50","_cell_guid":"e6556298-85fa-4b19-a949-772df5d1c277"},"cell_type":"markdown","source":"#### Observations\nAs the number of sibblings increases, the survival rate goes down. For families with 5-8 members the survival rate is 0."},{"metadata":{"_uuid":"ad30f9165f2bbff791fb02e2759a5282b20061ab","_cell_guid":"033455bc-471f-4251-b786-4528c33c6894"},"cell_type":"markdown","source":"### Parch\n#### Analysis"},{"metadata":{"_uuid":"34ef8635f4d9caf2cfec56aeb31d77bba7fc8d0a","_cell_guid":"80bdf022-5ba2-4625-b0ad-26304caa9acb","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train['Parch'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30bc78ba3db295199beccd26d716f55c18eadea6","_cell_guid":"88b62286-b27d-48dc-a105-65465d26411a","trusted":false,"collapsed":true},"cell_type":"code","source":"pd.crosstab(df_train.Parch, df_train.Survived).style.background_gradient(cmap='summer_r')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bf629450-d553-4d3c-be77-259f7f502571","scrolled":true,"_uuid":"d6813f42176c57c138ed8f99ff527c3cf0e7d02b","trusted":false,"collapsed":true},"cell_type":"code","source":"sns.barplot('Parch', 'Survived', data = df_train, errwidth=0);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6cc58db08117567ed1efa6493701ea645e1a1c97","_cell_guid":"150b4faf-06b6-4714-b270-3b6c69888048"},"cell_type":"markdown","source":"#### Observations\nIt seems like the chance to survive is higher if you had 1-3 parents/children on board.\n#### Decision\n* create a new feature \"family_size\" from Parch and SibSp and keep it for model training"},{"metadata":{"_uuid":"f703f65f2420845d2b84003b50b4ede88e5796fc","_cell_guid":"b84821bf-43d6-4197-ad80-62dce119b865"},"cell_type":"markdown","source":"# 3. Clean and Transform data"},{"metadata":{"_uuid":"fc17a5177ecbd8a7caa7e8fa4d45d90fd586bbc4","_cell_guid":"9805e40e-db99-4304-9729-e5766a49edcc"},"cell_type":"markdown","source":"The following features need to be edited and transformed:\n* Sex\n* Embarked\n* Age\n* Fare\n* Name\n* SibSp/Parch"},{"metadata":{"_uuid":"13e5fc19f5446e7cc0652a814090e7410497c2ac","collapsed":true,"_cell_guid":"613090bb-fee9-4b39-9dd8-2f320f2117f5","trusted":false},"cell_type":"code","source":"all_data = [df_train, df_test]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a70c180252a8d570acb29dc4e0eb5506e7d78593","_cell_guid":"19c79900-defe-4766-9f00-5c43754b0ab8"},"cell_type":"markdown","source":"The first two transformations ('Sex' and 'Embarked') we are going to make are pretty straightforward and simple. We just need to convert categorical features into numerical ones."},{"metadata":{"_uuid":"68c992255ddf3771c268d11787f9bda69cef83f5","_cell_guid":"c29ac79e-e252-4574-a0b6-35f5eca742d9"},"cell_type":"markdown","source":"#### Sex\nWe tranform this feature from categical to numerical."},{"metadata":{"_uuid":"3e416adb15dbb992ac444e8a31a48ca1a88e5660","_cell_guid":"f0e93ae2-ee9f-4ace-8f77-1ec5da122356","trusted":false,"collapsed":true},"cell_type":"code","source":"for dataset in all_data:\n    dataset['Sex'] = dataset['Sex'].map({'female': 1, 'male': 0}).astype(int)\n    \ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5cc64adb37257238ed1dc9728c4cc5ff5a8f539d","_cell_guid":"4aef9552-07a7-46a7-a12c-462b12bff1a4"},"cell_type":"markdown","source":"#### Embarked\nThe embarked column had two missing values. Since this number is very low, it seems to be ok to just remplace them with the most common occurance."},{"metadata":{"_uuid":"f57ba8f64148f0cbfa2475df8df87c746b742305","_cell_guid":"24c29c9e-159d-4bf6-bcca-f6f3606af4c9","trusted":false,"collapsed":true},"cell_type":"code","source":"most_freq_port = df_train.Embarked.dropna().mode()[0]\nmost_freq_port","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04c35e9de1de73ef3ea236d2a982e56ab2a82d36","_cell_guid":"45d9681a-132c-4c07-9576-509549feee25","trusted":false,"collapsed":true},"cell_type":"code","source":"for dataset in all_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna(most_freq_port)\n    \ndf_train['Embarked'].unique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"218565b02c95aaad6a0510a4b61f758782a5289d","_cell_guid":"7a8dac42-5972-4f0c-9dab-0bcda6998720","trusted":false,"collapsed":true},"cell_type":"code","source":"for dataset in all_data:\n    dataset['Embarked'] = dataset['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n    \ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"148903d889198c1210e6eb27c5da06d743abf1c3","_cell_guid":"7d824d95-270e-4187-896a-f6b00d0f5758"},"cell_type":"markdown","source":"The two continous features ('Age' and 'Fare') need to be transformed, too. In this case we use binning to convert them."},{"metadata":{"_uuid":"f7eb7f002dbe3a72695c1f924a167afc1558a8f0","_cell_guid":"d2776be8-5c8b-4bd0-aca9-ef6931f2a258"},"cell_type":"markdown","source":"#### Age\nFirst we need to complete the missing values for age. We will use the salutation of the name and fill in the mean for each group. We also take this opportunity and transform the 'Name' feature to something we can use for model training"},{"metadata":{"_uuid":"e78708f8982714b95b6f924e5c0fa67850175ac0","_cell_guid":"4189098f-bdc4-4b27-9a53-14a683fb2d93","trusted":false,"collapsed":true},"cell_type":"code","source":"for dataset in all_data:\n    dataset['Initial'] = dataset.Name.str.extract('([A-Za-z]+)\\.')\n    \npd.crosstab(df_train['Initial'], df_train['Sex']).T","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e704495a8360902034704f765232a2731b340998","collapsed":true,"_cell_guid":"085f36eb-1eac-4c76-a484-d3d5b198b812","trusted":false},"cell_type":"code","source":"for dataset in all_data:\n    dataset['Initial'] = dataset['Initial'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Dr. ', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Other')\n\n    dataset['Initial'] = dataset['Initial'].replace('Mlle', 'Miss')\n    dataset['Initial'] = dataset['Initial'].replace('Ms', 'Miss')\n    dataset['Initial'] = dataset['Initial'].replace('Mme', 'Mrs')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"833ece362f85012a0e77d7bcf6e4febc640e60a4","_cell_guid":"8fcc1b29-a061-4ee8-96c4-49a825aaec09","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train[['Initial', 'Survived']].groupby(['Initial'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4a5e4386fdd4a4c508a1f90c78f70210b470c4c","_cell_guid":"bd175b10-e34f-41b8-aedd-04a873c72560"},"cell_type":"markdown","source":"Looks like we created ourselves a nice feature from the name as well. There is still need for transformation into numerical but let's do this later."},{"metadata":{"_uuid":"0ec53bfd713e2b73c2b7649b635273b0d522d0cf","_cell_guid":"ab8c5098-244d-4adc-9e72-9ca07133eac2","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train.groupby('Initial')['Age'].mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"823e26376594443b625fee72b69c25d0b2946094","collapsed":true,"_cell_guid":"51cc6baa-b451-427e-af64-34e90c4604fb","trusted":false},"cell_type":"code","source":"for dataset in all_data:\n    dataset.loc[(dataset.Age.isnull())&(dataset.Initial=='Mr'),'Age']=33\n    dataset.loc[(dataset.Age.isnull())&(dataset.Initial=='Mrs'),'Age']=36\n    dataset.loc[(dataset.Age.isnull())&(dataset.Initial=='Master'),'Age']=5\n    dataset.loc[(dataset.Age.isnull())&(dataset.Initial=='Miss'),'Age']=22\n    dataset.loc[(dataset.Age.isnull())&(dataset.Initial=='Other'),'Age']=46","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f867f2fe1c0a53cd692f70671e11bac7514a103","_cell_guid":"0434a620-31df-4745-9144-bedf40128187","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train[df_train['Age'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"99d25435bd3f6d9424a5793a614d9dced1d7121e","_cell_guid":"f0e20af7-17fd-4fef-8f4b-10f60b0e277d"},"cell_type":"markdown","source":"I decided to group the data into 5 bins to minimize the risk of overfitting our model. After that we replace the Age with ordinals in both datasets."},{"metadata":{"_uuid":"38bec69eaad5e2648b92dbb646da378f7a5b2362","_cell_guid":"44286f69-2667-49d6-8755-0a4211fb3b0c","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train['AgeRange'] = pd.cut(df_train['Age'], 5)\ndf_train[['AgeRange', 'Survived']].groupby(['AgeRange'], as_index=False).mean().sort_values(by='AgeRange', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e748c1353c0e2102187e3adf901eccff525cea1","_cell_guid":"0f1df519-34dd-4b2b-97b2-d0b680a8804d","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train[['AgeRange', 'Survived']].groupby(['AgeRange'], as_index=False).count().sort_values(by='AgeRange', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94cc0e7c869f952c9a2efde5b7e51e282d816394","_cell_guid":"c42daa1f-b080-4b72-b69a-ee8d76444ccc"},"cell_type":"markdown","source":"As can be seen by the counts it wouldn't have made sense of we used more bins than 5 because some of them already have very few values."},{"metadata":{"_uuid":"d04fd037da9987969d32bb4a4a5093f411c875c7","collapsed":true,"_cell_guid":"d388ccfe-e10e-4ecc-bbc6-7730eacb252c","trusted":false},"cell_type":"code","source":"for dataset in all_data:\n    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[dataset['Age'] > 64, 'Age'] = 4\n    dataset['Age'] = dataset['Age'].astype(int)\n\ndf_train = all_data[0]\ndf_test = all_data[1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9b52a252efaea586d91b0550d20c3d545bd39a5","_cell_guid":"0cb6c7d4-d7dd-4815-b9bb-b001ab8f52cf"},"cell_type":"markdown","source":"The 'AgeRange' column can now be dropped, since it was only temporarily needed."},{"metadata":{"_uuid":"093873b65a46ed6526462d3a52b3dfcdd022d1c2","collapsed":true,"_cell_guid":"b19fb5ac-157a-40a0-8521-4b8c07882b66","trusted":false},"cell_type":"code","source":"df_train = df_train.drop(['AgeRange'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f233bc917d3e9399260f2bb21e755f87cc6d462e","_cell_guid":"064e792e-9963-4662-ad6f-a15c8104dc9f","trusted":false,"collapsed":true},"cell_type":"code","source":"all_data = [df_train, df_test]\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc010a682953fd04ba8d3782dd12f5cf8018b3a3","_cell_guid":"c60eac6a-08ef-4085-95ef-3d876b9b320a"},"cell_type":"markdown","source":"#### Fare\nWe will perform binning on the fare column as well. We don't have to deal with missing values here, so we can go straight to binning."},{"metadata":{"_uuid":"131334ab814a2fcc0de49b68b31d6474b748d59a","_cell_guid":"c28d7140-32ea-4740-a2cd-0cc94ef7ff48","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train['FareRange'] = pd.cut(df_train['Fare'], 4)\ndf_train[['FareRange', 'Survived']].groupby(['FareRange'], as_index=False).mean().sort_values(by='FareRange', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2f095221f0afe94b6e6c6f7b2a4f49822980a49","_cell_guid":"ca1398c6-e06c-4959-aee0-8cc2bd8c1c2d","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train[['FareRange', 'Survived']].groupby(['FareRange'], as_index=False).count().sort_values(by='FareRange', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a78a4906619317599a07876827f18e63543bd2f","_cell_guid":"91fe8a3a-5a8c-437a-bfc6-082cbefd0764","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51552f4081956f4196b84a5916fd1bb661261e00","collapsed":true,"_cell_guid":"0fe4e7aa-4773-4cbf-815d-64a42d8b7630","trusted":false},"cell_type":"code","source":"for dataset in all_data:\n    dataset.loc[dataset['Fare'] <= 128.082, 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 128.082) & (dataset['Fare'] <= 256.165), 'Fare'] = 2\n    dataset.loc[(dataset['Fare'] > 256.165) & (dataset['Fare'] <= 384.247), 'Fare'] = 3\n    dataset.loc[dataset['Fare'] > 384.247, 'Fare'] = 4\n    dataset['Fare'] = dataset['Fare'].fillna(0)\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ndf_train = all_data[0]\ndf_test = all_data[1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"48a7a046e4fa5261edaa7717efb405336ec9ab9c","_cell_guid":"eedf6a38-08f2-403e-ae8f-f6db7274bd30","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train = df_train.drop(['FareRange'], axis=1)\nall_data = [df_train, df_test]\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d44216956c8100cf581f3c3fded359b878947488","_cell_guid":"651f5e3c-32bf-4f4b-87d3-94e704c7552e"},"cell_type":"markdown","source":"#### Name\nAs we have seen before, we can extract the title of each passenger from the name. We already created a new column called 'Initial' for this dataset and saw, that the title gives some sort of indication if a passenger was more likely to survive or not. So we will use this instead for model training and drop the 'Name' column. Now we just have to convert the title to numerical values."},{"metadata":{"_uuid":"b4e74765d9a8254458bce753b780b905b504632a","_cell_guid":"727802aa-c333-4034-af56-c50833b04474","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train[['Initial', 'Survived']].groupby(['Initial'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76a5d5a0c8338862688e8a6c76784c1cbdb7e271","collapsed":true,"_cell_guid":"74b9c70d-c2cd-487a-a8ed-41161b6394e9","trusted":false},"cell_type":"code","source":"for dataset in all_data:\n    dataset['Initial'] = dataset['Initial'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dff20fe7d33a1b4cdf3f4f956c685a28757a484d","collapsed":true,"_cell_guid":"fedecb45-e2ca-4275-abcb-4da389adcb77","trusted":false},"cell_type":"code","source":"df_train['Initial'] = df_train['Initial'].replace(['Mr', 'Miss', 'Mrs', 'Master', 'Other'],[1, 2, 3, 4, 5]).astype(int)\ndf_test['Initial'] = df_test['Initial'].replace(['Mr', 'Miss', 'Mrs', 'Master', 'Other'],[1, 2, 3, 4, 5]).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"32c67ce32ca647672d4ab645349a6d6df0592374","_cell_guid":"99f21794-c179-4518-b7fd-a46f75288e6f","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"03d15059ebcac922659914f9edf3e95dacfec91c","_cell_guid":"36f19938-09dd-481b-9a38-3b84d519ad15"},"cell_type":"markdown","source":"Now we can drop the \"Name\" column."},{"metadata":{"_uuid":"0edb47a30d7cc0511858a833872be969374092b0","collapsed":true,"_cell_guid":"12769532-8dcd-4f46-92d5-96b4bef2e7fb","trusted":false},"cell_type":"code","source":"df_train = df_train.drop(['Name'], axis=1)\ndf_test = df_test.drop(['Name'], axis=1)\nall_data = [df_train, df_test]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9acd80fd52606e37e242e81c7de902ae2b775b72","_cell_guid":"e0b6949e-ab83-4848-9073-3818171df532"},"cell_type":"markdown","source":"#### SibSp/Parch\nWe will use these two features to calculate the familiy size and then create a feature which tells us if the person travelled alone or not. Later on, we will drop the features SipSp, Parch and FamiliySize."},{"metadata":{"_uuid":"d00004c2cf2317a282a51a7e6f4a5f7d5c439ef0","collapsed":true,"_cell_guid":"4904dc03-c585-4243-b717-2a1df5cae4d5","trusted":false},"cell_type":"code","source":"for dataset in all_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38d4b3850e69ef78a4a2e07eb3de213de65805ba","_cell_guid":"2d9d5760-ed5a-4730-a4b7-ac2c7bf4a55b","trusted":false,"collapsed":true},"cell_type":"code","source":"df_train = df_train.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ndf_test = df_test.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\nall_data = [df_train, df_test]\n\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad6757561660d7a6b9cc9d8473e8554a40b625eb","_cell_guid":"08e46de6-2f1f-4d93-b038-84fff44391f5"},"cell_type":"markdown","source":"# 4. Model Training"},{"metadata":{"_uuid":"47f9df63ae77bc36201e1b6cf060cc45515cedbb","collapsed":true,"_cell_guid":"08276216-5c2a-4c7f-913a-7af2c041b7d9","trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fef3a73dc75428cc36fa169518fe5573b7238519","_cell_guid":"1ee87d9d-c148-434c-9497-e08ef3e4654d"},"cell_type":"markdown","source":"I will use train_test_split on the training dataset, to get some indications how my algorithm performs. Bases on these results I will chose the algormithm for the final model."},{"metadata":{"_uuid":"f1f5267b194766372ea925c3583f023f9863c870","collapsed":true,"_cell_guid":"dc3e8560-d9eb-4b3f-b9e9-8a7cec57606f","trusted":false},"cell_type":"code","source":"train, test = train_test_split(df_train, test_size=0.3, stratify=df_train['Survived'])\nx_train = train.drop('Survived', axis=1)\ny_train = train['Survived']\nx_test = test.drop('Survived', axis=1)\ny_test = test['Survived']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"031ca86f43bb6297bc20792b9d647cdc624643c8","_cell_guid":"9fc5dfd9-f3ae-4c30-a51a-953f973bc27a","trusted":false,"collapsed":true},"cell_type":"code","source":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(x_train, y_train)\ny_pred_nb = gaussian.predict(x_test)\nprint(gaussian.score(x_train, y_train))\nprint('Accuracy score for Naive Bayes: ', accuracy_score(y_test, y_pred_nb))\nprint('Recall score for Naive Bayes: ', recall_score(y_test, y_pred_nb))\nprint('Precision score for Naive Bayes: ', precision_score(y_test, y_pred_nb))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c9e7e82757e5476cbe5d1ab2ffd4858414e94d9","collapsed":true,"_cell_guid":"04e4fc8d-6a7a-4699-8a95-23c5a2d33ad6","trusted":false},"cell_type":"code","source":"# Support Vector Machines\n\nsvc = SVC()\n\n# grid search for optimal parameters\nsvc_param_grid = {\n    'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n    'kernel': ['poly', 'linear', 'rbf', 'sigmoid'],\n    'degree': [2, 3, 4],\n    'gamma': [0.01, 0.1, 1.0],\n    'decision_function_shape': ['ovo', 'ovr'],\n    'coef0': [0.1, 0.2, 0.3, 0.4, 0.5]\n}\n\nsvc_clf = GridSearchCV(svc, param_grid = svc_param_grid, n_jobs=8)\n\nsvc_clf.fit(x_train, y_train)\nsvc_best = svc_clf.best_estimator_\nprint(svc_best)\n\ny_pred_svc = svc_clf.predict(x_test)\nprint(svc_clf.score(x_train, y_train))\nprint('Accuracy score for Support Vector Machines: ', accuracy_score(y_test, y_pred_svc))\nprint('Recall score for Support Vector Machines: ', recall_score(y_test, y_pred_svc))\nprint('Precision score for Support Vector Machines: ', precision_score(y_test, y_pred_svc))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c15df4dacbdda2a8ed7b5c102b866835da4e2aed","collapsed":true,"_cell_guid":"2481a252-593e-4162-bba5-1c18a0944603","trusted":false},"cell_type":"code","source":"# Random Forest\n\nforest = RandomForestClassifier()\n\n# grid search for optimal parameters\nforest_param_grid = {\n    'n_estimators': [5, 6, 7, 8, 9, 10], 'criterion': ['gini', 'entropy'], 'max_depth': [2, 3, 4, 5, 6, 7, 8], 'max_features': [2, 3, 4, 5, 6, 7], 'min_samples_split': [2, 3, 4, 5, 6, 7, 8]\n}\n\nforest_clf = GridSearchCV(forest, param_grid = forest_param_grid)\n\nforest_clf.fit(x_train, y_train)\nforest_best = forest_clf.best_estimator_\nprint(forest_best)\n\ny_pred_forest = forest_clf.predict(x_test)\nprint(forest_clf.score(x_train, y_train))\nprint('Accuracy score for Random Forest: ', accuracy_score(y_test, y_pred_forest))\nprint('Recall score for Random Forest: ', recall_score(y_test, y_pred_forest))\nprint('Precision score for Random Forest: ', precision_score(y_test, y_pred_forest))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b49675eba2c0b862693f4d377f4cee0920b8cc7f","collapsed":true,"_cell_guid":"488b0b46-0085-4cd0-8807-eaa9e59ae044","trusted":false},"cell_type":"code","source":"# Logistic Regression\n\nlogreg = LogisticRegression()\n\n# grid search for optimal parameters\nlogreg_param_grid = {\n    'tol': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n    'C': [1, 2, 3, 4, 5],\n}\n\nlogreg_clf = GridSearchCV(logreg, param_grid = logreg_param_grid)\n\nlogreg_clf.fit(x_train, y_train)\nlogreg_best = logreg_clf.best_estimator_\nprint(logreg_best)\n\ny_pred_logreg = logreg_clf.predict(x_test)\nprint(logreg_clf.score(x_train, y_train))\nprint('Accuracy score for Logistic Regression: ', accuracy_score(y_test, y_pred_logreg))\nprint('Recall score for Logistic Regression: ', recall_score(y_test, y_pred_logreg))\nprint('Precision score for Logistic Regression: ', precision_score(y_test, y_pred_logreg))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a33fcd2083b87ffbbada471d422b70811d0e9a6a","collapsed":true,"_cell_guid":"3f9e0f5d-f007-443a-bcf3-0d7109fba228","trusted":false},"cell_type":"code","source":"# Perceptron\n\nperceptron = Perceptron(max_iter=20)\n\n# grid search for optimal parameters\nperceptron_param_grid = {\n    'tol': [0.0001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n    'eta0': [1, 2, 3, 4, 5]\n}\n\nperceptron_clf = GridSearchCV(perceptron, param_grid = perceptron_param_grid)\n\nperceptron_clf.fit(x_train, y_train)\nperceptron_best = perceptron_clf.best_estimator_\nprint(perceptron_best)\n\ny_pred_perceptron = perceptron_clf.predict(x_test)\nprint(perceptron_clf.score(x_train, y_train))\nprint('Accuracy score for Perceptron: ', accuracy_score(y_test, y_pred_perceptron))\nprint('Recall score for Perceptron: ', recall_score(y_test, y_pred_perceptron))\nprint('Precision score for Perceptron: ', precision_score(y_test, y_pred_perceptron))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e0e420f6860c7b5f803aa3903b837fec9042ac97","collapsed":true,"_cell_guid":"ac83c9d9-1bc7-4397-9752-5d71a66ae5ea","trusted":false},"cell_type":"code","source":"# GradientBoostingClassifier\n\ngb = GradientBoostingClassifier()\n\n# grid search for optimal parameters\ngb_param_grid = {\n    'n_estimators': [77, 78, 79, 80, 81],\n    'max_depth': [2, 3, 4],\n    'min_samples_split': [2, 3, 4],\n    'criterion': ['friedman_mse', 'mse', 'mae'],\n    'max_features': [5, 6, 7]\n}\n\ngb_clf = GridSearchCV(gb, param_grid = gb_param_grid)\n\ngb_clf.fit(x_train, y_train)\ngb_best = gb_clf.best_estimator_\nprint(gb_best)\n\ny_pred_gb = gb_clf.predict(x_test)\nprint(gb_clf.score(x_train, y_train))\nprint('Accuracy score for Gradient Boosting: ', accuracy_score(y_test, y_pred_gb))\nprint('Recall score for Gradient Boosting: ', recall_score(y_test, y_pred_gb))\nprint('Precision score for Gradient Boosting: ', precision_score(y_test, y_pred_gb))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"feee41682ee1d477c31ee900827494f9af47b698","collapsed":true,"_cell_guid":"8b15f84e-341c-4205-ae99-814c2ca8e0aa","trusted":false},"cell_type":"code","source":"# Stochastic Gradient Descent\n\n#sgd = SGDClassifier(eta0=1, loss='hinge', max_iter=6, learning_rate='invscaling')\nsgd = SGDClassifier()\n\n# grid search for optimal parameters\nsgd_param_grid = {\n    'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n    'max_iter': list(range(1, 10, 1)),\n    'learning_rate': ['constant', 'optimal', 'invscaling'],\n    'eta0': list(range(1, 10, 1))\n}\n\nsgd_clf = GridSearchCV(sgd, param_grid = sgd_param_grid)\n\nsgd_clf.fit(x_train, y_train)\nsgd_best = sgd_clf.best_estimator_\nprint(sgd_best)\n\ny_pred_sgd = sgd_clf.predict(x_test)\nprint(sgd_clf.score(x_train, y_train))\nprint('Accuracy score for Stochastik Gradient Descent: ', accuracy_score(y_test, y_pred_sgd))\nprint('Recall score for Stochastik Gradient Descent: ', recall_score(y_test, y_pred_sgd))\nprint('Precision score for Stochastik Gradient Descent: ', precision_score(y_test, y_pred_sgd))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f312185235900466472694cd2581fb8c13984580","collapsed":true,"_cell_guid":"81ddb986-8870-4abc-821f-2b52c47c752c","trusted":false},"cell_type":"code","source":"# LinearSVC\n\n#linsvc = LinearSVC(loss='hinge')\nlinsvc = LinearSVC()\n\n# grid search for optimal parameters\nlinsvc_param_grid = {\n    'loss': ['hinge', 'squared_hinge'],\n    'tol': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0]\n}\n\nlinsvc_clf = GridSearchCV(linsvc, param_grid = linsvc_param_grid)\n\nlinsvc_clf.fit(x_train, y_train)\nlinsvc_best = linsvc_clf.best_estimator_\nprint(linsvc_best)\n\ny_pred_linsvc = linsvc_clf.predict(x_test)\nprint(linsvc_clf.score(x_train, y_train))\nprint('Accuracy score for LinearSVC: ', accuracy_score(y_test, y_pred_linsvc))\nprint('Recall score for LinearSVC: ', recall_score(y_test, y_pred_linsvc))\nprint('Precision score for LinearSVC: ', precision_score(y_test, y_pred_linsvc))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc2a8c5f2fcd362ff5254d39efea1d0c61f03498","collapsed":true,"_cell_guid":"d4b92f12-24e5-4237-bb6c-cda304fa9ed8","trusted":false},"cell_type":"code","source":"# Adaboost\n\nab = AdaBoostClassifier()\n\n# grid search for optimal parameters\nab_param_grid = {\n    'learning_rate': [0.02, 0.03, 0.04, 0.05, 0.06],\n    'n_estimators': list(range(100,1100,100))\n}\n\nab_clf = GridSearchCV(ab, param_grid = ab_param_grid)\n\nab_clf.fit(x_train, y_train)\nab_best = ab_clf.best_estimator_\nprint(ab_best)\n\ny_pred_ab = ab_clf.predict(x_test)\nprint(ab_clf.score(x_train, y_train))\nprint('Accuracy score for Adaboost: ', accuracy_score(y_test, y_pred_ab))\nprint('Recall score for Adaboost: ', recall_score(y_test, y_pred_ab))\nprint('Precision score for Adaboost: ', precision_score(y_test, y_pred_ab))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"642eb58c4c6941b710d0e6f0721f14397bc47b0b","_cell_guid":"7ab2e846-606a-4cf1-9603-1a301df79121"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"2e1a58b8a98976f5ea53f117133f37bca24da3e2","collapsed":true,"_cell_guid":"49aa0f71-6ae2-4d36-9138-8bd2a48a1d3d","trusted":false},"cell_type":"code","source":"x_train = df_train.drop('Survived', axis=1)\ny_train = df_train['Survived']\nx_test = df_test.drop('PassengerId', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e0f0165265a506a34c1f1fde1c90cc7e4e7cf09","collapsed":true,"_cell_guid":"c76a3d20-2f65-40fb-bc95-9e9f98ba35ac","trusted":false},"cell_type":"code","source":"logreg = LogisticRegression(tol=0.01)\n\nlogreg_param_grid = {\n    'tol': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0],\n    'C': [1, 2, 3, 4, 5],\n}\n\nlogreg_clf = GridSearchCV(logreg, param_grid = logreg_param_grid)\n\nlogreg_clf.fit(x_train, y_train)\nlogreg_best = logreg_clf.best_estimator_\nprint(logreg_best)\n\ny_pred_logreg = logreg_clf.predict(x_test)\nprint(logreg_clf.score(x_train, y_train))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bdb098358ed40f953a8e4f7647f9399cced5a4a3","collapsed":true,"_cell_guid":"6ddb9a6f-bc26-44fe-be70-eb8b24fa5e09","trusted":false},"cell_type":"code","source":"submission = pd.DataFrame({\n    'PassengerId': df_test['PassengerId'],\n    \"Survived\": y_pred_logreg\n})\n#submission.to_csv('firstsubmission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"pygments_lexer":"ipython3","version":"3.6.4","codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py","nbconvert_exporter":"python","mimetype":"text/x-python","name":"python"}},"nbformat":4,"nbformat_minor":1}