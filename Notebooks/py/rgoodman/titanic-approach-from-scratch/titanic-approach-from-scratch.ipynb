{"nbformat": 4, "metadata": {"_change_revision": 0, "_is_fork": false, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"name": "python", "file_extension": ".py", "mimetype": "text/x-python", "version": "3.6.1", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python"}}, "nbformat_minor": 0, "cells": [{"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "3e4efee1-ed31-4437-0271-d8e798f9acff", "trusted": false, "_uuid": "61ef66e2ebd4f20efbae5893e44e5f5358b090fc"}, "source": ["import numpy as np\n", "import pandas as pd\n", "\n", "import matplotlib.pyplot as plt\n", "\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn import datasets, linear_model\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.naive_bayes import GaussianNB\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "e1101151-74db-c099-013f-43c8a5f50685", "trusted": false, "_uuid": "a522d89418ae2eb706e5926149e4ebbbb50dcfab"}, "source": "global test_df\nglobal train\n\ntrain = pd.DataFrame.from_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "c0266980-980a-736a-767f-2a6447054fc3", "trusted": false, "_uuid": "bb7868c1fb5067e4319a4d8e51d730110ed9fbfe"}, "source": "def theview(train):\n    for i in train:\n        print ('\\n' + i + ': ' + str(train[i].isnull().sum()) + ' nulls')\n        print(str(len(train[i].unique())) + ' uniques' )\n        #print(str(len(train[i].unique()))\n        if len(train[i].unique()) <10:\n            print (train[i].unique())\n    print ('\\n' + str(train.shape))", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "e06a32d1-0e4f-b95e-cfe3-564e527435c8", "trusted": false, "_uuid": "863186906a871749fd2ef4fae97f934b06777e0c"}, "source": "#Cleanup\n\n#Cabin\n\ntrain = pd.concat( [train , pd.get_dummies(train['Cabin'].str[:1],dummy_na=False)] , axis=1)\ntest_df = pd.concat( [test_df , pd.get_dummies(test_df['Cabin'].str[:1],dummy_na=False)] , axis=1)\n\nfor i in train.columns:\n    if len(str(i))<2:\n        train.rename(columns={i: 'Cabin_'+i}, inplace=True)\nfor i in test_df.columns:\n    if len(str(i))<2:\n        test_df.rename(columns={i: 'Cabin_'+i}, inplace=True)   \n\n'''\ndef age_impute(train, test_df):\n    for i in [train, test_df]:\n        i['Age_Null_Flag'] = i['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n        data = train.groupby(['Pclass'])['Age']\n        i['Age'] = data.transform(lambda x: x.fillna(x.mean()))\n    return train, test_df\n\ntrain, test_df = age_impute(train, test_df)        \n'''\n\n#Deleting Cabin_T since doesn't exist in test.csv\ndel train['Cabin_T']        \n\n\n###Name Adjustments\n\ndef names(train, test_df):\n    for i in [train, test_df]:\n        i['Name_Len'] = i['Name'].apply(lambda x: len(x))\n        i['Name_Title'] = i['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\n        del i['Name']\n    return train, test_df\n\ntrain, test_df = names(train, test_df)\ntrain = pd.concat( [train , pd.get_dummies(train['Name_Title'])] , axis=1)\ntest_df = pd.concat( [test_df, pd.get_dummies(test_df['Name_Title'])] , axis=1)\n\n\n\nfor i in train.columns[1:].tolist():\n    if i not in test_df.columns[0:].tolist():\n        print(i)\n        del train[i]\n\ndel test_df['Dona.']\n\n\n\n#Embarked\ntrain = pd.concat( [train , pd.get_dummies(train['Embarked'])] , axis=1)\ntest_df = pd.concat( [test_df, pd.get_dummies(test_df['Embarked'])] , axis=1)\n\nfor i in train.columns:\n    if len(str(i))<2:\n        train.rename(columns={i: 'Embarked_'+i}, inplace=True)\nfor i in test_df.columns:\n    if len(str(i))<2:\n        test_df.rename(columns={i: 'Embarked_'+i}, inplace=True)      \n        \ntrain = pd.concat( [train , pd.get_dummies(train['Pclass'])] , axis=1)\ntest_df = pd.concat( [test_df, pd.get_dummies(test_df['Pclass'])] , axis=1)\n\n\nfor i in train.columns:\n    if len(str(i))<2:\n        train.rename(columns={i: 'Class_'+str(i)}, inplace=True)\nfor i in test_df.columns:\n    if len(str(i))<2:\n        test_df.rename(columns={i: 'Class_'+str(i)}, inplace=True)  \n\ntrain.replace('male', 1,inplace=True)\ntrain.replace('female', 0,inplace=True)\n#train['Sex'] = train.where(train['Sex']=='male',1,0)\n\n#train = train.drop(['Cabin','Embarked','Name','Ticket'], axis=1)\n#test_df = test_df.drop(['Cabin','Embarked','Name','Ticket'], axis=1)\n\ntrain = train.drop(['Cabin','Embarked','Ticket'], axis=1)\ntest_df = test_df.drop(['Cabin','Embarked','Ticket'], axis=1)\n\n#could fill ages instead of drop\n#train.dropna(subset = ['Age'],inplace=True)\n#simply pluggin with mean\n\n\n\ntest_df['Age'].fillna(test_df['Age'].mean(),inplace=True)\ntrain['Age'].fillna(train['Age'].mean(),inplace=True)\n\ntrain['Sex'] = train['Sex'].astype(int)\n\ndel train['Pclass']\ndel test_df['Pclass']\ndel train['Name_Title']\ndel test_df['Name_Title']", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "c8db4e46-07be-aff1-0e87-d7e29a01476e", "trusted": false, "_uuid": "a1e349d08be58591f84ba0caa3e2577980f03452"}, "source": "train['Age']", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "507ab1bb-7f71-e5a7-b2d4-2ec707d4f5ae", "trusted": false, "_uuid": "8d4e84ff4ef74f5d600f66f1104ad061bda519ea"}, "source": "#Still need to replacena for the 86 null ages and 1 null fare\ntest_df['Fare'].fillna(test_df['Fare'].mean(),inplace=True)\n\n\n#still need to convert male/female to 1/0\ntest_df.replace('male', 1,inplace=True)\ntest_df.replace('female', 0,inplace=True)\ntest_df['Sex'] = test_df['Sex'].astype(int)\ntest_df.set_index('PassengerId',inplace=True)", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "77e7067b-8734-9e56-b3fb-58dd6ab8d2f7", "trusted": false, "_uuid": "474c07e9f7caea325e235b62e596e0709ebeea10"}, "source": "bins = [0, 10,20,30,40,50,60,120]\ngroup_names = ['age0','age1','age2','age3','age4','age5','age6']\ntrain['AgeBin'] = pd.cut(train['Age'], bins, labels=group_names)\ntest_df['AgeBin'] = pd.cut(test_df['Age'], bins, labels=group_names)\n\ntrain = pd.concat( [train , pd.get_dummies(train['AgeBin'])] , axis=1)\ntest_df = pd.concat( [test_df, pd.get_dummies(test_df['AgeBin'])] , axis=1)\n\ndel train['Age']\ndel test_df['Age']\ndel train['AgeBin']\ndel test_df['AgeBin']\n\ntrain = train.drop(['Embarked_C','Embarked_Q','Embarked_S'], axis=1)\ntest_df = test_df.drop(['Embarked_C','Embarked_Q','Embarked_S'], axis=1)\n\n", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "6d3cecae-2ef6-28dc-bb93-f3ddc3119ca9", "trusted": false, "_uuid": "2bb5b44e85ea57d8addfe0785f57759b63e972ca"}, "source": "#Drop male feature when age <10\ntrain['Sex'] = np.where(train['age0']==1, 0, train['Sex'])\ntrain.where(train['age0']==1).dropna().head(5)", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "f73a1da0-78c4-464e-5bb5-e4552f8af2fb", "trusted": false, "_uuid": "725262762b0ad067e439314b3bd935f1179c99a3"}, "source": "for i in [train, test_df]:\n    i['Fam_Size'] = np.where((i['SibSp']+i['Parch']) == 0 , 'Solo', \\\n        np.where((i['SibSp']+i['Parch']) <= 3,'Nuclear', 'Big'))\n    \ntrain = pd.concat( [train , pd.get_dummies(train['Fam_Size'])] , axis=1)\ntest_df = pd.concat( [test_df, pd.get_dummies(test_df['Fam_Size'])] , axis=1)    \n\ndel train['Parch']\ndel test_df['Parch']\ndel train['SibSp']\ndel test_df['SibSp']\ndel train['Fam_Size']\ndel test_df['Fam_Size']\n", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "4f021005-1b46-8500-a359-b38a9edf0240", "trusted": false, "_uuid": "9c5a16697bc89016cce9fe48f0858ba31f958c0d"}, "source": "splittrain, splittest = train_test_split(train, test_size = 0.2,random_state=0)", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "c688684c-6334-7352-25e9-1977b68d14fe", "trusted": false, "_uuid": "4207fc462f10527a7590ed68f9f94d55b6977cf6"}, "source": "#for i in train.columns:\n#    print(i + ' ' + str(train[i].dtype))\n#print ('\\n'+'\\n')\n#for i in test_df.columns:\n#    print(i + ' ' + str(test_df[i].dtype))", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "6ebf135f-db47-0099-3d98-efe5d2b5a6cd", "trusted": false, "_uuid": "3940ab19213949625c205ae648a72e47d2ce061d"}, "source": "#For testing\nXsplittrain = splittrain.drop('Survived', 1)\nYsplittrain = splittrain['Survived']\n\nXsplittest = splittest.drop('Survived', 1)\nYsplittest = splittest['Survived']\n\n#For fitting all the data\nXtrain = train.drop('Survived', 1)\nYtrain = train['Survived']", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "5172417c-4961-20ba-4789-530cfded5f4b", "trusted": false, "_uuid": "8696ea1661bf93278c39cfac8fc1397419becfec"}, "source": "regr = linear_model.LinearRegression()\nrandom_forest = RandomForestClassifier(n_estimators=100)\ngaussian = GaussianNB()\nlogreg = linear_model.LogisticRegression()\n\nregr.fit(Xsplittrain, Ysplittrain)\nrandom_forest.fit(Xsplittrain, Ysplittrain)\ngaussian.fit(Xsplittrain, Ysplittrain)\nlogreg.fit(Xsplittrain, Ysplittrain)\n#", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "726dc284-9360-fdce-352d-6a686fff43ca", "trusted": false, "_uuid": "3afe3a192ae166968406323530111a9058455496"}, "source": "rf = RandomForestClassifier(criterion='gini', \n                             n_estimators=700,\n                             min_samples_split=10,\n                             min_samples_leaf=1,\n                             max_features='auto',\n                             oob_score=True,\n                             random_state=1,\n                             n_jobs=-1)\nrf.fit(Xsplittrain, Ysplittrain)", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "5c046584-25de-177a-08b0-96cc475ffaee", "trusted": false, "_uuid": "bec866e7ff200c43d4e7f52d6dd6bc4a61bb47f5"}, "source": "def runscore(x):\n    print('Test Score: ' + str(x.score(Xsplittest, Ysplittest)))\n    #print('\\n')\n    print('Train Score: ' + str(x.score(Xsplittrain, Ysplittrain)))", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "a7061983-6101-5697-0781-0d4f4acd1c9d", "trusted": false, "_uuid": "af00f904ee37c59d62f85d2280599bad6ece2b8c"}, "source": "print('RandomForest')\nrunscore(random_forest)\nprint('\\nLogistic')\nrunscore(logreg)\nprint('\\nLinear')\nrunscore(regr)\nprint('\\nGaussian')\nrunscore(gaussian)\nprint('\\nRF')\nrunscore(rf)", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "62f5496f-b50e-9fe8-b5d3-7261ba5dfa76", "trusted": false, "_uuid": "cb8ff68397e8f8ca9dad745314fb88bc8573093f"}, "source": "#for i in range(10,40):\n#    print(i)\n#    random_forest = RandomForestClassifier(n_estimators=i)\n#    random_forest.fit(Xsplittrain, Ysplittrain)\n#    runscore(random_forest)   ", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "25093a8e-5288-7b80-26e1-b0681823ee08", "trusted": false, "_uuid": "c8bd54b77d11adad9d4de7a0d3e597eddd5a74ac"}, "source": "# get Correlation Coefficient for each feature using Logistic Regression\ncoeff_df = pd.DataFrame(train.columns.delete(0))\ncoeff_df.columns = ['Features']\ncoeff_df[\"Coefficient Estimate\"] = pd.Series(logreg.coef_[0])\n\n# preview\ncoeff_df", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "9be59074-1615-4844-5ea3-44f3c30a2504", "trusted": false, "_uuid": "19d4b818022370a7bd20653be08d0eb3706e6678"}, "source": "plt.matshow(train.corr())", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "162c948c-5176-ebac-72cf-5a76849cdcd6", "trusted": false, "_uuid": "6cde8c80de11777198c92b7d3adbf1bd73205a43"}, "source": "train.corr()", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "108df438-5b8f-0db8-3766-9506b2abb827", "trusted": false, "_uuid": "b928652c12407d2053d017cb106b55cec3693bcd"}, "source": "logreg.fit(Xtrain, Ytrain)\nrf.fit(Xtrain, Ytrain)", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "dc717004-9015-aed5-5534-1f620a26bcda", "trusted": false, "_uuid": "78a1f69eca7e768731df02838eb86ef27cc94307"}, "source": "submission = pd.DataFrame({\n        \"PassengerId\": test_df.index,\n        \"Survived\": rf.predict(test_df)\n    })\n\nsubmission.to_csv('submissionFLYHI.csv', index=False)", "execution_count": null}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "b569ac08-a7b4-096a-cade-20dc44d4d1e6", "trusted": false, "_uuid": "899fe143c49a703036d3582ee018ceee9b7b5b7f"}, "source": "", "execution_count": null}]}