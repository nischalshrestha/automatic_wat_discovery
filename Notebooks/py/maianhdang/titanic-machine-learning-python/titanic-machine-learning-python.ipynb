{"nbformat": 4, "nbformat_minor": 1, "cells": [{"outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "metadata": {"_cell_guid": "37965d7a-a4d6-4730-9125-e9339961e041", "_uuid": "501dd06eac39afbab12894aab7dc99f94c47f54f"}, "execution_count": null, "cell_type": "code"}, {"outputs": [], "source": ["test = pd.read_csv('../input/test.csv')\n", "train = pd.read_csv('../input/train.csv')"], "metadata": {"_cell_guid": "a6d2dd57-8e2f-47c4-a2d6-8855e507ddb2", "_uuid": "eb4a0ba87d91c2c22b6369c20f71d4c721878c76", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"outputs": [], "source": ["test.head()"], "metadata": {"_cell_guid": "c9d1e51a-ac32-48bb-ab6d-d562ddf51fb6", "_uuid": "30e384b4b5ed27e39438a7476032722ed5f18383"}, "execution_count": null, "cell_type": "code"}, {"outputs": [], "source": ["train.head()"], "metadata": {"_cell_guid": "d019d8c1-5305-41ed-80ac-18abfe082137", "_uuid": "676febcf93b647d6b78a1851cacd3e5482311a6d"}, "execution_count": null, "cell_type": "code"}, {"source": ["# **2. Exploring Data**"], "metadata": {"_cell_guid": "b06b84cc-94c5-43e0-aaf6-4a2b170528a5", "_uuid": "5b341b3057c695d49ff3208e45822d89745d4d5a"}, "cell_type": "markdown"}, {"outputs": [], "source": ["print(test.describe()) # test set\n", "print(test.shape)"], "metadata": {"_cell_guid": "79b15195-c040-4ce7-80cc-b0b5b34ca429", "_uuid": "e33e585bc459ead7e6aaf3a58a6171cb3c78d93f"}, "execution_count": null, "cell_type": "code"}, {"outputs": [], "source": ["print(train.describe())\n", "print(train.shape)"], "metadata": {"_cell_guid": "c49a14a9-ea99-4d5d-9174-5b28ddeee5ab", "_uuid": "2c7347c22b21734ca0582a032ae8fecc7ca324d2"}, "execution_count": null, "cell_type": "code"}, {"source": ["## **2.1. Survival Rate by Gender**"], "metadata": {"_cell_guid": "ef0e7943-4d2a-4ff5-9613-eb5bb8ea4647", "_uuid": "0eb9ab41654a54e079656960f6061d4b88a0c27d"}, "cell_type": "markdown"}, {"outputs": [], "source": ["# Passengers that survived vs passengers that passed away\n", "print(train['Survived'].value_counts())\n", "\n", "# As proportions\n", "print(train['Survived'].value_counts(normalize=True))\n", "\n", "# Males that survived vs males that passed away\n", "print(train['Survived'][train['Sex'] == 'male'].value_counts())\n", "\n", "# Females that survived vs Females that passed away\n", "print(train['Survived'][train['Sex'] == 'female'].value_counts())\n", "\n", "# Normalized male survival\n", "print(train['Survived'][train['Sex'] == 'male'].value_counts(normalize=True))\n", "\n", "# Normalized female survival\n", "print(train['Survived'][train['Sex'] == 'female'].value_counts(normalize=True))"], "metadata": {"_cell_guid": "4bf72326-546a-4110-9d55-d7543a155ea2", "_uuid": "f61afe088ec5a2f065ccc4ef4a818c46a02072c2"}, "execution_count": null, "cell_type": "code"}, {"source": ["## **2.2. Survival by Age**"], "metadata": {"_cell_guid": "f4d8fe73-bad2-4f65-944a-8aedea4aea43", "_uuid": "0d3bf8b327d4b4b9626e9c190dc1b6df97f1fada"}, "cell_type": "markdown"}, {"outputs": [], "source": ["# Create the column Child and assign to 'NaN'\n", "train[\"Child\"] = float('NaN')\n", "\n", "# Assign 1 to passengers under 18, 0 to those 18 or older. Print the new column.\n", "train['Child'][train['Age'] < 18] = 1\n", "train['Child'][train['Age'] >= 18] = 0\n", "\n", "# Print normalized Survival Rates for passengers under 18\n", "print(train[\"Survived\"][train[\"Child\"] == 1].value_counts(normalize = True))\n", "\n", "# # Print normalized Survival Rates for passengers 18 or older\n", "print(train['Survived'][train['Child'] == 0].value_counts(normalize = True))"], "metadata": {"_cell_guid": "56e603d7-55d3-48ec-a167-a1fe1995bdaf", "_uuid": "aa43d152e9cf867de45c1ca8032ac740e65d02b8"}, "execution_count": null, "cell_type": "code"}, {"source": ["# **3. Naive Prediction: Females survive vs. Males die**"], "metadata": {"_cell_guid": "c2304e68-1e04-420a-b265-4eb4107e9e69", "_uuid": "5210c810a959b11f752c3a3dffc7d20d50be227e"}, "cell_type": "markdown"}, {"source": ["**Comment:** The pass away is majority. By the majority rules, the naive prediction is always saying \"pass away\". When we take a look on Gender, females have more than 50% of survive (74.20%) when males have less than 50% (18.89%). \n", "It motivates us to always predict \"survived\" for females, and \"die\" for males (as in the sample result).\n", "\n", "**The idea is find the subset with high survival rate. **"], "metadata": {"_cell_guid": "70fc0503-c6a4-427b-a2f4-b58a90f371bc", "_uuid": "5052fdc3ff5a3a6564f886c3f9f196ebf2f7fd64"}, "cell_type": "markdown"}, {"outputs": [], "source": ["# Create a copy of test: test_one\n", "test_one = test\n", "\n", "# Initialize a Survived column to 0\n", "test_one['Survived'] = 0\n", "\n", "# Set Survived to 1 if Sex equals \"female\" and print the `Survived` column from `test_one`\n", "test_one['Survived'][test_one['Sex'] == 'female'] = 1\n", "\n", "test_one['Survived'].head()"], "metadata": {"_cell_guid": "3e229156-8f48-43e3-8b03-c5d8e970c72a", "_uuid": "a20cb556e8a6b32d1592291ad5801693d7938190"}, "execution_count": null, "cell_type": "code"}, {"source": ["# **4. Decision Tree Preduction **"], "metadata": {"_cell_guid": "7c73e23b-82ff-42d1-b065-6a922e2d8eed", "_uuid": "3c40299538295c3d793cca9c4842c9b6636d6ddf"}, "cell_type": "markdown"}, {"source": ["Conceptually, the decision tree algorithm starts with all the data at the root node and scans all the variables for the best one to split on. Once a variable is chosen, you do the split and go down one level (or one node) and repeat. The final nodes at the bottom of the decision tree are known as terminal nodes, and the majority vote of the observations in that node determine how to predict for new observations that end up in that terminal node."], "metadata": {"_cell_guid": "e1b2baea-583f-4ac2-bcee-321d60916d1a", "_uuid": "bfbe5cbd613cbb203ccb003fe46b83601c17ef67"}, "cell_type": "markdown"}, {"outputs": [], "source": ["# Import the Numpy library\n", "import numpy as np\n", "# Import 'tree' from scikit-learn library\n", "from sklearn import tree"], "metadata": {"_cell_guid": "4f576921-2ba9-4394-a0ca-2d159c3fe27f", "_uuid": "0b1726839c72eeaabe87d027712aea1152eb2086", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["### **4.1. Cleaning and Formatting Data**\n", "* Missing values should be imputed (by median or majority)\n", "* Categorical Variables should be numeric"], "metadata": {"_cell_guid": "abd7ad33-2aab-438d-a65e-aac6b8ccebf7", "_uuid": "06fcec966f39d7a7940ad4625ece2638240ac073"}, "cell_type": "markdown"}, {"outputs": [], "source": ["print(train['Sex'].describe())\n", "print(train['Embarked'].describe())\n", "print(train['Embarked'].unique())"], "metadata": {"_cell_guid": "fca25d03-d753-447f-bb2c-ce8662253314", "_uuid": "85fa3589bf9aa7aeca71597ce8395fb9dace222e"}, "execution_count": null, "cell_type": "code"}, {"outputs": [], "source": ["train.columns"], "metadata": {"_cell_guid": "62787f37-b123-41da-8efa-9375be4b40a5", "_uuid": "da823897e0085bf0200605bb621044ec63e4f59c"}, "execution_count": null, "cell_type": "code"}, {"outputs": [], "source": ["train['Age'].unique()"], "metadata": {"_cell_guid": "83a89c1a-a24e-453b-b41e-45b904328108", "_uuid": "26290b23cca736a444989953925ef8b2bd9a8a6d"}, "execution_count": null, "cell_type": "code"}, {"outputs": [], "source": ["# Convert the male and female groups to integer form\n", "train[\"Sex\"][train[\"Sex\"] == \"male\"] = 0\n", "train[\"Sex\"][train[\"Sex\"] == \"female\"] = 1\n", "\n", "# Impute the Embarked variable\n", "train[\"Embarked\"] = train['Embarked'].fillna(\"S\")\n", "train['Age'] = train['Age'].fillna(train['Age'].median())\n", "\n", "# Convert the Embarked classes to integer form\n", "train[\"Embarked\"][train[\"Embarked\"] == \"S\"] = 0\n", "train[\"Embarked\"][train[\"Embarked\"] == \"C\"] = 1\n", "train[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2\n", "\n", "print(train['Sex'].head(5))\n", "print(train['Embarked'].head(5))"], "metadata": {"_cell_guid": "31767585-80fb-4051-b09f-5e39badda5e1", "_uuid": "ab4e35f816cd3585e2d1187a4bef2b3d5d99a1a0"}, "execution_count": null, "cell_type": "code"}, {"source": ["### **4.2. First Decision Tree**\n", "1. Create `my_tree_one` as `DecisiontreeClassifier` object\n", "2. `fit` method on `DecisiontreeClassifier` taking `np.array` as input\n", "3. Request attribute `feature_importances_` to see the weigh by importances for each included features\n", "4. Compute **mean accuracy** by calling the method score"], "metadata": {"_cell_guid": "43dc4c2f-8049-49dd-9d33-da16b336e22a", "_uuid": "475be15a29052895930a7a7a8396df79f4fe8aad"}, "cell_type": "markdown"}, {"outputs": [], "source": ["# Create the target and features numpy arrays: target, features_one\n", "target = train[\"Survived\"].values\n", "features_one = train[[\"Pclass\", \"Sex\", \"Age\", \"Fare\"]].values\n", "\n", "# Fit your first decision tree: my_tree_one\n", "my_tree_one = tree.DecisionTreeClassifier()\n", "my_tree_one = my_tree_one.fit(features_one, target)\n", "\n", "# Look at the importance and score of the included features\n", "print(my_tree_one.feature_importances_)\n", "print(my_tree_one.score(features_one, target))"], "metadata": {"_cell_guid": "3dd3060e-77b2-4683-8114-8461e9dc8fb9", "_uuid": "274e17efc2172186a8e486cdd63ae4e1866ba003"}, "execution_count": null, "cell_type": "code"}, {"source": ["** Comment:** The `Fare` is the most important feature"], "metadata": {"_cell_guid": "0fe0933a-8534-43ed-bfa0-c5eaa3a4c922", "_uuid": "3ba41dec3d241a0faef4d5c12d8716f0523cc2bc"}, "cell_type": "markdown"}, {"source": ["### **4.3. Prediction**"], "metadata": {"_cell_guid": "1bc8d72b-3304-4843-b476-19dbed4fb89a", "_uuid": "b2ce4588a3814d6dc3f3becde9d9044914a7a1a9"}, "cell_type": "markdown"}, {"outputs": [], "source": ["# on the test set, also manipulate nan values\n", "test['Fare'] = test['Fare'].fillna(test['Fare'].median())\n", "test['Age'] = test['Age'].fillna(test['Age'].median())\n", "\n", "# categorical var into numeric\n", "test['Sex'][test['Sex'] == 'male'] = 0\n", "test['Sex'][test['Sex'] == 'female'] = 1"], "metadata": {"_cell_guid": "c802bcf5-cb7f-450b-a85c-1ee46fe6d1fb", "_uuid": "cbd9597569b5733e9268cd96bc399ab06948c90a"}, "execution_count": null, "cell_type": "code"}, {"outputs": [], "source": ["# Extract the features from the test set: Pclass, Sex, Age, and Fare (to numpy.array)\n", "test_features = test[['Pclass', 'Sex', 'Age', 'Fare']].values\n", "\n", "# Make your prediction using the test set\n", "my_prediction = my_tree_one.predict(test_features)\n", "\n", "# Create a data frame with two columns: PassengerId & Survived. Survived contains your predictions\n", "PassengerId =np.array(test[\"PassengerId\"]).astype(int)\n", "my_solution = pd.DataFrame(my_prediction, PassengerId, columns = [\"Survived\"])\n", "print(my_solution)\n", "\n", "# Check that your data frame has 418 entries\n", "print(my_solution.shape)\n", "\n", "# Write your solution to a csv file with the name my_solution.csv\n", "my_solution.to_csv(\"solution_1.csv\", index_label = [\"PassengerId\"])"], "metadata": {"_cell_guid": "040c1338-085e-4642-a6a3-4ff371feccfa", "_kg_hide-output": true, "_uuid": "9779ccd2f60cadd842bba50c40308752622f1400"}, "execution_count": null, "cell_type": "code"}, {"source": ["### **4.4. Control Overfitting**\n", "\n", "The default decision tree set `max_depth` and `min_samples_split` as none, which is not good. Because more complex model means more overfitting. Thus, the above model performs worse than the naive model in gender"], "metadata": {}, "cell_type": "markdown"}, {"outputs": [], "source": ["# Create a new array with the added features: features_two\n", "features_two = train[[\"Pclass\",\"Age\",\"Sex\",\"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n", "\n", "#Control overfitting by setting \"max_depth\" to 10 and \"min_samples_split\" to 5 : my_tree_two\n", "max_depth = 10\n", "min_samples_split = 5\n", "my_tree_two = tree.DecisionTreeClassifier(max_depth = max_depth, min_samples_split = min_samples_split, random_state = 1)\n", "my_tree_two = my_tree_two.fit(features_two, target)\n", "\n", "#Print the score of the new decison tree\n", "print(my_tree_two.score(features_two, target))"], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"outputs": [], "source": ["# Convert the Embarked classes to integer form\n", "test[\"Embarked\"][test[\"Embarked\"] == \"S\"] = 0\n", "test[\"Embarked\"][test[\"Embarked\"] == \"C\"] = 1\n", "test[\"Embarked\"][test[\"Embarked\"] == \"Q\"] = 2"], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"outputs": [], "source": ["# Extract the features from the test set: Pclass, Sex, Age, and Fare (to numpy.array)\n", "test_features_two = test[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n", "\n", "# Make your prediction using the test set\n", "my_prediction_two = my_tree_two.predict(test_features_two)\n", "\n", "# Create a data frame with two columns: PassengerId & Survived. Survived contains your predictions\n", "PassengerId = np.array(test[\"PassengerId\"]).astype(int)\n", "my_solution_two = pd.DataFrame(my_prediction_two, PassengerId, columns=[\"Survived\"])\n", "print(my_solution)\n", "\n", "# Check that your data frame has 418 entries\n", "print(my_solution.shape)"], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["### **4.5. Feature-enginerring**\n", "Creatively engineering your own features by combining the different existing variables"], "metadata": {}, "cell_type": "markdown"}, {"outputs": [], "source": ["train_two = train.copy()\n", "train_two[\"family_size\"] = train_two['SibSp'] + train_two['Parch'] + 1\n", "\n", "# Create a new feature set and add the new feature\n", "features_three = train_two[[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"SibSp\", \"Parch\", \"family_size\"]].values\n", "\n", "# Define the tree classifier, then fit the model\n", "my_tree_three = tree.DecisionTreeClassifier()\n", "my_tree_three = my_tree_three.fit(features_three, target)\n", "\n", "# Print the score of this decision tree\n", "print(my_tree_three.score(features_three, target))"], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["# **5. Random Forecast**\n", "The Random Forest technique handles the overfitting problem you faced with decision trees. It grows multiple (very deep) classification trees using the training set. At the time of prediction, each tree is used to come up with a prediction and every outcome is counted as a vote. For example, if you have trained 3 trees with 2 saying a passenger in the test set will survive and 1 says he will not, the passenger will be classified as a survivor. This approach of overtraining trees, but having the majority's vote count as the actual classification decision, avoids overfitting."], "metadata": {}, "cell_type": "markdown"}, {"outputs": [], "source": ["# Import the `RandomForestClassifier`\n", "from sklearn.ensemble import RandomForestClassifier\n", "\n", "# We want the Pclass, Age, Sex, Fare,SibSp, Parch, and Embarked variables\n", "features_forest = train[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n", "\n", "# Building and fitting my_forest\n", "forest = RandomForestClassifier(max_depth=10, min_samples_split=2, n_estimators=100, random_state=1)\n", "my_forest = forest.fit(features_forest, target)\n", "\n", "# Print the score of the fitted random forest\n", "print(my_forest.score(features_forest, target))\n", "\n", "# Compute predictions on our test set features then print the length of the prediction vector\n", "test_features = test[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n", "pred_forest = my_forest.predict(test_features)\n", "print(len(pred_forest))"], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"outputs": [], "source": ["''' (7) Compare and Interpret'''\n", "\n", "#Request and print the `.feature_importances_` attribute\n", "print(my_tree_two.feature_importances_)\n", "print(my_forest.feature_importances_)\n", "\n", "#Compute and print the mean accuracy score for both models\n", "print(my_tree_two.score(features_two, target))\n", "print(my_forest.score(features_forest, target))"], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": [], "metadata": {"_cell_guid": "9a5d1f32-7113-499a-b86e-968a2e261b6d", "_uuid": "adc7534fcc60a6088640403c8f0412c377d2ce68"}, "cell_type": "markdown"}, {"source": [], "metadata": {"_cell_guid": "c9ba5389-78e9-46ba-830b-d4e35b9931be", "_uuid": "8cc781ad1cba56a805c4fba7f265e71095108a85"}, "cell_type": "markdown"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}}