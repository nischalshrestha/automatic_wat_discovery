{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9b742b2f-9e16-aee0-669b-0135c3c560da"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "\n",
        "# regular expressions\n",
        "import re\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bfbe221b-6544-3f87-9060-51d556da666f"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('../input/train.csv')\n",
        "test = pd.read_csv('../input/test.csv')\n",
        "\n",
        "# Store our passenger ID for easy access\n",
        "PassengerId = test['PassengerId']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3e4c0608-3c33-0594-6583-acc54dca219b"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "00fec92d-a4db-1760-7192-d9d7ee114f58"
      },
      "outputs": [],
      "source": [
        "full_data = [train, test]\n",
        "\n",
        "# Gives the length of the name\n",
        "train['Name_length'] = train['Name'].apply(len)\n",
        "test['Name_length'] = test['Name'].apply(len)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bc2f0978-3ae2-9f70-e010-259fe93858ee"
      },
      "outputs": [],
      "source": [
        "# Credit to Sina for her Titanic Best Working Classifier!\n",
        "\n",
        "# create family size variable\n",
        "for dataset in full_data:\n",
        "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
        "\n",
        "# If family size == 1, a person is traveling by his/herself and for that is counted as 'Alone'\n",
        "for dataset in full_data:\n",
        "    dataset['IsAlone'] = 0 # default to 0, meaning not alone\n",
        "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1 # Check for no companions\n",
        "    \n",
        "# If no information about embarkment, assume they joined in S\n",
        "for dataset in full_data:\n",
        "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
        "\n",
        "# Use median imputation method for Fare column\n",
        "for dataset in full_data:\n",
        "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
        "train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\n",
        "\n",
        "# Impute missing Age data\n",
        "for dataset in full_data:\n",
        "    avg_age = dataset['Age'].mean()\n",
        "    std_age = dataset['Age'].std()\n",
        "    null_count = dataset['Age'].isnull().sum()\n",
        "    age_null_random_list = np.random.randint(avg_age - std_age, avg_age + std_age, size=null_count)\n",
        "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
        "    dataset['Age'] = dataset['Age'].astype(int)\n",
        "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n",
        "\n",
        "# define regular expression function to extract a person's title\n",
        "def extract_title(name):\n",
        "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
        "    # if a title was found:\n",
        "    if title_search:\n",
        "        return title_search.group(1)\n",
        "    return \"\"\n",
        "\n",
        "# Create a new Column for Title\n",
        "for dataset in full_data:\n",
        "    dataset['Title'] = dataset['Name'].apply(extract_title)\n",
        "    \n",
        "# since there are quite a lot of rare titles (e.g. 'Countess'), we'll group them as 'rare'\n",
        "for dataset in full_data:\n",
        "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss') # Also replace french titles with common english abr.\n",
        "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
        "\n",
        "# Now we have to transform everything categorical into numerical values by mapping\n",
        "for dataset in full_data:\n",
        "    \n",
        "    # Transform gender into 0 for female and 1 for male\n",
        "    dataset['Sex'] = dataset['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
        "    \n",
        "    # Transform Age to a few categories\n",
        "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
        "    dataset.loc[ (dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age' ] = 1\n",
        "    dataset.loc[ (dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age' ] = 2\n",
        "    dataset.loc[ (dataset['Age'] > 38) & (dataset['Age'] <= 64), 'Age' ] = 3\n",
        "    dataset.loc[ dataset['Age'] > 64, 'Age' ] = 4\n",
        "    \n",
        "    # Map titles to values\n",
        "    title_map = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
        "    dataset['Title'] = dataset['Title'].map(title_map)\n",
        "    dataset['Title'] = dataset['Title'].fillna(0)\n",
        "    \n",
        "    # Map City of Embarkment to value\n",
        "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
        "    \n",
        "    # Mapping Fare\n",
        "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
        "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
        "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
        "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
        "    dataset['Fare'] = dataset['Fare'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0c2a2bcf-b93a-d2f1-3100-587f086b46e3"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "944e95d7-0497-7e12-8a81-3614c838f299"
      },
      "outputs": [],
      "source": [
        "# Now we'll drop any variables we don't need for our predictions \n",
        "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
        "train = train.drop(drop_elements, axis = 1)\n",
        "train = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n",
        "test  = test.drop(drop_elements, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3b21a5fa-d159-b37b-1097-4664e8531ebe"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
        "sns.heatmap(train.astype(float).corr(), annot=True, cmap='viridis', linecolor='white', linewidths=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3d424538-c02e-444b-1d3c-8ea7f6da7b6b"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(train, hue='Survived', diag_kind='kde', palette='Dark2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f012ec2d-f3ae-cd18-cc5a-8e7b100809e9"
      },
      "outputs": [],
      "source": [
        "# Import everything needed from SKLearn\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "#from sklearn.model_selection import KFold\n",
        "from sklearn.cross_validation import KFold;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3568e815-b458-261b-5fb0-ad4f9f385de6"
      },
      "outputs": [],
      "source": [
        "# Some useful parameters which will come in handy later on\n",
        "ntrain = train.shape[0]\n",
        "ntest = test.shape[0]\n",
        "SEED = 0 # for reproducibility\n",
        "NFOLDS = 5 # set folds for out-of-fold prediction\n",
        "#kf = KFold(NFOLDS, random_state=SEED)\n",
        "kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n",
        "\n",
        "# Class to extend the Sklearn classifier\n",
        "class SklearnHelper(object):\n",
        "    def __init__(self, clf, seed=0, params=None):\n",
        "        params['random_state'] = seed\n",
        "        self.clf = clf(**params)\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        self.clf.fit(x_train, y_train)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.clf.predict(x)\n",
        "    \n",
        "    def fit(self,x,y):\n",
        "        return self.clf.fit(x,y)\n",
        "    \n",
        "    def feature_importances(self,x,y):\n",
        "        return(self.clf.fit(x,y).feature_importances_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fbec28ae-436a-cf69-5e01-28d747c013ca"
      },
      "outputs": [],
      "source": [
        "# Out-Of-Fold Predictions\n",
        "def get_oof(clf, x_train, y_train, x_test):\n",
        "    oof_train = np.zeros((ntrain,))\n",
        "    oof_test = np.zeros((ntest,))\n",
        "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
        "\n",
        "    for i, (train_index, test_index) in enumerate(kf):\n",
        "        x_tr = x_train[train_index]\n",
        "        y_tr = y_train[train_index]\n",
        "        x_te = x_train[test_index]\n",
        "\n",
        "        clf.train(x_tr, y_tr)\n",
        "\n",
        "        oof_train[test_index] = clf.predict(x_te)\n",
        "        oof_test_skf[i, :] = clf.predict(x_test)\n",
        "\n",
        "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
        "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "60965390-631a-9b94-c342-ae4b99ec21d1"
      },
      "outputs": [],
      "source": [
        "# Put in our parameters for said classifiers\n",
        "# Random Forest parameters\n",
        "rf_params = {\n",
        "    'n_jobs': -1,\n",
        "    'n_estimators': 500,\n",
        "     'warm_start': True, \n",
        "     #'max_features': 0.2,\n",
        "    'max_depth': 6,\n",
        "    'min_samples_leaf': 2,\n",
        "    'max_features' : 'sqrt',\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "# Extra Trees Parameters\n",
        "et_params = {\n",
        "    'n_jobs': -1,\n",
        "    'n_estimators':500,\n",
        "    #'max_features': 0.5,\n",
        "    'max_depth': 8,\n",
        "    'min_samples_leaf': 2,\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "# AdaBoost parameters\n",
        "ada_params = {\n",
        "    'n_estimators': 500,\n",
        "    'learning_rate' : 0.75\n",
        "}\n",
        "\n",
        "# Gradient Boosting parameters\n",
        "gb_params = {\n",
        "    'n_estimators': 500,\n",
        "     #'max_features': 0.2,\n",
        "    'max_depth': 5,\n",
        "    'min_samples_leaf': 2,\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "# Support Vector Classifier parameters \n",
        "svc_params = {\n",
        "    'kernel' : 'linear',\n",
        "    'C' : 0.025\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1df1ac3a-5564-48f5-7c7b-00c7ed1251c0"
      },
      "outputs": [],
      "source": [
        "# Create objects that represent our 4 models\n",
        "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
        "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
        "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
        "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
        "svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eaaf6be6-3056-c230-11a4-039d4c761402"
      },
      "outputs": [],
      "source": [
        "# Split data into train and test sets\n",
        "y_train = train['Survived'].ravel()\n",
        "train = train.drop(['Survived'], axis=1)\n",
        "x_train = train.values # Creates an array of the train data\n",
        "x_test = test.values # Creats an array of the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "926adc04-3267-dd16-8f37-faf77facb04e"
      },
      "outputs": [],
      "source": [
        "# Create our OOF train and test predictions. These base results will be used as new features\n",
        "et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\n",
        "rf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\n",
        "ada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \n",
        "gb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) # Gradient Boost\n",
        "svc_oof_train, svc_oof_test = get_oof(svc,x_train, y_train, x_test) # Support Vector Classifier\n",
        "\n",
        "print(\"Training is complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a56cd583-bc58-4f52-ab12-a27cf0e81a9c"
      },
      "outputs": [],
      "source": [
        "rf_features = rf.feature_importances(x_train,y_train)\n",
        "et_features = et.feature_importances(x_train, y_train)\n",
        "ada_features = ada.feature_importances(x_train, y_train)\n",
        "gb_features = gb.feature_importances(x_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c099df77-ae69-0503-a20d-ef9057ac6e54"
      },
      "outputs": [],
      "source": [
        "# Create dataframe from above feature importances\n",
        "cols = train.columns.values\n",
        "feature_dataframe = pd.DataFrame({'features': cols,\n",
        "              'Random Forest feature importances': rf_features,\n",
        "              'Extra Trees feature importances': et_features,\n",
        "              'AdaBoost feature importances': ada_features,\n",
        "              'Gradient Boost feature importances': gb_features\n",
        "             })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e2c17daa-04fc-67f4-60d5-b9f4f53f9897"
      },
      "outputs": [],
      "source": [
        "feature_dataframe.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "06e6acf5-577a-9d0e-bf2a-d389e36391f8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.title('Random Forest feature importances', size=20)\n",
        "sns.barplot(x='features', y='Random Forest feature importances', data=feature_dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e3aa2470-4ff1-a8de-f913-1d08b0a157cb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.title('Gradient Boost feature importances', size=20)\n",
        "sns.barplot(x='features', y='Gradient Boost feature importances', data=feature_dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4cc819cf-2d22-ac49-ebcf-c3339bd269dc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.title('Extra Trees feature importances', size=20)\n",
        "sns.barplot(x='features', y='Extra Trees feature importances', data=feature_dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "75d78330-4f47-1d1c-836a-03517098f7df"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.title('AdaBoost feature importances', size=20)\n",
        "sns.barplot(x='features', y='AdaBoost feature importances', data=feature_dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "367ecc4d-a92d-a1b3-192a-a80cc2115c52"
      },
      "outputs": [],
      "source": [
        "feature_dataframe['mean'] = feature_dataframe.mean(axis= 1) # axis = 1 computes the mean row-wise\n",
        "feature_dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "12560a82-b6f8-4dca-8210-d8be19a01ce1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.title('Average Feature Importance', size=20)\n",
        "sns.barplot(x='features', y='mean', data=feature_dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b5a403b2-9c6e-43ce-bb13-6cd52efff12c"
      },
      "outputs": [],
      "source": [
        "base_predictions_train = pd.DataFrame( {'RandomForest': rf_oof_train.ravel(),\n",
        "     'ExtraTrees': et_oof_train.ravel(),\n",
        "     'AdaBoost': ada_oof_train.ravel(),\n",
        "      'GradientBoost': gb_oof_train.ravel()\n",
        "    })\n",
        "base_predictions_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "969b9819-1dd7-f6c1-fb45-ef59d2781ac2"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(base_predictions_train.astype(float).corr(), cmap='viridis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fdca6977-88bc-41e5-53e6-6eb3585d9ecc"
      },
      "outputs": [],
      "source": [
        "x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train, svc_oof_train), axis=1)\n",
        "x_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test, svc_oof_test), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5a6fa908-2735-f374-f9a6-7dba5598b205"
      },
      "outputs": [],
      "source": [
        "# Create and fit the Gradient Boosting Model\n",
        "gbm = xgb.XGBClassifier(\n",
        " n_estimators= 2000,\n",
        " max_depth= 4,\n",
        " min_child_weight= 2,\n",
        " gamma=0.9,                        \n",
        " subsample=0.8,\n",
        " colsample_bytree=0.8,\n",
        " objective= 'binary:logistic',\n",
        " nthread= -1,\n",
        " scale_pos_weight=1)\n",
        "\n",
        "gbm.fit(x_train, y_train)\n",
        "\n",
        "# Predict survival on test data\n",
        "predictions = gbm.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9f37cc34-65d3-ee28-9601-f2310516772b"
      },
      "outputs": [],
      "source": [
        "# Generate Submission File \n",
        "Submission = pd.DataFrame({ 'PassengerId': PassengerId,\n",
        "                            'Survived': predictions })\n",
        "Submission.to_csv(\"Submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "be28c265-6942-6aea-51ae-acdd5d80b487"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}