{"nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "toc": {"sideBar": true, "skip_h1_title": false, "toc_window_display": false, "toc_cell": true, "number_sections": false, "nav_menu": {}, "toc_position": {"height": "705px", "top": "34px", "right": "1068px", "width": "212px", "left": "0px"}, "toc_section_display": "block"}, "language_info": {"file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python", "version": "3.6.4", "mimetype": "text/x-python", "name": "python"}}, "nbformat_minor": 1, "cells": [{"cell_type": "markdown", "source": ["<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n", "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\">Introduction</a></span></li><li><span><a href=\"#1.-Data-Analysis\" data-toc-modified-id=\"1.-Data-Analysis-2\">1. Data Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1-Loading-and-Checking-Data\" data-toc-modified-id=\"1.1-Loading-and-Checking-Data-2.1\">1.1 Loading and Checking Data</a></span></li><li><span><a href=\"#1.2-Handling-Missing-Data\" data-toc-modified-id=\"1.2-Handling-Missing-Data-2.2\">1.2 Handling Missing Data</a></span></li><li><span><a href=\"#1.3-Feature-Engineering\" data-toc-modified-id=\"1.3-Feature-Engineering-2.3\">1.3 Feature Engineering</a></span></li><li><span><a href=\"#1.4-Data-Visualisation\" data-toc-modified-id=\"1.4-Data-Visualisation-2.4\">1.4 Data Visualisation</a></span></li></ul></li><li><span><a href=\"#2.-Model-Selection\" data-toc-modified-id=\"2.-Model-Selection-3\">2. Model Selection</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1-Neighbors\" data-toc-modified-id=\"2.1-Neighbors-3.1\">2.1 Neighbors</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1.1-Normal-KNN\" data-toc-modified-id=\"2.1.1-Normal-KNN-3.1.1\">2.1.1 Normal KNN</a></span></li><li><span><a href=\"#2.1.2-Weighted-KNN\" data-toc-modified-id=\"2.1.2-Weighted-KNN-3.1.2\">2.1.2 Weighted KNN</a></span></li></ul></li><li><span><a href=\"#2.2-Decision-Trees\" data-toc-modified-id=\"2.2-Decision-Trees-3.2\">2.2 Decision Trees</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.2.1-Discrete-Tree\" data-toc-modified-id=\"2.2.1-Discrete-Tree-3.2.1\">2.2.1 Discrete Tree</a></span></li></ul></li><li><span><a href=\"#2.3-Logistic-Regression\" data-toc-modified-id=\"2.3-Logistic-Regression-3.3\">2.3 Logistic Regression</a></span></li><li><span><a href=\"#2.4-Ensemble-Methods\" data-toc-modified-id=\"2.4-Ensemble-Methods-3.4\">2.4 Ensemble Methods</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.4.1-Extra-Trees-Classifier\" data-toc-modified-id=\"2.4.1-Extra-Trees-Classifier-3.4.1\">2.4.1 Extra Trees Classifier</a></span></li><li><span><a href=\"#2.4.2-Random-Forest\" data-toc-modified-id=\"2.4.2-Random-Forest-3.4.2\">2.4.2 Random Forest</a></span></li><li><span><a href=\"#2.4.3-Boosting\" data-toc-modified-id=\"2.4.3-Boosting-3.4.3\">2.4.3 Boosting</a></span><ul class=\"toc-item\"><li><span><a href=\"#ADA-Boosting\" data-toc-modified-id=\"ADA-Boosting-3.4.3.1\">ADA Boosting</a></span></li><li><span><a href=\"#Gradient-Boosting\" data-toc-modified-id=\"Gradient-Boosting-3.4.3.2\">Gradient Boosting</a></span></li><li><span><a href=\"#Extreme-Gradient-Boosting\" data-toc-modified-id=\"Extreme-Gradient-Boosting-3.4.3.3\">Extreme Gradient Boosting</a></span></li></ul></li><li><span><a href=\"#2.4.4-Voting-Methods\" data-toc-modified-id=\"2.4.4-Voting-Methods-3.4.4\">2.4.4 Voting Methods</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hard-/-Soft-Voting\" data-toc-modified-id=\"Hard-/-Soft-Voting-3.4.4.1\">Hard / Soft Voting</a></span></li><li><span><a href=\"#Hard-/-Soft-voting,-Parameter-Search\" data-toc-modified-id=\"Hard-/-Soft-voting,-Parameter-Search-3.4.4.2\">Hard / Soft voting, Parameter Search</a></span></li></ul></li><li><span><a href=\"#2.4.5-Stacking\" data-toc-modified-id=\"2.4.5-Stacking-3.4.5\">2.4.5 Stacking</a></span></li></ul></li></ul></li><li><span><a href=\"#3.-Evaluation\" data-toc-modified-id=\"3.-Evaluation-4\">3. Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1-Acurracy\" data-toc-modified-id=\"3.1-Acurracy-4.1\">3.1 Acurracy</a></span></li><li><span><a href=\"#3.2-Model-Correlations\" data-toc-modified-id=\"3.2-Model-Correlations-4.2\">3.2 Model Correlations</a></span></li><li><span><a href=\"#3.3-Custom-features-per-classifier\" data-toc-modified-id=\"3.3-Custom-features-per-classifier-4.3\">3.3 Custom features per classifier</a></span></li></ul></li></ul></div>"], "metadata": {"_uuid": "98988cc828f75961e0e3fc967705eb77b6a0f9a3", "toc": true, "_cell_guid": "ee0b5182-c89e-45ac-93bc-254d7b21049f"}}, {"cell_type": "markdown", "source": ["# Introduction\n", "\n", "This project was done by Group 15 from the Leren en Beslissen Course given during the Bachelor Artficial Intelligence at the University of Amsterdam.\n", "\n", "The team members were: Noa Visser, Laurens Weitkamp, Jim Voorn and Dani\u00ebl Vink.\n"], "metadata": {"_uuid": "6b37fc7981b6d833dbea4c73ea9806e801f37295", "_cell_guid": "25b0a228-f2dc-41d2-8019-d38e6b3c666d"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["import warnings\n", "warnings.filterwarnings('ignore')\n", "\n", "# Data processing packages\n", "import numpy as np\n", "import pandas as pd\n", "\n", "# Plotting/visualisation packages\n", "import seaborn as sns\n", "import graphviz\n", "import matplotlib.pyplot as plt\n", "import matplotlib.colors as mcolors\n", "\n", "# sklearn helper functions\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.metrics import accuracy_score\n", "from sklearn.preprocessing import OneHotEncoder\n", "from sklearn.model_selection import GridSearchCV\n", "\n", "# sklearn classification models\n", "from sklearn import tree, neighbors, linear_model, neighbors, ensemble\n", "import xgboost as xgb\n", "\n", "# Model stacking package\n", "from vecstack import stacking\n", "\n", "\n", "# Create a custom colormap for pearson coefficient heatmap\n", "colors1 = plt.cm.Blues_r(np.linspace(0., 1, 128))\n", "colors2 = plt.cm.Blues(np.linspace(0, 1, 128))\n", "colors = np.vstack((colors1, colors2))\n", "pearson_colors = mcolors.LinearSegmentedColormap.from_list('my_colormap', colors)\n", "\n", "# Notebook settings\n", "sns.set_style(\"whitegrid\")\n", "%config InlineBackend.figure_format = 'retina'\n", "%matplotlib inline\n", "alpha = 0.7\n", "\n", "def create_csv(results, filename, test):\n", "    results = pd.DataFrame(results)\n", "    results['PassengerId'] = test['PassengerId']\n", "    results.columns = ['Survived', 'PassengerId']\n", "    results.to_csv(filename, index = False)"], "metadata": {"collapsed": true, "_uuid": "b4f18eb8b90d7b06958dd61f3578655465119c44", "_cell_guid": "9ceaf6c3-ad17-47b7-82ba-1b7f68f5a8db"}}, {"cell_type": "markdown", "source": ["# 1. Data Analysis\n", "\n", "## 1.1 Loading and Checking Data"], "metadata": {"_uuid": "02a6581a0641220ef5eda952db5cf0961a588030", "_cell_guid": "d9af3741-f7c4-4233-b106-381c251db407"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["test  = pd.read_csv(\"../input/titanic/test.csv\")\n", "train = pd.read_csv(\"../input/titanic/train.csv\")\n", "\n", "print(train.shape, test.shape)"], "metadata": {"collapsed": true, "_uuid": "000d154659cc0c70662c8143fad8016c61b22e1e", "_cell_guid": "85a2a69b-0642-49a1-a5db-16b7697e1ec3"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["train.head()"], "metadata": {"collapsed": true, "_uuid": "897a4a0de19eb7e0ed29d97212a7a219c6fda92f", "_cell_guid": "720a272c-17d2-402c-87a7-1d7100b02c66"}}, {"cell_type": "markdown", "source": ["## 1.2 Handling Missing Data\n", "\n", "As we can see in the above DataFrame, the Cabin column often has _NaN_'s, missing values. In the case of Cabin this is a major issue as we can see in the cell below, over 77% is missing. The cabins themselves range from A to G, with A being the top level cabins, and this might indicate some correlation with the Pclass and perhaps even with the Ticket column. "], "metadata": {"_uuid": "9ed452192412ff3562d8f50973eb8133001d2f5d", "_cell_guid": "e89b8509-2d75-4dd3-b82c-255b13d7c170"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["pd.isnull(train).sum()"], "metadata": {"collapsed": true, "_uuid": "904a1c6c9b56271eb13531ff5e9605396aa4fbb5", "_cell_guid": "229d53e6-bba1-4bdc-bb10-9588aad19024"}}, {"cell_type": "markdown", "source": ["The total number of data samples we have for training is 891, and we can see that Cabin is missing 687 values in total here. "], "metadata": {"_uuid": "ba5dd064c81dca73fd8bf54d424c6bea2eabd0c5", "_cell_guid": "bc96efc8-4634-495e-917b-5961d9e68a6a"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["plt.figure(figsize = (18, 6))\n", "train[train['Survived'] == 1]['Age'].hist(label='Survived', alpha=alpha)\n", "train[train['Survived'] == 0]['Age'].hist(label='Died', alpha=alpha)\n", "plt.title(\"Age \")\n", "plt.legend();"], "metadata": {"collapsed": true, "_uuid": "e555ee67a5e6ce178442f07f5934b32502960f0a", "_cell_guid": "2e34bda3-b111-4b7f-830d-aeee35fa4220"}}, {"cell_type": "markdown", "source": ["## 1.3 Feature Engineering\n", "\n", "korte uitleg over het aanmaken van nieuwe features, tokenisation van sex, tokenisation van age"], "metadata": {"_uuid": "8966dd90ecc9b53a48833c13b6ec6b150a59ec17", "_cell_guid": "91a8ba59-9f81-4d0e-9e6b-e4163f4341a6"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["def feature_engineering(dataset):\n", "    \"\"\"\n", "    dataset: DataFrame\n", "    \"\"\"\n", "    \n", "    # First up is some \n", "    dataset['Fare'] = dataset['Fare'].fillna(0)\n", "    dataset['FarePP'] = (dataset['Fare'] / (dataset['SibSp'] + dataset['Parch'] + 1)).round().astype(int)\n", "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n", "    dataset['IsAlone'] = dataset['FamilySize'].apply(lambda x: 1 if x == 1 else 0)\n", "    dataset['SexBinary'] = dataset['Sex'].apply(lambda x: 1 if x == 'female' else 0)\n", "\n", "    # Knipt de titels uit de namen en voegt deze als kolom toe aan de dataframe\n", "    dataset['Title'] = dataset['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n", "\n", "    # Vervangt obscure of buitenlandse titels met overkoepelende titel.\n", "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n", "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n", "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n", "    dataset['Title'] = dataset['Title'].replace(['Capt', 'Col', 'Don', 'Dr', 'Jonkheer', 'Sir', 'Major', 'Rev'], 'Otherm')\n", "    dataset['Title'] = dataset['Title'].replace(['Dona', 'Lady', 'the Countess'], 'Otherf')\n", "\n", "    # berekent de mediaan per titel\n", "    medians = dataset[['Age', 'Title']].groupby(['Title'], as_index=False).median()\n", "    # vult ontbrekende leeftijden in met de mediaan van de betreffende titel\n", "    dataset.loc[dataset['Title'] == 'Master', 'Age'] = dataset.loc[dataset['Title'] == 'Master', 'Age'].fillna(medians.loc[medians['Title'] == 'Master']['Age'][0])\n", "    dataset.loc[dataset['Title'] == 'Mr', 'Age'] = dataset.loc[dataset['Title'] == 'Mr', 'Age'].fillna(medians.loc[medians['Title'] == 'Mr']['Age'][2])\n", "    dataset.loc[dataset['Title'] == 'Mrs', 'Age'] = dataset.loc[dataset['Title'] == 'Mrs', 'Age'].fillna(medians.loc[medians['Title'] == 'Mrs']['Age'][3])\n", "    dataset.loc[dataset['Title'] == 'Miss', 'Age'] = dataset.loc[dataset['Title'] == 'Miss', 'Age'].fillna(medians.loc[medians['Title'] == 'Miss']['Age'][1])\n", "    dataset.loc[dataset['Title'] == 'Otherm', 'Age'] = dataset.loc[dataset['Title'] == 'Otherm', 'Age'].fillna(medians.loc[medians['Title'] == 'Otherm']['Age'][5])\n", "    dataset.loc[dataset['Title'] == 'Otherf', 'Age'] = dataset.loc[dataset['Title'] == 'Otherf', 'Age'].fillna(medians.loc[medians['Title'] == 'Otherf']['Age'][4])\n", "    \n", "    # discretiseert de leeftijden in leeftijdsgroepen. Aantal kan aangepast worden, returnt ook een lijst met de ranges van \n", "    # de leeftijdsgroepen.\n", "    dataset['AgeGroup'], agebins = pd.cut(dataset['Age'], 6, labels=range(6), retbins=True)\n", "    dataset['AgeGroup'].head(20), agebins;\n", "    dataset['AgeGroup'] = dataset['AgeGroup'].astype(int) # it keeps the categorical dtype, we want int\n", "\n", "    from sklearn.preprocessing import LabelEncoder\n", "    label = LabelEncoder()\n", "\n", "    dataset['DiscreteTitle'] = label.fit_transform(dataset['Title'])\n", "\n", "    dataset['Fare'] = dataset['Fare'].apply(lambda x: dataset['Fare'].median() if x < 5 else x)\n", "    \n", "    # Some more discretisations\n", "    dataset['EmbarkedDiscrete'] = label.fit_transform(dataset['Embarked'].apply(lambda x: x if not pd.isnull(x) else 'S'))\n", "    dataset['FareAdjusted'] = dataset['Fare'].apply(lambda x: x if x != 0 else dataset['Fare'].median()) \n", "    dataset['FareBinned'] = label.fit_transform(pd.qcut(dataset['FareAdjusted'], 4))\n", "    \n", "    dataset['AgeGroup'] = dataset['AgeGroup'].astype(int)\n", "    \n", "    return dataset\n", "\n", "train    = feature_engineering(train)\n", "testing  = feature_engineering(test)"], "metadata": {"collapsed": true, "_uuid": "7b916efb91d8f2212bf191515eb8a85c246f7379", "_cell_guid": "3b5988d9-d100-4695-87ec-113e038457de"}}, {"cell_type": "markdown", "source": ["## 1.4 Data Visualisation\n", "\n", "To analyse our new features, let's create a Pearson Coefficient heatmap. This ranges from -1 to 1 and corresponds to the correlation between each feature. -1 indicates a strong negative correlation, and 1 indicates a strong positive correlation. 0 indicates that there is no correlation at all between features."], "metadata": {"_uuid": "c2e34d7f5dd1be5fcc94b6fdabf6a9ac367cd693", "_cell_guid": "cb2fb996-c6d2-43d1-9743-ba6049e67b6b"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["features = train[['Embarked', 'Survived', 'Pclass', 'IsAlone', 'SexBinary', 'AgeGroup', 'FareBinned', 'DiscreteTitle']].corr()\n", "plt.figure(figsize = (18, 8))\n", "sns.heatmap(features, cmap=pearson_colors, linewidths=1, annot=features, vmin=-1, vmax=1);\n", "plt.yticks(rotation=0)\n", "plt.title(\"Pearson Coefficient for all numerical features\")\n", "plt.show()"], "metadata": {"collapsed": true, "_uuid": "4e2f7692cd9f8253000f1f5411f698a89636a8f7", "_cell_guid": "c5b59ad0-f83e-44b6-a207-5ad0b76130b4"}}, {"cell_type": "markdown", "source": ["We see that __SexBinary__, __Pclass__, __IsAlone__ and __FareBinned__ have the highest correlations (in that order). What we can also see is that __Pclass__ and __FareBinned__ have a significantly strong correlation between eachother. Likewise, __Pclass__ and __AgeGroup__ have a good correlation too. We can use this information later during feature selection, we might for example choose to use __Pclass__ and drop __FareBinned__.\n", "\n", "\n", "Now let's try to figure out some more about the difference between sex and survival rate."], "metadata": {"_uuid": "905342bcbe7a4f5c572234e30a3c7cb567b7a4d1", "_cell_guid": "75440bcc-1308-47fa-af0a-34fa69657fd9"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["plt.figure(figsize = (18, 8))\n", "sns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data = train, alpha=alpha)\n", "plt.title(\"Survival rate of male and female per embarked location\")\n", "plt.xlabel(\"Sex\");\n", "plt.ylabel(\"Survival rate\");"], "metadata": {"collapsed": true, "_uuid": "57d7331c88e018bdb2da170715cf0bbac071aec2", "_cell_guid": "116ba6f4-5da2-48d4-a80d-c7aac5b19f1e"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["plt.figure(figsize = (18, 8))\n", "sns.barplot(x = 'AgeGroup', y = 'Survived', hue = 'Sex', data = train, alpha = alpha)\n", "plt.title(\"Survival rate of male and female in age groups\")\n", "plt.xlabel(\"Age group\")\n", "plt.ylabel(\"Survival rate\");"], "metadata": {"collapsed": true, "_uuid": "196d19669b5bbed286d0bd014c1f3a9c372654dd", "_cell_guid": "562b7915-a5fa-4e19-bed9-7b36c9cedef5"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["plt.figure(figsize = (18, 8))\n", "sns.barplot(x = 'Pclass', y = 'Survived', hue = 'Sex', data = train, alpha=alpha)\n", "plt.title(\"Survival rate of male and female per different Pclass\")\n", "plt.xlabel(\"Pclass\")\n", "plt.ylabel(\"Survival rate\");"], "metadata": {"collapsed": true, "_uuid": "f2991f051783337b7f5ac4d823a4331cc0b1dad5", "_cell_guid": "778eca17-61b9-4846-8078-9afa34e8421b"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["plt.figure(figsize = (18, 8))\n", "sns.barplot(x = 'FamilySize', y = 'Survived', data = train, alpha = alpha);"], "metadata": {"collapsed": true, "_uuid": "3631b683cd7bcd1abce3118dfcb7a049244c0376", "_cell_guid": "e8ad00f4-5d91-4e53-8011-717ebd45e413"}}, {"cell_type": "markdown", "source": ["# 2. Model Selection\n", "\n", "\n", "For the purpose of this classification task, a wide variety of models will be used. We will start of with simpler ones like K-NN and Decision Trees, and then venture into ensemble methods like Random Forest and Voting Classifiers. For each model we will calculate both the result from the default settings and the result from the grid searched settings. Grid search is a method in which a range of parameters will be used to calculate the optimal parameters for a given model on a dataset.\n", "\n", "```\n", "Classification Models\n", "\u2502\n", "\u2514\u2500\u2500\u2500 Neighbors\n", "\u2502     \u2514\u2500 K-NN\n", "\u2502     \u2514\u2500 Weighted K-NN\n", "\u2502\n", "\u2514\u2500\u2500\u2500 Decision Trees\n", "\u2502     \u2514\u2500 Discrete Tree\n", "\u2502\n", "\u2514\u2500\u2500\u2500 Logistic Regression\n", "\u2502\n", "\u2514\u2500\u2500\u2500 Ensembles\n", "\u2502     \u2514\u2500 Extra Trees\n", "\u2502     \u2514\u2500 Random Forest\n", "\u2502     \u2514\u2500 Boosting\n", "\u2502         \u2514\u2500 ADA\n", "\u2502         \u2514\u2500 Gradient\n", "\u2502         \u2514\u2500 Extreme Gradient\n", "\u2502     \u2514\u2500 Voting Classifier\n", "\u2502         \u2514\u2500 Hard\n", "\u2502         \u2514\u2500 Soft\n", "\u2502     \u2514\u2500 Stacking\n", "\n", "```"], "metadata": {"_uuid": "1f1c00e03e3fb15bd08e6e7fa25fff1a92766177", "_cell_guid": "1c8320c7-ca0b-4615-80fa-29c2c3404680"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["features_used = ['EmbarkedDiscrete', 'Pclass', 'SexBinary', 'AgeGroup', 'DiscreteTitle', 'FamilySize', 'FareBinned']\n", "\n", "\n", "X = train[features_used]\n", "y = train['Survived']\n", "test = testing[features_used]\n", "\n", "model_scores = {}\n", "cross_vals = 4\n", "\n", "#One Hot Encoding. In some cases it might be interesting to see if this actually improves the accuracy\n", "enc = OneHotEncoder()\n", "X_bin = enc.fit_transform(X).toarray().astype(int)\n", "test_bin = enc.fit_transform(test).toarray().astype(int)\n", "\n", "\n", "# Grid search \n", "grid_n_estimator = [10, 50, 100, 300]\n", "grid_ratio = [.1, .25, .5, .75, 1.0]\n", "grid_learn = [.01, .03, .05, .1, .25]\n", "grid_max_depth = [2, 4, 6, 8, 10, None]\n", "grid_min_samples = [5, 10, .03, .05, .10]\n", "grid_criterion = ['gini', 'entropy']\n", "grid_bool = [True, False]\n", "grid_seed = [0]"], "metadata": {"collapsed": true, "_uuid": "f3e5dbc9557c4629a44d4ef2fe3f4db684f81f10", "_cell_guid": "8f7a4466-cfdb-4b0e-902d-4c7ad8c75617"}}, {"cell_type": "markdown", "source": ["## 2.1 Neighbors\n", "\n", "### 2.1.1 Normal KNN"], "metadata": {"_uuid": "7d996451b641b7c6e1cda1907720fb9fd0702d82", "_cell_guid": "23624c70-ccad-4244-a5c1-9b5dee9f2066"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["# Default parameter model\n", "knn = neighbors.KNeighborsClassifier()\n", "\n", "# Grid search parameter model\n", "knn_params = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7],\n", "              'weights': ['uniform', 'distance'],\n", "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n", "\n", "\n", "knn_grid = GridSearchCV(estimator=neighbors.KNeighborsClassifier(),\n", "                        param_grid=knn_params,\n", "                        cv=cross_vals,\n", "                        scoring='roc_auc')\n", "knn_grid = knn_grid.fit(X, y).best_estimator_\n", "\n", "knn_score      = cross_val_score(knn, X, y, scoring='accuracy', cv=cross_vals)\n", "knn_grid_score = cross_val_score(knn_grid, X, y, scoring='accuracy', cv=cross_vals)\n", "\n", "print(\"KNN default:\\t{0}\\nKNN grid:\\t{1}\".format(\n", "    knn_score.mean(), knn_grid_score.mean()))\n", "model_scores['KNN'] = knn_score"], "metadata": {"collapsed": true, "_uuid": "4853191c3d8ef48c21f08e58126a55c1b29ae620", "_cell_guid": "a7281ca3-b91c-4eeb-810a-10c52881e35c"}}, {"cell_type": "markdown", "source": ["### 2.1.2 Weighted KNN"], "metadata": {"_uuid": "c0ae7bc9ac60ad4ded16cb954dd5359811526551", "_cell_guid": "ee442fa3-1884-4468-8159-268209f5c3b5"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["# Default parameter model\n", "knn = neighbors.KNeighborsClassifier(weights='distance')\n", "\n", "# Grid search parameter model\n", "knn_w_params = {'weights': ['distance'],\n", "              'n_neighbors': [1, 2, 3, 4, 5, 6, 7],\n", "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n", "\n", "\n", "knn_grid = GridSearchCV(estimator = neighbors.KNeighborsClassifier(),\n", "                                     param_grid = knn_w_params, \n", "                                     cv = cross_vals, \n", "                                     scoring = 'roc_auc')\n", "knn_grid = knn_grid.fit(X, y).best_estimator_\n", "\n", "\n", "knn_score = cross_val_score(knn, X, y, scoring='accuracy', cv = cross_vals)\n", "knn_grid_score = cross_val_score(knn_grid, X, y, scoring='accuracy', cv = cross_vals)\n", "\n", "print(\"KNN weighted default:\\t{0}\\nKNN weighted grid:\\t{1}\".format(knn_score.mean(), knn_grid_score.mean()))\n", "model_scores['KNN weighted'] = knn_score"], "metadata": {"collapsed": true, "_uuid": "5afd966458a82c5fc8ba523f2be605e7ecf78e5e", "_cell_guid": "b032fc20-2506-4fa4-8db0-6551c3b2a18a"}}, {"cell_type": "markdown", "source": ["## 2.2 Decision Trees\n", "\n", "### 2.2.1 Discrete Tree"], "metadata": {"_uuid": "f571159943d3bd7355622e315c8af959409c6ec0", "_cell_guid": "0bc96f37-90bf-42e9-ac0d-63bd326b4c90"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["# Default parameter model\n", "DTree = tree.DecisionTreeClassifier()\n", "\n", "# Grid search parameter model \n", "DTree_params = {'criterion': grid_criterion,\n", "                'max_depth': grid_max_depth,\n", "                'random_state': grid_seed}\n", "DTree_grid = GridSearchCV(estimator = tree.DecisionTreeClassifier(),\n", "                                     param_grid = DTree_params, \n", "                                     cv = cross_vals, \n", "                                     scoring = 'roc_auc')\n", "DTree_grid = DTree_grid.fit(X, y).best_estimator_\n", "\n", "\n", "DTree_score      = cross_val_score(DTree, X, y, scoring='accuracy', cv=cross_vals)\n", "DTree_grid_score = cross_val_score(DTree_grid, X, y, scoring='accuracy', cv=cross_vals)\n", "\n", "print(\"Discrete Tree default:\\t{0}\\nDiscrete Tree Grid:\\t{1}\".format(DTree_score.mean(), DTree_grid_score.mean()))\n", "model_scores['DecisionTree'] = DTree_grid_score"], "metadata": {"collapsed": true, "_uuid": "6f4d3994b0a7f170115f3676457c339ff6526a20", "_cell_guid": "5f46e384-f96c-4ab8-8b52-6ac9bc9ac255"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["# tree visualisation\n", "DTree.fit(X, y)\n", "DTree_out_train = DTree.predict(X)\n", "DTree_out_test = DTree.predict(test)\n", "\n", "dot_data = tree.export_graphviz(DTree, \n", "                     out_file=None, \n", "                     feature_names=X.keys(),  \n", "                     class_names=['Survived', 'Died'],\n", "                     filled=True, rounded=True,\n", "                     special_characters=True) \n", "\n", "\n", "graph = graphviz.Source(dot_data)\n", "#graph.render(\"Tree\") # Save tree\n", "#graph"], "metadata": {"collapsed": true, "_uuid": "d1be50d0086cb75dd0b96365d40a7a726772466a", "_cell_guid": "c8b3f6d0-4951-48f2-885d-7b981847f17d"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["plt.figure(figsize = (18, 7))\n", "sns.barplot(x = X.keys(), y = DTree.feature_importances_, alpha = alpha)\n", "plt.title(\"Feature importance for Decision Tree classifier\");"], "metadata": {"collapsed": true, "_uuid": "fc2504cbc94352c4cf0545147b5c5a3578e8ff33", "_cell_guid": "a4650bd8-0bba-4512-8cbb-07d0763be91c"}}, {"cell_type": "markdown", "source": ["## 2.3 Logistic Regression"], "metadata": {"_uuid": "1fdf557359aa40753ee562a3bc042b705affa921", "_cell_guid": "9beba875-e534-41db-b869-22119f2090e5"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["# Default parameter model\n", "LR = linear_model.LogisticRegression()\n", "\n", "# Grid search parameter model\n", "logres_params = {'fit_intercept': grid_bool,\n", "                 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag'],\n", "                 'random_state': grid_seed}\n", "\n", "LR_grid = GridSearchCV(estimator = linear_model.LogisticRegression(),\n", "                                     param_grid = logres_params, \n", "                                     cv = cross_vals, \n", "                                     scoring = 'roc_auc')\n", "LR_grid = LR_grid.fit(X, y).best_estimator_\n", "\n", "LR_score = cross_val_score(LR, X, y, scoring='accuracy', cv=cross_vals)\n", "LR_grid_score = cross_val_score(LR_grid, X, y, scoring='accuracy', cv=cross_vals)\n", "\n", "print(\"Logistic Regression default:\\t{0}\\nLogistic Regression Grid:\\t{1}\".format(LR_score.mean(), LR_grid_score.mean()))\n", "model_scores['Logistic Regression'] = LR_grid_score"], "metadata": {"collapsed": true, "_uuid": "87d7435060b488dfbee2108dcb389e1e3899eb04", "_cell_guid": "a19b92b2-44d1-4383-828c-d7e73ce8986d"}}, {"cell_type": "markdown", "source": ["## 2.4 Ensemble Methods\n", "\n", "### 2.4.1 Extra Trees Classifier"], "metadata": {"_uuid": "c7e9f3ffa4f281ab62b3d9c9f9bf3d5e5f975534", "_cell_guid": "f02f64d9-abef-4795-a4f7-3ab26c42bb73"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["# Default parameter model \n", "ETree = ensemble.ExtraTreesClassifier()\n", "\n", "# Grid search parameter model\n", "etree_params = {'n_estimators': grid_n_estimator,\n", "                'criterion': grid_criterion,\n", "                'max_depth': grid_max_depth,\n", "                'random_state': grid_seed}\n", "\n", "ETree_grid = GridSearchCV(estimator = ensemble.ExtraTreesClassifier(),\n", "                                     param_grid = etree_params, \n", "                                     cv = cross_vals, \n", "                                     scoring = 'roc_auc')\n", "ETree_grid = ETree_grid.fit(X, y).best_estimator_\n", "\n", "ETree_score = cross_val_score(ETree, X, y, scoring='accuracy', cv=cross_vals)\n", "ETree_grid_score = cross_val_score(ETree_grid, X, y, scoring='accuracy', cv=cross_vals)\n", "\n", "print(\"Extra trees default:\\t{0}\\nExtra trees grid:\\t{1}\".format(ETree_score.mean(), ETree_grid_score.mean()))\n", "model_scores['Extra Trees'] = ETree_grid_score"], "metadata": {"collapsed": true, "_uuid": "f31ec153392627eb6b674177ece880ad6af12646", "_cell_guid": "7b800544-b4cd-4cb2-a7c4-ecf2173d1411"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["plt.figure(figsize = (18, 7))\n", "sns.barplot(x = X.keys(), y = ETree_grid.feature_importances_, alpha = alpha)\n", "plt.title(\"Feature importance for Extra Trees classifier\");"], "metadata": {"collapsed": true, "_uuid": "c54a93ea695ba05035e1689f4d79736dc9b401b6", "_cell_guid": "5f6fdf2d-c7ef-4bdc-814a-bd05d75c2a76"}}, {"cell_type": "markdown", "source": ["### 2.4.2 Random Forest"], "metadata": {"_uuid": "2758e59010fd235c4a6524b67e5f3fd857ad5fb3", "_cell_guid": "fb6a3633-cdae-47e0-be9b-6ebb606ca319"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["# Default parameter model\n", "RandomForest = ensemble.RandomForestClassifier()\n", "\n", "# Grid search parameter model\n", "rf_params = {'n_estimators': grid_n_estimator,\n", "             'criterion': grid_criterion,\n", "             'max_depth': grid_max_depth,\n", "             'oob_score': [True],\n", "             'random_state': grid_seed}\n", "\n", "RandomForest_grid = GridSearchCV(ensemble.RandomForestClassifier(), \n", "                                 param_grid=rf_params,\n", "                                 cv = cross_vals, \n", "                                 scoring = 'roc_auc')\n", "RandomForest_grid = RandomForest_grid.fit(X, y).best_estimator_\n", "\n", "RandomForest_score      = cross_val_score(RandomForest, X, y, scoring='accuracy', cv=cross_vals)\n", "RandomForest_grid_score = cross_val_score(RandomForest_grid, X, y, scoring='accuracy', cv=cross_vals)\n", "\n", "print(\"Random Forest default:\\t{0}\\nRandom Forest grid:\\t{1}\".format(RandomForest_score.mean(), RandomForest_grid_score.mean()))\n", "model_scores['Random Forest'] = RandomForest_grid_score"], "metadata": {"collapsed": true, "_uuid": "986f1652ba7f4916bc75d8f9ae984606548064dd", "_cell_guid": "65f9eb6e-7349-4985-96c0-e1508c0810e7"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["plt.figure(figsize = (18, 7))\n", "sns.barplot(x = X.keys(), y = RandomForest_grid.feature_importances_, alpha = alpha)\n", "plt.title(\"Feature importance for Random Forest classifier\");"], "metadata": {"collapsed": true, "_uuid": "8f19d8d9cdd2762ca92981b899173a0a9cbe2932", "_cell_guid": "b1ab4954-8bbe-4123-b081-cc2fadcf0d56"}}, {"cell_type": "markdown", "source": ["### 2.4.3 Boosting\n", "\n", "#### ADA Boosting"], "metadata": {"_uuid": "f399dfe378c99ceb1b5e2917528e5a733e47792d", "_cell_guid": "c0379b4d-a5f9-4240-a2ce-7b800751bb89"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["# Default parameter model\n", "ADA = ensemble.AdaBoostClassifier()\n", "\n", "# Grid search parameter model\n", "ada_params = {'n_estimators': grid_n_estimator,\n", "              'learning_rate': grid_learn,\n", "              'random_state': grid_seed}\n", "\n", "ADA_grid = GridSearchCV(ensemble.AdaBoostClassifier(), \n", "                                 param_grid=ada_params,\n", "                                 cv = cross_vals, \n", "                                 scoring = 'roc_auc')\n", "ADA_grid = ADA_grid.fit(X, y).best_estimator_\n", "\n", "ADA_score      = cross_val_score(ADA, X, y, scoring='accuracy', cv=cross_vals)\n", "ADA_grid_score = cross_val_score(ADA_grid, X, y, scoring='accuracy', cv=cross_vals)\n", "\n", "\n", "print(\"ADA Boosting default:\\t{0}\\nADA Boosting grid:\\t{1}\".format(ADA_score.mean(), ADA_grid_score.mean()))\n", "model_scores['ADA Boosting'] = ADA_grid_score"], "metadata": {"collapsed": true, "_uuid": "49e8327e4edeafb6c274f8070af899d0fc15184c", "_cell_guid": "3fd755e2-a1dc-48be-8acb-937646743493"}}, {"cell_type": "markdown", "source": ["#### Gradient Boosting"], "metadata": {"_uuid": "55daba8e79e0496ac92b840a070d327a114b04e9", "_cell_guid": "6797cab2-db71-4dbc-a70d-2a1caebca257"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["# Default parameter model\n", "GB =  ensemble.GradientBoostingClassifier()\n", "\n", "# Grid search parameter model\n", "gb_params = {'learning_rate': [.05], \n", "              'n_estimators': [300],\n", "              'max_depth': grid_max_depth,\n", "              'random_state': grid_seed}\n", "\n", "GB_grid = GridSearchCV(ensemble.GradientBoostingClassifier(), \n", "                                 param_grid = gb_params,\n", "                                 cv = cross_vals, \n", "                                 scoring = 'roc_auc')\n", "GB_grid = GB_grid.fit(X, y).best_estimator_\n", "\n", "GB_score      = cross_val_score(GB, X, y, scoring='accuracy', cv=cross_vals)\n", "GB_grid_score = cross_val_score(GB_grid, X, y, scoring='accuracy', cv=cross_vals)\n", "\n", "\n", "print(\"Gradient Boosting default:\\t{0}\\nGradient Boosting grid:\\t{1}\".format(GB_score.mean(), GB_grid_score.mean()))\n", "model_scores['Gradient Boosting'] = GB_grid_score"], "metadata": {"collapsed": true, "_uuid": "a76684a08e38180cdb1f45ae778a8df7804b9449", "_cell_guid": "03e471d6-2eb1-4796-a394-dcdcb7fb48ee"}}, {"cell_type": "markdown", "source": ["#### Extreme Gradient Boosting"], "metadata": {"_uuid": "6abd41f0032a30ddc5797bf199417e332bed15d1", "_cell_guid": "ce0420ee-da4f-49f6-b32b-e103f8735353"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["xboost = xgb.XGBClassifier()\n", "\n", "knn.fit(X, y)\n", "knn_out_train = knn.predict(X)\n", "\n", "dtree = tree.DecisionTreeClassifier()\n", "dtree.fit(X, y)\n", "clf_out_train = dtree.predict(X)\n", "\n", "LR.fit(X, y)\n", "LR_out_train = LR.predict(X)\n", "\n", "\n", "GB.fit(X, y)\n", "ABC_out_train = GB.predict(X)\n", "\n", "ETree.fit(X, y)\n", "ETree_out_train = ETree.predict(X)\n", "\n", "RandomForest.fit(X, y)\n", "RandomForest_out_train = RandomForest.predict(X)\n", "\n", "\n", "classifier_train_matrix = np.concatenate((knn_out_train.reshape(-1, 1), clf_out_train.reshape(-1, 1), ETree_out_train.reshape(-1, 1), \n", "                                    RandomForest_out_train.reshape(-1, 1), LR_out_train.reshape(-1, 1), ABC_out_train.reshape(-1, 1)), axis=1)\n", "\n", "\n", "xgb_params = {'learning_rate': [0.2, 0.4], \n", "              'n_estimators': [100, 1000],\n", "              'max_depth': [2, 4, 6, 8, 10]}\n", "\n", "XGB_grid = GridSearchCV(xgb.XGBClassifier(), \n", "                                 param_grid = xgb_params,\n", "                                 cv = cross_vals, \n", "                                 scoring = 'roc_auc')\n", "\n", "XGBx_grid = GridSearchCV(xgb.XGBClassifier(), \n", "                                 param_grid = xgb_params,\n", "                                 cv = cross_vals, \n", "                                 scoring = 'roc_auc')\n", "\n", "XGB_grid = XGB_grid.fit(X,y).best_estimator_\n", "\n", "XGBx_grid = XGBx_grid.fit(classifier_train_matrix,y).best_estimator_\n", "\n", "XGB_score      = cross_val_score(xboost, X, y, scoring='accuracy', cv=cross_vals)\n", "XGB_grid_score = cross_val_score(XGB_grid, X, y, scoring='accuracy', cv=cross_vals)\n", "\n", "XGBx_score     = cross_val_score(xboost, classifier_train_matrix, y, scoring='accuracy', cv=cross_vals)\n", "XGBx_grid_score = cross_val_score(XGB_grid, classifier_train_matrix, y, scoring='accuracy', cv=cross_vals)\n", "\n", "print(\"XGBoost default:\\t{0}\\nXGBoost grid:\\t{1}\".format(XGB_score.mean(), XGB_grid_score.mean()))\n", "model_scores['XGBoost'] = XGB_grid_score\n", "\n", "print(\"XGBoost extra default:\\t{0}\\nXGBoost grid:\\t{1}\".format(XGBx_score.mean(), XGBx_grid_score.mean()))\n", "model_scores['XGBoost Extra'] = XGBx_grid_score"], "metadata": {"collapsed": true, "_uuid": "d3f1d5a8363d34b6ed2e307d8570e78043187d92", "_cell_guid": "5a31654a-4116-418c-bfbb-cb99eaeca746"}}, {"cell_type": "markdown", "source": ["### 2.4.4 Voting Methods"], "metadata": {"_uuid": "8adacbc7c2e4ffa6a65bbf0ac6b46cf19c48e9ed", "_cell_guid": "a5df5405-de13-4579-a9a8-f92c3fbc32ce"}}, {"cell_type": "markdown", "source": ["#### Hard / Soft Voting"], "metadata": {"_uuid": "eedfa44722936043dcaf7e30d9cf2d9454b2cdf5", "_cell_guid": "409023c5-f60e-42e5-a591-7dc4d7aedbb8"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["vote_est = [\n", "    ('ada', ensemble.AdaBoostClassifier()),\n", "    ('etc', ensemble.ExtraTreesClassifier()),\n", "    ('gbc', ensemble.GradientBoostingClassifier()),\n", "    ('rfc', ensemble.RandomForestClassifier()),\n", "    ('lr',  linear_model.LogisticRegressionCV()),\n", "    ('knn', neighbors.KNeighborsClassifier()),\n", "    ('xgb', xgb.XGBClassifier())\n", "]\n", "\n", "vote_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')\n", "vote_hard_score = cross_val_score(vote_hard, X, y, cv  = cross_vals)\n", "model_scores['Voting Hard'] = vote_hard_score\n", "\n", "vote_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')\n", "vote_soft_score = cross_val_score(vote_soft, X, y, cv  = cross_vals)\n", "model_scores['Voting Soft'] = vote_hard_score\n", "\n", "print(\"Hard vote score: {0}\\nSoft vote score: {1}\".format(vote_hard_score.mean(), vote_soft_score.mean()))"], "metadata": {"collapsed": true, "_uuid": "51ed96fd68982ac5d993a0df14d9fac0aabb4f21", "_cell_guid": "a8c026a7-a18b-435b-98f8-182c26b59392"}}, {"cell_type": "markdown", "source": ["#### Hard / Soft voting, Parameter Search"], "metadata": {"_uuid": "93e9dc0dab7a236eab202d1ee61109f8121bb9aa", "_cell_guid": "46b1b199-c50a-4415-93bf-2323daeaf84f"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["vote_est_grid = [\n", "     ('ada', ADA_grid),\n", "     ('etc', ETree_grid),\n", "     ('gbc', GB_grid),\n", "     ('rfc', RandomForest_grid),\n", "     ('lr',  LR_grid),\n", "     ('knn', knn_grid),\n", "     ('xgb', XGB_grid),\n", "     ('xgb extra', XGBx_grid)\n", "]\n", "\n", "vote_hard_grid = ensemble.VotingClassifier(estimators = vote_est_grid, voting = 'hard')\n", "vote_hard_grid_score = cross_val_score(vote_hard_grid, X, y, cv  = cross_vals)\n", "model_scores['Voting Hard Grid'] = vote_hard_grid_score\n", "\n", "vote_soft_grid = ensemble.VotingClassifier(estimators = vote_est_grid, voting = 'soft')\n", "vote_soft_grid_score = cross_val_score(vote_soft_grid, X, y, cv  = cross_vals)\n", "model_scores['Voting Soft Grid'] = vote_soft_grid_score\n", "\n", "print(\"Hard vote score: {0}\\nSoft vote score: {1}\".format(vote_hard_grid_score.mean(), vote_soft_grid_score.mean()))"], "metadata": {"collapsed": true, "_uuid": "295631a521edff06a122cefcc1dc0068edaff7a9", "_cell_guid": "70af82b1-dbf5-4615-962f-1e47573d048c"}}, {"cell_type": "markdown", "source": ["### 2.4.5 Stacking"], "metadata": {"_uuid": "6da2617584473cebb42402d359343e9480574f59", "_cell_guid": "9c3b1a8f-e0e4-4705-8c4f-b5bcfa417be2"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["# Make a list containing all models\n", "models = [a[1] for a in vote_est]\n", "\n", "# 1st layer train\n", "S_train, S_test = stacking(models, X.as_matrix(), y.as_matrix(), test.as_matrix(), \n", "                           regression = False,\n", "                           n_folds = 2,\n", "                           random_state = 1)\n", "\n", "# 2nd layer train using random forest\n", "clf = ensemble.RandomForestClassifier()\n", "clf.fit(S_train, y.as_matrix())\n", "\n", "\n", "model_scores['Stacking'] = cross_val_score(clf, X, y, cv=cross_vals)\n", "\n", "print(model_scores['Stacking'].mean())"], "metadata": {"collapsed": true, "_uuid": "0da8ff26a2324f022f57ae277fc8a78114d2e2e2", "_cell_guid": "c4036d9c-468d-42ba-af8e-f938aa873076"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": [], "metadata": {"collapsed": true, "_uuid": "1831306cbe6256fb09aa855051f6bd7dc8c35f0c", "_cell_guid": "8dcda783-2cdb-41db-a2a6-4627a0f4c1ca"}}, {"cell_type": "markdown", "source": ["# 3. Evaluation\n", "\n", "## 3.1 Acurracy"], "metadata": {"_uuid": "fc8d9c755983c29ffc7777319aa6fedf5fc1b301", "_cell_guid": "cb66926a-33f2-49ca-8340-6af0b6980aa9"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["plt.figure(figsize = (18, 8))\n", "\n", "scores = {key : val.mean() for key, val in model_scores.items()}\n", "algos = sorted(scores, key = scores.get, reverse=True)\n", "algos_scores = [scores[x] for x in algos]\n", "\n", "stds   = [model_scores[x].std() for x in algos]\n", "\n", "sns.barplot(y = algos, x = algos_scores, color='Blue', alpha=alpha, xerr=stds)\n", "plt.xlim(0, 0.9)\n", "plt.show()\n", "scores.keys()"], "metadata": {"collapsed": true, "_uuid": "6697079397456805183a3ca5c5531c919e5392d8", "_cell_guid": "5c779c91-8448-43e9-ae35-4d024b5408b2"}}, {"cell_type": "markdown", "source": ["## 3.2 Model Correlations"], "metadata": {"_uuid": "c1140ad2d1cac4d99cc8fa79e0a2064f455c8837", "_cell_guid": "c9c50b13-5723-46f5-8ac3-b879d965f6bb"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["# k_out_train\n", "# clf_out_train\n", "# ETree_out_train\n", "# RandomForest_out_train\n", "# LR_out_train\n", "# ABC_out_train\n", "\n", "train_output_matrix = np.array([y, knn_out_train, clf_out_train, ETree_out_train, RandomForest_out_train, LR_out_train, ABC_out_train])\n", "train_output_corr = np.corrcoef(train_output_matrix)\n", "\n", "labels = ['Training', 'KNN', 'DecisionTree', 'ExtraTrees', 'RandomForest', 'Log Regression', 'GradientBoosting']\n", "\n", "plt.figure(figsize = (18, 8))\n", "sns.heatmap(train_output_corr, cmap=pearson_colors, annot=train_output_corr, xticklabels=labels, yticklabels=labels, linewidths=1, vmin=-1, vmax=1);\n", "plt.yticks(rotation=0)\n", "plt.show()"], "metadata": {"collapsed": true, "_uuid": "55cb32f04210ef92fce71bf871dd86dd2e3facb7", "_cell_guid": "70324ec1-1052-4f0b-b849-532d609d4a1e"}}, {"cell_type": "markdown", "source": ["## 3.3 Custom features per classifier\n", "\n", "This section is about checking each different features for each individual model. The overal accuracies have been printed, but it is noticeable that they do not improve the previous score. Previously we used backward selection of features, starting with all and removing one by one untill the accuracy improves significantly."], "metadata": {"_uuid": "98b53d51846db13fd199669435dfdfd4f27a9b27", "_cell_guid": "893f3b54-70f9-4d65-9fd4-2e4962e89659"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["features_used = ['Pclass', 'SexBinary', 'AgeGroup', 'DiscreteTitle', 'FareBinned']\n", "X = train[features_used]\n", "test = testing[features_used]\n", "\n", "knn = neighbors.KNeighborsClassifier(n_neighbors=6, weights='distance')\n", "knn.fit(X, y)\n", "k_out= knn.predict(test)\n", "xk_out = knn.predict(X)\n", "\n", "print(cross_val_score(knn, X, y, scoring='accuracy', cv=7).mean())\n", "\n", "############################################################################################\n", "\n", "features_used = ['EmbarkedDiscrete', 'Pclass', 'SexBinary', 'AgeGroup', 'DiscreteTitle', 'FamilySize', 'FareBinned']\n", "X = train[features_used]\n", "test = testing[features_used]\n", "knn.fit(X, y)\n", "\n", "print(cross_val_score(knn, X, y, scoring='accuracy', cv=7).mean())"], "metadata": {"collapsed": true, "_uuid": "f896227091b5f88c1bd5f869a9bd995d1ee34e8a", "_cell_guid": "600f0b44-80df-4d2e-bdb7-56809784745c"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["features_used =  ['Pclass', 'SexBinary', 'AgeGroup', 'DiscreteTitle', 'FamilySize']\n", "X = train[features_used]\n", "test = testing[features_used]\n", "\n", "clf = tree.DecisionTreeClassifier()\n", "clf.fit(X, y)\n", "clf_out= clf.predict(test)\n", "xclf_out = clf.predict(X)\n", "\n", "print(cross_val_score(clf, X, y, scoring='accuracy', cv=5).mean())\n", "\n", "############################################################################################\n", "\n", "features_used = ['EmbarkedDiscrete', 'Pclass', 'SexBinary', 'AgeGroup', 'DiscreteTitle', 'FamilySize', 'FareBinned']\n", "X = train[features_used]\n", "test = testing[features_used]\n", "clf.fit(X, y)\n", "\n", "print(cross_val_score(clf, X, y, scoring='accuracy', cv=5).mean())"], "metadata": {"collapsed": true, "_uuid": "d9a6052e56e6743db7b5ba17828d25d0078d98b6", "_cell_guid": "0d7fe236-6b47-4d81-9dbc-0a4647161ce1"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["features_used = ['EmbarkedDiscrete', 'Pclass', 'SexBinary', 'AgeGroup', 'FamilySize', 'FareBinned']\n", "X = train[features_used]\n", "test = testing[features_used]\n", "\n", "LR = linear_model.LogisticRegression()\n", "LR.fit(X, y)\n", "LR_out = LR.predict(test)\n", "xLR_out = LR.predict(X)\n", "\n", "print(cross_val_score(LR, X, y, scoring='accuracy', cv=5).mean())\n", "\n", "#############################################################################################\n", "\n", "features_used = ['EmbarkedDiscrete', 'Pclass', 'SexBinary', 'AgeGroup', 'DiscreteTitle', 'FamilySize', 'FareBinned']\n", "X = train[features_used]\n", "test = testing[features_used]\n", "LR.fit(X,y)\n", "\n", "print(cross_val_score(LR, X, y, scoring='accuracy', cv=5).mean())"], "metadata": {"collapsed": true, "_uuid": "13a9807167d9347083954ac425de39828eb7cd7a", "_cell_guid": "456d0520-1dfa-49e5-9c57-3dc34bb01096"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["features_used = ['SexBinary', 'AgeGroup', 'FamilySize']\n", "X = train[features_used]\n", "test = testing[features_used]\n", "\n", "RandomForest = ensemble.RandomForestClassifier()\n", "RandomForest.fit(X, y)\n", "R_out = RandomForest.predict(test)\n", "xR_out = RandomForest.predict(X)\n", "\n", "print(cross_val_score(RandomForest, X, y, scoring='accuracy', cv=5).mean())\n", "\n", "#############################################################################################\n", "\n", "features_used = ['EmbarkedDiscrete', 'Pclass', 'SexBinary', 'AgeGroup', 'DiscreteTitle', 'FamilySize', 'FareBinned']\n", "X = train[features_used]\n", "test = testing[features_used]\n", "RandomForest.fit(X, y)\n", "\n", "print(cross_val_score(RandomForest, X, y, scoring='accuracy', cv=5).mean())"], "metadata": {"collapsed": true, "_uuid": "365be740f2217134711ce188e8f24b24d4d32d4a", "_cell_guid": "3471eda3-ba99-4582-b0df-e0c87627a531"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["features_used = ['Pclass', 'SexBinary', 'DiscreteTitle', 'FamilySize']\n", "X = train[features_used]\n", "test = testing[features_used]\n", "\n", "xboost = xgb.XGBClassifier(max_depth = 2, learning_rate = 0.1, n_estimators = 150)\n", "xboost.fit(X, y)\n", "x_out = xboost.predict(test)\n", "xx_out = xboost.predict(X)\n", "\n", "print(cross_val_score(xboost, X, y, cv = 5).mean())\n", "\n", "#############################################################################################\n", "\n", "features_used = ['EmbarkedDiscrete', 'Pclass', 'SexBinary', 'AgeGroup', 'DiscreteTitle', 'FamilySize', 'FareBinned']\n", "X = train[features_used]\n", "test = testing[features_used]\n", "xboost.fit(X, y)\n", "\n", "print(cross_val_score(xboost, X, y, cv = 5).mean())"], "metadata": {"collapsed": true, "_uuid": "562f761bf819bae3c27ed4aeeb395028ae2c99a8", "_cell_guid": "72cb82ee-ed70-414c-86fa-ccb902741498"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["features_used = ['Pclass', 'SexBinary', 'AgeGroup', 'DiscreteTitle', 'FamilySize']\n", "X = train[features_used]\n", "test = testing[features_used]\n", "\n", "ETree = ensemble.ExtraTreesClassifier(n_estimators=7)\n", "ETree.fit(X, y)\n", "E_out = ETree.predict(test)\n", "xE_out = ETree.predict(X)\n", "\n", "print(cross_val_score(ETree, X, y, scoring='accuracy', cv=5).mean())\n", "\n", "#############################################################################################\n", "\n", "features_used = ['EmbarkedDiscrete', 'Pclass', 'SexBinary', 'AgeGroup', 'DiscreteTitle', 'FamilySize', 'FareBinned']\n", "X = train[features_used]\n", "test = testing[features_used]\n", "ETree.fit(X, y)\n", "\n", "print(cross_val_score(ETree, X, y, scoring='accuracy', cv=5).mean())"], "metadata": {"collapsed": true, "_uuid": "c7a23a581000d92b967d622c37394383dc229b99", "_cell_guid": "6b677e46-deef-412b-9410-ec9614081799"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["features_used = ['SexBinary', 'AgeGroup','FamilySize']\n", "X = train[features_used]\n", "test = testing[features_used]\n", "\n", "ABC = ensemble.GradientBoostingClassifier()\n", "ABC.fit(X, y)\n", "ABC_out = ABC.predict(test)\n", "xABC_out = ABC.predict(X)\n", "\n", "print(cross_val_score(ABC, X, y, scoring='accuracy', cv=5).mean())\n", "\n", "#############################################################################################\n", "\n", "features_used = ['EmbarkedDiscrete', 'Pclass', 'SexBinary', 'AgeGroup', 'DiscreteTitle', 'FamilySize', 'FareBinned']\n", "X = train[features_used]\n", "test = testing[features_used]\n", "ABC.fit(X, y)\n", "\n", "print(cross_val_score(ABC, X, y, scoring='accuracy', cv=5).mean())"], "metadata": {"collapsed": true, "_uuid": "b9b9cf2484b4e6529bb94e0e1b4acb81dba761d3", "_cell_guid": "da626951-b339-42d0-9692-95513d6b0a36"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["x_out_matrix = np.concatenate((xk_out.reshape(-1, 1), xclf_out.reshape(-1, 1), xE_out.reshape(-1, 1), \n", "                                    xR_out.reshape(-1, 1), xLR_out.reshape(-1, 1), xABC_out.reshape(-1, 1)), axis=1)\n", "\n", "\n", "out_matrix = np.concatenate((k_out.reshape(-1, 1), clf_out.reshape(-1, 1), E_out.reshape(-1, 1), \n", "                                    R_out.reshape(-1, 1), LR_out.reshape(-1, 1), ABC_out.reshape(-1, 1)), axis=1)\n", "\n", "XGB_out = xgb.XGBClassifier()\n", "XGB_out.fit(x_out_matrix, y)\n", "print(cross_val_score(XGB_out, x_out_matrix, y, cv = 5).mean())\n", "\n", "# create_csv(XGB_out.predict(out_matrix), 'XGB_customfeat_results.csv', testing)\n", "# ==> 0.77511 Kaggle"], "metadata": {"collapsed": true, "_uuid": "82db1d470bccab930accc9198d51c903afa40020", "_cell_guid": "9f182b63-4ece-4074-8a48-fdec34303753"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["hardvote_y = np.zeros(len(out_matrix), dtype = 'int')\n", "hardvote_y\n", "\n", "for i in range(len(out_matrix)):\n", "    hardvote_y[i] = np.bincount(out_matrix[i]).argmax()\n", "\n", "# create_csv(hardvote_y, 'HardVote_customfeat_results.csv', testing)\n", "# ==> 0.78947 Kaggle"], "metadata": {"collapsed": true, "_uuid": "efe76bc15e4e14da2c7e4ba638b48edbe35c4e38", "_cell_guid": "ef698cc9-869e-43df-b6c7-a4a798294fc0"}}, {"cell_type": "markdown", "source": ["Stacking and Random Forest granted the highest Kaggle scores, both coming in at 0.80382.\n", "\n", "By the way, we checked both the training and the test set and there were no Jack or Rose aboard the Titanic. We feel incredibly let down by James Cameron. "], "metadata": {"_uuid": "7bf28ec3689441d9b960fa9789c1e59186928d1d", "_cell_guid": "f0cb7879-72a5-4a14-80ae-21596ed75ecc"}}]}