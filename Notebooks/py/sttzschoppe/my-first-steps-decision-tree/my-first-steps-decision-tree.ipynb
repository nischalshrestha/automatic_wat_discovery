{"nbformat_minor": 1, "metadata": {"language_info": {"mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.3", "pygments_lexer": "ipython3"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "cells": [{"execution_count": null, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "%matplotlib inline\n", "import matplotlib.pyplot as plt\n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "from sklearn import tree\n", "from sklearn.tree import DecisionTreeClassifier\n", "\n", "#Common Model Helpers\n", "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n", "from sklearn import feature_selection\n", "from sklearn import model_selection\n", "from sklearn import metrics\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output.\n", "\n"], "metadata": {"collapsed": true, "_uuid": "ac30640f8549adfb75a89a6116a9136b01014626", "_cell_guid": "4dbdb9f1-f876-4d37-a1c5-dd44fba423a8"}, "cell_type": "code", "outputs": []}, {"source": [], "metadata": {"_uuid": "7ce6f36525596eac1fd68aa9b430a89d7c6858ea", "_cell_guid": "4bd5cd2f-f264-4e98-8555-2548cb5ea01a"}, "cell_type": "markdown"}, {"execution_count": null, "source": ["train = pd.read_csv(\"../input/train.csv\")\n", "test =  pd.read_csv(\"../input/test.csv\")\n", "\n", "#train.head()\n"], "metadata": {"collapsed": true, "_uuid": "f04b099d67102e4ff6ef697e4083ba0422e0cf33", "_kg_hide-output": false, "_kg_hide-input": false, "_cell_guid": "d449d1e6-fe28-4e77-988a-50a543a949fd"}, "cell_type": "code", "outputs": []}, {"execution_count": null, "source": ["all_data = pd.concat((train.loc[:,'Pclass':'Embarked'],\n", "                      test.loc[:,'Pclass':'Embarked']))\n", "all_data.info()\n", "#train.head()"], "metadata": {"collapsed": true, "_uuid": "8be3afadb297a00908827df909bbedc17f24c166", "_cell_guid": "3fb6ec91-60c1-477b-9cf9-11e5f619c472"}, "cell_type": "code", "outputs": []}, {"execution_count": null, "source": ["#filling NA's with the proper values for each column:\n", "all_data.Age = all_data.Age.fillna(all_data.Age.median())\n", "all_data.Fare = all_data.Fare.fillna(all_data.Fare.median())\n", "all_data.Embarked = all_data.Embarked.fillna(all_data.Embarked.mode()[0],)\n", "\n", "#all_data = all_data.fillna(all_data.mean())\n", "all_data.info()"], "metadata": {"collapsed": true, "_uuid": "744d5743b52dff6625bfb3fc86499ef861f29285", "_cell_guid": "7efe7134-8077-45e8-bd4a-dcfe322a7b26"}, "cell_type": "code", "outputs": []}, {"execution_count": null, "source": ["all_data['Title'] = all_data['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n", "#cleanup rare title names\n", "#print(data1['Title'].value_counts())\n", "stat_min = 10 #while small is arbitrary, we'll use the common minimum in statistics: http://nicholasjjackson.com/2012/03/08/sample-size-is-10-a-magic-number/\n", "title_names = (all_data['Title'].value_counts() < stat_min) #this will create a true false series with title name as index\n", "\n", "#apply and lambda functions are quick and dirty code to find and replace with fewer lines of code: https://community.modeanalytics.com/python/tutorial/pandas-groupby-and-python-lambda-functions/\n", "all_data['Title'] = all_data['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\n", "print(all_data['Title'].value_counts())\n", "\n", "all_data = all_data.drop(['Name'], axis=1)\n", "all_data = all_data.drop(['Ticket'], axis=1)\n", "all_data = all_data.drop(['Cabin'], axis=1)\n", "\n", "all_data.info()"], "metadata": {"collapsed": true, "_uuid": "b4ca65cebcd66bd1efbc513b5c4933305986c7a1", "_cell_guid": "917e5213-309c-43bb-bda3-2951773a3d16"}, "cell_type": "code", "outputs": []}, {"execution_count": null, "source": ["all_data = pd.get_dummies(all_data)\n", "\n", "all_data.head()"], "metadata": {"collapsed": true, "_uuid": "4c9b1256147778fc09076af5a98b2b60a552c8a3", "_cell_guid": "a17f2809-de8b-4f98-aebe-ea96e3294f02"}, "cell_type": "code", "outputs": []}, {"execution_count": null, "source": ["#split dataset in cross-validation with this splitter class: \n", "#http://scikit-learn.org/stable/modules/generated/\n", "#sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n", "#note: this is an alternative to train_test_split\n", "cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, \n", "                                        train_size = .6, random_state = 0 ) \n", "# run model 10x with 60/30 split intentionally leaving out 10%"], "metadata": {"collapsed": true, "_uuid": "a708b6b3ba4be6f7c8a1d476424419c6acde4827", "_cell_guid": "cf99cb17-f4b5-44c7-9c7e-77739c4e8e39"}, "cell_type": "code", "outputs": []}, {"execution_count": null, "source": ["train_cleared = all_data[:train.shape[0]]\n", "train_cleared.info()\n", "\n", "from sklearn.model_selection import train_test_split\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(\n", "train_cleared, train.Survived, random_state=0, test_size=0.1)\n", "\n", "X_train.info()\n", "\n", "X_val = all_data[train.shape[0]:]\n", "X_val.info()"], "metadata": {"collapsed": true, "_uuid": "8eb70673c00ac3648cc8c32d321363e14794daf3", "_cell_guid": "c4e2712e-adff-42ce-a643-24f7c011df23"}, "cell_type": "code", "outputs": []}, {"execution_count": null, "source": ["#base model\n", "dtree = tree.DecisionTreeClassifier(random_state = 0)\n", "base_results = model_selection.cross_validate(dtree, train_cleared, train.Survived, cv  = cv_split, return_train_score=True)\n", "dtree.fit(train_cleared, train.Survived)\n", "\n", "print('BEFORE DT Parameters: ', dtree.get_params())\n", "print(\"BEFORE DT Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \n", "print(\"BEFORE DT Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\n", "print(\"BEFORE DT Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\n", "#print(\"BEFORE DT Test w/bin set score min: {:.2f}\". format(base_results['test_score'].min()*100))\n", "print('-'*10)\n", "\n", "\n", "#tune hyper-parameters: http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n", "param_grid = {'criterion': ['gini', 'entropy'],  #scoring methodology; two supported formulas for calculating information gain - default is gini\n", "              #'splitter': ['best', 'random'], #splitting methodology; two supported strategies - default is best\n", "              'max_depth': [2,4,6,8,10,None], #max depth tree can grow; default is none\n", "              #'min_samples_split': [2,5,10,.03,.05], #minimum subset size BEFORE new split (fraction is % of total); default is 2\n", "              #'min_samples_leaf': [1,5,10,.03,.05], #minimum subset size AFTER new split split (fraction is % of total); default is 1\n", "              #'max_features': [None, 'auto'], #max features to consider when performing split; default none or all\n", "              'random_state': [0] #seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\n", "             }\n", "\n", "#print(list(model_selection.ParameterGrid(param_grid)))\n", "\n", "#choose best model with grid_search: #http://scikit-learn.org/stable/modules/grid_search.html#grid-search\n", "#http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n", "tune_model = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, \n", "                                          scoring = 'roc_auc', cv = cv_split, return_train_score=True)\n", "tune_model.fit(train_cleared, train.Survived)\n", "\n", "#print(tune_model.cv_results_.keys())\n", "#print(tune_model.cv_results_['params'])\n", "print('AFTER DT Parameters: ', tune_model.best_params_)\n", "#print(tune_model.cv_results_['mean_train_score'])\n", "print(\"AFTER DT Training w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100)) \n", "#print(tune_model.cv_results_['mean_test_score'])\n", "print(\"AFTER DT Test w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\n", "print(\"AFTER DT Test w/bin score 3*std: +/- {:.2f}\". format(tune_model.cv_results_['std_test_score'][tune_model.best_index_]*100*3))\n", "print('-'*10)"], "metadata": {"collapsed": true, "_uuid": "502cec489d6deaf5c6db9209b2c65042972f7cbe", "_cell_guid": "82855d54-37dc-4f52-bfe1-4662319070db"}, "cell_type": "code", "outputs": []}, {"execution_count": null, "source": ["#base model\n", "print('BEFORE DT RFE Training Shape Old: ', train_cleared.shape) \n", "print('BEFORE DT RFE Training Columns Old: ', train_cleared.columns.values)\n", "\n", "print(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \n", "print(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\n", "print(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\n", "print('-'*10)\n", "\n", "\n", "\n", "#feature selection\n", "dtree_rfe = feature_selection.RFECV(dtree, step = 1, scoring = 'accuracy', cv = cv_split)\n", "dtree_rfe.fit(train_cleared, train.Survived)\n", "\n", "#transform x&y to reduced features and fit new model\n", "#alternative: can use pipeline to reduce fit and transform steps: http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n", "X_rfe = train_cleared.columns.values[dtree_rfe.get_support()]\n", "rfe_results = model_selection.cross_validate(dtree, train_cleared[X_rfe], train.Survived, cv  = cv_split)\n", "\n", "#print(dtree_rfe.grid_scores_)\n", "print('AFTER DT RFE Training Shape New: ', train_cleared[X_rfe].shape) \n", "print('AFTER DT RFE Training Columns New: ', X_rfe)\n", "\n", "print(\"AFTER DT RFE Training w/bin score mean: {:.2f}\". format(rfe_results['train_score'].mean()*100)) \n", "print(\"AFTER DT RFE Test w/bin score mean: {:.2f}\". format(rfe_results['test_score'].mean()*100))\n", "print(\"AFTER DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(rfe_results['test_score'].std()*100*3))\n", "print('-'*10)\n", "\n", "\n", "#tune rfe model\n", "rfe_tune_model = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring = 'roc_auc', cv = cv_split)\n", "rfe_tune_model.fit(train_cleared[X_rfe], train.Survived)\n", "\n", "#print(rfe_tune_model.cv_results_.keys())\n", "#print(rfe_tune_model.cv_results_['params'])\n", "print('AFTER DT RFE Tuned Parameters: ', rfe_tune_model.best_params_)\n", "#print(rfe_tune_model.cv_results_['mean_train_score'])\n", "print(\"AFTER DT RFE Tuned Training w/bin score mean: {:.2f}\". format(rfe_tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100)) \n", "#print(rfe_tune_model.cv_results_['mean_test_score'])\n", "print(\"AFTER DT RFE Tuned Test w/bin score mean: {:.2f}\". format(rfe_tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\n", "print(\"AFTER DT RFE Tuned Test w/bin score 3*std: +/- {:.2f}\". format(rfe_tune_model.cv_results_['std_test_score'][tune_model.best_index_]*100*3))\n", "print('-'*10)"], "metadata": {"collapsed": true, "_uuid": "9a63979004b14c18dd248e2e9720e03eab96c329", "_cell_guid": "474ffa0d-8bd8-4ea2-9797-e0bf603ca897"}, "cell_type": "code", "outputs": []}, {"execution_count": null, "source": ["model = DecisionTreeClassifier(random_state=0, max_depth=5)\n", "\n", "model.fit(X_train, y_train)\n", "print(\"Train score: {:.3f}\".format(model.score(X_train, y_train))) #0.869\n", "print(\"Test score: {:.3f}\".format(model.score(X_test, y_test))) #0.822\n", "decision_tree_predicts_base = model.predict(X_val)\n", "decision_tree_predicts_tuned_param = tune_model.predict(X_val)\n", "decision_tree_predicts_tuned_param_rfe = rfe_tune_model.predict(X_val[X_rfe])"], "metadata": {"collapsed": true, "_uuid": "54160c860dfbd6f09e303b9c70db2d23b8e55e4d", "_cell_guid": "c93e6a47-70de-4a73-b3fa-8eb6eb50de1c"}, "cell_type": "code", "outputs": []}, {"execution_count": null, "source": ["import graphviz \n", "dot_data = tree.export_graphviz(model, out_file=None, \n", "                         feature_names=list(train_cleared),    \n", "                         filled=True, rounded=True,  \n", "                         special_characters=True)  \n", "graph = graphviz.Source(dot_data)  \n", "graph"], "metadata": {"collapsed": true, "_uuid": "48d8a141fe5a51826e7ca0f3cf782412eb42a2d4", "_kg_hide-output": true, "_cell_guid": "3fb937c4-eed5-40f4-94bd-661c5ed1fa03"}, "cell_type": "code", "outputs": []}, {"execution_count": null, "source": ["result = pd.DataFrame({\"PassengerId\":test.PassengerId, \"Survived\":decision_tree_predicts_base})\n", "result.to_csv(\"DecisionTree_base.csv\", index = False)\n", "\n", "result = pd.DataFrame({\"PassengerId\":test.PassengerId, \"Survived\":decision_tree_predicts_tuned_param})\n", "result.to_csv(\"DecisionTree_tuned_Param.csv\", index = False)\n", "\n", "result = pd.DataFrame({\"PassengerId\":test.PassengerId, \"Survived\":decision_tree_predicts_tuned_param_rfe})\n", "result.to_csv(\"DecisionTree_tuned_Param_RFE.csv\", index = False)\n", "\n", "result.info()\n", "#print(check_output([\"ls\"]).decode(\"utf8\"))"], "metadata": {"collapsed": true, "_uuid": "669caecdf93c2ae88a91c0007f7f8a195d2a7301", "_cell_guid": "526614e8-d3a9-4056-80a2-84367aa03156"}, "cell_type": "code", "outputs": []}], "nbformat": 4}