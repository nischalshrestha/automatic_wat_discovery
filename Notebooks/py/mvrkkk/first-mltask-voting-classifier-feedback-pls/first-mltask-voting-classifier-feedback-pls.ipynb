{"cells":[{"metadata":{"_uuid":"213c6bb22f3c98b3784e04c0a22fecabf105ca58"},"cell_type":"markdown","source":"# Importing libraries"},{"metadata":{"_uuid":"48515f2649f7367eed535df36151a12b232e7c1d","trusted":true,"collapsed":true},"cell_type":"code","source":"# computation\nimport pandas as pd\nimport numpy as np\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# configuration\nsns.set_style('whitegrid')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bca4d6159a258e5f5b679b0dc3a54eadfa1998f8"},"cell_type":"markdown","source":"# Import data\n\nReading files with train/test data"},{"metadata":{"_uuid":"5a7c28fe49b932e71f353b83d1fbd9771b2caf8e","trusted":true},"cell_type":"code","source":"# getting path to train and test data\ntrain_data_path = '../input/train.csv'\ntest_data_path = '../input/test.csv'\n\ntrain = pd.read_csv(train_data_path,index_col=None)\ntest = pd.read_csv(test_data_path,index_col=None)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"690f2d4e32909f9236d030bdd3d0bdef010c7ccc"},"cell_type":"markdown","source":"# Getting know your data\n\nChecking a dtypes of variables and null values"},{"metadata":{"_uuid":"1498b4e3aaf796f3f4f49efc8a1936e6ab6bed61","trusted":true,"collapsed":true},"cell_type":"code","source":"print('====== Test data - info ======')\nprint(test.info())\nprint('\\n')\nprint('====== Train data - info ======')\nprint(train.info())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31d77dccca624e846ad40b4cd25f9a63c73d8c08"},"cell_type":"markdown","source":"# Filling a null values\n\nBased on dataframes info there is a lack of empty values, lets visualize them to better understand data"},{"metadata":{"_uuid":"13326d43d9ce7421787f237c4a46128b6a53f379","trusted":true,"collapsed":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,5), dpi = 100)\n\naxe1 = sns.heatmap(train.isnull(),\n            cmap = 'coolwarm',\n            yticklabels = False,\n            cbar = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02d10705a4d0ee9744eb4e40ecfe3e33f77829d6"},"cell_type":"markdown","source":"A simply but very informative kind of visualization shows as that there is a nan-values in Age, Cabin and Embarked features.\n\nFirst, lets deal with Age feat. To better fill nan values, lets fill them with average ages based on Pclasses.\n\nLets plot them to better understand distributions"},{"metadata":{"_uuid":"823113a9d0a313982da12b176802df6e614bb791","trusted":true,"collapsed":true},"cell_type":"code","source":"# define an age depending on Pclass\nsns.boxplot(data = train,x = 'Pclass',y = 'Age')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0245bac6690fc505f913240d4d5057c3f4f0fa26"},"cell_type":"markdown","source":"As shown above, we can define an average age for pclass 1 i approximately 37, for pclass 2 - 28-29 and for pclass 3 - 23-25.\n\nLets properly compute them and fill na values."},{"metadata":{"_uuid":"511abab0a949ff9796763604669601d290c9102d"},"cell_type":"markdown","source":"### Imputing null values"},{"metadata":{"_uuid":"ba53f4d1c5a1bdfb24ce47e67725e82ebf97708a","trusted":true,"collapsed":true},"cell_type":"code","source":"# gettina a unique list of classes\nclasses = train.Pclass.unique()\n\n# define a dict where class+age values will be stored\nclasses_mean_age = {}\n\n# filling our dictionary with mean ages for a particular class\nfor _ in classes:\n       classes_mean_age[_] = train[train['Pclass'] == _ ]['Age'].mean()\n\n# making a function to map values from dataframe with values from dictionary\ndef fill_na_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        for _ in classes_mean_age:\n            if Pclass == _:\n                Age = classes_mean_age[_]\n                return Age\n    else:\n        return Age\n\n# performing cleaning on train and test data\ntrain['Age'] = train[['Age','Pclass']].apply(fill_na_age,axis = 1)\ntest['Age'] = test[['Age','Pclass']].apply(fill_na_age,axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba6804d0c8f85921e8718f9360e4daecf3ed2795"},"cell_type":"markdown","source":"### Dropin' unnecessary features and feature generation"},{"metadata":{"_uuid":"ccf79bce5e09fd26f623d9bdea186f04701a3dec","trusted":true,"collapsed":true},"cell_type":"code","source":"# dropping cols and a na values\ntrain.drop(['PassengerId','Ticket','Cabin'],axis = 1,inplace = True)\ntrain.dropna(axis = 0,inplace=True)\n\ntest.drop(['Ticket','Cabin'],axis = 1,inplace = True)\ntest.dropna(axis = 0,inplace=True)\n\n# encoding features \nfrom sklearn.preprocessing import LabelEncoder\n\n# train\nencoder = LabelEncoder()\n\ntrain['Sex'] = encoder.fit_transform(train['Sex'])\ntrain['Embarked'] = encoder.fit_transform(train['Embarked'].astype(str))\ndummies_enbarked = pd.get_dummies(train['Embarked'],prefix='Emb',drop_first=True)\ntrain.drop('Embarked',1,inplace=True)\ntrain.join(dummies_enbarked)\n\n\ntest['Sex'] = encoder.fit_transform(test['Sex'])\ntest['Embarked'] = encoder.fit_transform(test['Embarked'])\ndummies_enbarked_test = pd.get_dummies(test['Embarked'], prefix='Emb',drop_first=True)\ntest.drop('Embarked',1,inplace=True)\ntest.join(dummies_enbarked_test)\n\n\n\n# Feature engineering and binning\ntrain['age_bin'] = encoder.fit_transform(pd.cut(train.Age,6))\ntest['age_bin'] = encoder.fit_transform(pd.cut(test.Age,6))\n\n\ntitle_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev',\n                    'Dr', 'Ms', 'Mlle','Col', 'Capt', 'Mme', 'Countess',\n                    'Don', 'Jonkheer']\n\npatern = '('+\"|\".join(title_list)+')'\n\n\ntrain['title'] = train['Name'].str.extract(patern)\ntest['title'] = test['Name'].str.extract(patern)\n\ndef replace_titles(x):\n    title=x['title']\n    if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col']:\n        return 'Mr'\n    elif title in ['Countess', 'Mme']:\n        return 'Mrs'\n    elif title in ['Mlle', 'Ms']:\n        return 'Miss'\n    elif title =='Dr':\n        if x['Sex']=='Male':\n            return 'Mr'\n        else:\n            return 'Mrs'\n    else:\n        return title\ntrain['title']=train.apply(replace_titles, axis=1)\ntest['title']=test.apply(replace_titles, axis=1)\n\ntrain['title'] = encoder.fit_transform(train['title'])\ntest['title'] = encoder.fit_transform(test['title'])\n\n\n\ntrain.drop('Name',1,inplace=True)\ntest.drop('Name',1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9b83bb8313bfb6e7dbf1bb03ca2a74fbd241fb0"},"cell_type":"markdown","source":"## Exploratory data analysis"},{"metadata":{"_uuid":"134559868088bf3fb4c10cc8082362b728b49699","trusted":true,"collapsed":true},"cell_type":"code","source":"# setting style\nplt.style.use('ggplot')\n\n# creating figure\nfig = plt.figure(figsize = (20,10))\n\n# creating axis\nax1 = plt.subplot2grid((3,3),(0,0))\nax2 = plt.subplot2grid((3,3),(0,1))\nax3 = plt.subplot2grid((3,3),(1,0))\nax4 = plt.subplot2grid((3,3),(1,1))\nax5 = plt.subplot2grid((3,3),(2,0),colspan =2)\n#ax6 = plt.subplot2grid((3,3),(0,2))\n#ax7 = plt.subplot2grid((3,3),(1,2))\n\n# Survival\ntrain.groupby('Survived').size().plot(kind='bar',\n                                      cmap = 'winter',\n                                      width = 0.8,\n                                      ax = ax1)\n# Survival by sex\ntrain.groupby(['Sex','Survived']).size().unstack().plot(kind='bar',\n                                                        width = 0.8,\n                                                        cmap = 'winter',\n                                                        ax = ax2)\n# Survival by Pclass\ntrain.groupby(['Pclass','Survived'])\\\n                .size()\\\n                .unstack()\\\n                .plot(kind='Bar',stacked = True,\n                width = 0.8,\n                cmap = 'winter',\n                ax = ax3)\n\n# Survival by gender and age distribution\ntrain[(train['Sex'] == 1) & (train['Survived'] == 0)]['Age'].plot('hist',\n                                                                       color = 'Blue',\n                                                                       alpha = 0.8,\n                                                                       ax=ax4,\n                                                                       label = 'Male / Died')\ntrain[(train['Sex'] == 0 ) & (train['Survived'] == 0)]['Age'].plot('hist',\n                                                                         color = 'lime',\n                                                                         alpha = 0.8,\n                                                                         ax=ax4,\n                                                                         label = 'Female / Died')\nax4.set_xlabel('Age')\nax4.legend()\n\n# Survival by sex and pclass\ntrain.groupby(['Sex','Pclass','Survived'])\\\n                .size()\\\n                .unstack()\\\n                .plot(kind='Bar',\n                stacked = True,width = 0.8,\n                cmap = 'winter',\n                ax = ax5)\n\ntrain\n\n# adding titles\nax1.set_title('Survivalness')\nax2.set_title('Survivalness by sex')\nax3.set_title('Survivalness by pclass')\nax4.set_title('Age distribution by sex - Died')\nax5.set_title('Survivalness by pclass and sex')\n\n# adding axes labels\naxes_list = [ax1,ax2,ax3,ax4,ax5]\n\nfor ax in axes_list:\n    ax.set_ylabel('# Of records')\n    \nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6635301d65fa08c756cb237357a36c41c318f726"},"cell_type":"markdown","source":"Notes from EDA:\n\n    - because this is binary classification problem, our shares of classes in train data are pretty balanced.\n    \n    - distribution of survivalness based on gender is shows us, that a lot of males died during titanic disaster. This is one of the strongest feature for predicion.\n    \n    - distribution of survivalness based on pclass shows that most of passanger of pclass 3 died more than other passanger.\n    - males with age from ~17 to 50 are more likely to die\n    - combining features gender + pclass - we can consider that female passangers + pclass 3 died most. Also, males from pclass 2 and 3 are died most of all."},{"metadata":{"_uuid":"79e1defc7dc79a285c906339c2aa468c30135876"},"cell_type":"markdown","source":"## Rescaling features"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"af047fb3d1fdd9c5b4037aff77c00b4caa570863"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nnorm = StandardScaler()\n\nX,y = train.iloc[:,1:],train['Survived']\n\n# scaling features\nX_sc = norm.fit_transform(X,y)\nX_sc_norm = pd.DataFrame(X_sc,columns=X.columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"728f8874a2055d157fd7e18de94c93b2bc382810","collapsed":true},"cell_type":"markdown","source":"## Building a model"},{"metadata":{"_uuid":"13d620332828f6245cef1d28f5b59d45e795df21"},"cell_type":"markdown","source":"### Training model"},{"metadata":{"_uuid":"de62b81fafc1ce0a240cf1a9cd2e5ca27e39a6b0","trusted":true,"collapsed":true},"cell_type":"code","source":"from sklearn.cross_validation import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import VotingClassifier, RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# split into train test\nX_train,X_test,y_train,y_test = train_test_split(X_sc_norm,y,test_size = 0.28,random_state = 111)\n\n# creating instances of models\ncf_lg = LogisticRegression(penalty='l2',class_weight='balanced',random_state=1)\ncf_rf = RandomForestClassifier(n_estimators=200,random_state=2)\ncf_gb = GaussianNB()\ncf_kn = KNeighborsClassifier(n_neighbors=3,p=2)\n\n# training ensemble of models\nelcf = VotingClassifier(estimators=[('Lg_cf',cf_lg),('rf',cf_lg),('gb',cf_gb),('kn',cf_kn)],voting='hard')\nelcf.fit(X_train,y_train)\n\n# making predictions\ny_pred = elcf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58d9aad1b03bd3535e0ffdd7d3389e0ee6be0287"},"cell_type":"markdown","source":"### Evaluating results"},{"metadata":{"_uuid":"ee9fe196b41eab7c7c85cbc646dd5fef44d1726f","scrolled":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n\nacc = accuracy_score(y_test,y_pred)\nreport = classification_report(y_test,y_pred)\nconf = confusion_matrix(y_test,y_pred)\n\nprint(conf)\nprint('\\n')\nprint('==========================Classification report=========================')\nprint(report)\nprint('Prediction accuracy:{0}'.format(acc))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4190a9d2cb1b944693b93341d19dd2869a26ef08"},"cell_type":"markdown","source":"### Prediction"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4ad49d20c09bad5f52fbd4de2b75fe1390e2afdd"},"cell_type":"code","source":"prediction = elcf.predict(test.drop('PassengerId',axis=1))\ntest['y_hat'] = prediction\n\nsubmission = test[['PassengerId','y_hat']]\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2c763f979aabd3ac348a138c51f9cf6e12614e9d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}