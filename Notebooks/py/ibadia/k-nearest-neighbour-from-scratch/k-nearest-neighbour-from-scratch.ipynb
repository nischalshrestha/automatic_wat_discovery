{"cells":[{"metadata":{"_cell_guid":"7245c1bc-f261-4bc9-a8a5-a72d435ec798","_uuid":"d9395b86d59a3530cbf47812b008900c189d65e0"},"cell_type":"markdown","source":"## In this notebook we are going to build a simple K Nearest Classifier from Scratch\n\n\n### and do a very bad prediction on titanic dataset. :D\nNOTE : THIS DOES NOT DO A GOOD PREDICTION ON DATASET, The purpose of this notebook is just to understand K Nearest Neighbor Classifier"},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false,"collapsed":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input/\"))\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":"So K nearest Neighbor is a simple algorithm which can be used to do classification on different data. To understand K Nearest Neighbour we just need to understand few simple things: \n1. Euclidean Distance (distance between two points in Graph)\n2. How voting works (literally)\n3. How to plot point (1,3) on a x,y plane graph\n4. How to plot (1,2,4) on a simple x,y,z graph\n\n\nNow without any issue lets come to the data, We will be using simple K nearest neighbor to find out that whether it is possible to find out that given a person Age and Fare can we predict that he will survive in the titanic or not.\n"},{"metadata":{"_cell_guid":"4d67eb7d-8bbc-4750-9359-717a596bacc3","_uuid":"b8c350f8c0d7f54b0cc53befe1feac419d7d0dce"},"cell_type":"markdown","source":"So First we will read the data,  The training data and lets look at the top5 rows of the data.\nTraining Data: Training data is the data we give to our Algorithm to learn with, Then we give our Algorithm the testing data. \nLets sayif i gave you some questions and answers like:\n\nX=[\n1+2=3\n\n2+3=5\n\n1+1=2]\n\n\nThen I ask you a question What is 33+3=?\n\nHere 33+3 is our testing data and X is our training data.\nWe train our model and test our model to see how many of the questions in test our model gave right answers to.\n\n\nJust like that in our dataset we will give our model a person Age and Fare along with the result that he/she survived or not.\n\nThen we will give our algorithm the testing data in which there will be Age and Fare and our model will predict whether the person survives or not.\n\nHave a look at a head which means top5 rows of our trainng data.\n"},{"metadata":{"_cell_guid":"4e6c0514-9039-46c0-8e80-2ad89bda88c7","_uuid":"69cae2126e7894dc51ce7576490229225768bd88","trusted":false,"collapsed":true},"cell_type":"code","source":"data=pd.read_csv(\"../input/train.csv\")[[\"Survived\",\"Age\",\"Fare\"]]\ndata=data.fillna(data.mean())\ndata.head()\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1880a132-af9b-4a91-8067-e5d1453a43de","_uuid":"321f3d7abcc3c85bcba400164f26cfff31d2c4e1"},"cell_type":"markdown","source":"As you can see in training data we gave the person age and fare and the result that whether the person survived or not. \n\n\nFor the test data we will just give the Age and Fare and let our algorithm decide that whether the person will survice or not.\nHere have a look at top5 rows of our testing data to get an idea of how our data is."},{"metadata":{"_cell_guid":"a5d2d97a-01fb-4a3d-a1b0-9eab42f4520f","_uuid":"3c282eda45618396d1f06f1182e0a6be12dabc56","collapsed":true,"trusted":false},"cell_type":"code","source":"passenger_id=pd.read_csv(\"../input/test.csv\")[\"PassengerId\"]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8889dfd0-473e-4012-8624-4edab445c304","_uuid":"3c3887fab034a49f59bf9f3ed50b9cdbd7f1b85e","collapsed":true,"trusted":false},"cell_type":"code","source":"test_data=pd.read_csv(\"../input/test.csv\")[[\"Age\",\"Fare\"]]\ntest_data=test_data.fillna(test_data.mean())\ntest_data.head()\ntest_data=test_data.values","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dfed9d04-eec1-4283-9c5d-84275e222b29","_uuid":"bb6126801ef83f3dc8e7d012321fbe80ab4f66ee"},"cell_type":"markdown","source":"Now that we have the training data in training_data, lets try to give it to our Algorithm to learn from that data\n\nNow we will start to understand the K Nearest Neighbor, \nFirst of all we will plot all points on a graph, How?\n\nOn X Axis we will put Age and on y axis we will put Fare\n\nExample, you look at the first sample and on that Age:22 and Fare:7.25, So we find 7.25 on x axis and 22 on y axis and put a dot (point) on the intersection\n\nExample"},{"metadata":{"_cell_guid":"9b6afdc4-2095-4938-a847-c68c4ef4d870","_uuid":"4701a27445d58c3a885653e9aa769d137a2e11b4","trusted":false,"collapsed":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.scatter( x=[7.25],y=[22])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"935ce6fd-b9a9-462a-b97b-c3a4524d17c1","_uuid":"3eb0a0f2dc3c1a598c72daa896e02f0d7ab85679"},"cell_type":"markdown","source":"Now how about we have 2 points Age:22 , Fare 7.25 and Age:30 and Fare: 19??\n"},{"metadata":{"_cell_guid":"7cfd8a69-4127-48f7-8ebf-b240e4d61847","_uuid":"3e5d613c8e8ce27496bf965524990712f3b9d80d","trusted":false,"collapsed":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.scatter( x=[7.25, 19],y=[22,30])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e26bb078-3e25-4691-becd-19524986d2f6","_uuid":"7ccacc5f10e65c30eaa3b214602496395350ccc3"},"cell_type":"markdown","source":"Just like that we will plot for all the data we have in data variable and the plot will look something like this."},{"metadata":{"_cell_guid":"5097c772-e4aa-4adb-84f4-f5948fe534c0","_uuid":"f8186b3db10afbe2912360623e07faca954fc2b4","trusted":false,"collapsed":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\ncol=data[\"Survived\"]\nplt.scatter( x=data[\"Fare\"],y=data[\"Age\"], c=col)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"041a1aa8-3be2-4c6d-8e5f-e971f92c6f2a","_uuid":"c8b603964154f15150aac252d3e54645d3148d38"},"cell_type":"markdown","source":"These points that we see on the graph are just GRAPHICAL representation of AGE AND FARE.Every single point over here corresponds to a row in our data, It corresponds to a sinlge person Age and Fare.\nHere Purple point implies that the person didnt survived and was dead in titanic and yellow point specifies that he is dead.\n### Fair enough, Now if I gave you a new Person AGE=30 and FARE=500, can you tell me whether he will survive by looking at the graph.\n### As the Name suggest K nearest neighbor just focus on the word Neighbor: \n#### What we will do is this that will will take a new person AGE and FARE, try to find the point on graph where x=500 and Y=30 and simply put the point(dot) there.\n\n#### We still have not predicted whether the person will survive or not, Try it your self look at the above graph and find a point where x=500 and y=35\n\n### If you have found the specified point, look for the point closest to that point?\n\n#### Now look at the color of the point closest to the point (x,y)=(500,30)?\n### What is the color?\n\n#### YELLOW, Since it is close (neighbor ) to the point which survived hence we can classify that the new person will survive the titanic.\n\n\n\n\n\n"},{"metadata":{"_cell_guid":"f6ef6a6f-6ea4-48d2-9d1e-2be136c3eea9","_uuid":"5cc33730d3912f50c6970d9036732b7a732c3cd1"},"cell_type":"markdown","source":"# Congratulations, We just learned how to classify using K Nearest Neighbor with k=1.\nNow what is k?\nRecall that the prerequisite for this kernel is this that you know how voting works. \nAssume that there are 3 people and two of them vote for Pizza and one of them votes for Burger. So by voting Pizza wins. \n\n\nSimilarly in K nearest neighbor we will do voting. \nHow?\nLets consider a new point 250,55.\nNow we will try to find out with k=5. \n\nWe will follow the same protocol we have followed before and find a point on graph where x=250 and y=55. \n\nNOW we find 5 colored points on graph closest to our new point!!.\nFair enough, \nAfter that we will look at the colors of the 5 nearest points to our new point.\nLets say we find 5 nearest points and 3 of them have a purple color and 2 of them have a yellow color. \n\nWhich means three of them died and 2 of them survived\n\nSadly our new point will be colored PURPLE and our algorithm says that new person will die. :(.\n\n\nJust like that if k=3, then we find two nearest points to our new point.\n\n\nWe dont choose k to be even number, guess why?\nBecause lets say we choose k=4 and the among the closest 4 points two of them are purple and two of them are yellow, What we will predict??.\n\n\n\nNow lets come to implementation, Now by looking at the graph we visually analyzed that so and so point are closer to the new point but programatically how we will do it\n\nWe will use simple Euclidean Distance, Now what is this?\nED is just a way of finding distance between two points in a graph\nE.G  P1=(1,25) and P2=(2,35)\n\nThen Euclidean distance =   sqrt (    (1-2)^2   +   (25-35)^2  )\n\n=sqrt(    1   +   100  )\n\n  =sqrt(    101)\n  \n  \n  \n  Now lets try to code it, Here is the thing, We have an X_train which have co-ordinates of all the current points whole labels we have and an array of new_points which have some new points.\n \n What we will do first is that we will find distance (EUCLIDEAN DISTANCE) using the formula specified  of the new point to all the current points.\n \n\n\n"},{"metadata":{"_cell_guid":"a2ce6342-d9ac-4176-971c-d7a8bea0b68e","_uuid":"3a90086980930716fb0b7af295ac05341aff2a30","collapsed":true,"trusted":false},"cell_type":"code","source":"def compute_distances_one_loop(new_points, X_train):\n    #X_Train have all of our training Samples, \n    # new_points is our new points which we want to predict\n    num_test = len(new_points)\n    num_train =X_train.shape[0]\n    dists = np.zeros((num_test, num_train))\n    for i in range(num_test):\n        \n        difference = new_points[i] - X_train\n        difference = np.square(difference)\n        sum1 = np.sum(difference, axis=1)\n        dists[i] = np.sqrt(sum1)\n    return dists","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b734ae58-f967-4c52-bbd7-8524b1e303de","_uuid":"c4c7da6457e93ff5a166ccfa1f2e4698366ead70"},"cell_type":"markdown","source":"## Let us try to plot the graph for our toy data set having only 4 people data of age and fare."},{"metadata":{"_cell_guid":"58e777b1-61d9-4927-a444-94950f7bf48e","_uuid":"7d758f66d22758f2b1c1b601275f3dd753222cd1","trusted":false,"collapsed":true},"cell_type":"code","source":"#Example:\nX_train=np.array([[1,2],[2,3],[4,5], [6,7]])\nY_train=np.array([1,0,0,1])\ncol=Y_train\nplt.scatter( x=X_train[:,0],y=X_train[:,1], c=col)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4430920f-553b-42b7-86f6-440bd6990d18","_uuid":"f3eab0a3ab5ed138255cbbf82c486b34d4e62a1f","trusted":false,"collapsed":true},"cell_type":"code","source":"#OUR TESTING DATA\nnew_point=[[3,4]]\ndists=compute_distances_one_loop(new_point, X_train)\nprint (dists)\nprint (\"ARRAY DIMENSIONS IS :\")\nprint (dists.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6959698f-5299-4900-93d0-e0d5a4ef480b","_uuid":"3cf9fa78edd6fc9a752800fa5cf812fc7a39c05c"},"cell_type":"markdown","source":"#### So we gave  testing data 3,4\n#### So our functions returns an array having one row and 4 columns. Now column 1 shows the distance with 1st row in X_train and column2 in result shows the distance with 2nd row in X_train  and so on.\n\nVisually we can see that our point is closest to second and third rows in X_train data. AND SECOND AND THIRD ROW IN X_TRAIN DATA DIDNT SURVIVED. \nHence we can predict that [3,4] in our test data will not survive too.\n\n\n"},{"metadata":{"_cell_guid":"c11f133b-3936-4294-9a5e-b9ff7bfb42c2","_uuid":"4f7448cd5f2035c9eeeeaecf4dee0fe6183e1146","collapsed":true,"trusted":false},"cell_type":"code","source":"# Now that we have distance from each point, we will simple find out the distance which is\n#least\ndef predict(dists, training_labels, k=3):\n    closest_y = []\n    rank = list(np.argsort(dists))\n    for x in range(0, k):\n        closest_y.append(training_labels[rank[x]])\n    closest_y = np.asarray(closest_y)\n    c=Counter(closest_y)\n    return (c.most_common()[0][0])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f8f7c341-c3f5-42ec-9c27-c494af41ea70","_uuid":"c0e2935f6e96dee43f072176f538960cb7f758be","trusted":false,"collapsed":true},"cell_type":"code","source":"result=predict(dists[0], Y_train)\nprint (result)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9bdf959e-6b06-475c-81b3-43b8052f8311","_uuid":"5e7ef3f83e5069cebbd05d9ad6953dcd010a41d0"},"cell_type":"markdown","source":"#### Programatically we made the functions predict which will do the same task, we did visually \n### Now we will apply the same logic with our 891 training dataset rows"},{"metadata":{"_cell_guid":"7592900e-c2f6-4976-905e-ffd704ad8e33","_uuid":"9f540286f0157981d51442ca61006e695ed4428c","trusted":false,"collapsed":true},"cell_type":"code","source":"compute_distances_one_loop([[1,2]],data[[\"Fare\",\"Age\"]]).shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ef271704-fdc2-4560-8617-3fb2b02b585f","_uuid":"bff6d5ecd37fbfb3de683bc7681ec060866ef919"},"cell_type":"markdown","source":"## Since we gave one new point and 891 current points, So it gave us a new array with one row containing 891 columns specifying distance with each point.\n\n\n\n## FINALLY lets try it with our testing data and send it to kaggle for review"},{"metadata":{"_cell_guid":"4eab6e7e-04f2-4ea6-8639-a6707d6453fd","_uuid":"2ba2deb28470f94d15418bce2d1d7b3a8ee58e89","collapsed":true,"trusted":false},"cell_type":"code","source":"dists=compute_distances_one_loop(test_data,data[[\"Fare\",\"Age\"]])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8fc66113-9fb2-471d-ba50-e16688fbaf9a","_uuid":"6cc50fc949691847ef1feba7c976ab2a2d21c668","collapsed":true,"trusted":false},"cell_type":"code","source":"Results=[]\nfor x in dists:\n    Results.append(predict(x, data[\"Survived\"]))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"93a9f60f-b671-4af6-b0dd-512ba2b0b192","_uuid":"40981a4dabba5878ff51b75771cd2af2c0c95f16","collapsed":true,"trusted":false},"cell_type":"code","source":"f=open(\"result.csv\",\"w\")\nf.write(\"PassengerId,Survived\")\nfor i in range(0, len(Results)):\n    f.write(\"\\n\")\n    f.write(str(passenger_id[i])+\",\"+ str(Results[i]))\n    \nf.close()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e631b281-7d8d-46a2-b400-e591be236573","_uuid":"72ca37d1b081def95e7a33b3412cb07d2e18badf"},"cell_type":"markdown","source":"### For a sanity check we will now just check whether our predictions are similar to scikit learn (inbuilt ) library or not."},{"metadata":{"_cell_guid":"71b72012-0e4d-4111-90f3-2e0fe59e07b3","_uuid":"eaf97a379f525d7d1565aa4cab67975bed66e6b1","trusted":false,"collapsed":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier(n_neighbors=3)\nneigh.fit(data[[\"Fare\",\"Age\"]], data[\"Survived\"])\nscikit_result=neigh.predict(test_data)\n\n\ncount=0\nnotr=[]\nfor i in range(0, len(scikit_result)):\n    if scikit_result[i]==Results[i]:\n        count+=1\n    else:\n        notr.append(i)\nprint (\"TOTAL INSTANCES\")\nprint (len(scikit_result))\nprint (\"SIMILAR RESULT B/W KNN AND SCIKIT LEARN INBUILT KNN\")\nprint (count)\nprint (\"\")\n\nprint (\"INDEXES OF WRONG RESULT\")\nprint (notr)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"330cd155-7109-4e9d-8387-fcb46247d4db","_uuid":"9072e8fc57dc9a8c731fde4a8aa1b88107cfff57","trusted":false,"collapsed":true},"cell_type":"code","source":"Results[55]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2e0da2fc-23ef-4eb0-9635-ebca5cb0d410","_uuid":"b34b07df0c0b176f76ac1eb7970f3662db422365","trusted":false,"collapsed":true},"cell_type":"code","source":"scikit_result[55]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"af0dc5b4-bb28-458c-ace2-4e210cca96e4","_uuid":"d162c7930d8c9d5f9776440709c46147962b0319","trusted":false,"collapsed":true},"cell_type":"code","source":"data.iloc[55]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b6ecf433-048c-45ca-9997-0e4f2812935e","_uuid":"e3523e3e61081a557491d6b258e34a55c2616c41"},"cell_type":"markdown","source":"**Our self implemented knn was correct, Although there were two places where it gave different result, that might be due to distance measuring technique. ** \n## of all the 418 samples the result of self implemented knn and inbuilt knn on scikit learn, only 2 instances produced different results, else all results were same."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"version":"3.6.4","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}