{"nbformat_minor": 1, "cells": [{"source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "execution_count": null, "metadata": {"_uuid": "80ce476bad4a9af58e71dd73dbc5bcaa91c8fc93", "_cell_guid": "c199a5d9-40d1-4ccd-b33a-5df6b81de09d"}, "cell_type": "code", "outputs": []}, {"source": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "1a4884b64d9c1df2938251cc63bb3466aabdec74", "_cell_guid": "f97f0791-ffbf-4651-9aca-bf1e24e6249d"}, "cell_type": "code", "outputs": []}, {"source": ["all_data = pd.read_csv(\"../input/train.csv\")\n", "all_data = all_data.drop('Name', axis = 1)\n", "all_data = all_data.drop('Ticket', axis = 1)\n", "all_data = all_data.drop('PassengerId', axis = 1)\n", "all_data = all_data.drop('Cabin', axis = 1)\n", "\n", "freq_port = all_data['Embarked'].dropna().mode()[0]\n", "all_data[\"Embarked\"].fillna(freq_port, inplace = True)\n", "\n", "# Add new features FamilySize and IsAlone.\n", "all_data['FamilySize'] = all_data['SibSp'] + all_data['Parch'] + 1\n", "all_data['IsAlone'] = 0\n", "all_data.loc[all_data['FamilySize'] == 1, 'IsAlone'] = 1\n", "\n", "all_data.info()"], "execution_count": null, "metadata": {"_uuid": "5e09318718f122476a7e3660fe084c1f86baab04", "_cell_guid": "fcc1d960-6ab0-4977-bec6-3c11e6b0b151"}, "cell_type": "code", "outputs": []}, {"source": ["from sklearn.base import BaseEstimator, TransformerMixin\n", "\n", "class DataFrameSelector(BaseEstimator, TransformerMixin):\n", "    def __init__(self, attribute_names):\n", "        self.attribute_names = attribute_names\n", "    def fit(self, X, y=None):\n", "        return self\n", "    def transform(self, X):\n", "        return X[self.attribute_names].values"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "b30579ae133e8e6c1f8aa9bae9967eb3b805562a", "_cell_guid": "c82f038d-83a8-469c-8e1b-3f36f87882af"}, "cell_type": "code", "outputs": []}, {"source": ["# Definition of the CategoricalEncoder class, copied from PR #9151.\n", "# Just run this cell, or copy it to your code, do not try to understand it (yet).\n", "import numpy as np\n", "from sklearn.base import BaseEstimator, TransformerMixin\n", "from sklearn.utils import check_array\n", "from sklearn.preprocessing import LabelEncoder\n", "from scipy import sparse\n", "\n", "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n", "    \"\"\"Encode categorical features as a numeric array.\n", "    The input to this transformer should be a matrix of integers or strings,\n", "    denoting the values taken on by categorical (discrete) features.\n", "    The features can be encoded using a one-hot aka one-of-K scheme\n", "    (``encoding='onehot'``, the default) or converted to ordinal integers\n", "    (``encoding='ordinal'``).\n", "    This encoding is needed for feeding categorical data to many scikit-learn\n", "    estimators, notably linear models and SVMs with the standard kernels.\n", "    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n", "    Parameters\n", "    ----------\n", "    encoding : str, 'onehot', 'onehot-dense' or 'ordinal'\n", "        The type of encoding to use (default is 'onehot'):\n", "        - 'onehot': encode the features using a one-hot aka one-of-K scheme\n", "          (or also called 'dummy' encoding). This creates a binary column for\n", "          each category and returns a sparse matrix.\n", "        - 'onehot-dense': the same as 'onehot' but returns a dense array\n", "          instead of a sparse matrix.\n", "        - 'ordinal': encode the features as ordinal integers. This results in\n", "          a single column of integers (0 to n_categories - 1) per feature.\n", "    categories : 'auto' or a list of lists/arrays of values.\n", "        Categories (unique values) per feature:\n", "        - 'auto' : Determine categories automatically from the training data.\n", "        - list : ``categories[i]`` holds the categories expected in the ith\n", "          column. The passed categories are sorted before encoding the data\n", "          (used categories can be found in the ``categories_`` attribute).\n", "    dtype : number type, default np.float64\n", "        Desired dtype of output.\n", "    handle_unknown : 'error' (default) or 'ignore'\n", "        Whether to raise an error or ignore if a unknown categorical feature is\n", "        present during transform (default is to raise). When this is parameter\n", "        is set to 'ignore' and an unknown category is encountered during\n", "        transform, the resulting one-hot encoded columns for this feature\n", "        will be all zeros.\n", "        Ignoring unknown categories is not supported for\n", "        ``encoding='ordinal'``.\n", "    Attributes\n", "    ----------\n", "    categories_ : list of arrays\n", "        The categories of each feature determined during fitting. When\n", "        categories were specified manually, this holds the sorted categories\n", "        (in order corresponding with output of `transform`).\n", "    Examples\n", "    --------\n", "    Given a dataset with three features and two samples, we let the encoder\n", "    find the maximum value per feature and transform the data to a binary\n", "    one-hot encoding.\n", "    >>> from sklearn.preprocessing import CategoricalEncoder\n", "    >>> enc = CategoricalEncoder(handle_unknown='ignore')\n", "    >>> enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])\n", "    ... # doctest: +ELLIPSIS\n", "    CategoricalEncoder(categories='auto', dtype=<... 'numpy.float64'>,\n", "              encoding='onehot', handle_unknown='ignore')\n", "    >>> enc.transform([[0, 1, 1], [1, 0, 4]]).toarray()\n", "    array([[ 1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.],\n", "           [ 0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]])\n", "    See also\n", "    --------\n", "    sklearn.preprocessing.OneHotEncoder : performs a one-hot encoding of\n", "      integer ordinal features. The ``OneHotEncoder assumes`` that input\n", "      features take on values in the range ``[0, max(feature)]`` instead of\n", "      using the unique values.\n", "    sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of\n", "      dictionary items (also handles string-valued features).\n", "    sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot\n", "      encoding of dictionary items or strings.\n", "    \"\"\"\n", "\n", "    def __init__(self, encoding='onehot', categories='auto', dtype=np.float64,\n", "                 handle_unknown='error'):\n", "        self.encoding = encoding\n", "        self.categories = categories\n", "        self.dtype = dtype\n", "        self.handle_unknown = handle_unknown\n", "\n", "    def fit(self, X, y=None):\n", "        \"\"\"Fit the CategoricalEncoder to X.\n", "        Parameters\n", "        ----------\n", "        X : array-like, shape [n_samples, n_feature]\n", "            The data to determine the categories of each feature.\n", "        Returns\n", "        -------\n", "        self\n", "        \"\"\"\n", "\n", "        if self.encoding not in ['onehot', 'onehot-dense', 'ordinal']:\n", "            template = (\"encoding should be either 'onehot', 'onehot-dense' \"\n", "                        \"or 'ordinal', got %s\")\n", "            raise ValueError(template % self.handle_unknown)\n", "\n", "        if self.handle_unknown not in ['error', 'ignore']:\n", "            template = (\"handle_unknown should be either 'error' or \"\n", "                        \"'ignore', got %s\")\n", "            raise ValueError(template % self.handle_unknown)\n", "\n", "        if self.encoding == 'ordinal' and self.handle_unknown == 'ignore':\n", "            raise ValueError(\"handle_unknown='ignore' is not supported for\"\n", "                             \" encoding='ordinal'\")\n", "\n", "        X = check_array(X, dtype=np.object, accept_sparse='csc', copy=True)\n", "        n_samples, n_features = X.shape\n", "\n", "        self._label_encoders_ = [LabelEncoder() for _ in range(n_features)]\n", "\n", "        for i in range(n_features):\n", "            le = self._label_encoders_[i]\n", "            Xi = X[:, i]\n", "            if self.categories == 'auto':\n", "                le.fit(Xi)\n", "            else:\n", "                valid_mask = np.in1d(Xi, self.categories[i])\n", "                if not np.all(valid_mask):\n", "                    if self.handle_unknown == 'error':\n", "                        diff = np.unique(Xi[~valid_mask])\n", "                        msg = (\"Found unknown categories {0} in column {1}\"\n", "                               \" during fit\".format(diff, i))\n", "                        raise ValueError(msg)\n", "                le.classes_ = np.array(np.sort(self.categories[i]))\n", "\n", "        self.categories_ = [le.classes_ for le in self._label_encoders_]\n", "\n", "        return self\n", "\n", "    def transform(self, X):\n", "        \"\"\"Transform X using one-hot encoding.\n", "        Parameters\n", "        ----------\n", "        X : array-like, shape [n_samples, n_features]\n", "            The data to encode.\n", "        Returns\n", "        -------\n", "        X_out : sparse matrix or a 2-d array\n", "            Transformed input.\n", "        \"\"\"\n", "        X = check_array(X, accept_sparse='csc', dtype=np.object, copy=True)\n", "        n_samples, n_features = X.shape\n", "        X_int = np.zeros_like(X, dtype=np.int)\n", "        X_mask = np.ones_like(X, dtype=np.bool)\n", "\n", "        for i in range(n_features):\n", "            valid_mask = np.in1d(X[:, i], self.categories_[i])\n", "\n", "            if not np.all(valid_mask):\n", "                if self.handle_unknown == 'error':\n", "                    diff = np.unique(X[~valid_mask, i])\n", "                    msg = (\"Found unknown categories {0} in column {1}\"\n", "                           \" during transform\".format(diff, i))\n", "                    raise ValueError(msg)\n", "                else:\n", "                    # Set the problematic rows to an acceptable value and\n", "                    # continue `The rows are marked `X_mask` and will be\n", "                    # removed later.\n", "                    X_mask[:, i] = valid_mask\n", "                    X[:, i][~valid_mask] = self.categories_[i][0]\n", "            X_int[:, i] = self._label_encoders_[i].transform(X[:, i])\n", "\n", "        if self.encoding == 'ordinal':\n", "            return X_int.astype(self.dtype, copy=False)\n", "\n", "        mask = X_mask.ravel()\n", "        n_values = [cats.shape[0] for cats in self.categories_]\n", "        n_values = np.array([0] + n_values)\n", "        indices = np.cumsum(n_values)\n", "\n", "        column_indices = (X_int + indices[:-1]).ravel()[mask]\n", "        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n", "                                n_features)[mask]\n", "        data = np.ones(n_samples * n_features)[mask]\n", "\n", "        out = sparse.csc_matrix((data, (row_indices, column_indices)),\n", "                                shape=(n_samples, indices[-1]),\n", "                                dtype=self.dtype).tocsr()\n", "        if self.encoding == 'onehot-dense':\n", "            return out.toarray()\n", "        else:\n", "            return out"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "ecd800b7227c450270707d7526fec77b739e7f13", "_cell_guid": "45d9038d-0583-4985-a3e5-e70745722d9d"}, "cell_type": "code", "outputs": []}, {"source": ["from sklearn.preprocessing import LabelEncoder\n", "encoder = LabelEncoder()\n", "all_data_sex = all_data['Sex']\n", "sex_encoded = encoder.fit_transform(all_data_sex)\n", "encoder.classes_"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "1912e54e17499d240333c8d82e480c9266fb3d4a", "_cell_guid": "071048d5-1cbd-4b2c-8a73-d5f735995318"}, "cell_type": "code", "outputs": []}, {"source": ["from sklearn.preprocessing import LabelEncoder\n", "encoder = LabelEncoder()\n", "all_data_emb = all_data['Embarked']\n", "emb_encoded = encoder.fit_transform(all_data_emb)\n", "encoder.classes_"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "2b027d1b6735e33f3235d63dd2550b5049b38fb4", "_cell_guid": "d5af1dcc-5387-496e-b85c-f83ac2680921"}, "cell_type": "code", "outputs": []}, {"source": ["from sklearn.pipeline import FeatureUnion, Pipeline\n", "from sklearn.preprocessing import StandardScaler, Imputer\n", "\n", "num_attributes = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'IsAlone']\n", "cat_attributes = ['Sex', 'Embarked']\n", "\n", "num_pipe = Pipeline([\n", "    ('selector', DataFrameSelector(num_attributes)),\n", "    ('imputer', Imputer(strategy=\"median\")),\n", "    ('std_scaler', StandardScaler())\n", "])\n", "\n", "cat_pipe = Pipeline([\n", "    ('selector', DataFrameSelector(cat_attributes)),\n", "    ('cat_encoder', CategoricalEncoder(encoding=\"onehot-dense\", categories=[['female', 'male'], ['C', 'Q', 'S']], handle_unknown='ignore'))\n", "])\n", "\n", "full_pipeline = FeatureUnion(transformer_list=[\n", "    (\"num_pip\", num_pipe),\n", "    (\"cat_pip\", cat_pipe),\n", "])\n", "\n", "prepared_data = full_pipeline.fit_transform(all_data)"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "aae241248e6406349e34bdad7164336d69fbe96a", "_cell_guid": "af7f7881-4d5d-49a3-b22b-8e553200fb10"}, "cell_type": "code", "outputs": []}, {"source": ["labels = all_data['Survived']"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "616b679e6122b94c3014a3a522ea7ae4fb7700e2", "_cell_guid": "d3d768ed-9e12-437d-b59c-c5a625042410"}, "cell_type": "code", "outputs": []}, {"source": ["from sklearn.linear_model import SGDClassifier\n", "from sklearn.model_selection import StratifiedKFold\n", "\n", "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n", "\n", "for train_index, test_index in skfolds.split(prepared_data, labels):\n", "    X_train_folds = prepared_data[train_index]\n", "    y_train_folds = (labels[train_index])\n", "    X_test_fold = prepared_data[test_index]\n", "    y_test_fold = (labels[test_index])\n", "    sgd_clr = SGDClassifier(random_state=42,tol=0.1)\n", "    sgd_clr.fit(X_train_folds, y_train_folds)\n", "    y_pred = sgd_clr.predict(X_test_fold)\n", "    n_correct = sum(y_pred == y_test_fold)\n", "    print(n_correct / len(y_pred))"], "execution_count": null, "metadata": {"_uuid": "9ec21dd30de6566ded20897f8719f9b1dabe630f", "_cell_guid": "b93ab1f4-8b84-4b45-9b07-bbe6a2a8e52e"}, "cell_type": "code", "outputs": []}, {"source": ["test_data = pd.read_csv(\"../input/test.csv\")\n", "test_data = test_data.drop('Name', axis = 1)\n", "test_data = test_data.drop('Ticket', axis = 1)\n", "test_data = test_data.drop('PassengerId', axis = 1)\n", "test_data = test_data.drop('Cabin', axis = 1)\n", "\n", "test_data[\"Embarked\"].fillna(freq_port, inplace = True)\n", "\n", "# Add new features FamilySize and IsAlone.\n", "test_data['FamilySize'] = test_data['SibSp'] + test_data['Parch'] + 1\n", "test_data['IsAlone'] = 0\n", "test_data.loc[test_data['FamilySize'] == 1, 'IsAlone'] = 1\n", "\n", "prepared_test_data = full_pipeline.fit_transform(test_data)\n", "\n", "test_predicts = sgd_clr.predict(prepared_test_data)"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "0728502b39940323788d3e8006bdbd5c2a4e2caa", "_cell_guid": "009e394f-c870-4c04-8e17-dced40bfc475"}, "cell_type": "code", "outputs": []}, {"source": ["test_predicts"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "a1bb2d93c04e85f46f085aab0733aaed83e9d826", "_cell_guid": "404abee4-94cd-40e4-a80d-4e9ef7147757"}, "cell_type": "code", "outputs": []}, {"source": ["test_data = pd.read_csv(\"../input/test.csv\")\n", "test_data['PassengerId']"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "53b12801aa27ce2df2ee1a62a43863f3cc04e556", "_cell_guid": "fa20a1a3-58cc-4b4a-8a62-70365899bee4"}, "cell_type": "code", "outputs": []}, {"source": ["result = np.c_[test_data['PassengerId'], test_predicts]"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "387f8ea953bc76d7b124db4c4e7553c4fe59a1b4", "_cell_guid": "916bb1c9-f967-4438-af6f-68b541f5ec1f"}, "cell_type": "code", "outputs": []}, {"source": ["np.savetxt('./predictions.csv', result, fmt='%i,%i', header=\"PassengerId,Survived\", comments='')"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "6850c40b48580140df8d2cb28f6942781c5ac01c", "_cell_guid": "4ca56a50-785f-4175-9848-698236fb6129"}, "cell_type": "code", "outputs": []}, {"source": ["pds = pd.read_csv('predictions.csv')"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "f4e5d74d9283dcf961a422acd658a0521a858cd3", "_cell_guid": "55ed7d92-98e5-4a4b-8b39-34df036309d8"}, "cell_type": "code", "outputs": []}, {"source": ["pds.info()"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "191f21a2c8269442e7134cd4529d937f7c0f2ed3", "_cell_guid": "9067ed6e-3e78-4445-9cd8-ff23a2aee726"}, "cell_type": "code", "outputs": []}, {"source": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "bea06529705fade787bf94e1c9a9cc29f953abd8", "_cell_guid": "3bd71f9f-5be3-4cf1-9af7-49526b5c4b89"}, "cell_type": "code", "outputs": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "mimetype": "text/x-python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.3", "name": "python"}}, "nbformat": 4}