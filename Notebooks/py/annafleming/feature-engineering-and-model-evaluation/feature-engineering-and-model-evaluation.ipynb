{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n%matplotlib inline\nfrom datetime import datetime\nsns.set()\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":34,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"original_train_df = pd.read_csv('../input/train.csv')\noriginal_test_df = pd.read_csv('../input/test.csv')\noriginal_train_df.shape, original_test_df.shape","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"26373c93645228cdabe92b3bbdb46f06fa407614"},"cell_type":"markdown","source":"I'm going to combine `Train` and `Test` datasets into one in order to efficently perform data clean up."},{"metadata":{"trusted":true,"_uuid":"db255051e1d787f24478f60f2f44e883142d47bf"},"cell_type":"code","source":"combined_df = original_train_df.append(original_test_df)\ncombined_df.head()","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"a55d44cdba9d3e6ccf36bffa3057fb4c28d2a161"},"cell_type":"markdown","source":"## Meet the data"},{"metadata":{"trusted":true,"_uuid":"0bba91b5d3b237657a065e7c39962bee3423c9a2"},"cell_type":"code","source":"original_train_df['Survived'].value_counts()","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"da7b86dd3e4a3aa05f124aa9934c50d8dff683aa"},"cell_type":"markdown","source":"It appears that both of the classes are well represented in the training dataset with the majority of `Survived` = 0"},{"metadata":{"_uuid":"53cf8ab91f71538f4439d74965941153640f79f1"},"cell_type":"markdown","source":"We are going to delete the features `PassengerId` and `Ticket`, since thay shouldn't have any predictive power. "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"10ee4d16bc2c21da3e8fad457f174217bd506d80"},"cell_type":"code","source":"combined_df = combined_df.drop(['PassengerId', 'Ticket'], axis=1)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"280f46a6d144586274f0b38a42f14efbb113e09d"},"cell_type":"markdown","source":"Let's now look at each feature."},{"metadata":{"_uuid":"d4fd5ad7ae4b05ddf1da260c0c89175c4b2c0d61"},"cell_type":"markdown","source":"#### Age"},{"metadata":{"trusted":true,"_uuid":"c9dba2d6620b806d145e8283ee00c2d0209f2659"},"cell_type":"code","source":"sns.kdeplot(combined_df[combined_df.Survived == 1]['Age'].dropna(), label='Survived', shade=True)\nsns.kdeplot(combined_df[combined_df.Survived == 0]['Age'].dropna(), label='Died', shade=True)","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"878ac49072a00cb9a425b7aab4ffd0c4d95c607b"},"cell_type":"markdown","source":"Looks like younger passengers had a better survival rate, then any other age group, while the adults between approximately 20 and 30 were less likely to survive.  "},{"metadata":{"_uuid":"7269d544a6b4618667003ac1e987d323026e8fb2"},"cell_type":"markdown","source":"#### Cabin\n\nSince `Cabin` value is going to be somewhat unique, we are going to create a new feature `Deck` using the first letter from `Cabin`. At first, we are going to fill the missing data with the value `U`.  We are also going to remove the feature `Cabin` from the dataset."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"934076366d3cf4ca4a2e5ea3e4baf81ce1fd3d73"},"cell_type":"code","source":"combined_df['Cabin'] = combined_df['Cabin'].fillna('U').astype(str)\ncombined_df['Deck'] = combined_df['Cabin'].apply(lambda x: x[0])\ncombined_df = combined_df.drop('Cabin', axis=1)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c377775c07b63da01947e234527a84cf268875a7"},"cell_type":"code","source":"sns.countplot(y=\"Deck\", hue=\"Survived\", data=combined_df)","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"3df7567539587f9212149f7232fa7618364e640f"},"cell_type":"markdown","source":"Most of the examples don't  have a record of the `Cabin` (`Deck`), so having the feature might not help with the prediction. We're still going to keep it for now."},{"metadata":{"_uuid":"a2f14ee35934f4e894951e8e3e5ec65c6422cdc0"},"cell_type":"markdown","source":"#### Embarked\t"},{"metadata":{"trusted":true,"_uuid":"2bca5b65f2bb24102796f8e593bb2b909da9e6a5"},"cell_type":"code","source":"combined_df[\"Embarked\"].value_counts()","execution_count":12,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7814934f3f95433e657f5873511c222da61dec7c"},"cell_type":"code","source":"sns.countplot(y=\"Embarked\", hue=\"Survived\", data=combined_df)","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"357a215c737fdfb9a28d2aea72811daf122835d9"},"cell_type":"markdown","source":"It looks like most of the passengers embarked in `S` and there is no clear correlation with the output label."},{"metadata":{"_uuid":"df00fd74c906955658b14233926e79356fbd9ee2"},"cell_type":"markdown","source":"#### Fare"},{"metadata":{"trusted":true,"_uuid":"3e5ec7f5258f138721af90ffe16386a291da8202"},"cell_type":"code","source":"sns.kdeplot(combined_df[combined_df.Survived == 1]['Fare'].dropna(), label='Survived', shade=True)\nsns.kdeplot(combined_df[combined_df.Survived == 0]['Fare'].dropna(), label='Died', shade=True)","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"0a57a1094bb64ec11f1b37e4ef91c182954fb705"},"cell_type":"markdown","source":"People with more expensive tickets appear to have a better survival rate. Also we need to note that the distribution is skewed to the right and most of the ticket vary between 0 and 100. "},{"metadata":{"_uuid":"668b82a4ba9c111d08a7661d4b93b999664c7289"},"cell_type":"markdown","source":"#### Name\n\nSince `Name` is unique in every record and can't help us with the predictions, we are going to extract the name prefix."},{"metadata":{"trusted":true,"_uuid":"2e1f490414fe41b1d06b71edfe3805e51d53c8f9"},"cell_type":"code","source":"def extract_prefix(name):\n    return name.split(',')[1].split('.')[0].strip()\n\ncombined_df['Prefix'] = combined_df['Name'].apply(extract_prefix)\n\ncombined_df = combined_df.drop('Name', axis=1)\n\ncombined_df['Prefix'].value_counts()","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"571d038ec8ff3a1ffbfd51ea33578e3bbc4e3b23"},"cell_type":"markdown","source":"Since we have a lot of low count prefixes, we are going to combine them into similar groups."},{"metadata":{"trusted":true,"_uuid":"8d2a16348eaf20bd6d03bbeaaaa6e3a745336d6d"},"cell_type":"code","source":"prefix_mapping = {'Ms': 'Miss', \n                  'Mlle': 'Miss', \n                  'Mme': 'Mrs', \n                  'Col': 'Sir',\n                  'Major': 'Sir', \n                  'Dona' : 'Lady', \n                  'the Countess': 'Lady',\n                  'Capt': 'Sir',  \n                  'Don': 'Sir',  \n                  'Jonkheer': 'Sir'}\ncombined_df['Prefix'] = combined_df['Prefix'].replace(prefix_mapping)\ncombined_df['Prefix'].value_counts()","execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"359e2bd13d76b4ff7735b3a6009d17cd2928f746"},"cell_type":"code","source":"sns.countplot(y=\"Prefix\", hue=\"Survived\", data=combined_df)","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"14103876f8342d2d18dbb34132af591622822f39"},"cell_type":"markdown","source":"From the plot, it looks like children (`Master`) and females had greater survival rate."},{"metadata":{"_uuid":"e207954d02da20b607a199f78d45cb4fb409b330"},"cell_type":"markdown","source":"#### Parch, SibSp"},{"metadata":{"trusted":true,"_uuid":"f0d869034f5ee8af7e17469e026621c7238d5b42"},"cell_type":"code","source":"combined_df['Parch'].value_counts()","execution_count":18,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37609ec68c7fcf1057e7b1ec3bd4f6df6471423b"},"cell_type":"code","source":"combined_df['SibSp'].value_counts()","execution_count":19,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8b4cbb3b22b21e6958be965b1379c3a05cf3960"},"cell_type":"code","source":"(combined_df['SibSp'] + combined_df['Parch']).value_counts()","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"66bef0cf55b97edc1581c7d4abb3a915bedda111"},"cell_type":"markdown","source":"It looks like the majority of the people traveled alone. We are going to keep the features unchanged."},{"metadata":{"_uuid":"f9a2b8323e16fecbf017123db07578650f001454"},"cell_type":"markdown","source":"#### Pclass"},{"metadata":{"trusted":true,"_uuid":"e2467efc7c31ef8a6b0e450ce9690ed94cc299ef"},"cell_type":"code","source":"sns.countplot(y=\"Pclass\", hue=\"Survived\", data=combined_df)","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"7d1ae942f8952b56d14c965dc7d1011e69a74d2d"},"cell_type":"markdown","source":"It appears that 1st class had better chances to survive, for the 2nd class it's roughly 50/50 and 3rd class passengers had quite low chance to survive."},{"metadata":{"_uuid":"167b07989cac69fac1ea1aaab5d471254d3ae792"},"cell_type":"markdown","source":"#### Sex"},{"metadata":{"trusted":true,"_uuid":"e4560a7fc45d46bd294f7a5b253eae64eed5c2cd"},"cell_type":"code","source":"sns.countplot(y=\"Sex\", hue=\"Survived\", data=combined_df)","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"aa47d6be965898c7f84724fadda3d6aef0eec6f7"},"cell_type":"markdown","source":"## Missing values"},{"metadata":{"trusted":true,"_uuid":"7ca6b924b746d6feffd8b1b6069dae4522efa552"},"cell_type":"code","source":"combined_df.isnull().sum()","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"993334d54c58100efea72b87b18db08d65a1ef2a"},"cell_type":"markdown","source":"##### Age\n\nWe are going to use median age for `Prefix` to impute missing values."},{"metadata":{"trusted":true,"_uuid":"15aca6ce9d8154bcf273dafb9a868557d860bb77"},"cell_type":"code","source":"median_ages = combined_df[['Age', 'Prefix']].groupby('Prefix').median()\nmedian_ages","execution_count":24,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c4829c6bc08c23a15f7ee473bdc7560ddc6cb7a6"},"cell_type":"code","source":"for title in median_ages.index:\n    title_mask = (combined_df['Prefix'] == title) & (combined_df['Age'].isnull()) \n    median_value = float(median_ages.loc[title])\n    combined_df.loc[title_mask,'Age'] = median_value","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"6b8372721b700806d5eeb40519d1b10530932fa5"},"cell_type":"markdown","source":"##### Embarked\n\nWe are going to use the most common value `S` to fill missing values."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"525d6c835d09ecaa267f7b5d8444c6cd83c53dca"},"cell_type":"code","source":"combined_df[\"Embarked\"] = combined_df[\"Embarked\"].fillna('S')","execution_count":26,"outputs":[]},{"metadata":{"_uuid":"d717846093a47978ca25c5ab151cc16e057c4a99"},"cell_type":"markdown","source":"##### Fare"},{"metadata":{"trusted":true,"_uuid":"bc3825fc994e511e2c91409e3285a35fea0cd0e1"},"cell_type":"code","source":"combined_df[combined_df['Fare'].isnull()]","execution_count":27,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8727a87a8c9241bf75967a8d6aa6d8cdf74a75aa"},"cell_type":"code","source":"median_fare = combined_df[(combined_df['Embarked'] == 'S') & (combined_df['Pclass'] == 3)]['Fare'].median()\nprint(median_fare)\ncombined_df[\"Fare\"] = combined_df[\"Fare\"].fillna(median_fare)","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"5c71ba1c11bb6d096cd6f4b2ca08987d6fdb3f43"},"cell_type":"markdown","source":"## Binning\n\nBinning is one way to make linear models more powerful on continuous data. We are going to apply binning to `Age` and `Fare`, and delete the original features."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8929b1bb86864c353a96633f1801ae19c2c61b0a"},"cell_type":"code","source":"# Age\nbins_count = 7\ncombined_df['Age_Bins'] = pd.qcut(combined_df['Age'], bins_count, labels=list(range(1,bins_count + 1)))\n\n# Fare\nbins_count = 5\ncombined_df['Fare_Bins'] = pd.qcut(combined_df['Fare'], bins_count, labels=list(range(1,bins_count + 1)))\n\ncombined_df = combined_df.drop(['Age', 'Fare'], axis=1)","execution_count":29,"outputs":[]},{"metadata":{"_uuid":"4003e7ab810ff58e8b768c2c5e6d3a82ba270f02"},"cell_type":"markdown","source":"## Create dummy features\n\nSince some of the features are encoded with numbers, we are going to need to specifically list all the categorical columns. Setting `drop_first` paremeter to `True` will help us to get rid of collinearity."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5cf2afb7c0e6eee1001d755f4fd88636330561f1"},"cell_type":"code","source":"categorical_columns = ['Embarked', 'Pclass', 'Sex', 'Deck', 'Prefix', 'Age_Bins', 'Fare_Bins']\ncombined_df = pd.get_dummies(combined_df, columns=categorical_columns, drop_first=True)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1def45692167e03be1b93e9da7d1e016cea6bf7"},"cell_type":"code","source":"combined_df.columns","execution_count":31,"outputs":[]},{"metadata":{"_uuid":"ea4895767eca140ddffa8fce5c327e759dd9a17e"},"cell_type":"markdown","source":"### Splitting `combined_df` back on training and testing datasets"},{"metadata":{"trusted":true,"_uuid":"daacae043cf2712d8c62ac6d90d9d3191c20e1f8"},"cell_type":"code","source":"train_df = combined_df[~combined_df['Survived'].isnull()]\ntest_df = combined_df[combined_df['Survived'].isnull()]\ntrain_df['Survived'] = train_df['Survived'].astype(int)\ntest_df = test_df.drop('Survived', axis=1)","execution_count":35,"outputs":[]},{"metadata":{"_uuid":"49f5a2d24dcbb4fdbe4dcaa251ad4e9cb7936289"},"cell_type":"markdown","source":"## Model testing"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f4cecba5815010776b798d4ba5f3a620d89da50c"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectPercentile\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.feature_selection import RFE","execution_count":36,"outputs":[]},{"metadata":{"_uuid":"a26f85221fddc88653d442913571783adf818db0"},"cell_type":"markdown","source":"First I'm going to write two small functions that are going to help us with model comparison."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"91e6335cf651dcc2e52e55b52511d14547e9d26d"},"cell_type":"code","source":"def test_models(df, label, models, scoring):\n    num_folds = 5\n    seed = 7\n    X = df.drop(label, axis=1).values\n    y = df[label].values\n    X_train, X_val, Y_train, Y_val = train_test_split(X, y, test_size=.30, random_state=seed)\n    results = {}\n    for name, model in models:\n        kfold = KFold(n_splits=num_folds, random_state=seed)\n        results[name] = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n        \n    for name in results:\n        print(\"%s: %s\" % (name, results[name].mean()))\n        \n    return results","execution_count":37,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b8b626d16d015abcd53a2a17d04f8e0e55d404c2"},"cell_type":"code","source":"def show_model_comparison_plot(results):\n    fig = plt.figure() \n    fig.suptitle('Algorithm Comparison') \n    ax = fig.add_subplot(111) \n    plt.boxplot(results.values()) \n    ax.set_xticklabels(results.keys())\n    ax.set_ylim(0,1)\n    plt.show()","execution_count":38,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15da4cb8fe19f89b6055078f230263c144062e32"},"cell_type":"code","source":"models = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('KNN', KNeighborsClassifier())) \nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('SVM', SVC())) \nresults = test_models(train_df, 'Survived', models , 'accuracy')\nshow_model_comparison_plot(results)","execution_count":39,"outputs":[]},{"metadata":{"_uuid":"e15f672ddaaca433552698eab91fcb7cdf0dd56b"},"cell_type":"markdown","source":"Looks like 'K-Nearest Neighbors' and 'SVM' came back with the best results. Let's perform some parameter tuning to further improve accuracy."},{"metadata":{"_uuid":"887e95493c41d8c12b2036cf467d2c144e37524d"},"cell_type":"markdown","source":"### Parameter tuning"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"854331819fff0748424f412ee95a83e68d394d08"},"cell_type":"code","source":"def param_tuning(df,label, model, scoring, parameters):\n    num_folds = 5\n    seed = 7\n    X = df.drop(label, axis=1).values\n    y = df[label].values\n    X_train, X_val, Y_train, Y_val = train_test_split(X, y, test_size=.30, random_state=seed)\n    grid = GridSearchCV(model, parameters, cv=5)\n    grid.fit(X_train, Y_train)\n    return grid.best_params_, grid.best_score_","execution_count":40,"outputs":[]},{"metadata":{"_uuid":"d037c292dde82d99721248ac4f8b2161603f6000"},"cell_type":"markdown","source":"#### SVM"},{"metadata":{"trusted":true,"_uuid":"cef10a1c0f7284b9febe7535082449d233bac43d"},"cell_type":"code","source":"params_svc = {'svc__gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n              'svc__C': [0.001, 0.01, 0.1, 1, 10, 100]}\nmodel = make_pipeline(SVC())\nparam_tuning(train_df, 'Survived', model , 'accuracy', params_svc)","execution_count":41,"outputs":[]},{"metadata":{"_uuid":"6e92ac60a12645ffbb863236b5cea3c320ad0322"},"cell_type":"markdown","source":"#### K-Nearest Neighbors"},{"metadata":{"trusted":true,"_uuid":"cccda5d6d8e2e211a6536bcb5b13b343d1b5901c"},"cell_type":"code","source":"params_knn = {'kneighborsclassifier__n_neighbors': [3, 4, 5, 6, 7]}\nmodel = make_pipeline(KNeighborsClassifier())\nparam_tuning(train_df, 'Survived', model, 'accuracy', params_knn)","execution_count":42,"outputs":[]},{"metadata":{"_uuid":"22ae7f9bf6046ed6766c7116bffec8a5a881202f"},"cell_type":"markdown","source":"After the parameter tuning our winner is `SVC` with C=1 and gamma=0.1. Let's see if Ensemble models are going to be able to beat it."},{"metadata":{"_uuid":"0601fba664927e2103427f93365dc83ed4adcb52"},"cell_type":"markdown","source":"### Ensemble models"},{"metadata":{"trusted":true,"_uuid":"53f8e556878328504bfb6c8fe85d56053274be98"},"cell_type":"code","source":"ensembles = []\nensembles.append(('AB', AdaBoostClassifier()))\nensembles.append(('GBM', GradientBoostingClassifier()))\nensembles.append(('RF', RandomForestClassifier()))\nensembles.append(('ET', ExtraTreesClassifier()))\nensembles.append(('XGB', XGBClassifier()))\nresults = test_models(train_df, 'Survived', ensembles , 'accuracy')\nshow_model_comparison_plot(results)","execution_count":43,"outputs":[]},{"metadata":{"_uuid":"07281216fdf1f0de4f03399b844184c6e9a6d4f1"},"cell_type":"markdown","source":"Let's see parameter tuning is going help `GradientBoostingClassifier` come up with a better score."},{"metadata":{"trusted":true,"_uuid":"66efe8fe152bafb585705adb77dab889de42eb31"},"cell_type":"code","source":"gb_grid_params = {'learning_rate': [0.1, 0.05, 0.02],\n              'max_depth': [3, 4, 5],\n              'min_samples_split': [2, 5,10] }\n\nmodel = GradientBoostingClassifier()\nparam_tuning(train_df, 'Survived', model, 'accuracy', gb_grid_params)","execution_count":44,"outputs":[]},{"metadata":{"_uuid":"aa8e4a613c903d4e5b3226d7d04e68ee9320a7df"},"cell_type":"markdown","source":"Parameter tuning did make a slight improvement, but `SVC` still holds the best accuracy score."},{"metadata":{"_uuid":"411e129a412008a29197b94d923ad3666ab96916"},"cell_type":"markdown","source":"We used all the features that we engineered for model training. Let's see now if performing feature selection before training is going to lead to better results."},{"metadata":{"_uuid":"de82d7cf7d099847ff24e4dd936c859acb948a0f"},"cell_type":"markdown","source":"### Feature selection"},{"metadata":{"_uuid":"f62f5f7c72576c0ea1cce63bdc3408c4f17592e9"},"cell_type":"markdown","source":"We are going to use our best performing model (SVC(C=1, gamma=0.1)) for evaluating feature selection techniques. Let's prepare the model, the dataset, and a function to run the comparison efficiently."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f368d32c13b387681e29e4b13309c79e05dfd328"},"cell_type":"code","source":"model = SVC(C=1,gamma=0.1)\nX = train_df.drop('Survived', axis=1)\ny = train_df['Survived']\n\ndef test_model(df, features, label, model, scoring):\n    num_folds = 5\n    seed = 7\n    X = df[features].values\n    y = df[label].values\n    X_train, X_val, Y_train, Y_val = train_test_split(X, y, test_size=.30, random_state=seed)\n    \n    kfold = KFold(n_splits=num_folds, random_state=seed)\n    result = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n    return result","execution_count":45,"outputs":[]},{"metadata":{"_uuid":"b666720fa089894d80b427a7eb84a5a18e35db45"},"cell_type":"markdown","source":"Let's run the model with all the feature one more time."},{"metadata":{"trusted":true,"_uuid":"fb99c6c6f8f603a194ded7b6a8d1e3d12c3e64a5"},"cell_type":"code","source":"all_columns = train_df.drop('Survived', axis=1).columns\ntest_model(train_df, all_columns, 'Survived', model , 'accuracy').mean()","execution_count":46,"outputs":[]},{"metadata":{"_uuid":"046c1a42b6b59de27d43190f8536bdaabac8470d"},"cell_type":"markdown","source":"#### Univariate feature selection"},{"metadata":{"trusted":true,"_uuid":"a7902fc8569fe0493ea745089618ea692230218b"},"cell_type":"code","source":"select = SelectPercentile(percentile=90) \nselect.fit(X, y)\nmask = select.get_support()\nuniv_features = np.array(all_columns)[mask]\nprint('Univariate feature selection')\nprint('------')\nprint('Excluded features')\nprint(np.array(all_columns)[~mask])\nprint('Accuracy %s' % test_model(train_df, univ_features, 'Survived', model , 'accuracy').mean())","execution_count":47,"outputs":[]},{"metadata":{"_uuid":"68c448badfa050b7acb45fbc17bc093adacfdf63"},"cell_type":"markdown","source":"#### Model-Based Feature Selection "},{"metadata":{"trusted":true,"_uuid":"e01e116ea8fa06a0b1d2d7592c9ae91b9719ce51"},"cell_type":"code","source":"select = SelectFromModel(\n        RandomForestClassifier(n_estimators=100, random_state=7),\n        threshold=\"mean\")\nselect.fit(X, y)\nmask = select.get_support()\nmb_features = np.array(all_columns)[mask]\nprint('Model-Based Feature Selection')\nprint('------')\nprint('Excluded features')\nprint(np.array(all_columns)[~mask])\nprint('Accuracy %s' % test_model(train_df, mb_features, 'Survived', model , 'accuracy').mean())","execution_count":52,"outputs":[]},{"metadata":{"_uuid":"e500f91d334397e138ab71a69f840cb8c4c83ea8"},"cell_type":"markdown","source":"#### Iterative Feature Selection "},{"metadata":{"trusted":true,"_uuid":"60c41ebec2cc1b8102feffdcd883af09be681f18"},"cell_type":"code","source":"print(\"Total features %s\" % len(all_columns))","execution_count":54,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e74839f1b54f381748d5523c2ce0b0df10e91475"},"cell_type":"code","source":"select = RFE(RandomForestClassifier(n_estimators=100, random_state=7),\n                 n_features_to_select=18)\nselect.fit(X, y)\nmask = select.get_support()\nrfe_features = np.array(all_columns)[mask]\nprint('Iterative Feature Selection')\nprint('------')\nprint('Excluded features')\nprint(np.array(all_columns)[~mask])\nprint('Accuracy %s' % test_model(train_df, rfe_features, 'Survived', model , 'accuracy').mean())","execution_count":55,"outputs":[]},{"metadata":{"_uuid":"5978f33eb248f3d6804ca951057c78c1dad834ad"},"cell_type":"markdown","source":"So none of the Feature selection algorithms helped us to improve our accuracy score, which means that all the features that we engineered previously contribute to predicting the correct result."}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}