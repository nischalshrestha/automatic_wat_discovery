{"nbformat_minor": 1, "metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"file_extension": ".py", "name": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python", "version": "3.6.1"}}, "cells": [{"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "58bab8dc-7cce-4d36-863b-551b6f15eb80", "_execution_state": "idle", "_uuid": "713b794ef52ca8c1399679bd2266d2c572cffe4a"}, "source": ["##This notebook is a simple implementation of logistic regression from Machine learning perspective, using gradient descent.\n", "## Concepts are well explained in machine learning videos posted by Andrew NG on youtube. Follow it for further explaination \n", "##\n", "\n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt  \n", "%matplotlib inline\n", "import keras\n", "from keras.layers import Dense\n", "from keras.models import Sequential\n", "from keras.callbacks import EarlyStopping\n", "\n", "    \n"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_execution_state": "idle", "_uuid": "432701d9e22249304a0508fdabe3ee3c82571c5a", "_cell_guid": "ec22816e-8fd4-4690-a6f3-3920b4bdcc76"}, "source": ["\n", "\n", "data=pd.read_csv(\"../input/train.csv\")\n", "test=pd.read_csv(\"../input/test.csv\")\n", "data=data.dropna()\n", "tempdata=data\n", "\n", "\n", "    "]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_execution_state": "idle", "_uuid": "3ea1f677108ed16821e7de9665987fed929389d9", "_cell_guid": "d247d03a-a759-4e54-b514-98a495223859"}, "source": ["# Sigmoid is same as logit function. i.e. when sigmoid is applied on input variable, the shape it generates is same as what you see below\n", "def sigmoid(z):  \n", "    return 1 / (1 + np.exp(-z))\n", "\n", "\n"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_execution_state": "idle", "_uuid": "031b06219fbb5929a11616dcceb56e46b3c41aa7", "_cell_guid": "b87ba82b-255f-44d4-a940-19327a16c925"}, "source": ["##\n", "num_range = np.arange(-10, 10)\n", "fig, ax = plt.subplots(figsize=(12,8))  \n", "ax.plot(num_range, sigmoid(num_range), 'g') \n"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_execution_state": "idle", "_uuid": "5ff2de37b76f0e0a434cb6a49ca51de960572ee4", "_cell_guid": "0953cab7-3307-44b4-900a-ee1f39cc913e"}, "source": ["## the cost is the function we use to determine how good the theta value is. Lower the cost, more accurate the theta is.  \n", "\n", "def cost(theta, X, y):  \n", "    theta = np.matrix(theta)\n", "    X = np.matrix(X)\n", "    y = np.matrix(y)\n", "    first = np.multiply(-y, np.log(sigmoid(X * theta.T)))\n", "    second = np.multiply((1 - y), np.log(1 - sigmoid(X * theta.T)))\n", "    return np.sum(first - second) / (len(X))\n", "\n", "\n"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_execution_state": "idle", "_uuid": "7d9e99aab52b5f2d24c67055c9242624c478b116", "_cell_guid": "56d5cf67-ec52-4d1a-a134-a79626319120"}, "source": ["# theta/slope/weights can be used interchangably. All these are multiplied by input variables to get predicted output value close to  real one.\n", "theta = np.matrix(np.array([1,2]))  \n", "print(theta)\n", "t=np.sum(theta)\n", "t\n", "\n"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_execution_state": "idle", "_uuid": "472871890e6b381249ee614cda8a06a7796b8885", "_cell_guid": "b5bb0712-1ca1-4672-a6d2-f9b19a9ea371"}, "source": ["## I have taken into account only first 3 columns, except \"Name\", just to show how gradient descent algorithm works\n", "\n", "cols = data.shape[1]  \n", "X_train = data.iloc[:,2:6]  \n", "X_test = test.iloc[:,1:5]  \n", "y_train = data.iloc[:,1]\n", "\n", "# convert categorical variable into dummy for Matrix calculation.\n", "X_train=X_train.drop('Name',1)\n", "X_test=X_test.drop('Name',1)\n", "X_train['Sex'] = X_train['Sex'].astype(object)\n", "X_train=pd.get_dummies(X_train)\n", "X_test=pd.get_dummies(X_test)\n", "X_train=X_train.drop('Sex_female',1)\n", "X_test=X_test.drop('Sex_female',1)\n", "\n", "# convert to numpy arrays and initalize the parameter array theta\n", "X_train = np.array(X_train.values)  \n", "X_test = np.array(X_test.values)  \n", "y_train = np.array(y_train.values)  \n", "theta = np.zeros(3) \n", "\n", "\n", "\n", "\n", "\n", "\n"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_execution_state": "idle", "_uuid": "9081bc5d98f7b53bbee94c80e331f7ffa3237f71", "_cell_guid": "531ed2a1-b284-4d45-89df-aefff9ab413a"}, "source": ["### quick check to see if cost function is running smoothly\n", "\n", "cost(theta, X_train, y_train)\n", "\n", "\n"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_execution_state": "idle", "_uuid": "564ee056435e9ff3a4da15e79800e8190bba565a", "_cell_guid": "dc8e312b-d3d5-4244-95ec-7eaffc86e8ab"}, "source": ["## Now this function finds the gradient of the model parameters that converges to local minima. \n", "##In other words, gradient which gives least value of cost function is the most desirable one\n", "##This is iterative process, which keeps changing the parameters in order to improve the outcome of the model on the training data. \n", "def gradient(theta, X_train, y_train):  \n", "    theta = np.matrix(theta)\n", "    X_train = np.matrix(X_train)\n", "    y_train = np.matrix(y_train)\n", "\n", "    parameters = int(theta.ravel().shape[1])\n", "    grad = np.zeros(parameters)\n", "\n", "    error = sigmoid(X_train * theta.T) - y_train\n", "\n", "    for i in range(parameters):\n", "        term = np.multiply(error, X_train[:,i])\n", "        grad[i] = np.sum(term) / len(X_train)\n", "\n", "    return grad\n", "\n", "\n", "\n"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_execution_state": "idle", "_uuid": "fbda92e780de0ed01e33888b2c332593716a9a6d", "_cell_guid": "be8e7184-cdd8-4d4d-addf-bb93a769360c"}, "source": ["## unlike in linear regression, where we calculate gradient descent in iterative manner, here we use optimizer from scipy library to compute the best gradient descent\n", "# Now once we have this best parameter value from the optimizer, we can feed it to test set to get the prediction \n", "import scipy.optimize as opt  \n", "result = opt.fmin_tnc(func=cost, x0=theta, fprime=gradient, args=(X_train, y_train))  \n", "cost(result[0], X_train, y_train)  \n", "\n", "\n", "\n"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_execution_state": "idle", "_uuid": "bc4dd34210acbf5ae78272ee6a4b3ba400487adc", "_cell_guid": "e144be2a-db2d-482d-9844-cbc4d40582cf"}, "source": ["##\n", "def prediction(theta, X_test):  \n", "    probability = sigmoid(X_test * theta.T)\n", "    return [1 if x >= 0.5 else 0 for x in probability]\n", "\n", "theta_min = np.matrix(result[0])  \n", "predictions = prediction(theta_min, X_test)  \n", "\n"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_execution_state": "idle", "_uuid": "e846e60fc17d88fff59bc12bc1002e3092714ebf", "_cell_guid": "517b51e0-8a78-4fc1-a00f-d31cdb17587f"}, "source": ["##merging Passenger Id and prediction output(Survived) together and writing to output directory\n", "Final_submission=pd.DataFrame({'PassengerId':test['PassengerId'],'Survived':predictions})\n", "Final_submission.to_csv(\"out.csv\")\n", "\n", "\n", "\n", "\n", "\n"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_execution_state": "idle", "_uuid": "e4d4a343588a17542777d2692c554fcf7191ee62", "_cell_guid": "157795f1-d5c3-457c-8fde-f02410d2c853"}, "source": []}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_execution_state": "idle", "_uuid": "9c82975795b4e0fd9012a6fe8f76d70fed59d3cd", "_cell_guid": "979111de-dec2-4a1b-85f7-e48d3cb7cf4f"}, "source": []}], "nbformat": 4}