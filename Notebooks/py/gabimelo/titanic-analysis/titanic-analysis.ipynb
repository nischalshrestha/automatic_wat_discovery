{"cells":[{"metadata":{"_uuid":"0282e1e76e88bb8ef0d47a38f9d7650fef2db5f0"},"cell_type":"markdown","source":"## Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport graphviz \n%matplotlib inline\n\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import (\n    cross_val_score, train_test_split, learning_curve, validation_curve\n)\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47bfaa811de0fd71eb57e0604e260449d74053f8"},"cell_type":"markdown","source":"## Data Load, Cleaning and Initial Exploration"},{"metadata":{"trusted":true,"_uuid":"7810dc18ff4614e328ef36673cbcdfeb163039ce","collapsed":true},"cell_type":"code","source":"raw_df = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6396e00a2349e7a8eb98c59b598973249770cb66"},"cell_type":"code","source":"df = raw_df.copy()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f39ce35ebb2663915f3be903083e496d4ccb33b9"},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d56d086323804652b2562580655e8bad56fe91d0"},"cell_type":"markdown","source":"**From above information, we can see that there are missing values on the age (177 missing), embarked (2 missing) and cabin (687 missing) columns.**"},{"metadata":{"trusted":true,"_uuid":"88d2151cdc7072c32c998760dbcd4821386d7d05","_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":"print('Amount of rows: {}\\n'.format(len(df)))\n\ncols_to_check = ['Survived', 'Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\nfor col in cols_to_check:\n    print('{}:\\n{}\\n'.format(col, df[col].value_counts()))\n    \nprint('Age range: [{}, {}]\\n'.format(np.min(df['Age']), np.max(df['Age'])))\n\nprint('Amount of unique names: {}'.format(df['Name'].nunique()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad9ddd25ca14c234710c02a0964b45e7131d7aff"},"cell_type":"markdown","source":"**Although name at first migth seem like a useless column, as we saw earlier, they seem to always come with a title. Let's try to split the name field into 3 new fields: first name, last name and title. Let's also make sure that there are no missing values for the title field.**\n\nInspiration for this came from: https://www.kaggle.com/pmarcelino/data-analysis-and-feature-extraction-with-python/notebook"},{"metadata":{"trusted":true,"_uuid":"46b7cdffe5bf607f001ca509080633516af82c18"},"cell_type":"code","source":"df['First Name'] = df['Name'].apply(lambda x: x.split('. ')[-1])\ndf['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\ndf['Last Name'] = df['Name'].apply(lambda x: x.split(',')[0])\n\nprint('Unique first names: {}'.format(df['First Name'].nunique()))\nprint('Unique last names: {}'.format(df['Last Name'].nunique()))\nprint('Unique titles: {}'.format(df['Title'].nunique()))\n\nassert not df['Title'].isnull().any()\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7221bb91630e87c47de2df7ad621d25f34a6352d"},"cell_type":"code","source":"df['Title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45ec7046fc883b231b644c9b20fde846383734f5"},"cell_type":"markdown","source":"**We saw earlier that the Age column has too many missing values. Now that we have a Title column, we could try to get the mean Age for each Title (as long as it's a value without too much variance) and imput the missing values for Age  as the mean Age for people with that title**"},{"metadata":{"trusted":true,"_uuid":"85258f04c0a2b1847a0b0d82f6634d5140075f8e"},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.barplot(x=df['Title'], y=df['Age'])\nplt.title('Mean age by title')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"825f445dded0a943c6d5fb32cd27ab0687aaaea2"},"cell_type":"code","source":"rows_with_missing_age = df[df['Age'].isnull()]\nax = sns.barplot(x = rows_with_missing_age['Title'].value_counts().index, \n                 y = rows_with_missing_age['Title'].value_counts())\nax.set_ylabel('')\nplt.title('Amount of missing values for Age column grouped by Title')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b196700369f14083f701887b5ac31970e93c8132","collapsed":true},"cell_type":"code","source":"map_means = df.groupby('Title')['Age'].mean().to_dict()\n\ndef imput_age(row):\n    if np.isnan(row['Age']):\n        return map_means[row['Title']]\n    else:\n        return row['Age']\ndf['Age'] = df.apply(imput_age, axis=1)\n\n# there should be no more missing values\nassert not np.isnan(df['Age']).any()\n\n# means shouldn't have changed:\nnew_map_means = df.groupby('Title')['Age'].mean().to_dict()\nfor key, value in map_means.items():\n    np.testing.assert_almost_equal(value, new_map_means[key])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7acef76bd313892323cdb70362569a4c9ecbec4d"},"cell_type":"markdown","source":"**Now we don't have any missing values for Age anymore.**\n\n**Let's ignore the Cabin column, as it has too much missing data, and discard rows with missing data in Embarked columns (as this will only affect 2 rows - less than 1% of our total data).**\n\n**\nTicket, PassengerId and Name probably also doesn't add any valuable information, let's drop it. (Ticket maybe could give us some insights, but we'd have to parse it - let's leave it aside for now).**\n\n**\nLet's also drop the recently created First Name and Last Name columns**"},{"metadata":{"trusted":true,"_uuid":"fe0558fe0192c663791c363994f5ac0d7d9f2f74"},"cell_type":"code","source":"df.drop(columns=['Cabin', 'PassengerId', 'Name', 'Ticket', 'Last Name', 'First Name'], inplace=True)\ndf.dropna(inplace=True)\n\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a4f017ff60a4a5e38b53996e9f8356f6b3a53451"},"cell_type":"code","source":"df['Sex'] = pd.Categorical(df['Sex'])\ndf['Embarked'] = pd.Categorical(df['Embarked'])\ndf['Title'] = pd.Categorical(df['Title'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"deeea52a6142b33e98966ceda5ad2d043b037dfc"},"cell_type":"markdown","source":"## Looking for insights from data"},{"metadata":{"trusted":true,"_uuid":"c5dd5151dd3af0eb7b27736a0ea20c3ab75cc409"},"cell_type":"code","source":"percentage_survived = df['Survived'].value_counts()[0]/(df['Survived'].value_counts()[0]+df['Survived'].value_counts()[1])\nprint('{:.2f}% of passengers on the currente data frame died'.format(percentage_survived*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79693e17bedfdd3051ad497bdac155e8dbae11ea"},"cell_type":"code","source":"plt.figure(figsize=(5,5))\ndf_corr_title = pd.get_dummies(df.filter(['Title', 'Survived'], axis=1), drop_first=True).corr()\nplt.scatter(df_corr_title['Survived'][1:], df_corr_title['Survived'].index[1:])\nplt.title('Correlation between titles and survival')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8db32a678704a688897cfd50f0e75dbebb437c6"},"cell_type":"code","source":"df_corr_wo_title = pd.get_dummies(df.drop('Title', axis=1), drop_first=True).corr()\nsns.heatmap(np.abs(df_corr_wo_title), annot=True, fmt='.2f')\n\n# plt.figure(figsize=(5,5))\n# df_corr_wo_title = pd.get_dummies(df.drop('Title', axis=1), drop_first=True).corr()\n# plt.scatter(df_corr_wo_title['Survived'][1:], df_corr_wo_title['Survived'].index[1:])\n\nplt.title('Correlation between other features')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29cfb340758b4f62a973d396efcafc605e24448c"},"cell_type":"code","source":"plt.figure(figsize=(5,7))\ndf_corr = pd.get_dummies(df, drop_first=True).corr()['Survived']\nplt.scatter(df_corr[1:], df_corr.index[1:])\nplt.title('Correlation between all features and survival')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26b313c639eb81ce6b41581a528a28fc43d8431e"},"cell_type":"markdown","source":"** From above plots we can see that:** \n- Pclass and Fare are highly correlated\n- Parch and Sibsp| are highly correlated\n- Pclass and Age are fairly correlated\n- Sex is highly correlated to Survived, followed by Pclass and then Fare"},{"metadata":{"trusted":true,"_uuid":"4c15d5f5c6d23b992f51b1eab521cd89b8dcd80c"},"cell_type":"code","source":"sns.barplot(x='Survived', y='Title', data=df)\nplt.title('Survival by Title')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f32a87971f50c29078994839cc083f8ad3f3f0e8"},"cell_type":"markdown","source":"**Below we analyse the relation between Embark port and Fare. From that we can assume that perhaps Embark wasn't helping the model, so we'll make some tests removing it when we're training and testing models.**"},{"metadata":{"trusted":true,"_uuid":"dbb05f213ace7c432de77fe6d928a77063828469"},"cell_type":"code","source":"sns.barplot(x='Embarked', y='Fare', hue='Pclass', data=df)\nplt.title('Fare grouped by embark port and Pclass')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"981e4dea32540761e4c367a33954ddaa5ad13aad"},"cell_type":"markdown","source":"**Below we see that Pclass matters a lot for survival, but Fare only seems to matter when Pclass == 1. For now we won't do anything about this, but the interaction between these two features could be explored later on.** "},{"metadata":{"trusted":true,"_uuid":"2dc28995ec2e907d92f3cdba68076756202190c7"},"cell_type":"code","source":"sns.barplot(x='Survived', y='Fare', hue='Pclass', data=df)\nplt.title('Fare grouped by survival and Pclass')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"239a6288b75262084002b1ca865a42cf09a12524"},"cell_type":"markdown","source":"**We can analyse how survival rates vary with Age. Later on we'll test how the models would performed if we grouped age ranges into bins.**"},{"metadata":{"trusted":true,"_uuid":"10dc9bd508eaeec8b8211a594c4f2a1e38a9630b"},"cell_type":"code","source":"g = sns.FacetGrid(df, col='Survived')\ng.map(sns.distplot, 'Age')\nplt.title('Distribution of Age, separated by Survival')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d3a7fa502697f3b79d3e5decc7bdbfddac0d725"},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nax = sns.barplot(x='Age', y='Survived', data=df)\n# ci = None\nplt.xticks(rotation=90)\nlabels = [item.get_text() for item in ax.get_xticklabels()]\nax.set_xticklabels([str(round(float(label), 2)) for label in labels])\nplt.title('Survival by Age')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58644d6f5e941608903aab001a160dbe6873d170"},"cell_type":"markdown","source":"## Model Testing and Selection\n\nGiven that the goal at the Kaggle competition is highest accuracy, that will be our metric.\n\nFirst we'll need to define a few functions, model training will begin after that."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"58f892dba993c73aeaf742cd1bbf66ac65b2a829"},"cell_type":"code","source":"def test_classifier(classifier, X_train, y_train, X_test, y_test):\n    classifier.fit(X_train, y_train)\n    y_pred = classifier.predict(X_test)\n    cs_score = cross_val_score(classifier, X_train, y_train, cv=10)\n    print('***************')\n    print(classifier.__class__)\n    print('CV Accuracy: {}  +/- {}'.format(cs_score.mean(), cs_score.std()))\n    print('Test Set Accuracy: {}'.format(accuracy_score(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5509c69263c628f735418dbe2db805d05cee3a99"},"cell_type":"code","source":"def test_classifiers(X_train, y_train, X_test, y_test):\n    classifiers = [DecisionTreeClassifier(random_state=42),\n                  LogisticRegression()]\n    for classifier in classifiers:\n        test_classifier(classifier, X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5371f8f8b87e17dba8455c08ad01d6d51149668f"},"cell_type":"code","source":"# this function is from the following notebook:\n# https://www.kaggle.com/pmarcelino/data-analysis-and-feature-extraction-with-python/notebook\n\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Validation score\")\n    plt.title(title)\n    plt.legend(loc=\"best\")\n    return plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e9251cb7eeef8a3dfbc036ada0fa2e770a0fefa5"},"cell_type":"code","source":"# this function is from the following notebook:\n# https://www.kaggle.com/pmarcelino/data-analysis-and-feature-extraction-with-python/notebook\n\ndef plot_validation_curve(estimator, title, X, y, param_name, param_range, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    train_scores, test_scores = validation_curve(estimator, X, y, param_name, param_range, cv)\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n    plt.plot(param_range, train_mean, color='r', marker='o', markersize=5, label='Training score')\n    plt.fill_between(param_range, train_mean + train_std, train_mean - train_std, alpha=0.15, color='r')\n    plt.plot(param_range, test_mean, color='g', linestyle='--', marker='s', markersize=5, label='Validation score')\n    plt.fill_between(param_range, test_mean + test_std, test_mean - test_std, alpha=0.15, color='g')\n    plt.grid() \n    plt.xscale('log')\n    plt.legend(loc='best') \n    plt.xlabel('Parameter') \n    plt.ylabel('Score') \n    plt.ylim(ylim)\n    plt.title(title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a5db271a5839cd0ce82c9241d6a45f33fa99f7c","collapsed":true},"cell_type":"code","source":"# dot_data = tree.export_graphviz(tree_classifier, out_file=None, \n# #                          feature_names=iris.feature_names,  \n# #                          class_names=iris.target_names,  \n#                          filled=True, rounded=True,  \n#                          special_characters=True)  \n# graph = graphviz.Source(dot_data)  \n# graph","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bdae4f17c62b5102c29c7d44efd3cd1da8dc1b30"},"cell_type":"code","source":"X = pd.get_dummies(df.drop(['Survived'], axis=1), drop_first=True)\ny = df['Survived']\n\nX['Family'] = X['SibSp'] + X['Parch']\nX.drop(['SibSp', 'Parch'], axis=1, inplace=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\ntest_classifiers(X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd2b7ef11203a8a3214acd5d917dd599aba1c6ba"},"cell_type":"code","source":"# Plot validation curve\ntitle = 'Validation Curve (Logistic Regression)'\nparam_name = 'C'\nparam_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0] \n# could also be written as param_range = np.logspace(-3, 2, num=6)\ncv = 10\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nplot_validation_curve(estimator=logreg, title=title, X=X_train, y=y_train, param_name=param_name,\n                      ylim=(0.5, 1.01), param_range=param_range)\n\ntitle = \"Learning Curves (Logistic Regression)\"\ncv = 10\nplot_learning_curve(logreg, title, X_train, y_train, ylim=(0.7, 1.01), cv=cv, n_jobs=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"977b830a7f8aa376b7880e761b6293d01a66dd09"},"cell_type":"code","source":"# there are some titles that are equivalent, and some that will be grouped together as 'Other'\ntitles_dict = {'Capt': 'Other',\n               'Col': 'Other',\n               'Major': 'Other',\n               'Jonkheer': 'Other',\n               'Don': 'Other',\n               'Sir': 'Other',\n               'Dr': 'Other',\n               'Rev': 'Other',\n               'Countess': 'Other',\n               'Mme': 'Mrs',\n               'Mlle': 'Miss',\n               'Ms': 'Miss',\n               'Mr': 'Mr',\n               'Mrs': 'Mrs',\n               'Miss': 'Miss',\n               'Master': 'Master',\n               'Lady': 'Other'}\n\ndf['Title'] = df['Title'].map(titles_dict)\n\nassert df['Title'].nunique() == 5\nassert df['Title'].isnull().any() == False\n\nsns.barplot(x='Title', y='Survived', data=df)\nplt.title('Survival by Title')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4363ca338b0c2ccf5123dc9ad1e37c9f1a0c90cf"},"cell_type":"code","source":"df['Age in bins'] = pd.Categorical(pd.cut(df['Age'], \n                                   bins=[0, 1, 16, 48, 100], \n                                   labels=['Baby', 'Kid/Teenager','Adult','Elder']))\n\nsns.barplot(x='Age in bins', y='Survived', data=df)\nplt.title('Survival by Age bins')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab851ed9a6529d4e6d29361700505c527ad493f1"},"cell_type":"code","source":"X = pd.get_dummies(df.drop(['Survived'], axis=1), drop_first=True)\nX['Family'] = X['SibSp'] + X['Parch']\nX.drop(['Age', 'SibSp', 'Parch'], axis=1, inplace=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\ntest_classifiers(X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c5b67f47321c1dd787fe1da946c9eac62bcf8fc"},"cell_type":"code","source":"# Plot validation curve\ntitle = 'Validation Curve (Logistic Regression)'\nparam_name = 'C'\nparam_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0] \n# could also be written as param_range = np.logspace(-3, 2, num=6)\ncv = 10\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\nplot_validation_curve(estimator=logreg, title=title, X=X_train, y=y_train, param_name=param_name,\n                      ylim=(0.5, 1.01), param_range=param_range)\n\ntitle = \"Learning Curves (Logistic Regression)\"\ncv = 10\nplot_learning_curve(logreg, title, X_train, y_train, ylim=(0.7, 1.01), cv=cv, n_jobs=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"efd1a174367283e45ddf94aeaa38b840aa17ba07"},"cell_type":"markdown","source":"We are going to choose Logistic Regression, with the feature selection done for the first test above for our predictions."},{"metadata":{"_uuid":"c64a3a8e1085cff65a9ad7cb4cc52475ac722ae5"},"cell_type":"markdown","source":"## Generating Predictions"},{"metadata":{"trusted":true,"_uuid":"24ad89dbf1dab2da9d2acff07adbbb6be33c4973"},"cell_type":"code","source":"df = raw_df.copy()\ntest_df = pd.read_csv('../input/test.csv')\n\ntest_passenger_ids = test_df['PassengerId'].values\n\ntest_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd0dba3e8b9acc54b6ad651749f1b27a10373051"},"cell_type":"code","source":"df['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\ntest_df['Title'] = test_df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n\nmap_means = df.groupby('Title')['Age'].mean().to_dict()\n\ndef imput_age(row):\n    if np.isnan(row['Age']):\n        return map_means[row['Title']]\n    else:\n        return row['Age']\ndf['Age'] = df.apply(imput_age, axis=1)\ntest_df['Age'] = test_df.apply(imput_age, axis=1)\n\ndf.drop(columns=['Cabin', 'PassengerId', 'Name', 'Ticket'], inplace=True)\ndf.dropna(inplace=True)\n\ntest_df.drop(columns=['Cabin', 'PassengerId', 'Name', 'Ticket'], inplace=True)\ntest_df = test_df.fillna(test_df.mean()) # 1 missing value on Fare column\n\ndf['Sex'] = pd.Categorical(df['Sex'])\ndf['Embarked'] = pd.Categorical(df['Embarked'])\ndf['Title'] = pd.Categorical(df['Title'])\n\ntest_df['Sex'] = pd.Categorical(test_df['Sex'])\ntest_df['Embarked'] = pd.Categorical(test_df['Embarked'])\ntest_df['Title'] = pd.Categorical(test_df['Title'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abb86a3175a35c040d30d63a1ab97a6ee7b4e93f"},"cell_type":"code","source":"X_train = pd.get_dummies(df.drop(['Survived'], axis=1), drop_first=True)\nX_test = pd.get_dummies(test_df, drop_first=True)\n# make sure both of have the same columns\nX_train, X_test = X_train.align(X_test, join='outer', axis=1, fill_value=0)\n\ny_train = df['Survived']\nX_train['Family'] = X_train['SibSp'] + X_train['Parch']\nX_train.drop(['SibSp', 'Parch'], axis=1, inplace=True)\n\nX_test['Family'] = X_test['SibSp'] + X_test['Parch']\nX_test.drop(['SibSp', 'Parch'], axis=1, inplace=True)\n\nclassifier = LogisticRegression(random_state=42)\nclassifier.fit(X_train, y_train)\npredictions = classifier.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f439662def25475a9cd6d2a6a94ed67ce9d1d3bc"},"cell_type":"code","source":"submission = pd.DataFrame({ 'PassengerId': test_passenger_ids,\n                            'Survived': predictions})\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}