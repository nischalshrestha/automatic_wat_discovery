{"metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "version": "3.6.1", "file_extension": ".py", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}}, "nbformat_minor": 0, "cells": [{"outputs": [], "metadata": {"collapsed": false, "_cell_guid": "2927581b-4a88-43c4-a061-f246330d9ec0", "_execution_state": "idle", "_uuid": "ec1a3ff1c72456db216a8d7818e504b369d8c043"}, "execution_count": null, "cell_type": "markdown", "source": "An attempt based in ideas from [here][1]\n\nImport standard libraries:\n  [1]: http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "ddd81db7-61cf-4609-bc0f-41c890acae1c", "_execution_state": "idle", "_uuid": "8e504644b44dc0dd1c0ebfa9ff29aff214414a82"}, "execution_count": null, "cell_type": "code", "source": "# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n#%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier"}, {"outputs": [], "metadata": {"collapsed": false, "_cell_guid": "e26e27cb-d2a5-4159-9ca5-684541532839", "_execution_state": "idle", "_uuid": "9bb6ff686dc171f3b1b943eaf4ed2e7be28959f8"}, "execution_count": null, "cell_type": "markdown", "source": "\nThen load the data:"}, {"outputs": [], "metadata": {"trusted": false, "_cell_guid": "8b384f50-0d1a-476a-8e8f-68a85c2e161c", "_execution_state": "idle", "_uuid": "9ebdd02c0077cb8d9d4ff2abed9823e403c9e700"}, "execution_count": null, "cell_type": "code", "source": "train_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\n\ntrain_df.columns.values"}, {"outputs": [], "metadata": {"collapsed": false, "_cell_guid": "007bcc25-d8e0-4c48-9de6-b6a387b7ee34", "_execution_state": "idle", "_uuid": "2cd3d7ee182de6cab64c377571d850715bef35dd"}, "execution_count": null, "cell_type": "markdown", "source": "And now check how the data looks:"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "7c4ebe3f-668a-4437-bf02-bc893d99cf83", "_execution_state": "idle", "_uuid": "04d9bcc25d1d5afd9022c446842457460b2c0a08"}, "execution_count": null, "cell_type": "code", "source": "train_df.head()"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "eb2fd6bc-e2ed-40e3-9adb-417a1270282d", "_execution_state": "idle", "_uuid": "604008688a61273ea40eab40ba3eae4567bd550b"}, "execution_count": null, "cell_type": "code", "source": "train_df.describe()"}, {"outputs": [], "metadata": {"collapsed": false, "_cell_guid": "47fcae7a-b1d3-4b5b-8224-32e6977b6da7", "_execution_state": "idle", "_uuid": "2658f55f37f7dba8ae48316033af90c09c029990"}, "execution_count": null, "cell_type": "markdown", "source": "Let's start analysing how various \"features\" affect the survival:"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "916518aa-7f8b-4821-8fe9-6b3bc296dcd0", "_execution_state": "idle", "_uuid": "39531654aa6d3935a0c544a3ea019e64a0eb410d"}, "execution_count": null, "cell_type": "code", "source": "# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.\n# Review Parch distribution using `percentiles=[.75, .8]`\n# SibSp distribution `[.68, .69]`\n# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`\n\ntrain_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "bb3aacd8-bfba-420e-a68b-493de54c79c7", "_execution_state": "idle", "_uuid": "227cec2ed896e7083860827eecf2947212e2fe5f"}, "execution_count": null, "cell_type": "code", "source": "train_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "74bccee6-88a1-4e78-a8ae-97b3a884eb39", "_execution_state": "idle", "_uuid": "87b187e7e2cdd0dbed2742ecf9f73f52f4b6a958"}, "execution_count": null, "cell_type": "code", "source": "survived_sex = train_df[train_df['Survived']==1]['Sex'].value_counts()\ndead_sex = train_df[train_df['Survived']==0]['Sex'].value_counts()\ndf = pd.DataFrame([survived_sex,dead_sex])\ndf.index = ['Survived','Dead']\ndf.plot(kind='bar',stacked=True, figsize=(15,8))"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "2ea1874d-e43e-4978-8b0d-d7719a7cc7b7", "_execution_state": "idle", "_uuid": "9ad6c968f6e2156ca20ae861e44475cd7a7a1eda"}, "execution_count": null, "cell_type": "code", "source": "train_df[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "c71b5989-ae4a-49b0-8dcf-c22ca1235ac9", "_execution_state": "idle", "_uuid": "41a48efae0c1ec17c7efd17d78a69d37cf73d80f"}, "execution_count": null, "cell_type": "code", "source": "survived_sibsp = train_df[train_df['Survived']==1]['SibSp'].value_counts()\ndead_sibsp = train_df[train_df['Survived']==0]['SibSp'].value_counts()\ndf = pd.DataFrame([survived_sibsp,dead_sibsp])\ndf.index = ['Survived','Dead']\ndf.plot(kind='bar',stacked=True, figsize=(15,10))"}, {"outputs": [], "metadata": {"collapsed": false, "_cell_guid": "da9c09df-5e35-49be-8a55-ebdddeda5c36", "_execution_state": "idle", "_uuid": "5207729be580da540a665d34cbd69d5ae127e4a4"}, "execution_count": null, "cell_type": "markdown", "source": "There are some columns like \"Name\", \"Embarked\", \"Cabin\" etc - which directly don't translate well to features. So we try to extract features out of them.\n\nAlso, some features like \"Age\" might be missing from some rows - they are essential, so we try to guess the missing values statistically from similar rows having that column."}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "0d41730d-d7f6-4b96-a439-5abdf06a17c1", "_execution_state": "idle", "_uuid": "0d814288cb92d4f7a50f873d2ae1f97c1251aed3"}, "execution_count": null, "cell_type": "code", "source": "def get_titles(data_frame):\n    # we extract the title from each name\n    data_frame['Title'] = data_frame['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n    \n    # a map of more aggregated titles\n    Title_Dictionary = {\n                        \"Capt\":       \"Officer\",\n                        \"Col\":        \"Officer\",\n                        \"Major\":      \"Officer\",\n                        \"Jonkheer\":   \"Royalty\",\n                        \"Don\":        \"Royalty\",\n                        \"Sir\" :       \"Royalty\",\n                        \"Dr\":         \"Royalty\",\n                        \"Rev\":        \"Royalty\",\n                        \"the Countess\":\"Royalty\",\n                        \"Dona\":       \"Royalty\",\n                        \"Mme\":        \"Mrs\",\n                        \"Mlle\":       \"Miss\",\n                        \"Ms\":         \"Miss\",\n                        \"Mr\" :        \"Mr\",\n                        \"Mrs\" :       \"Mrs\",\n                        \"Miss\" :      \"Miss\",\n                        \"Master\" :    \"Master\",\n                        \"Lady\" :      \"Royalty\"\n                        }\n    # we map each title\n    data_frame['Title'] = data_frame.Title.map(Title_Dictionary)\n    return data_frame"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "016c289a-e625-45a4-a6aa-1908255ddda8", "_execution_state": "idle", "_uuid": "31365bf950a8747a631d1f9d91734a286e2a4368"}, "execution_count": null, "cell_type": "code", "source": "train_df = get_titles(train_df)\ntrain_df.head()"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "4bec2b69-0d63-4d83-97f6-bb3cc9a8c9ac", "_execution_state": "idle", "_uuid": "901b9cdbbde7f04411c3316137085e3545696bab"}, "execution_count": null, "cell_type": "code", "source": "def process_age(data_frame, g_median):\n    # a function that fills the missing values of the Age variable\n    # TODO: Could try to use more features to get better median?\n    def fillAges(row, grouped_median):\n        return grouped_median.loc[row['Sex'], row['Pclass'], row['Title']]['Age']\n\n    data_frame.head(891).Age = data_frame.head(891).apply(lambda r : fillAges(r, g_median) \n                                                          if np.isnan(r['Age']) else r['Age'],\n                                                          axis=1)\n    return data_frame"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "b79b1e41-0b0e-45d2-ab71-02fcd5552d7a", "_execution_state": "idle", "_uuid": "b0ea4fbe3fc63c2a438aec92485531d68782ad04"}, "execution_count": null, "cell_type": "code", "source": "grouped_train = train_df.head(891).groupby(['Sex','Pclass','Title'])\ngrouped_median_train = grouped_train.median()\ntrain_df = process_age(train_df, grouped_median_train)\ntrain_df.head()"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "68708bbb-0024-469c-a10b-0014819d9281", "_execution_state": "idle", "_uuid": "6c3770247b5d796806a8e9c0058b46c4e46a3b38"}, "execution_count": null, "cell_type": "code", "source": "def process_names(data_frame):\n    # we clean the Name variable\n    data_frame.drop('Name',axis=1,inplace=True)\n    \n    # encoding in dummy variable\n    titles_dummies = pd.get_dummies(data_frame['Title'],prefix='Title')\n    data_frame = pd.concat([data_frame,titles_dummies],axis=1)\n    \n    # removing the title variable\n    data_frame.drop('Title',axis=1,inplace=True)\n    return data_frame"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "49cd5dc0-8e69-4134-803c-68b3587e50b2", "_execution_state": "idle", "_uuid": "501b30f07ccd78643e838eaf6d41dbade3a2ac61"}, "execution_count": null, "cell_type": "code", "source": "train_df = process_names(train_df)\ntrain_df.head()"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "6dd81ebc-fe3b-49a2-98a1-2d74ef04f769", "_execution_state": "idle", "_uuid": "1ad8532601f3aeee7534ce5d76d7bcba24a9efdf"}, "execution_count": null, "cell_type": "code", "source": "def process_fares(data_frame):    \n    # there's one missing fare value - replacing it with the mean.\n    # data_frame.head(891).Fare.fillna(data_frame.head(891).Fare.mean(), inplace=True)\n    data_frame.drop('Fare',axis=1,inplace=True)\n    return data_frame"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "1d9ac684-5d9f-4983-9ea4-b07e3206a60a", "_execution_state": "idle", "_uuid": "62e071bb82a9a19906b2f6bf697d17dff5782386"}, "execution_count": null, "cell_type": "code", "source": "train_df = process_fares(train_df)\ntrain_df.head()"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "731ad00a-86d6-4af1-8b89-4febe3219127", "_execution_state": "idle", "_uuid": "d1d7730df120a3d642cc09796e9fb0841aabc882"}, "execution_count": null, "cell_type": "code", "source": "def process_embarked(data_frame):\n    # two missing embarked values - filling them with the most frequent one (S)\n    data_frame.head(891).Embarked.fillna('S', inplace=True)\n    \n    # dummy encoding \n    embarked_dummies = pd.get_dummies(data_frame['Embarked'],prefix='Embarked')\n    data_frame = pd.concat([data_frame,embarked_dummies],axis=1)\n    data_frame.drop('Embarked',axis=1,inplace=True)\n    return data_frame"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "ecf2639a-f8a9-463a-8231-16171963ac09", "_execution_state": "idle", "_uuid": "2da06c54bff4739a55aaa20841dd0bccaaa89c10"}, "execution_count": null, "cell_type": "code", "source": "train_df = process_embarked(train_df)\ntrain_df.head()"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "48500441-d464-4ef0-b4e9-30474fff1305", "_execution_state": "idle", "_uuid": "28be2e316073d359008a881b3ed15000b22719a1"}, "execution_count": null, "cell_type": "code", "source": "def process_cabin(data_frame):\n    # replacing missing cabins with U (for Uknown)\n    data_frame.Cabin.fillna('U', inplace=True)\n    \n    # mapping each Cabin value with the cabin letter\n    data_frame['Cabin'] = data_frame['Cabin'].map(lambda c : c[0])\n    \n    # dummy encoding ...\n    cabin_dummies = pd.get_dummies(data_frame['Cabin'], prefix='Cabin')\n    data_frame = pd.concat([data_frame,cabin_dummies], axis=1)\n    data_frame.drop('Cabin', axis=1, inplace=True)\n    return data_frame"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "762ffd60-b1ac-4409-a476-47962d710fdf", "_execution_state": "idle", "_uuid": "cb85c06010eb8c6c6bac566ea5fddd857ac971c6"}, "execution_count": null, "cell_type": "code", "source": "train_df = process_cabin(train_df)\ntrain_df.head()"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "34a8e861-be15-4281-bdfb-ce94da359d01", "_execution_state": "idle", "_uuid": "dbb712fb99ff4d5df7ad08829498539d945c9d78"}, "execution_count": null, "cell_type": "code", "source": "def process_sex(data_frame):\n    # mapping string values to numerical one \n    data_frame['Sex'] = data_frame['Sex'].map({'male':1,'female':0})\n    return data_frame"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "1092d3aa-43d4-4499-9c3f-bd8acaa1d78d", "_execution_state": "idle", "_uuid": "4362350675a5905e5d4aa01e2e6217c7ce922edc"}, "execution_count": null, "cell_type": "code", "source": "train_df = process_sex(train_df)\ntrain_df.head()"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "c5557de9-276e-4b43-933a-6f16e3f49af1", "_execution_state": "idle", "_uuid": "6d38a32238058d387f5793adf2aded9dcead2a22"}, "execution_count": null, "cell_type": "code", "source": "def process_pclass(data_frame):    \n    # encoding into 3 categories:\n    pclass_dummies = pd.get_dummies(data_frame['Pclass'], prefix=\"Pclass\")\n    \n    # adding dummy variables\n    train_df = pd.concat([data_frame,pclass_dummies],axis=1)\n    \n    # removing \"Pclass\"\n    data_frame.drop('Pclass',axis=1,inplace=True)\n    return data_frame"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "8ceb6c5a-8144-4518-acd8-af006196c2b9", "_execution_state": "idle", "_uuid": "884d7575cb58bcfc44cd2e59275764eac996f3b5"}, "execution_count": null, "cell_type": "code", "source": "train_df = process_pclass(train_df)\ntrain_df.head()"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "e57f81f8-02b0-4b63-acfe-65938b495d0f", "_execution_state": "idle", "_uuid": "e5bb6966a03b59b7aefe07048df3c3502d5fd7a7"}, "execution_count": null, "cell_type": "code", "source": "train_df_tickets = set()\ntest_df_tickets = set()\ndef process_ticket(data_frame, training=False):\n    # a function that extracts each prefix of the ticket, returns 'XXX' if no prefix (i.e the ticket is a digit)\n    def cleanTicket(ticket):\n        ticket = ticket.replace('.','')\n        ticket = ticket.replace('/','')\n        ticket = ticket.split()\n        ticket = map(lambda t : t.strip(), ticket)\n        ticket = [t for t in ticket if not t.isdigit()]\n        # ticket = filter(lambda t : not t.isdigit(), ticket)\n        t_val = None\n        if len(ticket) > 0:\n            t_val = ticket[0]\n        else: \n            t_val = 'XXX'\n\n        if not training:\n            test_df_tickets.add(t_val)\n\n        if training or t_val in train_df_tickets:\n            train_df_tickets.add(t_val)\n            return t_val\n        else:\n            return \"XXX\"\n        \n    \n    # Extracting dummy variables from tickets:\n    data_frame['Ticket'] = data_frame['Ticket'].map(cleanTicket)\n    tickets_dummies = pd.get_dummies(data_frame['Ticket'], prefix='Ticket')\n    data_frame = pd.concat([data_frame, tickets_dummies], axis=1)\n    data_frame.drop('Ticket', inplace=True, axis=1)\n    return data_frame"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "858e642e-6104-4146-bffd-4daafd14a5db", "_execution_state": "idle", "_uuid": "9715953dd4ae1274c973b626333b55ce940360e1"}, "execution_count": null, "cell_type": "code", "source": "train_df = process_ticket(train_df, training=True)\ntrain_df.head()"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "7389cb19-b94e-40c9-80ab-c163a452a596", "_execution_state": "idle", "_uuid": "3461d97b6e2c61ca0939633692e66c04282a9a26"}, "execution_count": null, "cell_type": "code", "source": "def process_family(data_frame):\n    # introducing a new feature : the size of families (including the passenger)\n    data_frame['FamilySize'] = data_frame['Parch'] + data_frame['SibSp'] + 1\n    \n    # introducing other features based on the family size\n    data_frame['Singleton'] = data_frame['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n    data_frame['SmallFamily'] = data_frame['FamilySize'].map(lambda s: 1 if 2<=s<=4 else 0)\n    data_frame['LargeFamily'] = data_frame['FamilySize'].map(lambda s: 1 if 5<=s else 0)\n    return data_frame"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "dc1bcc4d-93b2-4dd5-8bbd-53e77a2750ba", "_execution_state": "idle", "_uuid": "d57782135336ce863a61d628dedce80ba9fa78e5"}, "execution_count": null, "cell_type": "code", "source": "train_df = process_family(train_df)\ntrain_df.head()"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "30f7b5bf-06fa-4bb6-9c87-c6c044e4145c", "_execution_state": "idle", "_uuid": "e1ea421285ad29f5793fbf9139ea0e1393397732"}, "execution_count": null, "cell_type": "code", "source": "targets = train_df.Survived\ntrain_df.drop('Survived', 1, inplace=True)\n\ntrain_df.reset_index(inplace=True)\ntrain_df.drop('index', inplace=True, axis=1)"}, {"outputs": [], "metadata": {"collapsed": false, "_cell_guid": "9bb897f6-09e0-4feb-8fb0-03b3c5d38726", "_execution_state": "idle", "_uuid": "00de716219af92cc050744b441161158e8086d0b"}, "execution_count": null, "cell_type": "markdown", "source": "Similarly process the test data; It needs to have same features as training data?"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "f1cbd787-33d1-4a7d-a6b8-9aa2b997b9c6", "_execution_state": "idle", "_uuid": "fd23983d3ac69820e910bbba72c68d3c2d7de610"}, "execution_count": null, "cell_type": "code", "source": "test_df = get_titles(test_df)\n\ngrouped_test = test_df.head(418).groupby(['Sex','Pclass','Title'])\ngrouped_median_test = grouped_test.median()\ntest_df = process_age(test_df, grouped_median_test)\n\ntest_df = process_names(test_df)\ntest_df = process_fares(test_df)\ntest_df = process_embarked(test_df)\ntest_df = process_cabin(test_df)\ntest_df = process_sex(test_df)\ntest_df = process_pclass(test_df)\ntest_df = process_ticket(test_df)\ntest_df = process_family(test_df)"}, {"outputs": [], "metadata": {"collapsed": false, "_cell_guid": "dd64ca15-75d6-4bb6-ba33-3142b8f2b883", "_execution_state": "idle", "_uuid": "469132256836d51816cdc150c3c5c79f909a0998"}, "execution_count": null, "cell_type": "markdown", "source": "Final cleanup before we try to fit the data!!"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "c5eedcbf-82de-4186-90a9-c8eab848b481", "_execution_state": "idle", "_uuid": "e391e2489d393e2a9e09a92cc3d5224f0a455a42"}, "execution_count": null, "cell_type": "code", "source": "train_df.drop('PassengerId', inplace=True, axis=1)\ntest_df.drop('PassengerId', inplace=True, axis=1)\n\n# train_df['Cabin_U'] = train_df['Cabin_T']\ntrain_df.drop('Cabin_T', inplace=True, axis=1)\n\nfor extra in train_df_tickets - test_df_tickets:\n    train_df['Ticket_XXX'] = train_df['Ticket_' + extra]\n    train_df.drop('Ticket_' + extra, inplace=True, axis=1)"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "fab1422b-d2fb-41f2-91b5-426b1337e106", "_execution_state": "idle", "_uuid": "28185a7faea6e3e06e51d68625ec35ce059a283b"}, "execution_count": null, "cell_type": "code", "source": "train_df.describe().columns"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "95c0a9b1-67b9-4340-9b6b-62b01f2a737f", "_execution_state": "idle", "_uuid": "4c35502ac82ca107af7e8279e429e6a68cf16f04"}, "execution_count": null, "cell_type": "code", "source": "test_df.describe().columns"}, {"outputs": [], "metadata": {"collapsed": false, "_cell_guid": "3d9d9ba3-fd2e-4213-93ab-d7afc32741e8", "_execution_state": "idle", "_uuid": "588f858a0c416cb92c48a5dc5d7eb015c1cc9bfc"}, "execution_count": null, "cell_type": "markdown", "source": "Now we build the statistical model using \"Random Forests\""}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "9464a224-c6d6-4bd9-943a-ea50ab38728b", "_execution_state": "idle", "_uuid": "e30a6bb4d518f0e52b944fbb5b4986277570314e"}, "execution_count": null, "cell_type": "code", "source": "from sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.cross_validation import StratifiedKFold\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\nfrom sklearn.cross_validation import cross_val_score"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "aad02ffb-b438-495e-bfe7-6c94b2544dfa", "_execution_state": "idle", "_uuid": "02e26d314fcfc41ded623d7a18cd1be568a28f4c"}, "execution_count": null, "cell_type": "code", "source": "def compute_score(clf, X, y, scoring='accuracy'):\n    xval = cross_val_score(clf, X, y, cv = 5, scoring=scoring)\n    return np.mean(xval)"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "e335bc95-30d0-4675-a55b-4f618cf2026e", "_execution_state": "idle", "_uuid": "ebb7b62a9e80ecf84cc5b2d8b6519940c0b98c9e"}, "execution_count": null, "cell_type": "code", "source": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectFromModel\nclf = RandomForestClassifier(n_estimators=30, max_features='sqrt')\nclf = clf.fit(train_df, targets)"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "e4ca4bb2-1ab4-48a5-8932-7140bb2a7855", "_execution_state": "idle", "_uuid": "251ad00f88dd8b7fefecd895f0d1e734c3853298"}, "execution_count": null, "cell_type": "code", "source": "features = pd.DataFrame()\nfeatures['feature'] = train_df.columns\nfeatures['importance'] = clf.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "43c820e1-18c9-4038-888d-2c952cadd831", "_execution_state": "idle", "_uuid": "255a708d145246a3963029b0aefbe5daa525bc98"}, "execution_count": null, "cell_type": "code", "source": "features.plot(kind='barh', figsize=(20, 20))"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "dbc038c3-ce6d-4554-bf5e-19aa461484db", "_execution_state": "idle", "_uuid": "d60cb0e260ff1e02d721b058ff0cfcffa4850619"}, "execution_count": null, "cell_type": "code", "source": "model = SelectFromModel(clf, prefit=True)\ntrain_reduced = model.transform(train_df)\ntrain_reduced.shape"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "aa4b4ed0-67f0-416f-b9d0-245aaf1e56e8", "_execution_state": "idle", "_uuid": "672276772232cb4772a212e131eef29431af7610"}, "execution_count": null, "cell_type": "code", "source": "test_reduced = model.transform(test_df)\ntest_reduced.shape"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "cf923e69-5ab3-434e-a9fa-4034132ff194", "_execution_state": "idle", "_uuid": "3c8a177fd6ae30a19f630f33231872875ae72ac8"}, "execution_count": null, "cell_type": "code", "source": "# turn run_gs to True if you want to run the gridsearch again.\nrun_gs = False\n\nif run_gs:\n    parameter_grid = {\n                 'max_depth' : [4, 6, 8],\n                 'n_estimators': [50, 10],\n                 'max_features': ['sqrt', 'auto', 'log2'],\n                 'min_samples_split': [1, 3, 10],\n                 'min_samples_leaf': [1, 3, 10],\n                 'bootstrap': [True, False],\n                 }\n    forest = RandomForestClassifier()\n    cross_validation = StratifiedKFold(targets, n_folds=5)\n\n    grid_search = GridSearchCV(forest,\n                               scoring='accuracy',\n                               param_grid=parameter_grid,\n                               cv=cross_validation)\n\n    grid_search.fit(train_df, targets)\n    model = grid_search\n    parameters = grid_search.best_params_\n\n    print('Best score: {}'.format(grid_search.best_score_))\n    print('Best parameters: {}'.format(grid_search.best_params_))\nelse: \n    parameters = {'bootstrap': False, 'min_samples_leaf': 3, 'n_estimators': 50, \n                  'min_samples_split': 10, 'max_features': 'sqrt', 'max_depth': 6}\n    \n    model = RandomForestClassifier(**parameters)\n    model.fit(train_df, targets)"}, {"outputs": [], "metadata": {"collapsed": false, "trusted": false, "_cell_guid": "d15818db-32ad-4ed8-9058-c896948a601f", "_execution_state": "idle", "_uuid": "3f56883763537c2f88331992683f3cbee90dd1cc"}, "execution_count": null, "cell_type": "code", "source": "compute_score(model, train_df, targets, scoring='accuracy')"}, {"outputs": [], "source": "output = model.predict(test_df).astype(int)\ndf_output = pd.DataFrame()\naux = pd.read_csv('../input/test.csv')\ndf_output['PassengerId'] = aux['PassengerId']\ndf_output['Survived'] = output\ndf_output[['PassengerId','Survived']].to_csv(index=False)", "execution_count": null, "metadata": {"collapsed": false, "_cell_guid": "5d83b7fc-73fb-4ee9-871e-c22eee41a76d", "_execution_state": "idle", "_uuid": "23628876bf6640e204a38616ab229423627e481c"}, "cell_type": "code"}], "nbformat": 4}