{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "cells": [{"metadata": {"_cell_guid": "22d606fd-ca56-4be7-8057-bd13209540f9", "_uuid": "1cbf70d5e7a0369fd8aa111cd88675e7d544dbf5"}, "source": ["<h3> Titanic Survival Prediction Algorithm </h3>\n", "This notebook details the underlying hypotheses for survival, builds several machine learning models based on hypotheses, and submits the GradientBoostingClassifier for scoring."], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "62e1e886-4790-4d48-bb48-6bc115ae90db", "_uuid": "b0987528ef8b77c088200e113ba17f784116d872"}, "source": ["# Modules for data manipulation\n", "import pandas as pd\n", "import numpy as np\n", "\n", "# machine learning packages\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.svm import SVC, LinearSVC\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.ensemble import GradientBoostingClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.linear_model import Perceptron\n", "from sklearn.linear_model import SGDClassifier\n", "from sklearn.tree import DecisionTreeClassifier"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "886a2b24-369e-4684-9be9-883ffb3d7e32", "_uuid": "dde4998305d23ee918df90c69ef8cb1cade063aa"}, "source": ["# load data\n", "train_df = pd.read_csv('../input/train.csv')\n", "test_df = pd.read_csv('../input/test.csv')"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "9db17654-852e-426e-a95a-11e0bf436395", "_uuid": "a3f4fead6000200f1e645231d5c2a898d64fb8ec"}, "source": ["<h4> Initial Hypotheses on factors impacting survival </h4>\n", "<li> Gender -- women preferred over men </li>\n", "<li> Age -- children over adults.  Create 'child' boolean variable. </li>\n", "<li> Passenger Class -- 1st class passengers 1st on boat </li>\n", "<li> Fare -- High paying passengers are ahead of other passengers at same class </li>\n", "<li> Alone vs In Group -- Loners more likely forgotten.  Groups encourage others to move </li>\n", "\n", "<h4> Irrelevant factors </h4>\n", "<li> Cabin #, Ticket # -- only care about fare and passenger class </li>\n", "<li> Name -- we don't have survival data for all passengers </li>\n", "\n", "<h4> Possibly useful factors </h4>\n", "<li> Title -- Miss, Master, Mr, Mrs, Other.  May be confounded w/ gender and age.</li>\n", "<li> Port of Embarkation </li>"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "1eced9f3-5e9d-4998-9b8d-9b5f58e391e8", "_uuid": "4dcabb9c7e263511a39641f67751ccf1d008fc00"}, "source": ["# Drop the ticket# and cabin# features.  They don't help w/ hypotheses.\n", "train_df = train_df.drop(['Ticket','Cabin'], axis=1)\n", "test_df = test_df.drop(['Ticket','Cabin'], axis=1)\n", "combine = [train_df, test_df]\n", "\n", "# Change the 'Name' field to title -- provides better analysis\n", "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n", "for dataset in combine:\n", "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n", "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n", " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n", "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n", "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n", "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n", "    #convert female / male to 1, 0\n", "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n", "    #Convert titles to numeric categories -- helps w/ sklearn algorithms\n", "    dataset['Title'] = dataset['Title'].map(title_mapping)\n", "    dataset['Title'] = dataset['Title'].fillna(0)\n", "    \n", "#Now drop name & passenger id from train; name from test\n", "train_df = train_df.drop(['Name','PassengerId'], axis=1)\n", "test_df = test_df.drop(['Name'], axis=1)\n", "combine = [train_df, test_df]"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "7fc10f99-4645-4a41-ae26-dbe77ded3010", "_uuid": "438851e06d184f9603c47e03e1903e2363fecb3b"}, "source": ["#Create age estimator for samples with no age data\n", "#Make estimator the average age for passenger by class & gender\n", "ages_est = np.zeros((2,3))\n", "for dataset in combine:\n", "    #Create estimator\n", "    for i in range(0, 2):\n", "        for j in range(0, 3):\n", "            guess_df = dataset[(dataset['Sex'] == i) & \\\n", "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n", "            ages_est[i,j] = guess_df.median()\n", "    #Fill blanks with estimates            \n", "    for i in range(0, 2):\n", "        for j in range(0, 3):\n", "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n", "                    'Age'] = ages_est[i,j]\n", "\n", "    dataset['Age'] = dataset['Age'].astype(int)\n", "\n", "#Create port of embarkation estimator for samples w/ no port data -- just use most common\n", "freq_port = train_df.Embarked.dropna().mode()[0]\n", "for dataset in combine:\n", "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n", "    #Convert port of embarkation to numeric categories\n", "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n", "\n", "#Create fare estimator for samples with no fare data -- use median for Pclass\n", "fare_est = np.zeros((3,1))\n", "for dataset in combine:\n", "    for i in range(0,3):\n", "        fare_est[i] = dataset[dataset['Pclass']==i+1]['Fare'].dropna().median()\n", "        dataset.loc[(dataset.Fare.isnull()) & (dataset.Pclass == i+1),'Fare'] = fare_est[i]\n", "\n", "#Create age bands -- resulted in groups of 16 years\n", "#train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\n", "for dataset in combine:\n", "    dataset.loc[dataset['Age'] < 17, 'Age'] = 0\n", "    dataset.loc[(dataset['Age'] >= 17) & (dataset['Age'] < 32), 'Age'] = 1\n", "    dataset.loc[(dataset['Age'] >= 32) & (dataset['Age'] < 48), 'Age'] = 2\n", "    dataset.loc[(dataset['Age'] >= 48), 'Age'] = 3\n", "    dataset['child'] = 0\n", "    dataset.loc[(dataset['Age'] == 0),'child'] = 1\n", "    \n", "#Create Fare bands -- use high/low for each passenger class\n", "for dataset in combine:\n", "    dataset.Fare = [1 if x > fare_est[y-1] else 0 for (x,y) in zip(dataset.Fare,dataset.Pclass)]"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "12d1e994-75e3-41de-a425-32024637a6f7", "_uuid": "f5602665b0a277a5faa9db92abafb47785378593"}, "source": ["#Look at family size -- create IsAlone feature\n", "for dataset in combine:\n", "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n", "    dataset['IsAlone'] = 0\n", "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1    \n", " \n", "#Search for mixture models\n", "for dataset in combine:\n", "    dataset['WealthFactor'] = 0\n", "    dataset.loc[(dataset['Sex']==0)&(dataset['Pclass']==1),'WealthFactor'] = 1\n", "    dataset.loc[(dataset['Sex']==1)&(dataset['Pclass']==3),'WealthFactor'] = -1\n", "\n", "#Remove unnecessary variables\n", "train_df = train_df.drop(['SibSp','Parch'], axis=1)\n", "test_df = test_df.drop(['SibSp','Parch'], axis=1)"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "a4b43524-84b4-45a3-8f4b-7df0c844e255", "_uuid": "9cde65bde0a2a616efb65e8743e455a730ea204f"}, "source": ["#Model the data\n", "X_train = train_df.drop(\"Survived\", axis=1)\n", "Y_train = train_df[\"Survived\"]\n", "X_test  = test_df.drop(\"PassengerId\", axis=1).copy()\n", "X_train.shape, Y_train.shape, X_test.shape\n", "\n", "# Logistic Regression\n", "logreg = LogisticRegression()\n", "logreg.fit(X_train, Y_train)\n", "Y_pred = logreg.predict(X_test)\n", "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n", "\n", "coeff_df = pd.DataFrame(train_df.columns.delete(0))\n", "coeff_df.columns = ['Feature']\n", "coeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n", "print(\"Logistic regression coefs are: \\n\",coeff_df.sort_values(by='Correlation', ascending=False),'\\n')"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "5fe5f548-c6bb-4e1f-9c1f-9fd2b655ff81", "_uuid": "f377584980477b15ca691c652a39719e1d246da2"}, "source": ["<h4> Review of logit model coefficients </h4>\n", "Most factors agree with hypotheses except for \"Family Size\".  Seems members of large groups are more likely to be victims.  The family size factor may be confounded with Title and other factors."], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "9e9fcd1f-7090-4218-9de7-44b20c56cbe5", "_uuid": "4f503f8f3aa025c7dbdb554e7acb6addd5aa7885"}, "source": ["# Now try several other methods\n", "# Support Vector Machines\n", "svc = SVC()\n", "svc.fit(X_train, Y_train)\n", "Y_pred = svc.predict(X_test)\n", "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n", "\n", "# K nearest neighbor\n", "knn = KNeighborsClassifier(n_neighbors = 3)\n", "knn.fit(X_train, Y_train)\n", "Y_pred = knn.predict(X_test)\n", "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n", "\n", "# Gaussian Naive Bayes\n", "gaussian = GaussianNB()\n", "gaussian.fit(X_train, Y_train)\n", "Y_pred = gaussian.predict(X_test)\n", "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n", "\n", "# Perceptron\n", "perceptron = Perceptron()\n", "perceptron.fit(X_train, Y_train)\n", "Y_pred = perceptron.predict(X_test)\n", "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n", "\n", "# Linear SVC\n", "linear_svc = LinearSVC()\n", "linear_svc.fit(X_train, Y_train)\n", "Y_pred = linear_svc.predict(X_test)\n", "acc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\n", "\n", "# Stochastic Gradient Descent\n", "sgd = SGDClassifier()\n", "sgd.fit(X_train, Y_train)\n", "Y_pred = sgd.predict(X_test)\n", "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n", "\n", "# Decision Tree\n", "decision_tree = DecisionTreeClassifier()\n", "decision_tree.fit(X_train, Y_train)\n", "Y_pred = decision_tree.predict(X_test)\n", "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 3)\n", "\n", "# Random Forest\n", "random_forest = RandomForestClassifier(max_features = 6, n_estimators=250)\n", "random_forest.fit(X_train, Y_train)\n", "Y_pred = random_forest.predict(X_test)\n", "random_forest.score(X_train, Y_train)\n", "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 3)\n", "\n", "# Gradient Boosting Classifier\n", "grad_boosting = GradientBoostingClassifier(n_estimators=250, max_depth=6)\n", "grad_boosting.fit(X_train, Y_train)\n", "Y_pred = grad_boosting.predict(X_test)\n", "grad_boosting.score(X_train, Y_train)\n", "acc_grad_boosting = round(grad_boosting.score(X_train, Y_train) * 100, 3)\n", "\n", "#Now evaluate models as a group\n", "models = pd.DataFrame({\n", "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n", "              'Random Forest', 'Naive Bayes', 'Perceptron', \n", "              'Stochastic Gradient Decent', 'Linear SVC', \n", "              'Decision Tree', 'Gradient Boosting'],\n", "    'Score': [acc_svc, acc_knn, acc_log, \n", "              acc_random_forest, acc_gaussian, acc_perceptron, \n", "              acc_sgd, acc_linear_svc, acc_decision_tree, acc_grad_boosting]})\n", "print(\"The models as a whole perform as:\\n\",models.sort_values(by='Score', ascending=False))"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "47ab270f-930b-4dc7-a5cc-a7b82737050a", "_uuid": "5815c2440733fd78373e4b43261c4a820fbc564b", "_kg_hide-output": true}, "source": ["#Finally submit the results\n", "submission = pd.DataFrame({\n", "        \"PassengerId\": test_df[\"PassengerId\"],\n", "        \"Survived\": Y_pred\n", "    })\n", "submission.to_csv('../output/submission.csv', index=False)"], "cell_type": "code", "outputs": []}], "nbformat_minor": 1, "nbformat": 4}