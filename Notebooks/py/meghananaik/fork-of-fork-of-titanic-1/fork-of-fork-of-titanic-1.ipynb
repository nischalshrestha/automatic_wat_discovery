{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "887b9167-7cc6-d7ed-12ab-57e0c1c71bfb"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c7a8ffaf-6442-2d2d-5e84-fa5e4768bb58"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "# Libraries for analysing data\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib as plt\n",
        "import random as rnd\n",
        "\n",
        "# Libraries for visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Definitions\n",
        "pd.set_option('display.float_format', lambda x: '%.0f' % x)\n",
        "%matplotlib inline\n",
        "\n",
        "# Libraries for machine learning\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "\n",
        "train_df = pd.read_csv('../input/train.csv', header=0)\n",
        "test_df = pd.read_csv('../input/test.csv', header=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ca5d5a53-eaac-3d71-ca4a-f6a7e22a1d9e"
      },
      "outputs": [],
      "source": [
        "train_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dba0da94-b499-2714-123a-3017e9021f55"
      },
      "outputs": [],
      "source": [
        "train_df.info()\n",
        "# Age and Embarked have NAn's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "832dabf9-aea8-acc1-3371-31cccbbed774"
      },
      "outputs": [],
      "source": [
        "#VISUALIZING THE DATA \n",
        "# Visualizing the data helps to undercover underlying patterns\n",
        "sns.barplot(x = \"Embarked\" , y = \"Survived\", hue= \"Sex\" , data = train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1c8fcd81-83c7-24e0-2ea3-521ae49c33be"
      },
      "outputs": [],
      "source": [
        "sns.barplot(x= \"Pclass\" , y = \"Survived\" , hue = \"Embarked\" , data = train_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "eac12e7b-e640-36d5-da88-abc5ec947d67"
      },
      "source": [
        "TRANSFORMING FEATURES\n",
        "\n",
        "1.  Age is cleaned and divided into logical human age groups, making it easier to plot\n",
        "2. For the \"Cabin\" feature,  the first letter is extracted for analysing survival rate and the rest is deleted.\n",
        "3. Fare is divided into quartile ranges for easy handling.\n",
        "4. For \"Name\" feature the last name and the prefix was extracted.\n",
        "5. All unwanted features are dropped.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e52f6cd4-c54f-0417-50d9-9adbdbe9cf36"
      },
      "outputs": [],
      "source": [
        "def simplify_ages(df):\n",
        "    df.Age = df.Age.fillna(-0.5)\n",
        "    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n",
        "    group_names = [1, 8, 7, 6, 5, 3, 2 ,4]\n",
        "    categories = pd.cut(df.Age, bins, labels=group_names)\n",
        "    df.Age = categories\n",
        "    return df\n",
        "\n",
        "def simplify_cabins(df):\n",
        "    df.Cabin = df.Cabin.fillna('N')\n",
        "    df.Cabin = df.Cabin.apply(lambda x: x[0])\n",
        "    return df\n",
        "\n",
        "def simplify_fares(df):\n",
        "    df.Fare = df.Fare.fillna(-0.5)\n",
        "    bins = (-1, 0, 8, 15, 31, 1000)\n",
        "    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n",
        "    categories = pd.cut(df.Fare, bins, labels=group_names)\n",
        "    df.Fare = categories\n",
        "    return df\n",
        "\n",
        "def format_name(df):\n",
        "    df['Lname'] = df.Name.apply(lambda x: x.split(' ')[0])\n",
        "    df['NamePrefix'] = df.Name.apply(lambda x: x.split(' ')[1])\n",
        "    return df    \n",
        "    \n",
        "def drop_features(df):\n",
        "    return df.drop(['Ticket', 'Name','Embarked'], axis=1)\n",
        "\n",
        "def transform_features(df):\n",
        "    df = simplify_ages(df)\n",
        "    df = simplify_cabins(df)\n",
        "    df = simplify_fares(df)\n",
        "    df = format_name(df)\n",
        "    df = drop_features(df)\n",
        "    return df\n",
        "\n",
        "train_df = transform_features(train_df)\n",
        "test_df = transform_features(test_df)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "26e57f91-8207-ce40-ee75-a15a8de3cb64"
      },
      "outputs": [],
      "source": [
        "sns.barplot(x=\"Age\", y=\"Survived\", hue=\"Sex\", data=train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c4fa565f-9e84-7b29-3dfd-9633330621f7"
      },
      "outputs": [],
      "source": [
        "sns.barplot(x=\"Cabin\", y=\"Survived\", hue=\"Sex\", data=train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4dad25e1-4b8f-f088-b70b-f25331ae248f"
      },
      "outputs": [],
      "source": [
        "sns.barplot(x=\"Fare\", y=\"Survived\", hue=\"Sex\", data=train_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c0b44506-02e2-4648-5634-2927cece0021"
      },
      "source": [
        "**Final Encoding:**\n",
        "\n",
        "This step normalizes labels , which converts unique string values to numbers, making data more flexible\n",
        "for algorithms. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "97779bbd-9a3a-1be7-7ff9-2f5492127a0c"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.replace({\"Sex\": { \"female\" : 2, \"male\" : 1} })\n",
        "test_df = test_df.replace({\"Sex\": { \"female\" : 2, \"male\" : 1} })\n",
        "train_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "15a495b0-9e19-e7e8-e3b9-8a842fd266d9"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "def encode_features(train_df, test_df):\n",
        "    features = ['Fare', 'Cabin', 'Age', 'Lname', 'NamePrefix']\n",
        "    df_combined = pd.concat([train_df[features], test_df[features]])\n",
        "    \n",
        "    for feature in features:\n",
        "        le = preprocessing.LabelEncoder()\n",
        "        le = le.fit(df_combined[feature])\n",
        "        train_df[feature] = le.transform(train_df[feature])\n",
        "        test_df[feature] = le.transform(test_df[feature])\n",
        "    return train_df, test_df\n",
        "    \n",
        "train_df, test_df = encode_features(train_df, test_df)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "327f9646-1856-1926-2ef4-6d0531dba45e"
      },
      "source": [
        "**Splitting up the Training Data:**\n",
        "\n",
        "First, separate the features(X) from the labels(y).\n",
        "X_all: All features minus the value we want to predict (Survived).\n",
        "y_all: Only the value we want to predict.\n",
        "Second, use Scikit-learn to randomly shuffle this data into four variables. In this case, I'm training 80% of the data, then testing against the other 20%.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b3ae5b1d-43b7-0943-2aec-fcb3377eed5f"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_all = train_df.drop(['Survived', 'PassengerId'], axis=1)\n",
        "y_all = train_df['Survived']\n",
        "\n",
        "num_test = 0.20\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=23)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8c34b8e4-0507-c641-e68c-574e5ccf8fe9"
      },
      "source": [
        "**Machine Learning Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f402c753-d93a-9b50-03ca-a649e585162d"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Choose the type of classifier. \n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# Choose some parameter combinations to try\n",
        "parameters = {'n_estimators': [4, 6, 9], \n",
        "              'max_features': ['log2', 'sqrt','auto'], \n",
        "              'criterion': ['entropy', 'gini'],\n",
        "              'max_depth': [2, 3, 5, 10], \n",
        "              'min_samples_split': [2, 3, 5],\n",
        "              'min_samples_leaf': [1,5,8]\n",
        "             }\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "acc_scorer = make_scorer(accuracy_score)\n",
        "\n",
        "# Run the grid search\n",
        "grid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer)\n",
        "grid_obj = grid_obj.fit(X_train, y_train)\n",
        "\n",
        "# Set the clf to the best combination of parameters\n",
        "clf = grid_obj.best_estimator_\n",
        "\n",
        "# Fit the best algorithm to the data. \n",
        "clf.fit(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4fc08538-9f22-cdca-9e25-c8ac5e1f2de4"
      },
      "outputs": [],
      "source": [
        "predictions = clf.predict(X_test)\n",
        "print(accuracy_score(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fb57920f-da94-e6da-011b-e20c77aad587"
      },
      "source": [
        "**Validate with KFold**\n",
        "\n",
        "Is this model actually any good? It helps to verify the effectiveness of the algorithm using KFold. This will split our data into 10 buckets, then run the algorithm using a different bucket as the test set for each iteration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9a85d804-dd1f-27d0-5423-0b6f29040cfe"
      },
      "outputs": [],
      "source": [
        "from sklearn.cross_validation import KFold\n",
        "\n",
        "def run_kfold(clf):\n",
        "    kf = KFold(891, n_folds=10)\n",
        "    outcomes = []\n",
        "    fold = 0\n",
        "    for train_index, test_index in kf:\n",
        "        fold += 1\n",
        "        X_train, X_test = X_all.values[train_index], X_all.values[test_index]\n",
        "        y_train, y_test = y_all.values[train_index], y_all.values[test_index]\n",
        "        clf.fit(X_train, y_train)\n",
        "        predictions = clf.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, predictions)\n",
        "        outcomes.append(accuracy)\n",
        "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy))     \n",
        "    mean_outcome = np.mean(outcomes)\n",
        "    print(\"Mean Accuracy: {0}\".format(mean_outcome)) \n",
        "\n",
        "run_kfold(clf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9973a723-f4ec-29fb-50b5-d35ad2e0556b"
      },
      "source": [
        "**Predict the Actual Test Data**\n",
        "\n",
        "\n",
        "And now for the moment of truth. Make the predictions, export the CSV file, and upload them to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9c708471-0403-a9e3-c3fe-618c05060825"
      },
      "outputs": [],
      "source": [
        "ids = test_df['PassengerId']\n",
        "predictions = clf.predict(test_df.drop('PassengerId', axis=1))\n",
        "\n",
        "\n",
        "output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\n",
        "output.to_csv('titanic-predictions.csv', index = False)\n",
        "output.head()"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}