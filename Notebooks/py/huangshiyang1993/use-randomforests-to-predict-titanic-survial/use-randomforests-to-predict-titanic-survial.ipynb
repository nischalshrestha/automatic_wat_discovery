{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nimport csv\nimport random\n\ndef list_take(list_elements, list_drop):\n    list_new = list()\n    for i, ele in enumerate(list_elements):\n        if i == 1:\n            survived = ele\n            continue\n        if i not in list_drop:\n            list_new.append(ele)\n    list_new.append(survived)\n    return list_new\n\n\ndef list_take(list_elements, list_drop, label_modify=False):\n    list_new = list()\n    for i, ele in enumerate(list_elements):\n        if label_modify and i == 1:\n            survived = ele\n            continue\n        if i not in list_drop:\n            list_new.append(ele)\n    if label_modify:\n        list_new.append(survived)\n    return list_new\n\n\ndef load_data(file_path=\"train.csv\", encoding=\"utf-8\"):\n    \"\"\"load data from file_path encode as encoding\n    split datas and labels into train and test\"\"\"\n    data_set = []\n    with open(file_path, encoding=encoding) as fp:\n        csv_reader = csv.reader(fp)\n        for ri, row in enumerate(csv_reader):\n            if ri == 0:\n                feat_list = list_take(row, [0, 3, 8, 10], True)\n            else:\n                data_set.append(list_take(row, [0, 3, 8, 10], True))\n    data_set = np.array(data_set)\n    age_avg = int(np.mean(data_set[data_set[:, 2] != '', 2].astype(np.float)))\n    data_set[data_set[:, 2] == '', 2] = str(age_avg)\n    embark_list = list(set(data_set[:, -2].tolist()) - {''})\n    null_num =len(np.nonzero(data_set[:, -2] == ''))\n    mul = int(null_num / len (embark_list)) + 1\n    data_set[data_set[:, -2] == '', -2] = np.array(random.sample(embark_list * mul , null_num))\n    return data_set[:, :-1], data_set[:, -1], feat_list[:-1]\n\n\ndef load_xdata(file_path=\"train.csv\", encoding=\"utf-8\"):\n    \"\"\"load data from file_path encode as encoding\n    split datas and labels into train and test\"\"\"\n    data_set = []\n    with open(file_path, encoding=encoding) as fp:\n        csv_reader = csv.reader(fp)\n        for ri, row in enumerate(csv_reader):\n            if ri == 0:\n                continue\n            else:\n                data_set.append(list_take(row, [0, 2, 7, 9], False))\n    data_set = np.array(data_set)\n    age_avg = int(np.mean(data_set[data_set[:, 3] != '', 3].astype(np.float)))\n    data_set[data_set[:, 3] == '', 3] = str(age_avg)\n    embark_list = list(set(data_set[:, -1].tolist()) - {''})\n    null_num =len(np.nonzero(data_set[:, -1] == ''))\n    mul = int(null_num / len (embark_list)) + 1\n    data_set[data_set[:, -1] == '', -1] = np.array(random.sample(embark_list * mul , null_num))\n    return data_set\n\n\ndef load_ydata(file_path=\"train.csv\", encoding=\"utf-8\"):\n    \"\"\"load data from file_path encode as encoding\n    split datas and labels into train and test\"\"\"\n    data_set = []\n    with open(file_path, encoding=encoding) as fp:\n        csv_reader = csv.reader(fp)\n        for ri, row in enumerate(csv_reader):\n            if ri == 0:\n                continue\n            else:\n                data_set.append(row[-1])\n    return np.array(data_set)\n\n\n\ndef map_str_label(data_mat):\n    feat_nums = data_mat.shape[1]\n    feat_map = []\n    for i in range(feat_nums):\n        value_set = set(data_mat[:, i].tolist())\n        j = 0\n        feat_dict = {}\n        for value in value_set:\n            feat_dict[j] = value\n            data_mat[data_mat[:, i] == value, i] = j\n            j = j + 1\n        feat_map.append(feat_dict)\n    return data_mat, feat_map\n\n\ndef test_accuracy(x, y, xtest_input=None, ytest_input=None):\n\n    ''''' 拆分训练数据与测试数据 '''\n    x, x_label = map_str_label(x)\n    y, y_label = map_str_label(y)\n    y = y.reshape(y.shape[0])\n    if xtest_input is None or ytest_input is None:\n        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n    else:\n        x_test, _ = map_str_label(xtest_input)\n        y_test, _ = map_str_label(ytest_input)\n        x_train, y_train = x, y \n\n    ''''' 使用信息熵作为划分标准，进行随机森林训练 '''\n    clf = RandomForestClassifier(n_estimators=10, criterion=\"entropy\", max_features=\"auto\", min_samples_split=4)\n    # print(clf)\n    clf.fit(x_train, y_train)\n\n    # class_names = []\n    # for class_label in y_label[0].values():\n    #     class_names.append(class_label)\n    ''''' 把决策树结构写入文件 '''\n    # with open(\"car_data.dot\", 'w+') as f:\n    #     f = tree.export_graphviz(clf, feature_names=feat_list, class_names=class_names, rounded=True, out_file=f)\n\n    ''''' 系数反映每个特征的影响力。越大表示该特征在分类中起到的作用越大 '''\n    # print(clf.feature_importances_)\n    '''''测试结果的打印'''\n    answer = clf.predict(x_test)\n    \n    # print(x_test)\n    # print(answer)\n    # print(y_test)\n    print(np.mean(answer == y_test))\n    return np.mean(answer == y_test)\n    # print(np.mean(answer == y_test))","execution_count":17,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a934e7f27a56827b8febf37aca93f55b9b7fea91","scrolled":false},"cell_type":"code","source":"accuracy = 0.0\ntime = 1000\ndata, labels, feat_list = load_data(\"../input/train.csv\")\nx = np.array(data)\nxtest = load_xdata(\"../input/test.csv\")\nytest = load_ydata(\"../input/gender_submission.csv\")\nlabels = np.array(labels)\ny = labels.reshape((x.shape[0], 1))\nwhile time:\n    time = time - 1\n    accuracy += test_accuracy(x, y, xtest, ytest)\naccuracy /= 1000\nprint(\"accuracy:\\t\", accuracy)","execution_count":18,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}