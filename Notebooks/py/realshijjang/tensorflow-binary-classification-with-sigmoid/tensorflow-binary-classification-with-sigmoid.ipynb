{"cells":[{"metadata":{"collapsed":true,"trusted":true,"_uuid":"8054d3767f053d1229f9167fa7a2c17b3cece6ac"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport io\nimport requests\nimport math\nfrom scipy import stats","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"a2f5d4483a82350eb620656a2746e4588b9f4a77"},"cell_type":"code","source":"# this is z-score that value minus mean divided by standard deviation\n# http://duramecho.com/Misc/WhyMinusOneInSd.html\ndef feature_normalize(dataset):\n    mu = np.mean(dataset,axis=0)\n    sigma = np.std(dataset,axis=0)\n    return (dataset - mu)/sigma\n\ndef str_to_int(df):\n    str_columns = df.select_dtypes(['object']).columns\n    print(str_columns)\n    for col in str_columns:\n        df[col] = df[col].astype('category')\n\n    cat_columns = df.select_dtypes(['category']).columns\n    df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)\n    return df\n\ndef count_space_except_nan(x):\n    if isinstance(x,str):\n        return x.count(\" \") + 1\n    else :\n        return 0\n\n# https://stackoverflow.com/a/42523230\ndef one_hot(df, cols):\n    \"\"\"\n    @param df pandas DataFrame\n    @param cols a list of columns to encode \n    @return a DataFrame with one-hot encoding\n    \"\"\"\n    for each in cols:\n        dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n        del df[each]\n        df = pd.concat([df, dummies], axis=1)\n    return df\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bc05d4c6ab3a64be9a21f75e9bf1eb188d57afb"},"cell_type":"code","source":"df_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2d78d09f74fef57bf90b76da4cdb23ef4062b52"},"cell_type":"code","source":"print (df_train.isnull().sum())\ndelete_columns = [\"Ticket\", \"Name\", \"PassengerId\", \"Cabin\", \"Embarked\"]\n\ndef pre_processing(df):\n    df.drop(delete_columns, axis=1, inplace=True)\n    # Count room nubmer\n    # df_train[\"Cabin\"] = df_train[\"Cabin\"].apply(count_space_except_nan)\n    # Replace NaN with mean value\n    df[\"Age\"].fillna(df[\"Age\"].mean(), inplace=True)\n    # Pclass, Embarked one-hot\n    df = one_hot(df, df.loc[:, [\"Pclass\"]].columns)\n    # String to int\n    df = str_to_int(df)\n    # Age Normalization\n    df[\"Age\"] = feature_normalize(df[\"Age\"])\n    stats.describe(df).variance\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30108276e4b0f69175403b3785636f8772a0f8f1"},"cell_type":"code","source":"df_train = pre_processing(df_train)\n#save PassengerId for evaluation\ntest_passenger_id = df_test[\"PassengerId\"]\ndf_test = pre_processing(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"066f836e04976a064880caa4a73bb1ebe0a13837"},"cell_type":"code","source":"features = df_train.iloc[:, 1:].values\n# features = feature_normalize(features)\nlabels = df_train.iloc[:, :1].values\nprint(features.shape, labels.shape)\nstats.describe(features).variance\n\nreal_test_x = df_test.values\nprint(real_test_x.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfc7ed543509a5c6c254b285fd1a8f5eb3a15190"},"cell_type":"code","source":"rnd_indices = np.random.rand(len(features)) < 0.80\n\ntrain_x = features[rnd_indices]\ntrain_y = labels[rnd_indices]\ntest_x = features[~rnd_indices]\ntest_y = labels[~rnd_indices]\n\nfeature_count = train_x.shape[1]\nlabel_count = train_y.shape[1]\nprint(feature_count, label_count)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"fef41c066222199b1e3b22d44b004f8ae43e9e5f"},"cell_type":"code","source":"# inputs\ntraining_epochs = 3000\nlearning_rate = 0.01\nhidden_layers = feature_count - 1\ncost_history = np.empty(shape=[1],dtype=float)\n\nX = tf.placeholder(tf.float32,[None,feature_count])\nY = tf.placeholder(tf.float32,[None,label_count])\nis_training=tf.Variable(True,dtype=tf.bool)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"aef69e4a4b455cd01e182083c03b28b266e553f4"},"cell_type":"code","source":"# models\n\ninitializer = tf.contrib.layers.xavier_initializer()\nh0 = tf.layers.dense(X, hidden_layers, activation=tf.nn.relu, kernel_initializer=initializer)\n# h0 = tf.nn.dropout(h0, 0.95)\nh1 = tf.layers.dense(h0, label_count, activation=None)\n\ncross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=h1)\ncost = tf.reduce_mean(cross_entropy)\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# prediction = tf.argmax(h0, 1)\n# correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\npredicted = tf.nn.sigmoid(h1)\ncorrect_pred = tf.equal(tf.round(predicted), Y)\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c791c9864a192568c517f3595e46a0246155a7f"},"cell_type":"code","source":"# session\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n\n    for step in range(training_epochs + 1):\n        sess.run(optimizer, feed_dict={X: train_x, Y: train_y})\n        loss, _, acc = sess.run([cost, optimizer, accuracy], feed_dict={\n                                 X: train_x, Y: train_y})\n        cost_history = np.append(cost_history, acc)\n        if step % 500 == 0:\n            print(\"Step: {:5}\\tLoss: {:.3f}\\tAcc: {:.2%}\".format(\n                step, loss, acc))\n            \n    # Test model and check accuracy\n    print('Test Accuracy:', sess.run([accuracy, tf.round(predicted)], feed_dict={X: test_x, Y: test_y}))\n    \n    # Save test result\n    test_predict_result = sess.run(tf.cast(tf.round(predicted), tf.int32), feed_dict={X: real_test_x})\n    evaluation = test_passenger_id.to_frame()\n    evaluation[\"Survived\"] = test_predict_result\n    evaluation.to_csv('result.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e551dd8eaa1ceefb0f50ae819e4d5d82dea8d261"},"cell_type":"code","source":"print(cost_history.shape)\nplt.plot(range(len(cost_history)),cost_history)\nplt.axis([0,training_epochs,0,1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc3a0bbf1ddfc5c75b8635b790d16da33246f5cf"},"cell_type":"code","source":"evaluation","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"1057957e19a3a87be2c6e508eaa50d85a736d926"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"}},"nbformat":4,"nbformat_minor":1}