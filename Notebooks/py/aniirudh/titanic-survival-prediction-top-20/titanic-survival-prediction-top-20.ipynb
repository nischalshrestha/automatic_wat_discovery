{"cells":[{"metadata":{"_uuid":"2eb0dd330bf7373dc6382a0faa603ff6a1f8df94"},"cell_type":"markdown","source":"# Import Python Libraries\n\nLet's start by import libraries such as pandas, numpy and matplotlib (for visualization)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e0a171ce2649cd9fcb1beee511267137d30abeba"},"cell_type":"code","source":"# import pandas, and numpy\nimport pandas as pd\nimport numpy as np\nfrom pandas import Series,DataFrame\n\n# matplotlib for visualization\nimport matplotlib.pyplot as plot\nimport seaborn as sns\n\n# ignore warnings for now\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"8f7b0f27f0700d68e7cbaa52bac1224ff0d3265a"},"cell_type":"markdown","source":"# Load the Data\n\nAfter importing the required libraries, we load the training and test data using the `read_csv` function, and print some sample of the training data."},{"metadata":{"trusted":true,"_uuid":"2ab12f8ff09f2b9b51a6fdf338d80ba489f52a57"},"cell_type":"code","source":"# load the training set\ntrain = pd.read_csv('../input/train.csv')\n\n# load the test set\ntest = pd.read_csv('../input/test.csv')\n\n# print some samples from the training set\ntrain.sample(5)","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"cfba8f44627a0e3ffdc50b2b5998437b1eacbaa4"},"cell_type":"markdown","source":"# Describe the Data\n\nUsing the `describe` function to check out all the columns, and values of the training data."},{"metadata":{"trusted":true,"_uuid":"c3685afc052844e6ed90cd95eccc5c4887aa8991"},"cell_type":"code","source":"# describe training data\ntrain.describe(include='all')","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"7916e694e03cac3d1a4981e43236ff56a652b079"},"cell_type":"markdown","source":"There are 12 columns with 891 values:\n\n* PassengerId (int): Self explanatory\n\n\n* Survived (int): Did the passenger survive or not\n\n\n* PClass (int): Ticket Class\n\n\n* Name (string)\n\n\n* Sex (string)\n\n\n* Age (float): If you see the Age column in the table above, you can see that only 714 out of 891 values have been recorded. In the data preprocessing step, we will fill in the missing values.\n\n\n* SibSp(int): No. of siblings/spouses aboard\n\n\n* Parch(int): No. of parents/children aboard\n\n\n* Ticket(int)\n\n\n* Fare(float)\n\n\n* Cabin(string): Only 204 values have been recorded for cabin. There is a huge gap that we might need to fill (891 - 204), hence the best way would be that we drop this column as we move forward towards prediction.\n\n\n* Embarked(string): Boarding point, we will fill in the 2 missing values later in the preprocessing step."},{"metadata":{"_uuid":"3d4be73533a9fe61e2320894de8007cdc41781b6"},"cell_type":"markdown","source":"# Data Visualization\n\n### Embarked Feature:"},{"metadata":{"trusted":true,"_uuid":"c4348bdd2a4fa69f50f908901c29346ac126def4"},"cell_type":"code","source":"sns.barplot(x=\"Embarked\", y=\"Survived\", data=train)\n\nprint(\"Number of passengers who embarked at S: \", (train[\"Embarked\"] == \"S\").value_counts(normalize = True)[1] *100)\nprint(\"Number of passengers who embarked at C: \", (train[\"Embarked\"] == \"C\").value_counts(normalize = True)[1] *100)\nprint(\"Number of passengers who embarked at Q: \", (train[\"Embarked\"] == \"Q\").value_counts(normalize = True)[1] *100)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"6c95cf6dd6e395d4596f25879bfd09ef60856469"},"cell_type":"markdown","source":"#####  Observations:\n\n'S' is the most occurred value.\n\nPassengers who boarded at C had a higher change of survival, and those who boarded at S had the lowest (33%) survival rate."},{"metadata":{"_uuid":"8b5d89163c6dd35641fbd153bc91737d23219f34"},"cell_type":"markdown","source":"### Pclass Feature:"},{"metadata":{"trusted":true,"_uuid":"d120d2b350d727b929d09ef9d8bf63b9e5fdbc6f"},"cell_type":"code","source":"sns.barplot(x=\"Pclass\", y=\"Survived\", data=train)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"52f89691ab24172b17988e1f34ba79d07a28a7ae"},"cell_type":"markdown","source":"##### Observation:\n\nPeople with higher class (social status) had a higher survial rate (~62%)"},{"metadata":{"_uuid":"1cf3a3778bf936d18017819459b3381f89aee7b3"},"cell_type":"markdown","source":"### Sex Feature:"},{"metadata":{"trusted":true,"_uuid":"c0bc7429a0b21cb0f554bfe90bc7cd4018ac4d5f"},"cell_type":"code","source":"sns.barplot(x=\"Sex\", y=\"Survived\", data=train)","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"0eb98f1ca7a23b410ffad91b65288d712de391f1"},"cell_type":"markdown","source":"##### Observation:\nFemales had the higher survival rate as compared to male. This is one of most important feature in our training data"},{"metadata":{"_uuid":"07408970ccd74c719b0f02d6e4c2102151b332ee"},"cell_type":"markdown","source":"### Sibsp Feature:"},{"metadata":{"trusted":true,"_uuid":"629c9ed69d9e97946edc54520be3ae1f6d4edeec"},"cell_type":"code","source":"sns.barplot(x=\"SibSp\", y=\"Survived\", data=train)","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"cb254ff6aef1780a2d78c2dffe66fc9de127981d"},"cell_type":"markdown","source":"##### Observation:\n\nBy looking at the graph, it is evident that people with 1 sibling/spouses had the higher survival rate as compared to people with 0 or more than 1 siblings/spouses on board."},{"metadata":{"_uuid":"64ae1fcacaf3365e630060bf91625182ba5c009f"},"cell_type":"markdown","source":"### Parch Feature:"},{"metadata":{"trusted":true,"_uuid":"ca935942c061ff7aa78b1e42a715c787c1825244"},"cell_type":"code","source":"sns.barplot(x=\"Parch\", y=\"Survived\", data=train)","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"c0621b9978dde1f15f47fdf2b06823cb816d726b"},"cell_type":"markdown","source":"##### Observation:\n\nPeople who are travelling alone are less likely to survive than the people who are travelling with 1-3 parents/children. "},{"metadata":{"_uuid":"bd814fc3d892f6d6e8b8a88d60d11918b7872820"},"cell_type":"markdown","source":"### Name/Title Feature:\n\nExtracting out title from the passenger name, since Title (Mr, Mrs. etc) will give a substantial amount of information."},{"metadata":{"trusted":true,"_uuid":"90e504ed47862bb1a2e07b33dab0d2d2f2b50370"},"cell_type":"code","source":"train['Title'] = train.Name.str.extract('([A-Za-z]+)\\.', expand=False)\ntest['Title'] = test.Name.str.extract('([A-Za-z]+)\\.', expand=False)\n\nsns.barplot(x=\"Title\", y=\"Survived\", data=train)","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"a104667d84ea23dace827e39484029fafaae03aa"},"cell_type":"markdown","source":"# Preprocessing and Cleaning Data\n"},{"metadata":{"_uuid":"6826bdb76beb660a8fdb60299fc7755e0ea1000c"},"cell_type":"markdown","source":"## 1. First, let's start by dropping columns which may not be useful in prediction.\n\nLet's start by dropping columns which may not be useful in prediction. For now, we are dropping Ticket and PassengerId column (Ticket does not seem that helpful to me, but if possible we can extract out some piece of information, which might help in improving accuracy)"},{"metadata":{"trusted":true,"_uuid":"e6832db3c1baea3ee3b2456f5c582624ff738d46"},"cell_type":"code","source":"train = train.drop(['PassengerId', 'Ticket'], axis=1)\ntest = test.drop('Ticket', axis=1)\n\ntest.describe(include='all')","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"ef272cbf9c5d257300bd2b98474ca44b055cdbed"},"cell_type":"markdown","source":"## 2. Fill in missing values\n\nThere are some columns which have missing value. For eg Embarked. In the training set, out of 891 rows, only 889 have values filled in for Embarked feature. Similarly for age as well.\n\n### Embarked: \n\n(Only for train set, since test set has no missing values for Embarked)\n\nThere are 2 missing values for the `Embarked` column. In the data visualization step, we observed that `S` was the most occured value for this feature, hence we will fill the 2 missing values with `S`"},{"metadata":{"trusted":true,"_uuid":"27a9ae21642121f6bbee24b441f46ddbbd08140c"},"cell_type":"code","source":"# fill NaN values with S, since S is the most occured value\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\ntrain.describe(include='all')","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"2688848664c78d6fa63c65c586500b790a60849d"},"cell_type":"markdown","source":"### Fare:\n\n(Only required for test set, training set has no missing values for Fare)"},{"metadata":{"trusted":true,"_uuid":"15870c08c7af4987be022c5464ec0ecff5d89892"},"cell_type":"code","source":"# fill in the missing fare values in test set\n# use the median value to fill up missing rows\ntest[\"Fare\"] = test[\"Fare\"].fillna(test[\"Fare\"].median())\ntest.describe(include='all')","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"87a1cbfa48982fc15a4ebba625bf2a003e68fbc5"},"cell_type":"markdown","source":"### Age:\n\n(Required for both training and test set)\n\nReference: (https://www.kaggle.com/omarelgabry/a-journey-through-titanic?scriptVersionId=447794)"},{"metadata":{"trusted":true,"_uuid":"7dd5d191172b2997e7de9f56518f0a292af56b9a"},"cell_type":"code","source":"# get average, std and missing values for age in training set\ntraining_age_avg = train[\"Age\"].mean()\ntraining_age_std = train[\"Age\"].std()\ntraining_age_missing = train[\"Age\"].isnull().sum()\n\nprint(\"Avg Training Age:\", training_age_avg, \"Std Training Age:\", training_age_std, \n      \"Missing Age:\",training_age_missing)\n\n# get average, std and missing values for age in test set\ntest_age_avg = test[\"Age\"].mean()\ntest_age_std = test[\"Age\"].std()\ntest_age_missing = test[\"Age\"].isnull().sum()\n\nprint(\"Avg Test Age:\", test_age_avg, \"Std Test Age:\", test_age_std, \"Missing Age:\",test_age_missing)\n\n# generate random number between (mean - std) & (mean + std)\nrandom_1 = np.random.randint(training_age_avg - training_age_std, training_age_avg + training_age_std,\n                            size = training_age_missing)\n\nrandom_2 = np.random.randint(test_age_avg - test_age_std, test_age_avg + test_age_std, size = test_age_missing)\n\ntrain['Age'].dropna()\ntrain[\"Age\"][np.isnan(train[\"Age\"])] = random_1\n\ntest['Age'].dropna()\ntest[\"Age\"][np.isnan(test[\"Age\"])] = random_2","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"18fb6753472c040b1a65eef4b37f5d08b4432b38"},"cell_type":"markdown","source":"## 3. Cleaning Data\n\n### Sex Feature: \n\nMap male and female to integers"},{"metadata":{"trusted":true,"_uuid":"d478e262c6d7cc8319be228a8284b86c6e267df9"},"cell_type":"code","source":"combine = [train, test]\n\n# integer mapping for male and female vars\nsex_map = {\"male\": 0, \"female\": 1}\n\n# map male and female to integers\nfor dataset in combine:\n    dataset[\"Sex\"] = dataset[\"Sex\"].map(sex_map)\n\n# extract out male and female as separate features in the dataset\nfor dataset in combine:\n    dataset['Male'] = dataset['Sex'].map(lambda s: 1 if s == 0 else 0)\n    dataset['Female'] = dataset['Sex'].map(lambda s: 1 if  s == 1  else 0)\n\n# remove Sex feature, as we already have male and female feature\ntrain = train.drop('Sex', axis=1)\ntest = test.drop('Sex', axis=1)\n\ntrain.head()","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"0fd72c29b8b1ae8f3cc63db672bfe722366e03e8"},"cell_type":"markdown","source":"## Embarked Feature:\n\nMap S, C and Q to integer values\n"},{"metadata":{"trusted":true,"_uuid":"0c08a9be4e35ee6e24082654da15c1b992c8ecc3"},"cell_type":"code","source":"combine = [train, test]\n\n# integer mapping for embarked feature\nembark_map ={\"S\": 0, \"C\": 1, \"Q\": 2}\n\n# map S, C and Q to integers\nfor dataset in combine:\n    dataset[\"Embarked\"] = dataset[\"Embarked\"].map(embark_map)\n\n# extract out S, C and Q as separate features in the dataset\nfor dataset in combine:\n    dataset['Embarked_S'] = dataset['Embarked'].map(lambda s: 1 if s == 0 else 0)\n    dataset['Embarked_C'] = dataset['Embarked'].map(lambda s: 1 if  s == 1  else 0)\n    dataset['Embarked_Q'] = dataset['Embarked'].map(lambda s: 1 if  s == 2  else 0)\n\n# remove Embarked feature, as we already have S, C and Q feature\ntrain = train.drop('Embarked', axis=1)\ntest = test.drop('Embarked', axis=1)\n\ntrain.head()","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"177d8123f8f72a7f592923435c3bb5851b5b3d59"},"cell_type":"markdown","source":"## Title Feature:\n\nMap title values to integer"},{"metadata":{"trusted":true,"_uuid":"e857a0d8d4df4ad744a2a2d2dddce9ebdbdf854e"},"cell_type":"code","source":"combine = [train, test]\n\n#extract a title for each Name in the train and test datasets\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Capt', 'Col',\n    'Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\n# map each of the title groups to a numerical value\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 6}\n\n# extract out different titles as features\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    dataset['Title_Mr'] = dataset['Title'].map(lambda s: 1 if s == 1 else 0)\n    dataset['Title_Miss'] = dataset['Title'].map(lambda s: 1 if  s == 2  else 0)\n    dataset['Title_Mrs'] = dataset['Title'].map(lambda s: 1 if  s == 3  else 0)\n    dataset['Title_Master'] = dataset['Title'].map(lambda s: 1 if  s == 4  else 0)\n    dataset['Title_Royal'] = dataset['Title'].map(lambda s: 1 if  s == 5  else 0)\n    dataset['Title_Rare'] = dataset['Title'].map(lambda s: 1 if  s == 6  else 0)\n\n# remove Title feature, as we already have different titles as feature\ntrain = train.drop(['Title', 'Name'], axis=1)\ntest = test.drop(['Title', 'Name'], axis=1)\n\ntrain.head()","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"6d8a5997a6971a0824a7653915629f49b99d59f6"},"cell_type":"markdown","source":"### Family Feature:\n\nCreate a new feature based on the family size"},{"metadata":{"trusted":true,"_uuid":"e23dbfcea727337f051ffedb85b6dbd421750e9c"},"cell_type":"code","source":"combine = [train, test]\n\n# create a Fsize feature\nfor dataset in combine:\n    dataset[\"Fsize\"] = dataset[\"SibSp\"] + train[\"Parch\"] + 1\n\n# extract out Fsize into 4 different features\nfor dataset in combine:\n    dataset['Single'] = dataset['Fsize'].map(lambda s: 1 if s == 1 else 0)\n    dataset['SmallF'] = dataset['Fsize'].map(lambda s: 1 if  s == 2  else 0)\n    dataset['MedF'] = dataset['Fsize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n    dataset['LargeF'] = dataset['Fsize'].map(lambda s: 1 if s >= 5 else 0)\n\n# remove Fsize, SibSp and Parch feature, as we already have features on family size\ntrain = train.drop(['Fsize', 'SibSp', 'Parch'], axis=1)\ntest = test.drop(['Fsize', 'SibSp', 'Parch'], axis=1)\n\ntrain.head()","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"9fb1c6ea56b13f3f262cb44ba5956c0cceec614e"},"cell_type":"markdown","source":"### PClass Feature:\n\nExtract out PClass into separate features"},{"metadata":{"trusted":true,"_uuid":"e7640d4d81fad4c31cbd87b7ec8b197434fec004"},"cell_type":"code","source":"combine = [train, test]\n\n# extract out Pclass into 3 different features\nfor dataset in combine:\n    dataset['Upper_Class'] = dataset['Pclass'].map(lambda s: 1 if s == 1 else 0)\n    dataset['Middle_Class'] = dataset['Pclass'].map(lambda s: 1 if  s == 2  else 0)\n    dataset['Lower_Class'] = dataset['Pclass'].map(lambda s: 1 if s == 3 else 0)\n\n# remove Pclass, as we already have features on classes\ntrain = train.drop('Pclass', axis=1)\ntest = test.drop('Pclass', axis=1)\n\ntrain.head()","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"f6d7ee78de2cca1b930efb39e78ab43d5ca6a51a"},"cell_type":"markdown","source":"### Fare Feature:"},{"metadata":{"trusted":true,"_uuid":"ace67b1aa855805343ea67fdfecc16fe866c3dcd"},"cell_type":"code","source":"combine = [train, test]\n\nfor dataset in combine:\n    dataset['FareBand'] = pd.qcut(dataset['Fare'], 4, labels = [1, 2, 3, 4])\n\ntrain = train.drop('Fare', axis=1)\ntest = test.drop('Fare', axis=1)\n\ntrain.head()","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"2b303c786470a3fb64e71a4d5d2c0e392a5eea62"},"cell_type":"markdown","source":"### Cabin Feature:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"55846ff1b088e5a4803c94cd7c8c4c44db551af2"},"cell_type":"code","source":"combine = [train, test]\n\n# fill missing cabin values with U (undefined)\nfor dataset in combine:\n    dataset[\"Cabin\"] = dataset[\"Cabin\"].fillna('U')\n\n# integer mapping for cabins\ncabin_map = {\"U\": 0, \"C\": 1, \"E\": 2, \"G\": 3, \"D\": 4, \"A\": 5, \"B\": 6, \"F\": 7, \"T\": 8}\n\n# map integers to cabin\nfor dataset in combine:\n    dataset[\"Cabin\"] = dataset[\"Cabin\"].map(cabin_map)\n\nfor dataset in combine:\n    dataset['Cabin_U'] = dataset['Cabin'].map(lambda s: 1 if s == 0 else 0)\n    dataset['Cabin_C'] = dataset['Cabin'].map(lambda s: 1 if  s == 1  else 0)\n    dataset['Cabin_E'] = dataset['Cabin'].map(lambda s: 1 if s == 2 else 0)\n    dataset['Cabin_G'] = dataset['Cabin'].map(lambda s: 1 if s == 3 else 0)\n    dataset['Cabin_D'] = dataset['Cabin'].map(lambda s: 1 if s == 4 else 0)\n    dataset['Cabin_A'] = dataset['Cabin'].map(lambda s: 1 if s == 5 else 0)\n    dataset['Cabin_B'] = dataset['Cabin'].map(lambda s: 1 if s == 6 else 0)\n    dataset['Cabin_F'] = dataset['Cabin'].map(lambda s: 1 if s == 7 else 0)\n    dataset['Cabin_T'] = dataset['Cabin'].map(lambda s: 1 if s == 8 else 0)\n\ntrain = train.drop(['Cabin'], axis=1)\ntest = test.drop('Cabin', axis=1)","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"95e622a84807518ae128c3721a72dfc9708b5220"},"cell_type":"markdown","source":"# Choosing Model\n\nLet's run the training set using different types of model:\n\n* Logistic Regression\n\n\n* Support Vector Machine\n\n\n* Random Forest Classifier\n\n\n* Decision Tree Classifier\n\n\n* Gradient Boost Classifier"},{"metadata":{"trusted":true,"_uuid":"6a9ea5f38855ba2450bac0baccf1cb702e1cba86"},"cell_type":"code","source":"X_train = train\nY_train = train[\"Survived\"]\nX_test = test.copy()\n\nX_test.head()","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"00aaefbbf39c0460cb5a1fe71e45854873024922"},"cell_type":"markdown","source":"## Logistic Regression:"},{"metadata":{"trusted":true,"_uuid":"f998f376a573d17dac8199e203957533cdec2aba"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr.fit(X_train, Y_train)\nY_pred = lr.predict(X_test)\nlr.score(X_train, Y_train)","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"11f32983edf9aede6a48cb5280660c41e421873a"},"cell_type":"markdown","source":"## Support Vector Machine:"},{"metadata":{"trusted":false,"_uuid":"08da2a087f007f40abe3d5114af1ffd604bc41b5"},"cell_type":"code","source":"from sklearn import svm\n\nsvm = svm.SVC()\nsvm.fit(X_train, Y_train)\nY_pred = svm.predict(X_test)\nsvm.score(X_train, Y_train)","execution_count":30,"outputs":[]},{"metadata":{"_uuid":"6cce58096c8814b8db1f9aa320b6568cd992f542"},"cell_type":"markdown","source":"## Random Forest:"},{"metadata":{"trusted":false,"_uuid":"9081e54b9e339cbc5a646a4d1bf7893ca41d1582"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)","execution_count":39,"outputs":[]},{"metadata":{"_uuid":"6a250e346a51a4e0ed36d824bd95be2a8c4f3d05"},"cell_type":"markdown","source":"## Decision Tree:\n"},{"metadata":{"trusted":false,"_uuid":"5f5b634a23f6fc3fbb855636d9f07a3b90cc46aa"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold\n\nkfold = StratifiedKFold(n_splits=10)\n\nDTC = DecisionTreeClassifier()\n\nadaDTC = AdaBoostClassifier(DTC, random_state=7)\n\nada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n              \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n              \"n_estimators\" :[1,2],\n              \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\n\ngsadaDTC = GridSearchCV(adaDTC,param_grid = ada_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsadaDTC.fit(X_train,Y_train)\n\nada_best = gsadaDTC.best_estimator_\n\ngsadaDTC.best_score_\n\nids = test[\"PassengerId\"]\n\npredictions = gsadaDTC.predict(X_test)\n\nids = test[\"PassengerId\"]\nint_id = []\nfor i in ids:\n    int_id.append(int(i))\n    \nint_pred = []\nfor y in predictions:\n    int_pred.append(int(y))\n\noutput = pd.DataFrame({\"PassengerId\": int_id, \"Survived\": int_pred})\noutput.to_csv(\"submission.csv\", index=False)\n\ngsadaDTC.best_score_","execution_count":43,"outputs":[]},{"metadata":{"_uuid":"c94b0f7cd1fe7d61447d518c70f1a3543fa05499"},"cell_type":"markdown","source":"## Gradient Boost:"},{"metadata":{"trusted":false,"_uuid":"90b939550c45956a87b7fa3977ac9cc118166fa3"},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbc = GradientBoostingClassifier()\ngbc.fit(X_train, Y_train)\nY_pred = gbc.predict(X_test)\ngbc.score(X_train, Y_train)","execution_count":27,"outputs":[]},{"metadata":{"_uuid":"7383666679bc8aeefa87ab168c3a61b3e6d5e678"},"cell_type":"markdown","source":"### Among all the models used, Random Forest Classifier gave the highest accuracy of 0.986."},{"metadata":{"trusted":true,"_uuid":"844d3e4a733143b059ce916179dd2878cff93751"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold\nkfold = StratifiedKFold(n_splits=10)\n\nRFC = RandomForestClassifier()\n\n## Search grid for optimal parameters\nrf_param_grid = {\"max_depth\": [n for n in range(9, 14)],\n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [n for n in range(4, 11)],\n              \"min_samples_leaf\": [n for n in range(2, 5)],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[n for n in range(10, 60, 10)],\n              \"criterion\": [\"gini\"]}\n\ngsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsRFC.fit(X_train,Y_train)\n\nRFC_best = gsRFC.best_estimator_\n\n# Best score\ngsRFC.best_score_\n\n# random_forest = RandomForestClassifier(n_estimators=100)\n# random_forest.fit(X_train, Y_train)\npredictions = gsRFC.predict(X_test)\ngsRFC.score(X_train, Y_train)\n\nids = test[\"PassengerId\"]\nint_id = []\nfor i in ids:\n    int_id.append(int(i))\n    \nint_pred = []\nfor y in predictions:\n    int_pred.append(int(y))\n\noutput = pd.DataFrame({\"PassengerId\": int_id, \"Survived\": int_pred})\noutput.to_csv(\"submission.csv\", index=False)\n\n\ngsRFC.best_score_\n\n# print (\"Starting 1\")\n# forrest_params = dict(     \n#     max_depth = [n for n in range(9, 14)],     \n#     min_samples_split = [n for n in range(4, 11)], \n#     min_samples_leaf = [n for n in range(2, 5)],     \n#     n_estimators = [n for n in range(10, 60, 10)],\n# )\n# print (\"Starting 2\")\n\n# forrest = RandomForestClassifier()\n# print (\"Starting 3\")\n\n# forest_cv = GridSearchCV(estimator=forrest, param_grid=forrest_params, cv=5) \n# print (\"Starting 4\")\n\n# forest_cv.fit(X_train, Y_train)\n# print (\"Starting 5\")\n\n# print(\"Best score: {}\".format(forest_cv.best_score_))\n# print(\"Optimal params: {}\".format(forest_cv.best_estimator_))\n\n# # random forrest prediction on test set\n# predictions = forest_cv.predict(X_test)\n# print (\"Starting 6\")\n\n# output = pd.DataFrame({\"PassengerId\": ids, \"Survived\": predictions})\n# output.to_csv(\"submission.csv\", index=False)\n\n# print (\"Starting 7\")\n\n\n# print(\"Best score: {}\".format(forest_cv.best_score_))\n# print(\"Optimal params: {}\".format(forest_cv.best_estimator_))","execution_count":2,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"nbformat":4,"nbformat_minor":1}