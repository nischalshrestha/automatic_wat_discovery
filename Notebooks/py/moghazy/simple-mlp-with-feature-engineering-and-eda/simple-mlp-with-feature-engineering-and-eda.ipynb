{"cells":[{"metadata":{"_uuid":"6b07cd2a3a3c758dbdff5c4a571c3e4ee94e8793"},"cell_type":"markdown","source":"# Simple Deep Neural Networks with Keras\nIn this tutorial i am going to show how to implement Deep Neural Networks in keras and Also we will have a look on simple feature engineering to be able to classify the dataset efficiently"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a36183f4043627fec4f3650053c87c7ca53218d"},"cell_type":"markdown","source":"First let's start by importing our dataset into dataframes using pandas. Dataframes enables us to work easily with data usign its built in functions."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"import pandas as pd\ntraining = pd.read_csv(\"../input/train.csv\");\n\nx_test = pd.read_csv(\"../input/test.csv\");","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97c4d91a27c09288157977984350cf16ffbe6838"},"cell_type":"markdown","source":"Now let's have a look on the dataset and search for important information manually."},{"metadata":{"trusted":true,"_uuid":"28840817ba08cfc35db8f2e57d86ff2b157a26b9"},"cell_type":"code","source":"training.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8bb539321270d3849d28c8718c017fa68d38a55"},"cell_type":"markdown","source":"Now I will explore the correlations of the featues relative to the target variable.\n#### Note: not all features are listed but only numeric features."},{"metadata":{"trusted":true,"_uuid":"7604110320e2365715dcc82ba4ad61dc2ddbfa7b"},"cell_type":"code","source":"import seaborn as sns\n\n\nimport matplotlib.pyplot as plt\n\n\ncorr = training.corr()\nf, ax = plt.subplots(figsize=(25, 25))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f1b03833324ea57f1b212c4901336790861fd487"},"cell_type":"markdown","source":"I will explore the size of the dataset to compare it with the number of NANs in the dataset"},{"metadata":{"trusted":true,"_uuid":"d9b24d2016dad11bb905008fba850ecb88555deb"},"cell_type":"code","source":"print(\"The number of traning examples(data points) = %i \" % training.shape[0])\nprint(\"The number of features we have = %i \" % training.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9a40efd24290bbcf850312ca62a93379cd68491"},"cell_type":"markdown","source":"I will count the number of data examples in each class in the target to determine which metric to use while evaluationg performance."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"db74e9a52ccc648877bb40881c98328ab454b393"},"cell_type":"code","source":"unique, count= np.unique(training[\"Survived\"], return_counts=True)\nprint(\"The number of occurances of each class in the dataset = %s \" % dict (zip(unique, count) ), \"\\n\" )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba43f7e67b107fbe128df6818e4c45dfdf424c19"},"cell_type":"markdown","source":"The numbers doesn't seem to be very far from each other, So i will use accuracy for performance eval.."},{"metadata":{"_uuid":"2b591db4e26212f186e884786819f3bcc9f92a70"},"cell_type":"markdown","source":"Now i will check the number of Null values. If most of a column's values are Nulls or NaNs i will drop it because filling it will not be accurate but if the number is small then i will fill it with the mean values."},{"metadata":{"trusted":true,"_uuid":"c414b828b9c785123d5890a1f9de373cea4e47ab"},"cell_type":"code","source":"training.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d01947a20fc55d38ddf2569af9b5e9f558dcae8b"},"cell_type":"markdown","source":"From the results of correlation matrix and the Nan number and manual checking of dataset, I will drop \"Name\" ,\"Ticket\",\"Cabin\" and \"PassengerId\".\n<lb>I will also store the label column and drop it from training.\n<lb>Then i will engineer the catagorical features and map the strings to integers to be able to use it in the model later."},{"metadata":{"trusted":true,"_uuid":"702243b3b8b99fae9b0acb01d0705a624d34a7a9","scrolled":true},"cell_type":"code","source":"np.random.seed(0)\ntraining.drop([ \"Name\" , \"PassengerId\",\"Ticket\",\"Cabin\"], inplace = True, axis = 1 )\ntraining.dropna( inplace = True)\nx_train = training\nrepCol3 = {  \"male\":0, \"female\" : 1}\nrepCol8 = {\"C\" : 0 ,   \"Q\" : 1 , 'S' : 2  }\n\nx_train['Family'] = x_train ['SibSp'] + x_train['Parch']\nx_train['IsAlone'] = 1\nx_train['IsAlone'].loc[x_train['Family'] > 0] = 0\n    \n# mean = x_train.mean().astype(np.int32)\n# print (mean)\n# x_train.fillna( mean , inplace = True)\nx_train.replace({\"Sex\": repCol3, \"Embarked\": repCol8} , inplace = True )\n# x_train = x_train / x_train.max() # Normalizing x_train data\nprint( x_train.shape )\nx_train.head(100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b623a6ffeda73b4fd885b5085c6341da84ada00f"},"cell_type":"code","source":"from scipy import stats\nimport numpy as np\n\nz = np.abs(stats.zscore(x_train))\nzee = (np.where(z > 3))[1]\n\nprint(\"number of data examples greater than 3 standard deviations = %i \" % len(zee))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15d6df30f166b42ccbd47f4b570bd556c5c92820"},"cell_type":"code","source":"# x_train = x_train[(z < 2.5).all(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a08ec961be82d25c2da859112f1133dbe6233ef"},"cell_type":"code","source":"x_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bef3b5a6ce3b1aeab307201c8252853400dae2ee"},"cell_type":"code","source":"y_train = x_train[\"Survived\"]\nx_train = x_train.drop(['Survived'], axis = 1)\n\nprint(y_train.shape )\ny_train.head(20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"297140108fe482363791fa2d647ddd0f03a99e15"},"cell_type":"markdown","source":"I will Plot some features to see if there is any pattern in the data."},{"metadata":{"trusted":true,"_uuid":"340a7f8fcb1206acbbfe59b01c41711e034cfd27"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nclasses = np.array(list(y_train.values))\n\ndef plotRelation(first_feature, sec_feature):\n    \n    plt.scatter(first_feature, sec_feature, c = classes, s=10)\n    plt.xlabel(first_feature.name)\n    plt.ylabel(sec_feature.name)\n    \nf = plt.figure(figsize=(25,20))\nf.add_subplot(331)\nplotRelation(x_train.Pclass, x_train.Embarked)\nf.add_subplot(332)\nplotRelation(x_train.Pclass, x_train.Age)\nf.add_subplot(333)\nplotRelation(x_train.Age, x_train.Sex)\nf.add_subplot(334)\nplotRelation(x_train.SibSp, x_train.Parch)\nf.add_subplot(335)\nplotRelation(x_train.Fare, x_train.Embarked)\nf.add_subplot(336)\nplotRelation(x_train.Fare, x_train.Embarked)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d2f282a4678c54731c02b2b0e9cc47c6133bb004"},"cell_type":"markdown","source":"Since i dropped some features from the training set I have to drop the same featurres from the test set and do the same steps of feature eng."},{"metadata":{"trusted":true,"_uuid":"786e9d4073b9e8717325297c67ee47c28f9be7f7"},"cell_type":"code","source":"x_test.drop([\"Name\",\"Ticket\",\"Cabin\" ], inplace = True, axis = 1 )\nx_test.replace({\"Sex\": repCol3, \"Embarked\": repCol8} , inplace = True )\nx_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d16aae371a092c32ef88c6f7101387269e91839c"},"cell_type":"markdown","source":"Now it is time to design the ML Pipeline. I will use Deep Neural Networks in Keras to classify the dataset. The number of layers i am using is optmized using some error analys of the results.\n<lb> I will use early stopping to stop if the error is not decreasing."},{"metadata":{"trusted":true,"_uuid":"4b033228ff01ff54d6c3e471f8cde84edc763da2"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import np_utils\nfrom keras import callbacks\nfrom keras import optimizers\n#y_train = np_utils.to_categorical(y_train)\n\nInputDimension = 9\nprint(y_train.shape )\n\nmodel = Sequential()\nmodel.add(Dense(10, input_dim=InputDimension, activation='relu'))\nmodel.add(Dense(10, activation='relu'))\n\nmodel.add(Dense(2, activation='softmax'))\n\n\nearlystopping = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=30, verbose=0, mode='min')\noptimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.001)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\nhistory = model.fit(x_train, pd.get_dummies(y_train), epochs=1000, batch_size=200, validation_split=0.2, verbose=0, callbacks=[earlystopping])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6c9703ed468d0ec3351a25dc9fba4ac89483901"},"cell_type":"markdown","source":"Now let's see how good is my training with respect to validation accuracies."},{"metadata":{"trusted":true,"_uuid":"d2d7508d6d394d8c85d3c27c254b9e2b2ea12d79"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92f7a5cb757572ccb53ad62e551cf653e5262980"},"cell_type":"markdown","source":"Now i will normalize the test set as i did before and will fill null values in the dataset as well."},{"metadata":{"trusted":true,"_uuid":"361656fc7fed40b326be7c17a104a32ddafeef6b"},"cell_type":"code","source":"id = x_test['PassengerId']\n\nx_test.drop(['PassengerId'], inplace = True, axis = 1)\n\nx_test['Family'] = x_test ['SibSp'] + x_test['Parch']\nx_test['IsAlone'] = 1\nx_test['IsAlone'].loc[x_test['Family'] > 0] = 0\n\n\nx_test.fillna( x_test.median() ,inplace = True)\n# x_test = x_test/ x_test.max()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"162726d19aaec49fe1e29599637424d79537b346"},"cell_type":"markdown","source":"Now every thing is okay with the dataset so i will predict the output values for submission"},{"metadata":{"trusted":true,"_uuid":"dcd1fdc352632ae8cbd0988065bfa31e61915972","scrolled":true},"cell_type":"code","source":"\npredictions = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee468f31cc1b1677e91872db7035d6d375c26789"},"cell_type":"markdown","source":"Predictions will return probability between 0 and 1 for survived or non survived so i will take the argmax() of the array to get the max index for each test example"},{"metadata":{"trusted":true,"_uuid":"15f383ea3ec3fd9ff4b8cf8040ff53fba6dd4ce4","scrolled":false},"cell_type":"code","source":"predictions = np.rint(predictions)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6a1a4d8cdb3415b99be326bc9aa3d5b4c72934d"},"cell_type":"markdown","source":"I will convert the array into dataframe with one col target value instead of two since my model returns 2 cols because of the 2 classes i have in the last layer."},{"metadata":{"trusted":true,"_uuid":"7f46a29785f3ac3f2f5c95c2b25519fe828f1e9f"},"cell_type":"code","source":"predict = pd.DataFrame(predictions, columns=['0', '1']).astype('int')\npredict['Survived'] = 0\npredict.loc[predict['0'] == 1, 'Survived'] = 0\npredict.loc[predict['1'] == 1, 'Survived'] = 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"186aeeef16eaaccd8f40ea9b863fca44f4768a61"},"cell_type":"markdown","source":"It is time to make submission."},{"metadata":{"trusted":true,"_uuid":"41d2e0b4d974f05b5a5b73df6bba8b7f612ce0b5","scrolled":true},"cell_type":"code","source":"id.reset_index(drop=True, inplace=True)\noutput = pd.concat([id,predict['Survived'] ], axis=1)\noutput.to_csv('titanic-predictions.csv', index = False)\noutput.head(100)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}