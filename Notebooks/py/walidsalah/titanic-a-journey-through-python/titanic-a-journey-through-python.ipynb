{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f2883730-7aef-a9ca-fa01-79da69234fac",
        "_active": false,
        "collapsed": false
      },
      "source": "## Introduction\n This is my first trial to apply ML analysis for Titanic disaster in Python.\n\n**Throw this Kernel I will cover the following ML roadmap:**\n\n   * **Data Preprocessing**\n    * Handling missing values\n    * Encode categorical variables\n    * Feature extraction\n\n   * **Learning**\n   * **Evaluation**\n   * **Preduction**\n\n\n    ",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "6ad6c376-d9f8-5d2f-a1db-cea452deeb0a",
        "_active": true,
        "collapsed": false
      },
      "source": "## Data Preprocessing ##\n\nTo build a good machine learning model the quality of data play a critical role before we feed it to a learning algorithm. Throw *Data Preprocessing* stage we try to apply useful techniques to make sure that we handle missing data correctly   Okay, letâ€™s load the data and have a look at it. 56\n\n",
      "execution_count": null,
      "cell_type": "markdown",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7965fa73-829c-cc96-e21a-b631395e0651",
        "_active": false,
        "collapsed": false
      },
      "outputs": [],
      "source": "    import pandas as pd",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b8e9fb16-b169-6bdd-36ac-4a6023853b79",
        "_active": false
      },
      "source": "Data Handling\n-------------\nfirst we need to load our data ",
      "execution_count": null,
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "62bb35b8-b057-52c3-77cf-0ee8daba6ca5",
        "_active": false
      },
      "outputs": [],
      "source": "X = pd.read_csv('../input/train.csv', header=None)\nY = pd.read_csv('../input/test.csv', header=None)\nX.head()",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f313154b-cee9-1eb9-307c-b22e97e384a5",
        "_active": false
      },
      "outputs": [],
      "source": null,
      "execution_state": "idle"
    }
  ]
}