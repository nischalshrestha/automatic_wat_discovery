{"nbformat": 4, "nbformat_minor": 1, "metadata": {"language_info": {"mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py", "version": "3.6.1", "name": "python"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "cells": [{"source": ["** Thanks Omar El Gabry 's wonderful Kernel -- A Journey through Titanic, which is the first Kernel I start from in Kagge. I would like to contribue some efforts so that the code is more comcise and beginner friendly. **\n", "\n", "\n", "----------------------------------------\n", " *  Rewrite the code in more concise version\n", " *  Using pipe to chain data preparation proceures\n", " *  Short version is less formidable to beginner\n", "\n"], "cell_type": "markdown", "metadata": {"_cell_guid": "91fca287-d357-4a5e-ac05-738487a16be5", "_uuid": "ee42a9ae9500b007a2787cbd37dd842662db5570"}}, {"source": ["### 1.  Import  libraries"], "cell_type": "markdown", "metadata": {"_cell_guid": "c09423c3-c166-4851-91ac-755365ae39b4", "_uuid": "91cf4ef80ba366ff3b20f11bf7fa5412dbed4b36"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["# Import libraries\n", "# pandas numpy, matplotlib, seaborn\n", "import pandas as pd\n", "from pandas import Series,DataFrame\n", "pd.options.mode.chained_assignment = None \n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "sns.set_style('whitegrid')\n", "%matplotlib inline\n", "\n", "# machine learning\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.ensemble import RandomForestClassifier"], "metadata": {"_cell_guid": "13f83811-cedf-4ce8-ab6f-259b0d912271", "collapsed": true, "_uuid": "9cb7947231143dc63e2acaed6348e6fb6df4c123"}}, {"source": ["### 2. Read data"], "cell_type": "markdown", "metadata": {"_cell_guid": "8a1d1f57-65f9-4713-9994-78653130cd1a", "_uuid": "429cb823e3d292e7634f237c2d6b16cc32d11f37"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["# Read data\n", "train_data = pd.read_csv(\"../input/train.csv\")\n", "y_train=train_data.loc[:,\"Survived\"].values\n", "train_df=train_data.drop(\"Survived\",1)\n", "test_df = pd.read_csv(\"../input/test.csv\")\n", "\n", "# preview the data\n", "train_data.head()"], "metadata": {"_cell_guid": "0ba83a23-b069-4641-ad64-8e18ee68058c", "collapsed": true, "_uuid": "c7c9897da45e2b1c91988f78e3ba454848692edf"}}, {"source": ["### 3.  Analyze and visualize data"], "cell_type": "markdown", "metadata": {"_cell_guid": "05d2a811-e640-49ac-a958-adf68558a560", "_uuid": "63257d0dd122383dad7793123b0b212b2f6b0b5f"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["# Analyze and visualize data\n", "#-- Continuous variables\n", "cols1=['Survived','Age','Parch','SibSp','Fare']\n", "# View the correlation matrix with heatmap \n", "cm = np.corrcoef(train_data[cols1].values.T)\n", "hm = sns.heatmap(cm,\n", "    cbar=True,\n", "    annot=True,\n", "    square=True,\n", "    cmap=\"YlGnBu\",             \n", "    fmt='.2f',\n", "    annot_kws={'size': 15},\n", "    yticklabels=cols1,\n", "    xticklabels=cols1)"], "metadata": {"_cell_guid": "f39f4b04-5235-446c-9b26-b81c037939bf", "collapsed": true, "_uuid": "134c5cbbf36be60f1c6bbcec0893397d85f64495"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["# -- Categorical variables\n", "\n", "cols2=['Sex','Parch','SibSp','Pclass','Embarked']\n", "# flatten compounded tuples\n", "import itertools\n", "flatten=lambda x: list(itertools.chain.from_iterable(x))\n", "\n", "# factorplot\n", "fig, axes = plt.subplots(3,2,figsize=(15,8))\n", "fig.suptitle(\"Factor plot -- Survived vs Factors\",fontsize=18)\n", "\n", "\n", "for v, axis in zip(cols2,flatten(axes)):\n", "    g=sns.factorplot(v,'Survived', data=train_data,ax=axis)\n", "    plt.close(g.fig)\n", "# countplot\n", "fig, axes = plt.subplots(3,2,figsize=(15,8))\n", "fig.suptitle(\"Count plot -- Count vs Factors\",fontsize=18)\n", "for v, axis in zip(cols2,flatten(axes)):\n", "    sns.countplot(x=v,hue='Survived', data=train_data,ax=axis, palette=\"Set1\")"], "metadata": {"_cell_guid": "dde34c7c-4a47-4f91-890c-46d19554d753", "_uuid": "d0bd71b45744bf149b10e9c838ea69de6188b3ef"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["# print data info\n", "train_df.info()\n", "print(\"----------------------------\")\n", "test_df.info()"], "metadata": {"_cell_guid": "8bd49c99-0f70-450a-b93b-f30ae2eb9c27", "_uuid": "d2d017552012f01cc3e873185233393d91dd89ec"}}, {"source": ["### 4. Prepare data"], "cell_type": "markdown", "metadata": {"_cell_guid": "1d4346af-803f-47d1-a7c9-6ad9237a0cb3", "_uuid": "652be040d844345aed688628b2f7a92fe9edf521"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["# filling na\n", "# only in titanic_df, fill the two missing values with the most occurred value, which is \"S\".\n", "train_data[\"Embarked\"] = train_data[\"Embarked\"].fillna(\"S\")\n", "# only for test_df, since there is a missing \"Fare\" values\n", "test_df[\"Fare\"].fillna(test_df[\"Fare\"].median(), inplace=True)\n", "# Age\n", "# Filling na with generated random numbers between (mean - std) & (mean + std)\n", "def fix_age(df):\n", "    X=df[\"Age\"]\n", "    m=X.mean()\n", "    s=X.std()\n", "    n=X.isnull().sum()\n", "    rand=np.random.randint(m-s, m+s,n)\n", "    X[X.isnull()]=rand\n", "    X.astype(int)\n", "    return df\n", "\n", "# Family\n", "# Add a Family variable if the passenger had any family member aboard or not,\n", "def fix_family(df):\n", "    df['Family'] = np.where( df[\"Parch\"] + df[\"SibSp\"]>0,1,0)   \n", "    return df\n", "# Children(age < 16) on aboard seem to have a high chances for Survival.\n", "def fix_person(df):\n", "    df['Person']= np.where(df['Age']<16,'child',df['Sex'])\n", "    return df\n", "# chain the data preparation proceures together\n", "def fix_data(df):\n", "    selected=['Person','Age','Family', 'Fare','Pclass','Embarked']\n", "    return ( df.pipe(fix_age)\n", "               .pipe(fix_family)\n", "               .pipe(fix_person)\n", "               .pipe(lambda X: X[selected])\n", "                # Covert categoricals into dummy variables\n", "               .pipe(pd.get_dummies,\n", "                     columns=['Pclass','Person', 'Embarked'],\n", "                     drop_first=True\n", "                     )\n", "    )\n", "\n", "    \n", "\n", "X_train=train_df.pipe(fix_data).values\n", "X_test =test_df.pipe(fix_data).values  "], "metadata": {"_cell_guid": "c46bdde1-1384-4ca9-9ce8-de98e07e7508", "collapsed": true, "_uuid": "7e7f13de8a1529f6c28a0404b442a5d2a3ff420a"}}, {"source": ["### 5. Model data"], "cell_type": "markdown", "metadata": {"_cell_guid": "6a48801d-d46a-45bf-9175-13b94e712c47", "_uuid": "d527d3d0bcae27ec3ab52b6d9999ecb24026262a"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["# Logistic Regression\n", "\n", "logreg = LogisticRegression()\n", "\n", "logreg.fit(X_train, y_train)\n", "\n", "y_pred = logreg.predict(X_test)\n", "\n", "logreg.score(X_train, y_train)"], "metadata": {"_cell_guid": "262ba887-d686-4316-8bbf-897465b61558", "collapsed": true, "_uuid": "a01ae53d990d499e21e83d7bebce96d5d3a24ce6"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["# Random Forests\n", "\n", "random_forest = RandomForestClassifier(n_estimators=100)\n", "\n", "random_forest.fit(X_train, y_train)\n", "\n", "y_pred = random_forest.predict(X_test)\n", "\n", "random_forest.score(X_train, y_train)"], "metadata": {"_cell_guid": "258bba1b-6b96-4314-990b-77bcf69310b5", "_uuid": "ee9dd6a3ed96be97768efb9dfd259ec30e2b8e9e"}}, {"source": ["### 6. Submit Result"], "cell_type": "markdown", "metadata": {"_cell_guid": "52f42d43-bed0-48b6-ade8-8401113df2e8", "_uuid": "fbd053c350b51ad4000e74c445e7e37924306bcb"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["submission = pd.DataFrame({\n", "        \"PassengerId\": test_df[\"PassengerId\"],\n", "        \"Survived\": y_pred\n", "    })\n", "submission.to_csv('titanic.csv', index=False)"], "metadata": {"_cell_guid": "55fcb080-5fc9-4e77-a93b-034b63c707df", "collapsed": true, "_uuid": "e4dab46990de9dda54127fa692e1cbab49585292"}}]}