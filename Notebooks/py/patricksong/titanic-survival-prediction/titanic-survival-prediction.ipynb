{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport xgboost as xgb\n\nfrom IPython import display\nfrom scipy.stats import norm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.python.data import Dataset\n\ntitanic_train_dataframe = pd.read_csv(\"../input/train.csv\")\ntitanic_test_dataframe = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f1ef6ddc0f021711e3db25479cda4948cee232b"},"cell_type":"code","source":"print(\"train_dataframe:\")\ntitanic_train_dataframe.info()\n\nprint(\"\\ntest_dataframe:\")\ntitanic_test_dataframe.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be249911e34f43c9fd4f22418146bfa9b631ab0d"},"cell_type":"code","source":"print(\"missing values: (train_dataframe)\")\nprint(titanic_train_dataframe.isnull().sum().sort_values(ascending=False))\n\nprint(\"\\nmissing values: (test_dataframe)\")\nprint(titanic_test_dataframe.isnull().sum().sort_values(ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe55318112884feeefadec83dc9f092b2bd88366"},"cell_type":"code","source":"row_indices = list(titanic_train_dataframe.loc[titanic_train_dataframe[\"Embarked\"].isnull()].index)\ndisplay.display(titanic_train_dataframe.loc[row_indices])\n\ntrain_embarked_series = titanic_train_dataframe.loc[titanic_train_dataframe[\"Embarked\"].notnull(), \"Embarked\"]\ntest_embarked_series = titanic_test_dataframe[\"Embarked\"]\nembarked_mode = pd.concat([train_embarked_series, test_embarked_series]).mode()[0]\nprint(\"mode of embarked column: {0}\".format(embarked_mode))\n\ntitanic_train_dataframe.loc[row_indices, \"Embarked\"] = embarked_mode\ndisplay.display(titanic_train_dataframe.loc[row_indices])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1bbfeb580e15db947ed91642f2ca8add5c618cd4"},"cell_type":"code","source":"row_indices = list(titanic_test_dataframe.loc[titanic_test_dataframe[\"Fare\"].isnull()].index)\ndisplay.display(titanic_test_dataframe.loc[row_indices])\n\ntrain_fare_series = titanic_train_dataframe.loc[titanic_train_dataframe[\"Pclass\"] == 3, \"Fare\"]\ntest_fare_series = titanic_test_dataframe.loc[titanic_test_dataframe[\"Pclass\"] == 3, \"Fare\"]\nfare_median = pd.concat([train_fare_series, test_fare_series]).median()\nprint(\"median of fare column: {0:.2f}\".format(fare_median))\n\ntitanic_test_dataframe.loc[row_indices, \"Fare\"] = fare_median\ndisplay.display(titanic_test_dataframe.loc[row_indices])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30525c3fec9e0a08a4af0609a20b73dcba790736"},"cell_type":"code","source":"for dataframe in [titanic_train_dataframe, titanic_test_dataframe]:\n    display.display(dataframe.loc[titanic_train_dataframe[\"Age\"].isnull(), [\"Sex\", \"Pclass\", \"PassengerId\"]].\\\n            groupby([\"Sex\", \"Pclass\"], as_index=True).\\\n            count().\\\n            rename(columns={\"PassengerId\": \"PassengerCount\"}))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87813cf3d4b3708516c35693d3ed01780505be1b"},"cell_type":"code","source":"def get_median_age():\n    dataframe = pd.concat([\n        titanic_train_dataframe.loc[titanic_train_dataframe[\"Age\"].notnull(), [\"Sex\", \"Pclass\", \"Age\"]],\n        titanic_test_dataframe.loc[titanic_test_dataframe[\"Age\"].notnull(), [\"Sex\", \"Pclass\", \"Age\"]]\n    ])\n    \n    median_ages = {\"male\": {}, \"female\": {}}\n    for sex in [\"male\", \"female\"]:\n        for p_class in [1, 2, 3]:\n            median_ages[sex][p_class] = dataframe.loc[(dataframe[\"Sex\"] == sex) & (dataframe[\"Pclass\"] == p_class), \"Age\"].median()\n    \n    return median_ages\n\nmedian_ages = get_median_age()\nprint(\"Median Ages:\")\nfor sex in [\"male\", \"female\"]:\n    for p_class in [1, 2, 3]:\n        print(\"    median_age({0}, {1}) = {2}\".format(sex, p_class, median_ages[sex][p_class]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8423a46d0ada72dc0e441e98c020adf2bdf40bd0"},"cell_type":"code","source":"for dataframe in [titanic_train_dataframe, titanic_test_dataframe]:\n    for sex in [\"male\", \"female\"]:\n        for p_class in [1, 2, 3]:\n            dataframe.loc[(dataframe[\"Sex\"] == sex) & (dataframe[\"Pclass\"] == p_class) & (dataframe[\"Age\"].isnull()), \"Age\"] = median_ages[sex][p_class]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52070783442af12d557ee5ec02821713ddd2c7b5"},"cell_type":"code","source":"drop_cols = [\"Cabin\", \"Ticket\"]\ntitanic_train_dataframe = titanic_train_dataframe.drop(drop_cols, axis=1)\ntitanic_test_dataframe = titanic_test_dataframe.drop(drop_cols, axis=1)\n\ndisplay.display(titanic_train_dataframe.head())\ndisplay.display(titanic_test_dataframe.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1697418c5a51bf2e83cc11953e2d9340e1c73b92"},"cell_type":"code","source":"titanic_train_dataframe.loc[titanic_train_dataframe[\"Pclass\"] == 3, \"Fare\"].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe74ff72114f2ecfbd921955f9d4ff6dd8d77712"},"cell_type":"code","source":"grid = sns.FacetGrid(titanic_train_dataframe, row=\"Sex\", col=\"Survived\")\ngrid.map(plt.hist, \"Age\", bins=20)\ngrid.add_legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"393304a254e34871e4168e310b164eca05dd5b3c","collapsed":true},"cell_type":"code","source":"def plot_scatter(dataframe, x_col, y_col, age_threshold=None, fare_threshold=None):\n    plt.figure(figsize=(21,6))\n    for index, sex in enumerate([\"male\", \"female\", None], 1):\n        plt.subplot(1, 3, index)\n        if sex is not None:\n            sex_dataframe = dataframe.loc[dataframe[\"Sex\"] == sex]\n        else:\n            sex_dataframe = dataframe\n        survived_dataframe = sex_dataframe.loc[sex_dataframe[\"Survived\"] == 1, [x_col, y_col]]\n        plt.scatter(survived_dataframe[x_col], survived_dataframe[y_col], c=\"blue\", label=\"survived\")\n        dead_dataframe = sex_dataframe.loc[sex_dataframe[\"Survived\"] == 0, [x_col, y_col]]\n        plt.scatter(dead_dataframe[x_col], dead_dataframe[y_col], c=\"green\", label=\"dead\")\n        plt.title(sex if sex is not None else \"male + female\")\n        plt.xlabel(x_col)\n        plt.ylabel(y_col)\n        if fare_threshold is not None:\n            plt.axhline(y=fare_threshold, color=\"red\")\n        if age_threshold is not None:\n            plt.axvline(x=age_threshold, color=\"red\")\n        plt.legend(loc=\"upper left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc9e9b4621c11a7fc65e9c1dfffae0852ffed698"},"cell_type":"code","source":"plot_scatter(titanic_train_dataframe, \"Age\", \"Fare\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c002f71c70c397281df4d3ba47848f3b012eb32a"},"cell_type":"code","source":"age_threshold = 13.0\nfare_threshold = 35.0\n\nplot_scatter(titanic_train_dataframe, \"Age\", \"Fare\", age_threshold=age_threshold, fare_threshold=fare_threshold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fa2618fb6b22319c883d00b6727c61235f62fa98"},"cell_type":"code","source":"def cross_features(dataframe, age_threshold, fare_threshold):\n    crossed_feature = \"AgeFare\"\n    dataframe[\"AgeFare\"] = 0\n    dataframe.loc[dataframe[\"Age\"] <= age_threshold, crossed_feature] = 1\n    dataframe.loc[(dataframe[\"Sex\"] == \"male\") & (dataframe[\"Age\"] > age_threshold) & (dataframe[\"Fare\"] <= fare_threshold), crossed_feature] = 2\n    dataframe.loc[(dataframe[\"Sex\"] == \"female\") & (dataframe[\"Age\"] > age_threshold) & (dataframe[\"Fare\"] <= fare_threshold), crossed_feature] = 3\n    dataframe.loc[dataframe[\"Fare\"] > fare_threshold, crossed_feature] = 4\n    \n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"deee10a153813998b8312ccd7ef8d22dd41ee356"},"cell_type":"code","source":"titanic_train_dataframe = cross_features(titanic_train_dataframe, age_threshold, fare_threshold)\ntitanic_test_dataframe = cross_features(titanic_test_dataframe, age_threshold, fare_threshold)\n\ndisplay.display(titanic_train_dataframe.head())\ndisplay.display(titanic_test_dataframe.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"824184c84f2994c88f05eb8f02cdae933f88a623"},"cell_type":"code","source":"def feature_correlation(dataframe, feature_name):\n    survived_rate_list = []\n    for index, feature_val in enumerate(list(dataframe[feature_name].unique()), 1):\n        hist = dataframe.loc[dataframe[feature_name] == feature_val, \"Survived\"].value_counts()\n        count = hist.sum()\n        print((\"\" if index == 1 else \"\\n\") + \"  {0} = {1}\".format(feature_name, feature_val))\n        print(\"  {0: >3} passengers\".format(count))\n        survived_cnt = 0 if 1 not in hist.index else hist[1]\n        print(\"  {0: >3} passengers survived. ({1:.2f})\".format(survived_cnt, survived_cnt / count * 100))\n        dead_cnt = 0 if 0 not in hist.index else hist[0]\n        print(\"  {0: >3} passengers dead.     ({1:.2f})\".format(dead_cnt, dead_cnt / count * 100))\n        survived_rate_list.append((feature_val, survived_cnt / count * 100))\n    survived_rate_list = sorted(survived_rate_list, key=lambda s: s[1], reverse=True)\n    \n    print(\"\\nSorted by Survived Rate:\")\n    for feature_val, survived_rate in survived_rate_list:\n        print(\"  {0} = {1}, survived_rate = {2:.2f}\".format(feature_name, feature_val, survived_rate))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e56e8c471fcdc5ed46aee5501b1365a7837bc80"},"cell_type":"code","source":"feature_correlation(titanic_train_dataframe, \"Sex\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb88cf83ff325a000c9f94514a664421dfe6fcac"},"cell_type":"code","source":"feature_correlation(titanic_train_dataframe, \"Pclass\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7221ad551e1eb8340a3e16dc2c05fde0fe2a711"},"cell_type":"code","source":"feature_correlation(titanic_train_dataframe, \"Embarked\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b08b3b14938d8acf591051dc56737285ee86239"},"cell_type":"code","source":"feature_correlation(titanic_train_dataframe, \"AgeFare\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc6fbc2eed177f8cbb4eea0d703b9196c73019c2"},"cell_type":"code","source":"for dataframe in [titanic_train_dataframe, titanic_test_dataframe]:\n    dataframe[\"Title\"] = dataframe[\"Name\"].str.extract(r\" ([A-Za-z]+)\\.\", expand=False)\n\npd.concat([dataframe[[\"Title\", \"PassengerId\"]] for dataframe in [titanic_train_dataframe, titanic_test_dataframe]]).\\\n    groupby(\"Title\", as_index=False).\\\n    count().\\\n    rename(columns={\"PassengerId\": \"PassengerCount\"}).\\\n    sort_values(by=[\"PassengerCount\"], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50406c61385fbe24791f9a4e8ca00fa766495e90"},"cell_type":"code","source":"for dataframe in [titanic_train_dataframe, titanic_test_dataframe]:\n    dataframe[\"Title\"] = dataframe[\"Title\"].replace([\"Mlle\", \"Ms\"], \"Miss\")\n    dataframe[\"Title\"] = dataframe[\"Title\"].replace(\"Mme\", \"Mrs\")\n    dataframe[\"Title\"] = dataframe[\"Title\"].replace([\"Rev\", \"Dr\", \"Col\", \"Major\", \"Capt\", \"Lady\", \"Jonkheer\", \"Dona\", \"Don\", \"Countess\", \"Sir\"], \"Other\")\n\npd.concat([dataframe[[\"Title\", \"PassengerId\"]] for dataframe in [titanic_train_dataframe, titanic_test_dataframe]]).\\\n    groupby(\"Title\", as_index=False).\\\n    count().\\\n    rename(columns={\"PassengerId\": \"PassengerCount\"}).\\\n    sort_values(by=[\"PassengerCount\"], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"571f81738f57cb7f42def9b67be8ffabc929c02f"},"cell_type":"code","source":"feature_correlation(titanic_train_dataframe, \"Title\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc0a4c8f8e35843534d4a7feae7065702a057a8c"},"cell_type":"code","source":"titanic_train_dataframe = titanic_train_dataframe.drop([\"Name\"], axis=1)\ntitanic_test_dataframe = titanic_test_dataframe.drop([\"Name\"], axis=1)\n\ndisplay.display(titanic_train_dataframe.head())\ndisplay.display(titanic_test_dataframe.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e62d3a7e96811b733db5dda0da6d8338dade1bdd"},"cell_type":"code","source":"plt.figure(figsize=(14,12))\nplt.subplot(2, 2, 1)\nsns.distplot(titanic_train_dataframe[\"Fare\"], fit=norm)\nplt.subplot(2, 2, 2)\nsns.distplot(np.log1p(titanic_train_dataframe[\"Fare\"]), fit=norm);\nplt.subplot(2, 2, 3)\nsns.distplot(titanic_test_dataframe[\"Fare\"], fit=norm)\nplt.subplot(2, 2, 4)\nsns.distplot(np.log1p(titanic_test_dataframe[\"Fare\"]), fit=norm);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a569681eb2e0d4de6b4e7965361062c0c82311d2"},"cell_type":"code","source":"titanic_train_dataframe[\"NormalizedFare\"] = np.log1p(titanic_train_dataframe[\"Fare\"])\ndisplay.display(titanic_train_dataframe[\"NormalizedFare\"].describe())\ntitanic_test_dataframe[\"NormalizedFare\"] = np.log1p(titanic_test_dataframe[\"Fare\"])\ndisplay.display(titanic_test_dataframe[\"NormalizedFare\"].describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e9300158ff3be32aa2c6b38197e9ac293eca7b3"},"cell_type":"code","source":"plt.figure(figsize=(14,6))\nplt.subplot(1, 2, 1)\nsns.distplot(titanic_train_dataframe[\"Age\"], fit=norm);\nplt.subplot(1, 2, 2)\nsns.distplot(titanic_test_dataframe[\"Age\"], fit=norm);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44df8f3aa1625140a3430ca4e7de345f3c790fe2"},"cell_type":"code","source":"titanic_train_dataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"52926dcd1103890e24e9594246b92d4e0c68d3a5"},"cell_type":"code","source":"std_sc = StandardScaler()\n\nnumeric_columns = [\"NormalizedAge\", \"NormalizedFare\", \"NormalizedPclass\", \"NormalizedEmbarked\"]\n\ntitanic_train_dataframe[\"NormalizedAge\"] = titanic_train_dataframe[\"Age\"]\ntitanic_train_dataframe[\"NormalizedPclass\"] = titanic_train_dataframe[\"Pclass\"].map({1: 0.62, 2: 0.47, 3:0.24})\ntitanic_train_dataframe[\"NormalizedEmbarked\"] = titanic_train_dataframe[\"Embarked\"].map({\"C\": 55.36, \"Q\": 38.96, \"S\": 33.90})\ntitanic_train_dataframe.loc[:, numeric_columns] = std_sc.fit_transform(titanic_train_dataframe.loc[:, numeric_columns])\n\ntitanic_test_dataframe[\"NormalizedAge\"] = titanic_test_dataframe[\"Age\"]\ntitanic_test_dataframe[\"NormalizedPclass\"] = titanic_test_dataframe[\"Pclass\"].map({1: 0.62, 2: 0.47, 3:0.24})\ntitanic_test_dataframe[\"NormalizedEmbarked\"] = titanic_test_dataframe[\"Embarked\"].map({\"C\": 55.36, \"Q\": 38.96, \"S\": 33.90})\ntitanic_test_dataframe.loc[:, numeric_columns] = std_sc.transform(titanic_test_dataframe.loc[:, numeric_columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c6f7a6e43cfd942fa40d4072834e56591944d31"},"cell_type":"code","source":"titanic_train_dataframe[\"IsAlone\"] = np.where((titanic_train_dataframe[\"SibSp\"] + titanic_train_dataframe[\"Parch\"]) == 0,\"yes\", \"no\")\ntitanic_test_dataframe[\"IsAlone\"] = np.where((titanic_test_dataframe[\"SibSp\"] + titanic_test_dataframe[\"Parch\"]) == 0,\"yes\", \"no\")\n\ndisplay.display(titanic_train_dataframe[\"IsAlone\"].value_counts() / titanic_train_dataframe.shape[0] * 100)\n\ndisplay.display(titanic_train_dataframe.head())\ndisplay.display(titanic_test_dataframe.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"41ea17e011afacfdd7d4d871849f7fa2c2c14d4f"},"cell_type":"code","source":"def print_survival_rate(dataframe):\n    row_count = dataframe.shape[0]\n    label_hist = dataframe[\"Survived\"].value_counts()\n    print(\"Survived Rate ({0} passengers):\".format(row_count))\n    print(\"  {0} passengers dead. ({1:.2f}%)\".format(label_hist[0], label_hist[0] / row_count * 100))\n    print(\"  {0} passengers survivied. ({1:.2f}%)\".format(label_hist[1], label_hist[1] / row_count * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a1228d1a3921a3f5eebe6eeb309013bd2f1564b"},"cell_type":"code","source":"print_survival_rate(titanic_train_dataframe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e18fd341ebba5a928a541de34dcbb4b563d834d9"},"cell_type":"code","source":"reindex_titanic_train_dataframe = titanic_train_dataframe.reindex(np.random.permutation(titanic_train_dataframe.index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f70321d45d6ce2211b290c77a61725d66efd0327"},"cell_type":"code","source":"num_training = int(reindex_titanic_train_dataframe.shape[0] * 0.8)\nnum_validation = reindex_titanic_train_dataframe.shape[0] - num_training\n\nprint(\"{0} training examples\".format(num_training))\nprint(\"{0} validiating examples\".format(num_validation))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9f235660b9725accbc51e9d784d8a1b83dcdb821"},"cell_type":"code","source":"training_dataframe = reindex_titanic_train_dataframe.head(num_training)\nvalidation_dataframe = reindex_titanic_train_dataframe.tail(num_validation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"340fa838e7bad09cec5da7cfc0e3da3416e2f079","collapsed":true},"cell_type":"code","source":"def get_logistic_features(dataframe):\n    processed_dataframe = pd.DataFrame()\n    processed_dataframe[\"IsFemale\"] = dataframe[\"Sex\"].map({\"female\": 1, \"male\": 0})\n    processed_dataframe[\"IsAlone\"] = dataframe[\"IsAlone\"].map({\"yes\": 1, \"no\": 0})\n    processed_dataframe[\"NormalizedPclass\"] = dataframe[\"NormalizedPclass\"].copy()\n    processed_dataframe[\"NormalizedEmbarked\"] = dataframe[\"NormalizedEmbarked\"].copy()\n    processed_dataframe[\"NormalizedAge\"] = dataframe[\"NormalizedAge\"].copy()\n    processed_dataframe = pd.concat([processed_dataframe, pd.get_dummies(dataframe[\"Title\"], prefix=\"Title_\")], axis=1)\n    return processed_dataframe\n\ndef get_logistic_labels(dataframe):\n    return dataframe[\"Survived\"].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c80bebd7d6f2de99f1c111b3455943832e9dc225"},"cell_type":"code","source":"logistic_training_X = get_logistic_features(training_dataframe)\nlogistic_training_Y = get_logistic_labels(training_dataframe)\nlogistic_validation_X = get_logistic_features(validation_dataframe)\nlogistic_validation_Y = get_logistic_labels(validation_dataframe)\n\nlogistic_regression = LogisticRegression()\nlogistic_regression.fit(logistic_training_X, logistic_training_Y)\n\nlogistic_training_accuracy = logistic_regression.score(logistic_training_X, logistic_training_Y)\nprint(\"training accuracy: {0:.2f}\".format(logistic_training_accuracy))\nlogistic_validation_accuracy = logistic_regression.score(logistic_validation_X, logistic_validation_Y)\nprint(\"validation accuracy: {0:.2f}\".format(logistic_validation_accuracy))\n\ncoefficient_dataframe = pd.DataFrame()\ncoefficient_dataframe[\"Features\"] = pd.Series(list(logistic_training_X.columns))\ncoefficient_dataframe[\"Coefficients\"] = logistic_regression.coef_[0]\ncoefficient_dataframe.sort_values(by=\"Coefficients\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d6962727b2566aac1fcf77bf77f1403e5f97c18"},"cell_type":"code","source":"logistic_test_X = get_logistic_features(titanic_test_dataframe)\nlogistic_test_Y = logistic_regression.predict(logistic_test_X)\n\nlogistic_submit_dataframe = pd.DataFrame()\nlogistic_submit_dataframe[\"PassengerId\"] = titanic_test_dataframe[\"PassengerId\"].copy()\nlogistic_submit_dataframe[\"Survived\"] = logistic_test_Y\nlogistic_submit_dataframe.to_csv(\"logistic_submission.csv\", index=False, header=[\"PassengerId\", \"Survived\"])\n\nprint_survival_rate(logistic_submit_dataframe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b26358fe3c00c98c2c44c4b56698b2629abc452f"},"cell_type":"code","source":"def get_xgb_features(dataframe):\n    processed_dataframe = pd.DataFrame()\n    processed_dataframe[\"IsFemale\"] = dataframe[\"Sex\"].map({\"female\": 1, \"male\": 0})\n    processed_dataframe[\"Pclass\"] = dataframe[\"Pclass\"].copy()\n    processed_dataframe[\"Age\"] = dataframe[\"Age\"].copy()\n    processed_dataframe[\"Age\"] = dataframe[\"NormalizedAge\"].copy()\n    processed_dataframe[\"Fare\"] = dataframe[\"Fare\"].copy()\n    processed_dataframe[\"Fare\"] = dataframe[\"NormalizedFare\"].copy()\n    processed_dataframe[\"IsAlone\"] = dataframe[\"IsAlone\"].map({\"yes\": 1, \"no\": 0})\n    processed_dataframe = pd.concat([processed_dataframe, pd.get_dummies(dataframe[\"Title\"], prefix=\"Title_\")], axis=1)\n    return processed_dataframe\n\ndef get_xgb_labels(dataframe):\n    return dataframe[\"Survived\"].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cdb38768d118bbe0e0a819c39aefa242e509d56"},"cell_type":"code","source":"xgb_training_X = get_xgb_features(training_dataframe)\nxgb_training_Y = get_xgb_labels(training_dataframe)\nxgb_validation_X = get_xgb_features(validation_dataframe)\nxgb_validation_Y = get_xgb_labels(validation_dataframe)\n\nxgb_classifier = xgb.XGBClassifier()\nxgb_classifier.fit(xgb_training_X, xgb_training_Y)\n\nxgb_training_accuracy = xgb_classifier.score(xgb_training_X, xgb_training_Y)\nprint(\"training accuracy: {0:.2f}\".format(xgb_training_accuracy))\nxgb_validation_accuracy = xgb_classifier.score(xgb_validation_X, xgb_validation_Y)\nprint(\"validation accuracy: {0:.2f}\".format(xgb_validation_accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c7a97a68fd2cfa74ce9f8e4a38449a64bdaa282"},"cell_type":"code","source":"xgb_test_X = get_xgb_features(titanic_test_dataframe)\nxgb_test_Y = xgb_classifier.predict(xgb_test_X)\n\nxgb_submit_dataframe = pd.DataFrame()\nxgb_submit_dataframe[\"PassengerId\"] = titanic_test_dataframe[\"PassengerId\"].copy()\nxgb_submit_dataframe[\"Survived\"] = xgb_test_Y\nxgb_submit_dataframe.to_csv(\"xgb_submission.csv\", index=False, header=[\"PassengerId\", \"Survived\"])\n\nprint_survival_rate(xgb_submit_dataframe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6b8bfc759a22c929b504ec8ca093e05468dfbff1"},"cell_type":"code","source":"def nn_input_fn(features, labels, batch_size=1, shuffle=True, num_epochs=None):\n    features = {key: np.array(value) for key, value in dict(features).items()}\n    ds = Dataset.from_tensor_slices((features, labels))\n    ds = ds.batch(batch_size).repeat(num_epochs)\n    if shuffle:\n        ds = ds.shuffle(10000)\n    features, labels = ds.make_one_shot_iterator().get_next()\n    return features, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"973379caf915b4ef37c487ea08a882532b31c06e"},"cell_type":"code","source":"def get_nn_features(dataframe):\n    processed_dataframe = pd.DataFrame()\n    processed_dataframe[\"IsFemale\"] = dataframe[\"Sex\"].map({\"female\": 1, \"male\": 0})\n    processed_dataframe[\"IsAlone\"] = dataframe[\"IsAlone\"].map({\"yes\": 1, \"no\": 0})\n    processed_dataframe[\"NormalizedAge\"] = dataframe[\"NormalizedAge\"].copy()\n    processed_dataframe[\"NormalizedFare\"] = dataframe[\"NormalizedFare\"].copy()\n    processed_dataframe[\"NormalizedPclass\"] = dataframe[\"NormalizedPclass\"].copy()\n    processed_dataframe[\"Title\"] = dataframe[\"Title\"].copy()\n    \n    return processed_dataframe\n\ndef get_nn_labels(dataframe):\n    return dataframe[\"Survived\"].copy()\n\ndef construct_feature_columns():\n    is_female_col = tf.feature_column.numeric_column(\"IsFemale\")\n    is_alone_col = tf.feature_column.numeric_column(\"IsAlone\")\n    age_col = tf.feature_column.numeric_column(\"NormalizedAge\")\n    fare_col = tf.feature_column.numeric_column(\"NormalizedFare\")\n    pclass_col = tf.feature_column.numeric_column(\"NormalizedPclass\")\n    title_col = tf.feature_column.categorical_column_with_vocabulary_list(key=\"Title\", vocabulary_list=[\"Mr\", \"Miss\", \"Mrs\", \"Master\", \"Other\"])\n    title_col = tf.feature_column.embedding_column(title_col, dimension=2)\n    return [is_female_col, is_alone_col, age_col, fare_col, pclass_col, title_col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b83d56fd30be5d114d9c530693b9d0360fb1e9d","collapsed":true},"cell_type":"code","source":"def train_nn(steps, \n             batch_size,\n             learning_rate,\n             hidden_units,\n             training_examples, \n             training_labels,\n             validation_examples,\n             validation_labels):\n    periods = 10\n    steps_per_period = steps / periods\n    \n    training_input_fn = lambda: nn_input_fn(training_examples, training_labels, batch_size=batch_size)\n    predict_training_input_fn = lambda: nn_input_fn(training_examples, training_labels, num_epochs=1, shuffle=False)\n    predict_validation_input_fn = lambda: nn_input_fn(validation_examples, validation_labels, num_epochs=1, shuffle=False)\n    \n    optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n    #optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n    #optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n    optimizer = tf.contrib.estimator.clip_gradients_by_norm(optimizer, 5.0)\n    \n    classifier = tf.estimator.DNNClassifier(feature_columns=construct_feature_columns(), hidden_units=hidden_units, optimizer=optimizer)\n    \n    training_losses = []\n    validation_losses = []\n    for period in range(periods):\n        classifier.train(input_fn=training_input_fn, steps=steps_per_period)\n        training_metrics = classifier.evaluate(input_fn=predict_training_input_fn)\n        validation_metrics = classifier.evaluate(input_fn=predict_validation_input_fn)\n        training_loss = training_metrics[\"loss\"]\n        training_losses.append(training_loss)\n        validation_loss = validation_metrics[\"loss\"]\n        validation_losses.append(validation_loss)\n        print(\"period = {0:<2}, training_loss = {1:.2f}, validation_loss = {2:.2f}\".format(period, training_loss, validation_loss))\n    \n    plt.figure(figsize=(6, 6))\n    plt.plot(training_losses, label=\"training\")\n    plt.plot(validation_losses, label=\"validation\")\n    plt.title(\"Losses vs. Periods\")\n    plt.xlabel(\"Periods\")\n    plt.ylabel(\"loss\")\n    plt.legend()\n    \n    return classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e71fd6b157ba8cafc5d7e662ae753c5fdf57493b"},"cell_type":"code","source":"nn_training_X = get_nn_features(training_dataframe)\nnn_training_Y = get_nn_labels(training_dataframe)\nnn_validation_X = get_nn_features(validation_dataframe)\nnn_validation_Y = get_nn_labels(validation_dataframe)\n\nsteps = 75\nbatch_size = 10\nlearning_rate = 0.1\nhidden_units = [14, 7]\nnn_classifer = train_nn(steps,\n                        batch_size,\n                        learning_rate,\n                        hidden_units,\n                        nn_training_X,\n                        nn_training_Y,\n                        nn_validation_X,\n                        nn_validation_Y)\n\ntraining_metrics = nn_classifer.evaluate(input_fn=lambda: nn_input_fn(nn_training_X, nn_training_Y, num_epochs=1, shuffle=False))\nprint(\"\\ntraining accuracy: {0:.2f}\".format(training_metrics[\"accuracy\"]))\nvalidation_metrics = nn_classifer.evaluate(input_fn=lambda: nn_input_fn(nn_validation_X, nn_validation_Y, num_epochs=1, shuffle=False))\nprint(\"validation accuracy: {0:.2f}\".format(validation_metrics[\"accuracy\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c32d1fb9821918b09e07f7ed0e40be2b37b13802"},"cell_type":"code","source":"nn_test_X = get_nn_features(titanic_test_dataframe)\n\ndef prefict_input_fn(features, batch_size=1):\n    features = {key: np.array(value) for key, value in dict(features).items()}\n    ds = Dataset.from_tensor_slices(features)\n    ds = ds.batch(batch_size).repeat(1)\n    return ds.make_one_shot_iterator().get_next()\n\nnn_test_Y = nn_classifer.predict(lambda: prefict_input_fn(nn_test_X))\nnn_test_Y = np.array([prediction[\"class_ids\"][0] for prediction in nn_test_Y])\n\nnn_submit_dataframe = pd.DataFrame()\nnn_submit_dataframe[\"PassengerId\"] = titanic_test_dataframe[\"PassengerId\"].copy()\nnn_submit_dataframe[\"Survived\"] = nn_test_Y\nnn_submit_dataframe.to_csv(\"nn_submission.csv\", index=False, header=[\"PassengerId\", \"Survived\"])\n\nprint_survival_rate(nn_submit_dataframe)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}