{"cells":[{"metadata":{"_cell_guid":"9b2777e9-f2f1-4dd0-abf4-9811e6e7ed24","_uuid":"4af28527642d89aa911942b28076a081315af171"},"cell_type":"markdown","source":"# Using a Tensorflow Custom Estimator to classify Titanic dataset"},{"metadata":{"_cell_guid":"c390db67-1759-4e63-b763-4eed373d1ccf","_uuid":"ae44c8114f08af49e91e34be2bd8e6fa779b43eb"},"cell_type":"markdown","source":"My focus here is just show a basic approach of a Custom Estimator using Google's Open Source TensorFlow library.\n\nThe TensorFlow team developed the Estimator API to make the library more accessible to the everyday developer. This high level API provides a common interface to train(...) models, evaluate(...) models, and predict(...) outcomes of unknown cases similar to (and influenced by) the popular Sci-Kit Learn library, which is accomplished by implementing a common interface for various algorithms. Some functions used here are copied from google tensorflow. "},{"metadata":{"_cell_guid":"1758c06d-d2b5-47c8-a4fb-2ef410d2a6da","_uuid":"a5a83a4a19473479550696bff971c0600c692c12"},"cell_type":"markdown","source":"### Load data after feat. engineering and cleanning data"},{"metadata":{"_cell_guid":"c28aeb89-b779-4899-8abd-239365dd0cd0","_uuid":"513e2197e1d612f45f7adc774df182d3e0b41f2e","collapsed":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"3468372e-19d3-4b0f-9a10-a0659150417c","_uuid":"15c6a2de4705bee4e53310f4b11b54e376e95e38"},"cell_type":"markdown","source":"I did the feature engineering and cleaning step separately. If want to see more details please, see here: [ Titanic Best Working Classfier:](https://www.kaggle.com/sinakhorami/titanic-best-working-classifier) by Sina"},{"metadata":{"_cell_guid":"7067a1b9-4c35-43b3-a0d1-735e79478753","_uuid":"db2f4d04c5d54d2da489bbef159be393caed6214","collapsed":true,"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/titanic-test-ready/train-ready.csv')\ntest = pd.read_csv('../input/titanic-test-ready/test-ready.csv')","execution_count":19,"outputs":[]},{"metadata":{"_cell_guid":"8bf2b0b2-0df0-4c26-a2b6-e2afbff30be5","_uuid":"f52b4f230d23241f63526e55ffe1fd07ebbf3f8a","trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":20,"outputs":[]},{"metadata":{"_cell_guid":"b4c6d658-9af0-4d59-9e7b-a9ec5f987ba1","_uuid":"cdbe6a6c6879bc4e3ee0bda83b13da55c40f74cd"},"cell_type":"markdown","source":"### Custom Estimator using tensorFlow"},{"metadata":{"_cell_guid":"a7c08bcd-4286-4400-aac4-cccdc55f4482","_uuid":"9e322e74d0cff6233b4d70b9f45b4f38e27239bd","trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"2db50042-204d-4cf2-871b-7a5ce7504b63","_uuid":"12709fc47261c960f65d057daf7034bfa9c031ad"},"cell_type":"markdown","source":"We will create a DNN with three hidden layers, and dropout of 0.1 probability. Creating three fully connected layers each layer having a dropout probability of 0.1."},{"metadata":{"_cell_guid":"f08d5a0f-31da-4369-83a6-0d550900e763","_uuid":"73ba64c5e455a8f4a6549bf0e785f51e6cefb544"},"cell_type":"markdown","source":"#### Create the model"},{"metadata":{"_cell_guid":"034786fe-0d73-4743-b866-6e4a3c480616","_uuid":"9cd41cc3d83d9fc83f786d23f3cb1af993109b76"},"cell_type":"markdown","source":"Function to create the model"},{"metadata":{"_cell_guid":"7e97dde9-0bba-422e-b3c2-71369bdef5a8","_uuid":"61764772e2a05f0d3850637aa589d3369e56f156","collapsed":true,"trusted":true},"cell_type":"code","source":"def my_model(features, labels, mode, params):\n    \"\"\"DNN with three hidden layers, and dropout of 0.1 probability.\"\"\"\n    # Create three fully connected layers each layer having a dropout\n    # probability of 0.1.\n    \n    net = tf.feature_column.input_layer(features, params['feature_columns'])\n    for units in params['hidden_units']:\n        net = tf.layers.dense(net, units=units, activation=tf.nn.relu)\n\n    # Compute logits (1 per class).\n    logits = tf.layers.dense(net, params['n_classes'], activation=None)\n\n    # Compute predictions.\n    predicted_classes = tf.argmax(logits, 1)\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        predictions = {\n            'class_ids': predicted_classes[:, tf.newaxis],\n            'probabilities': tf.nn.softmax(logits),\n            'logits': logits,\n        }\n        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n\n    # Compute loss.\n    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n\n    # Compute evaluation metrics.\n    accuracy = tf.metrics.accuracy(labels=labels,\n                                   predictions=predicted_classes,\n                                   name='acc_op')\n    metrics = {'accuracy': accuracy}\n    tf.summary.scalar('accuracy', accuracy[1])\n\n    if mode == tf.estimator.ModeKeys.EVAL:\n        return tf.estimator.EstimatorSpec(\n            mode, loss=loss, eval_metric_ops=metrics)\n\n    # Create training op.\n    assert mode == tf.estimator.ModeKeys.TRAIN\n\n    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)","execution_count":21,"outputs":[]},{"metadata":{"_cell_guid":"9f252c97-109a-4618-887b-2cf5cefab190","_uuid":"2863ca7c9d9518323fc88c02a87cc773c8d8801c","collapsed":true,"trusted":true},"cell_type":"code","source":"def train_input_fn(features, labels, batch_size):\n    \"\"\"An input function for training\"\"\"\n\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n    dataset = dataset.shuffle(10).repeat().batch(batch_size)\n    return dataset","execution_count":22,"outputs":[]},{"metadata":{"_cell_guid":"28f2dec3-c162-4016-8830-80a0badc3134","_uuid":"db0d758aa0ebfee68b171ed91b8cce803a466abd","collapsed":true,"trusted":true},"cell_type":"code","source":"def eval_input_fn(features, labels, batch_size):\n    \"\"\"An input function for evaluation or prediction\"\"\"\n    features=dict(features)\n    if labels is None:\n        inputs = features\n    else:\n        inputs = (features, labels)\n\n    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n    \n    assert batch_size is not None, \"batch_size must not be None\"\n    dataset = dataset.batch(batch_size)\n\n    return dataset","execution_count":23,"outputs":[]},{"metadata":{"_cell_guid":"63a6545b-f9a0-41c0-9152-06e510cf0fec","_uuid":"11a52405009c68d8c19b84bf4ef8a291e49d78ca","trusted":true,"collapsed":true},"cell_type":"code","source":"y = train.pop('Survived')\nX = train","execution_count":24,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"4dc9ffa0e1b94067237187689c9f6ebbf019148d"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)  ","execution_count":25,"outputs":[]},{"metadata":{"_cell_guid":"db430d5e-7920-4e51-b6c3-c71302db6e85","_uuid":"e5fb9ee90e791635f84f85ee3bd4ee2d34c8608c","collapsed":true,"trusted":true},"cell_type":"code","source":"feature_columns = []\n\nfor key in X_train.keys():\n    feature_columns.append(tf.feature_column.numeric_column(key=key))","execution_count":26,"outputs":[]},{"metadata":{"_cell_guid":"2077b00a-4dc2-4d66-8568-eedf71dbdbca","_uuid":"0fe43359b8c86c8f02fa279b015d93ad10dad141"},"cell_type":"markdown","source":"[](http://)Build 2 hidden layer DNN with first with 2x inputs size and a second with inputs size units respectively"},{"metadata":{"_cell_guid":"ac5e7116-3a86-4f44-bb61-1b551294bf76","_uuid":"30f7358f645c591eb1fbec52d16265fadeb28f1e","scrolled":true,"trusted":true},"cell_type":"code","source":"units = len(X_train.columns) * 2\nprint (units)","execution_count":27,"outputs":[]},{"metadata":{"_cell_guid":"f58fd7ce-8c4c-4e93-9025-11f9be2de653","_uuid":"9ddcf0727cbeea7a55f059669919440044d3e4dd","trusted":true},"cell_type":"code","source":"classifier = tf.estimator.Estimator(\n    model_fn=my_model,\n    params={\n        'feature_columns': feature_columns,\n        # Two hidden layers of 10 nodes each.\n        'hidden_units': [units, int(units/2)],\n        # The model must choose between 3 classes.\n        'n_classes': 2,\n    })","execution_count":28,"outputs":[]},{"metadata":{"_cell_guid":"6064e6ad-7b6c-4ccd-a48a-6c03931de24e","_uuid":"39860cf1d773434976bf6ee55a85bb703eec1a9a"},"cell_type":"markdown","source":"#### Train and evaluation the Model"},{"metadata":{"_cell_guid":"fcf814db-efd0-436b-af11-57b943add943","_uuid":"6d34b251df5fce88a7865341c5b7db56a5672e11","scrolled":true,"trusted":true},"cell_type":"code","source":"batch_size = 100\ntrain_steps = 400\n  \nfor i in range(100):\n    \n    classifier.train(\n        input_fn=lambda:train_input_fn(X_train, y_train,\n                                       batch_size),\n        steps=train_steps)\n","execution_count":29,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd805f1ad78f07d6ca23fef49569a0e2f6be5724"},"cell_type":"code","source":"eval_result = classifier.evaluate(\n    input_fn=lambda:eval_input_fn(X_val, y_val,\n                                  batch_size)\n)\n\n","execution_count":30,"outputs":[]},{"metadata":{"_cell_guid":"9b4c0359-dc26-4b20-8553-90aee9861a3b","_uuid":"cc978934bbdb886d3cce61514d50dbecc885a7b2"},"cell_type":"markdown","source":"#### Generate predictions from the model"},{"metadata":{"_cell_guid":"41bf5e29-bb91-41f8-9751-cdec6dc0bdf8","_uuid":"06b07e17d6e63df67c62f6306e70c7bd4e0cf496","collapsed":true,"trusted":true},"cell_type":"code","source":"predictions = classifier.predict(\n    input_fn=lambda:eval_input_fn(test,labels=None,\n    batch_size=batch_size))","execution_count":31,"outputs":[]},{"metadata":{"_cell_guid":"a828dd79-5623-48ef-86f8-70fa898880cd","_uuid":"e081575dfdb2a090708673a367d8f1e829219590","trusted":true},"cell_type":"code","source":"results = list(predictions)\n\ndef x(res,j):\n    class_id = res[j]['class_ids'][0]\n    probability = int(results[i]['probabilities'][class_id] *100)\n\n    if int(class_id) == 0:\n        return ('%s%% probalitity to %s' % (probability,'Not survive'))\n    else:\n        return ('%s%% probalitity to %s' % (probability,'Survive!'))\n\nprint ('Predictions for 10 first records on test(dataset):')\n\nfor i in range(0,10):    \n    print (x(results,i))","execution_count":33,"outputs":[]},{"metadata":{"_cell_guid":"288ffc10-cef9-4b4e-8101-dc05d6157525","_uuid":"16cde1e7c22ebd6926a1ef672d12819f5c83fceb"},"cell_type":"markdown","source":"#### Generate the csv to submit. "},{"metadata":{"_cell_guid":"511d2da5-aafb-435b-8c68-e453950e08f1","_uuid":"bb79b1cb9c21fb78af1b27bb498bb21b3fe96f36","trusted":true},"cell_type":"code","source":"len(results)","execution_count":34,"outputs":[]},{"metadata":{"_cell_guid":"bf75de9e-f331-4ac9-bd5d-a9d7152e4619","_uuid":"853ad4590c4fffa854a81893b5834a8acf41af9d","trusted":true},"cell_type":"code","source":"len(train)","execution_count":35,"outputs":[]},{"metadata":{"_cell_guid":"ead789ab-ce05-45ce-88d7-58751f2ef3a8","_uuid":"85a792e85c05a4db14e24f15ab5b149cad7a5d46","collapsed":true,"trusted":true},"cell_type":"code","source":"passengers = {}\ni = len(train) + 1\nfor x in results:\n    passengers[i] = int(x['class_ids'][0])\n    i+=1","execution_count":36,"outputs":[]},{"metadata":{"_cell_guid":"59e63f89-5bf2-4ea2-a575-2bd8c9ea0fd4","_uuid":"058f4697e9ecf36c506ca072a4cc55887d141f8e","collapsed":true,"trusted":true},"cell_type":"code","source":"import csv\ncsvfile = './gender_submission.csv'\nwith open(csvfile, 'w') as f:\n    outcsv = csv.writer(f, delimiter=',')\n    header = ['PassengerId','Survived']\n    outcsv.writerow(header)\n    for k,v in passengers.items():\n        outcsv.writerow([k,v])","execution_count":37,"outputs":[]},{"metadata":{"_cell_guid":"e5cb9ac8-5e83-4136-b9a4-a406b62e922f","_uuid":"0069ca5b29efb10a836d641a2a74ce2f313f9504","trusted":true},"cell_type":"code","source":"submissions = pd.read_csv(csvfile)\nsubmissions.head(5)","execution_count":38,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}