{"cells":[{"metadata":{"_cell_guid":"604275e1-a2e7-46b4-9544-5256a25bea4f","_uuid":"a89127980a00ad84bef2a4630793c7d60bf086e0"},"cell_type":"markdown","source":"# Using a Tensorflow DNNClassifier to classify Titanic dataset with One hot encoder approach"},{"metadata":{"_cell_guid":"3c80925b-1152-4572-a3a6-e1e5941d043a","_uuid":"6210ae18b4b020794ff2c15a48cbfdbb8eca7a13"},"cell_type":"markdown","source":"**This version for each trainning step I evaluted the model**\n\nMy focus here is just show a basic approach of a Deep Neural Classifier using Google's Open Source TensorFlow library.\n\nThe TensorFlow team developed the Estimator API to make the library more accessible to the everyday developer. This high level API provides a common interface to train(...) models, evaluate(...) models, and predict(...) outcomes of unknown cases similar to (and influenced by) the popular Sci-Kit Learn library, which is accomplished by implementing a common interface for various algorithms"},{"metadata":{"_cell_guid":"623f98c7-7565-4c5c-baa9-3b989be1650d","_uuid":"ca27307307bce2f8b0e8d50d9f3cc8e09feff0db"},"cell_type":"markdown","source":"### Load data after feat. engineering and cleanning data"},{"metadata":{"_cell_guid":"0a2b2c33-2ae8-4c53-b8b6-31edfd10f7cb","_uuid":"9a33c8433bb385b2a40d883ddeafa78818d82b8c","collapsed":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np","execution_count":122,"outputs":[]},{"metadata":{"_cell_guid":"3c69a512-ba72-42c0-88d7-b1c2fd5bd27b","_uuid":"d657e59ab9f83d2d547d58d656080813b0ab2e64"},"cell_type":"markdown","source":"I did the feature engineering and cleaning step separately. If want to see more details please, see here: [ Titanic Best Working Classfier:](https://www.kaggle.com/sinakhorami/titanic-best-working-classifier) by Sina"},{"metadata":{"_cell_guid":"31c90eb7-2dab-4423-83cc-1ba32bfa4b26","_uuid":"17b8582634b2a6bb6e54c3a1809d8a37681deacf","collapsed":true,"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/titanic-test-ready/train-ready.csv')\ntest = pd.read_csv('../input/titanic-test-ready/test-ready.csv')","execution_count":123,"outputs":[]},{"metadata":{"_cell_guid":"c8b4043b-3d2a-45a0-bbce-c974db26d8ee","_uuid":"87fc0091f3d719d5dea16c04eb21577a149ec434","trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":124,"outputs":[]},{"metadata":{"_uuid":"32fd3e9bd85d48482d6ce89265609a572b7bef9d"},"cell_type":"markdown","source":"### One hot encoder"},{"metadata":{"_uuid":"40f1f60309a5c1b3a3b2d97a9f5f2a0da4d4ad4f"},"cell_type":"markdown","source":"One hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction.  \n\nThe categorical value represents the numerical value of the entry in the dataset. For example: For each **Title **(Master., Miss, Mr, Mrs, Capt, etc)  in the dataset or during a feature engineering process, it would have been given categorical value as number like 1, 2, 3... N . As the number of unique entries increases, the categorical values also proportionally increases.\n\nProblem with label encoding is that it assumes higher the categorical value, better the category, but is not necessarily true!\n\nWhat this form of organization presupposes is Master  < Miss < Mr < Mrs ... ( 1 < 2 < 3 < 4...) based on the categorical values. Say supposing your model internally calculates average, then accordingly we get, 1+3 = 4/2 =2. This implies that: Average of Master and Mr is Miss. This is definitely a recipe for disaster. \n\nThis model’s prediction would have a lot of errors. \n\nThis is why we use one hot encoder to perform “binarization” of the category and include it as a feature to train the model.\n\nLets do it!"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"6e7fe79acfcf35647ee6b758dba28263fc41532b"},"cell_type":"code","source":"def one_hot_enconder(df1,df2):\n    col_name = []\n    cols = {}\n    \n    col = [x for x in df1.columns if x not in ['Survived']]\n    len_df1 = df1.shape[0]\n    df = pd.concat([df1,df2],ignore_index=True)\n    \n    print('Categorical feature',len(col))\n    for c in col:\n        if df[c].nunique()>2 :\n            col_name.append(c)\n            cols[c] = c\n    \n    df = pd.get_dummies(df, prefix=cols, columns=col_name,drop_first=True)\n\n    df1 = df.loc[:len_df1-1]\n    df2 = df.loc[len_df1:]\n    print('Train',df1.shape)\n    print('Test',df2.shape)\n    return df1,df2","execution_count":125,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d1a72b568f3a19e159cce399d2ebfa4d9abf0b3"},"cell_type":"code","source":"train,test = one_hot_enconder(train,test)","execution_count":126,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39705a611becfb84d9302a0216148e3fd4ff1b80"},"cell_type":"code","source":"train.head()","execution_count":127,"outputs":[]},{"metadata":{"_cell_guid":"b206cb95-d333-43d2-acc6-254408d460ce","_uuid":"5e2634a7e4bd3621e6cdecdccc49f2bfc1cdecc1"},"cell_type":"markdown","source":"### DNNClassifier using tensorFlow: a basic approach"},{"metadata":{"_cell_guid":"7d01576c-700a-4154-88db-b2a3c6a0135a","_uuid":"f5dc69a6c060b20b2f7352d8d23d467c5cb0c9b2"},"cell_type":"markdown","source":"Helper functions"},{"metadata":{"_cell_guid":"bdab0ac2-3dca-43aa-a96a-617608bad1b8","_uuid":"619969fa0539d1a39dc4e925d6729849df1ad1fd","collapsed":true,"trusted":true},"cell_type":"code","source":"def train_input_fn(features, labels, batch_size):\n    \"\"\"An input function for training\"\"\"\n\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n    dataset = dataset.shuffle(10).repeat().batch(batch_size)\n    return dataset","execution_count":128,"outputs":[]},{"metadata":{"_cell_guid":"63f17c03-8f82-41bb-8fc2-bf308d1b38a0","_uuid":"d7aaab8cc14e44daff15c69551846b95f2fa771d","collapsed":true,"trusted":true},"cell_type":"code","source":"def eval_input_fn(features, labels, batch_size):\n    \"\"\"An input function for evaluation or prediction\"\"\"\n    features=dict(features)\n    if labels is None:\n        inputs = features\n    else:\n        inputs = (features, labels)\n\n    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n    \n    assert batch_size is not None, \"batch_size must not be None\"\n    dataset = dataset.batch(batch_size)\n\n    return dataset","execution_count":129,"outputs":[]},{"metadata":{"_cell_guid":"8595b534-dab6-43c1-a367-5b3ac3157bf5","_uuid":"acbc5473c2135e3ec879803b6e091b1840b56f88","collapsed":true,"trusted":true},"cell_type":"code","source":"y = train.pop('Survived')\nX = train","execution_count":130,"outputs":[]},{"metadata":{"_cell_guid":"20337885-e084-4c5a-93c2-751805182c36","_uuid":"c7f52efaff9f2deab87ae1d97a198ba1d73ee59f"},"cell_type":"markdown","source":"#### Create the model"},{"metadata":{"_cell_guid":"04ea22fc-d0b1-4cd9-835f-5d9c30a8026e","_uuid":"fcce5b89e84e99189b9a5ef3777864681c8be911","collapsed":true,"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nfeature_columns = []\n\nfor key in X.keys():\n    feature_columns.append(tf.feature_column.numeric_column(key=key))","execution_count":131,"outputs":[]},{"metadata":{"_cell_guid":"7bdf6c5b-460c-4f1f-ae1e-89ade6f40589","_uuid":"db55d73b99a346383810b302f67724fea6265bcb"},"cell_type":"markdown","source":"One hidden layer of 37 ( number of freatures x 2 + 1 ). The model must choose between 2 classes."},{"metadata":{"_cell_guid":"9536dc29-1787-478c-9829-9174bac7acd7","_uuid":"24d00689d11a4b36fef2dd9cc52fed96fd6a9cf0","trusted":true},"cell_type":"code","source":"classifier = tf.estimator.DNNClassifier(\n    feature_columns=feature_columns,\n    hidden_units=[37,],\n    n_classes=2)","execution_count":132,"outputs":[]},{"metadata":{"_cell_guid":"e1db3b75-07db-4d43-b561-58bd9a66c86a","_uuid":"d16a4c18e37e6bf0175df83f01590b00320a3819"},"cell_type":"markdown","source":"#### Train and evaluation the Model"},{"metadata":{"_cell_guid":"0bd6fa8f-82e0-4020-b61f-695b7559c027","_uuid":"b0539550e666485fba623ae55add3a2b3234ec17","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn.metrics import explained_variance_score, mean_absolute_error, median_absolute_error\nfrom sklearn.model_selection import train_test_split ","execution_count":133,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29e682210cdaa9ffdb1701d39613a0c6f00d97f3"},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=12) \nprint(\"Training instances   {}, Training features   {}\".format(X_train.shape[0], X_train.shape[1]))  \nprint(\"Validation instances {}, Validation features {}\".format(X_val.shape[0], X_val.shape[1]))  \nprint(\"Testing instances    {}, Testing features    {}\".format(test.shape[0], test.shape[1]))  ","execution_count":134,"outputs":[]},{"metadata":{"_cell_guid":"3ffe362a-5162-47af-84bf-e665eac83e96","_uuid":"fdbeaf956bd18878fcf18b590f2c17e0055f7591","trusted":true},"cell_type":"code","source":"batch_size = 100\ntrain_steps = 400\n\nevaluations = []  \nfor i in range(200):  \n    classifier.train(\n        input_fn=lambda:train_input_fn(X, y,\n                                       batch_size),\n                    steps=train_steps)\n    \n    eval_result = classifier.evaluate(\n            input_fn=lambda:eval_input_fn(X_val, y_val,batch_size)\n        )\n    \n    evaluations.append(eval_result)","execution_count":135,"outputs":[]},{"metadata":{"_cell_guid":"824b649f-8703-4535-b517-2de16b43ae2e","_uuid":"3e1bba2be6cb938084823486fb57196ae2166e86","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt  \n%matplotlib inline\n\n# manually set the parameters of the figure to and appropriate size\nplt.rcParams['figure.figsize'] = [14, 10]\n\nloss_values = [ev['loss'] for ev in evaluations]  \ntraining_steps = [ev['global_step'] for ev in evaluations]\n\nplt.scatter(x=training_steps, y=loss_values)  \nplt.xlabel('Training steps')  \nplt.ylabel('Loss (SSE)')  \nplt.show() ","execution_count":144,"outputs":[]},{"metadata":{"_cell_guid":"3bd4071a-9494-4bcd-a4c8-4f3bfa7d4d32","_uuid":"8bd65a49a98d1f5ff7d5842e22b3e108d7a7952d"},"cell_type":"markdown","source":"#### Generate predictions from the model"},{"metadata":{"_cell_guid":"dcec61d7-abf1-4a04-8d1a-970bdff7b205","_uuid":"b9e79af018da6200d5f19331ed8041bbe13528d7","collapsed":true,"trusted":true},"cell_type":"code","source":"predictions = classifier.predict(\n    input_fn=lambda:eval_input_fn(test,labels=None,\n    batch_size=batch_size))","execution_count":145,"outputs":[]},{"metadata":{"_cell_guid":"90455ba1-2007-45ef-9208-2c90fcdaf581","_uuid":"fa2e122a18ce76700f245c8a198e0b6f93ffefaf","trusted":true},"cell_type":"code","source":"results = list(predictions)\n\ndef x(res,j):\n    class_id = res[j]['class_ids'][0]\n    probability = int(results[j]['probabilities'][class_id] *100)\n\n    if int(class_id) == 0:\n        return ('%s%% probalitity to %s' % (probability,'Not survive'))\n    else:\n        return ('%s%% probalitity to %s' % (probability,'Survive!'))\n\nprint ('Predictions for 10 first records on test(dataset):')\n\nfor i in range(0,10):    \n    print (x(results,i))","execution_count":146,"outputs":[]},{"metadata":{"_cell_guid":"efc7931d-44c0-47fc-9697-67456e2c6510","_uuid":"9499f14b45c1b744ce26bf68c262776f64d9390b"},"cell_type":"markdown","source":"#### Generate the csv to submit. "},{"metadata":{"_cell_guid":"be4c0d13-0972-4644-8606-a67400306d1b","_uuid":"a41573f7da2466c42de9e0e99f52d87b08a73113","trusted":true},"cell_type":"code","source":"len(results)","execution_count":147,"outputs":[]},{"metadata":{"_cell_guid":"81dbad1a-fe51-4556-9a99-a60a4a5c2180","_uuid":"4c26991b1437ecd6fc844d13bd356885a6e817c3","trusted":true},"cell_type":"code","source":"len(train)","execution_count":148,"outputs":[]},{"metadata":{"_cell_guid":"50faaf5a-9481-4d54-bd31-183fcdfa23a8","_uuid":"158da279ea0550501b8052fecf084f401d910eb0","collapsed":true,"trusted":true},"cell_type":"code","source":"passengers = {}\ni = len(train) + 1\nfor x in results:\n    passengers[i] = int(x['class_ids'][0])\n    i+=1","execution_count":149,"outputs":[]},{"metadata":{"_cell_guid":"d474a9de-e1f2-4cca-b55a-3cacd56894a3","_uuid":"3c1d8d1b84f3883de48d8aae81d1137fbf8adf9a","collapsed":true,"trusted":true},"cell_type":"code","source":"import csv\ncsvfile = 'submissions_ohe2.csv'\nwith open(csvfile, 'w') as f:\n    outcsv = csv.writer(f, delimiter=',')\n    header = ['PassengerId','Survived']\n    outcsv.writerow(header)\n    for k,v in passengers.items():\n        outcsv.writerow([k,v])","execution_count":152,"outputs":[]},{"metadata":{"_cell_guid":"fbd82270-0a17-4c6b-b642-206617c6d9bf","_uuid":"4f52ae8cc69e2a5da52c60dafbb4d445ff6b4666","trusted":true},"cell_type":"code","source":"submissions = pd.read_csv(csvfile)\nsubmissions.head(10)","execution_count":153,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}