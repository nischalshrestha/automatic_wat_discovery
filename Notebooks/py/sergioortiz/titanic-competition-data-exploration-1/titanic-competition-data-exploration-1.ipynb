{"cells":[{"metadata":{"trusted":true,"_uuid":"156820d714a4f86be8f4a60cd76559bcd8097114"},"cell_type":"markdown","source":"# Titanic Competition: Exploring Data - Iteration 1\n\nWelcome! This kernel is part of the *Titatic competition learning series* which can be accessed from <a href=\"https://www.kaggle.com/sergioortiz/titanic-competition-a-learning-diary\">here</a>.  \n\nLet's start with the data exploration basics..."},{"metadata":{"trusted":true,"_uuid":"46a2dc1f32f6f9a287d1be2fa44463e5d8d93aeb"},"cell_type":"code","source":"import os\nimport pandas as pd\n\ninput_io_dir=\"../input\"\n\noriginal_train_data=pd.read_csv(input_io_dir+\"/train.csv\")\noriginal_test_data=pd.read_csv(input_io_dir+\"/test.csv\")\nprint('original_train_data',original_train_data.shape)\nprint('original_test_data',original_test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"84e53c40553c7f113a3a9ad930d3b1181b104c58"},"cell_type":"markdown","source":"## General overview\nLet's first have a look at some data with basic pandas DataFrame functions..."},{"metadata":{"trusted":true,"_uuid":"0d486121ea12fabd4acc46e0133a78be96fdb6d8"},"cell_type":"code","source":"original_train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a79584a821a7c79c6425f3b23ea4eb9ff3e32379"},"cell_type":"code","source":"print('Training data --------------')\nprint(original_train_data.info())\nprint('Test data ------------------')\nprint(original_test_data.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ec8128e4652e74dc208d774f923e81395924915"},"cell_type":"code","source":"original_train_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6c6b21a62316e806f12ad8e4e6f662dd7d3465f"},"cell_type":"code","source":"original_test_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b1a567e1cb96e95d847c285bada61d027685cf9"},"cell_type":"markdown","source":"### General overview: conclusions\n* Small training data set - less than 1,000 rows. \n* Features by type\n  * Categorical\n    * Pclass: ordinal\n    * Sex\n    * Embarked\n  * Numeric\n    * Age: continuous\n    * Fare: continuous\n    * SibSp: discrete\n    * Parch: discrete\n  * Other\n    * Name\n    * Ticket\n    * Cabin\n* Missing data\n  * Age: some missing values - strategy relevant for training\n  * Cabin: many missing values - watch out as training may not be good on such a reduced data set\n  * Embarked: few missing values - strategy unlikely to affect training\n* Potential outliers (Fare - max is far way from mean+-std)"},{"metadata":{"_uuid":"60370f87ac5ab566df6740464c97bf7c22cf2908"},"cell_type":"markdown","source":"## Potential barriers for learning\nLet's analyse different factors that can hinder learning\n### Comparing training and test data sets\nLearning models can be ineffective when data distribution is very different between training and test sets.<br/>\nLet's explore this subject for a while..."},{"metadata":{"trusted":true,"_uuid":"c98227be8c20bbac5e9ae932def61021de205716","scrolled":false},"cell_type":"code","source":"def ExploreCategoricalVariable(dataSet,variableName):\n    print('Variable:'+variableName)\n    print(dataSet[variableName].value_counts()/len(dataSet[variableName]))\n    print('')\n\nprint('----------------------- Training set')\nExploreCategoricalVariable(original_train_data,'Sex')\nExploreCategoricalVariable(original_train_data,'Pclass')\nExploreCategoricalVariable(original_train_data,'Embarked')\nprint('----------------------- Test set')\nExploreCategoricalVariable(original_test_data,'Sex')\nExploreCategoricalVariable(original_test_data,'Pclass')\nExploreCategoricalVariable(original_test_data,'Embarked')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f02d90d13995208b9c9e1940fa91383c11913c18"},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfig, axarr = plt.subplots(4, 2, figsize=(12, 8))\n\noriginal_train_data['Age'].hist(ax=axarr[0][0])\noriginal_test_data['Age'].hist(ax=axarr[0][1])\noriginal_train_data['Fare'].hist(ax=axarr[1][0])\noriginal_test_data['Fare'].hist(ax=axarr[1][1])\noriginal_train_data['Parch'].hist(ax=axarr[2][0])\noriginal_test_data['Parch'].hist(ax=axarr[2][1])\noriginal_train_data['SibSp'].hist(ax=axarr[3][0])\noriginal_test_data['SibSp'].hist(ax=axarr[3][1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc8a10e28c41d870ea034a7683015027e45e7008"},"cell_type":"markdown","source":"### Potential barriers for learning: conclusions\nThere are no significant differences in both categorical and numeric data - that is, it appears to be evenly distributed between the two data sets.  \nOn the other hand, there can be limitations derived from the reduced data set size - e.g. some learning models can improve its accuracy with increased datasets. Learning curves will help to evaluate if this is the case.\nFinally, existing features present very different values and this can hinder learning. Data values must be scaled and normalised."},{"metadata":{"trusted":true,"_uuid":"9fba14d690bd02960bbcbeac16660d0c265abbf4"},"cell_type":"markdown","source":"## Trends and correlations\nLet's start identifying correlations with the corr function.\nThis will be useful only for ordinal variables as it reflects the extent to which a variable (e.g. Survived) varies when other features values change.  "},{"metadata":{"_uuid":"f240eb1e0566293ea9b4e318f8223e182c383aab","trusted":true},"cell_type":"code","source":"original_train_data.corr()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8650c2ffb6dfc43b73002a865e5840e4294f4d53"},"cell_type":"markdown","source":"In the table above, we will look at the the second column - Survived column.\nAs we can see, the following fields are clearly correlated:\n* Fare\n* Pclass\n\nUnlike I would have expected, it is curious how Age is not directly correlated with survival.\nBoth SubSp and Parch are not directly related with the survival.  "},{"metadata":{"_uuid":"fda2978e8b5af2d2b3af1a0675b20efb0d047e91"},"cell_type":"markdown","source":"For categorical data (non-ordinal), let's analyse data manually..."},{"metadata":{"trusted":true,"_uuid":"0c77e959ea2f2e011a35d57a67fd0d829d20c04b"},"cell_type":"code","source":"original_train_data.groupby('Sex')['Survived'].sum().plot.bar(stacked=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b24a5b019a3394402a26fa4766ef12baab7d3b73"},"cell_type":"code","source":"original_train_data.groupby('Embarked')['Survived'].sum().plot.bar(stacked=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66f088d4c3833c2be8c8c20cf78529ad986838c1"},"cell_type":"markdown","source":"In both cases, it seems there is a clear relationship with survival - e.g. female are more likely to survive than male - and also people embarking in Southampton."},{"metadata":{"_uuid":"2d800ad9a8cd0c0b4e7db950cb0dbc0199db9913"},"cell_type":"markdown","source":"### Trends and correlations: conclusions\nInitial exploration only directly relates a small subset of features with survival:\n* Sex\n* Embarked\n* Fare\n* Pclass\n\nThis does not mean that the rest of features are not related - may be it's only that the relationship is not obvious."},{"metadata":{"_uuid":"35aaf5bcc14908df8ba9aa083ed3f086cf3c76f2"},"cell_type":"markdown","source":"## Building new features\nThe following features are good candidates for creating new features:\n* Name\n* Parch\n* SibSp \n* Cabin \n* Ticket"},{"metadata":{"_uuid":"7e732ec1ecc107db31e2ae192ed434a1f402a72a"},"cell_type":"markdown","source":"### Name: exploring Title feature\nThe most obvious case is extracting the title feature from the name string.\nLet's  create an initial extraction routine and analyse how the feature is correlated with survival"},{"metadata":{"trusted":true,"_uuid":"c6336ba149b65561080edb35c954bd9696d6dbaf"},"cell_type":"code","source":"original_train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e21338aebf91dfc02fd71279a56cd72bcd4f7fb8"},"cell_type":"code","source":"import numpy as np\n\ndef extractTitleFromNameForExploring(name):\n    pos_point=name.find('.')\n    if pos_point == -1: return \"\"\n    wordList=name[0:pos_point].split(\" \")\n    if len(wordList)<=0: return \"\"\n    title=wordList[len(wordList)-1]\n    return title\n\n# Get a list with different titles\ntraining_titleList=np.unique(original_train_data['Name'].apply(lambda x: extractTitleFromNameForExploring(x)))\nfor title in training_titleList:\n    training_titleSet=original_train_data[original_train_data['Name'].apply(lambda x: title in x)]\n    # Evaluate survival rate for each subset\n    survivalRate=float(len(training_titleSet[training_titleSet['Survived']==1]))/float(len(training_titleSet))\n    print('Title['+title+'] count:'+str(len(training_titleSet))+' survival rate:'+str(survivalRate))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"409ba5531dcc997977718f058b7079ba27e39f66"},"cell_type":"code","source":"# Let's check test data set values - just to confirm the training will consider all potential values\ntest_titleList=np.unique(original_test_data['Name'].apply(lambda x: extractTitleFromNameForExploring(x)))\nfor title in test_titleList:\n    test_titleSet=original_test_data[original_test_data['Name'].apply(lambda x: title in x)]\n    print('Title['+title+'] count:'+str(len(test_titleSet)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e4530aee36a1662d1433f728442d0fd0dd1e506d"},"cell_type":"markdown","source":"Ups...there is a new value (Dona) which was not present in the training data set."},{"metadata":{"_uuid":"54f2f422d5509bbac5ad064e0658b51ac2464cbf"},"cell_type":"markdown","source":"The following title values are numerous and will be very useful for the learning model:\n* Miss\n* Mr\n* Mrs\n* Master  \n...but others are not so numerous, as Capt or Jonkheer.\nIt is also remarkable:\n* Some titles seem redundant -e.g. Mme = Miss or Mlle=Mrs  \n* Some titles can be grouped in categories\n  * Army-related\n    * Capt\n    * Col\n    * Major\n  * Nobility\n    * Countess\n    * Lady\n    \n Let's group titles in these categories and analyse again data... \n\n\n\n\n\n"},{"metadata":{"trusted":true,"_uuid":"4a10a077d6568efbe0613444bd3104e7c997ad95"},"cell_type":"code","source":"import numpy as np\n\ndef multipleReplace(text, wordDic):\n    for key in wordDic:\n        if text.lower()==key.lower():\n            text=wordDic[key]\n            break\n    return text\n\ndef normaliseTitle(title):\n    wordDic = {\n    'Mlle': 'Miss',\n    'Ms': 'Mrs',\n    'Mrs':'Mrs',\n    'Master':'Master',\n    'Mme': 'Mrs',\n    'Lady': 'Nobility',\n    'Countess': 'Nobility',\n    'Capt': 'Army',\n    'Col': 'Army',\n    'Dona': 'Other',\n    'Don': 'Other',\n    'Dr': 'Other',\n    'Major': 'Army',\n    'Rev': 'Other',\n    'Sir': 'Other',\n    'Jonkheer': 'Other',\n    }     \n    title=multipleReplace(title,wordDic)\n    return title\ndef extractTitleFromName(name):\n    pos_point=name.find('.')\n    if pos_point == -1: return \"\"\n    wordList=name[0:pos_point].split(\" \")\n    if len(wordList)<=0: return \"\"\n    title=wordList[len(wordList)-1]\n    normalisedTitle=normaliseTitle(title)\n    return normalisedTitle\n\n# Get a list with different titles\ntitleList=np.unique(original_train_data['Name'].apply(lambda x: extractTitleFromName(x)))\nfor title in titleList:\n    titleSet=original_train_data[original_train_data['Name'].apply(lambda x: title in extractTitleFromName(x))]\n    # Evaluate survival rate for each subset\n    survivalRate=float(len(titleSet[titleSet['Survived']==1]))/float(len(titleSet))\n    print('Title['+title+'] count:'+str(len(titleSet))+' survival rate:'+str(survivalRate))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e238804c55a48860b823223df56bcb3286fdaaed"},"cell_type":"markdown","source":"Some of the categories such as Army or Nobility have a so few samples that the learning algorithm may not be able to learn effectively.  \nIn addition to these categories, we may be able to extract additional features related with Age (e.g. Master is a young boy) or Marital Status. However, we will stop here and postpone this exploration for the next iteration.\n\n### Parch/SibSp: exploring IsAlone and FamilySize feature\nCombining these two features we can extract whether a passenger traveled alone and family size. \nLet's explore these possibilities..."},{"metadata":{"trusted":true,"_uuid":"174530ebad66c78c65acce1d06a73c266650c94a"},"cell_type":"code","source":"original_train_data['IsAlone']=(original_train_data[\"SibSp\"]+original_train_data[\"Parch\"]).apply(lambda x: 0 if x>0 else 1)\noriginal_train_data['FamilySize']=original_train_data[\"SibSp\"]+original_train_data[\"Parch\"]+1\n\noriginal_train_data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c11e09952ae591429cdcc92a6765f707bf557439"},"cell_type":"code","source":"import numpy as np\ntotal=original_train_data.groupby('IsAlone')['PassengerId'].count()\nsurvived=original_train_data[original_train_data['Survived']==1].groupby('IsAlone')['PassengerId'].count()\nnotSurvived=original_train_data[original_train_data['Survived']==0].groupby('IsAlone')['PassengerId'].count()\ndf=pd.concat([total, survived,notSurvived], axis=1, sort=True)\ndf.fillna(0,inplace=True)\ndf.columns=['Total','Survived','NotSurvived']\ndf=df.astype('int64')\nprint(df)\ndf.loc[:,['Survived','NotSurvived']].plot.bar(stacked=True,figsize=(20,8))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5737530baa1df4c6803a94ff41f65b4531ca915a"},"cell_type":"markdown","source":"Ups...travelling Alone appears to be negatively correlated with Survival - almost 42% of lonely passengers didn't survive!"},{"metadata":{"trusted":true,"_uuid":"8712b0d4782e682a57f26968a1b7b5e045c9c4bc"},"cell_type":"code","source":"print(\"FamilySize value distribution\")\nprint(original_train_data['FamilySize'].value_counts()/len(original_train_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcfde7f0bb5233e89550e17a51ddf0b852169fe1"},"cell_type":"code","source":"import numpy as np\ntotal=original_train_data.groupby('FamilySize')['PassengerId'].count()\nsurvived=original_train_data[original_train_data['Survived']==1].groupby('FamilySize')['PassengerId'].count()\nnotSurvived=original_train_data[original_train_data['Survived']==0].groupby('FamilySize')['PassengerId'].count()\ndf=pd.concat([total, survived,notSurvived], axis=1, sort=True)\ndf.fillna(0,inplace=True)\ndf.columns=['Total','Survived','NotSurvived']\ndf=df.astype('int64')\nprint(df)\ndf.loc[:,['Survived','NotSurvived']].plot.bar(stacked=True,figsize=(20,8))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c85b0a44bf3e874afe42a46c42c50ffac187b39d"},"cell_type":"markdown","source":"Survival varies with family size  - families with 3 and 4 members are the most likely to survive."},{"metadata":{"_uuid":"665f3b36c84acab65ff7bb0d112f496fe9cacfb6"},"cell_type":"markdown","source":"### Cabin: exploring passengers with NoCabin defined\nCabin is one of the most unreliable features as there are many missing values.\nHowever, let's explore if defining the cabin is related with survival\n"},{"metadata":{"trusted":true,"_uuid":"71df8a9f310de33c7a15f74bfd13e83c5534511b"},"cell_type":"code","source":"original_train_data['NoCabin']=original_train_data['Cabin'].isnull().apply(lambda x: 1 if x is True else 0)\noriginal_train_data.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14796ad722911c2b768caea19950f58ff3e485ce"},"cell_type":"code","source":"total=original_train_data.groupby('NoCabin')['PassengerId'].count()\nsurvived=original_train_data[original_train_data['Survived']==1].groupby('NoCabin')['PassengerId'].count()\nnotSurvived=original_train_data[original_train_data['Survived']==0].groupby('NoCabin')['PassengerId'].count()\ndf=pd.concat([total, survived,notSurvived], axis=1, sort=True)\ndf.fillna(0,inplace=True)\ndf.columns=['Total','Survived','NotSurvived']\ndf=df.astype('int64')\nprint(df)\ndf.loc[:,['Survived','NotSurvived']].plot.bar(stacked=True,figsize=(20,8))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d339bbf8632bb1357d56f7a2d1c8ed3c7a62a050"},"cell_type":"markdown","source":"Strange but true, it seems that those with no cabin assigned are less likely to survive than those with cabin.\nIt would be wise to know exactly what 'not having a cabin assigned' really means.\n\nLet's know have a look at shared cabins - are people sharing cabins more likely to survive?\n"},{"metadata":{"trusted":true,"_uuid":"fa3fb8cd099ca4c04fe24b7ff62fd6da84ed96d7"},"cell_type":"code","source":"import numpy as np\n# Group data to detect sharing of cabins - excluding missing  values\ncabinList=original_train_data[original_train_data['Cabin'].notnull()==True].groupby('Cabin')['PassengerId'].count()\ncabinList=cabinList.reset_index()\ncabinList.columns=['Cabin','Count']\nprint('Distribution of people per cabin - not considering those with missing cabin')\nprint(cabinList['Count'].value_counts())\n\n# Add new column to indicate number of people a passenger is sharing with\n# -1 means there is no data to compute the feature\ndef extractCabinSharedWithFeature(name):\n    if (str(name)!='nan'):\n        row=cabinList.loc[cabinList['Cabin'] == name]\n        count=row['Count']-1\n        return count\n    else:\n        return -1\n\noriginal_train_data['CabinSharedWith']=original_train_data['Cabin'].apply(lambda x: extractCabinSharedWithFeature(x)).astype(int)\n# Let's now analyse this new column\ntotal=original_train_data[original_train_data['CabinSharedWith']!=-1]['PassengerId'].count()\nsurvived=original_train_data[(original_train_data['CabinSharedWith']!=-1) & (original_train_data['Survived']==1)].groupby('CabinSharedWith')['PassengerId'].count()\nnotSurvived=original_train_data[(original_train_data['CabinSharedWith']!=-1) & (original_train_data['Survived']==0)].groupby('CabinSharedWith')['PassengerId'].count()\nsurvivedPercent=survived/total\nnotSurvivedPercent=notSurvived/total\nprint('Survivor distribution by feature CabinSharedWith')\nprint(survivedPercent)\nprint('NotSurvivor distribution by feature CabinSharedWith')\nprint(notSurvivedPercent)\ndf=pd.concat([survived,survivedPercent,notSurvived,notSurvivedPercent], axis=1, sort=True)\ndf.fillna(0,inplace=True)\ndf.columns=['Survived','SurvivedPercent','NotSurvived','NotSurvivedPercent']\ndf.loc[:,['Survived','NotSurvived']].plot.bar(stacked=True,figsize=(20,8))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60f8ff536e31e5e5357bf1f5950ffa6ddcbbe494"},"cell_type":"markdown","source":"Interesting - notice how survival rate is higher among those passengers sharing cabin.\nWe might wonder whether this is true or those sharing cabin have something in common.\nLet's search for correlations..."},{"metadata":{"trusted":true,"_uuid":"a02a9e6b2514c9d01b4aafec44c453822ca5afe9"},"cell_type":"code","source":"original_train_data.corr()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"088b7bc82fac7ce03646b3be861242a33ff53ea2"},"cell_type":"markdown","source":"There is some correlation with socio-economic status - Fare/Pclass.\nIn case these are relevant variables for training, I wonder whether this new variables will contribute much or will be somewhat redudant."},{"metadata":{"_uuid":"7c1ba91a7926330df322419f26d2008769e312de"},"cell_type":"markdown","source":"### Ticket: exploring TicketType\nThe ticket feature can be difficult to explore as contains text and code information altogether.  \nLet's explore the field and try to build something useful..."},{"metadata":{"trusted":true,"_uuid":"fd45eef524e637ed9286689e5a6ceda88d5c433a"},"cell_type":"code","source":"original_train_data['Ticket'].head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"481fb80b7c58a8a0015293abdddd5a49e0f61321"},"cell_type":"markdown","source":"It seems what tickets have prefixes - we will extract them and try to find patterns."},{"metadata":{"trusted":true,"_uuid":"9e885d0a000ef65f978d6c77147bf9e7f327b4a1"},"cell_type":"code","source":"def getTicketType(name, normalise):\n    item=name.split(' ')\n    itemLength=len(item)\n    if itemLength>1:\n        ticketType=\"\"\n        for i in range(0,itemLength-1):\n            ticketType+=item[i].upper()\n    else:\n        ticketType=\"NORMAL\"\n    if normalise==True:\n        ticketType= ticketType.translate(str.maketrans('','','./'))\n    return ticketType\n\n# Let's list what we have - first view without normalising\ntraining_itemList=[]\nfor ticket in original_train_data['Ticket']:\n    training_itemList.append(getTicketType(ticket,False))\nticketTypeList=np.unique(training_itemList)\nprint(\"Ticket type values: no normalisation\")\nprint(ticketTypeList)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e51b7aea12f335ec9007012a97ac710f2f03a0df"},"cell_type":"markdown","source":"Some of the tickets types are quite similar.\nLet's normalise them so that they are grouped."},{"metadata":{"trusted":true,"_uuid":"f93000e9baab87cd1a936df97c5e4af74d303262"},"cell_type":"code","source":"training_itemList=[]\nfor ticket in original_train_data['Ticket']:\n    training_itemList.append(getTicketType(ticket,True))\nticketTypeList=np.unique(training_itemList)\nprint(\"Ticket type values: normalisation\")\nprint(ticketTypeList)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9631a6f9617f2b01419672032f04c4f04f064cf0"},"cell_type":"markdown","source":"Now, we will explore correlation between these values and survival..."},{"metadata":{"trusted":true,"_uuid":"a600ac0a5bfb9320f934a02fcff059254655326a"},"cell_type":"code","source":"pd.set_option('display.max_columns', None)\noriginal_train_data['TicketType']=original_train_data['Ticket'].apply(lambda x: getTicketType(x,True))\ntotal=pd.DataFrame(original_train_data.groupby('TicketType')['PassengerId'].count())\ntotal.columns=['Total']\nsurvived=pd.DataFrame(original_train_data[original_train_data['Survived']==1].groupby('TicketType')['PassengerId'].count())\nsurvived.columns=['Survived']\nnotSurvived=pd.DataFrame(original_train_data[original_train_data['Survived']==0].groupby('TicketType')['PassengerId'].count())\nnotSurvived.columns=['NotSurvived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc25e012fbc0882692d5dd303df1f893d0946053"},"cell_type":"code","source":"# Let's merge all ticket type in the same list\ndf_all=total\ndf_all=df_all.merge(survived,left_index=True, right_on=\"TicketType\")\ndf_all=df_all.merge(notSurvived,left_on='TicketType',left_index=True, right_on=\"TicketType\")\ndf_all['Ratio']=df_all['Survived']/df_all['Total']\ndf_all.loc[:,['Ratio']].plot.bar(figsize=(20,8))\ndf_all\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8d4402b701a15422f6cfa2dbbf82e2a02347220"},"cell_type":"markdown","source":"Same concern as with the previous feature - what if this feature is highly correlated with socio-economic status?\nIt may be redundant and ineffective for training...\nLet's explore the data directly....in particular, the ticketType with the highest ratio."},{"metadata":{"trusted":true,"_uuid":"77f0d08c5d4290d3e000f16988b9157026b9d1a1"},"cell_type":"code","source":"original_train_data[original_train_data['TicketType']=='FCC']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb4f5cee12e6229efe49d62a15f588259c2ebef6"},"cell_type":"markdown","source":"Interesting! It seems that  three of the members belong to the same family...  \nLet's take note for the next rounds of exploration..."},{"metadata":{"_uuid":"424da39da87aa447c83e91e876d252335478ffc6"},"cell_type":"markdown","source":"### Devising new features: conclusions\nThese are the conclusions after work on this section:  \n* New features\n  * Title\n  * IsAlone\n  * FamilySize\n  * NoCabin\n  * CabinSharedWith\n  * TicketType\n * Doubts on whether some of these features will add more variance and enrich the learning model."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}