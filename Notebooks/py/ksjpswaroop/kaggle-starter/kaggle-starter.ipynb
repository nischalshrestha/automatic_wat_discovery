{"nbformat_minor": 1, "metadata": {"language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "file_extension": ".py", "version": "3.6.4", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "pygments_lexer": "ipython3"}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat": 4, "cells": [{"execution_count": null, "cell_type": "code", "source": [], "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": [], "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "from sklearn import linear_model as lm\n", "from sklearn.cross_validation import train_test_split\n", "from matplotlib import pyplot as plt\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": [], "metadata": {"_uuid": "da2c882294e2de9c771ed53e5ed226e359e7d3d0", "_cell_guid": "86c608e6-e0ff-4f4c-aa89-21a2d877ae4a"}}, {"execution_count": null, "cell_type": "code", "source": ["# reading the train file and saving it as a pandas data frame #\n", "train_df = pd.read_csv('../input/train.csv')\n", "test_df = pd.read_csv('../input/test.csv')"], "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["# dimensions of the input data (number of rows and columns) #\n", "print(\"Train dataframe shape is : {}\".format(train_df.shape))\n", "print(\"Test dataframe shape is : {}\".format(test_df.shape))"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# name of the columns #\n", "train_df.columns"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["test_df.columns"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# taking a look at the first few rows #\n", "train_df.head(10)"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# getting the summary statistics of the numerical columns #\n", "train_df.describe()"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# getting the datatypes of the individual columns #\n", "train_df.dtypes"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# more information about the dataset #\n", "train_df.info()"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["test_df.info()"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# dropping the cabin variable #\n", "train_df.drop(['Cabin'], axis=1, inplace=True)\n", "test_df.drop(['Cabin'], axis=1, inplace=True)"], "outputs": [], "metadata": {"collapsed": true}}, {"cell_type": "markdown", "source": ["# Plotting"], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# let us get some plots to see the data #\n", "train_df.Survived.value_counts().plot(kind='bar', alpha=0.6)\n", "plt.title(\"Distribution of Survival, (1 = Survived)\")"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# scatter plot between survived and age #\n", "plt.scatter(range(train_df.shape[0]), np.sort(train_df.Age), alpha=0.2)\n", "plt.title(\"Age Distribution\")"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["train_df.Pclass.value_counts().plot(kind=\"bar\", alpha=0.6)\n", "plt.title(\"Class Distribution\")"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["train_df.Embarked.value_counts().plot(kind='bar', alpha=0.6)\n", "plt.title(\"Distribution of Embarked\")"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "source": ["# Plots with DV"], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["train_male = train_df.Survived[train_df.Sex == 'male'].value_counts().sort_index()\n", "train_female = train_df.Survived[train_df.Sex == 'female'].value_counts().sort_index()\n", "\n", "ind = np.arange(2)\n", "width = 0.3\n", "fig, ax = plt.subplots()\n", "male = ax.bar(ind, np.array(train_male), width, color='r')\n", "female = ax.bar(ind+width, np.array(train_female), width, color='b')\n", "ax.set_ylabel('Count')\n", "ax.set_title('DV count by Gender')\n", "ax.set_xticks(ind + width)\n", "ax.set_xticklabels(('DV=0', 'DV=1'))\n", "ax.legend((male[0], female[0]), ('Male', 'Female'))\n", "plt.show()"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "source": ["# Supervised Machine Learning\n", "## Logistic Regression"], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# getting the necessary columns for building the model #\n", "train_X = train_df[[\"Pclass\", \"SibSp\", \"Parch\", \"Fare\"]]\n", "train_y = train_df[\"Survived\"]\n", "test_X = test_df[[\"Pclass\", \"SibSp\", \"Parch\", \"Fare\"]]"], "outputs": [], "metadata": {"collapsed": true}}, {"cell_type": "markdown", "source": ["# Cross Validation\n", "How do we know the performance on the model on a new dataset??\n", "what we can do is, build the model on a part fo the dataset and then test it on the other part so that we get an idea of how our model performs on a new data. This process is known as Model Validation in Machine Learning field.\n", "So now let us split the train data into two parts\n", "1. Developement sample\n", "2. Validation Sample"], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# split the train data into two samples #\n", "dev_X, val_X, dev_y, val_y = train_test_split(train_X, train_y, test_size=0.33, random_state=42)\n", "\n", "# Build the machine learning model - in this case, logistic regression #\n", "# Initialize the model #\n", "clf = lm.LogisticRegression()\n", "\n", "# Build the model on development sample #\n", "clf.fit(dev_X, dev_y)\n", "\n", "# Predict on the validation sample #\n", "val_preds = clf.predict(val_X)\n", "print(val_preds[:10])\n"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["# import the function that computes the accuracy score #\n", "from sklearn.metrics import accuracy_score\n", "\n", "accuracy_score(val_y, val_preds)"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["val_preds = clf.predict_proba(val_X)\n", "val_preds[:10]"], "outputs": [], "metadata": {}}, {"cell_type": "markdown", "source": ["### To-DO:\n", "Need to analyse on other variables and improve accuracy"], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": [], "outputs": [], "metadata": {"collapsed": true}}]}