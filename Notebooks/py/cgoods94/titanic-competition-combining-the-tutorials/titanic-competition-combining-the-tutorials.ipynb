{"metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.1", "mimetype": "text/x-python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}}}, "nbformat_minor": 1, "nbformat": 4, "cells": [{"metadata": {"_uuid": "5533889e6086ca137bcc4ccfc22ea7abe0e9427e", "collapsed": true, "_cell_guid": "3a7c02fe-647f-4dde-8aca-e119ce8fdc39"}, "cell_type": "code", "source": ["# Imports\n", "\n", "# pandas\n", "import pandas as pd\n", "from pandas import Series,DataFrame\n", "\n", "# numpy, matplotlib, seaborn\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "sns.set_style('whitegrid')\n", "%matplotlib inline\n", "\n", "# preprocessing\n", "from fancyimpute import KNN\n", "\n", "# machine learning\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.ensemble import RandomForestClassifier"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "eb6544d8e1fa069b212783773288a05fbcd4d4f2", "_cell_guid": "a9fda0fb-8a03-4f05-9b56-ea13051ee7f8"}, "cell_type": "markdown", "source": ["## Loading the Data"]}, {"metadata": {"_uuid": "33eb5b380620039eea0310f3317c96c185b957e5", "collapsed": true, "_cell_guid": "870e5e15-78a8-41c0-acfb-6fff03c17d9b", "scrolled": true}, "cell_type": "code", "source": ["train = pd.read_csv('../input/train.csv')\n", "test_raw = pd.read_csv('../input/test.csv')"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "56ca00995710927340c65ef68f330295bcba581d", "_cell_guid": "f116de51-b135-4f78-a683-2803e44df639"}, "cell_type": "markdown", "source": ["PassengerId won't have information about survival since it is abritrarily cast, and Cabin is too sparse to be reliable, so they will be discarded."]}, {"metadata": {"_uuid": "4236a828d9753aecb9626798c5a3e5dcea9017e9", "collapsed": true, "_cell_guid": "5f81776d-af0d-4284-ad82-fb5abdf25e50"}, "cell_type": "code", "source": ["train.drop(['PassengerId', 'Cabin'], axis=1, inplace = True)\n", "test = test_raw.drop(['Cabin'], axis = 1)\n", "\n", "test.info()"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "1ffdffb453e69ace89a3b30c4559bf2222eeec8c", "_cell_guid": "b3935b6e-d1c3-416d-81ec-d84e2dec9763"}, "cell_type": "markdown", "source": ["## Single-Value Imputation\n", "\n", "As is evident from the above info call, the Fare, Embarked, and Age variables have missing observations. I'm going to impute these using k-nearest neighbors. \n"]}, {"metadata": {"_uuid": "8405a079981150af0200b28f8f27d57239c52c08", "_cell_guid": "5727aa50-8ce3-422f-9aa4-b4317efef684"}, "cell_type": "markdown", "source": ["### Embarked\n", "\n", "Let's take a look at the distribution of Fare across the three ports from which the passengers Embarked."]}, {"metadata": {"_uuid": "a6fda5d7a35771c37166d6be69bf14f428d22ada", "collapsed": true, "_cell_guid": "9cb25163-a6e4-4a62-b13b-9fa25388a288"}, "cell_type": "code", "source": ["full = pd.concat([train, test])\n", "sns.boxplot(x = \"Fare\", y = \"Embarked\", data = full)"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "186d2bfbafa085e52cacb79bc138e34c5d3648f7", "_cell_guid": "eaeb40c5-cc2c-4cb5-8442-b7dd90c8b868"}, "cell_type": "markdown", "source": ["Those outliers out of Cherbourg sure are annoying. Who paid over $500 for a ticket?\n", "\n", "Anyway, let's now analyze the 2 passengers who are missing a port."]}, {"metadata": {"_uuid": "fc295371cea5a44137d9126c9fc3b9e78773ba08", "collapsed": true, "_cell_guid": "206ee4c6-214d-4969-86ac-7a9c2fad919f", "scrolled": false}, "cell_type": "code", "source": ["full[full.Embarked != full.Embarked]"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "5bcb5a08937d48070e28fb483b3a827b0dc16486", "_cell_guid": "81363df6-fe27-4ffe-a959-f11fa3a5d852"}, "cell_type": "markdown", "source": ["These two passengers paid \\$80 for a first-class ticket, and it is in fact the same ticket number. Let's see which port is most likely to sell a first-class ticket for \\$80."]}, {"metadata": {"_uuid": "7d2f8a9f29ab14bb4fe6eb7e29f882a0ef85ca6b", "collapsed": true, "_cell_guid": "0e608ecf-5f4b-45fa-9369-0a6d197d91d3"}, "cell_type": "code", "source": ["sns.boxplot(x = \"Fare\", y = \"Embarked\", data = full[full.Pclass == 1])\n", "plt.axvline(x = 80, color = 'r', linewidth = 3)"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "c09be9eee10fa2070a277593d011b55da8b142b9", "_cell_guid": "9d9a001c-10f2-4110-97a8-b3b66b66b711"}, "cell_type": "markdown", "source": ["It is most likely that these ladies sailed out of Cherbourg. Let's impute those values now."]}, {"metadata": {"_uuid": "1dd1a96405a0b68ab4bf0901ea7e4a8c7a05906a", "collapsed": true, "_cell_guid": "5210eb51-427b-495f-ad99-5b1131c6eee5"}, "cell_type": "code", "source": ["train.loc[train.Embarked != train.Embarked, \"Embarked\"] = \"C\"\n", "test.loc[test.Embarked != test.Embarked, \"Embarked\"] = \"C\"\n", "\n", "full = pd.concat([train, test])\n", "full.loc[(full.Fare == 80) & (full.Pclass == 1),:]\n"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "bc87d80468365a67f976a4192584088914ef4c50", "_cell_guid": "14062bb5-6038-4718-9a54-2d979e68ad34"}, "cell_type": "markdown", "source": ["## Fare\n", "\n", "Only one Fare value is missing. Let's check it out."]}, {"metadata": {"_uuid": "4f241d7b325f7cd785dfefe88612b916e027f2b2", "collapsed": true, "_cell_guid": "0f6791d9-ca0e-49a9-af9d-566be6cc6b3a"}, "cell_type": "code", "source": ["test[test.Fare != test.Fare]"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "2b0b3e9e89e7148f411beca7d426279723b0cfe1", "_cell_guid": "7ee23195-22d2-49bd-aa49-ef44af437d5d"}, "cell_type": "markdown", "source": ["Ah, a passenger from the test set. This time, we'll just use the mean fare for a third-class passenger embarking from Southampton."]}, {"metadata": {"_uuid": "9e01fb42fb2969fe0e5049d9314d8dfb2b294511", "collapsed": true, "_cell_guid": "6d358815-d7dd-4960-8756-1ec2085b2fb3"}, "cell_type": "code", "source": ["imp_fare = full.loc[(full.Embarked == 'S') & (full.Pclass == 3), \"Fare\"].mean() \n", "\n", "test.loc[test.Fare != test.Fare, \"Fare\"] = round(imp_fare, 2)\n", "test.loc[(test.Name == \"Storey, Mr. Thomas\"),:]"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "d8d83210580ac5bec4c058de696b098616531d95", "_cell_guid": "b78cb778-7788-499c-a8f7-0151f2744d75"}, "cell_type": "markdown", "source": ["# One Hot Encoding\n", "\n", "Before imputing the Age variable, it would be wise to one-hot encode the categorical Embarked and Sex variables. This will help with the age imputation by giving us more data for the k-nearest neighbors algorithm and it will be useful for the actual model training at the end."]}, {"metadata": {"_uuid": "cbee8fe246a7d62c160388167f44fe3cb738b0de", "collapsed": true, "_cell_guid": "9493489d-32d1-4d00-9420-bd9fe79a9e30"}, "cell_type": "code", "source": ["full = pd.concat([train, test])\n", "full.info()"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "5c2af5376bbdcd0116cc02191f021cfda3d408eb", "collapsed": true, "_cell_guid": "c54f7726-b7e2-4915-b69c-3c2346fa6f09"}, "cell_type": "code", "source": ["# Embarked\n", "embark_dummies_train  = pd.get_dummies(train['Embarked'])\n", "embark_dummies_test = pd.get_dummies(test['Embarked'])\n", "\n", "train = train.join(embark_dummies_train)\n", "test = test.join(embark_dummies_test)\n", "\n", "train.drop(['Embarked'], axis = 1, inplace = True)\n", "test.drop(['Embarked'], axis = 1, inplace = True)\n", "\n", "# Sex\n", "\n", "sex_dummies_train = pd.get_dummies(train['Sex'])\n", "sex_dummies_test = pd.get_dummies(test['Sex'])\n", "\n", "train = train.join(sex_dummies_train)\n", "test = test.join(sex_dummies_test)\n", "\n", "train.drop(['Sex'], axis = 1, inplace = True)\n", "test.drop(['Sex'], axis = 1, inplace = True)\n", "\n"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "a31e3e0b98d440cf2fbd957d0c066bd17734dd92", "collapsed": true, "_cell_guid": "fe28aecb-3441-4802-b111-10140a276bbb"}, "cell_type": "code", "source": ["test.info()"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "ab79ad4e108c5c409636ceee7b5a25d3d31ff35e", "_cell_guid": "a92f7d2d-0f19-4479-813e-f4f5058bdcdd"}, "cell_type": "markdown", "source": ["## Age\n", "\n", "With 263 missing values, imputing this variable will require something more systematic than the other two. Specifically, I am going to employ k-nearest neighbors imputation. For k, I am going to use the square root of the sample size rounded to the nearest whole number."]}, {"metadata": {"_uuid": "ad116a93621fa2b0d866f49eaa07012971c3b6fb", "collapsed": true, "_cell_guid": "0ab8b236-eb1c-4bcf-b7e2-bdbfb0fe93c3"}, "cell_type": "code", "source": ["k_train = int(np.sqrt(891))\n", "k_test = int(np.sqrt(418))\n", "\n", "train_features = train.drop(['Survived'], axis = 1).select_dtypes(include = [np.float, np.int])\n", "test_features = test.select_dtypes(include = [np.float, np.int])\n", "\n", "filled_ages_train = pd.DataFrame(KNN(k = k_train).complete(train_features)).loc[:,1]\n", "filled_ages_test = pd.DataFrame(KNN(k = k_test).complete(test_features)).loc[:,1]\n", "\n", "train.Age = round(filled_ages_train, 1)\n", "test.Age = round(filled_ages_train, 1)\n", "\n", "full = pd.concat([train, test])\n", "full.info()"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "266511581e4ec2b6112dcbe76c8033325cc24b60", "_cell_guid": "be77a581-6fc2-4f90-9763-d77919035196"}, "cell_type": "markdown", "source": ["## Feature Engineering\n", "\n", "### Title\n", "\n", "One feature I'd like to borrow from Megan Risdal's tutorial is the Title feature. This is extracted from the Name feature using regular expressions.\n", "\n"]}, {"metadata": {"_uuid": "51ab697ff3a79b41eea8dda327d982cfcbf718da", "collapsed": true, "_cell_guid": "e4677122-3590-49a0-8b51-e039ccceffe6"}, "cell_type": "code", "source": ["train_titles = train.Name.str.replace('(.*, )|(\\\\..*)', '').rename('Title')\n", "train = train.join(train_titles)\n", "\n", "test_titles = test.Name.str.replace('(.*, )|(\\\\..*)', '').rename('Title')\n", "test = test.join(test_titles)"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "b7a73bfd9e499cb31260e4ed3c5e0248d7c4e343", "collapsed": true, "_cell_guid": "bc3f5822-5e9b-41ca-87a8-aa67cc2d1612"}, "cell_type": "code", "source": ["full = pd.concat([train, test])\n", "full.groupby(\"Title\").Title.count()"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "493a2a7c2583ba0210c9886776486dc6ef6afa75", "_cell_guid": "47c52880-caeb-4771-ba0d-0fcd82e92d74"}, "cell_type": "markdown", "source": ["Also going to lump the rare titles into one descriptor:"]}, {"metadata": {"_uuid": "420de68f14d3a18a5366ee113f8dcad3738971e5", "collapsed": true, "_cell_guid": "0252c326-caef-4d3b-9f98-c528eb28bef7"}, "cell_type": "code", "source": ["rare_title = [\"Capt\", \"Col\", \"Don\", \"Dona\", \"Dr\", \"Jonkheer\", \n", "              \"Lady\", \"Major\", \"Rev\", \"Sir\", \"the Countess\"]\n", "\n", "train.loc[train.Title.isin(rare_title), \"Title\"] = \"Rare\"\n", "test.loc[test.Title.isin(rare_title), \"Title\"] = \"Rare\"\n", "\n", "full = pd.concat([train ,test])\n", "full.groupby(\"Title\").Title.count()"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "c9fac2d05e531f31a9241ed45e63823f92d80b41", "_cell_guid": "1cdc7af7-72f2-47e8-9eb9-eaeab9f9eb70"}, "cell_type": "markdown", "source": ["And then we just have to fix the female title abbreviations to Mrs/Miss to have nice and tidy Title factors."]}, {"metadata": {"_uuid": "08eca093493e78701bf01ab2aeee861293dc6f18", "collapsed": true, "_cell_guid": "0f72e605-0426-43ab-a122-e05f26008b98"}, "cell_type": "code", "source": ["train.loc[train.Title.isin([\"Mlle\", \"Ms\"]), \"Title\"] = \"Miss\"\n", "train.loc[train.Title == \"Mme\", \"Title\"] = \"Mrs\"\n", "\n", "test.loc[test.Title.isin([\"Mlle\", \"Ms\"]), \"Title\"] = \"Miss\"\n", "test.loc[test.Title == \"Mme\", \"Title\"] = \"Mrs\"\n", "\n", "full = pd.concat([train ,test])\n", "full.groupby(\"Title\").Title.count()"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "ebf6eee66855c7a3b46cd9c311b15e0e5d55911e", "_cell_guid": "3b483073-a98f-4080-ac45-2abf8a1db8c9"}, "cell_type": "markdown", "source": ["Let's one-hot encode these since there are only five of them."]}, {"metadata": {"_uuid": "5fb45699af88025500909109d2db30fb23909c42", "collapsed": true, "_cell_guid": "efdcd53e-c68b-4634-975e-c3be7db22b76"}, "cell_type": "code", "source": ["title_dummies_train  = pd.get_dummies(train['Title'])\n", "title_dummies_test = pd.get_dummies(test['Title'])\n", "\n", "train = train.join(title_dummies_train)\n", "test = test.join(title_dummies_test)\n", "\n", "train.drop(['Title'], axis = 1, inplace = True)\n", "test.drop(['Title'], axis = 1, inplace = True)\n", "\n", "full = pd.concat([train ,test])\n", "full.describe()"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "3b40584f21bfda3f4024d4843b8981abb2c88356", "_cell_guid": "30da116b-7936-4b3a-9b5a-9746b1b09f23"}, "cell_type": "markdown", "source": ["### Family Size\n", "\n", "We can make a Family Size variable from Parch and Sibsp.\n"]}, {"metadata": {"_uuid": "b302c81862037553cdbb599c1c626943d9add8cf", "collapsed": true, "_cell_guid": "38896be1-c0cd-482f-953e-50485e40dac8"}, "cell_type": "code", "source": ["train_fsize = train.Parch + train.SibSp\n", "train = train.join(train_fsize.rename('Fsize'))\n", "\n", "test_fsize = test.Parch + test.SibSp\n", "test = test.join(test_fsize.rename('Fsize'))\n", "\n", "full = pd.concat([train ,test])\n", "full.describe()"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "cd6ef0c330b947f790b19b22af4d11a626ddbe0f", "_cell_guid": "0d59a32d-aebf-425a-bf2a-ba3058eb1a1d"}, "cell_type": "markdown", "source": ["### Child\n", "\n", "Let's make a variable for whether or not the passenger was a child."]}, {"metadata": {"_uuid": "4d003b24187e438bed1a3dcaf2a7436e6b7ebc54", "collapsed": true, "_cell_guid": "82c7c437-7f18-4e2f-ace3-642684a34054"}, "cell_type": "code", "source": ["train_child = train.Age < 16\n", "train = train.join(train_child.rename('Child'))\n", "\n", "test_child = test.Age < 16\n", "test = test.join(test_child.rename('Child'))\n", "\n", "full = pd.concat([train ,test])\n", "full.groupby(\"Child\").Child.count()"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "5aaab708ddc5ea9f7aaf3464223c5213e1d2058b", "collapsed": true, "_cell_guid": "7006b4f2-7b21-4e03-9c8f-9f0de2b6c882"}, "cell_type": "code", "source": ["test.info()"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "5114ffbab6fe26bac3d1f384aaa6f0db9262b6e6", "_cell_guid": "8d5ed295-dd27-4d16-a373-eb502c254e6d"}, "cell_type": "markdown", "source": ["## Model Building\n", "\n", "We'll go by Omar El Gabry's Python tutorial for this portion."]}, {"metadata": {"_uuid": "8ee188faa15b7f9dda18c1e638193d036590d21a", "collapsed": true, "_cell_guid": "748411b7-35a2-48fc-8442-f1ddb567b227"}, "cell_type": "code", "source": ["X_train = train.drop([\"Survived\", \"Name\", \"Ticket\"],axis=1)\n", "Y_train = train[\"Survived\"]\n", "X_test  = test.drop([\"PassengerId\", \"Name\", \"Ticket\"], axis = 1)"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "f3bb5ce8ffd24aacd2844f8e438af2248eb70fff", "collapsed": true, "_cell_guid": "29ffd090-bc4c-4549-8ba3-9c371e77da1a"}, "cell_type": "code", "source": ["# Logistic Regression\n", "\n", "logreg = LogisticRegression()\n", "\n", "logreg.fit(X_train, Y_train)\n", "\n", "Y_pred = logreg.predict(X_test)\n", "\n", "logreg.score(X_train, Y_train)"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "2f598ce02ccd7d216c0fae8ed3b0612f7a5a362d", "collapsed": true, "_cell_guid": "cce00ef6-a429-4293-b2a3-6e76942b8043"}, "cell_type": "code", "source": ["# Random Forests\n", "\n", "random_forest = RandomForestClassifier(n_estimators=100)\n", "\n", "random_forest.fit(X_train, Y_train)\n", "\n", "Y_pred = random_forest.predict(X_test)\n", "\n", "random_forest.score(X_train, Y_train)"], "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "d329200c9e3ba5495c65b0a9c32765bc183df7a3", "_kg_hide-output": false, "collapsed": true, "_cell_guid": "6debd124-e099-4d8f-ac7f-4172d690e97e"}, "cell_type": "code", "source": ["submission = pd.DataFrame({\n", "        \"PassengerId\": test[\"PassengerId\"],\n", "        \"Survived\": Y_pred\n", "    })\n", "submission.to_csv('pySubmission.csv', index=False)"], "outputs": [], "execution_count": null}]}