{"nbformat_minor": 1, "metadata": {"language_info": {"pygments_lexer": "ipython3", "mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.3", "file_extension": ".py"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "cells": [{"cell_type": "markdown", "metadata": {"_uuid": "9b9b22f40fda1540bc0bcd5bb68f6c66996098ae", "_cell_guid": "e05805bd-e4a6-42e7-881e-3986cd887473"}, "source": ["Hello everyone!, \n", "\n", "This is my first kernel on Kaggle.so any input is appreaciated. This notebook provides Exploratory analysis, feature engineering, data cleaning/mining and machine learning model parameter turning using GridSearchCV along with visualization of the decision boundaries the models."]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "cae4742eede6bdac0d4f76de4021d11ef2a2343f", "collapsed": true, "_cell_guid": "59c47284-b760-492f-bd5e-3703e203dd8a"}, "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "import seaborn as sns\n", "from scipy import stats\n", "from scipy.stats import norm\n", "import seaborn as sns\n", "sns.set(context = 'paper', palette = 'winter_r', style = 'darkgrid', rc= {'figure.facecolor': 'gray',}, font_scale=1.5)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "322ec68dde0462823cec68e7e3a8ce5fbaebac3a", "collapsed": true, "_cell_guid": "a58bf3ce-f426-49f4-ace0-38e783c50bec"}, "source": ["def Readcsv(data):\n", "    return (pd.read_csv(data,index_col = 'PassengerId'))\n", "\n", "traindf = Readcsv('../input/train.csv')\n", "testdf  = Readcsv('../input/test.csv')   "], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "aad652f3e0e97eb3705a51cdbfd66c9335a621b6", "_cell_guid": "6551a8ec-3108-4562-8d18-cd504eb9352c"}, "source": ["traindf.columns, testdf.columns"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "02f5dda2a2ff45580e51ac640557bb390b0cb85a", "_cell_guid": "67b52475-3359-43e0-8e68-b010e5343e89"}, "source": ["There are many columns(features) in this dataset let us break them down.\n", "\n", "**Survived**: Wheather the person Survived or not.\n", "\n", "**Pclass**: Passanger class indicates the class of that person aboard the ship.\n", "\n", "**SibSp**: Shows the number of Sibling/Spouces they had.\n", "\n", "**Parch**: Parch indicates Parents with children\n", "\n", "**TIcket**: Ticket name/Number.\n", "\n", "**Fare**: How much the Passenger paid.\n", "\n", "**Cabin**: Cabin name of that Passenger.\n", "\n", "**Embarked**: Point of Embarkation where *C* means Cherbourg, *Q* means Queenstown, *S* means Southampton."]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "774499b1573cd9a5952fef7e432a508f72348abb", "_cell_guid": "dbd0c09d-5b3a-4b1e-9f65-0ad530432f00"}, "source": ["traindf.head()"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "4ed817dcfa27725028f88895985f985d487afd8b", "_cell_guid": "57d516c8-408a-4a68-acc2-e98c593a09e7"}, "source": ["We can differentiate the data into two groups:\n", "\n", "**Categorical**: From the dataset we can see that *Survived*, *Pclass*, *Sex*, *Embarked* are categorical. Why? they have discrete values such has 0 or 1.\n", "\n", "**Continuous**: From the dataset we can see that *Age* and *Fare* has a value which can be **measured.**"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "e212fbd68dea74b0124bdcefdbb25d4fd6fc6c1b", "_cell_guid": "4fe88e99-8ed8-4424-9051-e74875597931"}, "source": ["traindf.isnull().sum()"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "fdc98eaa45d9d74f6edf9326d3b4d3aba5b69d2c", "_cell_guid": "bd57a192-881b-4662-9c57-c0cd834cbe7d"}, "source": ["<h1><center>Exploratory Analysis</center></h1>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "153efaf44774e052ac1f9aef80f65c750afa71dc", "_cell_guid": "d3c7fab3-da36-4b60-91c6-00ee92b8a3f0"}, "source": ["plt.figure(figsize = [17,6])\n", "a = sns.distplot(traindf['Age'].dropna(),bins = range(0,81,1), rug = True, fit = norm)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "1df833694c69e6b640ac79fa95dfbd881784e8de", "_cell_guid": "4ab7df19-5a58-478b-8ec0-076f9020a786"}, "source": ["What does the graph tell us? Most of the Passengers aboard the Titanic were in the range of 16~ to 40. The age distribution shows bi-modal curve."]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "a707f877465173c3e48ba528720b02141000fb38", "_cell_guid": "f86aed8b-ef53-4394-a6fc-282289e4c423"}, "source": ["f, ax = plt.subplots(4, 3,figsize=[22,12])\n", "#sns.set_palette('Set1', 8, .75)\n", "#sns.set_style('whitegrid')\n", "#plt.subplot(331)\n", "sns.violinplot(x = 'Sex', y = 'Survived', data = traindf,ax = ax[0,0])\n", "#sns.despine(offset=10, trim=True)\n", "#plt.subplot(332)\n", "sns.barplot(x = 'Pclass',y ='Survived',data = traindf,hue = 'Embarked',ax = ax[0,1])\n", "#plt.subplot(333)\n", "sns.distplot(traindf[traindf['Survived']==1]['Age'].dropna(),norm_hist = True,bins = np.arange(0,81,1),color = 'blue',\n", "            ax = ax[0,2])\n", "sns.distplot(traindf[traindf['Survived']==0]['Age'].dropna(),norm_hist = True,bins = np.arange(0,81,1), color = 'red',\n", "            ax = ax[0,2])\n", "#plt.subplot(334)\n", "sns.violinplot(x = 'Sex', y = 'Fare', data = traindf,ax = ax[1,0])\n", "#plt.subplot(335)\n", "sns.barplot(x ='Pclass', y = 'Fare',data = traindf , hue = 'Embarked', ax = ax[1,1])\n", "#plt.subplot(336)\n", "sns.distplot(traindf[traindf['Survived']==1]['Fare'].dropna(),bins = np.arange(0,580,10),color = 'blue',\n", "            ax = ax[1,2])\n", "sns.distplot(traindf[traindf['Survived']==0]['Fare'].dropna(),bins = np.arange(0,580,10),color = 'red',\n", "            ax = ax[1,2])\n", "\n", "#plt.subplot(337)\n", "sns.violinplot(x = 'Sex', y ='SibSp',data = traindf,ax = ax[2,0])\n", "#plt.subplot(338)\n", "sns.barplot(x= 'Pclass', y = 'SibSp', data = traindf, hue = 'Embarked', ax = ax[2,1])\n", "#plt.subplot(339)\n", "sns.regplot(x = 'Fare', y = 'Age', data = traindf, ax = ax[2,2])\n", "#plt.subplot(341)\n", "sns.violinplot(x = 'Sex', y = 'Parch', data = traindf, ax = ax[3,0])\n", "#plt.subplot(342)\n", "sns.barplot(x = 'Pclass', y = 'Parch', data = traindf, hue = 'Embarked', ax = ax[3,1])\n", "plt.close(12)\n", "plt.close(13)\n", "plt.close(14)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "d2f3e7edf66dafb7c9d74033e199c7d0be2a4b94", "_cell_guid": "2f92c492-ff3e-4fa7-a83d-7bfe86d6e260"}, "source": ["**1.** Starting from the first graph, we can see that very few males survived as compared to female  and very few females died in comparision to males.\n", "\n", "**2.** First and second class had the most survival rate than the third class whereas pessangers who boarded from *'S'* had the least survival rate.\n", "\n", "**3.** The *blue* and *red* distribution shows whether the pessanger survived or not.\n", "\n", "**4. & 5.** There were many passengers from both category who paid nothing to board the ship particularly from the **third** class \n", "\n", "**6.** The distribution of Fare with respect to Survival *blue* indicating Survived while *red* indicating dead.\n", "\n", "**7. & 8.** There were more *female* SibSp(siblings and spouces) as compared to *male* and majority of them were from **First** class from *Q* station followed by **third** class.\n", "\n", "**9.** Distribution of Fare by Age shows that there were many passengers paying nothing being majority while a few paying more than 500!\n", "\n", "**10. & 11.** By looking at the graph we can see that it is similar with SibSp to some extent with the only difference that *Parch* is flattened and the bar plot says that *Parch* there were no Passengers from *Q* aboard as *1st* and *2nd* class.\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "9b2cebae3d6b7837f08095fbb5ea725cd058a672", "_cell_guid": "40e61c28-80e2-43f8-afda-0632a7a500cf"}, "source": ["traindf[traindf['Fare']>500]"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "5d58413df61639f65fc2481cdceac01087a9e6af", "_cell_guid": "ed464ac9-08db-4f10-8134-9cc321c3bd19"}, "source": ["We can see that those who paid highest have the same ticket names. we'll investigate this further."]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "71d261ab35fd6458cd3e571cfc009099e7bef08f", "collapsed": true, "_cell_guid": "dfbc3943-f436-43a9-b180-5f5513939ae1"}, "source": ["def get_isnull(train,test):\n", "    return(train.isnull().sum(), test.isnull().sum())    "], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "030f4473663a7e2e13d76ef257da7ae3f4202d2b", "_cell_guid": "091c7a0c-55eb-4dab-907d-1fadb4d1958b"}, "source": ["get_isnull(traindf,testdf)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "7aafaf8eb6933484f3e12da2a7bd485c52e284ab", "_cell_guid": "527a4797-4c5c-4743-8304-dea612c2879c"}, "source": ["There are alot of missing values present in both the datasets which is not good for our model."]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "26f290405e01d147f8848a412a9d18b6dda667b6", "collapsed": true, "_cell_guid": "51b8e834-283b-4d96-a52e-51e21a2219f4"}, "source": ["#function for concatation so that we won't have to repeat them again and again in future.\n", "def combine(data1,data2):\n", "    fulldf = pd.concat([data1,data2])\n", "    return fulldf"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "8d29b14c48c96c68bf54fb6a12942f02d54efd6c", "collapsed": true, "_cell_guid": "5816fb78-5f9e-4d44-b7ea-abaf5f92438b"}, "source": ["#Function for separation so that we won't have to repeat them again.\n", "def saperate(data):\n", "    data1 = data.iloc[:len(traindf)]\n", "    data2 = data.iloc[len(traindf):]\n", "    return data1, data2"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "7a744578a078dae34269402d1225a617ac0d0c04", "_cell_guid": "129137dd-562e-4a87-b39d-4889503dc1b1"}, "source": ["testdf[testdf['Fare'].isnull()]"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "9c67da5254aa6101e86796c5be3c6e24079cc82b", "_cell_guid": "95ad7847-a650-4617-8408-cab12a8c58bd"}, "source": ["median is used instead of mean so that the value does not sway too much in a direction."]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "da5c008e3d6c5cba41cc1b5f443e5a29d6a204ad", "collapsed": true, "_cell_guid": "cc78b088-b32a-4119-99d4-99147ac8d97a"}, "source": ["def filling(data1,data2):\n", "    data = combine(data1,data2)\n", "    data['Embarked'] = data['Embarked'].fillna('C')\n", "    data['Age']      = data['Age'].fillna(data['Age'].median())\n", "    data['Fare']     = data['Fare'].fillna(data['Fare'].median())\n", "    data['Cabin']    = data['Cabin'].fillna('Z')\n", "    data['Cabin']    = data['Cabin'].apply(lambda x: str(x)[0])\n", "    traindf, testdf    = saperate(data)\n", "    return traindf, testdf\n", "traindf, testdf = filling(traindf, testdf)\n", "#testdf = filling(testdf)\n"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "432ba74ee5930803a0e52bc6a6183778878eec54", "_cell_guid": "b41feaeb-4429-4a86-b086-fd9a48cf0aeb"}, "source": ["sns.barplot(x= 'Cabin', y = 'Survived', data = traindf ,order = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'Z', 'T'])"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "5f25edd11cde92b6644535e9bf8e2affc846e21c", "collapsed": true, "_cell_guid": "d70143ba-1f63-4e38-b82e-beebadf56880"}, "source": ["def pew(data1, data2):\n", "    data = combine(data1,data2)\n", "    data['Cabin'] = data['Cabin'].replace(['B', 'D', 'E'], 'H')   #High\n", "    data['Cabin'] = data['Cabin'].replace(['F', 'C'], 'M')        #Medium\n", "    data['Cabin'] = data['Cabin'].replace(['T', 'G', 'A',], 'L')  #Low\n", "    data['Cabin'] = data['Cabin'].replace(['Z'],'X')              #Missing\n", "    traindf, testdf    = saperate(data)\n", "    return traindf, testdf\n", "traindf, testdf = pew(traindf,testdf)\n", "#testdf  = pew(testdf)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "ac5250f4503f28d7b6be918fb98c53831217a1d6", "_cell_guid": "233cdfab-9f1e-496e-bffb-021b9dc55b19"}, "source": ["It's better that we combine both SibSp and Parch as they can be represented as family."]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "55a683f13a0b4f6953a53d8b297f0cb4795ee036", "collapsed": true, "_cell_guid": "12c4040c-a4e6-4771-a783-822eaaeafcbf"}, "source": ["def family(data1, data2):\n", "    data = combine(data1,data2)\n", "    data['Family'] = data['SibSp'] + data['Parch'] + 1\n", "    data['Alone']  = data['Family'].apply(lambda x: 1 if x == 1 else 0)\n", "    data.drop(['SibSp','Parch'],axis = 1, inplace = True)\n", "    traindf, testdf    = saperate(data)\n", "    return traindf, testdf\n", "traindf, testdf = family(traindf, testdf)\n", "#testdf  = family(testdf)\n"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "bc7bcbf0aabf6ad8fb90d510da7ea5ec46e20d60", "_cell_guid": "67dfcf3b-672f-45ab-af61-fa0421cfcdc6"}, "source": ["f,ax = plt.subplots(1,3,figsize=[20,7])\n", "sns.barplot(x = 'Alone', y = 'Survived', data = traindf,orient = 'h', ax = ax[0])\n", "sns.barplot(x = 'Survived', y = 'Family', data = traindf,orient = 'h', ax = ax[1])\n", "sns.factorplot(y = 'Family',data = traindf, kind = 'count', orient = 'h', ax = ax[2])\n", "plt.close(2)\n", "plt.close(3)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "1d618143df99e6068cda76c9cdcef381e6ee1fe1", "_cell_guid": "5b4eb2a9-057d-4bfe-84d9-d9cbe1202022"}, "source": ["Most of the Passengers aboard were alone. The Passengers who were alone had a lower survival rate which is also true for Passengers who had more than 4 members with them."]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "0d4a2938eebbde0d3a96712d0678f33b2e4d4a01", "_cell_guid": "855303e5-005e-4b21-a826-df0cddc120c6"}, "source": ["traindf.head()"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "f435e39250c7462b5cf40c5123f3d8056b0b4940", "collapsed": true, "_cell_guid": "46153b96-d215-4f0a-aba5-edd19563f741"}, "source": ["def FamilyGroup(data1, data2):\n", "    data = combine(data1,data2)\n", "    data.loc[data['Family'] > 2, 'FamilyGroup'] = 3\n", "    data.loc[data['Family'] == 1, 'FamilyGroup'] = 1\n", "    data.loc[data['Family'] == 2, 'FamilyGroup'] = 2\n", "    traindf, testdf    = saperate(data)\n", "    return traindf, testdf\n", "traindf, testdf = FamilyGroup(traindf, testdf)\n", "#testdf  = FamilyGroup(testdf) "], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "4abd2ee815eb1d420a38389b282aac2d2e10104c", "collapsed": true, "_cell_guid": "10943ecc-6111-4300-8456-118698705013"}, "source": ["def mapping(data1, data2):\n", "    data = combine(data1,data2)\n", "    data['Embarked'] = data['Embarked'].map({'C':1, 'S':2, 'Q':3})\n", "    data['Sex']      = data['Sex'].map({'male': 1,'female':0})\n", "    data['CabinGroup'] = data['Cabin'].map({'H': 0, 'M': 1, 'L': 2, 'X':3})\n", "    traindf, testdf    = saperate(data)\n", "    return traindf, testdf\n", "traindf, testdf = mapping(traindf, testdf)\n", "#testdf  = mapping(testdf)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "ba22f728b68074756f52dff858c0e476cf3ae04c", "_cell_guid": "29797129-0af3-4b62-8e1e-6939959f3222"}, "source": ["traindf['CabinGroup'].value_counts()"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "0f8d2b60c3d0927fcdb93d5a1d8ad4e7bce5bd8a", "_cell_guid": "51244a1d-e1e6-46a1-ac72-6a3f30ba29f3", "scrolled": true}, "source": ["traindf.head()"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "86b55bde516379e4c7eb5672be9bb119cb8212f4", "collapsed": true, "_cell_guid": "9fb45104-778f-4941-acfb-cbabb745e274"}, "source": ["def Titles(data1, data2):\n", "    data = combine(data1,data2)\n", "    data['Title'] = data['Name'].apply(lambda x: str(x).split(',')[1].split('.')[0])\n", "    data['TitleGroup'] = 0\n", "    data['TitleGroup'] = data['Title'].replace(['Mme','Ms','Lady','Sir','Mlle','the Countess',],0,          #High\n", "                                            regex = True).replace(['Mrs','Miss','Master',],1,               #Medium\n", "                                            regex = True).replace(['Dr','Major','Col','Mr'],2,              #Low\n", "                                            regex = True).replace(['Don','Rev','Capt','Jonkheer','Dona'],4, #Least\n", "                                            regex = True)\n", "    #data['TitleGroup'] = data['TitleGroup'].replace({'male':1,'female':0,'Special':2})\n", "    traindf, testdf    = saperate(data)\n", "    return traindf, testdf\n", "traindf, testdf = Titles(traindf, testdf)\n", "#testdf  = Titles(testdf)\n", "##['Mrs','Miss','Mme','Ms','Lady','Mlle','Countess','Dona'],'female'\n", "##['Sir','Don','Rev','Mr',],'male'\n", "##['Col','Dr','Col','Capt','Major','Jonkheer','Master'],'Special'"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "d1b10efe3a2cb1e5b74f12600153e96a47792709", "_cell_guid": "5993872c-66f2-40a7-b2c3-f8cabfd2cb42"}, "source": ["plt.figure(figsize = [8,5])\n", "sns.barplot(x = 'Survived', y = 'Title', data = traindf, palette = 'Blues_d',)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "5ddc5c90ab160e99e3d5c8b62aa3539a08d478f3", "collapsed": true, "_cell_guid": "f62bdc2b-362c-4cee-8d19-3385d3b1d780"}, "source": ["def surname(data1, data2):\n", "    data = combine(data1,data2)\n", "    data['Surname'] = data['Name'].apply(lambda x: str(x).split(' ')[0].split(',')[0])\n", "    Shares = 0\n", "    Shares = data.groupby('Surname').apply(lambda x: x.shape[0])\n", "    data['SharedSurname'] = data['Surname'].map(Shares)\n", "    traindf, testdf    = saperate(data)\n", "    return traindf, testdf\n", "\n", "traindf, testdf = surname(traindf, testdf)\n"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "125f6d13d65d197bf2add7d203c8d32241fe6170", "_cell_guid": "04d51af1-25a5-4bea-83de-e353fe759f60"}, "source": ["traindf.loc[traindf['Ticket'].str.contains('113803')]"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "3a07d6a653519afca5cf6b5040d018a0d519b5b0", "_cell_guid": "a99f6cce-717e-41bd-8bf8-b67a48d1bda5"}, "source": ["def age_distribution(data1, data2):\n", "    data = combine(data1,data2)\n", "    data.loc[data['Age']].round()\n", "    data.loc[data['Age'] <= 16, 'AgeGroup'] = 1\n", "    data.loc[(data['Age'] > 16) & (data['Age'] <= 40), 'AgeGroup'] = 2\n", "    data.loc[(data['Age'] > 40) & (data['Age'] < 60), 'AgeGroup'] = 3\n", "    data.loc[(data['Age'] >= 60), 'AgeGroup'] = 4\n", "    #data['AgeGroup'].astype(int)\n", "    traindf, testdf    = saperate(data)\n", "    return traindf, testdf\n", "traindf, testdf = age_distribution(traindf, testdf)\n", "#testdf = age_distribution(testdf)\n", "plt.figure(figsize = [17,6])\n", "sns.barplot(x = traindf['AgeGroup'], y = traindf['Survived'])#data = traindf,)#ci = 95, orient = 'v')\n", "plt.rc('xtick',labelsize = 12)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "9b3e68daa523f12a8a7f424f8dc8fb133b858ae9", "_cell_guid": "f36674de-2436-4e8c-83d4-7f53369d1afd"}, "source": ["traindf.head(2)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "f6b84a9185ab8fc168d5069f461690f089e445a4", "_cell_guid": "b5a1b948-3bc6-4bb6-a8c9-9667cfa041dc"}, "source": ["sns.factorplot(x = 'Pclass', y = 'Fare', col = 'Embarked', hue = 'Sex', data = traindf, margin_titles = True)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "fff1ca35a90e8832cb0ea2143376fe281827d679", "_cell_guid": "7837e6bf-6309-42ac-bb7f-161c83d30269"}, "source": ["There is much difference for *1st* and *2nd* Embarkation for *1st* and *3rd* Pclass in terms of fare for males and females while the *2nd* class fare is similar in all the Embarkations."]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "53756f2f52b5e03f4d5d05bb3744e026a50e7426", "collapsed": true, "_cell_guid": "74999ed1-0e54-45e2-94ac-640e84822399"}, "source": ["def SharedSurname(data1, data2):\n", "    data = combine(data1,data2)\n", "    Shares = 0\n", "    Shares = data.groupby('Surname').apply(lambda x: x.shape[0])\n", "    data['SharedSurname'] = data['Surname'].map(Shares)\n", "    traindf, testdf    = saperate(data)\n", "    return traindf, testdf\n", "traindf, testdf = SharedSurname(traindf, testdf)\n", "#testdf  = SharedSurname(testdf)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "5abc461406f9a8f521a5764728449b1460a712c1", "_cell_guid": "82e8a993-ebd4-4e9a-a9fd-4e67447dc593"}, "source": ["testdf.head(3)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "da3b6d2d97f5598c58efa2efea6049aa209b894a", "_cell_guid": "83163b79-3d1d-4969-b77d-7efea8125a01"}, "source": ["Grouping Fare and creating a new column called *'FareGroup'* with their means by Pclass"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "ba85fc0604af1252684e991de1996612695b8ffe", "collapsed": true, "_cell_guid": "6f04a2ab-556a-4a96-80c4-873036597c44"}, "source": ["def fare_distribution(data1, data2):\n", "    data = combine(data1,data2)\n", "    payment = data.groupby('Pclass')['Fare'].mean()\n", "    data.loc[(data['Fare'] < payment[3]),'FareGroup'] = 1\n", "    data.loc[(data['Fare'] > payment[3]) & (data['Fare'] <  payment[2]),'FareGroup'] = 2\n", "    data.loc[(data['Fare'] > payment[2]) & (data['Fare'] <  payment[1]), 'FareGroup'] = 3\n", "    data.loc[(data['Fare'] > payment[1]),'FareGroup'] = 4\n", "    #data['Fare'] = data['Fare'].map({'Very Low': 0, 'Low': 1, 'Medium':2, 'High':3})\n", "    data['FareGroup'] = data['FareGroup'].astype(int)\n", "    traindf, testdf    = saperate(data)\n", "    return traindf, testdf\n", "#payment = fulldf.groupby('Pclass')['Fare'].mean()\n", "traindf, testdf = fare_distribution(traindf, testdf)\n", "#testdf = fare_distribution(testdf)\n"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "93076020f35626a724a1cee9760a2d9b2752c4d9", "collapsed": true, "_cell_guid": "3000094e-b77e-4f4d-a8aa-79e788cac5c1"}, "source": ["#pd.get_dummies(traindf,columns = (['Pclass','Sex','Age','Fare','Embarked','Family','Alone','Title']), drop_first = True)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "138221b2839a939ade86841905f5e05063e1fff1", "collapsed": true, "_cell_guid": "b06ae864-3c83-4cc3-ba77-0d6064b453a4"}, "source": ["def Tickets(data1, data2):\n", "    data = combine(data1,data2)\n", "    #Creating a new column to display the freq of the tickets present\n", "    data['SharedTicketCount'] = data.groupby('Ticket')[['Fare']].transform('count').astype(int)\n", "    #Removing any characters other than alphabets and numbers to count the ticket length\n", "    data['Ticket'] = data['Ticket'].str.replace('.','').str.replace('/','').str.replace(' ','')\n", "    data['TicketLength'] = data['Ticket'].apply(lambda x: len(str(x)))\n", "    traindf, testdf    = saperate(data)\n", "    return traindf, testdf\n", "traindf, testdf = Tickets(traindf, testdf)\n", "#testdf = Tickets(testdf)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "895394da3fd216445197a03c416b47029a10fdaa", "_cell_guid": "d5652cb8-1b85-4a43-a88f-44785cd30c1b"}, "source": ["traindf.columns"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "d5abfb89e988497738dd49cc4d1382681910adb6", "_cell_guid": "ee98425e-2efb-4ab3-a9d6-00838f875339"}, "source": ["traindf.head()"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "e2f39b38588241f431f1a0b6162e6b48735f46bb", "_cell_guid": "ffcb8089-7356-471f-afd0-0c011c203115"}, "source": ["X = traindf.drop(['Name','Title','Surname','Survived','Cabin','Ticket',\n", "                  'Age','Fare','Family','Alone'],axis = 1)\n", "y = traindf['Survived']\n", "X.shape , y.shape"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "0ada422bce0ecc0d95eb97ebc0a27040f575b90b", "_cell_guid": "a3145198-cca2-47a0-9fb9-4388ea43f9ac"}, "source": ["X.columns"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "32e69f6bfb89fc3f02f25163fc3cbef3d1eea920", "_cell_guid": "16d38501-5ada-4def-9b81-ef04f4fbcb47"}, "source": ["# Correlation"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "2d8239e43fed361dac1e8ab8049b786cc62a846e", "_cell_guid": "23a89cb7-838b-498b-adb6-54f8527dc681"}, "source": ["f, ax = plt.subplots(figsize = [25,16])\n", "sns.heatmap(traindf.corr(),linewidths = .5, annot = True, cmap = 'YlGnBu', square = True)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "6e3a8e0f975e0ec1b2b39132847d1f7666cf658f", "collapsed": true, "_cell_guid": "e90d2011-27fe-46bb-aa8f-a778d2a6f24c"}, "source": ["Since categorical features have been created from the features present in the dataset taking only the categorical for training the models."]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "40288fbf3c8bbcb654ea88d5ff173d0290cd34a1", "collapsed": true, "_cell_guid": "51880bcd-cc65-4f53-ab45-854460886cf1"}, "source": ["from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n", "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.svm import SVC\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from xgboost import XGBClassifier, plot_importance "], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "7e56eff1b183fad9c87ff698c3eece75ef82aca0", "_cell_guid": "aabf1570-7270-45bd-9edf-b8112ed924ec"}, "source": ["X.columns"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "5512536b469268f1df14d6e072f64b941fca4878", "collapsed": true, "_cell_guid": "1aa22047-c9e3-4268-a8b8-ae365dbdfddb"}, "source": ["npX = np.array(X).copy()\n", "npy = np.array(y).copy()"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "6d3fd9191575827b11457b6f23d141ff21bac326", "_cell_guid": "b76e8000-8689-419a-a7b4-c590267aeb0c"}, "source": ["<h1><center>Models</center></h1>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "baad822c33515e144a81ad914283acb609e9d4ef", "collapsed": true, "_cell_guid": "bf375756-1371-4a08-a4f1-5f2c23707b8f"}, "source": ["clf_rf = RandomForestClassifier()\n", "clf_et = ExtraTreesClassifier()\n", "clf_bc = BaggingClassifier()\n", "clf_ada = AdaBoostClassifier()\n", "clf_dt = DecisionTreeClassifier()\n", "clf_xg = XGBClassifier()\n", "clf_lr = LogisticRegression()\n", "clf_svm = SVC()"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "1e15a23fad517f55d533c6680828de6d309985a6", "collapsed": true, "_cell_guid": "088950f8-46a8-42d8-97ce-ae7b4081a4bb"}, "source": ["Classifiers = ['RandomForest','ExtraTrees','Bagging','AdaBoost','DecisionTree','XGBoost','LogisticRegression','SVM']\n", "scores = []\n", "models = [clf_rf, clf_et, clf_bc, clf_ada, clf_dt, clf_xg, clf_lr, clf_svm]\n", "for model in models:\n", "    score = cross_val_score(model, npX, npy, scoring = 'accuracy', cv = 10, n_jobs = -1).mean()\n", "    scores.append(score)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "a992d4cdd19118cd685ca3db733e0d82fe1fd48e", "collapsed": true, "_cell_guid": "fe1d50ab-f19c-45ef-876c-ecd1a67335ea"}, "source": ["mode = pd.DataFrame(scores, index = Classifiers, columns = ['score']).sort_values(by = 'score',\n", "             ascending = False)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "20aadb5a406ca1a671b25d383619990dd0d90b86", "_cell_guid": "d607f2f0-e00b-42eb-97dd-aa99e20985ee"}, "source": ["mode"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "3ff9fc1d6a56bb35899f16b0a5b28e7406d10437", "_cell_guid": "2650f655-0f14-4772-af88-299cae9cc641"}, "source": ["Selecting the top 3 classifiers for model prediction."]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "6e301ea99571f7d658b427bd9f02663d65b0d96d", "collapsed": true, "_cell_guid": "40fc73df-ed2c-4380-905e-17249cb6cd9b"}, "source": ["parameters_xg = {'max_depth':[3,6,7], 'learning_rate': [0.1,0.2], 'n_estimators': [300,200], \n", "                 'min_child_weight': [4], 'reg_alpha': [6,0], 'reg_lambda': [1,8],'max_delta_step':[2],\n", "                 'gamma':[0],'seed':[1]}\n", "\n", "parameters_svm = {'C':[0.9,0.01],'kernel':['rbf','linear'], 'gamma':[0,0.1,'auto'], 'probability':[True,False],\n", "                  'random_state':[0,7,16],'decision_function_shape':['ovo','ovr'],'degree':[3,4,10]}\n", "\n", "parameters_rf = {'n_estimators': [100,50], 'max_features': [7,'auto',None],\n", "                 'n_jobs': [-1], 'min_samples_leaf': [2,4,], 'random_state':[1,7,], \n", "                 'min_samples_split':[2,6,], 'oob_score': [True,False],\n", "                 'criterion': ['gini'], 'warm_start': [True,False]}\n"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "148c218ef1d6dc069265e45aa7f002dd5e2c88aa", "collapsed": true, "_cell_guid": "b49fdb06-b829-41bc-a6e3-deab6290470a"}, "source": ["def grid(model,parameters):\n", "    grid = GridSearchCV(estimator = model, param_grid = parameters, cv = 10, \n", "                        scoring = 'accuracy')\n", "    grid.fit(npX,npy)\n", "    return grid.best_score_, grid.best_estimator_.get_params()"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "6645c2ba066e514000becdfb9edef762c240f855", "collapsed": true, "_cell_guid": "bbbf77fb-c8ed-4d0d-9501-e01a1a3c5f11"}, "source": ["def imp_features(model, model_name, params):\n", "    Model = model(**params)\n", "    Model.fit(npX,npy)\n", "    names = X.columns\n", "    feature = Model.feature_importances_\n", "    important_features = pd.Series(data = feature, index = names,)\n", "    important_features = important_features.sort_values(ascending = True)\n", "    return important_features.plot(kind = 'barh', grid = False,title = model_name)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "996d478c57a9d2c4204c13657f3fd2c0b42f8516", "_cell_guid": "fe21e568-8db0-4e5c-9f23-ce6a05154dcf"}, "source": ["best_score_xg, best_params_xg = grid(clf_xg,parameters_xg)\n", "print(best_score_xg)\n", "imp_features(XGBClassifier, 'XGBoostClassifier', best_params_xg)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "5b07a720c529af5c1f1908b19fac8453049cd019", "_kg_hide-input": false, "_cell_guid": "e018125b-b376-4a74-9ab4-8389bd2663ac", "_kg_hide-output": false}, "source": ["best_score_rf, best_params_rf = grid(clf_rf, parameters_rf)\n", "print(best_score_rf)\n", "imp_features(RandomForestClassifier,'Random Forest', best_params_rf)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "a10567ab4288d9de455783b43fd8d68693b65452", "_cell_guid": "103770d7-7d34-4da5-b74d-51854735422a"}, "source": ["best_score_svm, best_params_svm = grid(clf_svm, parameters_svm)\n", "print(best_score_svm)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "fee6ea4e3e665d6c5dc3730f102e554bd88427b8", "_cell_guid": "14236e24-2af1-44d6-8964-8f1f50ecdf34"}, "source": ["Let us visualize the decision boundaries to see if our models are overfitting or not but the number of features in our data set are 7+ we'll have to reduce the dimensions to 2 to be able to visualize, in this notebook PCA is used for dimensionality reduction. "]}, {"cell_type": "markdown", "metadata": {"_uuid": "e76b54726b932c9afd146b06b0ea04e22b7c652b", "_cell_guid": "77d4221d-4afb-4d43-b536-66a598b2c510"}, "source": ["<h1><center>Decision Boundary Visualization</center></h1>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "341e981b7fd795aa9d5ca04f38cdc06f7ebc06a8", "collapsed": true, "_cell_guid": "028eec85-8c92-4c9f-80fc-a7fd6a66844b"}, "source": ["from sklearn.preprocessing import StandardScaler\n", "from sklearn.decomposition import PCA\n", "from matplotlib.colors import ListedColormap\n", "x = StandardScaler().fit_transform(X)\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = .2)\n", "X_train_reduced = PCA(n_components = 2).fit_transform(X_train)\n", "X_test_reduced  = PCA(n_components=  2).fit_transform(X_test)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "0962165a3b330e0857f83034d4424df7f05cfa32", "collapsed": true, "_cell_guid": "7731ec61-c57d-40f9-b507-015677cf59b1"}, "source": ["def boundaries(model, heading, best_params):\n", "    Model = model(**best_params)\n", "    Model.fit(X_train_reduced, y_train)\n", "\n", "    X_set, y_set = np.concatenate([X_train_reduced, X_test_reduced], axis = 0), np.concatenate([y_train, y_test], axis = 0)\n", "    X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n", "                             np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n", "\n", "    #plt.figure(figsize = [15,16])\n", "    plt.contourf(X1, X2, Model.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n", "                     alpha = 0.5, cmap = ListedColormap(('k', 'blue')))\n", "    \n", "    plt.xlim(X1.min(), X1.max())\n", "    plt.ylim(X2.min(), X2.max())\n", "\n", "    for i, j in enumerate(np.unique(y_set)):\n", "        plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', 'green'))(i), label = j)\n", "    plt.xticks(fontsize = 3)\n", "    plt.yticks(fontsize = 3)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "c7c8afa3cc46c27a72dc10f975cd847dfa660347", "_cell_guid": "832f47fa-0826-4e7f-b7c2-dcdf0449c2e1"}, "source": ["fig = plt.figure(figsize=[15,7])\n", "\n", "ax = plt.subplot(1,2,1)\n", "plt.title('XGBClassifier')\n", "boundaries(XGBClassifier,'eXtreme Boosting Classifier', best_params_xg)\n", "\n", "\n", "ax = plt.subplot(1,2,2)\n", "plt.title('RandomForest')\n", "boundaries(RandomForestClassifier, 'Random Forest', best_params_rf)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "e7f900cd3f2f5bb85b9d2229d0c56560704e0424", "_cell_guid": "b721c0e3-c992-49c8-a7b1-3ecbf7006dd8"}, "source": ["The graphs above clearly shows that the models are overfitting quite a bit, hence their performance will be bad on the test set. Let's look at our SVM model's decision boundaries with **mlxtend** library."]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "d2e019083d3ef55acf5569234985a679217233b3", "_cell_guid": "6a887b34-7fb0-471a-bde9-92cb0bb896ab"}, "source": ["from mlxtend.plotting import plot_decision_regions\n", "t = np.array(y_train)\n", "t = t.astype(np.integer)\n", "clf_svm = SVC(**best_params_svm)\n", "clf_svm.fit(X_train_reduced,t)\n", "plt.figure(figsize = [15,10])\n", "plot_decision_regions(X_train_reduced, t, clf = clf_svm, hide_spines = False, colors = 'purple,limegreen',\n", "                      markers = ['^','v'])\n", "plt.title('Support Vector Machines')"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "505318d7085ea6f11e57e08b50dded0d01618cc4", "collapsed": true, "_cell_guid": "7abcd0eb-8900-44bc-bfcf-03a109405210"}, "source": ["clf_svm = SVC(**best_params_svm)\n", "clf_svm.fit(npX,npy)\n", "testdf = testdf.drop(['Name','Title','Surname','Survived','Cabin','Ticket',\n", "                  'Age','Fare','Family','Alone'],axis = 1)\n", "nptest = np.array(testdf)\n", "pred = clf_svm.predict(nptest)\n", "predictions = pd.DataFrame(pred, index = testdf.index, columns = ['Survived'])\n", "predictions.to_csv('predictions_svm_with_groups.csv')"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "db80f992a09aa9d3b7748365aa73be13c744fcef", "_cell_guid": "c6db00db-afb9-40b1-b52e-af653d8df11e"}, "source": ["![](http://i.imgur.com/LyRLYuc.png)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "9ebabe6ac2875690def96c79b001f99240373c2a", "collapsed": true, "_cell_guid": "691de38f-0cbb-4b0f-8137-47e2595d2330"}, "source": ["<h1><center> References </center></h1>"]}, {"cell_type": "markdown", "metadata": {"_uuid": "cd1fbbeb97d40db5d5d7235e27d391f2dd43dc75", "_cell_guid": "fe0c1d1c-8cb9-4e1e-8b93-026fc335e8f1"}, "source": ["* Titanic Data Processing with Python: [Jarvis Yang](https://www.kaggle.com/chuanguy/titanic-data-processing-with-python-0-813)\n", "* mlxtend library: [Eike Dehling](https://www.kaggle.com/eikedehling)\n", "* Decision Boundary from scratch: [bronson](https://www.kaggle.com/jsultan/visualizing-classifier-boundaries-using-kernel-pca)\n", "* And to everyone on the discussion forums for solving my doubts."]}], "nbformat": 4}