{"cells":[{"metadata":{"_uuid":"a49b20e4d6466532a6f0a7e876135a7b5776222b"},"cell_type":"markdown","source":"# TITANIC: MACHINE LEARNING FROM DISASTER\n## A KAGGLE competition\nIn questo progetto si andrà ad analizzare un dataset contenente tutte le informazioni relative ai passeggeri del Titanic, nave tristemente famosa in quanto è affondata provocando diverse centinaia di morti. Il dataset è un dataset pubblico scaricato da Kaggle (https://www.kaggle.com/c/titanic), che è stato reso disponibile in quanto oggetto di una delle competizioni iniziali per familiarizzare con il sistema."},{"metadata":{"trusted":true,"_uuid":"63e215f2dac2d72a94203b032ff5cb0eb2753cd9"},"cell_type":"code","source":"#importiamo le librerie necessarie per l'analisi del dataset\nimport pandas as pd\n# pandas è una libreria molto utilizzata in data analysis in quanto permette di gestire grosse quantità di dati in maniera veloce e inuitiva\n#inoltre offre molte altre funzionalità integrate, come la creazione di grafici ecc-\nimport numpy as np\n#numpy è una libreria utilizzata per un'insieme di operazioni numeriche\nimport matplotlib.pyplot as plt\n#matplotlib ci permette di visualizzare l'andamento dei dati attraverso grafici e tabelle\nimport seaborn as sns\n#seaborn, come matplotlib, permette di visualizzare grafici e creare istogrammi","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c76ca2d1c12d5036e4079ad8e47037accf78f35"},"cell_type":"markdown","source":"### Il dataset è diviso in due parti: test.csv e train.csv. \nIl primo viene usato come 'ground truth', ovvero come campo di allenamento dove allenare il classificatore, mentre nel secondo si andrà a testare il modello ricavato in precedenza per osservare l'accuratezza. \\n Siccome questa è una competitions, il testing set è proposto senza *labels*, quindi non saarò in grado di definire l'accuratezza della classificazione sul testing set. Possiamo ovviare a questo dividendo il training set in due parti, come se fosse l'intero dataset, ma questo avverà in un secondo momento."},{"metadata":{"trusted":true,"_uuid":"f422b40f1d46695a509e527c94361b1653ccf9e6"},"cell_type":"code","source":"#carichiamo il dataset\ntrain= pd.read_csv(\"../input/train.csv\")\n#train = pd.read_csv(\"train.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9bbc6df9fdfe21e9bf38560dfda72229fda8961f"},"cell_type":"markdown","source":"#### Le feature all'interno del dataset si distribuiscono come :\n- PASSENGERID:\n    indica l'ID di ogni passeggero\n- PCLASS:\n    è il tipo di cabina affidato a ogni passeggero: è un indicatore dello stato socio economico dei passeggeri\n    si divide in 1 classe, seconda classe, terza classe. \n- AGE:\n    è l'età di ogni passeggero, è di tipo float perchè quando è una stima viene posto come un numero decimale.\n- SIBSP:\n    definisce le relazioni familiari: indica quanti fratelli/sorelle o mogli/spose sul Titanic\n- PARCH:\n    definisce le relazioni familiari: indica quanti mamme/papà o figli sul Titanic\n- TICKET:\n    Indica il numero di ticket \n- FARE:\n    Indica la tariffa\n- Cabin:\n    Indica il numero della cabina\n- Embarked:\n    Indica dove si è imbarcato il passeggero (C = Cherbourg, Q = Queenstown, S = Southampton)"},{"metadata":{"trusted":true,"_uuid":"63dc089109d5f0e44ff3efc03b52687f923a2a17"},"cell_type":"code","source":"#per rendere più facile la lettura, cambiamo i nomi delle colonne in lowercase\ntrain.columns = [x.lower() for x in train.columns]\ntrain.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"377d1d1bc4aec16327f01f5ee65170982d862d97"},"cell_type":"code","source":"#train.info ci permette di analizzare il dataset e capire quali dati possiede ogni colonna\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"882fe4ba38ecbd854c5cd98152c077a9d68978f6"},"cell_type":"markdown","source":"### Preprocessing dei dati: valori nulli\nNotiamo come nel dataset sono presenti dei valori nulli: prima di poter visualizzare i dati e prima di creare il nostro classificatore dobbiamo trasformarli in modo da poterli rappresentare.\nLe feature su cui dobbiamo lavorare sono Age, cabin e embraked: tutte le altre feature non hanno valori nulli"},{"metadata":{"trusted":true,"_uuid":"fd46c0e22497d554a2e7039f0c9580a9e3275cfa"},"cell_type":"code","source":"#L'idea principale che si utilizza quando si vanno a riempire valori vuoti, e che i 'segnaposto' che si vanno a inserire \n#non devono togliere o dare informazioni aggiuntive ai dati, ovvero 'snaturare' il dataset: infatti, se noi diamo valori\n#che non c'entrano con quelli reali, è molto probabile che la classificazione avvenga non inerente con la realtà.\n#Inserendo nei valori nulla la media delle età, ricaviamo un dato che non aggiunge nè toglie valore alla distribuzione dei dati,\n#non alterandone l'andamento.\ntrain['age'] = train['age'].fillna(train['age'].median())\ntrain['fare'] = train['fare'].fillna(train['fare'].median())\n#stessa cosa per embarked: siccome non sappiamo dove sono saliti i passeggeri, poniamo come segnapost la U di 'Unknown'\ntrain['embarked'] = train['embarked'].fillna('S')\n# per le cabine dobbiamo capire come si distribuiscono nel dataset:\ntrain['cabin'] = train['cabin'].fillna('Unknown')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f465ac8278513eac5ca3736348f73841c4adfa7"},"cell_type":"markdown","source":"Prima di poter fare una classificazione, tutti i dati all'interno del dataset dovranno essere di tipo numerico: le feature EMBARKED e  CABIN sono dati testuali: dovremo trasformali. \nUtilizzeremo un metodo 'ad etichetta': daremo un numero ad ogni campo che sarà identificativo della sua classe (es. a tutti i passeggeri che saranno saliti a Southampton daremo come valore 1, che è identificativo della classe S nel dataset.)\n"},{"metadata":{"trusted":true,"_uuid":"177cdc6f8c01ae818bc2daba0d7076d261f50103"},"cell_type":"code","source":"#per farlo utilizziamo una funzione, denominata def_embarked, e andremo a modificare il dataset attraverso l'operatore lambda\ndef def_embarked(point):\n    if point == \"S\":\n        return 1\n    elif point == \"Q\":\n        return 2\n    elif point == \"C\":\n        return 3\n    else:\n        return 0\n\ntrain[\"embarked_\"] = train.apply(lambda row:def_embarked(row[\"embarked\"]),axis=1)\n\n#per cabin il discorso è un po' diverso: ogni cabina è divisa in una lettera identificativa di una parte della nave più\n#il numero di stanza reale. è necessario dividere in classi in base alla lettera che vi è davanti.\n# identifichiamo la posizione di ogni cabina (se la hanno) all'interno della nave\ndef def_position(cabin):\n    return cabin[:1]\ntrain[\"Position\"] = train.apply(lambda row:def_position(row[\"cabin\"]), axis=1)\n#value_counts() ci restituisce quanti valori ci sono all'interno di uan colonna:\ntrain[\"Position\"].value_counts()\n#osserviamo 8 possibili classi, che andremo ad aggiungere al nostro dataset:\ndef def_cabin(pos):\n    if pos == \"C\":\n        return 1\n    elif pos == \"B\":\n        return 2\n    elif pos == \"D\":\n        return 3\n    elif pos == \"E\":\n        return 4\n    elif pos == \"F\":\n        return 5\n    elif pos == \"A\":\n        return 6\n    elif pos == \"G\":\n        return 7\n    else: \n        return 0\ntrain[\"cabin_\"] = train.apply(lambda row:def_cabin(row[\"Position\"]),axis=1)\n#stessa cosa la effettuiamo con male o female\ndef def_sex(sex):\n    if sex==\"male\":\n        return 0\n    else:\n        return 1\ntrain[\"sex_\"] = train.apply(lambda row: def_sex(row[\"sex\"]),axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d716b0d2b144db43e0847151add7bbe4fcf7814"},"cell_type":"markdown","source":"### Preprocessing dei dati: valori utili\nIl dataset contiene dati che potrebbero essere poco utili durante la classificazione: PASSENGERID e NAME probabilmente non sono utili per una classificazione: saranno feature che andremo a cancellare.\nInoltre togliamo tutte quelle feature che sono state trasformate"},{"metadata":{"trusted":true,"_uuid":"2d4149a4920029c2eeac308aace2345cc8a2dede"},"cell_type":"code","source":"train = train.drop(columns=\"passengerid\")\ntrain = train.drop(columns=\"name\")\ntrain = train.drop(columns = \"embarked\")\ntrain = train.drop(columns = \"cabin\")\ntrain = train.drop(columns= \"Position\")\ntrain = train.drop(columns=\"sex\")\n\ntrain = train.drop(columns=\"ticket\") #drop ma c'è da rivedere, perchè non capisco come funziona","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa91ceac970bf36ee8219637a00258b6837751bb"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"28c115b8e249637cab8d7c53a8c6c2d0abb87376"},"cell_type":"markdown","source":"### Classificazione: Preparazione\nPrima di effettuare la classificazione, abbiamo necessità di creare i vari vettori contenenti i dati relativi al dataset:\n    - Target Names: \n        - ovvero il nome delle etichette, nel nostro caso sopravvissuto o non sopravvissuto\n    - Feature Names:\n        - Ovvero i nomi delle feature: nel nostro caso pclass, age, sibsp, parch, fare, embarked_,cabin_sex_\n    - Data:\n        - Ovvero i dati relativi a ogni campo del dataset: quindi il valore che ha ogni feature in ogni riga del dataset\n    - Target:\n        - Ovvero l'etichetta di ogni riga del dataset, che può essere 0 o 1, ovvero sopravvissuto o non sopravvissuto."},{"metadata":{"trusted":true,"_uuid":"7775eb599708539e820317e55e69d3a44c24b5bf"},"cell_type":"code","source":"x = []\nfor i in train[\"survived\"]:\n    if(i == 1):\n        x.append(\"Survived\")\n    else:\n        x.append(\"Not Survived\")\ntitanic_target_names = np.asarray(x)\ntitanic_feature_names =  np.asarray(train.columns[1:])\ntrain_ = train.drop(columns=\"survived\")\ntitanic_data = np.asarray(train_.get_values())\ntitanic_target = np.asarray(train[\"survived\"])\n#con train_test_split dividiamo il nostro dataset in due parti: la prima che la utilizzeremo per il training, grande il 75% del totale,\n#mentra la seconda la utilizzeremo per il testing, che è grande il 25% del totale. Ovviamente dividerà anche le etichette relative\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(titanic_data,titanic_target,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac375eaeac162c1116ee96b35de58f3015cb0fbc"},"cell_type":"markdown","source":"### Classificazione: Decision Tree Classifier\nCome primo classificatore utilizziamo DecisionTreeClassifier, che si basa sull'interrogazione del dataset in modo da poterlo dividere sempre più in maniera specifica in modo da poter classificare meglio i dati. \nPer info: https://it.wikipedia.org/wiki/Albero_di_decisione"},{"metadata":{"trusted":true,"_uuid":"fe6bc8ac31dc8b5d155119619e12254d3e231614"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier(random_state = 0)\ntree.fit(X_train,y_train)\nprint(\"Accuracy on training set: {}\".format(tree.score(X_train,y_train)))\nprint(\"Accuracy on the testing set: {}\".format(tree.score(X_test,y_test)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75b827269b6886ab859f60540e3bf6b1d0597a40"},"cell_type":"markdown","source":"### Classificazione: Analisi dei risultati ottenuti"},{"metadata":{"_uuid":"503580250b9f24b8382cc63f224ea80d8c409fc3"},"cell_type":"markdown","source":"Sul training set abbiamo un'accuratezza alta, circa del 91%, mentre sul testing set abbiamo un 73%. Il valore che ci interessa è ovviamente il secondo: vogliamo avere una accuratezza maggiore quando non si hanno il valore delle etichette. Andiamo ad osservare come si distribuisce l'albero e se è possibile aumentare il grado di accuratezza."},{"metadata":{"_uuid":"31654505c015e4b928b98a8d79539de7c360ef47"},"cell_type":"markdown","source":"### Salvare l'albero e visualizzarlo"},{"metadata":{"trusted":true,"_uuid":"d84645c4dae92b2e8f0f9c83f579d4e2c84bd6be"},"cell_type":"code","source":"#graphviz è una libreria che serve per caricare grafici e salvarli. Nel nostro caso andiamo a salvare la raffigurazione\n#dell'albero sopra creato e poi andremo a visualizzarlo nel kernel. C'è salvato anche nella cartella\nimport graphviz\nfrom sklearn.tree import export_graphviz\nexport_graphviz(tree,out_file=\"tree.dot\",class_names=[\"Survived\",\"Not Survived\"],feature_names=titanic_feature_names,impurity=False,filled=True)\nwith open(\"tree.dot\") as f:\n    dot_graph = f.read()\ngraphviz.Source(dot_graph)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"780f59624f1ef7f85ee162660fa316569ee81cfd"},"cell_type":"markdown","source":"Osserviamo come ogni feature ha dato il suo contributo alla classificazione"},{"metadata":{"trusted":true,"_uuid":"950bbb5895b6a80674320f414b069c9573084c29"},"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_feature_importances(model):\n    n_features = titanic_data.shape[1]\n    plt.barh(range(n_features),model.feature_importances_,align='center')\n    plt.yticks(np.arange(n_features), titanic_feature_names)\n    plt.xlabel(\"Feature importance\")\n    plt.ylabel(\"Feature\")\n    plt.show()\nplot_feature_importances(tree)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"40c0062f88dce96376dd54a5c4cce2c4365ce39f"},"cell_type":"markdown","source":"La feature principale su cui si è basata la classificazione è il genere, seguito poi da l'età . Questo conferma l'idea che prima si salvano le donne e i bambini. "},{"metadata":{"_uuid":"6000715ebec1c0708b3e4e0906ce4a3ba80b00f6"},"cell_type":"markdown","source":"Possiamo gestire la 'profondità' di un DecisionTree attraverso l'attributo max_depth. Con profondità si intende il numero di domande massimo che il modello fa la dataset: in questo modo si combatte l'overfitting, ovvero la generalizzazione ottenuta solo su dati del dataset.\nOra andiamo a visualizzare l'andamento del grado di importanza di ogni feature in base alla profondità massima."},{"metadata":{"trusted":true,"_uuid":"796121e8f9629272591c21295cd592a462944bb0"},"cell_type":"code","source":"results = []\nimportances = []\nmax_ = [0,0]\nfor i in range(1,10):\n    tree = DecisionTreeClassifier(max_depth=i,random_state = 1)\n    tree.fit(X_train,y_train)\n    if (tree.score(X_test,y_test) > max_[0]):\n        max_ = [tree.score(X_test,y_test),i-1]\n    results.append(tree.score(X_test,y_test))\n    importances.append(tree.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c8d1c04573c8f3d531faf1af06fde5b152c1150"},"cell_type":"code","source":"plt.plot([max_[1]],[max_[0]],marker='o',color=\"red\")\nplt.plot(results)\nplt.title(\"Accuracy on max_depth\")\nplt.ylabel('Accuracy')\nplt.xlabel('max_depth')\nplt.legend([\"Max Accuracy: {0} with {1} depth\".format(round(max_[0],2),max_[1])],loc=(1.04,0.5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f0d2c87ba9f7743829cfafd846bd772ab6303f19"},"cell_type":"markdown","source":"Notiamo come l'accuratezza vari al variare del numero massimo di interrogazioni al dataset, con accuratezza massima a 2. Come varia l'importanza di ogni feature in base alla profondità? "},{"metadata":{"trusted":true,"_uuid":"e1b28404af58d80b43c5178fb591d6374544c3df"},"cell_type":"code","source":"plt.plot(importances)\nplt.legend(titanic_feature_names,loc=(1.04,0.05))\nplt.title(\"Feature importances through max_depth\")\nplt.ylabel('Accuracy')\nplt.xlabel('max_depth')\n#plt.legend([\"Max Accuracy: {0} with {1} depth\".format(round(max_[0],2),max_[1])],loc=(1.04,0.5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5e040a296cfab81ee403eb8f0b293dab855d73a"},"cell_type":"markdown","source":"Notiamo come maggiori sono le domande poste dal modello, più si stabilizzano le percentuali di importanza di ogni feature. Questo perchè il modello, all'aumentare della profondità, è più soggetto a overfitting."},{"metadata":{"trusted":true,"_uuid":"7390c70694d85f082e785a376401bf0c0efbd0fa"},"cell_type":"code","source":"plt.plot(importances)\nplt.plot([max_[1]],[max_[0]],marker='o',color=\"red\")\nplt.plot(results, color=\"red\")\nplt.legend(titanic_feature_names,loc=(1.04,0.05))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"14c75df6d0ef45f25510e8ce8668412e46b2d958"},"cell_type":"markdown","source":"Dall'ultimo grafico notiamo come a max_depth 2 abbiamo la maggior accuratezza, con relativa importanza delle feature"},{"metadata":{"_uuid":"b909bbfc1df41f6195b2cb38737e207a73ef5efe"},"cell_type":"markdown","source":"### Random Forest Classifier"},{"metadata":{"_uuid":"820154edbc406acc11deccf78242ebb857c614a2"},"cell_type":"markdown","source":"Con random forest classifier si intede un classificatore che si basa non su un solo albero, ma su più di uno, in modo da cercare di combattere l'overfitting.\nRichiamando il classificatore, possiamo inserire il numero di alberi che vogliamo creare: andiamo ad analizzare un po' quello che succede."},{"metadata":{"trusted":true,"_uuid":"8ad0ff40f517cd3b259f38df705b8ac446ba8cf7"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nforest = RandomForestClassifier(n_estimators=1,random_state=0)\nforest.fit(X_train,y_train)\n\nprint(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train,y_train)))\nprint(\"Accuracy on testing set: {:.3f}\".format(forest.score(X_test,y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31cec96eeb9596c5cb4fde0d56a57a1d7cd939e6"},"cell_type":"code","source":"plot_feature_importances(forest)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"599f051c1fb84760329623b18bdaf7c14ac0eb36"},"cell_type":"markdown","source":"Le feature sono un po' diverse da quelle del singolo decision tree (perchè?)"},{"metadata":{"trusted":true,"_uuid":"47c109415e01fe6793ed735a01488b916e708297"},"cell_type":"code","source":"results_forest = []\nimportances_forest = []\nmax_forest = [0,0]\nfor i in range(1,10):\n    forest = RandomForestClassifier(n_estimators=i,random_state=0)\n    forest.fit(X_train,y_train)\n    if (forest.score(X_test,y_test) > max_forest[0]):\n        max_forest = [forest.score(X_test,y_test),i-1]\n    results_forest.append(forest.score(X_test,y_test))\n    importances_forest.append(forest.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c25eb54e8f4172b82126b1a0e6890970be47d3e"},"cell_type":"code","source":"plt.plot([max_forest[1]],[max_forest[0]],marker='o',color=\"red\")\nplt.plot(results_forest)\nplt.title(\"Accuracy on max_depth\")\nplt.ylabel('Accuracy')\nplt.xlabel('n_estimators')\nplt.legend([\"Max Accuracy: {0} with {1} n_estimators\".format(round(max_forest[0],2),max_forest[1])],loc=(1.04,0.5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"219d30ae1d911f66952b5fc767807870ba91032d"},"cell_type":"code","source":"plt.plot(importances_forest)\nplt.plot([max_forest[1]],[max_forest[0]],marker='o',color=\"red\")\nplt.plot(results_forest, color=\"red\")\nplt.legend(titanic_feature_names,loc=(1.04,0.05))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff52c46f5916c09698224593dc447c47ee73728e"},"cell_type":"markdown","source":"Come prima, andiamo a visualizzare accuratezza in base al numero di alberi e percentuale di importanza di ogni feature. L'accuratezza non varia di molto."},{"metadata":{"_uuid":"130e18a96f1504ddd5aba2313c7cb51f9f751a10"},"cell_type":"markdown","source":"### Conclusioni"},{"metadata":{"_uuid":"bae1098b4f0983d8a0b1fa248184fa6e071eb891"},"cell_type":"markdown","source":"Si sono utilizzati due tipi di classificatori: DecisionTree e RandomForest. Per entrambi si hanno avuto risultati differenti:\n\n- Best DecisionTree (max_depth = x): \n    - On training set: %\n    - On testing set: %\n- Best RandomForest (n_estimators = x): \n    - On training set: %\n    - On testing set: %\n\nPer entrambi si ha avuta una buona classificazione, con differenze sostanziali individuate sull'importanza data a ogni feature. (PERCHE'?)"},{"metadata":{"_uuid":"73a414bb8152bcee2b482f71596462f575a4b574"},"cell_type":"markdown","source":"#### Last but not least: inviamo i nostri risultati a Kaggle\nPer inviare a Kaggle i risultati e osservare la bontà della nostra classificazione, bisogna riportare tutte le operazioni fatte sul training set al test: osserviamo come è strutturato il test set, e vediamo se dobbiamo apportare delle modifiche:"},{"metadata":{"trusted":true,"_uuid":"7390cecc39c9ccf3667cffa1bbfec7750695cd9b"},"cell_type":"code","source":"test = pd.read_csv(\"../input/test.csv\")\ntest1 = pd.read_csv(\"../input/test.csv\")\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb430fc74fef11d5fa94db1395a060f8026056f4"},"cell_type":"markdown","source":"Il test set (come ci immaginavamo) è uguale al training set, senza però avere le etichette che dicono se la persona è sopravvissuta o meno: quello dobbiamo scoprirlo noi. Applichiamo ogni operazione fatta prima sul nuovo documento."},{"metadata":{"trusted":true,"_uuid":"284d07cf43ea11e74e536e82a393dc796daf7cf7"},"cell_type":"code","source":"test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].median())\ntest[\"Fare\"] = test[\"Fare\"].fillna(test[\"Fare\"].median())\ntest[\"Cabin\"] = test[\"Cabin\"].fillna(\"C\")\ntest[\"Embarked\"] = test[\"Embarked\"].fillna(\"U\")\ntest[\"embarked_\"] = test.apply(lambda row:def_embarked(row[\"Embarked\"]),axis=1)\ntest[\"Position\"] = test.apply(lambda row:def_position(row[\"Cabin\"]), axis=1)\ntest[\"cabin_\"] = test.apply(lambda row:def_cabin(row[\"Position\"]),axis=1)\ntest[\"sex_\"] = test.apply(lambda row: def_sex(row[\"Sex\"]),axis = 1)\ntest = test.drop(columns=\"PassengerId\")\ntest = test.drop(columns=\"Name\")\ntest = test.drop(columns = \"Embarked\")\ntest = test.drop(columns = \"Cabin\")\ntest = test.drop(columns= \"Position\")\ntest = test.drop(columns=\"Sex\")\ntest = test.drop(columns=\"Ticket\")\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dff04cc15e3fe4e9a7a57e99041fbdb354d936b5"},"cell_type":"markdown","source":"Ora che abbiamo pronto il nostro dataset, possiamo entrare nella classificazione. Utilizzeremo quella che ci ha mostrato migliori risultati, ovvero decision tree con grado di profondità 2:"},{"metadata":{"trusted":true,"_uuid":"c0b39b62617239d3b8e658b3aaef60ddeff7a6b6"},"cell_type":"code","source":"best_tree = DecisionTreeClassifier(max_depth=2,random_state = 1)\nbest_tree.fit(X_train,y_train)\npred = best_tree.predict(test)\nd =  {'PassengerId' : test1[\"PassengerId\"],'Survived' : pred}\nprediction = pd.DataFrame(d,columns=[\"PassengerId\",\"Survived\"])\nprediction.to_csv(\"Kaggle_first_try.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}