{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5f3c4698-bd11-a864-914f-4e70504bc4b7"
      },
      "source": [
        "This notebook was inspired from [Megan Risdal's \"Exploring Survival on the Titanic\"][1] and [Omar El Gabry's \"A journey through Titanic\"][2]\n",
        "\n",
        "\n",
        "  [1]: https://www.kaggle.com/mrisdal/titanic/exploring-survival-on-the-titanic\n",
        "  [2]: https://www.kaggle.com/omarelgabry/titanic/a-journey-through-titanic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1362edb8-0215-c239-3e24-f05b1e079b05"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.graphics.mosaicplot import mosaic\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import cross_validation\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b9b9ab6b-f9fc-89fe-2f41-6791bdcd9567"
      },
      "outputs": [],
      "source": [
        "#load data & add the two for data cleaning\n",
        "train = pd.read_csv(\"../input/train.csv\")\n",
        "test = pd.read_csv(\"../input/test.csv\")\n",
        "full = pd.concat([train,test]).set_index(\"PassengerId\")\n",
        "#Description of the data\n",
        "print(full.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "047dd330-c84e-836e-a358-428cb6b81def"
      },
      "outputs": [],
      "source": [
        "#Data--Sex\n",
        "#set the values to numeric\n",
        "full.set_value(full[\"Sex\"] == \"male\", \"Sex\", 0)\n",
        "full.set_value(full[\"Sex\"] == \"female\", \"Sex\", 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f788822c-ec8d-296c-d093-862e549677b3"
      },
      "outputs": [],
      "source": [
        "#Data--Age\n",
        "print(\"The percentage of NaN Values in Age column is: %s %%\" % (((pd.isnull(full[\"Age\"]).sum()) * 100)/1309))\n",
        "plt.figure(figsize=(8,6))\n",
        "#Distribution of the original Age values (blue)\n",
        "sns.distplot(full[\"Age\"].dropna().astype(int), bins=70, label=\"old\")\n",
        "#fill the NaN values in Age with random values\n",
        "for index, row in full.iterrows():\n",
        "    if np.isnan(row[\"Age\"]):\n",
        "        rand = np.random.randint(full[\"Age\"].mean() - full[\"Age\"].std(), \n",
        "                                 full[\"Age\"].mean() + full[\"Age\"].std())        \n",
        "        full.set_value(index, \"Age\", rand)\n",
        "#convert all float values to int       \n",
        "full[\"Age\"] = full[\"Age\"].astype(int)\n",
        "#Distribution of the new Age values (green)\n",
        "sns.distplot(full[\"Age\"], bins=70, label=\"new\")\n",
        "plt.legend()\n",
        "#Distribution of survived/not survived passengers by age\n",
        "plt.figure(figsize=(10,4))\n",
        "av_age = full.groupby(full[\"Age\"]).mean()[\"Survived\"]\n",
        "av_age_plot = sns.barplot(x=av_age.index, y=av_age.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "774a7d7c-4651-4842-0507-770b10fdb60a"
      },
      "outputs": [],
      "source": [
        "#Data--Cabin\n",
        "print(\"The percentage of NaN Values in Cabin column is: %s %%\" % (((pd.isnull(full[\"Cabin\"]).sum()) * 100)/1309))\n",
        "#Since there are so many NaN values, we can discard the Cabin column\n",
        "full = full.drop(\"Cabin\", axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "693ba5f7-f379-96b2-ad83-60238a765dab"
      },
      "outputs": [],
      "source": [
        "#Data--Embarked\n",
        "print(\"The percentage of NaN Values in Embarked column is: %s %%\" % (((pd.isnull(full[\"Embarked\"]).sum()) * 100)/1309))\n",
        "print(full[full[\"Embarked\"].isnull()])\n",
        "#Both passengers in the NaN columns paid a Fare of 80.0 and boarded in the 1st class.\n",
        "#We can use this fact to fill the appropriate value.\n",
        "tmp = full[[\"Pclass\", \"Fare\"]][full[\"Embarked\"].isnull()]\n",
        "new_value = full[full[\"Pclass\"]==1].groupby(full[\"Embarked\"]).median()\n",
        "print(new_value[\"Fare\"])\n",
        "#Since C has the closest value to 80.0, we can fill in 'C'\n",
        "full[\"Embarked\"] = full[\"Embarked\"].fillna('C')\n",
        "#set the values to numeric.\n",
        "full.set_value(full[\"Embarked\"] == \"S\", \"Embarked\", 0)\n",
        "full.set_value(full[\"Embarked\"] == \"C\", \"Embarked\", 1)\n",
        "full.set_value(full[\"Embarked\"] == \"Q\", \"Embarked\", 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5bc972a8-0d73-c881-2a30-efd4b4e2f214"
      },
      "outputs": [],
      "source": [
        "#Data--Fare\n",
        "print(\"The percentage of NaN Values in Fare column is: %s %%\" % (((pd.isnull(full[\"Fare\"]).sum()) * 100)/1309))\n",
        "print(full[full[\"Fare\"].isnull()])\n",
        "#Passenger in the NaN column embarked at 0(\"S\"), and boarded in the 3rd class.\n",
        "new_value_2 = full[full[\"Pclass\"] == 3][full[\"Embarked\"] == 0][\"Fare\"].median()\n",
        "full[\"Fare\"] = full[\"Fare\"].fillna(new_value_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "10f0d882-06bf-a1cf-42f3-e0f7acd83479"
      },
      "outputs": [],
      "source": [
        "#Data --Name\n",
        "print(\"The percentage of NaN Values in Name column is: %s %%\" % (((pd.isnull(full[\"Fare\"]).sum()) * 100)/1309))\n",
        "#While the Name value itself might be useless in analysis, we can extract the respective titles.\n",
        "#split_title: function that helps creating the title column.\n",
        "def split_title(x):\n",
        "    return (x.split(\",\")[1].split(\".\")[0].strip())\n",
        "#Creating title column using the split_title function.\n",
        "full[\"Title\"] = full[\"Name\"].apply(split_title)\n",
        "#Table of the distribution of title by sexes\n",
        "title_by_sex = pd.DataFrame(index = full[\"Title\"].drop_duplicates().values)\n",
        "title_by_sex[\"Male\"] = full[full[\"Sex\"] == 0][\"Title\"].value_counts()\n",
        "title_by_sex[\"Female\"] = full[full[\"Sex\"] == 1][\"Title\"].value_counts()\n",
        "title_by_sex = title_by_sex.fillna(value = 0)\n",
        "print(title_by_sex)\n",
        "#It seems that we can only keep the 4 titles, and set the rest to \"Rare Title\"\n",
        "rare_title = [\"Don\", \"Dona\", \"Rev\", \"Dr\", \"Major\", \"Lady\", \"Sir\",\n",
        "              \"Col\", \"Capt\", \"the Countess\", \"Jonkheer\"]\n",
        "#Putting \"Mlle\" & \"Ms\" to \"Miss\", \"Mme\" to \"Mr\", and other titles to \"Rare Title\"             \n",
        "for index, row in full.iterrows():\n",
        "    if row['Title'] == \"Mlle\":\n",
        "        full.set_value(index, 'Title', 'Miss')\n",
        "    elif row['Title'] == \"Ms\":\n",
        "        full.set_value(index, 'Title', 'Miss')\n",
        "    elif row['Title'] == \"Mme\":\n",
        "        full.set_value(index, 'Title', 'Mrs')\n",
        "    elif row['Title'] in rare_title:\n",
        "        full.set_value(index, 'Title', 'Rare Title')\n",
        "#Table of the distribution of title by sexes        \n",
        "title_by_sex2 = pd.DataFrame(index = [\"Master\", \"Miss\", \"Mr\", \"Mrs\", \"Rare Title\"])\n",
        "title_by_sex2[\"Male\"] = full[full[\"Sex\"] == 0][\"Title\"].value_counts()\n",
        "title_by_sex2[\"Female\"] = full[full[\"Sex\"] == 1][\"Title\"].value_counts()\n",
        "title_by_sex2 = title_by_sex2.fillna(0)\n",
        "print(title_by_sex2)\n",
        "#Surname column: column of every surnames (might be useful for additional research)\n",
        "#split_surname: function that helps creating the surname column\n",
        "def split_surname(x):\n",
        "    return (x.split(\",\")[0])\n",
        "#Creating surname column using the function.\n",
        "full[\"Surname\"] = full[\"Name\"].apply(split_surname)\n",
        "#set the values to numeric\n",
        "full.set_value(full[\"Title\"] == \"Mr\", \"Title\", 0)\n",
        "full.set_value(full[\"Title\"] == \"Mrs\", \"Title\", 1)\n",
        "full.set_value(full[\"Title\"] == \"Miss\", \"Title\", 2)\n",
        "full.set_value(full[\"Title\"] == \"Master\", \"Title\", 3)\n",
        "full.set_value(full[\"Title\"] == \"Rare Title\", \"Title\", 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1120f73a-2cb3-f4b2-ee68-91f024aef725"
      },
      "outputs": [],
      "source": [
        "#Data -- Parch & SibSp\n",
        "print(\"The percentage of NaN Values in Parch column is: %s %%\" % (((pd.isnull(full[\"Parch\"]).sum()) * 100)/1309))\n",
        "print(\"The percentage of NaN Values in SibSp column is: %s %%\" % (((pd.isnull(full[\"SibSp\"]).sum()) * 100)/1309))\n",
        "#Family column: adding the Parch and SipSp column to a more simpler column.\n",
        "full[\"Family\"] = full[\"SibSp\"] + full[\"Parch\"] + 1\n",
        "#Graph to compare the rate of survival\n",
        "plt.figure(figsize=(8,6))\n",
        "avg_fm = full.groupby(full[\"Family\"]).mean()[\"Survived\"]\n",
        "sns.barplot(x=avg_fm.index, y=avg_fm.values)\n",
        "#It seems that a family of 4 boasts the highest survival rate.\n",
        "#To deal with the more fewer larger families, we will create a simplified,\n",
        "#discretized family size variable.\n",
        "#assign_size: function that divides the family into 3 groups\n",
        "def assign_size(x):\n",
        "    if x == 1:\n",
        "        return 'singleton'\n",
        "    elif (x < 5) & (x > 1):\n",
        "        return 'small'\n",
        "    elif (x > 4):\n",
        "        return 'large'\n",
        "#Re-create family column using the assign_size        \n",
        "full[\"Family\"] = full[\"Family\"].apply(assign_size)\n",
        "mosaic(full, ['Family', 'Survived'])\n",
        "#set the values to numeric\n",
        "full.set_value(full[\"Family\"] == \"singleton\", \"Family\", 0)\n",
        "full.set_value(full[\"Family\"] == \"small\", \"Family\", 1)\n",
        "full.set_value(full[\"Family\"] == \"large\", \"Family\", 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e0edda04-23d2-2e69-2e5a-e01368e1fa09"
      },
      "outputs": [],
      "source": [
        "#Machine Learning\n",
        "#Define Training/Test sets.\n",
        "train = full[:891]\n",
        "test = full[891:1310]\n",
        "#Define the predictor variables\n",
        "predictors = [\"Age\", \"Embarked\", \"Fare\", \"Pclass\", \"Sex\", \"Title\", \"Family\"]\n",
        "x_train = train[predictors]\n",
        "y_train = train[\"Survived\"]\n",
        "x_test= test[predictors]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8222545c-6d87-8ee5-baba-f4a7dfce1b38"
      },
      "outputs": [],
      "source": [
        "#Logistic Regression -- cross validation w/ cv=3\n",
        "alg = LogisticRegression(random_state = 1)\n",
        "scores = cross_validation.cross_val_score(alg, x_train, y_train, cv=3)\n",
        "print(scores.mean())\n",
        "#Random Forest -- cross validation w/ cv=3\n",
        "alg_2 = RandomForestClassifier(random_state = 1, n_estimators = 150, min_samples_split = 4, min_samples_leaf = 2)\n",
        "scores_2 = cross_validation.cross_val_score(alg_2, train[predictors], train[\"Survived\"], cv=3)\n",
        "print(scores_2.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ac152cf7-38e6-7569-26eb-2795d4f0f512"
      },
      "outputs": [],
      "source": [
        "#The Random Forest tends to have a higher percentage than the Logistic model\n",
        "alg_2.fit(x_train, y_train)\n",
        "predictions = alg_2.predict(x_test)\n",
        "submission = pd.DataFrame({'PassengerId': test.index, 'Survived': predictions})\n",
        "submission.to_csv('titanic_submission.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}