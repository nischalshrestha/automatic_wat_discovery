{"cells":[{"metadata":{"_uuid":"aec7846aa6aac77cf606b2f6973304e574f930d1"},"cell_type":"markdown","source":"# Introduction\n\nAs many others before me, this is my first \"dive\" into a kaggle project. With its popularity and relative ease of manipulation, I felt the \"Titanic: ML from Disaster\" was a great place to start. Join me on this voyage through cleaning, visualizing, and modeling the Titanic survivals and please feel free to leave comments below. All criticisms are well received.\n\nBon Voyage!"},{"metadata":{"trusted":false,"_uuid":"4bf353c00574116e8ecd1a5568ae1dec72f01765"},"cell_type":"code","source":"#Imports\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns \n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"426e9c98ee3ffb6ad38d14f8f30fb8c823ec70de"},"cell_type":"code","source":"#Read in the data\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\nfull = pd.concat([train,test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"13b7d9056ee08555615a585636debb4e993bc7bf"},"cell_type":"code","source":"#Check head\nfull.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1ef5349c763d5f95411577decdd0582b6cdd0f75"},"cell_type":"code","source":"#Check info\nfull.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"228e50a408873ed4ab716588ee8bc6d4ed82d6ae"},"cell_type":"markdown","source":"It's worth taking note of the number of missing values:\n- Age: 263\n- Cabin: 1014!!!\n- Embarked: 2\n- Fare: 1\n- Survived: 418 (But this corresponds to our test set, so no worries here)"},{"metadata":{"_uuid":"993bc4681eb6b52c10d8310ae8ab124bcc204bad"},"cell_type":"markdown","source":"# Data Cleaning\n\nNow that we have a sense of our data, I'm going to go through column by column, thinking about each variable and organizing it into a form we can use for analysis."},{"metadata":{"_uuid":"7584038fb20e8294c5c523a598e56483356542b1"},"cell_type":"markdown","source":"### 1.Age: Age of Passenger\n    - We'll have to deal with some missing values, but I'm going to back to this last."},{"metadata":{"_uuid":"b629d388dcf21b40a98ecd89eeb2bed064de8faa"},"cell_type":"markdown","source":"### 2.Cabin: Cabin the passenger stayed in.\n    - Nearly 80% missing, so I'm just going to drop it."},{"metadata":{"trusted":false,"_uuid":"43165c04248da4e4f75ce4cc6922383ed998d294"},"cell_type":"code","source":"#Drop 'Cabin'\nfull.drop('Cabin',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5581a79a197f342ea80dbe1e49d384b8228807d9"},"cell_type":"markdown","source":"### 3.Embarked: Indicates port that the passenger embarked from.\n    - Fill in the na values with whichever port was most prevalent.\n    - Convert into a dummy variable."},{"metadata":{"trusted":false,"_uuid":"15c3f3a60fec9b08ac8b9da1db752bbcb4b7f4de"},"cell_type":"code","source":"#Check which port most of the passengers came from\nfull['Embarked'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5ee7217addab54b0d6c60ae229dff41a54156b3c"},"cell_type":"code","source":"#Fill na values with 'S'\nfull['Embarked'].fillna('S',inplace = True)\n\n#Convert 'Embarked' into dummy variables and drop 'Embarked'\nfull = pd.concat([full,pd.get_dummies(full['Embarked'],drop_first=True,prefix='Port')],axis=1)\nfull.drop('Embarked',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10ba058d52896a3a9a7abdd5a5cc29fa8429c6d9"},"cell_type":"markdown","source":"### 4.Fare: Price of the ticket the passenger paid for.\n    - Fill missing Fare value in with average Fare."},{"metadata":{"trusted":false,"_uuid":"90a22d680de41ef35f3a4122407e9a17c53085ca"},"cell_type":"code","source":"#Fill na values with average Fare\nfull.loc[full['Fare'].isnull(),'Fare'] = full['Fare'].mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9e041f6c5881153e97ab4fbbd3f8b659e5db65b"},"cell_type":"markdown","source":"### 5.Name: Passenger name.\n    - Title may signify importance.\n    - Reduce Name to title."},{"metadata":{"trusted":false,"_uuid":"d9ac95d45d9a0bd9872c18e3ec59241af2f676a1"},"cell_type":"code","source":"#Split names into a list\nfull_title = full['Name'].apply(lambda x: x.split()[1])\n\n#Function: Takes in a title and returns the title if it's among those specified; Else returns 'No Title'\ndef impute_title(title):\n    if title not in ['Mr.','Miss.','Mrs.','Master.']:\n        return 'No title'\n    else:\n        return title\n\n#Assign titles, convert into dummy variables, and drop 'Name'\nfull_title = full_title.apply(impute_title)\nfull = pd.concat([full,pd.get_dummies(full_title,drop_first=True)],axis=1)\nfull.drop('Name',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80c1e1235ec13e6c6c00b929d81155d3a4c216ab"},"cell_type":"markdown","source":"### 6.Parch: # of parents or children a passenger had. "},{"metadata":{"_uuid":"b002713d52fdbe6b576215e395a6e73ee515f6ca"},"cell_type":"markdown","source":"### 7.PassengerId: Passenger Index. \n    - Not a predictor.\n    - Store Test IDs before dropping."},{"metadata":{"trusted":false,"_uuid":"da7a2f48236d69aada68b93aded2b68a1556b462"},"cell_type":"code","source":"#Store test ids for later use and drop 'PassengerId'\ntest_id = test['PassengerId']\nfull.drop('PassengerId',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25af10e222667f3c3be4d63025f6ab65a8679ced"},"cell_type":"markdown","source":"### 8.Pclass: Numeric representation of class. \n    - Effectively a categorical variable, so let's represent it as such.\n"},{"metadata":{"trusted":false,"_uuid":"5bb2a411a1477f87f77b9f256891aefb9de82161"},"cell_type":"code","source":"#Convert 'Pclass' into dummy variables and drop 'Pclass'\nfull = pd.concat([full,pd.get_dummies(full['Pclass'],drop_first=True,prefix='Pclass')],axis=1)\nfull.drop('Pclass',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c44728450be6ba78e69ab05c38687aee4f905fec"},"cell_type":"markdown","source":"### 9.Sex: Passenger sex. \n    - Assign a binary variable."},{"metadata":{"trusted":false,"_uuid":"f2fca231298b52af97de58c6b1f73175035595b3"},"cell_type":"code","source":"#Convert 'Sex' into dummy variable and drop 'Sex'\nfull = pd.concat([full,pd.get_dummies(full['Sex'],drop_first=True)],axis=1)\nfull.drop('Sex',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d6a8c012d4da0e43a885ee763c9192fe6cd51cc"},"cell_type":"markdown","source":"### 10.SibSp: # of siblings or spouses a passenger had."},{"metadata":{"_uuid":"095d13c7f141b7b5713d04c56516481ddb3617b3"},"cell_type":"markdown","source":"### 11.Survived: Whether or not the passenger survived. \n    - This is our target."},{"metadata":{"_uuid":"e2064ce56fa941c8e7830e21cba10e6df1778ff0"},"cell_type":"markdown","source":"### 12.Ticket: Ticket number of passenger.\n    - Has potential for feature engineering, but I'm going to ignore for this analysis."},{"metadata":{"trusted":false,"_uuid":"99c0dff44e3cb9985c7975ae5a0ec75ec2dddd8f"},"cell_type":"code","source":"#Drop 'Ticket'\nfull.drop('Ticket',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f59b40835cafdb4674f0b833c2ebfbdf11747847"},"cell_type":"code","source":"#Take a look at the data frame now\nfull.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e20a49c363503a8054bd935dcf4e5dc09a76f7d"},"cell_type":"markdown","source":"# Returning to Age.\n\nWe're going to fill in Age based on a linear regression performed on the rest of the variables. It would likely be fine for the analysis to fill in with simply average age or even average age of Pclass or Sex, but we have the tools to make a more detailed prediction, so might as well!"},{"metadata":{"trusted":false,"_uuid":"380710662231ec400fa2a8677f57b086bcc0672d"},"cell_type":"code","source":"#Import Linear Regression Model\nfrom sklearn.linear_model import LinearRegression\n\n#Fit model on data that does have an Age entry\nimpute_age = LinearRegression()\nimpute_age.fit(full[full['Age'].isnull()==False].drop(['Survived','Age'],axis=1),\n               full[full['Age'].isnull()==False].drop('Survived',axis=1)['Age'])\n\n#Impute ages for those that were missing\nages = impute_age.predict(full[full['Age'].isnull()].drop(['Survived','Age'],axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"56ba8586edb6978b89be740279c9bff8ccd839d7"},"cell_type":"code","source":"#Compare Age Distributions with and without imputed ages\nplt.figure(figsize=(13.5,6))\nplt.subplot(1,2,1)\nplt.hist(full[full['Age'].isnull()==False].drop('Survived',axis=1)['Age'],\n         bins=range(0,80,5),edgecolor='white')\nplt.title('Without Age Imputations')\nplt.xlabel('Age')\n\nplt.subplot(1,2,2)\nplt.hist(list(full[full['Age'].isnull()==False].drop('Survived',axis=1)['Age']) + list(ages),\n         bins=range(0,80,5),edgecolor='white',alpha=.5)\nplt.title('With Age Imputations')\nplt.xlabel('Age')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fcefeb3fe87e7b3a23ea890824a11b084399bba0"},"cell_type":"markdown","source":"Visually, the distribution appears unchanged. We've added roughly 100 passeners in their late 20s, which appears to be the most significant change. This looks to be about where the average age of the distribution without age imputations lies, though, so I'm actually pleased with this result. I feel confident that these results won't skew the outcome, so we can proceed with filling in the missing age values with the imputed ones."},{"metadata":{"trusted":false,"_uuid":"c36c312b17962f993ed98ecaf5dd4cf81a911e9d"},"cell_type":"code","source":"#Fill dataframe in with imputed ages\nfull.loc[full['Age'].isnull(),'Age'] = ages","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c9e8280368614f5203293b2e9b87cbc345b0048b"},"cell_type":"markdown","source":"# Visualizations\nWith our data cleaned up and in a workable format, it's time to take a look at it!"},{"metadata":{"_uuid":"c6dbef5ae53a41e7a20b3c72b76068032ca444c8"},"cell_type":"markdown","source":"### Any strong correlations?"},{"metadata":{"trusted":false,"_uuid":"e3ab11cfb1bc07d914a3ead773e694235607799a"},"cell_type":"code","source":"#Produce heatmap of correlations\nplt.figure(figsize=(16,8))\nsns.heatmap(full.corr(),annot=True,cmap='viridis')\nplt.tight_layout","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8744e5a7400249dc2eedad3530e861b938827f4a"},"cell_type":"markdown","source":"Wow! Who would've thought 'Mr.' and 'male' would be so strongly correlated?? Jokes aside, there is some useful insight to be had here. First and foremost, I'm curious what's most strongly correlated with 'Survived'. It appears the largest contributors are 'male' (or 'Mr.'...) and 'Pclass_3'. 'Miss.' and 'Mrs.' are prevalent as well, but it's fair to assume that the sex is really what's contributing to this relationship as opposed to the title. Another couple standouts are the relationships between 'Pclass_3' and 'Age' and 'Fare'. It's easy to see how the 3rd class is going to be cheaper, but it's also interesting that they tend to be younger as well. For passengers buying their own tickets, this makes sense, but let's think about those who aren't, the children. If class 3 tended to be younger, it means that they either had more children or the higher classes had fewer. The question worth asking then is whether or not family size impacted survival rates."},{"metadata":{"_uuid":"6b77871f39140e3d8cd833aee0f8a9b82c88fd7a"},"cell_type":"markdown","source":"### Family Size Exploration"},{"metadata":{"trusted":false,"_uuid":"b1b3a732833d61433345796aacbf169e303c9547"},"cell_type":"code","source":"#Illustrate relationship between family size and survival rate\nplt.figure(figsize=(13.5,6))\nsns.countplot((full['SibSp'] + full['Parch'] + 1),hue=full['Survived'],palette='viridis')\nplt.xlabel('Family Size')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97db3935d6620a638a25603b3da8779cf215dd7c"},"cell_type":"markdown","source":"If you were alone, you had a much greater chance of dying. If you were in a large family (greater than 4 members), you had a greater chance of dying. But if you were in a small family (2-4 members), you actually had a better chance of surviving. Let's go ahead then and create features for this in our dataframe."},{"metadata":{"trusted":false,"_uuid":"9c622394c4470d3bc72ddb13472cd4fa39761101"},"cell_type":"code","source":"#Create new column for family size\nfull['Family'] = (full['SibSp'] + full['Parch'] + 1)\n\n#Function: Takes in family size and returns corresponding description\ndef impute_alone(x):\n    if x == 1:\n        return 'Alone'\n    elif x > 4:\n        return 'Large Family'\n    else:\n        return 'Small Family'\n\n#Label each passenger's family size\nfull['Family'] = full['Family'].apply(impute_alone)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9366a06f68bf68dce3596e3527be79cc03dea3cc"},"cell_type":"code","source":"#Again, illustrate relationship between family size and survival rate\nplt.figure(figsize=(13.5,6))\nsns.countplot(full['Family'],hue=full['Survived'],palette='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"88804811a3e86e1ee3fbdea58223f64126f1ee1d"},"cell_type":"code","source":"#Convert into dummy variable and drop 'SibSp', 'Parch', and 'Family'\nfull = pd.concat([full,pd.get_dummies(full['Family'],drop_first=True)],axis=1)\nfull.drop(['SibSp','Parch','Family'],inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e025affbc277f8badc518ce44b86281e032a27b3"},"cell_type":"markdown","source":"### One last look at the data"},{"metadata":{"trusted":false,"_uuid":"c37b615618d68dd08ace54165d4d21ece9bd9108"},"cell_type":"code","source":"#Take a look\nfull.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d28d44c8872cbb96dbf547badd959d551936320"},"cell_type":"markdown","source":"# Model Fitting"},{"metadata":{"trusted":false,"_uuid":"735a92c9831fcbc530f57cac8031ce89adb095f8"},"cell_type":"code","source":"#Standardize Age and Fare\nfull['Age'] = (full['Age'] - full['Age'].mean()) / full['Age'].std()\nfull['Fare'] = (full['Fare'] - full['Fare'].mean()) / full['Fare'].std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e0f5fb44b611b739d9777b22eefda468ea59b905"},"cell_type":"code","source":"#Split the data back into train and test sets\ntrain = full.iloc[0:len(train)]\ntest = full.iloc[len(train):len(full)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"dabde9a0104e594ddf5f71c964d2773af56f0f36"},"cell_type":"code","source":"#Scikit imports\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e6ac7c393a134a0a048f35a49b770330ae09930f"},"cell_type":"code","source":"#Split the data 'train' data into train and test sets\nX = train.drop('Survived',axis=1)\ny = train['Survived']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef39ecde5efb6e4588a171b50f1204598d9ced60"},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":false,"_uuid":"17d6ee0270d7ea237a67149f0003e8a3b6d64a0e"},"cell_type":"code","source":"#Fit and predict with Logistic Regression model\nlr = LogisticRegression()\nlr.fit(X_train,y_train)\npred_lr = lr.predict(X_test)\nprint(confusion_matrix(y_test,pred_lr))\nprint('\\n')\nprint(classification_report(y_test,pred_lr))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"457aa728aef63bcf59dc6a85360847300c20fffc"},"cell_type":"markdown","source":"### K Nearest Neighbors w/ optimization"},{"metadata":{"trusted":false,"_uuid":"9847f73a524a7396bc34c7e591d37504615394eb"},"cell_type":"code","source":"#Create empty array to hold errors\nerror_rate = []\n\n#Iterate through different K values, fit, predict, and store error rates\nfor i in range(1,100,2):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))\n\n#Plot error rates with respect to K value\nplt.figure(figsize=(10,6))\nplt.plot(range(1,100,2),error_rate,color='blue',ls='dashed',marker='o',\n        markerfacecolor='red',markersize=10)\nplt.title('Error Rate vs K Value')\nplt.xlabel('K')\nplt.ylabel('Error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"22e751165e51f23bb984d1e17e2889468fc33dc5"},"cell_type":"code","source":"#Min at k = 3\n#Re-run model with new k value\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train,y_train)\npred_knn = knn.predict(X_test)\nprint(confusion_matrix(y_test,pred_knn))\nprint('\\n')\nprint(classification_report(y_test,pred_knn))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86f4df0dc53dc9e77c4f7140f18740a5c4da8e17"},"cell_type":"markdown","source":"### Support Vector Classification w/ optimization"},{"metadata":{"trusted":false,"_uuid":"d714dac0b10a8762fb91492881b92a6befde2fe7"},"cell_type":"code","source":"#Iterate through various parameter values of SVC and apply optimal model\nparam_grid = {'C':[0.1,1,10,100,1000],'gamma':[1,0.1,.01,.001,.0001]}\ngrid = GridSearchCV(SVC(),param_grid,verbose=1)\ngrid.fit(X_train,y_train)\npred_grid = grid.predict(X_test)\nprint(grid.best_params_)\nprint('\\n')\nprint(confusion_matrix(y_test,pred_grid))\nprint('\\n')\nprint(classification_report(y_test,pred_grid))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c138ffa39c771900c0bc37eb1b22c517d4df37a5"},"cell_type":"markdown","source":"### Decision Tree"},{"metadata":{"trusted":false,"_uuid":"a819e94c658d6f77e7a6ed44683b3af06987b584"},"cell_type":"code","source":"#Fit and predict with Decision Tree\ndtree = DecisionTreeClassifier()\ndtree.fit(X_train,y_train)\npred_dtree = dtree.predict(X_test)\nprint(confusion_matrix(y_test,pred_dtree))\nprint('\\n')\nprint(classification_report(y_test,pred_dtree))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a7021d8386ceb7d150e63c4cff8c56d72bb9d10"},"cell_type":"markdown","source":"### Random Forest"},{"metadata":{"trusted":false,"_uuid":"b056aff442ac9f98248d1599eecbbb4f2bba79d9"},"cell_type":"code","source":"#Fit and predict with Random Forest\nrfc = RandomForestClassifier(n_estimators=200)\nrfc.fit(X_train,y_train)\npred_rfc = rfc.predict(X_test)\nprint(confusion_matrix(y_test,pred_rfc))\nprint('\\n')\nprint(classification_report(y_test,pred_rfc))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e0f7feee70f8e1363e2de3e76f360401ae5f7710"},"cell_type":"markdown","source":"# Conclusions & Extensions\nIt was a very narrow margin, but the Support Vector model with parameter optimization produced the highest accuracy. Often times it can be imperative to consider the precision and recall of the predictions, but for this project our primary concern was simply accuracy. Therefore, I'm going to retrain the model on the entirety of data at our disposal, then use it to make predictions on our test set! Before I do so, though, I want to take the time to list some potential extensions of the analysis:\n    - Feature engineer 'Cabin' and 'Ticket': Perhaps information on passenger's location on the boat can be found.\n    - Dive deeper into the family dynamics, looking at whether Mothers and Daughters perhaps had higher survival rates.\n    - There are always more models to try!\n        - Does giving greater weight to the passengers that were incorrectly classified improve the predictions?"},{"metadata":{"trusted":false,"_uuid":"e6a1d52f0b4fddaef541bc8ad082f23f58f114a9"},"cell_type":"code","source":"#Fit optimal SVC model on the entirety of the training set and predict on test set\ngrid.fit(train.drop('Survived',axis=1),train['Survived'])\npred_final = grid.predict(test.drop('Survived',axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c231bb3822df4b7ebf63c786d356a33253b72daa"},"cell_type":"code","source":"#Create Submission\nsubmission = pd.DataFrame(\n    {'PassengerId' : test_id,\n     'Survived' : pred_final}\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"742c25d25768038fccc7e3178f7eb08735ad1303"},"cell_type":"code","source":"#Make sure everything looks good\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"553089949fde5c2260c97366acd92bfbb3b63a66"},"cell_type":"code","source":"#Store it\nsubmission.to_csv('Submission',index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6e9c1dd378094851b62dfe5aa69bb77934b84e6"},"cell_type":"markdown","source":"# Thank you!\nLand, ho! (hopefully...). Thanks for making it with me this far. Again, please feel free to leave comments. I'm continually trying to improve my coding skill, analysis, and presentation, so all advice or criticism is welcomed and well received. Cheers!"},{"metadata":{"trusted":false,"_uuid":"161acf7533332d09cde0db33b8a5ff6d2a6b57c9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}