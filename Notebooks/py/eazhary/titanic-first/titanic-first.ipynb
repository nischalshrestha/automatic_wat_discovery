{"metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py", "name": "python", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.1"}}, "nbformat_minor": 0, "nbformat": 4, "cells": [{"metadata": {"_cell_guid": "d2fe489c-b7e0-48fd-9a8b-446b54388cc8", "_execution_state": "idle", "_uuid": "620241c5ab51ac18a8f9517257476616ace4bfe5", "trusted": false}, "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv\n\nfrom matplotlib import pyplot as plt\nimport matplotlib\n\nmatplotlib.style.use('ggplot')\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": false, "_cell_guid": "bdc0ba7f-5460-49f7-bed2-769766ebabc4", "_execution_state": "idle", "_uuid": "26351d8d9731378f60e180b136f52f1f9ad1d051", "trusted": false}, "source": "dd = pd.DataFrame({'A':[1,1,1,1,2,2,2,2,1,1,2,2], 'C': ['F','F','M','M','F','F','M','M','F','M','F','M'], 'B':[10,10,8,8,2,2,1,1,np.nan,np.nan,np.nan,np.nan]})\nprint(dd)\nm = dd.groupby(['A','C'],as_index=False).median().sort_values(by='A', ascending=True)\nprint(m)\ndd['B'].fillna(dd.groupby(['C','A'])['B'].transform('median'),inplace=True )\ndd['Boy']=np.where((dd['B']>5) & (dd['B']<10),1,0)\nprint(dd)", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": false, "_cell_guid": "02660900-cb4f-47ff-8860-64c8ec9a4f04", "_execution_state": "idle", "_uuid": "c6947850f5fc271cef40058aab4c6015e8704e52", "trusted": false}, "source": "train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv('../input/test.csv')\n\nprint(train.shape)\nprint(test.shape)\nprint(list(train))", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": false, "_cell_guid": "407d61cf-41ac-4b8f-9314-78a36456876e", "_execution_state": "idle", "_uuid": "0ee55ed45f88796af16420cbead59e52ae924fe9", "trusted": false}, "source": "combined = train.copy()\ncombined = combined.append(test)\nprint(train.shape)\nprint(test.shape)\nprint(combined.shape)\nprint(test.iloc[0])\nprint(combined.iloc[891])", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": false, "_cell_guid": "84ed4dce-39c5-4fb1-9803-2e4f60d091f8", "_execution_state": "idle", "_uuid": "12851faa2517e9ec5ff72eb8f39b34362be2979f", "trusted": false}, "source": "import re as re\ndef get_title(name):\n\ttitle_search = re.search(' ([A-Za-z]+)\\.', name)\n\t# If the title exists, extract and return it.\n\tif title_search:\n\t\treturn title_search.group(1)\n\treturn \"\"\n\n\n#train['Title'] = train['Name'].apply(get_title)\n#test['Title'] = test['Name'].apply(get_title)\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2, \"Dona\":10}\n    \nfull_data =[train,test]\nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)\n#    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n# \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n#    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n#    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n#    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    #dataset['Title']=dataset['Title'].astype(int)\n#print(train.head(5))\n#print(test.head(5))\n#print(pd.value_counts(test['Title']))\nprint(test[['Name','Title']].iloc[414])", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": false, "_cell_guid": "aca33b88-55ca-46e8-8936-5a3e305dd315", "_execution_state": "idle", "_uuid": "12a35ba83a991b35ef43a18739b6154e710c83c8", "trusted": false}, "source": "train['Age'].fillna(train.groupby(['Sex','Pclass','Title'])['Age'].transform('median'),inplace=True )\ntest['Age'].fillna(train.groupby(['Sex','Pclass','Title'])['Age'].transform('median'),inplace=True )\n#test['Age'].fillna(train['Age'].median(), inplace = True)\ntrain['Fare'].fillna(train.groupby(['Pclass'])['Fare'].transform('median'), inplace = True)\ntest['Fare'].fillna(train.groupby(['Pclass'])['Fare'].transform('median'), inplace = True)\n#print(train['Embarked'].describe())\n\n#print(train.Embarked.dropna().mode()[0])\nfreqEmbark = train.Embarked.dropna().value_counts().index[0]\nprint(freqEmbark)\ntrain['Embarked'].fillna(freqEmbark,inplace=True)\ntest['Embarked'].fillna(freqEmbark,inplace=True)\n#print(test.Fare)\n#print(train.isnull().sum())\n#print(test.isnull().sum())\n", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": false, "_cell_guid": "6efdadda-4816-44a0-8792-16068fc69abe", "_execution_state": "idle", "_uuid": "b417e9f1f5495e60e3d4138061dc6f23fe66fe83", "trusted": false}, "source": "#engineer Age Bands\ntrain['AgeBand']=pd.cut(train['Age'],5, labels=[0,1,2,3,4]).astype(int)\ntest['AgeBand']=pd.cut(test['Age'],5, labels=[0,1,2,3,4]).astype(int)\ntrain['Fare'] = pd.qcut(train['Fare'],4,labels=[0,1,2,3]).astype(int)\ntest['Fare'] = pd.qcut(test['Fare'],4,labels=[0,1,2,3]).astype(int)\n#print(test.Fare)\nprint(train[['Fare', 'Survived']].groupby(['Fare'], as_index=False).mean().sort_values(by='Fare', ascending=True))\n", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": false, "_cell_guid": "6ecc9d8d-0d68-427a-845c-357f9d3da9ea", "_execution_state": "idle", "_uuid": "e2af831a82b5134ebb3c93b67230e2af67df8758", "trusted": false}, "source": "train['Sex'].replace({'male':1 ,'female':0},inplace=True)\ntest['Sex'].replace({'male':1 ,'female':0},inplace=True)\ntrain['Embarked'].replace({'S':0,'C':1,'Q':2}, inplace = True)\ntest['Embarked'].replace({'S':0,'C':1,'Q':2}, inplace = True)", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": false, "_cell_guid": "12725334-689b-4e6a-9c97-cedf40165ced", "_execution_state": "idle", "_uuid": "9ec4c491515f2764aa8068f9187d24053c8cc122", "trusted": false}, "source": "train['isAlone'] = np.where( (train['SibSp']+train['Parch'])==0,0,1)\ntest['isAlone'] = np.where( (test['SibSp']+test['Parch'])==0,0,1)\ntrain['FamilySize']=train['Parch']+train['SibSp']+1\ntest['FamilySize']=test['Parch']+test['SibSp']+1\ntrain['LargeFamily']=np.where(train['FamilySize']>5,1,0)\ntest['LargeFamily']=np.where(test['FamilySize']>5,1,0)\ntrain['SmallFamily']=np.where((train['FamilySize']>=2) & (train['FamilySize']<=4),1,0)\ntest['SmallFamily']=np.where((test['FamilySize']>=2) & (test['FamilySize']<=4),1,0)\n\n\ntrain.Age=train.Age.astype(int)\ntest.Age = test.Age.astype(int)\n\n#print(test[['Family','SibSp','Parch']].head(10))\n#train.drop(['Age','SibSp','Parch','Ticket'], inplace=True, axis=1)\n#test.drop(['Age','SibSp','Parch','Ticket'], inplace=True, axis=1)\n#train.Fare = train.Fare.astype(int)\n#test.Fare = test.Fare.astype(int)\nprint(train.dtypes)\nprint(test.dtypes)\n", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": false, "_cell_guid": "50f8fce8-9414-461d-9004-835b4a1cc649", "_execution_state": "idle", "_uuid": "f0e5cecbb24152045d0de6918301069aaff4298d", "trusted": false}, "source": "    \n#test = pd.get_dummies(test,columns=['Title','Pclass','Embarked'])    \n#train = pd.get_dummies(train,columns=['Title','Pclass','Embarked'])    \n#print (train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())\nprint(train.head(10))\nprint(test.head(10))\n#print(pd.crosstab(train['Title'], train['Sex']))", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": false, "_cell_guid": "dfef7446-2f97-49fc-8cdd-fbf59acc2790", "_execution_state": "idle", "_uuid": "eec379892b516ad4784281551cc5b12e28a95b54", "trusted": false}, "source": "from sklearn.model_selection import train_test_split\n\nX = train.drop(['Survived','PassengerId','Name','Ticket','Age','SibSp','Parch','Cabin'], axis=1)\nT = test.drop(['PassengerId','Name','Ticket','Age','SibSp','Parch','Cabin'], axis=1) ##'Age','SibSp','Parch',\nY = train['Survived'].values.ravel()\nprint(X.shape)\nprint(X)\n\nprint(T.isnull().sum())\n#print(Y)\n#print(T)\n\nX_tr,X_val,Y_tr,Y_val =  train_test_split(X,Y,test_size=0.2, stratify =Y, random_state=123)", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": false, "_cell_guid": "0f68ae53-da5a-4528-b61b-245de5d2dd4a", "_execution_state": "idle", "_uuid": "883cc5a2daccb1d2518686694454f25497cffb9d", "trusted": false}, "source": "#feature selection\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectFromModel\n\nclf = RandomForestClassifier(n_estimators=50, max_features='sqrt')\nclf.fit(X,Y)\n\nfeatures = pd.DataFrame()\nfeatures['importance']= clf.feature_importances_\nfeatures['features']= X.columns\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('features', inplace=True)\nfeatures.plot(kind='barh')", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": false, "_cell_guid": "07d63b66-ae9c-4394-bfc6-53878dbf860f", "_execution_state": "idle", "_uuid": "5ec8ff382795c75dad1af273ff355145534fd573", "trusted": false}, "source": "#model = SelectFromModel(clf, prefit=True)\n#X_s = model.transform(X)\n#print(X_s.shape)\n#T_s = model.transform(T)", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": false, "_cell_guid": "102d96db-5948-47bb-8ac1-3d98ae914ebe", "_execution_state": "idle", "_uuid": "d916c92e3cc145ce43bf45fb46e8592613399d41", "trusted": false}, "source": "import xgboost as xg\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.cross_validation import StratifiedKFold\nfrom sklearn.metrics import auc\nfrom sklearn.neighbors import KNeighborsClassifier\ngbm = xg.XGBClassifier(n_estimators=300, max_depth=2, learning_rate=0.1, min_child_weight=7)\n#gbm = xg.XGBClassifier()\n\ngbm_params = {\n    'learning_rate': [0.05, 0.1],\n    'n_estimators': [300, 1000],\n    'max_depth': [2, 3, 10],\n    'min_child_weight': [1,3,5,7]\n}\n\nlr_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n# construct the set of hyperparameters to tune\nknn_grid = {\"n_neighbors\": np.arange(1, 31, 2),\n\t\"metric\": [\"euclidean\", \"cityblock\"]}\n\nclf1 = LogisticRegression(random_state=1, C=10)\nclf2 = RandomForestClassifier(random_state=1,n_estimators=50, bootstrap=False, min_samples_split=10, min_samples_leaf=3,max_depth=6 )\nclf3 = GaussianNB()\nclf4 = KNeighborsClassifier(n_neighbors = 5, metric=\"cityblock\")\n\neclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3),('knn', clf4) ,('xbboost', gbm)], voting='hard')\n\n\n#cv = StratifiedKFold(Y)\n#grid = GridSearchCV(clf4, knn_grid,cv=cv,verbose=10,n_jobs=-1)\n#grid.fit(X_s, Y)\n#print (grid.best_params_)\n\n\n\nfor clf, label in zip([clf1, clf2, clf3,clf4,gbm, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'KNN', 'XGBOOST','Ensemble']):\n    scores = cross_val_score(clf, X, Y, scoring='accuracy')\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n\ngbm.fit(X,Y)\neclf.fit(X,Y)\npredictions2=eclf.predict(T)\nprint(\"voting\")\nprint(predictions2)\nprint('xb')\npredictions= gbm.predict(T)\nprint(predictions)", "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": false, "_cell_guid": "b75c463d-6f8a-40f9-9079-f704b08783dc", "_execution_state": "idle", "_uuid": "5ed0a693d3dbed3dcfe6b7d2c638cfa413878bfa", "trusted": false}, "source": "submission1 = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": predictions2\n    })\n\nsubmission1.to_csv('votinggood.csv', index=False)\nsubmission2 = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": predictions\n    })\nsubmission2.to_csv('xgbgood.csv', index=False)", "execution_count": null, "cell_type": "code", "outputs": []}]}