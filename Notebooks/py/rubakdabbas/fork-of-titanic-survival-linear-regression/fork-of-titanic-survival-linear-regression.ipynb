{"cells": [{"outputs": [], "source": "import pandas\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scipy.stats\nimport statsmodels.api as sm\nfrom pandas.core import datetools", "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "604b2f6a7e7736eec3013ef276d51b8d07ee1cb7", "_cell_guid": "1c6db6b3-0ed1-4383-af87-da97fddfacec", "trusted": false, "collapsed": false}}, {"outputs": [], "source": "df = pandas.read_csv('titanic_train.csv')", "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "a036a37be22b96c8635abcc565e1ae7bbdf69ee2", "_cell_guid": "99330059-9c19-4a77-9b81-20721bc8ebf7", "trusted": false, "collapsed": false}}, {"outputs": [], "source": "# filling empty cells with men", "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "9f9372a305f35e1acddd07059d5b6b1b8793ac99", "_cell_guid": "b0ecd9e4-2776-43b0-9129-34f0e4e9bf5c", "trusted": false, "collapsed": true}}, {"outputs": [], "source": "def imputation(data):\n    df_age= data['Age']\n    mean_df = np.mean(df_age)\n    data['Age'] = data['Age'].fillna(mean_df)\n    return data", "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "aba62b016296a358f3a40f5199e8a42c2426efba", "_cell_guid": "8863d659-6d5b-49dd-ad28-5694d1e69840", "trusted": false, "collapsed": true}}, {"outputs": [], "source": "def features_normalize(features):\n    ''' Feature Normalization When features differ by orders of magnitude,\n    first performing feature scaling can make gradient descent converge \n    much more quickly'''\n    sd = np.std(features, axis=0)\n    mean = np.mean(features, axis=0)\n    x_norm = (features - mean)/sd\n    return x_norm", "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "b9da3c7bafc2400fc1fd873bd516efd47c184b94", "_cell_guid": "25b433a0-b355-4c14-904a-58d2af201f40", "trusted": false, "collapsed": true}}, {"outputs": [], "source": "def compute_cost(features, values, theta):\n    \"\"\"\n    Compute the cost of a list of parameters, theta, given a list of features \n    (input data points) and values (output data points).\n    \"\"\"\n    m = len(values)\n    sum_of_square_errors = np.square(np.dot(features, theta) - values).sum()\n    cost = sum_of_square_errors / (2*m)\n\n    return cost", "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "bf09f13b27091e3354f251d59b3cee5e5741c735", "_cell_guid": "c559bdd0-d549-4b7f-8624-709d2b69e246", "trusted": false, "collapsed": true}}, {"outputs": [], "source": "def gradient_descent(features, values, theta, alpha, num_iterations):\n    \"\"\"\n    Perform gradient descent given a data set with an arbitrary number of features.\n    \n    \"\"\"\n\n    m = len(values)\n    cost_history = []\n    for i in range(num_iterations):\n        prediction_values = np.dot(features, theta)\n        theta = theta - alpha/m * np.dot(np.transpose(features), (prediction_values-values))\n        cost = compute_cost(features, values, theta)\n        cost_history.append(cost)\n    return theta, pandas.Series(cost_history)", "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "65d04cde909c5efacca2f151a42c9b83c4e250de", "_cell_guid": "889cdc73-1bd4-4f85-ba6c-85bb236e8eda", "trusted": false, "collapsed": true}}, {"outputs": [], "source": "def compute_r_squared(data, predictions):\n    # Calculates the coefficient of determination, R^2, for the model that produced \n\n    mean = np.mean(data)\n    sum_of_square_errors = np.square(data - predictions).sum()\n    sum_of_square_data =  np.square(data - mean).sum()\n    r_squared = 1- sum_of_square_errors/sum_of_square_data\n    return r_squared", "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "8da1c28c4cc92d0b5ebc940aa41ba7f52735bc91", "_cell_guid": "bcd7550a-1f13-47aa-a2ec-8d20fcf527f0", "trusted": false, "collapsed": true}}, {"outputs": [], "source": "def prediction_grad_dic(dfa):\n    df = imputation(dfa)\n    \n    # Select Features (try different features!)\n    features = df[['Pclass', 'Age', 'SibSp', 'Parch']]\n    \n    \n    # Add date to features using dummy variables\n    dummy_units = pandas.get_dummies(df['Sex'], prefix='sex')\n    features = features.join(dummy_units)\n    #print dummy_units\n    # Values\n    values = df['Survived']\n    m = len(values)\n     \n    features = features_normalize(features)\n    add_col = features.insert(0, 'x0', 1)\n#    features['ones'] = np.ones(m) # Add a column of 1s (y intercept)\n    \n    # Convert features and values to numpy arrays\n    features_array = np.array(features)\n    values_array = np.array(values)\n\n    # Set values for alpha, number of iterations.\n    alpha = 0.05 # please feel free to change this value\n    num_iterations = 100 # please feel free to change this value\n    \n    # Initialize theta, perform gradient descent\n    theta_gradient_descent = np.zeros(len(features.columns))\n    theta_gradient_descent, cost_history = gradient_descent(features_array, \n                                                            values_array, \n                                                            theta_gradient_descent, \n                                                            alpha, \n                                                            num_iterations)\n \n    \n    predictions = np.dot(features_array, theta_gradient_descent)\n    r_squared = compute_r_squared(values_array, predictions)\n    data_pred = pandas.DataFrame(data = predictions)\n    feature_array = pandas.DataFrame(data = features_array)\n    y = data_pred.round(decimals=0)\n    x = y.astype(int)\n    return x, theta_gradient_descent, cost_history", "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "b87b968f8ba946d093023b1d9d23b60db6413942", "_cell_guid": "870f8eb6-4962-4ec9-a876-88a6ae02473c", "trusted": false, "collapsed": false}}, {"outputs": [], "source": "def plot_cost_history(df):\n    alpha = 0.05 # please feel free to change this value\n    x, theta_gradient_descent, cost_history = prediction_grad_dic(df)\n    cost_df = pandas.DataFrame({\n        'Cost_History': cost_history,\n        'Iteration': range(len(cost_history))})\n    plt.figure()\n    plt.plot(cost_df['Cost_History'], cost_df['Iteration'])\n   \n    plt.title('Cost_History vs. Iteration for alpha = %.3f' % alpha)\n    plt.xlabel('Iteration')\n    plt.ylabel('Cost_History')   \n    plt.show()", "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "1d4f58efa99968c51a2a64121a2f1dba0d725dab", "_cell_guid": "c72ff049-f1b4-4bc4-806f-2d9ad6bd84c9", "trusted": false, "collapsed": true}}, {"outputs": [], "source": "plot_cost_history(df)", "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "d5eab96a3e8a01fe09b1f268c06ab037c31aa572", "_cell_guid": "7a3428c4-9d07-403b-b445-af245a0ab0c2", "trusted": false, "collapsed": false}}, {"outputs": [], "source": "prediction_grad_dic(df)", "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "68a6cb7eb9aef9084f6092b7efe6d614a1c4cc74", "_cell_guid": "01e3eba8-f953-4dee-b6dd-66f427fb86d6", "trusted": false, "collapsed": false}}, {"outputs": [], "source": "def data_predict(dfa):\n    global df\n    data = imputation(dfa)\n    features = data[['Pclass', 'Age', 'SibSp', 'Parch']]\n    dummy_units = pandas.get_dummies(data['Sex'], prefix='sex')\n    features = features.join(dummy_units)\n    features = features_normalize(features)\n    add_col = features.insert(0, 'x0', 1)\n    features_array = np.array(features)\n    x, theta_gradient_descent, cost_history = prediction_grad_dic(df)\n    predictions = np.dot(features_array, theta_gradient_descent)\n    data_pred = pandas.DataFrame(data = predictions)\n    y = data_pred.round(decimals=0)\n    x = y.astype(int)\n    p = pandas.DataFrame(data['PassengerId'])\n    p.insert(1,'Survived',x)\n    return p                          ", "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "d0ff02233fce0d46a88774954cfcd9bcdfdb5377", "_cell_guid": "99376cb7-2072-497c-9cce-455eef491c24", "trusted": false, "collapsed": false}}, {"outputs": [], "source": "data = pandas.read_csv('titanic_test.csv')", "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "4b1685b700c4aa0af983ff5834f699e2a12f9d45", "_cell_guid": "e140d6a5-ac5d-41db-bae6-f0299408da10", "trusted": false, "collapsed": true}}, {"outputs": [], "source": "data_rev = data_predict(data)", "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "3fe9016caa0fe32c8ead0be5df1b7c0a6619fd37", "_cell_guid": "6fea44d6-a75c-4398-9173-43a5e3d47ff3", "trusted": false, "collapsed": false}}, {"outputs": [], "source": "data_rev.to_csv('predict_test_titanic.csv', index = False)", "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "860c80acbef733e9ccf5b9b922dbd42da39a0c5a", "_cell_guid": "c8dca586-c45d-4d91-ae96-527e2d0b5fce", "trusted": false, "collapsed": true}}, {"outputs": [], "source": "data_rev", "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "9ec32194f45bdc16c2374b5887f7e2327272d478", "_cell_guid": "addc1705-d38e-467e-8ac4-f85326a8f893", "trusted": false, "collapsed": false}}, {"outputs": [], "source": "", "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "c3d75508defb2525a8093c2cfee7413423f5eb7b", "_cell_guid": "9ae7adc0-2618-421a-9a54-c34b80570a8a", "trusted": false, "collapsed": true}}], "nbformat": 4, "nbformat_minor": 2, "metadata": {"language_info": {"file_extension": ".py", "version": "3.6.1", "codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "name": "python"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}}