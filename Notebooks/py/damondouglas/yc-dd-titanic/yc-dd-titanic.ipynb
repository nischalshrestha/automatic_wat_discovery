{"cells":[{"metadata":{"trusted":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"},"cell_type":"markdown","source":"## Introduction\n\nOn April 15, 2912 more than 1,500 souls perished on board the RMS Titanic[1].  This challenge uses machine learning to predict based on passenger data whether an individual would have survived this tragedy.  The titanic dataset comprises information on a passenger's age, boarding class, paid fare, point of embarkment, gender, cabin number, ticket details, and the number of accompanied family members."},{"metadata":{"_uuid":"23372f5357edb00ef9f0d74cb0011332c2fc7936"},"cell_type":"markdown","source":"# Imports, Data, Constants and Helpers"},{"metadata":{"collapsed":true,"trusted":false,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"},"cell_type":"markdown","source":"## Imports"},{"metadata":{"trusted":true,"_uuid":"55a8711ac4f7eca86f50b1c4fbad9eca59bc5954"},"cell_type":"code","source":"# Import libraries\nimport warnings; warnings.simplefilter('ignore')\nimport re\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport scipy\nimport scipy.stats as stats\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.mosaicplot import mosaic\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.decomposition import PCA\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.cluster import KMeans\nfrom sklearn import metrics\nfrom sklearn.datasets import load_wine\nfrom sklearn import svm\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"297cefed7e8f1ae7fe5bfca0c6c052dee2c929d1"},"cell_type":"markdown","source":"## Data"},{"metadata":{"trusted":true,"_uuid":"7bfe88bc2c48b54750e134f17d11bbae4eb6141b"},"cell_type":"code","source":"# courtesy Names Corpus Version 1.3 by Mark Kantrowitz (c) 1991 (http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/nlp/corpora/names/)\nnames = pd.read_csv(\"../input/names/names.csv\")\ntrain = pd.read_csv(\"../input/titanic/train.csv\")\ntest = pd.read_csv(\"../input/titanic/test.csv\")\ntrain.info()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bdcb37f04c69b588081f7ad13db39b55327574ee"},"cell_type":"markdown","source":"## Globals and Constants"},{"metadata":{"trusted":true,"_uuid":"596069967e611946ade81ba963c17636c3c60345"},"cell_type":"code","source":"\"\"\"\nGlobals\n=======\n\"\"\"\nMEDIAN_AGE = train.Age.median()\nMEDIAN_FARE = train.Fare.median()\nSVM_MODEL = None\nCATBOOST_MODEL = None\n\n\"\"\"\nColumns\n=========\n\"\"\"\n\n# To avoid hardcoding column names:\nclass columns:\n    pass\n\nc = columns()\nfor col in train.columns.values:\n    setattr(c, col, col)\n\nsetattr(c, \"Female\", \"Female\")\nsetattr(c, \"Title\", \"Title\")\nsetattr(c, \"HasSib\", \"HasSib\")\nsetattr(c, \"HasParch\", \"HasParch\")\nsetattr(c, \"HasFamily\", \"HasFamily\")\nsetattr(c, \"FareCluster\", \"FareCluster\")\nsetattr(c, \"AgeCluster\", \"AgeCluster\")\nsetattr(c, \"CabinLevel\", \"CabinLevel\")\nsetattr(c, \"Sarch\", \"Sarch\")\n\n# Additional Constants\nHAS_SIB_THRESHOLD = 0\nHAS_PARCH_THRESHOLD = 0\nNUM_FARE_CLUSTERS = 3\nNUM_AGE_CLUSTERS = 6\nMARRIED_TITLES = [\"Mr\", \"Mrs\"]\nTRUE_LOVE_AGE_CUTOFF = 18\nCOMMON = \"Common\"\nPRIVILAGED = \"Privilaged\"\nMILITARY = \"Military\"\nPUBLIC_SERVANT = \"PublicServant\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1788269fd5f43f4c6caa281b4dfa70ce2d4392f6"},"cell_type":"markdown","source":"## Helpers"},{"metadata":{"trusted":true,"_uuid":"a762aa2baa004613337f14f3db9118820fdaf264"},"cell_type":"code","source":"# Pipeline manager\nclass Pipeline:\n    _steps = {}\n    \n    def step(func):\n        df = pd.DataFrame()\n        df = func(df)\n        try:\n            df.info()\n        except:\n            raise \"function does not return pandas.DataFrame\"\n\n        Pipeline._steps[func.__name__] = func\n        return func\n\n\n    def process(df: pd.DataFrame) -> pd.DataFrame:\n        df_copy = df.copy()\n        for f in Pipeline._steps.values():\n            df_copy = f(df_copy)\n\n        return df_copy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37434f252e9239d2837a1fcaad19c8aee376fa0f"},"cell_type":"code","source":"# Drafts a contingency table between column1 and column2 with pvalues.\n# Assums column1 and column2 are categorical variables.\ndef contingency(df: pd.DataFrame, column1: str, column2: str) -> pd.DataFrame:\n    row = sorted(pd.unique(df[column1]))\n    col = sorted(pd.unique(df[column2]))\n    d = {}\n    columns = [(column2, k) for k in col]\n    index = [(column1, m) for m in row]\n    p = []\n    total = []\n\n    for k in col:\n        if k not in d:\n            d[k] = []\n        for m in row:\n            d[k].append(\n                len(\n                    df.query(\"{} == {} and {} == {}\".format(column2, k, column1, m))\n                )\n            )\n\n    for m in row:\n        slice = df.query(\"{} == {}\".format(column1, m))\n        (_, pval) = stats.chisquare(slice[column2].value_counts())\n        p.append(pval)\n\n        total.append(len(slice))\n\n    cs = pd.DataFrame(d)\n    cs.columns = pd.MultiIndex.from_tuples(columns)\n    cs.index = pd.MultiIndex.from_tuples(index)\n    cs[\"Total\"] = total\n    cs[\"Pvalue\"] = p\n    \n    return cs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"521db987066a70e78a70bf40804c2e6180e94f97"},"cell_type":"code","source":"# Plotting Helpers\ndef pretty_hist(df: pd.DataFrame, yaxis_title: str, column_name: str, title: str, labels: list):\n    values = df.groupby([column_name])[column_name].count().values\n    uniq_values = pd.unique(df[column_name].values)\n    ticks = np.arange(np.min(uniq_values) - 0.5, np.max(uniq_values)+1, step=1)\n    n = len(df)\n    percentages = [int(k*100/n) for k in values]\n    \n    if len(percentages) != len(labels):\n        print(len(percentages), len(labels))\n    assert len(percentages) == len(labels)\n        \n    for i in range(len(labels)):\n        labels[i] = labels[i] + \" ({}%)\".format(percentages[i])\n\n    labels.insert(0, \"\")\n    labels.append(\"\")\n    plt.hist(df[column_name], np.arange(len(uniq_values)*2), rwidth=0.3)\n    plt.title(title)\n    plt.xticks(ticks, labels)\n    plt.ylabel(yaxis_title)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f528026a83e16ba93f52bec9526ed32c4df70f7b"},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"trusted":true,"_uuid":"7bf6f5312c785bff952092c4460aa3383bea49bc"},"cell_type":"markdown","source":"# Univariate"},{"metadata":{"_uuid":"c8a910dfa2627a80ef1baa8ae406fc99b8cf905a"},"cell_type":"markdown","source":"## PassengerId\n`PassengerId` is unique to each record and does not provide any meaningful information for the model.  This variable will be dropped."},{"metadata":{"trusted":true,"_uuid":"4803e709726b043b35c94204812337b7380e2d9c"},"cell_type":"code","source":"assert len(pd.unique(train.PassengerId.values)) == len(train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1bf4dad5b28eec9b7e02980976b3e3904cec53b"},"cell_type":"markdown","source":"## Survived\n`Survived` is the outcome variable to be modeled.  Note that the percent survived (~38%) in the training dataset matches what occured historically, confirming at least with this factor that we've likely sampled appropriately from the population."},{"metadata":{"trusted":true,"_uuid":"34714e63af8ab7a7e535935fc71c40956f3dc466"},"cell_type":"code","source":"pretty_hist(train, \"Count\", c.Survived, \"Survived | Titanic train dataset\", [\"Not\\nSurvived\", \"Survived\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88ab34e7d8124a214604bb7c3a45ff49b7bef628"},"cell_type":"markdown","source":"## Pclass\n`Pclass` represents the passenger boarding class.  As expected, most passengers were residing in 3rd class."},{"metadata":{"trusted":true,"_uuid":"1c94d848f1a6b48e92f8af9f2072a23f46b306b5"},"cell_type":"code","source":"pretty_hist(train, \"Count\", c.Pclass, \"Pclass | Titanic train dataset\", [\"1st\", \"2nd\", \"3rd\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd5ce95313d0317259939cc6122514945761bdaf"},"cell_type":"markdown","source":"## Name\n`Name` in this training dataset typically follows the format, `<Last Name>, <Title> <First Name>`.  We can use this property to extract the title."},{"metadata":{"trusted":true,"_uuid":"caab92ac8305fdb81eb291b5efcebb9a86819da9"},"cell_type":"code","source":"train[[c.Name]].head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7dcde3904cf1262db88f5d2f8429300ff4fdd63a"},"cell_type":"markdown","source":"## Sex\nThere were more males aboard the RMS Titanic than females."},{"metadata":{"trusted":true,"_uuid":"46b9a6ad1d4ba6a3a4a46ece236ffc63ae791d19"},"cell_type":"code","source":"pretty_hist(train.assign(Sex = [1 if k == 'female' else 0 for k in train.Sex]), \"Count\", c.Sex, \"Sex | Titanic train dataset.\", [\"Male\", \"Female\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"077ed3a294c359b8fe33ddd35fce17beb06464b2"},"cell_type":"markdown","source":"## Age\n`Age` has significant missing values (~19%) and appears to be multimodel as shown with the kde plot. "},{"metadata":{"trusted":true,"_uuid":"5f2eeb3a9c2f04f7489756dc0a0fea8f0362598a"},"cell_type":"code","source":"pretty_hist(train.assign(Missing = [1 if k else 0 for k in train.Age.isnull()]), \"Count\", \"Missing\", \"Age | Titanic train dataset.\", [\"Not\\nMissing Value\", \"Missing Value\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4368f208368dba435e2eb2d0caca9dd440369a1"},"cell_type":"code","source":"ax = train.Age.plot.kde()\nax.set_title(\"Age | Titanic train dataset.\")\nax.set_ylabel(\"Density\")\nax.set_xbound(0)\n_ = ax.set_xlabel(\"Age (year)\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"16facc2fd124fe325337ca1ade7719b7dcad4705"},"cell_type":"markdown","source":"## SibSp\nMost passengers had at most 1 sibling on board as shown in the `SibSp` variable."},{"metadata":{"trusted":true,"_uuid":"803c7420c83a296944456d1ae8d0e955057e84cd"},"cell_type":"code","source":"p = plt.hist(train.SibSp)\nplt.title(\"SibSb | Titanic train dataset.\")\nplt.ylabel(\"Count\")\n_ = plt.xlabel(\"Number of siblings on board.\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cad708a076091f99a3921fb4b3cf8638195f5ede"},"cell_type":"markdown","source":"## Parch\n`Parch` shows that most passengers boarded alone. "},{"metadata":{"trusted":true,"_uuid":"e6dbd95850c73af75acfd11cf91f169b4293e1ee"},"cell_type":"code","source":"p = plt.hist(train.Parch)\nplt.title(\"Parch | Titanic train dataset.\")\nplt.ylabel(\"Count\")\n_ = plt.xlabel(\"Number of parent/children accompanied on board.\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bdfab3c06934a51596d7195a84330dc97c35241f"},"cell_type":"markdown","source":"## Ticket\n`Ticket` most likely correlates with `Pclass` and will therefore be dropped."},{"metadata":{"_uuid":"d2c0b9fa9da73c7fd5b2d68358918c5ba1ca4256"},"cell_type":"markdown","source":"## Fare\nThere are no missing `Fare` values.  Most passengers paid less than $100."},{"metadata":{"trusted":true,"_uuid":"ea2b458574a413756867192ab3e375c83631df3c"},"cell_type":"code","source":"assert train.Fare.isnull().sum() == 0 # True\nax = train.Fare.plot.kde()\nax.set_title(\"Fare | Titanic train dataset.\")\nax.set_ylabel(\"Density\")\nax.set_xbound(0)\n_ = ax.set_xlabel(\"Fare ($)\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb67bbcbc0a720328e1d3e1cd0763cb81c8732e5"},"cell_type":"markdown","source":"## Cabin\n\n**We decided to drop this field as it may relate more to `Pclass` which is more of an association with survival.**\n\nMost `Cabin` assignments start with a number and others a letter.  The letter may correspond to the ship deck [see Titanic cutaway diagram](https://en.wikipedia.org/wiki/First_class_facilities_of_the_RMS_Titanic#/media/File:Titanic_cutaway_diagram.png)[2]. According to the diagram, life boats were near the A deck (top most floor).  However, according to the testimonies of survivors [3], once the ship made contact with the ice berg, there was a significant amount of time to reach the lifeboats.  The issue was not so much the distance to the lifeboats but that there was a lack thereof.  On a large scale, there was no fighting for positions on a lifeboat, according to the testimonies.  Finally, when the ship broke in two pieces, the life boats had already departed."},{"metadata":{"trusted":true,"_uuid":"2190c14baa455fa203e878b9cb17ca1bc3aff1e9"},"cell_type":"code","source":"train.assign(CabinLetter = train.Cabin.str.get(0)).CabinLetter.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"368930dc969484f0d453eb2e8e7f0589a47e902b"},"cell_type":"markdown","source":"## Embarked\n`Embarked` indicates passenger's port of departure where S, C, and Q correspond to **C**herbourg, **S**outhampton, and **Q**ueenstown, respectively.  The order of passenger embarkment was first Southampton, followed by Cherbourg and finally Queenstown before setting out into the Atlantic Ocean [1].  There were only two missing embarkment records of two ladies in first class traveling in the same Cabin who survived.\nOn face value, one may consider `Embarked` to lack predictive value.  However, where a passenger boarded may dictate ship cabin filling order which may have influenced access to lifeboats."},{"metadata":{"trusted":true,"_uuid":"dcce9023423cf7fbc625693a3206fa8721f6240a"},"cell_type":"code","source":"train.Embarked.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"056cbaf55b6ae7f09a97ea03c6898f2c46e6f0f6"},"cell_type":"code","source":"train[train.Embarked.isnull()]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ca52c18ae46045643195d164088999ca1a23182"},"cell_type":"markdown","source":"# Bivariate Analysis"},{"metadata":{"_uuid":"8996b4c38cb429ab10a4bfd1d5b2b0be4bdcec03"},"cell_type":"markdown","source":"## Embarked versus Survived"},{"metadata":{"_uuid":"9aa74bbed9b4a851ef289aded870dc2a97ea6c15"},"cell_type":"markdown","source":"Most people embraced at S, but it has a high rate of not survived\n- source: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.boxplot.html\n- source - http://pandas.pydata.org/pandas-docs/version/0.9.1/visualization.html\n- Source: https://stackoverflow.com/questions/48799718/pandas-pivot-table-to-stacked-bar-chart\n"},{"metadata":{"trusted":true,"_uuid":"a023ac6b3ccca57bd52750cd90625e9e3e660552"},"cell_type":"code","source":"train['Embarked'].value_counts()\ntrain['Embarked'].value_counts().plot.bar();\n\ndf_Survived = train[train['Survived']==1]\ndf_Not_Survived = train[train['Survived']==0]\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\ndf_Survived['Embarked'].value_counts().plot.box(ax=axes[0]); \naxes[0].set_title('Embarked Survived')\ndf_Not_Survived['Embarked'].value_counts().plot.box(ax=axes[1]); \naxes[1].set_title('Embarked not Survived')\n\nfig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8, 5))\ndf_Survived['Embarked'].value_counts().plot.bar(ax=axes[0]); \naxes[0].set_title('the total count of Embarked for survived ')\ndf_Not_Survived['Embarked'].value_counts().plot.bar(ax=axes[1]); \naxes[1].set_title('the total count of Embarked for non-survived ')\n\ntrain.groupby('Survived')['Embarked'].value_counts().unstack(level=1).plot.bar(stacked=True)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"527f36c4dac744aa57b144ef707b71e453393fd4"},"cell_type":"markdown","source":"## Fare versus Survived\n`Fare` there is a significant difference in that paid by passengers who survived and who didn't survive.  Therefore, it will be valuable to keep this variable in the model."},{"metadata":{"trusted":true,"_uuid":"35c106a0deb11e55225df76fb86ca0769bf8baab"},"cell_type":"code","source":"stats.ttest_ind(train[train.Survived == 0].Fare, train[train.Survived == 1].Fare)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8219e2eaf3b7341dd930d32601b59459dd74a5b"},"cell_type":"markdown","source":"According to the graph, we can know that the fare is critical to the survival.\n- source: https://stackoverflow.com/questions/14885895/color-by-column-values-in-matplotlib\n- source: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.boxplot.html\n- source - http://pandas.pydata.org/pandas-docs/version/0.9.1/visualization.html\n"},{"metadata":{"trusted":true,"_uuid":"76e322dbda96f5b6a9a6b4cfa0a7d4bafebb44ab"},"cell_type":"code","source":"\nfg = sns.FacetGrid(data=train, hue='Survived')\nfg.map(plt.scatter, 'Age', 'Fare').add_legend()\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\ndf_Survived['Fare'].value_counts().plot.box(ax=axes[0], sharey=True); \naxes[0].set_title('Fare for df_Survived')\ndf_Not_Survived['Fare'].value_counts().plot.box(ax=axes[1]); \naxes[1].set_title('Fare for df_Not_Survived')\nplt.show()\n\nfig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8, 8), sharey=True)\ndf_Survived['Fare'].value_counts().plot.hist(ax=axes[0]); \naxes[0].set_title('Fare for df_Survived')\ndf_Not_Survived['Fare'].value_counts().plot.hist(ax=axes[1]); \naxes[1].set_title('Fare for df_Not_Survived')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"264887bec121adaf292abf4cfd8c69ee692bd8e9"},"cell_type":"markdown","source":"## Sex"},{"metadata":{"_uuid":"cf10c7dd84238a6b743802f8f6b62bfe51b781bc"},"cell_type":"markdown","source":"The total of the male is slightly more than the female but most females survived \n- Source: https://stackoverflow.com/questions/50319614/count-plot-with-stacked-bars-per-hue\n"},{"metadata":{"trusted":true,"_uuid":"e3e219210d9b585feff3a0c913775a48b6f4667a"},"cell_type":"code","source":"print(train['Sex'].value_counts())\ntrain['Sex'].value_counts().plot.bar()\n\ntrain.groupby('Survived')['Sex'].value_counts().unstack(level=1).plot.bar(stacked=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2edf766284b691ec8abd3a59237706da6c0050d"},"cell_type":"markdown","source":"## Pclass\nThere was a statistically significant survival outcome between boarding classes 1 and 3 only.  2nd class passengers almost equally survived, while 1st and 3rd class passengers found opposite fates.  Roughly 25% 3rd class passengers survived.  Over 50% 1st class passengers enjoyed safety after this tragedy.  Therefore, `Pclass` is worthy to include in the model."},{"metadata":{"trusted":true,"_uuid":"ba24fe4e3f3f34b6c6f968901222a3b9fa57ff78"},"cell_type":"code","source":"contingency(train, c.Pclass, c.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c02275295bd7e58c894ec0fe3d4ef88ada80e000"},"cell_type":"code","source":"fig, _ = mosaic(train, [c.Pclass, c.Survived], title=\"Pclass vs Survived | Titanic train dataset.\", axes_label=True)\nfig.axes[0].set_ylabel(c.Survived)\n_ = fig.axes[0].set_xlabel(c.Pclass)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e2271fd3803060f6628bd39fcf611d21e4eda96"},"cell_type":"markdown","source":"According to the graph, most people who died were from class 3.****\n- source: https://stackoverflow.com/questions/50319614/count-plot-with-stacked-bars-per-hue"},{"metadata":{"trusted":true,"_uuid":"95bf0f1e8454ab0fc593e4866f26505c9a243d49"},"cell_type":"code","source":"train.groupby('Survived')['Pclass'].value_counts().unstack(level=1).plot.bar(stacked=True)\ntrain['Pclass'].value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f066295206b8c08b333286569ffde6a531b18a7"},"cell_type":"markdown","source":"## Pclass versus Fare"},{"metadata":{"_uuid":"5c84f76cde5557fc710c29f4e2ccc81d5c60d5ec"},"cell_type":"markdown","source":"We want to find out the relationship between class and fare. The people who were class 1 paid more than the other two. This result helps me to identify the relationship between embedded and class.\n- source: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.boxplot.html\n- source:  https://stackoverflow.com/questions/50319614/count-plot-with-stacked-bars-per-hue"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"37522532b87654ccddb853452db3079887acf33a"},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(20, 4), sharey=True)\ntrain[train['Pclass']==1]['Fare'].plot.box(ax=axes[0]);\naxes[0].set_title('Class 1')\n\ntrain[train['Pclass']==2]['Fare'].plot.box(ax=axes[1]); \naxes[1].set_title('Class 1')\n\ntrain[train['Pclass']==3]['Fare'].plot.box(ax=axes[2]); \naxes[2].set_title('Class 3')\ntrain.groupby('Pclass')['Embarked'].value_counts().unstack(level=1).plot.bar(stacked=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"955809c0d2f5fb0f8d6179082bfdb9fe11b8f6a2"},"cell_type":"markdown","source":"# Preprocessing\n\nWe preprocess variables by one-hot recoding if categorical or kmeans clustering followed by one-hot recoding before providing them to the model.  Using a decorator pattern, flag a method to the pipeline processor to ensure consistency when applying methodology to both train and test datasets."},{"metadata":{"trusted":true,"_uuid":"8c49db242c59d69f72f61e8621e0b14a35847c9a"},"cell_type":"markdown","source":"## Sex"},{"metadata":{"_uuid":"ac7e7ab1c861e82c35b78117ab4949de54b09e9e"},"cell_type":"markdown","source":"### Definition\nWe simply create a new variable `Female`, assigning `1` where indicated and `0` otherwise."},{"metadata":{"trusted":true,"_uuid":"4039a2979898d4c1c75643c30eece3dc438f5f92"},"cell_type":"code","source":"@Pipeline.step\ndef numerify_sex(df: pd.DataFrame) -> pd.DataFrame:\n    if c.Sex not in df.columns.values:\n        return df\n    \n    dfcopy = df.assign(Sex=df.Sex.str.title())\n    return dfcopy.join(pd.get_dummies(dfcopy.Sex)).drop([\"Male\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c30e7ad4bf42e75f933a062bceff61f233eabfc"},"cell_type":"markdown","source":"### Testing\n`Female` seems associated with `Survived`."},{"metadata":{"trusted":true,"_uuid":"5e55e49b22a54a09e3c14482bd09d1e16f6edc2f"},"cell_type":"code","source":"# Test numerify_sex\ntrain_sex_numerified = numerify_sex(train)\nassert train_sex_numerified.query(\"Sex == 'Male'\").query(\"Female == 0\").Female.count() == 577\nassert train_sex_numerified.query(\"Sex == 'Female'\").query(\"Female == 1\").Female.count() == 314\n\ncontingency(train_sex_numerified, c.Female, c.Survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05764555730ded69909ef6fb9ce983caee0d77f3"},"cell_type":"markdown","source":"## Name"},{"metadata":{"_uuid":"76ddc714e40b9cddd77b6c6fe3757afe01baba09"},"cell_type":"markdown","source":"### Definition\nThe `Name` variable was recoded based on the extracted title assuming a string pattern `<Last Name>, <Title> <First Name>(<Additional Name>...)`.  We employ the Names Corpus to check against a potential error that `Title` may actually map to a `First Name`.  The train dataset is consistent with the string pattern.  We cannot assume this in future test datasets.\n\n- Names Corpus Version 1.3 Courtesy: Mark Kantrowitz (c) 1991 (http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/nlp/corpora/names/)"},{"metadata":{"trusted":true,"_uuid":"797da5ac4132e8ac04f029c7b7a460e498e05942"},"cell_type":"code","source":"def extract_title(name: str) -> str:\n    return re.search(r'(?<=\\,\\s)\\w+', name).group(0)\n\ndef remap_title(name: str) -> str:\n    result = name\n    remap = {\n        \"Mr\": COMMON,\n        \"Mrs\": COMMON,\n        \"Mlle\": PRIVILAGED,\n        \"Mme\": PRIVILAGED,\n        \"Ms\": PRIVILAGED,\n        \"the\": PRIVILAGED,\n        \"Miss\": PRIVILAGED,\n        \"Master\": PRIVILAGED,\n        \"Rev\": PUBLIC_SERVANT,\n        \"Dr\": PUBLIC_SERVANT,\n        \"Don\": COMMON,\n        \"Madame\": COMMON,\n        \"Major\": MILITARY,\n        \"Lady\": PRIVILAGED,\n        \"Sir\": PRIVILAGED,\n        \"Col\": MILITARY,\n        \"Capt\": MILITARY,\n        \"Royalty\": PRIVILAGED,\n        \"Dona\": PRIVILAGED,\n        \"Jonkheer\": COMMON\n    }\n    if is_name(name):\n        result = \"NONE\"\n\n    if name in remap:\n        result = remap[name]\n    else:\n        raise Exception(\"{} not assignable to title remapping.\".format(name))\n\n    return result\n\ndef is_name(name: str) -> bool:\n    return names.Name.equals(name)\n\n@Pipeline.step\ndef numerify_title(df: pd.DataFrame) -> pd.DataFrame:\n    if c.Name not in df.columns.values:\n        return df\n\n    dfcopy = df.copy()\n    if dfcopy.Name.isnull().sum() > 0:\n        raise Exception(\"numerify_title is not implemented to handle missing data\")\n\n    dfcopy = dfcopy.assign(Title=[remap_title(extract_title(s)) for s in dfcopy.Name])\n\n    dfcopy = dfcopy.join(pd.get_dummies(dfcopy.Title))\n\n    return dfcopy","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7e8048885bd0b3621026ccf4aba29df6a43106df"},"cell_type":"markdown","source":"### Testing\nBeing `Female` and `Privilaged` ensured greater chances of survival."},{"metadata":{"trusted":true,"_uuid":"202c1883c5596ffcbca0d6c12c6b691213d3cc1f"},"cell_type":"code","source":"train_title = numerify_title(train)\nf = train_title[train_title.Sex == 'female']\nm = train_title[train_title.Sex == 'male']\n\ntitleS = pd.unique(train_title.Title.values)\nms = []\nfs = []\ntot = []\n\nfor k in titleS:\n    ms.append(m[m.Title == k].Survived.sum())\n    fs.append(f[f.Title == k].Survived.sum())\n    tot.append(len(train_title[train_title.Title == k]))\n\n\ndf = pd.DataFrame()\ndf = df.assign(Title = titleS, MaleSurvived = ms, FemaleSurvived = fs, Total = tot)\ndf = df[[\"Title\", \"MaleSurvived\", \"FemaleSurvived\", \"Total\"]]\ndf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e26eae3db4d4961c83d29ae13a6cccf666d1373b"},"cell_type":"markdown","source":"## Pclass"},{"metadata":{"_uuid":"4d546ac53c3cae6c887c99ca4b3f9cc14159772d"},"cell_type":"markdown","source":"### Definition\nWe simply hot-recoded `Pclass` into `Pclass_<n>...`"},{"metadata":{"trusted":true,"_uuid":"bdf6eda41aa808b2122ca2bcc2f84d1577512496"},"cell_type":"code","source":"@Pipeline.step\ndef recode_pclass(df: pd.DataFrame) -> pd.DataFrame:\n    if c.Pclass not in df.columns.values:\n        return df\n\n    dfcopy = df.copy()\n    assert dfcopy.Pclass.isnull().sum() == 0\n\n    return dfcopy.join(pd.get_dummies(dfcopy.Pclass, prefix=c.Pclass))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fde5867432cecf97cf338e3336bf12aa708664a6"},"cell_type":"markdown","source":"### Testing"},{"metadata":{"trusted":true,"_uuid":"86584d1141273ad22de3907be04c77e48bc5f3d3"},"cell_type":"code","source":"# Test recode_pclass\ntrain_pclass = recode_pclass(train)\nassert train_pclass.Pclass_1.isnull().sum() == 0\nassert train_pclass.Pclass_2.isnull().sum() == 0\nassert train_pclass.Pclass_3.isnull().sum() == 0\nassert len(train_pclass.query(\"Pclass == 1 and Pclass_1 == 1 and Pclass_2 == 0 and Pclass_3 == 0\")) == len(train.query(\"Pclass == 1\"))\nassert len(train_pclass.query(\"Pclass == 2 and Pclass_1 == 0 and Pclass_2 == 1 and Pclass_3 == 0\")) == len(train.query(\"Pclass == 2\"))\nassert len(train_pclass.query(\"Pclass == 3 and Pclass_1 == 0 and Pclass_2 == 0 and Pclass_3 == 1\")) == len(train.query(\"Pclass == 3\"))\ntrain_pclass[[c.Pclass, \"Pclass_1\", \"Pclass_2\", \"Pclass_3\"]].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e66e76e247e0ab7cf754930b395149d0b6fa0eb8"},"cell_type":"markdown","source":"## SibSp and Parch"},{"metadata":{"_uuid":"b13f5e30e25ab306e255d825766c78f604c4dacc"},"cell_type":"markdown","source":"### Definition\nWe decided to recode `SibSp` and `Parch` into one variable `HasFamily`.  The `SibSp` variable comingles flagging of whether a passenger co-boarded with a spouse or sibling which we attempted to address (see `Sarch` definition)."},{"metadata":{"trusted":true,"_uuid":"3b2a395e1b8b2b274bfb59b7f50afabd8301f018"},"cell_type":"code","source":"def recode_sibsp(df: pd.DataFrame) -> pd.DataFrame:\n    if c.SibSp not in df.columns.values:\n        return df\n\n    dfcopy = df.copy()\n    assert dfcopy.SibSp.isnull().sum() == 0\n\n    return dfcopy.assign(HasSib = [k > HAS_SIB_THRESHOLD for k in dfcopy.SibSp])\n\ndef recode_parch(df: pd.DataFrame) -> pd.DataFrame:\n    if c.Parch not in df.columns.values:\n        return df\n\n    dfcopy = df.copy()\n    assert dfcopy.Parch.isnull().sum() == 0\n\n    return dfcopy.assign(HasParch = [k > HAS_PARCH_THRESHOLD for k in dfcopy.Parch])\n\n@Pipeline.step\ndef recode_has_family(df: pd.DataFrame) -> pd.DataFrame:\n    if c.SibSp not in df or c.Parch not in df:\n        return df\n\n    dfcopy = df.copy()\n    df_sibsp = recode_sibsp(dfcopy)\n    df_parch = recode_parch(dfcopy)\n    df_family = df_sibsp.merge(df_parch)\n    has_family = [m or n for (m,n) in zip(df_sibsp.HasSib, df_parch.HasParch)]\n    return df_family.assign(HasFamily = [1 if k else 0 for k in has_family])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3314387e36ba5af483f6dcd784200bd984a85a9f"},"cell_type":"markdown","source":"### Testing\nNot `HasFamily` seems more associated with not `Survived`.  `HasFamily` seems equivalent in terms of `Survived` (p-value ~ 0.83)."},{"metadata":{"trusted":true,"_uuid":"53f3e1989bb2c6bed6264da1bf67612131dd0d71"},"cell_type":"code","source":"train_family = recode_has_family(train)\nqry = \"(SibSp > {} or Parch > {}) and HasFamily == 1\".format(HAS_SIB_THRESHOLD, HAS_PARCH_THRESHOLD)\nassert len(train_family.query(qry)) == len(train_family.query(\"HasFamily == 1\"))\ncontingency(train_family, c.HasFamily, c.Survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a016da52206cb59313ad3b6667608c003feda63"},"cell_type":"markdown","source":"## Fare"},{"metadata":{"_uuid":"729bf30c3d8f65b1cd3d1d201f69212786a5a677"},"cell_type":"markdown","source":"### Definition\nUsing the KMeans algorithm we converted the `Fare` variable into hot-recoded categorical clusters instead of inputing the continuous variable into the model."},{"metadata":{"trusted":true,"_uuid":"bffbece097f98ce2dfe97e14a321d3095a0089cf"},"cell_type":"code","source":"@Pipeline.step\ndef recode_fare(df: pd.DataFrame) -> pd.DataFrame:\n    if c.Fare not in df.columns.values:\n        return df\n\n    dfcopy = df.copy()\n    \n    median_fare = 0\n    \n    if not MEDIAN_FARE:\n        median_fare = dfcopy.Fare.median()\n    \n    dfcopy.Fare.fillna(median_fare, inplace=True)\n    \n    X = dfcopy.Fare.values.reshape(-1,1)\n    km = KMeans(n_clusters=NUM_FARE_CLUSTERS, random_state=0)\n    results = km.fit(X)\n    dfcopy = dfcopy.assign(FareCluster = results.predict(X))\n    \n    return dfcopy.join(pd.get_dummies(dfcopy.FareCluster, prefix=c.FareCluster))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ff82f033e24fa8fdc7370531d680e242ba7092d"},"cell_type":"markdown","source":"### Testing\n`Fare` clustered into three groups that didn't overlap.  There appears an association with `FareCluster` assignment and `Survived`."},{"metadata":{"trusted":true,"_uuid":"aeac38716567fd1e213d16834fb65df726a74fe1"},"cell_type":"code","source":"train_fare = recode_fare(train)\ncenters = pd.unique(train_fare.FareCluster.values)\nn_centers = len(centers)\nfig, axes = plt.subplots(len(centers), sharex=True, sharey=True)\nfor i, k in zip(range(n_centers+1), centers):\n    ax = axes[i]\n    train_fare[train_fare.FareCluster == i].Fare.plot.kde(ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c0671bbe0b41bb9b2c9df206d288cdc414164ea"},"cell_type":"code","source":"minS = []\nmaxS = []\nclusterS = range(train_fare.FareCluster.min(),train_fare.FareCluster.max()+1)\nfor k in clusterS:\n    g = train_fare[train_fare.FareCluster == k]\n    minS.append(g.Fare.min())\n    maxS.append(g.Fare.max())\n    \ndf = pd.DataFrame()\ndf.assign(FareCluster = clusterS, MinFare=minS, MaxFare=maxS).sort_values(by=\"MinFare\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb90301474c47c7429570bc2439cebd6ef43e217"},"cell_type":"code","source":"contingency(train_fare, c.FareCluster, c.Survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d2da3040c2bb363274edff1ae9e06b84f98bae1"},"cell_type":"markdown","source":"## Age"},{"metadata":{"_uuid":"747a844f662d56ecd5f6af84b9f5d6942b16baaf"},"cell_type":"markdown","source":"### Definition\nUsing the KMeans algorithm we converted the `Age` variable into hot-recoded categorical clusters instead of inputing the continuous variable into the model.  Missing values are imputed using the median.  We assign a global variable `MEDIAN_AGE` from the `train` dataset.  We will impute missing values in the `test` dataset using the median from the `train` dataset."},{"metadata":{"trusted":true,"_uuid":"d266d48489ae251ffaa7d6637cbbd1c95d7f428c"},"cell_type":"code","source":"@Pipeline.step\ndef recode_age(df: pd.DataFrame) -> pd.DataFrame:\n    if c.Age not in df.columns.values:\n        return df\n\n    dfcopy = df.copy()\n    \n    median_age = 0\n    \n    if not MEDIAN_AGE:\n        median_age = dfcopy.Age.median()\n    \n    dfcopy.Age.fillna(median_age, inplace=True)\n    X = dfcopy.Age.values.reshape(-1,1)\n    km = KMeans(n_clusters=NUM_AGE_CLUSTERS, random_state=0)\n    results = km.fit(X)\n    dfcopy = dfcopy.assign(AgeCluster = results.predict(X))\n    return dfcopy.join(pd.get_dummies(dfcopy.AgeCluster, prefix=c.AgeCluster))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2bdd790355582c7ea3bfdfc0963bdd4dce04cc0a"},"cell_type":"markdown","source":"### Testing\nThe KMeans algorithm custered the `Age` variable into five groups that do not overlap.  `AgeCluster` assignment seems significantly associated with `Survived`."},{"metadata":{"trusted":true,"_uuid":"1964cafd48e8213f4383e490873c010eb66c55f8"},"cell_type":"code","source":"train_age = recode_age(train)\nassert train_age.AgeCluster.isnull().sum() == 0\ncenters = sorted(pd.unique(train_age.AgeCluster.values))\nn_centers = len(centers)\nfig, axes = plt.subplots(len(centers)-1, sharex=True, sharey=True)\nfor i, k in zip(range(0, n_centers+1), centers[1:]):\n    ax = axes[i]\n    train_age[train_age.AgeCluster == i].Age.plot.kde(ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"015cf98a8fe09273b83016b8d1944af45d4c2691"},"cell_type":"code","source":"minS = []\nmaxS = []\nclusterS = range(train_age.AgeCluster.min(),train_age.AgeCluster.max()+1)\nfor k in clusterS:\n    g = train_age[train_age.AgeCluster == k]\n    minS.append(g.Age.min())\n    maxS.append(g.Age.max())\n    \ndf = pd.DataFrame()\ndf.assign(AgeCluster = clusterS, MinAge=minS, MaxAge=maxS).sort_values(by=\"MinAge\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98a374481bcf91a1ac919bf2daa9baa8fab756c0"},"cell_type":"code","source":"contingency(train_age, c.AgeCluster, c.Survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"527ba014b2bff3be096df4095eb1b67056da08c6"},"cell_type":"markdown","source":"## Embarked"},{"metadata":{"_uuid":"fa0b4ba55b4a721c002b2dffceeeecf5dd4f00b8"},"cell_type":"markdown","source":"### Definition\nWe simply hot recode `Embarked` into `Embarked_<n>...`.  "},{"metadata":{"trusted":true,"_uuid":"210a9657266efec9a502ac1cdcdcc6c496578cc3"},"cell_type":"code","source":"@Pipeline.step\ndef recode_embarked(df: pd.DataFrame) -> pd.DataFrame:\n    if c.Embarked not in df.columns.values:\n        return df\n    \n    dfcopy = df.copy()\n    \n    dfcopy.Embarked.fillna(dfcopy.Embarked.mode()[0], inplace=True)\n    return dfcopy.join(pd.get_dummies(dfcopy.Embarked, prefix=c.Embarked))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f6591eb50784c89cda4ae312db7074508bdb6d2"},"cell_type":"markdown","source":"### Testing"},{"metadata":{"trusted":true,"_uuid":"6c5eec80a20267889472d90d580c182d1ef6003f"},"cell_type":"code","source":"train_embarked = recode_embarked(train)\ntrain_embarked[[c.Embarked, \"Embarked_C\", \"Embarked_Q\", \"Embarked_S\"]].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29b092bd25fea6308a975e948e3a56913239bcf6"},"cell_type":"markdown","source":"# Sarch"},{"metadata":{"_uuid":"25ddad52bdfb3641a497bb22f034a8db5f5470f1"},"cell_type":"markdown","source":"### Definition\nSurvivor testimonies state that wives coboarded with their husbands remained to perish with them [3].  Therefore, we create a new variable `Sarch` indicating whether or not an individual's spouse is on board with the following criteria:\n* `SibSp` == 1\n* `Parch` == 0\n* Age > 18 (we defined as `TRUE_LOVE_AGE_CUTOFF`)\n* `Title` remapped from `Name` using `remap_title(Name)` is `Mr` or `Mrs`"},{"metadata":{"trusted":true,"_uuid":"8c18ccc8f90c52119d158e78ac0fecddb22777d9"},"cell_type":"code","source":"def code_sarch(df: pd.DataFrame) -> pd.DataFrame:\n    if c.SibSp not in df.columns.values:\n        return df\n    \n    if c.Parch not in df.columns.values:\n        return df\n    \n    if c.Age not in df.columns.values:\n        return df\n    \n    dfcopy = df.copy()\n    sibsp1 = dfcopy.SibSp == 1\n    parch0 = dfcopy.Parch == 0\n    titleS = [extract_title(k) for k in dfcopy.Name]\n    title_mr_or_mrs = [k in MARRIED_TITLES for k in titleS]\n    \n    median_age = 0\n    \n    if not MEDIAN_AGE:\n        median_age = dfcopy.Age.median()\n    \n    dfcopy.Age.fillna(median_age, inplace=True)\n    \n        \n    age_gt_cutoff = [k > TRUE_LOVE_AGE_CUTOFF for k in dfcopy.Age]\n    return dfcopy.assign(Sarch = 1 * (sibsp1 & parch0 & title_mr_or_mrs & age_gt_cutoff))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d56760bbc4662ea0d3adf7d43ec429bcbb1328d2"},"cell_type":"markdown","source":"### Testing\nWhile there is a significant association with not `Sarch` and not `Survived`, having a spouse co-passenger does not seem significantly associated with `Survived` (p-value ~ 0.57).  Also when applied to the model it reduced the score.\n**Unfortunately this new variable did not improve the model and was not added to the preprocessing pipeline.  We kept the variable definition for interest to the reader.**"},{"metadata":{"trusted":true,"_uuid":"4d882287237b4fb29f3722d2f86c441173e27d01"},"cell_type":"code","source":"train_sarch = code_sarch(train)\ncontingency(train_sarch, c.Sarch, c.Survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f3cc88aa7c3be4f48e12357830569d1b42d5f102"},"cell_type":"markdown","source":"# Model Build"},{"metadata":{"_uuid":"5c9245aa410a0508a45cf6e7c1ad982a1eefe956"},"cell_type":"markdown","source":"## Preprocess Data"},{"metadata":{"trusted":true,"_uuid":"1407dd485e2986cd86e5a723712a9226fe2f8df6"},"cell_type":"code","source":"train_recoded = Pipeline.process(train)\ncolumns_to_drop = [c.PassengerId, c.Pclass, c.Name, c.Sex, c.Age, c.SibSp, c.Parch, c.Ticket, c.Fare, c.Cabin, c.Embarked, c.HasSib, c.HasParch, c.Title, c.AgeCluster, c.FareCluster]\ntrain_recoded.drop(columns_to_drop, axis=1, inplace=True)\ntrain_recoded.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a385114f37b6b35efafeaae04c243c831222278"},"cell_type":"markdown","source":"## Split training dataset into its own train and test subsets."},{"metadata":{"trusted":true,"_uuid":"c9fa1fda8db710c6c46408fbc8c85c1e4385ba5b"},"cell_type":"code","source":"X = train_recoded.drop([c.Survived], axis=1)\ny = train_recoded.Survived\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc88c6cdaa28b0fd9209280f522583212ec1bd31"},"cell_type":"markdown","source":"## Support Vector Machine"},{"metadata":{"trusted":true,"_uuid":"636e4e8a39ec6a6183ceb01db09a62fbcd33a8b6"},"cell_type":"code","source":"def getSVM(X_train: pd.DataFrame, X_test: pd.DataFrame, y_train: pd.DataFrame, y_test: pd.DataFrame) -> GridSearchCV:\n    parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n    svc = svm.SVC(gamma=\"scale\")\n    clf = GridSearchCV(svc, parameters, cv=5)\n    clf.fit(X_train, y_train)\n    print(\"score %s\" % (clf.score(X_test, y_test)))\n    y_pred = clf.predict(X_test)\n    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\")\n    return clf\n\nSVM_MODEL = getSVM(X_train, X_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ef6a9e798694457af75ef7134d4c81761e2f9f3"},"cell_type":"markdown","source":"## KNeighborsClassifier"},{"metadata":{"trusted":true,"_uuid":"fb5a2608d72e347a99840d923af754371ac1f24f"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\ndef getKN():\n    scores = []\n    bestScore = 0\n    bestModel = None\n    for n in range(1, 10):\n        clf = KNeighborsClassifier(n_neighbors=n)\n        clf.fit(X_train, y_train)\n        s = clf.score(X_test, y_test)\n        if bestScore < s:\n            bestScore = s\n            bestModel = clf\n        print(\"%s score %s\" % (n, s))\n        scores.append(s)\n    plt.plot(range(1, 10), scores, 'ro')\n    plt.show()\n    y_pred = bestModel.predict(X_test)\n    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\")\n    return bestModel\ngetKN()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56746a615a8f9bee42b46a2ceb4cdf9a9881f4fe"},"cell_type":"markdown","source":"## RandomForestClassifier"},{"metadata":{"trusted":true,"_uuid":"3f663888a93ef8041f53fd7606df8616b287ed8e"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\ndef getRFT():\n    gnb = RandomForestClassifier(n_estimators=100, random_state=20)\n    gnb.fit(X_train, y_train)\n    print(\"score %s\" % (gnb.score(X_test, y_test)))\n    y_pred = gnb.predict(X_test)\n    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\")\n    return gnb\ngetRFT()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55daa9210e437b60b863ab21104f4372bf0d7eb2"},"cell_type":"markdown","source":"## Model Optimization"},{"metadata":{"_uuid":"94588282c2bddac9fe708f2700f82e25a436886a"},"cell_type":"markdown","source":"GridSearchCV for Random Forest Classifier\n- source: https://stackoverflow.com/questions/30102973/how-to-get-best-estimator-on-gridsearchcv-random-forest-classifier-scikit\n- source: http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n"},{"metadata":{"trusted":true,"_uuid":"015fb9fcea33da1f9718f8569293a18202ebbe0f"},"cell_type":"code","source":"\ndef getRFTGridSearch():\n    from sklearn.model_selection import GridSearchCV\n    from sklearn.ensemble import RandomForestClassifier\n\n    rfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True, random_state=20) \n\n    param_grid = { \n        'n_estimators': [200, 700],\n        'max_features': ['auto', 'sqrt', 'log2']\n    }\n    CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n    CV_rfc.fit(X_train, y_train)\n    print(\"score %s\" % (CV_rfc.score(X_test, y_test)))\n    forest = RandomForestClassifier(n_estimators = CV_rfc.best_params_['n_estimators'], max_features= CV_rfc.best_params_['max_features'], random_state=20)\n    forest.fit(X_train, y_train)\n    \n    # get feature importance\n    importances = forest.feature_importances_\n    std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n                 axis=0)\n    indices = np.argsort(importances)[::-1]\n\n    # Print the feature ranking\n    print(\"Feature ranking:\")\n    indcesOfFeatureNames = [ X_train.columns[f] for f in indices ]\n    for f in range(X.shape[1]):\n        print(\"%d. feature %s (index %d )(%f)\" % (f + 1, X_train.columns[f], indices[f], importances[indices[f]]))\n\n    # Plot the feature importances of the forest\n    plt.figure()\n    plt.title(\"Feature importances\")\n    plt.bar(range(X.shape[1]), importances[indices],\n           color=\"r\", yerr=std[indices], align=\"center\")\n    plt.xticks(range(X.shape[1]), indcesOfFeatureNames, rotation=70)\n    plt.xlim([-1, X.shape[1]])\n    plt.show()\n    \n    return forest\ngetRFTGridSearch()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f78b01a03e0e80d0a44036691e4987dcf6f32df"},"cell_type":"markdown","source":"## CatBoost\n> Training and applying models for the classification problems. When using the applying methods only the probability that the object belongs to the class is returned. Provides compatibility with the scikit-learn tools.\n\n- source: https://tech.yandex.com/catboost/doc/dg/concepts/python-usages-examples-docpage/"},{"metadata":{"trusted":true,"_uuid":"54f572bf53192554cd5611789da917d93b8500af"},"cell_type":"code","source":"def getCatBoost():\n    from catboost import CatBoostClassifier\n    model = CatBoostClassifier(iterations=10, learning_rate=1, depth=4, loss_function='Logloss', random_state=20)\n    model.fit(X_train, y_train)\n    print(\"score %s\" % (model.score(X_test, y_test)))\n    y_pred = model.predict(X_test)\n    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\")\n    return model\nCATBOOST_MODEL = getCatBoost()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d84af08bdab57d3b1f89342b7a67d031342b8d58"},"cell_type":"markdown","source":"# Apply Preprocessing and Model to Test Dataset."},{"metadata":{"trusted":true,"_uuid":"cf0e565ea3c34356388f285311e44295e87dac81"},"cell_type":"code","source":"test_recoded = Pipeline.process(test)\ncolumns_to_drop = [c.PassengerId, c.Pclass, c.Name, c.Sex, c.Age, c.SibSp, c.Parch, c.Ticket, c.Fare, c.Cabin, c.Embarked, c.HasSib, c.HasParch, c.Title, c.AgeCluster, c.FareCluster]\ntest_recoded.drop(columns_to_drop, axis=1, inplace=True)\ntest_recoded.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4b50930b3286cb1a6b050c1ef63180e8b5ed150"},"cell_type":"code","source":"y_pred = SVM_MODEL.predict(test_recoded)\nsubmission = pd.DataFrame()\nsubmission = submission.assign(PassengerId = test.PassengerId, Survived = y_pred)\nsubmission.to_csv(\"titanic_survival_prediction.csv\", index=False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfca63d4001a682a188baf3c1c59fcd346052e49"},"cell_type":"code","source":"y_pred = CATBOOST_MODEL.predict(test_recoded)\nsubmission = pd.DataFrame()\nsubmission = submission.assign(PassengerId = test.PassengerId, Survived = y_pred)\nsubmission.to_csv(\"titanic_survival_prediction_CATBOOST_MODEL.csv\", index=False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a33b0582db2a0fd72f221778e66344d933f4422"},"cell_type":"markdown","source":"# Summary and Conclusion\n\n- We used SVM, KNN, and Random Forest in the beginning. RandomForestClassifier has a better accuracy score.  Therefore, we applied `GridSearchCV` for Random Forest in order to find a best hyper parameters. \n- We also tried `CatBoostClassifier`, and we get slightly better performance\n- Not surprised, the feature of `Female` is most important. \n"},{"metadata":{"trusted":true,"_uuid":"80abdfd6801fdd66286ed1008f17e18e5ffa73e7"},"cell_type":"markdown","source":"# References\n1. RMS Titanic. (n.d.). In Wikipedia. Retrieved Oct 31, 2018, from [https://en.wikipedia.org/wiki/RMS_Titanic](https://en.wikipedia.org/wiki/RMS_Titanic).\n2. First class facilities of the RMS Titanic (n.d.). In Wikipedia. Retrieved Oct 31, 2018, from [https://en.wikipedia.org/wiki/First_class_facilities_of_the_RMS_Titanic](https://en.wikipedia.org/wiki/First_class_facilities_of_the_RMS_Titanic).\n3. Titanic Archive - 1957 Interviews (n.d.). From YouTube. Retrieved Oct 31, 2018, from [https://www.youtube.com/watch?v=FVLiZo6Pkak](https://www.youtube.com/watch?v=FVLiZo6Pkak&t=250s)."},{"metadata":{"trusted":true,"_uuid":"30f3e1ff42651aea5fc5bcdfef5d0b499e13fc23"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}