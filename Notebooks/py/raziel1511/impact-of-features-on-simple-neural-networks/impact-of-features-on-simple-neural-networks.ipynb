{"cells": [{"cell_type": "markdown", "metadata": {"_cell_guid": "e6e82996-22f6-4bf6-b60d-1f4586d9e72d", "_uuid": "6a2d97b0ad7e4070bc42158e653ac6e0e5967fcd"}, "source": ["# Impact of Features on simple Neural Networks\n", "\n", "\n", "## Introduction\n", "\n", "After a lecture about ML I found out about Kaggle and I thought it might be a motivating way to practice and apply what I've learned.\n", "\n", "To get a feeling about how the __quantity__ and __quality__ of features influences the performance of a simple neural network I decided to try a few constellations and measure the output. I hope sharing my results might help another beginner. However, I'm also new to ML, so feedback is very welcome.\n", "\n", "At first I'm going to introduce the basic program and afterwards I'm going to augment it step by step. "]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "ba8c3879-6d4e-4fbb-8340-39230db62e70", "_uuid": "e0e0dd640e3d343e60c49f3ee4ee646fdb77dfa4"}, "source": ["## First Approach\n", "\n", "For this project I used **Keras** to simplify the construction of the NN. To load the data I used pandas:"]}, {"cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "95b67929-a46d-4d11-9da8-7f952c09301f", "_uuid": "a0b39d6e48dc6557e6ecb4267951872e34944fb0"}, "outputs": [], "source": ["# Import Dataset\n", "data = pd.read_csv('train.csv')\n", "df = pd.DataFrame(data)\n", "\n", "# Replace Sex with 1(male) and 0(female)\n", "df.replace({'male': 1, 'female': 0}, inplace=True)"], "execution_count": null}, {"cell_type": "markdown", "metadata": {"_cell_guid": "660265f0-c9a3-410c-ac6c-aa95947fd3f3", "_uuid": "19e82edc258728638d5f8c52725e8476c21a4488"}, "source": ["I replaced missing features (e.g. Age) with -1 and trained a three layer, fully connected network with 1500 nodes on each layer an dropout. Afterwards, I tried dropping some values randomly."]}, {"cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "e31e4fbc-d9af-42a3-92a6-3f65db997ac0", "_uuid": "5b9aa1f6d1d01f6b59fa77ccbfbaef628ec38ec6"}, "outputs": [], "source": ["# Shuffle Data \n", "df = df.sample(frac=1.0)\n", "\n", "# Delete Cabin (Data to sparse) and ID (pure Random)\n", "# print(df['Survived'].isnull().sum())  # Age:177, Cabin: 687, Embarked:2\n", "df.drop(['PassengerId', 'Cabin', 'Cabin', 'Embarked', 'Name', 'Ticket'], axis=1, inplace=True)\n", "\n", "# Create train and test\n", "train_data = df.values[:800]\n", "test_data = df.values[800:]\n", "\n", "x_train = train_data[:, 1:]\n", "y_train = np_utils.to_categorical(train_data[:, 0])\n", "\n", "x_test = test_data[:, 1:]\n", "y_test = np_utils.to_categorical(test_data[:, 0])\n", "\n", "# Setup the Network\n", "model = Sequential()\n", "model.add(Dense(1500,\n", "                activation='relu',\n", "                input_shape=(x_train.shape[1],),\n", "                kernel_regularizer=regularizers.l2(0.1)\n", "                ))\n", "model.add(Dropout(0.5))\n", "model.add(Dense(2000, activation='relu',\n", "                kernel_regularizer=regularizers.l2(0.1)\n", "                ))\n", "model.add(Dropout(0.5))\n", "model.add(Dense(1500, activation='relu'))\n", "model.add(Dense(2, activation='softmax',\n", "                kernel_regularizer=regularizers.l2(0.1)\n", "                ))\n", "\n", "# Compile the model\n", "model.compile(loss='categorical_crossentropy',\n", "              optimizer='adam',\n", "              metrics=['accuracy'])\n", "\n", "tb = TensorBoard(log_dir='logs/{}'.format(time()))\n", "\n", "# Train\n", "model.fit(x=x_train, y=y_train, batch_size=200, verbose=2, epochs=25, callbacks=[tb])\n", "\n", "# Eval\n", "score = model.evaluate(x_test, y_test, verbose=0)\n", "print(\"Accuracy: {}\".format(score[1]))\n"], "execution_count": null}, {"cell_type": "markdown", "metadata": {"_cell_guid": "e7ecf797-a219-44dc-b390-6abad80241e7", "_uuid": "b170f14b69b18a13e1b718fd482a46f9b316bbda"}, "source": ["Some features reduced the accuracy slightly when added or dropped, but in general the accuracy was not exceeding 61%."]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "d1ecabfb-1a56-4dab-bed7-1bed017d1ac4", "_uuid": "6f8a35c8bd9b84b2a1482abe8f25007d422ab4b4"}, "source": ["## Extracting New Features\n", "After the first approach was not very successful I decided to engineer some new features, inspired by [Megan Risdals script](https://www.kaggle.com/mrisdal/exploring-survival-on-the-titanic). \n", "\n", "The first step was counting how often a certain title occurs:"]}, {"cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "6a76c62a-fe89-4d28-aaca-92a2449141c5", "_uuid": "b9b49e9a40b16fd01e85f3651e4909d3feefc160"}, "outputs": [], "source": ["# Extract title from the name\n", "\n", "def getTitle(name):\n", "    '''\n", "    :param name: Name of the format Firstname, Title Surename\n", "    :return: Title\n", "    '''\n", "\n", "    m = re.search('(?<=,\\s)\\w+', name)\n", "    return (m.group(0))\n", "\n", "\n", "# Extract titles and count\n", "title_set = {}\n", "for name in df['Name']:\n", "    title = getTitle(name)\n", "    if title in title_set:\n", "        title_set[title] = title_set[title] + 1\n", "    else:\n", "        title_set[title] = 1\n", "print(title_set) \n", "# Output:\n", "# {'Mr': 517, 'Ms': 1, 'Don': 1, 'the': 1, \n", "# 'Mlle': 2, 'Jonkheer': 1, 'Rev': 6, \n", "# 'Dr': 7, 'Miss': 182, 'Major': 2, \n", "# 'Sir': 1, 'Lady': 1, 'Mme': 1, 'Mrs': 125, \n", "# 'Master': 40, 'Col': 2, 'Capt': 1}\n"], "execution_count": null}, {"cell_type": "markdown", "metadata": {"_cell_guid": "816ee4e8-9823-4496-a3e5-a670010bf95b", "_uuid": "3669425f07b00799b147e457bbe3ab572f0b3a0e"}, "source": ["To simplify the classes I merged *Col, Capt* and *Major* to the title-group _Military_, *Mme, Mlle, Ms* to _UnmarriedWoman_, and eventually *Lady, Sir* and *the* to _nobility_. Other titles are considered to be _miscellaneous_. \n", "\n", "These classes were used to add a new (numerical) attribute to the data:"]}, {"cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "7b5dbdf7-da98-48bb-b685-59680f719971", "_uuid": "5c7bca219ee81dbf53c90fb99b8ba7615f7d5f1a"}, "outputs": [], "source": ["def getTitleNum(name):\n", "    '''\n", "    Assign a numeral according to the title\n", "    :param name: \n", "    :return: numeral according to title\n", "    '''\n", "\n", "    title = getTitle(str(name).upper())\n", "\n", "    title_dict = {}\n", "    title_dict[\"MR\"] = 0\n", "    title_dict[\"MRS\"] = 1\n", "    title_dict[\"COL\"] = 2\n", "    title_dict[\"CAPT\"] = 2\n", "    title_dict[\"MAJOR\"] = 2\n", "    title_dict[\"MME\"] = 3\n", "    title_dict[\"MLLE\"] = 3\n", "    title_dict[\"MS\"] = 3\n", "    title_dict[\"MISS\"] = 3\n", "    title_dict[\"LADY\"] = 4\n", "    title_dict[\"SIR\"] = 4\n", "    title_dict[\"THE\"] = 4\n", "    title_dict[\"MASTER\"] = 5\n", "    title_dict[\"REV\"] = 6\n", "    title_dict[\"DR\"] = 7\n", "\n", "    if title in title_dict:\n", "        return title_dict[title]\n", "    else:\n", "        return -1\n", "\n", "\n", "df['Title'] = df.apply(lambda row: getTitleNum(row['Name']), axis=1)"], "execution_count": null}, {"cell_type": "markdown", "metadata": {"_cell_guid": "7253cf2c-2a32-4409-83cc-844cc83fc9bf", "_uuid": "d7cf131dcbce1a20bb6342cf7b6036695ccb27b9"}, "source": ["The old network increased its accuracy on the Test-Data by 10% to 71%. So apparently the title is a good predictor. Even after removing sex and age the accuracy didn't differ significantly. This was strange since Cameron told us that it's women and children first. \n", "\n", "Therefore, I discretized the age into *toddler (<3)*, *child (<12)*, *teenager (<17)*, *adult (<50)* and *senior (>50)*. With this data I trained another, similar NN to predict the age of the passengers with missing data."]}, {"cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "573888ee-afd7-41b4-a3f0-2da53b58c3f6", "_uuid": "987c7ac7124b6fe92bf86829b9a0ba08357bbba9"}, "outputs": [], "source": ["# Discretize the Age\n", "def discretAge(age):\n", "    if age < 3:\n", "        return 0\n", "    if age < 12:\n", "        return 1\n", "    if age < 17:\n", "        return 2\n", "    if age < 50:\n", "        return 3\n", "    if age >= 50:\n", "        return 4\n", "    # Keep the missing values\n", "    return age\n", "\n", "\n", "df['DisAge'] = df.apply(lambda row: discretAge(row['Age']), axis=1)\n", "\n", "# Replace Sex with 1(male) and 0(female)\n", "df.replace({'male': 1, 'female': 0}, inplace=True)\n", "\n", "# Shuffle Data and extract rows with missing age\n", "df = df.sample(frac=1.0)\n", "age_missing = df[df['Age'].isnull()]\n", "age_complete = df[df['Age'].notnull()]\n", "\n", "\n", "# Create train and test\n", "ages = age_complete['DisAge'].values\n", "\n", "x_train = age_complete[['Title','Pclass', 'Sex']].values[:650]\n", "y_train = np_utils.to_categorical(ages[:650])\n", "\n", "x_test = age_complete[['Title','Pclass', 'Sex']].values[650:]\n", "y_test = np_utils.to_categorical(ages[650:])\n", "\n", "# Setup the Network\n", "model = Sequential()\n", "model.add(Dense(800,\n", "                activation='relu',\n", "                input_shape=(x_train.shape[1],),\n", "                kernel_regularizer=regularizers.l2(0.1)\n", "                ))\n", "\n", "model.add(Dropout(0.5))\n", "model.add(Dense(800, activation='relu'))\n", "model.add(Dense(5, activation='softmax',\n", "                kernel_regularizer=regularizers.l2(0.1)\n", "                ))\n", "\n", "# Compile the model\n", "model.compile(loss='categorical_crossentropy',\n", "              optimizer='adam',\n", "              metrics=['accuracy'])\n", "\n", "tb = TensorBoard(log_dir='logs/{}'.format(time()))\n", "\n", "# Train\n", "model.fit(x=x_train, y=y_train, batch_size=200, verbose=2, epochs=25, callbacks=[tb])\n", "\n", "# Eval\n", "score = model.evaluate(x_test, y_test, verbose=0) # ~75%"], "execution_count": null}, {"cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "5ae0ed81-6e19-4426-bbb3-70bbb378a6e0", "_uuid": "14d17268b26cec80d365cdbec4283fae2e009529"}, "outputs": [], "source": ["# Apply the new model to predict the missing values\n", "\n", "def predictAge(row):\n", "    '''\n", "    Use the trained network to predict the discrete Age\n", "    :param row:\n", "    :return:\n", "    '''\n", "\n", "    if math.isnan(float(row['DisAge'])):\n", "        v = np.array(row[['Title', 'Pclass', 'Sex']].values)\n", "        pred = model_age_prediction.predict(v.reshape((1,3)))\n", "        return np.argmax(pred)\n", "    return row['DisAge']\n", "\n", "df['DisAge'] = df.apply(lambda row: predictAge(row), axis=1)"], "execution_count": null}, {"cell_type": "markdown", "metadata": {"_cell_guid": "16cee6f5-310b-4d9a-9691-016b8302ba5e", "_uuid": "2e02f6bd18361835a73e24e0c1a3c64a82972f5a"}, "source": ["The same network increased its accuracy by another 15% to 87% accuracy. By adding some other values (e. g. Fare) the accuracy fell again, sometimes dramatically. "]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "d587cbec-7025-46e6-b52c-69b0a5308e94", "_uuid": "c02aef73db26a1ad68e3256301bc95eb02b72a92"}, "source": ["## Conclusion\n", "\n", "This example shows, that the quality of features is very important. High quantity, however, could do more harm than good. Maybe that's just an artifact from this dataset or maybe I did something terribly wrong. Anyway, feedback is very welcome. =)  \n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"nbconvert_exporter": "python", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "file_extension": ".py", "version": "3.6.1", "mimetype": "text/x-python"}}, "nbformat_minor": 1, "nbformat": 4}