{"metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python", "file_extension": ".py", "version": "3.6.3", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat_minor": 1, "cells": [{"metadata": {}, "cell_type": "markdown", "source": ["# ** I have made some significant change to my method of Feature Selection. This can been seen in my other kernel: My titanic attempt:) Improved Feature Selection**"]}, {"metadata": {"_uuid": "2b8bfe31a09fe71a545c9decb8293d955771d8dc", "collapsed": true, "_cell_guid": "4675b78a-f4bd-4bf7-88f4-c716bc5b0c4d"}, "execution_count": null, "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": []}, {"metadata": {"_uuid": "c873c4a4103d4a127c0a9ed0f7b2f714aa0aed30", "collapsed": true, "_cell_guid": "6f8e7d07-e887-4349-8d41-08c12f3b68be"}, "execution_count": null, "cell_type": "code", "source": ["# machine learning\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.svm import SVC, LinearSVC\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.linear_model import Perceptron\n", "from sklearn.linear_model import SGDClassifier\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.feature_selection import SelectKBest\n", "from sklearn.feature_selection import chi2"], "outputs": []}, {"metadata": {"_uuid": "b9af7ae8cac9513305153b081ed679b1691521f8", "collapsed": true, "_cell_guid": "509b4e39-2c8f-4c24-a933-876af1504e6e", "_kg_hide-input": true}, "execution_count": null, "cell_type": "code", "source": ["#Import the necessary data\n", "test_df = pd.read_csv('../input/test.csv')\n", "train_df = pd.read_csv('../input/train.csv')\n", "combine = [train_df, test_df]"], "outputs": []}, {"metadata": {"_uuid": "beca47b71e3ce53803cd5cb50c1da7950b459cfa", "collapsed": true, "_cell_guid": "f95d5f86-7da2-487b-9673-1be553fb8a37"}, "execution_count": null, "cell_type": "code", "source": ["#determine the quality of the provided data in order to determine the proceedure for data cleaning.\n", "#missing values\n", "#train_df.info()\n", "print (\"percentage of missing values for age: \",(1-((714/891)))*100)\n", "print (\"Percentage of missing values for cabin: \",(1-((204/891)))*100)\n"], "outputs": []}, {"metadata": {"_uuid": "737ee2a790f56125308cee5a48682e3666a0c736", "_cell_guid": "d2b9ff68-bb68-4f1c-a342-020f7fec875c"}, "cell_type": "markdown", "source": ["Based on the results above, I need to consider if there is any point in cleaning the data, ie, replacing missing values.\n", "\n", "1.Cabin:\n", "Every passenger would have been assigned a cabin and yet this information has not been kept. This cannot be considered a random miss. Instead, this suggests it is poor record keeping. The next thing to consider is the volume missing data. A massive 77.10% is missing, if I were to deal with this, I risk seriously skewing the data. If I remove the rows that are missing this data, I lose 77% of my data overall, this is not an option. If I replace it, I have very little information in order to determine the best value to replace the missing value. I suggest the best option is to ignore this column completely. As much as it would be interesting to determine if a cabins location has a bearing on survival, there just isn't enough data for the results to be considered reliable.\n", "\n", "2.Age:\n", "Intuitively I would think age has a bearing on survival. it is well known that when it comes to the priority of saving a person, it is women and children first, therefore is a person is young, such as a child, they have a higher chance of survival, compare to an adult. The percentage of missing values is 19.86%. It is reasonable to suggest this data can be cleaned. \n", "As to the reason for it not being recorded, the person in question may not have wanted their age to be known, they were a child and it was missed, or they just didn't know. For the moment I would like to keep the variable in, therefore I will replace the missing value. The below suggests that the data is slightly skewed, I will use the mode as althought the mean is arond 29 years, the mode suggests there were many younger people on board.\n", "\n", "3. Other variables that add no value:\n", "There are some columns in there that will not add any value and will instead just create noise. I will fix the above 2 issues and then determine the columns that add no value.\n", "\n", "Conclusion:\n", "I will remove the Cabin variable and replace the missing age values with the mode. "]}, {"metadata": {"_uuid": "1f3d3a130268934c3fd39a8c5177cf2d5bc80fad", "collapsed": true, "_cell_guid": "ef0652cc-a252-4fab-aec4-53ffe9ec0b8f"}, "execution_count": null, "cell_type": "code", "source": [], "outputs": []}, {"metadata": {"_uuid": "357bbe44986e12cb9f7d79fb672ad8626cb8c0e1", "collapsed": true, "_cell_guid": "b87b9d1d-2360-4529-be85-d91a42f76f8c"}, "execution_count": null, "cell_type": "code", "source": ["print (\"The average age: \",train_df[\"Age\"].mean())\n", "print (\"The mode of age in train dataset: \",train_df[\"Age\"].mode())\n", "print (\"The mode of age in test dataset: \",test_df[\"Age\"].mode())"], "outputs": []}, {"metadata": {"_uuid": "82d0dfa677876eade2222913d706dc6e2fa7bae7", "collapsed": true, "_cell_guid": "76dd009c-f190-4358-a8e8-72fb6d2be934"}, "execution_count": null, "cell_type": "code", "source": ["#remove the cabin column\n", "train_df.drop('Cabin', axis = 1, inplace = True)\n", "test_df.drop('Cabin', axis = 1, inplace = True)\n", "#while we are here, remove the name & tickets columns as it is obvious it will add no value\n", "train_df.drop(['Name','Ticket'], axis = 1, inplace = True)\n", "test_df.drop(['Name','Ticket'], axis = 1, inplace = True)\n", "combine = [train_df,test_df]"], "outputs": []}, {"metadata": {"_uuid": "7b8423c8fc303f6f4c38f80337c249b7f85fed08", "collapsed": true, "_cell_guid": "7a8a2a2c-e8c5-496c-a466-a8adc53965d1"}, "execution_count": null, "cell_type": "code", "source": ["train_df['Age'].fillna(24, inplace=True)\n", "test_df['Age'].fillna(21, inplace=True)"], "outputs": []}, {"metadata": {"_uuid": "f5cf84ed182757e8fde6b87c0d33a9ab8da0deab", "collapsed": true, "_cell_guid": "f618c7b9-3b6b-412f-aa3d-ce84aa2f391f"}, "execution_count": null, "cell_type": "code", "source": ["train_df.head()"], "outputs": []}, {"metadata": {"_uuid": "7a13d0c05cdd6fedcff6ec85769d78ef03669dcc", "collapsed": true, "_cell_guid": "9b44e788-cfd5-4214-8d0c-a6dc5f29c1c4"}, "execution_count": null, "cell_type": "code", "source": ["#Turn the sex category into a binary variable\n", "gender_mapping = {\"female\": 0, \"male\": 1}\n", "for dataset in combine:\n", "    dataset['Sex'] = dataset['Sex'].map(gender_mapping)\n", "    dataset['Sex'] = dataset['Sex'].fillna(0)\n", "\n", "train_df.head()"], "outputs": []}, {"metadata": {"_uuid": "65804d9280dea4c246143ab691ccf2b1bfcbfee2", "collapsed": true, "_cell_guid": "c6b52bc7-0238-43fc-95b7-cfcb02fb4d7a"}, "execution_count": null, "cell_type": "code", "source": [], "outputs": []}, {"metadata": {"_uuid": "643bd6137a4e5b6aeb0131b842e7f86639ca0964", "_cell_guid": "b704e981-3f8e-454c-b8cd-f733025cc4a3"}, "cell_type": "markdown", "source": ["The above correlaiton matrix highlights the various levels off correlations between survival and the other available variables.\n", "Considering statistically, the variables that have an important level of correlation are:\n", "* Pclass - this suggests a weak negative relationship between class and the ability to survive\n", "* Sex - This suggests a moderate negative relationship\n", "* Fare - This suggest a weak positive relationship.\n", "\n", "The above results are somewhat surprising as I would have expected age to have more of an impact. The theory I have, which is seen across many data sets is the values each variable gets. Fare and Age are large numbers when compared to passenger class, or gender, therefore it is a good idea if I now fix up some of the other data and consider grouping these variables."]}, {"metadata": {"_uuid": "282889747a39ae1b1765dacd7e0ddec644cc108d", "collapsed": true, "_cell_guid": "f11e50c0-39ae-4976-8ecc-ffcb74c0decf"}, "execution_count": null, "cell_type": "code", "source": ["#split the ages up into groups\n", "#train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\n", "#train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)\n"], "outputs": []}, {"metadata": {"_uuid": "19636d18fdf60523b6124dd95c3a6a027b1df195", "collapsed": true, "_cell_guid": "4aadedb0-1603-4ef5-8b5e-a611a60f4744"}, "execution_count": null, "cell_type": "code", "source": ["#for dataset in combine:    \n", " #   dataset.loc[ dataset['Age'] <= 16.336, 'Age'] = 0\n", " #   dataset.loc[(dataset['Age'] > 16.336) & (dataset['Age'] <= 32.252), 'Age'] = 1\n", " #   dataset.loc[(dataset['Age'] > 32.252) & (dataset['Age'] <= 48.168), 'Age'] = 2\n", " #   dataset.loc[(dataset['Age'] > 48.168) & (dataset['Age'] <= 64.084), 'Age'] = 3\n", " #   dataset.loc[ dataset['Age'] > 64.084, 'Age']\n", " #   dataset['Age'] = dataset['Age'].astype(int)\n", "#train_df.head()"], "outputs": []}, {"metadata": {"_uuid": "0c6172f7ed301b5e7d0ecfa81cd61755970c0f22", "collapsed": true, "_cell_guid": "9134c3da-7b37-457b-918a-10fca5a82474"}, "execution_count": null, "cell_type": "code", "source": [], "outputs": []}, {"metadata": {"_uuid": "1b9d295e20834acd72d2ad8c861e34a77d1b7c0b", "collapsed": true, "_cell_guid": "b252f9f9-66c5-484c-a603-e839a4997ed6"}, "execution_count": null, "cell_type": "code", "source": ["test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n", "test_df.head()"], "outputs": []}, {"metadata": {"_uuid": "4bacfbb20ecf9982c1e243eb240762232b49cc0a", "collapsed": true, "_cell_guid": "6df24fb1-392e-422d-bb44-4685978f30f3"}, "execution_count": null, "cell_type": "code", "source": ["#now banding for fare\n", "#train_df['FareBand'] = pd.cut(train_df['Fare'], 4)\n", "#train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)"], "outputs": []}, {"metadata": {"_uuid": "d2ce4eabec2870aaee6ecf092faa06e40e1da5fe", "collapsed": true, "_cell_guid": "94976c06-663d-4bea-9561-dc722b6273d1"}, "execution_count": null, "cell_type": "code", "source": ["#for dataset in combine:    \n", "#    dataset.loc[ dataset['Fare'] <= 128.082, 'Fare'] = 0\n", "#    dataset.loc[(dataset['Fare'] > 128.082) & (dataset['Fare'] <= 256.165), 'Fare'] = 1\n", "#    dataset.loc[(dataset['Fare'] > 256.165) & (dataset['Fare'] <= 384.247), 'Fare'] = 2\n", "#    dataset.loc[ dataset['Fare'] > 384.247, 'Fare'] = 3\n", "#    dataset['Fare'] = dataset['Fare'].astype(int)\n", "#train_df.head()"], "outputs": []}, {"metadata": {"_uuid": "7292101e39495b56b687b53d406be31619a5512a", "collapsed": true, "_cell_guid": "c1281164-e854-45f5-9d6d-ce599783a6cb"}, "execution_count": null, "cell_type": "code", "source": ["#drop the 2 band column\n", "#train_df = train_df.drop(['FareBand','AgeBand'], axis=1)\n", "#combine = [train_df, test_df]"], "outputs": []}, {"metadata": {"_uuid": "ecc055dda94729e5753ffcf04a49f15290705dd3", "collapsed": true, "_cell_guid": "8fab7e1e-d51e-42d9-8008-eda65cf4db28"}, "execution_count": null, "cell_type": "code", "source": ["#Need to turn embarked into a number\n", "freq_port = train_df.Embarked.dropna().mode()[0]\n", "freq_port\n", "for dataset in combine:\n", "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n", "for dataset in combine:\n", "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n", "\n", "train_df.head()"], "outputs": []}, {"metadata": {"_uuid": "db0bf8bb9bddfb9367164d45e2b64fe18b11d35e", "collapsed": true, "_cell_guid": "ad50f509-cc78-4b51-a858-4c75651bab21"}, "execution_count": null, "cell_type": "code", "source": ["train_df.corr(method = 'pearson')"], "outputs": []}, {"metadata": {"_uuid": "2e4c5fc2165e62401e804013373f89f8bac46697", "collapsed": true, "_cell_guid": "46a3b990-5bd0-453e-b3bc-e9b1e3da8d8f"}, "execution_count": null, "cell_type": "code", "source": ["#Taking the above correlation matrix into account, remove PassengerID, Age, Sibsp, Parch\n", "train_df = train_df.drop(['PassengerId','Age','SibSp','Parch','Fare'], axis=1)\n", "combine = [train_df, test_df]\n"], "outputs": []}, {"metadata": {"_uuid": "a89e46823f0742a7783222cdf70c6f348dae561b", "collapsed": true, "_cell_guid": "f8647b10-7a8c-4026-8f96-8344b9cb9009"}, "execution_count": null, "cell_type": "code", "source": ["train_df.corr(method = 'pearson')"], "outputs": []}, {"metadata": {"_uuid": "4262431a968fd6966259ca02be29fc8b63020d8b", "collapsed": true, "_cell_guid": "8e810096-4a1a-4a2a-acf3-8526f36b76c4"}, "execution_count": null, "cell_type": "code", "source": ["#set up the data for the models\n", "X_train = train_df.drop(\"Survived\", axis=1)\n", "Y_train = train_df[\"Survived\"]\n", "X_test  = test_df.drop(['PassengerId','Age','SibSp','Parch','Fare'], axis=1).copy()\n", "X_train.shape, Y_train.shape, X_test.shape\n", "#print (X_train.head())"], "outputs": []}, {"metadata": {"_uuid": "de834e66079e95b9c3eba9be08543fd8dce55e9f", "collapsed": true, "_cell_guid": "b85d57db-7969-4f1b-8297-e1181d098890"}, "execution_count": null, "cell_type": "code", "source": ["test = SelectKBest(score_func=chi2, k=\"all\")\n", "fit = test.fit(X_train, Y_train)\n", "# summarize scores\n", "np.set_printoptions(precision=3)\n", "print(fit.scores_)\n", "features = fit.transform(X_train)\n", "# summarize selected features\n", "print(features[0:5,:])"], "outputs": []}, {"metadata": {"_uuid": "10559c1919ac7f1907d4c6bb1ea3ddbd9274fc4e", "collapsed": true, "_cell_guid": "5341b3c8-02b0-488b-91c2-8d046240a740"}, "execution_count": null, "cell_type": "code", "source": ["# Logistic Regression\n", "logreg = LogisticRegression()\n", "logreg.fit(X_train, Y_train)\n", "Y_pred = logreg.predict(X_test)\n", "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n", "acc_log"], "outputs": []}, {"metadata": {"_uuid": "e593b265abf51f87f4706127678296526f57f295", "collapsed": true, "_cell_guid": "ba284374-11fa-4e6e-9476-178966a9cb36"}, "execution_count": null, "cell_type": "code", "source": ["# Support Vector Machines\n", "svc = SVC()\n", "svc.fit(X_train, Y_train)\n", "Y_predSVM = svc.predict(X_test)\n", "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n", "acc_svc"], "outputs": []}, {"metadata": {"_uuid": "10b45783b0e4a44779e138da136e8cc0d6f0abba", "collapsed": true, "_cell_guid": "23ce6b15-3e39-4f14-800d-e254e439c3a2"}, "execution_count": null, "cell_type": "code", "source": ["\n", "\n", "knn = KNeighborsClassifier(n_neighbors = 3)\n", "knn.fit(X_train, Y_train)\n", "Y_pred = knn.predict(X_test)\n", "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n", "acc_knn\n", "\n"], "outputs": []}, {"metadata": {"_uuid": "a8085e8c1caea88aa11a80ae456bca9ef7d7ceb6", "collapsed": true, "_cell_guid": "f488c29e-835e-4878-8094-8d7c50dac0af"}, "execution_count": null, "cell_type": "code", "source": ["# Gaussian Naive Bayes\n", "\n", "gaussian = GaussianNB()\n", "gaussian.fit(X_train, Y_train)\n", "Y_pred = gaussian.predict(X_test)\n", "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n", "acc_gaussian"], "outputs": []}, {"metadata": {"_uuid": "fe7401c142e20fd64f2acf6b1ca2dfcbea8f7ddf", "collapsed": true, "_cell_guid": "5e2e3c87-d2aa-4d32-a459-bff27977fa1c"}, "execution_count": null, "cell_type": "code", "source": ["# Perceptron\n", "\n", "perceptron = Perceptron()\n", "perceptron.fit(X_train, Y_train)\n", "Y_pred = perceptron.predict(X_test)\n", "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n", "acc_perceptron"], "outputs": []}, {"metadata": {"_uuid": "77a5ae6e9be8d1ed1e06e35e38472576e0eea25f", "collapsed": true, "_cell_guid": "e7040cbd-19b9-47e6-8ac8-498a0e21793c"}, "execution_count": null, "cell_type": "code", "source": ["# Linear SVC\n", "\n", "linear_svc = LinearSVC()\n", "linear_svc.fit(X_train, Y_train)\n", "Y_pred = linear_svc.predict(X_test)\n", "acc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\n", "acc_linear_svc"], "outputs": []}, {"metadata": {"_uuid": "323e18e416176d2b3edeefc08300bbd763486eca", "collapsed": true, "_cell_guid": "c6e4c530-5c85-455b-96ae-abeecccd04ab"}, "execution_count": null, "cell_type": "code", "source": ["\n", "\n", "# Stochastic Gradient Descent\n", "\n", "sgd = SGDClassifier()\n", "sgd.fit(X_train, Y_train)\n", "Y_pred = sgd.predict(X_test)\n", "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n", "acc_sgd\n", "\n"], "outputs": []}, {"metadata": {"_uuid": "05ccee0995572f8b5ae9d6d65faf52693a032301", "collapsed": true, "_cell_guid": "798ba6d0-362b-421e-bc4b-f795fc9b50b5"}, "execution_count": null, "cell_type": "code", "source": ["\n", "\n", "# Decision Tree\n", "\n", "decision_tree = DecisionTreeClassifier()\n", "decision_tree.fit(X_train, Y_train)\n", "Y_pred = decision_tree.predict(X_test)\n", "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n", "acc_decision_tree\n", "\n"], "outputs": []}, {"metadata": {"_uuid": "f55a99048ba54fe6fbc7063fcf49ea5f1c1e891c", "collapsed": true, "_cell_guid": "568059d7-edb8-4ae1-82be-d205f9f156e9"}, "execution_count": null, "cell_type": "code", "source": ["# Random Forest\n", "\n", "random_forest = RandomForestClassifier(n_estimators=100)\n", "random_forest.fit(X_train, Y_train)\n", "Y_predRF = random_forest.predict(X_test)\n", "random_forest.score(X_train, Y_train)\n", "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n", "acc_random_forest"], "outputs": []}, {"metadata": {"_uuid": "945ef2f14ccf86c267f4eafc8a884fe47d744e60", "collapsed": true, "_cell_guid": "9c797921-ad36-4eb3-900a-b523ef3643f2"}, "execution_count": null, "cell_type": "code", "source": ["models = pd.DataFrame({\n", "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n", "              'Random Forest', 'Naive Bayes', 'Perceptron', \n", "              'Stochastic Gradient Decent', 'Linear SVC', \n", "              'Decision Tree'],\n", "    'Score': [acc_svc, acc_knn, acc_log, \n", "              acc_random_forest, acc_gaussian, acc_perceptron, \n", "              acc_sgd, acc_linear_svc, acc_decision_tree]})\n", "models.sort_values(by='Score', ascending=False)"], "outputs": []}, {"metadata": {"collapsed": true, "_uuid": "dcfdb8cea146ac2dc7269b35a58508e11cb452e2", "_kg_hide-output": true, "_cell_guid": "759ffefe-80a4-41fd-8340-713807ffd236"}, "execution_count": null, "cell_type": "code", "source": ["submission = pd.DataFrame({\n", "        \"PassengerId\": test_df[\"PassengerId\"],\n", "        \"Survived\": Y_predSVM\n", "    })\n", "\n", "#submission.head()\n", "submission.to_csv('submission.csv', index=False)\n"], "outputs": []}, {"metadata": {"_uuid": "df4cdd76ab1f9ff4ee59afada5629659c00dc398", "collapsed": true, "_cell_guid": "3a39fd14-e417-47f9-ab9e-f4c4e0ad441a"}, "execution_count": null, "cell_type": "code", "source": [], "outputs": []}], "nbformat": 4}