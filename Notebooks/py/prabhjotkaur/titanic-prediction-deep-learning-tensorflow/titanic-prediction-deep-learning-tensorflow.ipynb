{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\n\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')\n\ntrain_data = train_data.fillna(np.nan)\n# train_data.shape, test_data.shape\nindex_NaN_age = list(train_data[\"Age\"][train_data[\"Age\"].isnull()].index)\nfor i in index_NaN_age :\n    age_med = train_data[\"Age\"].median()\n    age_pred = train_data[\"Age\"][((train_data['SibSp'] == train_data.iloc[i][\"SibSp\"]) & (train_data['Parch'] == train_data.iloc[i][\"Parch\"]) & (train_data['Pclass'] == train_data.iloc[i][\"Pclass\"]))].median()\n    if not np.isnan(age_pred) :\n        train_data['Age'].iloc[i] = age_pred\n    else :\n        train_data['Age'].iloc[i] = age_med\nmin_fare = min(train_data[\"Age\"])\nmax_fare = max(train_data[\"Age\"])\ntrain_data[\"Age\"] = (train_data[\"Age\"]-min_fare)/(max_fare-min_fare)\ntrain_data[\"Embarked\"] = train_data[\"Embarked\"].fillna(\"S\")","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8997cfef6cfb1d24d343cf72a471575bea406a7f"},"cell_type":"code","source":"test_data = test_data.fillna(np.nan)\n# train_data.shape, test_data.shape\nindex_NaN_age = list(test_data[\"Age\"][test_data[\"Age\"].isnull()].index)\nfor i in index_NaN_age :\n    age_med = test_data[\"Age\"].median()\n    age_pred =test_data[\"Age\"][((test_data['SibSp'] == test_data.iloc[i][\"SibSp\"]) & (test_data['Parch'] == test_data.iloc[i][\"Parch\"]) & (test_data['Pclass'] == test_data.iloc[i][\"Pclass\"]))].median()\n    if not np.isnan(age_pred) :\n        test_data['Age'].iloc[i] = age_pred\n    else :\n        test_data['Age'].iloc[i] = age_med\nmin_fare = min(test_data[\"Age\"])\nmax_fare = max(test_data[\"Age\"])\ntest_data[\"Age\"] = (test_data[\"Age\"]-min_fare)/(max_fare-min_fare)\ntest_data[\"Embarked\"] = test_data[\"Embarked\"].fillna(\"S\")\n\ntrain_data[\"Ticket\"].isnull().sum()","execution_count":5,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"e8347b48f7f83b1179b7c754c5eddb744667c6e5"},"cell_type":"code","source":"guess_Fare = train_data.Fare.loc[ (train_data.Ticket == '3') & (train_data.Pclass == 3) & (train_data.Embarked == 'S')].median()\ntrain_data.Fare.fillna(guess_Fare , inplace=True)\n\nguess_Fare = test_data.Fare.loc[ (test_data.Ticket == '3') & (test_data.Pclass == 3) & (test_data.Embarked == 'S')].median()\ntest_data.Fare.fillna(guess_Fare , inplace=True)\n\ntrain_data['Fare-bin'] = pd.qcut(train_data.Fare,5,labels=[1,2,3,4,5]).astype(int)\ntest_data['Fare-bin'] = pd.qcut(test_data.Fare,5,labels=[1,2,3,4,5]).astype(int)\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94724f13d3afcda29b80935422fbbbf547ce96d0"},"cell_type":"code","source":"train_data['Ticket'] = train_data['Ticket'].map(lambda x: x[0])\ntrain_data[\"Ticket\"]= train_data['Ticket'].replace(['A','W','F','L','5','6','7','8','9'], '4')\n# train_data = pd.get_dummies(train_data, columns=[\"Ticket\"])\ntrain_data[:5]\ntest_data['Ticket'] = test_data['Ticket'].map(lambda x: x[0])\ntest_data[\"Ticket\"]= test_data['Ticket'].replace(['A','W','F','L','5','6','7','8','9'], '4')\ntrain_data[:5]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3fdd1eddefd61a0f15cef58acdc1a5d266c553f6"},"cell_type":"code","source":"train_data['Title'] = train_data.Name.map( lambda x: x.split(',')[1].split( '.' )[0].strip())\ntest_data['Title'] = test_data.Name.map( lambda x: x.split(',')[1].split( '.' )[0].strip())","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c1b258aa83af0042637474a3145009b75aaad59"},"cell_type":"code","source":"train_data['Title'] = train_data['Title'].replace('Mlle', 'Miss')\ntrain_data['Title'] = train_data['Title'].replace(['Mme','Lady','Ms'], 'Mrs')\ntrain_data.Title.loc[ (train_data.Title !=  'Master') & (train_data.Title !=  'Mr') & (train_data.Title !=  'Miss') \n             & (train_data.Title !=  'Mrs')] = 'Others'\n\ntest_data['Title'] = test_data['Title'].replace('Mlle', 'Miss')\ntest_data['Title'] = test_data['Title'].replace(['Mme','Lady','Ms'], 'Mrs')\ntest_data.Title.loc[ (test_data.Title !=  'Master') & (test_data.Title !=  'Mr') & (test_data.Title !=  'Miss') \n             & (test_data.Title !=  'Mrs')] = 'Others'","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e23f5e130959c7b5cfc98c6bfcdc9199926ff70"},"cell_type":"code","source":"train_data = pd.get_dummies(train_data, columns=[\"Ticket\"])\ntrain_data\ntest_data = pd.get_dummies(test_data, columns=[\"Ticket\"])\n\ntrain_data = pd.concat([train_data, pd.get_dummies(train_data['Title'])], axis=1).drop(labels=['Name'], axis=1)\ntest_data = pd.concat([test_data, pd.get_dummies(test_data['Title'])], axis=1).drop(labels=['Name'], axis=1)\ntest_data.shape","execution_count":10,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a1609de4bf37534b4725b31649d544e94b81d65"},"cell_type":"code","source":"train_data['Family'] = train_data['SibSp'] + train_data['Parch'] + 1\ntest_data['Family'] = test_data['SibSp'] + test_data['Parch'] + 1\ntrain_data[:5]","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97bf2484ae2a82b1a90a979780f113f96bea4fbe"},"cell_type":"code","source":"train_data = train_data.replace([\"male\", \"female\"], [0,1])\ntrain_data = train_data.replace([\"S\", \"C\", \"Q\"], [0,1,2])\ntrain_data = train_data.replace([\"NaN\"],[0])\nX = train_data[[\"Pclass\",\"Sex\",\"Age\",\"Family\",\"Fare-bin\",\"Embarked\",\"Ticket_1\",\"Ticket_2\",\"Ticket_3\",\"Ticket_4\",\"Ticket_C\",\"Ticket_P\",\"Ticket_S\",\"Master\",\"Miss\",\"Mr\",\"Mrs\",\"Others\"]]\nY = train_data[[\"Survived\"]]\n\nm1 = X.shape[0] #no of examples\n\nX_train = X[:m1-100]\nY_train = Y[:m1-100]\nX_test = X[m1-100: m1]\nY_test = Y[m1-100: m1]\n\ntest_data = test_data.replace([\"male\", \"female\"], [0,1])\ntest_data = test_data.replace([\"S\", \"C\", \"Q\"], [0,1,2])\nX_predict = test_data[[\"Pclass\",\"Sex\",\"Age\",\"Family\",\"Fare-bin\",\"Embarked\",\"Ticket_1\",\"Ticket_2\",\"Ticket_3\",\"Ticket_4\",\"Ticket_C\",\"Ticket_P\",\"Ticket_S\",\"Master\",\"Miss\",\"Mr\",\"Mrs\",\"Others\"]]\n\n\nX_train.shape, Y_train.shape, X_test.shape, Y_test.shape, X_predict.shape ","execution_count":12,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd4a2a1c6488a67bf5dca0a6a28ce2f15d237641"},"cell_type":"code","source":"X_train = X_train.transpose();\nY_train = Y_train.transpose();\nX_test = X_test.transpose();\nY_test = Y_test.transpose();\nX_predict = X_predict.transpose();\nX_train.shape, Y_train.shape, X_test.shape, Y_test.shape, X_predict.shape","execution_count":13,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bec4eb3dd9e51f935e303d30db582dff085fe471"},"cell_type":"code","source":"n_x = 18  #input units\nn_h1 = 40 #units in 1st hidden layer\nn_h2 = 20 #units in 2nd hidden layer\nn_h3 = 10 #units in 3rd hidden layer\nn_y = 1 #output units","execution_count":28,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"57f0e8775b78745ec2b1f357691bc4682cffde5b"},"cell_type":"code","source":"def create_placeholders(n_x, n_y):\n    X = tf.placeholder(tf.float32, [n_x, None], name = 'X')\n    Y = tf.placeholder(tf.float32, [n_y, None], name = 'Y')\n\n    return X,Y","execution_count":29,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c261f2e52c02cbab4d2815cb65cbb4272acd98b8"},"cell_type":"code","source":"def intialize_params():\n    W1 = tf.get_variable(\"W1\", [n_h1,n_x], initializer= tf.contrib.layers.xavier_initializer(seed=1) )\n    b1 = tf.get_variable(\"b1\", [n_h1, 1], initializer= tf.zeros_initializer())\n    W2 = tf.get_variable(\"W2\", [n_h2,n_h1], initializer= tf.contrib.layers.xavier_initializer(seed=1) )\n    b2 = tf.get_variable(\"b2\", [n_h2, 1], initializer= tf.zeros_initializer())\n    W3 = tf.get_variable(\"W3\", [n_h3,n_h2], initializer= tf.contrib.layers.xavier_initializer(seed=1) )\n    b3 = tf.get_variable(\"b3\", [n_h3, 1], initializer= tf.zeros_initializer())\n    W4 = tf.get_variable(\"W4\", [n_y,n_h3], initializer= tf.contrib.layers.xavier_initializer(seed=1) )\n    b4 = tf.get_variable(\"b4\", [n_y, 1], initializer= tf.zeros_initializer())\n    \n    parameters = {\n        \"W1\": W1,\n        \"b1\": b1,\n        \"W2\": W2,\n        \"b2\": b2,\n        \"W3\": W3,\n        \"b3\": b3,\n        \"W4\": W4,\n        \"b4\": b4\n    }\n    return parameters","execution_count":30,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"24cea8b9f442334f3cac8afc6a7886a1af442710"},"cell_type":"code","source":"def forward_prop(X, parameters, keep_prob):\n    W1 = parameters['W1']\n    b1 = parameters['b1']\n    W2 = parameters['W2']\n    b2 = parameters['b2']\n    W3 = parameters['W3']\n    b3 = parameters['b3']\n    W4 = parameters['W4']\n    b4 = parameters['b4']\n    \n    Z1 = tf.add(tf.matmul(W1, X), b1)\n    A1 = tf.nn.relu(Z1)\n     # apply DropOut to hidden layer\n    drop_out = tf.nn.dropout(A1, keep_prob)  # DROP-OUT here\n    Z2 = tf.add(tf.matmul(W2, drop_out), b2)\n    A2 = tf.nn.relu(Z2)\n    Z3 = tf.add(tf.matmul(W3, A2), b3)\n    A3 = tf.nn.relu(Z3)\n    Z4 = tf.add(tf.matmul(W4, A3), b4)\n    A4 = tf.sigmoid(Z4)\n    \n    return A4","execution_count":31,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"17c918703a765f4e6f726993b71478f262a62e82"},"cell_type":"code","source":"def compute_cost(A3, Y):\n    logits  = tf.transpose(A3)\n    labels = tf.transpose(Y) \n    \n    cost = tf.losses.mean_squared_error(labels=labels, predictions=logits)\n    \n    return cost","execution_count":32,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"99fa72ffa4ea3e60f64662cf83888b31d7592cdb"},"cell_type":"code","source":"def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.01, num_epochs = 2000, print_cost = True):\n    ops.reset_default_graph()\n    tf.set_random_seed(1)\n    seed=3\n    \n    [n_x, m] = X_train.shape\n    n_y = Y_train.shape[0]\n    \n    costs= []\n    \n    X, Y = create_placeholders(n_x, n_y)\n    \n    keep_prob = tf.placeholder(tf.float32)\n    \n    parameters = intialize_params()\n    \n    A3 = forward_prop(X, parameters, keep_prob)\n    \n    cost = compute_cost(A3, Y)\n    \n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n    \n    init = tf.global_variables_initializer()\n    \n    with tf.Session() as sess:\n        sess.run(init)\n        \n        for epoch in range(num_epochs):\n            epoch_cost = 0\n            _, epoch_cost = sess.run([optimizer, cost], feed_dict={X:X_train, Y: Y_train, keep_prob : 0.5})\n            # Print the cost every epoch\n            if print_cost == True and epoch % 100 == 0:\n                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n            if print_cost == True and epoch % 5 == 0:\n                costs.append(epoch_cost)\n                \n        plt.plot(np.squeeze(costs))\n        plt.ylabel('cost')\n        plt.xlabel('iterations (per tens)')\n        plt.title(\"Learning rate =\" + str(learning_rate))\n        plt.show()\n\n        parameters = sess.run(parameters)\n        \n        correct_prediction = tf.equal(tf.round(A3), Y)\n        \n        # Calculate accuracy on the test set\n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n\n        print(\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train, keep_prob : 1.0}))\n        print(\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test, keep_prob : 1.0}))\n        \n        return parameters","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09e9fd90dc088e96659590649f5193278f272e34"},"cell_type":"code","source":"parameters = model(X_train, Y_train, X_test, Y_test)","execution_count":34,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7419a4e1acbd1409b4904c827b344c4b1c275bb3"},"cell_type":"code","source":"def predict(X_predict, parameters):\n    X, Y = create_placeholders(n_x, n_y)\n    keep_prob = tf.placeholder(tf.float32)\n    Y_pred = tf.cast(tf.round(forward_prop(X, parameters, keep_prob)), tf.int32) \n    init = tf.global_variables_initializer()\n    with tf.Session() as sess:\n        sess.run(init)\n        Y_pred = sess.run(Y_pred, feed_dict={X:X_predict, keep_prob:1.0})        \n    return Y_pred ","execution_count":36,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9d59ceb320ea0cdcf6635e19dcb94a50b293b5e"},"cell_type":"code","source":"predictions = predict(X_predict, parameters)\npredictions.shape","execution_count":37,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5d47483b2fbaac11b8a03c1b8aad72852fd750af"},"cell_type":"code","source":"index = test_data[\"PassengerId\"]\npredictions = predictions.transpose().reshape(test_data[\"PassengerId\"].shape)\nsubmission = pd.DataFrame({\n        \"PassengerId\": test_data[\"PassengerId\"],\n        \"Survived\": predictions\n    })","execution_count":38,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6500f08a916eb53eff5bb4be1259c112c8e6526d"},"cell_type":"code","source":"# submission.to_csv('./output/submission.csv', index=False)","execution_count":40,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"952f4b63a232dbf000692ec0ca46f88e3e0d6c39"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}