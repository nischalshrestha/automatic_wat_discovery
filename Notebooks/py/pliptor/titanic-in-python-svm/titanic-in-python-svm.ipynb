{"cells":[{"metadata":{"_uuid":"5e8be8e2e574a81d8ccf48d9bb5e31d62aacb53a"},"cell_type":"markdown","source":"# Titanic in Python SVM\n\nThis notebook investigates working with the Titanic set using only the **Age, Sex, Pclass, and Embarked** features for prediction. \n\nThis is a supporting kernel for this other [**kernel**](https://www.kaggle.com/pliptor/how-am-i-doing-with-my-score). The goal is not the score maximization but to investigate the problem using a reduced number of features.\n\n1. [Reading data](#read_data)\n2. [Data preparation](#preparation)\n3. [Modeling](#modeling)\n4. [Predicting and creating a submission file](#submission)\n\n[Conclusions](#conclusions)\n\n"},{"metadata":{"_uuid":"f5813f8afef53d767f2fcc7db8348749f3b0f3f9"},"cell_type":"markdown","source":"# 1) Reading data <a class=\"anchor\" id=\"read_data\"></a>\n\nWe will only read the relevant columns of the data. It will keep the data clean and prevent any accidental leakage of other features into our setup."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"3bd2508a07abf6d92940ff1f3cba585b291dbfd5"},"cell_type":"code","source":"import pandas as pd\nimport numpy  as np\n\nnp.random.seed(2018)\n\nfeature_names = ['Age','Pclass','Embarked','Sex']\n\n# load data sets \ntrain = pd.read_csv('../input/train.csv', usecols =['Survived','PassengerId'] + feature_names)\ntest  = pd.read_csv('../input/test.csv',  usecols =['PassengerId'] + feature_names )\n\n# combine train and test for joint processing \ntest['Survived'] = np.nan\ncomb = pd.concat([ train, test ])\ncomb.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ec267fe2476697b593d85eb0af09fa9f7d59043"},"cell_type":"markdown","source":"# 2) Data preparation <a class=\"anchor\" id=\"preparation\"></a>  \n\nLet's first fix two missing values in Embarked. We note here the final result is not impacted with a choice for the filling value ('S','C','Q'). This is probably because altering two rows is not sufficient to change the model's statistics in a significant manner."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"f8ba11ef4ea6d8dd7da61029341851cfa66a67b6"},"cell_type":"code","source":"print('Number of missing Embarked values ',comb['Embarked'].isnull().sum())\ncomb['Embarked'] = comb['Embarked'].fillna('S')\ncomb['Embarked'].unique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"583c142459b666a9a8cb1261eb4d64f6ae3598ca"},"cell_type":"markdown","source":"## 2.1) Age\n\nWe follow the same strategy in the [**divide and conquer kernel**](https://www.kaggle.com/pliptor/divide-and-conquer-0-82296). The idea is to discard most of the Age data and keep just what seems to matter the most (young folks had priority). We also create an indicator flag for those that had no Age data available."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"8c4c632e6487634e388afe594181edcac633968a"},"cell_type":"code","source":"comb['NoAge'] = comb['Age'] == np.NAN\ncomb['Age'] =  comb['Age'].fillna(-1)\ncomb['Age'].hist(bins=100)\ncomb['Minor'] = (comb['Age']<14.0)&(comb['Age']>=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51f42746b4fe09cf6705fdb53c7ed5e74a159c74"},"cell_type":"markdown","source":"## 2.2) One-hot and Label encode\n\nWhile we could use sklearn to perform one-hot and label encoding, we will do these tasks manually since there are only a couple of features to be treated."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"5e751b6343ab89cb15998d6944e2b5bd535f5836"},"cell_type":"code","source":"# one-hot encode Pclass\ncomb['P1'] = comb['Pclass'] == 1 \ncomb['P2'] = comb['Pclass'] == 2\ncomb['P3'] = comb['Pclass'] == 3\n\n# one-hot encode Embarked\ncomb['ES'] = comb['Embarked'] == 'S' \ncomb['EQ'] = comb['Embarked'] == 'Q'\ncomb['EC'] = comb['Embarked'] == 'C'","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"f935c92ee6223c7640b89232645c93d66fb542c7"},"cell_type":"code","source":"# Label encode Sex\ncomb['Sex'] = comb['Sex'].map({'male':0,'female':1})\n\n# drop Pclass, Embarked and Age features\ncomb = comb.drop(columns=['Pclass','Embarked','Age'])\ncomb.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ebfdf38c984525646ff686e03c725aa5d935615"},"cell_type":"markdown","source":"Now we split back comb as we are done pre-processing."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"4aea9534f239fcf4e3a59377d4afa9d9aa060bbd"},"cell_type":"code","source":"df_train = comb.loc[comb['Survived'].isin([np.nan]) == False]\ndf_test  = comb.loc[comb['Survived'].isin([np.nan]) == True]\n\nprint(df_train.shape)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"f4811222d3bb5f570c9840a3ffa17e01949abdbb"},"cell_type":"code","source":"print(df_test.shape)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"edbe1baa93f8219cc7efc2f50c85962116de7856"},"cell_type":"markdown","source":"We are now ready for modeling!"},{"metadata":{"_uuid":"43ca693a56939b1fa8487303ac2e805c90c3123b"},"cell_type":"markdown","source":"# 3) Modeling <a class=\"anchor\" id=\"modeling\"></a>\n\nWe will use support vector machine (SVM) in classification mode for the model and use GridSearchCV to tune it."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"0fe0ff574f75fc976f7c50c3058825e7b246d975"},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"5597b24815a6d27efbdc8701f112973d5bd57510"},"cell_type":"code","source":"feature_names = ['Sex','P1','P2','P3','EQ','ES','EC','NoAge','Minor']\n\nfrom sklearn.svm import SVC\nmodel = SVC()\nparam_grid = {'C':[1,2,5,10,20,50]} \ngrs = GridSearchCV(model, param_grid=param_grid, cv = 10, n_jobs=1, return_train_score = False)\ngrs.fit(np.array(df_train[feature_names]), np.array(df_train['Survived']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3d0537397ea426b183b55a8b53418e4dc0d4bc1"},"cell_type":"markdown","source":"Now that the tuning is completed, we print the best parameter found and also the estimated accuracy for the unseen data.  "},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"8ea27a72019012bb4b20dbd5dccefd613a6df79c"},"cell_type":"code","source":"print(\"Best parameters \" + str(grs.best_params_))\ngpd = pd.DataFrame(grs.cv_results_)\nprint(\"Estimated accuracy of this model for unseen data:{0:1.4f}\".format(gpd['mean_test_score'][grs.best_index_]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81c4f87fa5f85c887162b1593ad2dee4b94ccd18"},"cell_type":"markdown","source":"# 4) Predicting and creating a submission file<a class=\"anchor\" id=\"submission\"></a>"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"153fd857ac7a17b19e24538f7b33e0e4751eb39c"},"cell_type":"code","source":"pred = grs.predict(np.array(df_test[feature_names]))\n\nsub = pd.DataFrame({'PassengerId':df_test['PassengerId'],'Survived':pred})\nsub.to_csv('AgeSexPclassEmbarked.csv', index = False, float_format='%1d')\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a6d85722a93cfd1c833cf3f4f462686ab0670f3"},"cell_type":"markdown","source":"# Conclusions <a class=\"anchor\" id=\"conclusions\"></a>\n\nWe tackled the Titanic problem using only the **Age, Sex, Embarked and Pclass** features. You should get a public score of **0.78947**. It is argued in [**this kernel**](https://www.kaggle.com/pliptor/how-am-i-doing-with-my-score) that the public score is about 2% lower than cross validation estimates for unseen data when the model heavily relies on the Gender and Pclass features. This kernel supports the findings. The cross validation for unseen data is 0.8249.\n\nWe also note this kernel is similar to [**this kernel**](https://www.kaggle.com/pliptor/minimalistic-titanic-in-python-lightgbm) but with the Age feature added. The addition of the Age feature improved the public score by about 0.01 from **0.77990** to **0.78947**.\n\nThanks for reading this kernel and let me know if you have any questions or comments!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}