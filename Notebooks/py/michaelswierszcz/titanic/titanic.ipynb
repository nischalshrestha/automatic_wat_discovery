{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c7de0572-7083-68ba-2405-68664b6f7c67"
      },
      "source": [
        "# 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3a2379c0-22b4-d155-ae59-9ce12959a8df"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "\n",
        "from statsmodels.graphics.mosaicplot import mosaic\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor   \n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "train = pd.read_csv(\"../input/titanic/train.csv\")\n",
        "test = pd.read_csv(\"../input/titanic/test.csv\")\n",
        "combined = pd.concat((train,test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b7176246-c6f8-df73-05a9-5bcbeb475ae8"
      },
      "source": [
        "# 2. Diving Into The Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b7d17e3b-2b92-ce53-0336-4410b13282c2"
      },
      "outputs": [],
      "source": [
        "print(train.shape)\n",
        "print(test.shape)\n",
        "print(combined.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d63bb9c3-b7b3-f036-1fdb-29d6b5779590"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "40b0505c-54e1-9503-8894-4cc7d5de6083"
      },
      "outputs": [],
      "source": [
        "train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7ecc5338-25ee-7d42-33a6-672419f951a5"
      },
      "outputs": [],
      "source": [
        "print(train.isnull().sum())\n",
        "print(test.isnull().sum())\n",
        "print(combined.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2252c56f-a50e-edb2-9a98-06019f5d7f5f"
      },
      "outputs": [],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "77924ab6-947c-71b9-b347-1e3d4b852e84"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 4))\n",
        "mosaic(train,[\"Survived\",'Sex','Pclass'], axes_label = False, ax=ax)\n",
        "\n",
        "plt.figure(figsize=[12,8])\n",
        "plt.subplot(231)\n",
        "sns.barplot('Sex', 'Survived', data=train)\n",
        "plt.subplot(232)\n",
        "sns.barplot('Pclass', 'Survived', data=train)\n",
        "plt.subplot(233)\n",
        "sns.barplot('Pclass', 'Survived', hue = 'Sex', data=train)\n",
        "plt.subplot(234)\n",
        "sns.barplot('Parch', 'Survived', data=train)\n",
        "plt.subplot(235)\n",
        "sns.barplot('SibSp', 'Survived', data=train)\n",
        "plt.subplot(236)\n",
        "sns.barplot('Embarked', 'Survived', data=train)\n",
        "\n",
        "fig, axes = plt.subplots(1,3, figsize=(12, 4))\n",
        "tab = pd.crosstab(combined['Embarked'], combined['Pclass'])\n",
        "tab.div(tab.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, ax=axes[0])\n",
        "tab = pd.crosstab(combined['Embarked'], combined['Sex'])\n",
        "tab.div(tab.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, ax=axes[1])\n",
        "tab = pd.crosstab(combined['Pclass'], combined['Sex'])\n",
        "tab.div(tab.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, ax=axes[2])\n",
        "\n",
        "plt.figure(figsize=[12,4])\n",
        "plt.hist([train.loc[(train['Survived'])==1, 'Age'].dropna(), \\\n",
        "          train.loc[(train['Survived'])==0, 'Age'].dropna()], \\\n",
        "          bins = 40, histtype='stepfilled', stacked=True, label=['Survived','Died'])\n",
        "plt.legend()\n",
        "\n",
        "age_bin = pd.cut(train['Age'], np.linspace(train['Age'].min(), train['Age'].max(), 41))\n",
        "age_grouped = train['Survived'].groupby(age_bin).mean()\n",
        "\n",
        "plt.figure(figsize=[12,4])\n",
        "plt.plot(np.linspace(0,80,40), age_grouped, color='purple', label='Total')\n",
        "plt.legend()\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Survival Percentage')\n",
        "\n",
        "male_age_bin = pd.cut(train.loc[(train['Sex'] == 'male'),'Age'],\\\n",
        "\tnp.linspace(train['Age'].min(), train['Age'].max(), 41))\n",
        "male_age_grouped = train.loc[(train['Sex'] == 'male'),'Survived']\\\n",
        ".groupby(male_age_bin).mean()\n",
        "\n",
        "female_age_bin = pd.cut(train.loc[(train['Sex'] == 'female'),'Age'],\\\n",
        "\tnp.linspace(train['Age'].min(), train['Age'].max(), 41))\n",
        "female_age_grouped = train.loc[(train['Sex'] == 'female'),'Survived']\\\n",
        ".groupby(female_age_bin).mean()\n",
        "\n",
        "plt.figure(figsize=[12,4])\n",
        "ax = plt.axes()\n",
        "ax.plot(np.linspace(0,80,40),female_age_grouped, color='red', label='Female')\n",
        "ax.plot(np.linspace(0,80,40),male_age_grouped, color='blue', label='Male')\n",
        "plt.legend()\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Survival Percentage')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "78f4ff95-a58e-504f-0daa-2138b8b5a79b"
      },
      "outputs": [],
      "source": [
        "survival_percentage = round(train.pivot_table('Survived', index='Sex', columns='Pclass', \n",
        "                                              margins=True),3) * 100\n",
        "print(f'Total Survival Percentage: {survival_percentage.iloc[2,3]}% \\n'\n",
        "\tf'Female Survival Percentage: {survival_percentage.iloc[0,3]}% \\n'\n",
        "\tf'Male Survival Percentage: {survival_percentage.iloc[1,3]}%')\n",
        "print(survival_percentage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fd26a72b-e9bc-e26b-a7cd-22ebd8e6e4ce"
      },
      "source": [
        "# 3. Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8525aacc-d817-6049-7eea-87da5690c76f"
      },
      "outputs": [],
      "source": [
        "# Changed the Sex category from two different strings to a binary number\n",
        "# Replaced Sex with Male to be more clear\n",
        "# Created a list of dummy variables in order to represent the categorical Embarked data\n",
        "# Dropped 'Cabin' and 'Ticket' as they were very incomplete, difficult to estimate, and most likely \\\n",
        "# very collinear with the other features. That being said, it would have been interesting to model \\\n",
        "# the survival rate by level in the ship that the cabin resided in.\n",
        "# Lastly the PassengerId was made into an explicit Index in order to better manipulate the data \\\n",
        "# across the three different sets of data; train, test, combined.\n",
        "\n",
        "le = LabelEncoder()\n",
        "combined['Sex'] = le.fit_transform(combined['Sex'])\n",
        "combined = combined.rename(columns={'Sex':'Male'})\n",
        "combined = pd.concat([combined, pd.get_dummies(combined['Embarked'])],axis=1)\n",
        "combined = combined.drop(['Cabin', 'Ticket', 'Embarked'], 1)\n",
        "combined.set_index('PassengerId',drop=True,inplace=True)\n",
        "train.set_index('PassengerId',drop=True,inplace=True)\n",
        "train = combined.loc[train.index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4071445a-37f8-a004-5718-732257da07b2"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(figsize=(11,9))\n",
        "plt.title(\"Pearson Correlation of Features\", y=1.02, size=15)\n",
        "sns.heatmap(train.drop(['Name'],1).corr(),vmax=.6,cmap=\"RdBu_r\",annot=True, square=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "92e8d9bd-351c-ff69-64fb-e12efa850e9e"
      },
      "outputs": [],
      "source": [
        "# Vectorized the string data in the Name category in order to extract the titles of the different \\\n",
        "# passengers.\n",
        "# Then the data was sorted and manually inspected to pick titles out of the top 60 words\n",
        "\n",
        "vec = CountVectorizer()\n",
        "words = vec.fit_transform(combined['Name'])\n",
        "names = pd.DataFrame(words.toarray(), columns=vec.get_feature_names())\n",
        "print(names.sum().sort_values(ascending=False).head(60))\n",
        "names.set_index(combined.index, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "466083f3-c7b5-67fc-ef5b-a6df0efa13b8"
      },
      "outputs": [],
      "source": [
        "# Used a boolean mask to remove the most common titles from the data \n",
        "# Inspected the remaining data to extract the lesser known titles\n",
        "\n",
        "mask = (names['master']==0) & (names['rev']==0) & (names['dr']==0) & (names['mrs']==0) & \\\n",
        "       (names['miss']==0) & (names['mr']==0)\n",
        "print(combined[mask]['Name'])\n",
        "print(combined[mask]['Name'].count())\n",
        "print(combined[~(mask)]['Name'].count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cd317659-d1e9-9219-ee4f-35d5eaf386e1"
      },
      "outputs": [],
      "source": [
        "# Removed all the columns that were not passenger titles\n",
        "# Searched for all passengers with more than one title (due to pseudonyms). If the title was two of \\\n",
        "# the same, it was corrected to be one. If the titles were differed, the real title was chosen to be \\\n",
        "# the official and the pseudonym was discarded\n",
        "\n",
        "names = names[['master','mr','miss','mrs','dr','rev','don','mme','ms','major','mlle','col','capt',\n",
        " 'countess','jonkheer','dona']]\n",
        "print(names.sum().sum())\n",
        "print(names[names.sum(1)>1])\n",
        "names.loc[(names['mr']>1),'mr'] = 1\n",
        "names.loc[(names.sum(1)>1),'miss'] = 1\n",
        "names.loc[(names.sum(1)>1),'mlle'] = 0\n",
        "names.loc[(names.sum(1)>1),'mrs'] = 0\n",
        "print(names[names.sum(1)>1])\n",
        "print(names.sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "578a7882-fb73-caf4-a396-327032f2d98a"
      },
      "outputs": [],
      "source": [
        "# Since there were 16 titles, many of which encompassed only a single digit amount of passengers, \\\n",
        "# the titles were changed to their closest equivalent. The remaining titles were \\\n",
        "# miss, mrs, master, and mr\n",
        "\n",
        "print(names.sum())\n",
        "names.loc[(names['ms'])==1,'miss'] = 1\n",
        "names.loc[(names['ms'])==1,'ms'] = 0\n",
        "names.loc[(names['mme'])==1,'mrs'] = 1                         \n",
        "names.loc[(names['mme'])==1,'mme'] = 0\n",
        "names.loc[(names['mlle'])==1,'miss'] = 1\n",
        "names.loc[(names['mlle'])==1,'mlle'] = 0\n",
        "names.loc[(names['jonkheer'])==1,'mr'] = 1\n",
        "names.loc[(names['jonkheer'])==1,'jonkheer'] = 0\n",
        "names.loc[(names['countess'])==1,'mrs'] = 1\n",
        "names.loc[(names['countess'])==1,'countess'] = 0\n",
        "names.loc[(names['don'])==1,'mr'] = 1\n",
        "names.loc[(names['don'])==1,'don'] = 0\n",
        "names.loc[(names['dona'])==1,'mrs'] = 1\n",
        "names.loc[(names['dona'])==1,'dona'] = 0\n",
        "names.loc[(names['col'])==1,'mr'] = 1\n",
        "names.loc[(names['col'])==1,'col'] = 0\n",
        "names.loc[(names['major'])==1,'mr'] = 1\n",
        "names.loc[(names['major'])==1,'major'] = 0\n",
        "names.loc[(names['capt'])==1,'mr'] = 1\n",
        "names.loc[(names['capt'])==1,'capt'] = 0\n",
        "names.loc[(names['dr'])==1,'mr'] = 1\n",
        "names.loc[(names['dr'])==1,'dr'] = 0\n",
        "names.loc[(names['rev'])==1,'mr'] = 1\n",
        "names.loc[(names['rev'])==1,'rev'] = 0\n",
        "print(names.sum())\n",
        "print(names.sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d09d42d8-816d-f2b7-e9f6-13f6a2346d21"
      },
      "outputs": [],
      "source": [
        "names = names[['master','mr','miss','mrs']]\n",
        "combined = combined.drop(['Name'],1)\n",
        "combined = pd.concat([combined,names],axis=1)\n",
        "train = combined.loc[train.index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4c32e61a-824a-77e4-6f0b-5cfb9b1a2bc7"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(figsize=(12,10))\n",
        "plt.title(\"Pearson Correlation of Features\", y=1.02, size=15)\n",
        "sns.heatmap(train.corr(),vmax=.6,cmap=\"RdBu_r\",annot=True,fmt='.2f',square=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f67dd04b-50ab-180a-d7f2-b34fac18d4d3"
      },
      "outputs": [],
      "source": [
        "print(train.groupby([train['mr'],train['miss'],train['mrs'],train['master']])['Survived'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bcaa07fb-f1eb-50ec-22a8-5901cb0eaba4"
      },
      "outputs": [],
      "source": [
        "# Empty Age entries were estimated by median age of the Pclass that the passenger belonged to.\n",
        "# This assumption/step could have been even more precise but the expected differences made the payoff \\\n",
        "# low\n",
        "\n",
        "print(train.isnull().any())\n",
        "print(train.isnull().sum())\n",
        "\n",
        "combined.loc[(combined['Pclass'])==3,'Age'] = combined.loc[(combined['Pclass'])==3,'Age']\\\n",
        ".fillna(combined.loc[(combined['Pclass'])==3,'Age'].median())\n",
        "combined.loc[(combined['Pclass'])==2,'Age'] = combined.loc[(combined['Pclass'])==2,'Age']\\\n",
        ".fillna(combined.loc[(combined['Pclass'])==2,'Age'].median())\n",
        "combined.loc[(combined['Pclass'])==1,'Age'] = combined.loc[(combined['Pclass'])==1,'Age']\\\n",
        ".fillna(combined.loc[(combined['Pclass'])==1,'Age'].median())\n",
        "train = combined.loc[train.index]\n",
        "\n",
        "print(train.isnull().any())\n",
        "print(train.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4868d685-6984-2747-2ad2-faf286c7066a"
      },
      "source": [
        "# 4. Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b9d3ba4e-bc54-a0ca-83cb-dbe35d6401e1"
      },
      "outputs": [],
      "source": [
        "X = train.drop(['Survived'],1)\n",
        "y = train.Survived"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "57390363-a5f7-b453-e705-46088c8b9164"
      },
      "outputs": [],
      "source": [
        "lreg = LogisticRegression()\n",
        "lreg_yhat= lreg.fit(X, y).predict(X)\n",
        "\n",
        "lreg_sas = accuracy_score(y, lreg_yhat)\n",
        "lreg_cv5s = cross_val_score(lreg, X, y, cv=5, n_jobs=-1).mean()\n",
        "lreg_l1os = cross_val_score(lreg, X, y, cv=LeaveOneOut().split(X), n_jobs=-1).mean()\n",
        "print('Self Accuracy Score : {}'.format(lreg_sas))\n",
        "print('CV5 Score : {}'.format(lreg_cv5s))\n",
        "print('CVLeave1Out Score : {}'.format(lreg_l1os))\n",
        "\n",
        "lreg_pvsa_survival = np.column_stack((cross_val_predict(lreg, X, y, cv=5, n_jobs=-1), y))\n",
        "print('Predicted Survival : {}'.format(lreg_pvsa_survival[:,0].mean()))\n",
        "print('Actual Survival : {}'.format(lreg_pvsa_survival[:,1].mean()))\n",
        "print(classification_report(y, lreg_pvsa_survival[:,0], target_names=['dead','notdead']))\n",
        "\n",
        "cm = confusion_matrix(y,lreg_pvsa_survival[:,0])\n",
        "ax = plt.axes()\n",
        "sns.heatmap(cm, ax=ax, fmt='d', square=True, annot=True, vmin=0)\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('Actual')\n",
        "ax.set_title('LREG - Survival - Confusion Matrix')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f444b49f-cced-f509-243b-632c4ce80472"
      },
      "outputs": [],
      "source": [
        "# Logistic regression is susceptible to multicolinearity and since I wanted to study the weight of \\\n",
        "# the coefficients I decided to remove all features that had high VIF scores\n",
        "# The new coefficients more accuratly display the true weights\n",
        "\n",
        "print(pd.DataFrame(list(zip(X.columns, np.transpose(lreg.fit(X, y).coef_)))))\n",
        "\n",
        "def calculate_vif_(X, thresh=5.0):\n",
        "    variables = list(range(X.shape[1]))\n",
        "    dropped=True\n",
        "    while dropped:\n",
        "        dropped=False\n",
        "        vif = [variance_inflation_factor(X[variables].values, ix) for ix in \\\n",
        "               range(X[variables].shape[1])]\n",
        "\n",
        "        maxloc = vif.index(max(vif))\n",
        "        if max(vif) > thresh:\n",
        "            print('dropping \\'' + X[variables].columns[maxloc] + '\\' at index: ' + str(maxloc))\n",
        "            del variables[maxloc]\n",
        "            dropped=True\n",
        "\n",
        "    print('Remaining variables:')\n",
        "    print(X.columns[variables])\n",
        "    return X[variables]\n",
        "#credit to SpanishBoy & Prashant on stackexchange\n",
        "\n",
        "Xdelta = calculate_vif_(X)\n",
        "print(pd.DataFrame(list(zip(Xdelta.columns, np.transpose(lreg.fit(Xdelta, y).coef_)))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d905c531-5693-a666-0eea-c85adef1683c"
      },
      "outputs": [],
      "source": [
        "gnb = GaussianNB()\n",
        "gnb_yhat = gnb.fit(X, y).predict(X)\n",
        "\n",
        "gnb_sas = accuracy_score(y, gnb_yhat)\n",
        "gnb_cv5s = cross_val_score(gnb, X, y, cv=5, n_jobs=-1).mean()\n",
        "gnb_l1os = cross_val_score(gnb, X, y, cv=LeaveOneOut().split(X), n_jobs=-1).mean()\n",
        "print('Self Accuracy Score : {}'.format(gnb_sas))\n",
        "print('CV5 Score : {}'.format(gnb_cv5s))\n",
        "print('CVLeave1Out Score : {}'.format(gnb_l1os))\n",
        "\n",
        "gnb_pvsa_survival = np.column_stack((cross_val_predict(gnb, X, y, cv=5 , n_jobs=-1), y))\n",
        "print('Predicted Survival : {}'.format(gnb_pvsa_survival[:,0].mean()))\n",
        "print('Actual Survival : {}'.format(gnb_pvsa_survival[:,1].mean()))\n",
        "print(classification_report(y, gnb_pvsa_survival[:,0], target_names=['dead','notdead']))\n",
        "\n",
        "cm = confusion_matrix(y,gnb_pvsa_survival[:,0])\n",
        "ax = plt.axes()\n",
        "sns.heatmap(cm, ax=ax, fmt='d', square=True, annot=True, vmin=0)\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('Actual')\n",
        "ax.set_title('GNB - Survival - Confusion Matrix')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c16d48b0-fad2-9219-6c01-afe5243bf53c"
      },
      "outputs": [],
      "source": [
        "lsvc = SVC(kernel='linear', C=1)\n",
        "lsvc_yhat= lsvc.fit(X, y).predict(X)\n",
        "\n",
        "lsvc_sas = accuracy_score(y, lsvc_yhat)\n",
        "lsvc_cv5s = cross_val_score(lsvc, X, y, cv=5, n_jobs=-1).mean()\n",
        "lsvc_l1os = cross_val_score(lsvc, X, y, cv=LeaveOneOut().split(X), n_jobs=-1).mean()\n",
        "print('Self Accuracy Score : {}'.format(lsvc_sas))\n",
        "print('CV5 Score : {}'.format(lsvc_cv5s))\n",
        "print('CVLeave1Out Score : {}'.format(lsvc_l1os))\n",
        "\n",
        "lsvc_pvsa_survival = np.column_stack((cross_val_predict(lsvc, X, y, cv=5, n_jobs=-1), y))\n",
        "print('Predicted Survival : {}'.format(lsvc_pvsa_survival[:,0].mean()))\n",
        "print('Actual Survival : {}'.format(lsvc_pvsa_survival[:,1].mean()))\n",
        "print(classification_report(y, lsvc_pvsa_survival[:,0], target_names=['dead','notdead']))\n",
        "\n",
        "cm = confusion_matrix(y,lsvc_pvsa_survival[:,0])\n",
        "ax = plt.axes()\n",
        "sns.heatmap(cm, ax=ax, fmt='d', square=True, annot=True, vmin=0)\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('Actual')\n",
        "ax.set_title('LSVC - Survival - Confusion Matrix')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8fba4792-253a-ce7b-2bf9-ef81811ae108"
      },
      "outputs": [],
      "source": [
        "rfc = RandomForestClassifier()\n",
        "rfc_yhat = rfc.fit(X, y).predict(X)\n",
        "\n",
        "rfc_sas = accuracy_score(y, rfc_yhat)\n",
        "rfc_cv5s = cross_val_score(rfc, X, y, cv=5, n_jobs=-1).mean()\n",
        "rfc_l1os = cross_val_score(rfc, X, y, cv=LeaveOneOut().split(X), n_jobs=-1).mean()\n",
        "print('Self Accuracy Score : {}'.format(rfc_sas))\n",
        "print('CV5 Score : {}'.format(rfc_cv5s))\n",
        "print('CVLeave1Out Score : {}'.format(rfc_l1os))\n",
        "\n",
        "rfc_pvsa_survival = np.column_stack((cross_val_predict(rfc, X, y, cv=5, n_jobs=-1), y))\n",
        "print('Predicted Survival : {}'.format(rfc_pvsa_survival[:,0].mean()))\n",
        "print('Actual Survival : {}'.format(rfc_pvsa_survival[:,1].mean()))\n",
        "print(classification_report(y, rfc_pvsa_survival[:,0], target_names=['dead','notdead']))\n",
        "\n",
        "cm = confusion_matrix(y,rfc_pvsa_survival[:,0])\n",
        "ax = plt.axes()\n",
        "sns.heatmap(cm, ax=ax, fmt='d', square=True, annot=True, vmin=0)\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('Actual')\n",
        "ax.set_title('RFC - Survival - Confusion Matrix')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1bc8230b-9e1f-2b68-72d9-c0c16e130d9b"
      },
      "outputs": [],
      "source": [
        "bc = BaggingClassifier()\n",
        "bc_yhat = bc.fit(X,y).predict(X)\n",
        "\n",
        "bc_sas = accuracy_score(y, bc_yhat)\n",
        "bc_cv5s = cross_val_score(bc, X, y, cv=5, n_jobs=-1).mean()\n",
        "bc_l1os = cross_val_score(bc, X, y, cv=LeaveOneOut().split(X), n_jobs=-1).mean()\n",
        "print('Self Accuracy Score : {}'.format(bc_sas))\n",
        "print('CV5 Score : {}'.format(bc_cv5s))\n",
        "print('CVLeave1Out Score : {}'.format(bc_l1os))\n",
        "\n",
        "bc_pvsa_survival = np.column_stack((cross_val_predict(bc, X, y, cv=5, n_jobs=-1), y))\n",
        "print('Predicted Survival : {}'.format(bc_pvsa_survival[:,0].mean()))\n",
        "print('Actual Survival : {}'.format(bc_pvsa_survival[:,1].mean()))\n",
        "print(classification_report(y, bc_pvsa_survival[:,0], target_names=['dead','notdead']))\n",
        "\n",
        "cm = confusion_matrix(y,bc_pvsa_survival[:,0])\n",
        "ax = plt.axes()\n",
        "sns.heatmap(cm, ax=ax, fmt='d', square=True, annot=True, vmin=0)\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('Actual')\n",
        "ax.set_title('BC - Survival - Confusion Matrix')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "24ed60f1-d646-538c-bd46-1ee3ab183797"
      },
      "outputs": [],
      "source": [
        "gbc = GradientBoostingClassifier()\n",
        "gbc_yhat = gbc.fit(X,y).predict(X)\n",
        "\n",
        "gbc_sas = accuracy_score(y, gbc_yhat)\n",
        "gbc_cv5s = cross_val_score(gbc, X, y, cv=5, n_jobs=-1).mean()\n",
        "gbc_l1os = cross_val_score(gbc, X, y, cv=LeaveOneOut().split(X), n_jobs=-1).mean()\n",
        "print('Self Accuracy Score : {}'.format(gbc_sas))\n",
        "print('CV5 Score : {}'.format(gbc_cv5s))\n",
        "print('CVLeave1Out Score : {}'.format(gbc_l1os))\n",
        "\n",
        "gbc_pvsa_survival = np.column_stack((cross_val_predict(gbc, X, y, cv=5, n_jobs=-1), y))\n",
        "print('Predicted Survival : {}'.format(gbc_pvsa_survival[:,0].mean()))\n",
        "print('Actual Survival : {}'.format(gbc_pvsa_survival[:,1].mean()))\n",
        "print(classification_report(y, gbc_pvsa_survival[:,0], target_names=['dead','notdead']))\n",
        "\n",
        "cm = confusion_matrix(y,gbc_pvsa_survival[:,0])\n",
        "ax = plt.axes()\n",
        "sns.heatmap(cm, ax=ax, fmt='d', square=True, annot=True, vmin=0)\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('Actual')\n",
        "ax.set_title('GBC - Survival - Confusion Matrix')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1cce694d-5dc6-a3e5-ef7e-aba2c5d434ee"
      },
      "outputs": [],
      "source": [
        "vote = VotingClassifier(estimators=[('lreg', lreg), ('gbc', gbc), ('bc', bc), ('rfc', rfc), \n",
        "\t('lsvc', lsvc), ('gnb', gnb)], voting='hard')\n",
        "vote_yhat = vote.fit(X,y).predict(X)\n",
        "\n",
        "vote_sas = accuracy_score(y, vote_yhat)\n",
        "vote_cv5s = cross_val_score(vote, X, y, cv=5, n_jobs=-1).mean()\n",
        "vote_l1os = cross_val_score(vote, X, y, cv=LeaveOneOut().split(X), n_jobs=-1).mean()\n",
        "print('Self Accuracy Score : {}'.format(vote_sas))\n",
        "print('CV5 Score : {}'.format(vote_cv5s))\n",
        "print('CVLeave1Out Score : {}'.format(vote_l1os))\n",
        "\n",
        "vote_pvsa_survival = np.column_stack((cross_val_predict(vote, X, y, cv=5, n_jobs=-1), y))\n",
        "print('Predicted Survival : {}'.format(vote_pvsa_survival[:,0].mean()))\n",
        "print('Actual Survival : {}'.format(vote_pvsa_survival[:,1].mean()))\n",
        "print(classification_report(y, vote_pvsa_survival[:,0], target_names=['dead','notdead']))\n",
        "\n",
        "cm = confusion_matrix(y,vote_pvsa_survival[:,0])\n",
        "ax = plt.axes()\n",
        "sns.heatmap(cm, ax=ax, fmt='d', square=True, annot=True, vmin=0)\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('Actual')\n",
        "ax.set_title('GBC - Survival - Confusion Matrix')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "44f7c680-8ccf-6b04-8c9a-ded0cef3d484"
      },
      "source": [
        "# 5. Prediction and Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1282d167-228b-7f59-2f46-b30c9abeac2f"
      },
      "outputs": [],
      "source": [
        "gbc_scores = ['gbc', gbc_sas, gbc_cv5s, gbc_l1os, gbc_pvsa_survival[:,0].mean()]\n",
        "bc_scores = ['bc', bc_sas, bc_cv5s, bc_l1os, bc_pvsa_survival[:,0].mean()]\n",
        "lreg_scores = ['lreg', lreg_sas, lreg_cv5s, lreg_l1os, lreg_pvsa_survival[:,0].mean()]\n",
        "rfc_scores = ['rfc', rfc_sas, rfc_cv5s, rfc_l1os, rfc_pvsa_survival[:,0].mean()]\n",
        "lsvc_scores = ['lsvc', lsvc_sas, lsvc_cv5s, lsvc_l1os, lsvc_pvsa_survival[:,0].mean()]\n",
        "gnb_scores = ['gnb', gnb_sas, gnb_cv5s, gnb_l1os, gnb_pvsa_survival[:,0].mean()]\n",
        "vote_scores = ['vote', vote_sas, vote_cv5s, vote_l1os, vote_pvsa_survival[:,0].mean()]\n",
        "\n",
        "classifier_comparison = pd.DataFrame([gbc_scores, bc_scores, lreg_scores, rfc_scores, \n",
        "\tlsvc_scores, gnb_scores, vote_scores], columns=['Classifier','SAS','CV5S','L1OS',\n",
        "\t'Predicted Survival'])\n",
        "print(classifier_comparison)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "31f0ce2e-bebb-f2c4-cff1-9b5b4bd94837"
      },
      "outputs": [],
      "source": [
        "# Reindexed the test dataframe, and used the mean fare for the Pclass that the missing fare value \\\n",
        "# was in. \n",
        "\n",
        "test.set_index('PassengerId',drop=True,inplace=True)\n",
        "test = combined.loc[test.index]\n",
        "Xtest = test.drop(['Survived'],1)\n",
        "Xtest.loc[(Xtest['Fare'].isnull()), 'Fare'] = \\\n",
        "combined.loc[(Xtest.loc[(Xtest['Fare'].isnull()), 'Pclass']), 'Fare'].mean()\n",
        "test_gbc_yhat = gbc.fit(X,y).predict(Xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f7c436ed-47eb-cb09-f7a2-95362fae291d"
      },
      "outputs": [],
      "source": [
        "submit = pd.DataFrame(list(zip(test.index, test_gbc_yhat)), columns = ['PassengerId', 'Survived'])\n",
        "submit.to_csv(\"../working/submit.csv\", index=False)\n",
        "print(submit.tail())\n",
        "print(submit.Survived.mean())"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}