{"cells":[{"metadata":{"_uuid":"4c1a441b813f911b5ebe44baa7135c33bc870322"},"cell_type":"markdown","source":"Load in our Titanic data:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\ntitanic_full_train = pd.read_csv('../input/train.csv')\ntitanic_test = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af5e5792e0a95cb70e2612137ee519aedca23353"},"cell_type":"markdown","source":"Start with looking at the data."},{"metadata":{"trusted":true,"_uuid":"b6f38c777699aed3db5bfa3c1118ed6fab951c32"},"cell_type":"code","source":"titanic_full_train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0257d93e29fc6a0c358607ce2a270e5004b8f091"},"cell_type":"code","source":"titanic_full_train.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d5f7d79b1a58259a806628152f07fde268fe894"},"cell_type":"markdown","source":"Items to note regarding the data:\n- We are missing values for Age, Cabin, and Embarked\n    - Embarked is only missing two values\n    - Age is missing 177 values\n    - Cabin only has 204 of the 891 values\n- Pclass only has values of 1, 2, or 3\n- Sex only has values of 'male' or 'female'\n- SibSp and Parch are the counts of siblings/spouses and parents/children on board, respectively, and are predominantly zero\n- Embarked only has values of C, Q, and S\n    "},{"metadata":{"_uuid":"4e5637bd4b62b5d6178eb80cbde8f0316e51da2b"},"cell_type":"markdown","source":"Now let's look at some plots of the data:"},{"metadata":{"trusted":true,"_uuid":"15583e5b0933bc64b1be5805dbcd019345f66651"},"cell_type":"code","source":"fields = ['Survived', 'Age', 'Fare', 'Parch', 'SibSp', 'Pclass']\ntitanic_full_train[fields].hist(bins=25, figsize=(20,15))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e75e97ed7d9b3e3c202e4489b44afd67f98a6240"},"cell_type":"markdown","source":"Items to note from the plots:\n- regarding age, most people are in their twenties, but there are a number of small children as well\n- the majority of fares are very low, with few larger fares\n- most had no parents/children on board, but there were some\n- there were more in third class than first and second\n- most had no siblings or spouses, but there were some (decent number of 1 - probably spouses?)\n- the survival rate was not very good"},{"metadata":{"trusted":true,"_uuid":"36f216e1601bd10dfe4dd7e1defd6fa062fc02bf"},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\nfrom sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\nfrom sklearn.impute import SimpleImputer\n\ntitanic_y = titanic_full_train.Survived\nclf = GradientBoostingClassifier()\ntitanic_X_colns = ['PassengerId', 'Age', 'Fare',]\ntitanic_X = titanic_full_train[titanic_X_colns]\nmy_imputer = SimpleImputer()\nimputed_titanic_X = my_imputer.fit_transform(titanic_X)\n\nclf.fit(imputed_titanic_X, titanic_y)\ntitanic_plots = plot_partial_dependence(clf, features=[1,2], X=imputed_titanic_X, \n                                        feature_names=titanic_X_colns, grid_resolution=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"760a65d6b7d4ebb51a29a0d9da75e54dfc96ca0f"},"cell_type":"markdown","source":"From the above plots, survival chances increased for the young (women and children got off the boat first?) and those with higher fares also had increased survival chances (closer to lifeboats?)."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e89f6584d0c6b3263603bb5f9fdccb634384fe82"},"cell_type":"code","source":"y = titanic_full_train.Survived\nX = titanic_full_train.drop(['Survived'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1cf7b2801b0a07e9589330e1dc92d1c34b7468a5"},"cell_type":"markdown","source":"Clean the data and prepare for modeling.  Remove the fields we aren't using.\n\nI will remove Name and Ticket, as these won't be included in the model.  I will also remove Cabin, because there are so many missing values."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9ce953e122e38fa12fb301697daec008b1d3bf9d"},"cell_type":"code","source":"X = X.drop(['Name', 'Ticket', 'Cabin'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2e7acb110a0faef958ceee4ae3513ca207e9dd39"},"cell_type":"code","source":"#use one-hot encoding for categoricals (Sex, Embarked) using get_dummies\nOHE_X = pd.get_dummies(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"356406a55bb716807d73010bf843957c5d5210c5"},"cell_type":"code","source":"#review the data we now have\nOHE_X.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"186588f77be9e9ee7bcf89937710cd921eec2a94"},"cell_type":"markdown","source":"We now have indicator variables for each value of Sex and Embarked, rather than text.\nAnd all of our data is numerical now."},{"metadata":{"_uuid":"9a24e50651b0d23875f4cc1b8ab41fe168b85acc"},"cell_type":"markdown","source":"For Age, there are a number of missing values, but this variable appears to be important, so we will impute the missing values so we can use this element in the model."},{"metadata":{"trusted":true,"_uuid":"5611841f1dcd7c2487834899b9180a481703c146","collapsed":true},"cell_type":"code","source":"#keep track of what was imputed\nX_plus = OHE_X.copy()\n\ncols_with_missing = (col for col in OHE_X.columns \n                                 if OHE_X[col].isnull().any())\nfor col in cols_with_missing:\n    X_plus[col + '_was_missing'] = X_plus[col].isnull()\n\nX_plus = my_imputer.fit_transform(X_plus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"54409ae469c10eaab806bf9a327c9b882334b662"},"cell_type":"code","source":"#split the data into training and testing data\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_plus,\n                                                    y, \n                                                    train_size=0.7,\n                                                    test_size=0.3,\n                                                    random_state=0,\n                                                    stratify = y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d48b2ff50ade7729d3375e69f028d7dc696b1d3"},"cell_type":"code","source":"#try random forest\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\nrf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b43818fa5f9d8b958fbeb51f4978c3745abaa119"},"cell_type":"code","source":"#try XGBoost\n\nfrom xgboost import XGBClassifier\n\nxgb = XGBClassifier()\nxgb.fit(X_train, y_train)\nxgb.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4b5a1f3ce07c496560cf201a838360e16ff6cf0"},"cell_type":"code","source":"#try logistic regression\n\nfrom sklearn.linear_model import LogisticRegression\n\nlg = LogisticRegression()\nlg.fit(X_train, y_train)\nlg.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9aadb4ccb96e8ca0129da2ba44256ed16ddc42c5"},"cell_type":"code","source":"#try randomized search cv\n\nimport xgboost as xgb\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Create the parameter grid: gbm_param_grid \ngbm_param_grid = {\n    'n_estimators': range(8, 20),\n    'max_depth': range(6, 10),\n    'learning_rate': [.4, .45, .5, .55, .6],\n    'colsample_bytree': [.6, .7, .8, .9, 1]\n}\n\ngbm = XGBClassifier(n_estimators=10)\n\nxgb_random = RandomizedSearchCV(param_distributions=gbm_param_grid, \n                                    estimator = gbm, scoring = \"accuracy\", \n                                    verbose = 1, n_iter = 50, cv = 4)\n\nX = np.concatenate([X_train, X_test], axis=0)\ny = np.concatenate([y_train, y_test], axis=0)\nxgb_random.fit(X, y)\n\nprint(\"Best parameters found: \", xgb_random.best_params_)\nprint(\"Best accuracy found: \", xgb_random.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"698c35d6be98f77191037c73e62199a5a0a6a324","collapsed":true},"cell_type":"code","source":"# Treat the test data in the same way as training data:\n# use OHE, then impute and track imputed values\nOHE_X_submit = pd.get_dummies(titanic_test)\nOHE_X, OHE_X_submit = OHE_X.align(OHE_X_submit,\n                                  join='inner', \n                                  axis=1)\n\nOHE_X_submit_plus = OHE_X_submit.copy()\ncols_with_missing = (col for col in OHE_X.columns \n                                 if OHE_X[col].isnull().any())\nfor col in cols_with_missing:\n    OHE_X_submit_plus[col + '_was_missing'] = OHE_X_submit_plus[col].isnull()\nOHE_X_submit_plus = my_imputer.transform(OHE_X_submit_plus)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b7ba4dca142e925477ecbea70ea0f1dc71bb1a4d"},"cell_type":"code","source":"# Use the model to make predictions\nxgb_pred = xgb_random.predict(OHE_X_submit_plus)\nsubmission = pd.concat([titanic_test.PassengerId, pd.DataFrame(xgb_pred)], axis = 'columns')\nsubmission.columns = [\"PassengerId\", \"Survived\"]\nsubmission.to_csv('titanic_submit.csv', header=True, index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}