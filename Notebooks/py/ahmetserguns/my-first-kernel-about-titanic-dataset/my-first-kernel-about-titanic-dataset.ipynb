{"cells":[{"metadata":{"trusted":true,"collapsed":true,"_uuid":"353e2617e8f702fdf11e527656501c2987cf7fa4"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler,LabelEncoder,RobustScaler,MinMaxScaler,Normalizer\nfrom sklearn.metrics import accuracy_score,confusion_matrix, classification_report\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV, StratifiedKFold, learning_curve\n\nfrom speedml import Speedml","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6451d5ec2ba8742191f0ee7623b907596017f843"},"cell_type":"code","source":"train_dataset=pd.read_csv(\"../input/train.csv\")\ntest_dataset=pd.read_csv(\"../input/test.csv\")\ndatasets=[train_dataset,test_dataset]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2ce52a22bed7d508ec9441b549458767b74c1f6"},"cell_type":"code","source":"train_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7561ed64504323dfff85372cc68c7a3fc1bc94d"},"cell_type":"code","source":"for dataset in datasets: # datasets : 1st train_dataset, 2nd test_dataset\n    total = dataset.isnull().sum().sort_values(ascending=False)\n    percent_1 = dataset.isnull().sum()/dataset.isnull().count()*100\n    percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n    print(missing_data.head(5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6228232766c5a441494b25b452e3d86f59eadfc2"},"cell_type":"markdown","source":"# DATA PROCESSING"},{"metadata":{"trusted":true,"_uuid":"5607b4cab8f78a34ef6a7dc9d1f3bed48bb61e8c","collapsed":true},"cell_type":"code","source":"\ndef clean_data(dataset):\n    \n    \n    #------ Embarked---------------\n    dataset[\"Embarked\"]=dataset[\"Embarked\"].fillna(\"S\")\n    \n    #-------------Fare-------------\n    dataset.loc[dataset.Fare==0, \"Fare\"]=\"NaN\" # Fare'e str değeri atadığımız için artık object'e dönüştü!!\n    dataset[\"Fare\"]=dataset[\"Fare\"].astype(float) # Fare datasını yeniden float'a çeviriyoruz ki aritmetik hesaplamalar yapılabilelim\n    dataset[\"Fare\"].fillna(dataset.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\n \n    #-------------Name-------------\n    dataset['Title'] = dataset['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]   \n    \n    #-------------Age-------------\n    \n    dataset[\"Age\"].fillna(dataset.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\n    #dataset['Age'] = dataset['Age'].astype(int)\n    #-------------Title-------------\n    dataset['Title'].replace(['Mlle','Mme','Ms',\"Capt\",\"Col\",\"Don\",\"Jonkheer\",\"Rev\",\"Major\",\"Dr\",\"Lady\",\"Sir\",\"the Countess\"],\n                               [\"Miss\",\"Miss\",\"Mrs\",\"Mr\",\"Mr\",\"Mr\",\"Mr\",\"Mr\",\"Mr\",\"Mr\",\"Loyal\",\"Loyal\",\"Loyal\"],inplace=True)\n    \n    #-------------Cabin-------------\n    #dataset['Cabin'].fillna('U', inplace=True)\n    #dataset['Cabin'] = dataset['Cabin'].apply(lambda x: x[0])\n    \n    #import re\n    #deck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n    #dataset['Cabin'] = dataset['Cabin'].fillna(\"U0\")\n    #dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n    #dataset['Deck'] = dataset['Deck'].map(deck)\n    #dataset['Deck'] = dataset['Deck'].fillna(0)\n    #dataset['Deck'] = dataset['Deck'].astype(int)\n \n    dataset.drop(['Cabin'], axis=1,inplace = True)\n        \n   #-------------Age-------------\n    #bins = [0, 11, 18, 22, 28, 33, 40, 66,100]\n    #group_names = ['0-11', '12-18', '19-22', '20-28','28-33',\"34-40\",\"41-66\",\"67-100\" ]\n    #dataset['AgeScala'] = pd.cut(train_dataset['Age'], bins, labels=group_names)\n    #dataset[\"AgeScala\"]=pd.qcut(train_dataset[\"Age\"], 7).value_counts()\n   \n    #dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n    #dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n    #dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n    #dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n    #dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n    #dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n    #dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n    #dataset.loc[ dataset['Age'] > 66, 'Age'] = 7\n    #dataset['Age'] = dataset['Age'].astype(int)\n    #\n    #dataset.loc[ dataset['Fare'] <= 7.775, 'Fare'] = 0\n    #dataset.loc[(dataset['Fare'] > 7.75) & (dataset['Fare'] <= 8.7), 'Fare'] = 1\n    #dataset.loc[(dataset['Fare'] > 8.7) & (dataset['Fare'] <= 14.454), 'Fare']   = 2\n    #dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 26), 'Fare']   = 3\n    #dataset.loc[(dataset['Fare'] > 26) & (dataset['Fare'] <= 52), 'Fare']   = 4\n    #dataset.loc[ dataset['Fare'] > 52, 'Fare'] = 5\n    #dataset['Fare'] = dataset['Fare'].astype(int)\n\n    #-------------Alone or Not-------------\n    #dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n    #dataset.loc[dataset['relatives'] > 0, 'alone'] = 0\n    #dataset.loc[dataset['relatives'] == 0, 'alone'] = 1\n    #dataset['alone'] = dataset['alone'].astype(int)  \n    \n    dataset['Age_Class']= dataset['Age']*dataset['Pclass']\n    \nif __name__==\"__main__\":\n    clean_data(train_dataset)\n    clean_data(test_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8d093fd009859f9846800ece06b985cbce492620"},"cell_type":"code","source":"#---- Silinecek değişkenler-------\ndrop_column = ['PassengerId', 'Ticket', 'Name']\ntrain_dataset.drop(drop_column, axis=1, inplace = True)\ndrop_column_ = ['Ticket', 'Name']\ntest_dataset.drop(drop_column_,axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"17ef49c649f0029093fa3fb67671cbbe63500464"},"cell_type":"code","source":"#train_dataset.to_csv('deneme.csv',index=True,header=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"415d989e29a4f1c2ddce7eeebe2238e205a4d84e","collapsed":true},"cell_type":"code","source":"columns_=[\"Age\",\"Fare\",\"Title\",\"Deck\",\"Pclass\",\"SibSp\",\"Parch\",\"Sex\",\"Age_Class\",\"Embarked\"]   \ncolumns__=[\"Sex\",\"Embarked\",\"Title\",\"Age_Class\"]\n\nfor dataset in datasets:\n    for i in columns__:\n        dataset[i] = LabelEncoder().fit_transform(dataset[i])  # dönüşüm\n      \n    #for j in columns_:\n    #    dataset[j]=dataset[j].astype(float)   # int to float dönüşüm uyarısını almamak için\n    \n    #for k in columns_:\n       \n    #    dataset[k] = StandardScaler().fit_transform(dataset[k].values.reshape(-1, 1))  # dönüşüm\n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba631aff87d92c0b6be1b4cd1f43b9a2b46737b3"},"cell_type":"code","source":"train_dataset.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f7b912cc5d824aa1601abce4e00b9f1c56792de"},"cell_type":"code","source":"test_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"227c2b6b1c7ef6c4350046203df77eb97cbb42f5"},"cell_type":"markdown","source":"# MODEL CALCULATIONS"},{"metadata":{"trusted":true,"_uuid":"031d6bb1e6e05ac8d952190baf16f372b379e2f2","collapsed":true},"cell_type":"code","source":"variables_=[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked\",\"Title\",\"Age_Class\"]\n\nfeatures=train_dataset[variables_].values\n\ntarget=train_dataset[\"Survived\"].values\n\nx_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f406656a529f38824daa5f42d4b8a3d2aa05085a"},"cell_type":"code","source":"y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab68548c1be2993cc5858edef15d636e23853679"},"cell_type":"code","source":"# train_dataset.corr()\nf,ax = plt.subplots(figsize=(5, 5))\nsns.heatmap(train_dataset.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4b95ffbdc6d0462269344aa48e62711f2c2038df"},"cell_type":"code","source":" \n#Ensemble Methods\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom xgboost import XGBClassifier\n\n#Gaussian Processes\nfrom sklearn.gaussian_process import GaussianProcessClassifier   \n\n#GLM\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.linear_model import RidgeClassifierCV\n#from sklearn.linear_model import SGDClassifier\n#from sklearn.linear_model import Perceptron\n\n#Navies Bayes\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.naive_bayes import GaussianNB\n\n#Nearest Neighbor\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#Tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\n\n#Discriminant Analysis\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\n# Support Vector\nfrom sklearn import svm\n\n\n#Neural Network\nfrom sklearn.neural_network import MLPClassifier\n\n\n#===========================================================================================================================\n\nmodels = []\n\n#Ensemble Methods\nmodels.append((\"AdaBoostClassifier\", AdaBoostClassifier))\nmodels.append((\"BaggingClassifier\", BaggingClassifier))\nmodels.append((\"RandomForestClassifier\", RandomForestClassifier))\nmodels.append((\"GradientBoostingClassifier\",  GradientBoostingClassifier))\nmodels.append((\"XGBClassifier\",  XGBClassifier))\n\n\n#Gaussian Processes\nmodels.append((\"GaussianProcessClassifier\",  GaussianProcessClassifier))\n\n#GLM\n#models.append((\"LinearRegression\", LinearRegression))\nmodels.append((\"LogisticRegression\", LogisticRegression))\n#models.append((\"LogisticRegressionCV\", LogisticRegressionCV))\n#models.append((\"PassiveAggressiveClassifier\",  PassiveAggressiveClassifier))\nmodels.append((\"RidgeClassifierCV\",  RidgeClassifierCV))\n#models.append((\"SDK\",  SGDClassifier))\n#models.append((\"PERS\",  Perceptron))\n\n#Navies Bayes\nmodels.append((\"BernoulliNB\",  BernoulliNB))\nmodels.append((\"GaussianNB\",  GaussianNB))\n\n#Nearest Neighbor\nmodels.append((\"KNeighborsClassifier\", KNeighborsClassifier))\n\n#Tree\nmodels.append((\"DecisionTreeClassifier\", DecisionTreeClassifier))              \nmodels.append((\"ExtraTreesClassifier\", ExtraTreesClassifier))               \n\n#Discriminant Analysis\nmodels.append((\"LinearDiscriminantAnalysis\", LinearDiscriminantAnalysis))\nmodels.append((\"QuadraticDiscriminantAnalysis\", QuadraticDiscriminantAnalysis))\n\n# Support Vector\n#models.append((\"Support Vector Regression\", svm))\n\n#Neural network\n#models.append((\"MLPClassifier\", MLPClassifier))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c04bd7e62ed61b47a7c762f8f96174fcbfe53eef"},"cell_type":"code","source":"aim_score= 0.80         # determine success rate exam: 0.80\n\nfor description in models:\n    short_name, model_name = description\n    classifier = model_name()\n\n    classifier.fit(x_train, y_train)             # eğitim\n    y_pred = classifier.predict(x_test)          # tahmin\n    score = accuracy_score(y_test, y_pred)       # tahmin ile test için ayrılan set karşılaştırılıyor\n    #score1 = classifier.score(x_test, y_test)\n    \n    # cv'de belirtilen deneme sonrasında accuracy sonucunun ne olduğunu ölçüyoruz. Böylece ilk başta çok başarılı gibi\n    # görünen modellerin gerçek değerlerine ulaşmış oluyoruz.\n    #scores.mean()\n        \n    if score > aim_score:\n            conf_matrix_ = confusion_matrix(y_test,y_pred)\n            true_answer=conf_matrix_[0][0]+conf_matrix_[1][1]\n            wrong_answer=conf_matrix_[0][1]+conf_matrix_[1][0]\n            total=true_answer+wrong_answer\n            scores=model_selection.cross_val_score(classifier, features, target, scoring=\"accuracy\", cv=5)\n            print(classification_report(y_test, y_pred))\n            print(\"{} --> {:.2f} --> {:.2f} --> Total: {} ~ True: {}  \".format(short_name, score, scores.mean(), total,true_answer))\n            print(\"--------------------\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"987a76687d34fbf0645ce61ffc5341d20476e4b2"},"cell_type":"markdown","source":"# Building Machine Learning Models (after try=50)"},{"metadata":{"_uuid":"eb5992ef33fca0c629e14fad10a0a7068f76fc83"},"cell_type":"markdown","source":"işlemcisine güvenen cv değerini artırabilir."},{"metadata":{"trusted":true,"_uuid":"0c4b59d6d5fe50a86f0ca893825e634e30166359"},"cell_type":"code","source":"gradient=GradientBoostingClassifier()\ngradient.fit(x_train,y_train)\nY_pred=gradient.predict(x_test)\nacc_gradinet=round(gradient.score(x_train, y_train)*100,2)\nprint(acc_gradinet)\nscore_gradinet=model_selection.cross_val_score(gradient, features, target, scoring=\"accuracy\", cv=50)\nprint(\"After try: {}\".format(round(score_gradinet.mean()*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ad6c2d4e9cc96a09b24515ac8f01a8dcdcfbab1"},"cell_type":"code","source":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(x_train, y_train) \nY_pred = decision_tree.predict(x_test)\nacc_decision_tree = round(decision_tree.score(x_train, y_train)*100,2)\nprint(acc_decision_tree)\nscore_decision_tree=model_selection.cross_val_score(decision_tree, features, target, scoring=\"accuracy\", cv=50)\nprint(\"After try: {}\".format(round(score_decision_tree.mean()*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15f2e6613883aacbc40d0abc7010addcce34b20a"},"cell_type":"code","source":"XG=XGBClassifier()\nXG.fit(x_train,y_train)\nY_pred=XG.predict(x_test)\nacc_XGBC=round(XG.score(x_train, y_train)*100,2)\nprint(acc_XGBC)\nscore_XGBC=model_selection.cross_val_score(XG, features, target, scoring=\"accuracy\", cv=50)\nprint(\"After try: {}\".format(round(score_XGBC.mean()*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e71d6e65299c0e04e603fcf7947964b3a3dfb427"},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn import linear_model\nsgd = linear_model.SGDClassifier(max_iter=5, tol=None)\nsgd.fit(x_train, y_train)\nY_pred = sgd.predict(x_test)\nsgd.score(x_train, y_train)\nacc_sgd = round(sgd.score(x_train, y_train) * 100, 2)\nprint(acc_sgd)\nscore_sgd=model_selection.cross_val_score(sgd, features, target, scoring=\"accuracy\", cv=50)\nprint(\"After try: {}\".format(round(score_sgd.mean()*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c26bb4f95ba4cbd0d902b0a067887e445f57a5ec"},"cell_type":"code","source":"logreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\nY_pred = logreg.predict(x_test)\nacc_log = round(logreg.score(x_train, y_train) * 100, 2)\nprint(acc_log)\nscore_log=model_selection.cross_val_score(logreg, features, target, scoring=\"accuracy\", cv=50)\nprint(\"After try: {}\".format(round(score_log.mean()*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"208d3a60c0e24680844f9956c973f1e1cbb970e3"},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(x_train, y_train) \nY_pred = knn.predict(x_test)\nacc_knn = round(knn.score(x_train, y_train) * 100, 2)\nprint(acc_knn)\nscore_knn=model_selection.cross_val_score(knn, features, target, scoring=\"accuracy\", cv=50)\nprint(\"After try: {}\".format(round(score_knn.mean()*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b39bb56d98919e83c471f9deedc6d4d51758e7a"},"cell_type":"code","source":"gaussian = GaussianNB()\ngaussian.fit(x_train, y_train) \nY_pred = gaussian.predict(x_test) \nacc_gaussian = round(gaussian.score(x_train, y_train) * 100, 2)\nprint(acc_gaussian)\nscore__gaussian=model_selection.cross_val_score(gaussian, features, target, scoring=\"accuracy\", cv=50)\nprint(\"After try: {}\".format(round(score__gaussian.mean()*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b05c121e8a7225ac7fdea871a6b67a72e0132e6c"},"cell_type":"code","source":"from sklearn.linear_model import Perceptron\nperceptron = Perceptron(max_iter=5)\nperceptron.fit(x_train, y_train)\nY_pred = perceptron.predict(x_test)\nacc_perceptron = round(perceptron.score(x_train, y_train) * 100, 2)\nprint(acc_perceptron)\nscore_perceptron=model_selection.cross_val_score(perceptron, features, target, scoring=\"accuracy\", cv=50)\nprint(\"After try:{}\".format(round(score_perceptron.mean()*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4f1eeda3925306d38abed12a27933317efec65c"},"cell_type":"code","source":"decision_tree = DecisionTreeClassifier()\ndecision_tree.fit(x_train, y_train)\nY_pred = decision_tree.predict(x_test) \nacc_decision_tree = round(decision_tree.score(x_train, y_train) * 100, 2)\nprint(acc_decision_tree)\nscore_decision_tree_svc=model_selection.cross_val_score(decision_tree, features, target, scoring=\"accuracy\", cv=50)\nprint(\"After try: {}\".format(round(score_decision_tree.mean()*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b79144677256114a30d9070826c6d4a5abe95cea"},"cell_type":"markdown","source":"# Random Forest"},{"metadata":{"trusted":true,"_uuid":"cc191d6e75d7987be7627de8ad8513c5998d82ea"},"cell_type":"code","source":"random_forest = RandomForestClassifier(n_estimators=100,oob_score = True)\nrandom_forest.fit(x_train, y_train)\nY_prediction = random_forest.predict(x_test)\nrandom_forest.score(x_train, y_train)\nacc_random_forest = round(random_forest.score(x_train, y_train) * 100, 2)\nprint(acc_random_forest)\nscore_random_forest=model_selection.cross_val_score(random_forest, features, target, scoring=\"accuracy\", cv=50)\nprint(\"After try: {}\".format(round(score_random_forest.mean()*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a0775831fa21b992c1a3009aea99d7b821dd4c5"},"cell_type":"code","source":"print(\"oob score:\", round(random_forest.oob_score_, 4)*100, \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5cdb81f0bcd9614d1553d6f93803cecd2bce908"},"cell_type":"code","source":"random_forest = RandomForestClassifier(criterion = \"gini\", \n                                       min_samples_leaf = 1, \n                                       min_samples_split = 10,   \n                                       n_estimators=100, \n                                       max_features='auto', \n                                       oob_score=True, \n                                       random_state=1, \n                                       n_jobs=-1)\n\nrandom_forest.fit(x_train, y_train)\nY_prediction = random_forest.predict(x_test)\n\nrandom_forest.score(x_train, y_train)\n\nprint(\"oob score:\", round(random_forest.oob_score_, 4)*100, \"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6635ff689d9b1b0982e1865a44e86c18e4ed99a"},"cell_type":"code","source":"from sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import confusion_matrix\npredictions = cross_val_predict(random_forest, x_train, y_train, cv=3)\nconfusion_matrix(y_train, predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ecedd85913b5e8acfc59cd63e41330358ec161c"},"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score,f1_score\n\nprint(\"Precision\\t:\", round(precision_score(y_train, predictions)*100,2))\nprint(\"Recall\\t:\",round(recall_score(y_train, predictions)*100,2))\nprint(\"f1 score\\t:\", round(f1_score(y_train, predictions)*100,2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"edede796909c1e6471cb1b5f5019855b7620d9a2"},"cell_type":"code","source":"#Apply our prediction to test data\n#predictions = gradient.predict(test_dataset[variables_])\n\n# Create a new dataframe with only the columns Kaggle wants from the dataset\n#submission_DFs = pd.DataFrame({ \n#    \"PassengerId\" : test_dataset[\"PassengerId\"],\n#    \"Survived\" : predictions\n    })\n#print(submission_DFs.head(2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a09e2de34696083558f087c986d6322a37a1a4eb"},"cell_type":"code","source":"# prepare file for submission\n#submission_DFs.to_csv(\"submission_gradient.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5c9279fcb173bd2350505d81d37793cbec08dbb0"},"cell_type":"code","source":"# Only for XGRB\n#Apply our prediction to test data\n#predictionx = XG.predict(test_dataset[variables_].as_matrix())\n\n# Create a new dataframe with only the columns Kaggle wants from the dataset\n#submission_DFx = pd.DataFrame({ \n#    \"PassengerId\" : test_dataset[\"PassengerId\"],\n#    \"Survived\" : predictionx\n    })\n#print(submission_DFx.head(2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"87e9ab923eaa7fae5a42ef8ccef2711cd00792c0"},"cell_type":"code","source":"# prepare file for submission\n#submission_DFx.to_csv(\"submission_XBGC.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"27e78510198a6e1307fc3991366977955841e5ef"},"cell_type":"markdown","source":"# -------------------------------------------------/-------------------------------------------------------"},{"metadata":{"_uuid":"9651330f1fcc1e3dabe7f8830287d1c4e9cc261a"},"cell_type":"markdown","source":"Precision:\nOur model predicts 72 % of the time, a passengers survival correctly (precision).\n\nRecall:\nThe recall tells us that it predicted the survival of 72 % of the people who actually survived.\n\nF-Score:\nYou can combine precision and recall into one score, which is called the F-score. The F-score is computed with the harmonic mean of precision and recall. Note that it assigns much more weight to low values. As a result of that, the classifier will only get a high F-score, if both recall and precision are high."},{"metadata":{"_uuid":"551e2fe24a3890619adada2d7d68b199fb46228f"},"cell_type":"markdown","source":"# Precision Recall Curve"},{"metadata":{"trusted":true,"_uuid":"95493381d105c554596cb00811170bd38fc19fa0"},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\n\n# getting the probabilities of our predictions\ny_scores = random_forest.predict_proba(x_train)\ny_scores = y_scores[:,1]\n\nprecision, recall, threshold = precision_recall_curve(y_train, y_scores)\ndef plot_precision_and_recall(precision, recall, threshold):\n    plt.plot(threshold, precision[:-1], \"r-\", label=\"precision\", linewidth=5)\n    plt.plot(threshold, recall[:-1], \"b\", label=\"recall\", linewidth=5)\n    plt.xlabel(\"threshold\", fontsize=19)\n    plt.legend(loc=\"upper right\", fontsize=19)\n    plt.ylim([0, 1])\n\nplt.figure(figsize=(14, 7))\nplot_precision_and_recall(precision, recall, threshold)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78f711cb4d0c7f4727fed791a2b7f45d6484cdab"},"cell_type":"markdown","source":"# ROC AUC Curve\nThe red line in the middel represents a purely random classifier (e.g a coin flip) and therefore your classifier should be as far away from it as possible. "},{"metadata":{"trusted":true,"_uuid":"57c1a020125f7604eb089080669933106a2456ac"},"cell_type":"code","source":"from sklearn.metrics import roc_curve\n# compute true positive rate and false positive rate\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, y_scores)\n# plotting them against each other\ndef plot_roc_curve(false_positive_rate, true_positive_rate, label=None):\n    plt.plot(false_positive_rate, true_positive_rate, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'r', linewidth=4)\n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positive Rate (FPR)', fontsize=16)\n    plt.ylabel('True Positive Rate (TPR)', fontsize=16)\n\nplt.figure(figsize=(14, 7))\nplot_roc_curve(false_positive_rate, true_positive_rate)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2881a9d6bc5bc3f47a6c2da537b44ae8c656cf1d"},"cell_type":"markdown","source":"The ROC AUC Score is the corresponding score to the ROC AUC Curve.\nIt is simply computed by measuring the area under the curve, which is called AUC.\nA classifiers that is 100% correct, would have a ROC AUC Score of 1\nand a completely random classiffier would have a score of 0.5."},{"metadata":{"trusted":true,"_uuid":"1fb95fd1dfc9715349d2b08bb280a450ae7066e7"},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nr_a_score = roc_auc_score(y_train, y_scores)\nprint(\"ROC-AUC-Score: {:2f}\".format( r_a_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"93b507b91dcbb3adce488f9f2c140d148b7df86b"},"cell_type":"code","source":"#results = pd.DataFrame({\n#    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n#              'Random Forest', 'Naive Bayes', 'Perceptron', \n#              'Stochastic Gradient Decent', \n#              'Decision Tree'],\n#    'Score': [acc_linear_svc, acc_knn, acc_log, \n#              acc_random_forest, acc_gaussian, acc_perceptron, \n#              acc_sgd, acc_decision_tree],\n#    })\n#result_df = results.sort_values(by='Score', ascending=False)\n#result_df = result_df.set_index('Score')\n#result_df.head(9)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4db91a50bc2768209b64bb957b7eb4595f9edd68"},"cell_type":"markdown","source":"# Keras"},{"metadata":{"trusted":true,"_uuid":"93fe55ae61a256adf27c0aa73c8a50d2cb675072"},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.utils.np_utils import to_categorical\n\noutput = train_dataset['Survived'].values\noutput = to_categorical(output, 2)\n\nX_train, X_validation, y_train, y_validation = train_test_split(features, output, test_size=0.05)\nimport numpy\nnumpy.random.seed(7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f07f1a06d28b5ee55c2a4838cb1ac5b77b0885cb"},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(32, input_dim=9, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(8, activation='tanh'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"07f52ee4c8f67f106dc775b490dddcbb58cb8147"},"cell_type":"code","source":"#model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c3e2b68ed098b0c445efe02d4b35001ad37ff2d4"},"cell_type":"code","source":"model.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.sgd(),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c12703ae767eb908f523b1ec1d0c663088d1c25"},"cell_type":"code","source":"model.fit(X_train, y_train, \n          batch_size=200, \n          epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c37609b695f3b37afb13531143afb15038d59fe2"},"cell_type":"code","source":"acc = model.evaluate(X_validation, y_validation)\nprint('Hata Toplami(LOSS):', acc[0])\nprint('Basari(ACC):', acc[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9985ad525e46decfd7f5af3bf868cb0c5f709632"},"cell_type":"code","source":" #prediction_= model.predict_classes(test_dataset[variables_])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bb3f1dd904d3eafead1ad9d9b7ea4e7ef41aabbe"},"cell_type":"code","source":"#submission = pd.DataFrame()\n#submission['PassengerId'] = test_dataset[\"PassengerId\"]\n#submission['Survived'] = prediction_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c37829bc3f80e5ed97a27c59e35d8b388e4ae299"},"cell_type":"code","source":"#submission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"551c84745cd4d0a515df4291efaccbb043021644"},"cell_type":"code","source":"#submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6ddde23447ad895bc94d55923a3fc96816cec249"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}