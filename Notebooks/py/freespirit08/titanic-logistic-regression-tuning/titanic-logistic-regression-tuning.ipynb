{"cells":[{"metadata":{"_uuid":"184806e46f10728f329454d97dec1c29824248e3"},"cell_type":"markdown","source":"# Titanic - Logistic Regression Hyperparameter Optimization\n\n**Author:** Arindam Chatterjee  \n**Start Date:** 23rd July, 2018\n\n**Purpose:** The objective of this notebook is to understand how the hyperparameters of an algorithm affect the predictive performance & how tuning them can help us optimize our goal. The goal itself can be simply accuracy or model build time. \n\nSince, this is my first try at Kaggle, I chose the simplest yet most tried out dataset of Titanic & a rather simplistic algorithm in Logistic Regression. I will continue to add new things in the notebook like more algorithms & visualizations whenever I get the time from my office work."},{"metadata":{"_uuid":"7e0f0b9fff11548e72104837081d5e0070c292bc"},"cell_type":"markdown","source":"## Import Libaries"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom time import time\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\npath=\"../input\" #For Kaggle\n#path=\"input\"\nprint(os.listdir(path))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d51a2100b3fd817e7d5c24809521464b69f1881"},"cell_type":"markdown","source":"## Read Files"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv(path+\"/train.csv\")\ntest = pd.read_csv(path+\"/test.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1388c9f5ec29e9b66e19483864577136d7e295c"},"cell_type":"code","source":"train.info()\nprint('-'*50)\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11b0a27ad547894f32acb87ea9927febbf6adee7","trusted":true},"cell_type":"code","source":"# Drop PassengerId, Ticket as they are basically Row_identifier(unique ID) type columns\n# Drop Cabin since it has 77%,78% missing data in train,test sets respectively making imputation infeasible\ntrain.drop(columns=['PassengerId','Ticket','Cabin'], axis=1, inplace = True)\ntest.drop(columns=['Ticket','Cabin'], axis=1, inplace = True)\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0cce4c139f1cbbef07a3b42ec0c66a7d3d91311","trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15,15))\nsns.countplot(x=\"Survived\", hue=\"Pclass\", data=train, ax=axes[0][0])\nsns.countplot(x=\"Survived\", hue=\"Sex\", data=train, ax=axes[0][1])\nsns.countplot(x=\"Survived\", hue=\"SibSp\", data=train, ax=axes[1][0])\nsns.countplot(x=\"Survived\", hue=\"Parch\", data=train, ax=axes[1][1])\nsns.countplot(x=\"Survived\", hue=\"Embarked\", data=train, ax=axes[2][0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33206237391d348db10cd90f06bf8c9700b48881"},"cell_type":"markdown","source":"## Feature Engineering\n\n1. Add feature:  \n    a) FamilySize = Parch + SibSp  \n    b) Title = apply regex ([A-Za-z]+)\\. on Name \n2. Impute Missing values:  \n    a) Fare  \n    b) Age  \n    c) Embarked\n3. Bin feature  \n    a) Fare  \n    b) Age \n4. One-hot encode categorical features  \n    Sex, Embarked, Title, Fare_bin, Age_bin\n5. Drop Unnecessary features  \n    Name, Age, Fare  \n6. Typecast & Reduce Feature size from int64 to np.uint8  \n    Survived, Pclass, SibSp, Parch, FamilySize  \n\n##### Note that Double space(  ) works as newline in Jupyter Markdown ."},{"metadata":{"_uuid":"81c6bac4616b49583a953eb5f83be4e999fad26c"},"cell_type":"markdown","source":"### 1. Add Features"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c1fb2713f027fabd07b0855bb091f47e2579f972"},"cell_type":"code","source":"#1. a) Add family_size\ntrain['FamilySize'] = train['SibSp'] + train['Parch'] + 1\ntest['FamilySize'] = test['SibSp'] + test['Parch'] + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d33b5c71168fc7d83eac304f5fee1643064f216"},"cell_type":"code","source":"#1. b) Add Title\nimport re\ndef getTitle(name):\n    title = re.search('([A-Za-z]+)\\.',name)\n    if title:\n        return title.group(1)\n    return \"\"\n\ntrain['Title'] = train['Name'].apply(getTitle)\ntest['Title'] = test['Name'].apply(getTitle)\npd.crosstab(train['Title'], train['Survived'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5eede9023a6b49e7e73153d0dd67211f136469db"},"cell_type":"code","source":"pd.crosstab(test['Title'], test['Sex'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94bba384b96b7d8d17d5aa004b2c1fc384e76954"},"cell_type":"code","source":"#Bucket the Titles into appropriate groups\ntrain['Title']=train['Title'].replace(['Capt','Col','Don','Dr','Jonkheer','Major','Rev','Sir','Dona'],'Rare')\ntrain['Title']=train['Title'].replace('Ms','Miss')\ntrain['Title']=train['Title'].replace(['Mlle','Mme','Lady','Countess'],'Mrs')\npd.crosstab(train['Title'], train['Survived'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0fe2b68763895640c93edcb2907678d5c32e3b9"},"cell_type":"code","source":"test['Title']=test['Title'].replace(['Capt','Col','Don','Dr','Jonkheer','Major','Rev','Sir','Dona'],'Rare')\ntest['Title']=test['Title'].replace('Ms','Miss')\ntest['Title']=test['Title'].replace(['Mlle','Mme','Lady','Countess'],'Mrs')\npd.crosstab(test['Title'], test['Sex'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ba1564d1faa65367dc977a8db108a9a0cf692c3"},"cell_type":"markdown","source":"### 2. Impute Missing Values  \n\nQ) Replace missing values :Mean or Median ?  \nA) https://www.quora.com/What-is-more-accurate-the-median-or-mean  "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d77d795b726a7240e4d3b86eea12532ed1cb08a5"},"cell_type":"code","source":"# 2a) Fare: Only test set has missing values\ntest['Fare'].fillna(test['Fare'].median(), inplace = True)\n\n# 2b) Age\ntrain['Age'].fillna(train['Age'].median(), inplace = True)\ntest['Age'].fillna(test['Age'].median(), inplace = True)\n\n# 2c) Embarked\ntrain['Embarked'].fillna(train['Embarked'].mode()[0], inplace = True) #replace with the 1st Mode","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e3ca78feb6f71db0d0d1e0ebc1bd1f04aee1d5d"},"cell_type":"markdown","source":"### 3. Bin feature"},{"metadata":{"_uuid":"d15092575f4c129b183a6e10a843b3651741c138","trusted":true},"cell_type":"code","source":"#3.a) Bin feature Fare into groups\nplt.figure(figsize=(50,200))\n#fig, axes2 = plt.subplots(nrows=1, ncols=1, figsize=(50,70))\n#sns.countplot(x=\"Fare\", data=train[train['Survived']==0], ax=axes2[0])\n#sns.countplot(x=\"Fare\", data=train[train['Survived']==1], ax=axes2[0])\n\n#sns.kdeplot(x=\"Fare\", data=train[train['Survived']==0], ax=axes2[0])\n#sns.kdeplot(train['Fare'])\n#sns.countplot(train['Fare'])\nsns.countplot(y=\"Fare\", hue=\"Survived\", data=train)\n#sns.distplot(train['Fare'])\n#sns.countplot(y=\"Fare\", data=train)\n#pd.crosstab(train['Fare'], train['Survived'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f4d56ae78f19a1e959ebc3689505ce59b339c08"},"cell_type":"code","source":"train['Fare_bin'] = pd.cut(train['Fare'],bins=[0,7.125,15.1,30,60,120,1000],\n                           labels=['very_low_fare', 'low_fare', 'medium_fare', \n                                   'moderate_fare', 'high_fare', 'very_high_fare'])\ntest['Fare_bin'] = pd.cut(train['Fare'],bins=[0,7.125,15.1,30,60,120,1000],\n                           labels=['very_low_fare', 'low_fare', 'medium_fare', \n                                   'moderate_fare', 'high_fare', 'very_high_fare'])\npd.crosstab(train['Fare_bin'], train['Survived'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30b9f4d8c801b010b2af9dfc689fad764cdc2b1d"},"cell_type":"code","source":"#3.b) Bin Age\nplt.figure(figsize=(50,100))\nsns.countplot(y=\"Age\", hue=\"Survived\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2338e66a9124d2c262d35ac8dd27e0196bd1c94c"},"cell_type":"code","source":"#0,12,20,40,60,120\ntrain['Age_bin'] = pd.cut(train['Age'], bins=[0,12,20,40,60,120], \n                          labels=['Child','Teenage','Adult','MiddleAge','ElderAge'])\ntest['Age_bin'] = pd.cut(test['Age'], bins=[0,12,20,40,60,120], \n                          labels=['Child','Teenage','Adult','MiddleAge','ElderAge'])\npd.crosstab(train['Age_bin'], train['Survived'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf3b341e3da01d6d9abc763c81ca4a55b3f5ab69"},"cell_type":"markdown","source":"### 4. One-hot encode categorical features  \nSex, Embarked, Title, Fare_bin, Age_bin"},{"metadata":{"trusted":true,"_uuid":"36d2aac40e38b4b8622e0cf8b09f06471d30cfec"},"cell_type":"code","source":"train = pd.get_dummies(train, columns = [\"Sex\",\"Embarked\",\"Title\",\"Fare_bin\", \"Age_bin\"], prefix_sep='=', \n                             prefix=[\"Sex\",\"Embarked\",\"Title\",\"Fare_bin\", \"Age_bin\"])\ntest = pd.get_dummies(test, columns = [\"Sex\",\"Embarked\",\"Title\",\"Fare_bin\", \"Age_bin\"], prefix_sep='=', \n                             prefix=[\"Sex\",\"Embarked\",\"Title\",\"Fare_bin\", \"Age_bin\"])\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5f2d365ec1b7068ca3d3e6f4d888c8d9cfe0e63"},"cell_type":"markdown","source":"### 5. Drop Unnecessary features  \nName, Age, Fare"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e9d1b75e30d3f32ff5a19b59e8c89e00e7867d49"},"cell_type":"code","source":"train.drop(columns=['Name','Age','Fare'], axis=1, inplace = True)\ntest.drop(columns=['Name','Age','Fare'], axis=1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5809e49527bf79957070c061b851168e55687b94"},"cell_type":"markdown","source":"### 6. Typecast & Reduce Feature size from int64 to np.uint8\nSurvived, Pclass, SibSp, Parch, FamilySize"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"81b38c27e6fd495b33cdd5114a749e452e439dad"},"cell_type":"code","source":"cols = ['Pclass','SibSp','Parch','FamilySize']\ntrain[cols] = train[cols].astype(np.uint8)\ntest[cols] = test[cols].astype(np.uint8)\ntrain['Survived'] = train['Survived'].astype(np.uint8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8c047f554a1d4d8951883e6dbe5e17610646220b"},"cell_type":"code","source":"# Need to save this after all pre-processing done for submission\ntest_Pids = test['PassengerId']\ntest.drop(columns=['PassengerId'], axis=1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f0cdf184daf46cab236fdfcb3d65f27ad9561ba"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f2d133ecde1bc9f054134063137a31fcc71870e"},"cell_type":"markdown","source":"#### Create Train & Validation Sets"},{"metadata":{"_uuid":"e93ba7a8749ae37deef8da0794e87d2ee13ab872","trusted":true},"cell_type":"code","source":"X = train.drop(columns='Survived')\nY = train['Survived']\n\nskf = StratifiedKFold(n_splits=4,random_state=1)\nfor train_index, test_index in skf.split(X, Y):\n    X_tr, X_val = X.iloc[train_index], X.iloc[test_index]\n    Y_tr, Y_val = Y.iloc[train_index], Y.iloc[test_index]\n    print('Train & Validation sets built.')\n    break","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d464b18603adee825ab82581a492cf9806caeb79","collapsed":true},"cell_type":"markdown","source":"## Model Build & Optimizations  \n\nThe objective of this step is to visually understand how the different hyperparamaters & random_state affect\nthe outcome of the model ie: its predictive accuracy.   \nWe will initially go through each of them individually even though for most model algorithms, the hyperparameters\nare not independant of each other. The test set used will be constant thrughout the process.\n\nThe below data descriptions are taken from the sklearn documentation in:  \nhttp://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html  \n\n1. C : float, default: 1.0 : Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.\n2. tol : float, default: 1e-4 : Tolerance for stopping criteria. This tells the algorithm to stop searching for a minimum (or maximum) once some tolerance is achieved, i.e. once it is close enough. \n3. solver : {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default: ‘liblinear’ Algorithm to use in the optimization problem.\n4. max_iter : int, default: 100 : Useful only for the newton-cg, sag and lbfgs solvers. Maximum number of iterations taken for the solvers to converge."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"984414f0364f30b1d98ee8ca92d37bb8d1092581"},"cell_type":"code","source":"#Define generalized function for Scoring current instance of model & data\n'''\nreturns ::  a)acc: accuracy as computed on Validation set\n            b)exec_time: model build/fit time\n'''\ndef evaluate(X_tr, Y_tr, X_val, Y_val, params):\n    model = LogisticRegression()\n    #We should use set_params to pass parameters to model object.\n    #This has the advantage over using setattr in that it allows Scikit learn to perform some validation checks on the parameters.\n    model.set_params(**params)\n    \n    start=time()\n    model.fit(X_tr,Y_tr)\n    exec_time = time() - start\n    \n    Y_pred = model.predict(X_val)\n    acc = accuracy_score(Y_val,Y_pred) * 100.0\n    return acc, exec_time","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a2c107c5dffc9f0717295727f80e1cf67c5f5f6"},"cell_type":"markdown","source":"### 1. Optimizing C"},{"metadata":{"trusted":true,"_uuid":"53c03997dc3baf195e02bb221a3c084e41e7b061"},"cell_type":"code","source":"C=0.001\niterations = 500\nresults = np.zeros((iterations, 5))\n\nfor i in range(0,iterations):    \n    model_params = {'C':C,'random_state':1}\n    acc_val,time_val = evaluate(X_tr, Y_tr, X_val, Y_val, model_params)\n    acc_tr,time_tr = evaluate(X_tr, Y_tr, X_tr, Y_tr, model_params)\n    results[i] = i+1, C, acc_tr, acc_val, time_val\n    C+=0.005\n\nres_df = pd.DataFrame(  data=results[0:,0:], \n                        index=results[0:,0],\n                        columns=['Sl','C','Train_acc','Val_acc','Build_time'])\nres_df['Sl'] = res_df['Sl'].astype(np.uint16)\nres_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c43fe4f3d1d02b58dd250c09f07703e22b0d83d9"},"cell_type":"code","source":"#Find value of C & Train_acc at which Valiation set acuracy is highest.\nres_df[res_df['Val_acc'] == res_df['Val_acc'].max()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c91be24bde824d9283961e5abe56e5acdc3b2d46"},"cell_type":"code","source":"plt.xlabel('C')\nplt.ylabel('Accuracy')\nplt.title('Train & Validation Set Accuracy w.r.t to Regularization parameter C')\nplt.grid(True)\nplt.plot(res_df['C'], res_df['Train_acc'] , 'r*-') # plotting t, a separately \nplt.plot(res_df['C'], res_df['Val_acc'] , 'b.') # plotting t, a separately","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ec56d3245380393cd5de29e22c08cc00ad80d65a"},"cell_type":"markdown","source":"C is the inverse of regularization strength. Hence, smaller values increase regularization & can result in underfitting while as we increase C, model becomes more prone to overfitting.  \nThus we find that, for the train data, model accuracy increases as C value increases. BUT, with increase in C,\nthe accuracy on validation data starts to increase initially before peaking at (0.211, 83.03571429). After that,\nthe effect of overfitting causes the accuracy to decrease. Hence the optimal value of C is 0.211"},{"metadata":{"_uuid":"f1e5b495c2236bc05b7e7b863f4e458a1f8455c7"},"cell_type":"markdown","source":"### 2. Optimzing tol (Tolerance for Stopping Criteria)  \n\ntol = Tolerance for stopping criteria. This tells the algorithm to stop searching for a minimum (or maximum) once some tolerance is achieved, i.e. once it is close enough. tol will change depending on the objective function being minimized/maximized and the algorithm they use to find the minimum, and thus will depend on the model we are fitting.\n\nFor the newton-cg and lbfgs solvers, the iteration will stop when ``max{|g_i | i = 1, ..., n} <= tol`` where ``g_i`` is the i-th component of the gradient."},{"metadata":{"trusted":true,"_uuid":"3f72a29fea8470c32b7782492a12a7fa6adf66ce"},"cell_type":"code","source":"#tol=1e-6\ntol=1e-10\n#iterations = 50\niterations = 37\nresults = np.zeros((iterations, 5))\n\nfor i in range(0,iterations):    \n    model_params = {'tol':tol,'random_state':1}\n    acc_val,time_val = evaluate(X_tr, Y_tr, X_val, Y_val, model_params)\n    acc_tr,time_tr = evaluate(X_tr, Y_tr, X_tr, Y_tr, model_params)\n    results[i] = i+1, tol, acc_tr, acc_val, time_val\n    #tol*=5\n    tol*=2\n    #print(tol)\n\nres_df_tol = pd.DataFrame(  data=results[0:,0:], \n                        index=results[0:,0],\n                        columns=['Sl','tol','Train_acc','Val_acc','Build_time'])\nres_df_tol['Sl'] = res_df['Sl'].astype(np.uint16)\nres_df_tol.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"faad22acba19fdce8b236c968a19943ea4f4ba8b"},"cell_type":"code","source":"plt.figure(figsize=(20,5))\nplt.xlabel('tol')\nplt.ylabel('Accuracy')\nplt.title('Train & Validation Set Accuracy w.r.t to Tolerance tol')\nplt.grid(True)\nplt.plot(res_df_tol['tol'], res_df_tol['Train_acc'] , 'r*')\nplt.plot(res_df_tol['tol'], res_df_tol['Train_acc'] , 'y-')\nplt.plot(res_df_tol['tol'], res_df_tol['Val_acc'] , 'b.')\n#plt.plot(res_df_tol['tol'], res_df_tol['Build_time'] , 'g')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03daa622436b91616fcc97fdd3df575c42d76ae6"},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(15,10))\n\nax[0].set(xlabel='tol', ylabel='Accuracy')\nax[0].set_title('Train & Validation Set Accuracy w.r.t to Tolerance tol')\nax[0].grid(True)\nax[0].plot(res_df_tol['tol'], res_df_tol['Train_acc'] , 'r*')\nax[0].plot(res_df_tol['tol'], res_df_tol['Train_acc'] , 'y')\nax[0].plot(res_df_tol['tol'], res_df_tol['Val_acc'] , 'b.')\n\nax[1].set(xlabel='tol', ylabel='Model Build Time')\nax[1].set_title('Model Build Time w.r.t to Tolerance tol')\nax[1].grid(True)\nax[1].plot(res_df_tol['tol'], res_df_tol['Build_time'] , 'r*')\nax[1].plot(res_df_tol['tol'], res_df_tol['Build_time'] , 'y')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed29509a0c6bf44e6315f42e6b27cbf7ced988f5"},"cell_type":"markdown","source":"Tolerance tol for Logistic regression represents when convergence is achieved for its gradience values in an iteration. Hence, to converge for lower values of tol, more number of iterations are needed at the expense of greater model build time. This is illustrated in Plot-2. \n\nBut, as we see in Plot-1, for a fast simple algorithm like Logistic Regression working on small sets of data, accuracy also increases for smaller values of tol. We see that, accuracy remains more or less constant between tol values of 0 & 0.33 for both sets. The dafult value of 1e-4 is sufficient for this case as further lowering it increases the buil time wihout any appreciable increase in accuracy. On the other hand, accuracy falls of pretty sharply once tol bcomes more than 1.8. Beyond, tol of ~3.4, accuracy again stabilizes in the low ~61%. \n\nBy running for greater values of tol upto tol=20, it was found to remain constant. Again, the tol graph will depend on many other factors like nature of the data & the internal solver, which we will see below."},{"metadata":{"_uuid":"368ec008d0969b8489cceec6424f66e3b3054247"},"cell_type":"markdown","source":"### 3. Optimizing the internal solver : \n\n** From sklearn documentation, **  \nsolver : {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, \ndefault: ‘liblinear’ Algorithm to use in the optimization problem.\n\na) For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n\nb) For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss; ‘liblinear’ is limited to one-versus-rest schemes.\n\nc) ‘newton-cg’, ‘lbfgs’ and ‘sag’ only handle L2 penalty, whereas ‘liblinear’ and ‘saga’ handle L1 penalty.\n\nNote that ‘sag’ and ‘saga’ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.\n\nNew in version 0.17: Stochastic Average Gradient descent solver.\n\nNew in version 0.19: SAGA solver.\n\n**LIBLINEAR – A Library for Large Linear Classification**  \nhttp://www.csie.ntu.edu.tw/~cjlin/liblinear/\n\n**SAG – Mark Schmidt, Nicolas Le Roux, and Francis Bach**  \nMinimizing Finite Sums with the Stochastic Average Gradient  \nhttps://hal.inria.fr/hal-00860051/document\n\n**SAGA – Defazio, A., Bach F. & Lacoste-Julien S. (2014).**  \nSAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives.  \nhttps://arxiv.org/abs/1407.0202\n\n**Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent**\nmethods for logistic regression and maximum entropy models. Machine Learning 85(1-2):41-75.  \nhttp://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n"},{"metadata":{"_uuid":"fd863ad357511be40069cf5415abae306aa6f5e2"},"cell_type":"markdown","source":"#### 3.1 Variation of tol wrt to the Solver"},{"metadata":{"trusted":true,"_uuid":"edb9788f70a8147b1aaf5a48fc67d2d5056dca4f"},"cell_type":"code","source":"# 3.1 Variation of tol wrt to the Solver\n\ntol=1e-10\niterations = 37\n\n# There are 5 solvers. For each, we need to see their accuracy on train & validation sets plus their build time.\n# Additionaly, first two columns are Sl & tol. Hence, a total of (5*3) + 2 = 17 columns reqd.\nresults = np.zeros((iterations, 17))\nsolver_list = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n\nfor i in range(0,iterations):    \n    model_params = {'tol':tol,'random_state':1}\n    results[i][0:2] = i+1, tol\n    \n    j = 2 #internal counter for iterating over each of the solver's results values\n    for solver in solver_list:\n        model_params.update({'solver': solver})\n        acc_val,time_val = evaluate(X_tr, Y_tr, X_val, Y_val, model_params)\n        acc_tr,time_tr = evaluate(X_tr, Y_tr, X_tr, Y_tr, model_params)\n        results[i][j:j+3] = acc_tr, acc_val, time_val\n        j+=3\n        \n    tol*=2\n\ncolumns = ['Sl','tol']\nfor solver in solver_list:\n    columns.append('Train_acc_'+solver)\n    columns.append('Val_acc_'+solver)\n    columns.append('Build_time_'+solver)\n\nres_df_solver_tol = pd.DataFrame( data=results[0:,0:], \n                                  index=results[0:,0],\n                                  columns=columns)\nres_df_solver_tol['Sl'] = res_df_solver_tol['Sl'].astype(np.uint16)\nres_df_solver_tol.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f081c7bdfa7922a0ae6e89a004db841c82ff27df"},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(15,15))\n\nax[0].set(xlabel='tol', ylabel='Accuracy')\nax[0].set_title('Variation in Training Data Accuracy w.r.t to Tolerance tol for different Solvers')\nax[0].grid(True)\n\ncolour_list = ['r','g','b','c','m']\nfor i in range(0,5):\n    ax[0].plot(res_df_solver_tol['tol'],\n               res_df_solver_tol['Train_acc_'+solver_list[i]],\n               colour_list[i]+'.-', label=solver_list[i])\nax[0].legend()\n\nax[1].set(xlabel='tol', ylabel='Accuracy')\nax[1].set_title('Variation in Validation Data Accuracy w.r.t to Tolerance tol for different Solvers')\nax[1].grid(True)\nfor i in range(0,5):\n    ax[1].plot(res_df_solver_tol['tol'],\n               res_df_solver_tol['Val_acc_'+solver_list[i]] ,\n               colour_list[i]+'.-', label=solver_list[i])    \nax[1].legend()\n    \nax[2].set(xlabel='tol', ylabel='Build_Time')\nax[2].set_title('Variation in Model Build Time w.r.t to Tolerance tol for different Solvers')\nax[2].grid(True)\nfor i in range(0,5):\n    ax[2].plot(res_df_solver_tol['tol'],\n               res_df_solver_tol['Build_time_'+solver_list[i]] ,\n               colour_list[i]+'.-', label=solver_list[i])  \nax[2].legend()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4395b39fadf7aa5e56c6210313880293377d73f"},"cell_type":"markdown","source":"**Conclusion:** From the above plots, we can see that the default solver 'liblinear' loses accuracy rapidly with increaseing value of Tolerance(tol). This is countered by having the fastest build speed. For small values of tol, there is no practical difference in accuracy between the solvers. But as tol increases, the other solvers are able to maintain their accuracy with lbfgs & newton-cg remaining almost constant."},{"metadata":{"_uuid":"32b5d501f008d04b0a398019a4969f2129ffcd08"},"cell_type":"markdown","source":"#### 3.2 Variation of C wrt to the Solver"},{"metadata":{"trusted":true,"_uuid":"c095733516230576dae9858c626751ad6981e06a"},"cell_type":"code","source":"# 3.2 Variation of C wrt to the Solver\n\nC=0.001\niterations = 500\n\n# There are 5 solvers. For each, we need to see their accuracy on train & validation sets plus their build time.\n# Additionaly, first two columns are Sl & C. Hence, a total of (5*3) + 2 = 17 columns reqd.\nresults = np.zeros((iterations, 17))\nsolver_list = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n\nfor i in range(0,iterations):    \n    model_params = {'C':C,'random_state':1}\n    results[i][0:2] = i+1, C\n    \n    j = 2 #internal counter for iterating over each of the solver's results values\n    for solver in solver_list:\n        model_params.update({'solver': solver})\n        acc_val,time_val = evaluate(X_tr, Y_tr, X_val, Y_val, model_params)\n        acc_tr,time_tr = evaluate(X_tr, Y_tr, X_tr, Y_tr, model_params)\n        results[i][j:j+3] = acc_tr, acc_val, time_val\n        j+=3\n        \n    C+=0.005\n\ncolumns = ['Sl','C']\nfor solver in solver_list:\n    columns.append('Train_acc_'+solver)\n    columns.append('Val_acc_'+solver)\n    columns.append('Build_time_'+solver)\n\nres_df_solver_C = pd.DataFrame( data=results[0:,0:], \n                                  index=results[0:,0],\n                                  columns=columns)\nres_df_solver_C['Sl'] = res_df_solver_C['Sl'].astype(np.uint16)\nres_df_solver_C.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"caa282e0200c068a84d920786fa26f6530f8648c"},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(15,30))\n\nax[0].set(xlabel='C', ylabel='Accuracy')\nax[0].set_title('Variation in Training Data Accuracy w.r.t to Inverse Regularization parameter C for different Solvers')\nax[0].grid(True)\n\ncolour_list = ['r','g','b','c','m']\nfor i in range(0,5):\n    ax[0].plot(res_df_solver_C['C'],\n               res_df_solver_C['Train_acc_'+solver_list[i]],\n               colour_list[i]+'-', label=solver_list[i])\nax[0].legend()\n\nax[1].set(xlabel='C', ylabel='Accuracy')\nax[1].set_title('Variation in Validation Data Accuracy w.r.t to Inverse Regularization parameter C for different Solvers')\nax[1].grid(True)\nfor i in range(0,5):\n    ax[1].plot(res_df_solver_C['C'],\n               res_df_solver_C['Val_acc_'+solver_list[i]] ,\n               colour_list[i]+'-', label=solver_list[i])    \nax[1].legend()\n    \nax[2].set(xlabel='C', ylabel='Build_Time')\nax[2].set_title('Variation in Model Build Time w.r.t to Inverse Regularization parameter C for different Solvers')\nax[2].grid(True)\nfor i in range(0,5):\n    ax[2].plot(res_df_solver_C['C'],\n               res_df_solver_C['Build_time_'+solver_list[i]] ,\n               colour_list[i]+'-', label=solver_list[i])  \nax[2].legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"563c51d6f964d660df7a3e1a0e7608377399ae57"},"cell_type":"markdown","source":"**Conclusion:** As Regularization increases, the solvers have more or less similar performance in terms of accuracy with the liblinear giving the highest accuracy of all for a value of C which is the point where the model is neither under-fitted nor over-fitted. The region surrounding the liblinear peak shows the highest accuracy values for the other solvers too but without a peak. But given the size of the data & the number of iterations fixed at default 100(sag & saga did not converge with the default value), it cannot be concluded which solver is the best by accuracy. But, time wise, we see liblinear is the fastest while stochastic gradient methods(sag/saga) being the slowest."},{"metadata":{"_uuid":"f67663ac9014af2e68c6b893ac49efa1d630e7c4"},"cell_type":"markdown","source":"### 4. Optimizing the max_iterations for a solver \n\nmax_iter : int, default: 100 : Useful only for the newton-cg, sag and lbfgs solvers. Maximum number of iterations taken for the solvers to converge.\n"},{"metadata":{"trusted":true,"_uuid":"a38c7305af46d21dfea7490c8b608288322aea89"},"cell_type":"code","source":"max_iter=5\niterations = 40\n\n# There are 3 solvers. For each, we need to see their accuracy on train & validation sets plus their build time.\n# Additionaly, first two columns are Sl & C. Hence, a total of (3*3) + 2 = 11 columns reqd.\nresults = np.zeros((iterations, 11))\nsolver_list = ['newton-cg', 'lbfgs', 'sag']\n\nfor i in range(0,iterations):    \n    model_params = {'max_iter':max_iter,'random_state':1}\n    results[i][0:2] = i+1, max_iter\n    \n    j = 2 #internal counter for iterating over each of the solver's results values\n    for solver in solver_list:\n        model_params.update({'solver': solver})\n        acc_val,time_val = evaluate(X_tr, Y_tr, X_val, Y_val, model_params)\n        acc_tr,time_tr = evaluate(X_tr, Y_tr, X_tr, Y_tr, model_params)\n        results[i][j:j+3] = acc_tr, acc_val, time_val\n        j+=3\n        \n    max_iter += 5\n\ncolumns = ['Sl','max_iter']\nfor solver in solver_list:\n    columns.append('Train_acc_'+solver)\n    columns.append('Val_acc_'+solver)\n    columns.append('Build_time_'+solver)\n\nres_df_solver_max_iter = pd.DataFrame( data=results[0:,0:], \n                                  index=results[0:,0],\n                                  columns=columns)\nres_df_solver_max_iter['Sl'] = res_df_solver_max_iter['Sl'].astype(np.uint16)\nres_df_solver_max_iter.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"805212994009f26c052579022ab40f50c8b9587b"},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(15,30))\n\nax[0].set(xlabel='max_iter', ylabel='Accuracy')\nax[0].set_title('Variation in Training Data Accuracy w.r.t to Max Iterations for different Solvers')\nax[0].grid(True)\n\ncolour_list = ['r*-','gv-','bs-']\nfor i in range(0,3):\n    ax[0].plot(res_df_solver_max_iter['max_iter'],\n               res_df_solver_max_iter['Train_acc_'+solver_list[i]],\n               colour_list[i]+'-', label=solver_list[i])\nax[0].legend()\n\nax[1].set(xlabel='max_iter', ylabel='Accuracy')\nax[1].set_title('Variation in Validation Data Accuracy w.r.t to Max Iterations for different Solvers')\nax[1].grid(True)\nfor i in range(0,3):\n    ax[1].plot(res_df_solver_max_iter['max_iter'],\n               res_df_solver_max_iter['Val_acc_'+solver_list[i]] ,\n               colour_list[i]+'-', label=solver_list[i])    \nax[1].legend()\n    \nax[2].set(xlabel='max_iter', ylabel='Build_Time')\nax[2].set_title('Variation in Model Build Time w.r.t to Max Iterations for different Solvers')\nax[2].grid(True)\nfor i in range(0,3):\n    ax[2].plot(res_df_solver_max_iter['max_iter'],\n               res_df_solver_max_iter['Build_time_'+solver_list[i]] ,\n               colour_list[i]+'-', label=solver_list[i])  \nax[2].legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb10cbc10300b63a7c8346e378766db58812d30c"},"cell_type":"markdown","source":"**Conclusion:** Solver newton-cg appears as the least susceptible to accuracy differences with variation in the maximum number of iterations allowed for convergence, for both train & validation data. Its build time also fluctuates the least & almost follows a parralel line to X-axis. After a certain value of max_iter, the other 2 solvers also have constant accuracy curves. But, sag build time increases consistently with time without any accuracy increase."},{"metadata":{"trusted":true,"_uuid":"d7432bbfcf6eae9c6c96f73ec8b20add9b8a28d3"},"cell_type":"code","source":"# Final values for Log Reg:\nmodel_params = {'C':0.211, 'tol':1e-6, 'solver':'liblinear', 'random_state':1}\nmodel = LogisticRegression()\nmodel.set_params(**model_params)\nmodel.fit(X_tr,Y_tr)\nY_pred = model.predict(X_val)\nacc = accuracy_score(Y_val,Y_pred) * 100.0\nprint('Final Accuracy = {}%'.format(acc))\nresults_logreg = model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"08fd0bb0e0d0c727a862f8f2e16dc1f14be2669c"},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": test_Pids,\n        \"Survived\": results_logreg})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"85e69cb62e91592bf6159bbb11bab84957040a32"},"cell_type":"code","source":"submission.to_csv(\"try_1_logreg.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ea22f6cae81ed372bc883594f8d04f767ae8d2d7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}