{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b66840b9-abdb-8faf-61d6-c2e00ffc9b3a"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_test, \n",
        "                             y = y_test.astype(int), cv = 10, scoring = 'precision')\n",
        "print(\"Accuracy mean \" + str(accuracies.mean()))\n",
        "print(\"Accuracy std \" + str(accuracies.std()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "021a4f8e-9941-9047-b832-8fa339ac6354"
      },
      "source": [
        "std seems high\n",
        "\n",
        "Before changing algorithm, let's try to work on features\n",
        "\n",
        "*Feature selection* using RFE (recursive feature elimination)\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e605589a-8e40-7005-495f-5aeaacf9f9eb"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import RFE \n",
        "\n",
        "rfe = RFE(classifier, 6)\n",
        "rfe = rfe.fit(X_test, y_test.astype(int))\n",
        "# summarize the selection of the attributes\n",
        "print(rfe.support_)\n",
        "print(rfe.ranking_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "17f7c072-1f3a-3628-9f20-95d6e02c7705"
      },
      "source": [
        "Hello everybody,\n",
        "\n",
        "this is my first notebook/competition and I hope to have feedbacks about what I'm doing (especially wrong things).\n",
        "\n",
        "I haven't seen other submissions, as I want to start from scratch and see what I can find\n",
        "\n",
        "I'm very fascinated by ML and I'm eager to learn as much as possible \n",
        "\n",
        "Ok, let's start!\n",
        "\n",
        "Besides the results, what I'll like to do is to establish a correct general workflow helping to work with all datasets\n",
        "\n",
        "The steps:\n",
        "\n",
        "\n",
        "\n",
        "1) Inspect the data to have a first guess of features, relations, instances quality and draw some graph helping to visualize them\n",
        "\n",
        "2) Do some preprocessing (get rid of nan, categorical feature encoding, feature scaling - if necessary)\n",
        "\n",
        "3) Further analysis\n",
        "\n",
        "4) Build a baseline classifier (Logistic Regression in this case) just to have a starting point\n",
        "\n",
        "5) Do features selection and engineering to improve results\n",
        "\n",
        "6) Repeat from step 2 with another approach (algorithm, features, etc) until complete satisfaction :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4d24f31b-51ca-9234-9aba-0effef3c474c"
      },
      "outputs": [],
      "source": [
        "# Importing some libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Importing the train dataset from file\n",
        "dataset = pd.read_csv('../input/train.csv')\n",
        "\n",
        "#Some info about it\n",
        "dataset.info()\n",
        "\n",
        "dataset.isnull().sum()\n",
        "\n",
        "dataset.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "404fee07-8893-88a7-ded4-1ffdaee70e40"
      },
      "source": [
        "Let's see what we have \n",
        "\n",
        "PassengerId: meta\n",
        " \n",
        "Survived: target \n",
        "\n",
        "Pclass: feature (seems important, based on position probably) \n",
        "\n",
        "Name: meta\n",
        " \n",
        "Sex: feature (not sure how can impact on surviving an iceberg hit :)) \n",
        "\n",
        "Age: feature (maybe target related) \n",
        "\n",
        "Sibsp, Parch: (seem important, an event happening to all the people in a group) \n",
        "\n",
        "Fare: maybe related to class \n",
        "\n",
        "Ticket, Cabin, Embarked: not related, just meta\n",
        "\n",
        "\n",
        "Rows number seems ok respect the features \n",
        "\n",
        "Age is missing on 20% data, we'll see how to deal it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4674e2d7-2b89-b29b-88c5-012e7ce5f4ff"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Let's explore the data visually against the target\n",
        "\n",
        "survived_pclass = pd.crosstab([dataset.Pclass], dataset.Survived.astype(bool))\n",
        "survived_pclass.plot(kind='bar', stacked=False, color=['red','blue'], grid=False)\n",
        "\n",
        "survived_sex = pd.crosstab([dataset.Sex], dataset.Survived.astype(bool))\n",
        "survived_sex.plot(kind='bar', stacked=False, color=['red','blue'], grid=False)\n",
        "\n",
        "survived_sibsp = pd.crosstab([dataset.SibSp], dataset.Survived.astype(bool))\n",
        "survived_sibsp.plot(kind='bar', stacked=False, color=['red','blue'], grid=False)\n",
        "\n",
        "survived_parch = pd.crosstab([dataset.Parch], dataset.Survived.astype(bool))\n",
        "survived_parch.plot(kind='bar', stacked=False, color=['red','blue'], grid=False)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "15a75398-b54c-c494-4720-07f0e42d9fb6"
      },
      "source": [
        "So male, with 3rd class and alone is the victim type\n",
        "High SibSp too seems very deadly :(\n",
        "\n",
        "Ok, time to preprocess for further analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "27394a13-e02d-c3a6-e614-33f681514677"
      },
      "outputs": [],
      "source": [
        "#get all relevant columns\n",
        "workingDataset = dataset.iloc[:, [1,2,4,5,6,7,9]]\n",
        "\n",
        "# get rid of age nan rows (first approach)\n",
        "workingDataset = workingDataset[np.isfinite(workingDataset['Age'])]\n",
        "\n",
        "# feature/target selection\n",
        "\n",
        "workingData = workingDataset.values\n",
        "X = workingData[:, 1:]\n",
        "y = workingData[:, 0]\n",
        "\n",
        "# encoding feature (sex)\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labelencoder_X = LabelEncoder()\n",
        "X[:,1] = labelencoder_X.fit_transform(X[:, 1])\n",
        "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
        "X = onehotencoder.fit_transform(X).toarray()\n",
        "\n",
        "# avoid dummy trap\n",
        "X = X[:, 1:]\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from pandas import DataFrame\n",
        "sc = StandardScaler()\n",
        "preprocessedData = sc.fit_transform(X)\n",
        "# rebuild feature's dataframe with normalized data for graphs purpose\n",
        "preprocessedDataset = DataFrame(data=preprocessedData)\n",
        "preprocessedDataset.columns = ['Sex','Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
        "\n",
        "preprocessedDataset.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c55d1ab4-372f-e5b6-cf91-4e9cfd10a0db"
      },
      "outputs": [],
      "source": [
        "def rand_jitter(arr):\n",
        "    stdev = .01*(max(arr)-min(arr))\n",
        "    return arr + np.random.randn(len(arr)) * stdev\n",
        "\n",
        "colors = np.where(dataset.Survived == 1, 'blue', 'red')\n",
        "plt.scatter(x=rand_jitter(dataset.Parch), y=rand_jitter(dataset.SibSp), c = colors)\n",
        "plt.xlabel('Parch')\n",
        "plt.ylabel('SibSp')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a5f5c41d-8088-7902-c1ad-8708fc2b3405"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x=rand_jitter(preprocessedDataset.Age), y=rand_jitter(preprocessedDataset.Fare), c = colors)\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Fare')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "84e7f2ba-f032-d727-d9a9-a7d5ced45b86"
      },
      "outputs": [],
      "source": [
        "plt.boxplot(preprocessedData)\n",
        "plt.xlabel(\"Attribute Index\")\n",
        "plt.ylabel((\"Quartile Ranges - Normalized \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4cc1f78f-fd45-5a0d-8cab-cadfb8580d31"
      },
      "outputs": [],
      "source": [
        "#parallel coordinates\n",
        "nRows = len(preprocessedDataset.index)\n",
        "nCols = len(preprocessedDataset.columns)\n",
        "\n",
        "\n",
        "nDataCol = nCols\n",
        "for i in range(nRows):\n",
        "   #assign color based on \"1\" or \"0\" labels\n",
        "   if y[i] == 1:   #survived\n",
        "      pcolor = \"blue\"\n",
        "   else:\n",
        "      pcolor = \"red\"\n",
        "   #plot rows of data as if they were series data\n",
        "   dataRow = preprocessedDataset.iloc[i,0:nDataCol] \n",
        "   dataRow.plot(color=pcolor, alpha=0.5)\n",
        "\n",
        "plt.xlabel(\"Attribute Index\")\n",
        "plt.ylabel((\"Attribute Values\"))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "56c96c79-cb05-2f27-13f0-1cef31ccf28f"
      },
      "source": [
        "\n",
        "Low correlation betwen features\n",
        "Fare with some outliers, age should be ok...let's have confirmation with probplots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7083a9e4-7443-fdb8-262c-fc9644cdaa82"
      },
      "outputs": [],
      "source": [
        "import scipy.stats as stats\n",
        "import pylab\n",
        "\n",
        "col = 5 \n",
        "colData = []\n",
        "for row in X:\n",
        "   colData.append(float(row[col]))\n",
        "\n",
        "stats.probplot(colData, dist=\"norm\", plot=pylab)\n",
        "pylab.show()\n",
        "\n",
        "col = 2 \n",
        "colData = []\n",
        "for row in X:\n",
        "   colData.append(float(row[col]))\n",
        "\n",
        "stats.probplot(colData, dist=\"norm\", plot=pylab)\n",
        "pylab.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ae205e9b-1bc7-1f24-4609-836d95684e3b"
      },
      "outputs": [],
      "source": [
        "corMat = DataFrame(preprocessedDataset.corr())\n",
        "\n",
        "#visualize correlations using heatmap\n",
        "plt.pcolor(corMat)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4fbd9ded-6f3b-6715-5c57-8eca52773cde"
      },
      "source": [
        "Correlation is low\n",
        "\n",
        "Time to build baseline classifier with Logistic Regression and simple split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0af58b4c-9ec5-aa8f-2793-035a13042a09"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(preprocessedData, y, \n",
        "                                                    test_size = 0.25, random_state = 0)\n",
        "\n",
        "y_test = y_test.astype(int)\n",
        "y_train = y_train.astype(int)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "import seaborn as sn\n",
        "sn.heatmap(cm, annot=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ca4fbe55-c5a2-b330-4ca8-7935d88738f7"
      },
      "source": [
        "mmm I'm sure can be better...\n",
        "\n",
        "Let's check the accuracy doing k-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8a03ae42-4da1-a876-6c0a-594d8d5e005a"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "accuracy = cross_val_score(estimator = classifier, X = X_test, \n",
        "                             y = y_test, cv = 10, scoring = 'accuracy')\n",
        "\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (accuracy.mean(), accuracy.std() * 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7afb8f88-7448-8890-4340-c265117d1713"
      },
      "source": [
        "std seems high\n",
        "\n",
        "Before changing algorithm, let's try to work on features\n",
        "\n",
        "*Feature selection* using RFE (recursive feature elimination)\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a1a0cc06-0886-edc0-35f2-ea52eb550a08"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "rfe = RFE(classifier, 6)\n",
        "rfe = rfe.fit(X_test, y_test)\n",
        "# summarize the selection of the attributes\n",
        "print(rfe.support_)\n",
        "print(rfe.ranking_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ea22138f-ecd3-237e-e50a-2be0a0dc556c"
      },
      "source": [
        "Feature engineering using PCA\n",
        "\n",
        "(but should not work given the result of RFE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "13094234-c6ab-564d-77ac-643b64f1a0ce"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 2)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "\n",
        "# Fitting Logistic Regression to the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test_pca)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sn.heatmap(cm, annot=True)\n",
        "\n",
        "accuracy = cross_val_score(estimator = classifier, X = X_test_pca, \n",
        "                             y = y_test, cv = 10, scoring = 'accuracy')\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (accuracy.mean(), accuracy.std() * 2))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5bb0c956-6e8f-7f9d-dfd3-a090f24070c4"
      },
      "outputs": [],
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "X_set, y_set = X_test_pca, y_test\n",
        "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
        "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
        "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
        "             alpha = 0.75, cmap = ListedColormap(('red', 'blue')))\n",
        "plt.xlim(X1.min(), X1.max())\n",
        "plt.ylim(X2.min(), X2.max())\n",
        "for i, j in enumerate(np.unique(y_set)):\n",
        "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
        "                c = ListedColormap(('red',  'blue'))(i), label = j)\n",
        "plt.title('Logistic Regression (Test set)')\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "db23f3b7-7f69-ac6a-ceea-b7f232123e69"
      },
      "source": [
        "Let's try LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2cb6229b-c311-2bd4-0cc7-0d20c83bc5dc"
      },
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "lda = LDA(n_components = 2)\n",
        "X_train_lda = lda.fit_transform(X_train, y_train)\n",
        "X_test_lda = lda.transform(X_test)\n",
        "\n",
        "# Fitting Logistic Regression to the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train_lda, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred_lda = classifier.predict(X_test_lda)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred_lda)\n",
        "sn.heatmap(cm, annot=True)\n",
        "\n",
        "accuracy = cross_val_score(estimator = classifier, X = X_test_lda, \n",
        "                             y = y_test, cv = 10, scoring = 'accuracy')\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (accuracy.mean(), accuracy.std() * 2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "be3ff12b-0aa0-9e06-6416-014ca03b9fd2"
      },
      "source": [
        "ok, let's finish with kernel-pca using not linear approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0e631879-e1f1-7ee5-f678-0384f4a60caa"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import KernelPCA\n",
        "kpca = KernelPCA(n_components = 5, kernel = 'rbf')\n",
        "X_train_kpca = kpca.fit_transform(X_train)\n",
        "X_test_kpca = kpca.transform(X_test)\n",
        "\n",
        "# Fitting Logistic Regression to the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train_kpca, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred_kpca = classifier.predict(X_test_kpca)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred_kpca)\n",
        "sn.heatmap(cm, annot=True)\n",
        "\n",
        "accuracy = cross_val_score(estimator = classifier, X = X_test_kpca, \n",
        "                             y = y_test, cv = 10, scoring = 'accuracy')\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (accuracy.mean(), accuracy.std() * 2))"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}