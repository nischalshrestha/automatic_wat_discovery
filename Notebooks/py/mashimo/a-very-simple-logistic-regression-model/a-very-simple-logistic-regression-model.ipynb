{"cells":[{"metadata":{"_cell_guid":"a3fffcc8-46e2-4346-b8de-354f41806d95","_uuid":"30bb17447531d9b1f563bebcaae37d9265f5bd8c"},"cell_type":"markdown","source":"# Titanic \n\nGoal: predict survival on the Titanic  \n\nHere we are looking into how to apply Logistic Regression to the Titanic dataset."},{"metadata":{"_cell_guid":"d3bc772a-f3dd-4e07-a2cf-1cab13d9843c","_uuid":"497cbf6b6b1795d653c2dde5c5d2e1aaddec222d"},"cell_type":"markdown","source":"# 1. Collect and understand the data"},{"metadata":{"_cell_guid":"2f3f9444-f10e-4e26-a148-ed280c6827a1","_uuid":"827ceb42c82d2cc318aa019847ac1566e30b4755","collapsed":true,"trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":30,"outputs":[]},{"metadata":{"_cell_guid":"8d128176-234e-467d-87b0-d74513b7ac64","_uuid":"476bda4a772d9577f82c5f14ca052c76f2a6c4ad","collapsed":true,"trusted":true},"cell_type":"code","source":"# get titanic training file as a DataFrame\ntitanic = pd.read_csv(\"../input/train.csv\")","execution_count":31,"outputs":[]},{"metadata":{"_cell_guid":"57dc52f3-8183-404a-826e-fefd079a80ba","_uuid":"7139e6904e273b6deb010a849d002e238aaeccfd","trusted":true},"cell_type":"code","source":"titanic.shape","execution_count":32,"outputs":[]},{"metadata":{"_cell_guid":"1c6e9d92-02b9-411c-9796-4564dd510824","_uuid":"d67bcd232f2f765c9f67a705929fe4794869cd93","trusted":true},"cell_type":"code","source":"# preview the data\ntitanic.head()","execution_count":33,"outputs":[]},{"metadata":{"_cell_guid":"9e727654-fdec-467c-b507-887e946dd83a","_uuid":"ea5503f098726b3ecb53ffce4f129fce3b1ddb76"},"cell_type":"markdown","source":"Variable Description\n---\nSurvived: Survived (1) or died (0);  this is the target variable  \nPclass: Passenger's class (1st, 2nd or 3rd class)    \nName: Passenger's name  \nSex: Passenger's sex  \nAge: Passenger's age  \nSibSp: Number of siblings/spouses aboard  \nParch: Number of parents/children aboard  \nTicket: Ticket number  \nFare: Fare  \nCabin: Cabin  \nEmbarked: Port of embarkation"},{"metadata":{"_cell_guid":"8f0bd3c2-6f5d-47ae-80ed-db774302591e","_uuid":"e1ac18636576210de914039646adf2c7873a8d01","trusted":true},"cell_type":"code","source":"titanic.describe()","execution_count":34,"outputs":[]},{"metadata":{"_cell_guid":"b8c0458f-8c4d-49cd-b7f7-58e75ebfcca6","_uuid":"7b9d79e1c20ad9c8e3cc3ffb1cfe1e499d62fb97"},"cell_type":"markdown","source":"Not all features are numeric:"},{"metadata":{"_cell_guid":"625e2d2e-cbdd-450c-8637-0e3f464138e0","_uuid":"941c7b6c731e1a0caa6f789df1e7a65c5fa1f235","trusted":true},"cell_type":"code","source":"titanic.info()","execution_count":35,"outputs":[]},{"metadata":{"_cell_guid":"856dc3b5-dd81-4ede-87b5-f3793cb1d939","_uuid":"7dc561843d57857e3c4dda83787e532ba2159fac"},"cell_type":"markdown","source":"# 2. Process the Data\nCategorical variables need to be transformed into numeric variables"},{"metadata":{"_cell_guid":"851ed8b0-e110-4f0f-a21b-1eb3d9a5ce0c","_uuid":"74e0d679346e9bffbd0c5ea6a1104cb10bba8504"},"cell_type":"markdown","source":"### Transform the embarkment port"},{"metadata":{"_cell_guid":"5d0d890a-34d4-4f24-a616-a0566b14d5e3","_uuid":"737e6c9c968c18dc5802a680515c2acf34f2dc73"},"cell_type":"markdown","source":"There are three ports: C = Cherbourg, Q = Queenstown, S = Southampton"},{"metadata":{"_cell_guid":"489f002e-be8c-490c-b886-fbe31b61f6dd","_uuid":"1ab7787e7c14e9097dd052aa2296ba76d4573cb1","trusted":true},"cell_type":"code","source":"ports = pd.get_dummies(titanic.Embarked , prefix='Embarked')\nports.head()","execution_count":36,"outputs":[]},{"metadata":{"_cell_guid":"ef6fe4a7-26b2-44e1-b0a1-87ec36596b0b","_uuid":"1787519de936da6483f10a6bf8cab1aa9fd730f6"},"cell_type":"markdown","source":"Now the feature Embarked (a category) has been trasformed into 3 binary features, e.g. Embarked_C = 0 not embarked in Cherbourg, 1 = embarked in Cherbourg.  \nFinally, the 3 new binary features substitute the original one in the data frame:"},{"metadata":{"_cell_guid":"1ebc79ff-40b4-4cb2-ad1c-b805706f669c","_uuid":"ce14afe8ef63ef82d99b4a73047c8900065ce5ba","collapsed":true,"trusted":true},"cell_type":"code","source":"titanic = titanic.join(ports)\ntitanic.drop(['Embarked'], axis=1, inplace=True) # then drop the original column","execution_count":37,"outputs":[]},{"metadata":{"_cell_guid":"48181569-38e2-40bb-94cc-fce84cbd05ce","_uuid":"82d4739986df5722a941490cfb1ccac03cf47fd1"},"cell_type":"markdown","source":"### Transform the gender feature\nThis transformation is easier, being already a binary classification (male or female, this was 1912).\nIt doesn't need to create separate dummy categories, a mapping will be enough:"},{"metadata":{"_cell_guid":"8403d00b-620f-4146-8bb1-4d6145068031","_uuid":"4c5c3494c295b60c282e0a434b2d60ec9bf7697c","collapsed":true,"trusted":true},"cell_type":"code","source":"titanic.Sex = titanic.Sex.map({'male':0, 'female':1})","execution_count":38,"outputs":[]},{"metadata":{"_cell_guid":"4a152190-01bf-4685-9694-82fe42e6b357","_uuid":"34655438bfc7f2b5bdd6d0267cc096135e737a1e"},"cell_type":"markdown","source":"## Extract the target variable\nCreate an X dataframe with the input features and an y series with the target (Survived)"},{"metadata":{"_cell_guid":"4ef8f19d-0906-4c38-a680-1e06240f8533","_uuid":"2e13c55f27f533d15d70fa05cea6aac56c8d9ba9","collapsed":true,"trusted":true},"cell_type":"code","source":"y = titanic.Survived.copy() # copy “y” column values out","execution_count":39,"outputs":[]},{"metadata":{"_cell_guid":"eded1f9d-2b81-4894-90b5-eb128b948d6c","_uuid":"fad0889cbcd83e597faafc6f1d978b214feb3dbc","collapsed":true,"trusted":true},"cell_type":"code","source":"X = titanic.drop(['Survived'], axis=1) # then, drop y column","execution_count":40,"outputs":[]},{"metadata":{"_cell_guid":"bb8a8faa-5b56-4f97-adb4-54bf061d90a7","_uuid":"623366646e107ec78f9d927f91003d7c81e31a4b","collapsed":true},"cell_type":"markdown","source":"### Drop not so important features\nFor the first model, we ignore some categorical features which will not add too much of a signal."},{"metadata":{"_cell_guid":"58352eda-b4c7-4469-b155-02d44e566526","_uuid":"8d96706177375d34f0b3e282263a551f8e387436","collapsed":true,"trusted":true},"cell_type":"code","source":"X.drop(['Cabin'], axis=1, inplace=True) ","execution_count":41,"outputs":[]},{"metadata":{"_cell_guid":"425a37c1-faa7-4f08-bac9-3c046d64b0b5","_uuid":"0f1f74cebd914233d30e05d84290fd49e2cd3cc1","collapsed":true,"trusted":true},"cell_type":"code","source":"X.drop(['Ticket'], axis=1, inplace=True) ","execution_count":42,"outputs":[]},{"metadata":{"_cell_guid":"c676db74-31ac-459c-95ca-0e9d78f1c974","_uuid":"fa24400b1cfe919ba97ea844ff52081456d239eb","collapsed":true,"trusted":true},"cell_type":"code","source":"X.drop(['Name'], axis=1, inplace=True) \nX.drop(['PassengerId'], axis=1, inplace=True)","execution_count":43,"outputs":[]},{"metadata":{"_cell_guid":"5eada173-6b91-4cfb-b828-bcc85f2f01f7","_uuid":"cd78157a04151d0869c69d5d8b5dbf7d8aae15ab","trusted":true},"cell_type":"code","source":"X.info()","execution_count":44,"outputs":[]},{"metadata":{"_cell_guid":"43ac2b7e-2b03-425a-acaa-8e06edd5885b","_uuid":"90a817452be0469385eddd5fe0228ecc764fcbfb"},"cell_type":"markdown","source":"All features are now numeric, ready for regression.  \nBut we have still a couple of processing to do."},{"metadata":{"_cell_guid":"f0ff8da7-1c4d-47b5-825c-49f834ebd6a7","_uuid":"9fb0996c6c11f0748a19761b17626e19c76b7e42"},"cell_type":"markdown","source":"## Check if there are any missing values"},{"metadata":{"_cell_guid":"9ea55973-5a88-4b40-ae60-4d71afeba189","_uuid":"4135aa8c7932b2bccfa8c7628ff637d13dcdbdde","trusted":true},"cell_type":"code","source":"X.isnull().values.any()","execution_count":45,"outputs":[]},{"metadata":{"_cell_guid":"e779c2cb-5574-4c6d-b894-16e182d8cdbe","_uuid":"188b8a206964462e744427c47894096a4c7dc8f2","collapsed":true,"trusted":true},"cell_type":"code","source":"#X[pd.isnull(X).any(axis=1)]  # check which rows have NaNs","execution_count":46,"outputs":[]},{"metadata":{"_cell_guid":"29993da6-d111-4b5d-83da-1a332e344725","_uuid":"bb90d1e4e02687bba3af77e7aec60a9d2a907a03"},"cell_type":"markdown","source":"True, there are missing values in the data (NaN) and a quick look at the data reveals that they are all in the Age feature.  \nOne possibility could be to remove the feature, another one is to fill the missing value with a fixed number or the average age."},{"metadata":{"_cell_guid":"b9cdbb15-c258-4f65-9dff-1c524a10c554","_uuid":"09bbf45f9e3a60b70721aff6c37498241ef06a22","collapsed":true,"trusted":true},"cell_type":"code","source":"X.Age.fillna(X.Age.mean(), inplace=True)  # replace NaN with average age","execution_count":47,"outputs":[]},{"metadata":{"_cell_guid":"801cebad-3620-40e5-95c6-05e2d9cbd3f3","_uuid":"1b79ee7333c58f69fc2c60b8407ed8fc2237de24","trusted":true},"cell_type":"code","source":"X.isnull().values.any()","execution_count":48,"outputs":[]},{"metadata":{"_cell_guid":"7d38fd3d-abbd-426c-8596-8639bc109415","_uuid":"a67a3d5e597d5dbe82889f565cd96c7eb217b724"},"cell_type":"markdown","source":"Now all missing values have been removed.  \nThe logistic regression would otherwise not work with missing values."},{"metadata":{"_cell_guid":"d271de3f-17a2-4266-85d5-cb503bf71ae0","_uuid":"1fcb68f671791372fd19a06a541d206f18314028"},"cell_type":"markdown","source":"## Split the dataset into training and validation\n\nThe **training** set will be used to build the machine learning models. The model will be based on the features like passengers’ gender and class but also on the known survived flag.\n\nThe **validation** set should be used to see how well the model performs on unseen data. For each passenger in the test set, I use the model trained to predict whether or not they survived the sinking of the Titanic, then will be compared with the actual survival flag."},{"metadata":{"_cell_guid":"375cc187-0e6a-48c1-9abc-8415fdaad3e3","_uuid":"104f8bcd92bcc19098c9b8ff37205a08498c894b","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n  # 80 % go into the training test, 20% in the validation test\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=7)","execution_count":49,"outputs":[]},{"metadata":{"_cell_guid":"28ee2c04-2c17-4161-a34e-99a2dfc4ec4a","_uuid":"3fb77b5ad0f522018496a4dce9f0e678987b2995"},"cell_type":"markdown","source":"# 3. Modelling"},{"metadata":{"_cell_guid":"519c177a-4024-488b-8b9b-e35de4ff2d31","_uuid":"4c0d26941092308ab4017ff0c7e7dcf56506964c"},"cell_type":"markdown","source":"## Get a baseline\nA baseline is always useful to see if the model trained behaves significantly better than an easy to obtain baseline, such as a random guess or a simple heuristic like all and only female passengers survived. In this case, after quickly looking at the training dataset - where the survival outcome is present - I am going to use the following:\n"},{"metadata":{"_cell_guid":"748d99b2-4f24-4c6c-aeb4-9cf2983af2a3","_uuid":"c246fdbe4945da7b5a6c57dd44811d41a31ea3b8","collapsed":true,"trusted":true},"cell_type":"code","source":"def simple_heuristic(titanicDF):\n    '''\n    predict whether or not the passngers survived or perished.\n    Here's the algorithm, predict the passenger survived:\n    1) If the passenger is female or\n    2) if his socioeconomic status is high AND if the passenger is under 18\n    '''\n\n    predictions = [] # a list\n    \n    for passenger_index, passenger in titanicDF.iterrows():\n          \n        if passenger['Sex'] == 1:\n                    # female\n            predictions.append(1)  # survived\n        elif passenger['Age'] < 18 and passenger['Pclass'] == 1:\n                    # male but minor and rich\n            predictions.append(1)  # survived\n        else:\n            predictions.append(0) # everyone else perished\n\n    return predictions","execution_count":50,"outputs":[]},{"metadata":{"_cell_guid":"e3038683-18df-4ced-8113-906cd9de07d3","_uuid":"492eb2ba9f266f0b426ee1805b88fce942d5fd77"},"cell_type":"markdown","source":"Let's see how this simple algorithm will behave on the validation dataset and we will keep that number as our baseline:"},{"metadata":{"_cell_guid":"8bae599d-a9b4-4d1d-b053-f70b041b5d37","_uuid":"d8d7dc0db4d78610a6f7acc98020c5ebc10863c4","trusted":true},"cell_type":"code","source":"simplePredictions = simple_heuristic(X_valid)\ncorrect = sum(simplePredictions == y_valid)\nprint (\"Baseline: \", correct/len(y_valid))","execution_count":51,"outputs":[]},{"metadata":{"_cell_guid":"574bba24-1460-448e-a238-7e0648de0813","_uuid":"73ddc5831a3c857fcfa424f6ef475acf1fbea2c0"},"cell_type":"markdown","source":"Baseline: a simple algorithm predicts correctly 73% of validation cases.  \nNow let's see if the model can do better."},{"metadata":{"_cell_guid":"d4593c17-a3af-4dbb-9281-5edeabda8826","_uuid":"8286bd009da563759c5b9161fd0199a1c32c89df"},"cell_type":"markdown","source":"##  Logistic Regression"},{"metadata":{"_cell_guid":"61305e27-c5cc-4ef0-b3a7-697e3c11fcf4","_uuid":"c25f12bab80cf30520cb45b14d11b34f94faedf7"},"cell_type":"markdown","source":"Will use a simple logistic regression, that takes all the features in X and creates a regression line.\nThis is done using the LogisticRegression module in SciKitLearn."},{"metadata":{"_cell_guid":"b50b0b15-2301-4dad-8f36-17a57bd45c05","_uuid":"da79b04df0c2ac05a08f3296970d1aecb43a4db0","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()","execution_count":52,"outputs":[]},{"metadata":{"_cell_guid":"28f733c9-1701-45fb-acc1-f70cf69cb73a","_uuid":"bcd1563b5ccfcb70bfe972369560f5dd1b2a239c","trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train)","execution_count":53,"outputs":[]},{"metadata":{"_cell_guid":"1847aca6-ec5f-4c0d-9322-0c2ea0a361d5","_uuid":"e3518da452af052ce095cb7fed30dbad9cb2dfe0"},"cell_type":"markdown","source":"# 4. Evaluate the model"},{"metadata":{"_cell_guid":"c6397771-ccfd-4727-995b-53d7602c77a9","_uuid":"a6f875ec1e0bcf35c4975c24641036f3587cbf2b","trusted":true},"cell_type":"code","source":"model.score(X_train, y_train)","execution_count":54,"outputs":[]},{"metadata":{"_cell_guid":"fa0a2259-a479-41ed-81c0-e1e16e0893f9","_uuid":"78d7d53d2120f54f8e2300254b5959ccba3849e6","trusted":true},"cell_type":"code","source":"model.score(X_valid, y_valid)","execution_count":55,"outputs":[]},{"metadata":{"_cell_guid":"69a931af-a031-4e64-aa9e-0bd99ba6d6e5","_uuid":"7f464bf74547e77e348b03b1218dfddc8ead0a1e"},"cell_type":"markdown","source":"Two things:\n- the score on the training set is much better than on the validation set, an indication that could be overfitting and not being a general model, e.g. for all ship sinks.\n- the score on the validation set is better than the baseline, so it adds some value at a minimal cost (the logistic regression is not computationally expensive, at least not for smaller datasets)."},{"metadata":{"_cell_guid":"a8877f38-1225-482f-9567-8ab3d882a051","_uuid":"c4d8e7ba0ed0f34b4984f6f391611fe20242e148"},"cell_type":"markdown","source":"An advantage of logistic regression (e.g. against a neural network) is that it's easily interpretable.  It can be written as a math formula:"},{"metadata":{"_cell_guid":"0750b17e-0e07-4b2a-b184-883a05691914","_uuid":"203d436e9a7bf4b771ffa854d04d4f3b483e3665","trusted":true},"cell_type":"code","source":"model.intercept_ # the fitted intercept","execution_count":27,"outputs":[]},{"metadata":{"_cell_guid":"270f9c5b-fc00-452e-8db3-b46dfd254016","_uuid":"1af225662affcbd64033439c0f4c9429e24c9623","trusted":true},"cell_type":"code","source":"model.coef_  # the fitted coefficients","execution_count":28,"outputs":[]},{"metadata":{"_cell_guid":"7982cade-5714-49bc-97ca-28e682635a2b","_uuid":"afb7845bc491262112fa0ad268f2b2e2869f5607"},"cell_type":"markdown","source":"Which means that the formula is:  \n$$ \\boldsymbol P(survive) = \\frac{1}{1+e^{-logit}} $$  \n  \nwhere the logit is:  \n  \n$$ logit = \\boldsymbol{\\beta_{0} + \\beta_{1}\\cdot x_{1} + ... + \\beta_{n}\\cdot x_{n}}$$ \n  \nwhere $\\beta_{0}$ is the model intercept and the other beta parameters are the model coefficients from above, each multiplied for the related feature:  \n  \n$$ logit = \\boldsymbol{1.4224 - 0.9319 * Pclass + ... + 0.2228 * Embarked_S}$$ "},{"metadata":{"_cell_guid":"c9d7b760-9aed-438d-9593-f8cb5facd58e","_uuid":"afb0fd3fa54b16dd59470be22f81e81471e7aed6"},"cell_type":"markdown","source":"# 5. Iterate on the model\nThe model could be improved, for example transforming the excluded features above or creating new ones (e.g. I could extract titles from the names which could be another indication of the socio-economic status)."},{"metadata":{"_cell_guid":"64c0ac0e-b021-4b35-82d3-f2e2dfdeff9f","_uuid":"152e917a09344836fd2cba1e60214aafff414678"},"cell_type":"markdown","source":"The correlation matrix may give us a understanding of which variables are important"},{"metadata":{"_cell_guid":"c1a628bc-0275-4da3-b6e1-01ffbcf3c143","_uuid":"5fee6c2cb815eccaf9c6febc046eafc66e22883f","trusted":true},"cell_type":"code","source":"titanic.corr()","execution_count":56,"outputs":[]},{"metadata":{"_cell_guid":"3480ba26-e9c4-49cc-b13f-8e4dbd7e01b2","_uuid":"fa1292b18451b2071bff5f7708cd08a345c6438c"},"cell_type":"markdown","source":"# 6. Deploy to Kaggle"},{"metadata":{"_cell_guid":"48c1b44b-d0d4-49a8-b505-f20cc781b588","_uuid":"4d328a76a7c3d3fde5073c1ff8a25ec16e1740a8"},"cell_type":"markdown","source":"The resulting score is **0.75119**  \nNote that the score on the validation set has been a good predictor!"},{"metadata":{"_cell_guid":"d970ed4f-029c-4d43-982c-8ad5b22b38b5","_uuid":"9f88e8fe0b2c4f6dd95c407eac2102347c927e78","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}