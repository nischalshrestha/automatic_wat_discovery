{"cells":[
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "import matplotlib.pyplot as plt\n\n# Set the global default size of matplotlib figures\nplt.rc('figure', figsize=(10, 5))\n# Size of matplotlib figures that contain subplots\nfizsize_with_subplots = (10, 10)\n# Size of matplotlib histogram bins\nbin_size = 10\n\ndf_train = pd.read_csv('../input/train.csv')\ndf_train.head()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df_train.tail()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df_train.dtypes"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df_train.info()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df_train.describe()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Set up a grid of plots\nfig = plt.figure(figsize=fizsize_with_subplots) \nfig_dims = (3, 2)\n\n# Plot death and survival counts\nplt.subplot2grid(fig_dims, (0, 0))\ndf_train['Survived'].value_counts().plot(kind='bar', \n                                         title='Death and Survival Counts')\n\n# Plot Pclass counts\nplt.subplot2grid(fig_dims, (0, 1))\ndf_train['Pclass'].value_counts().plot(kind='bar', \n                                       title='Passenger Class Counts')\n\n# Plot Sex counts\nplt.subplot2grid(fig_dims, (1, 0))\ndf_train['Sex'].value_counts().plot(kind='bar', \n                                    title='Gender Counts')\nplt.xticks(rotation=0)\n\n# Plot Embarked counts\nplt.subplot2grid(fig_dims, (1, 1))\ndf_train['Embarked'].value_counts().plot(kind='bar', \n                                         title='Ports of Embarkation Counts')\n\n# Plot the Age histogram\nplt.subplot2grid(fig_dims, (2, 0))\ndf_train['Age'].hist()\nplt.title('Age Histogram')"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "pclass_xt = pd.crosstab(df_train['Pclass'], df_train['Survived'])\npclass_xt"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Normalize the cross tab to sum to 1:\npclass_xt_pct = pclass_xt.div(pclass_xt.sum(1).astype(float), axis=0)\n\npclass_xt_pct.plot(kind='bar', \n                   stacked=True, \n                   title='Survival Rate by Passenger Classes')\nplt.xlabel('Passenger Class')\nplt.ylabel('Survival Rate')"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "sexes = sorted(df_train['Sex'].unique())\ngenders_mapping = dict(zip(sexes, range(0, len(sexes) + 1)))\ngenders_mapping"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df_train['Sex_Val'] = df_train['Sex'].map(genders_mapping).astype(int)\ndf_train.head()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "sex_val_xt = pd.crosstab(df_train['Sex_Val'], df_train['Survived'])\nsex_val_xt_pct = sex_val_xt.div(sex_val_xt.sum(1).astype(float), axis=0)\nsex_val_xt_pct.plot(kind='bar', stacked=True, title='Survival Rate by Gender')"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Get the unique values of Pclass:\npassenger_classes = sorted(df_train['Pclass'].unique())\n\nfor p_class in passenger_classes:\n    print('M: ', p_class, len(df_train[(df_train['Sex'] == 'male') & \n                             (df_train['Pclass'] == p_class)]))\n    print('F: ', p_class, len(df_train[(df_train['Sex'] == 'female') & \n                             (df_train['Pclass'] == p_class)]))"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Plot survival rate by Sex\nfemales_df = df_train[df_train['Sex'] == 'female']\nfemales_xt = pd.crosstab(females_df['Pclass'], df_train['Survived'])\nfemales_xt_pct = females_xt.div(females_xt.sum(1).astype(float), axis=0)\nfemales_xt_pct.plot(kind='bar', \n                    stacked=True, \n                    title='Female Survival Rate by Passenger Class')\nplt.xlabel('Passenger Class')\nplt.ylabel('Survival Rate')\n\n# Plot survival rate by Pclass\nmales_df = df_train[df_train['Sex'] == 'male']\nmales_xt = pd.crosstab(males_df['Pclass'], df_train['Survived'])\nmales_xt_pct = males_xt.div(males_xt.sum(1).astype(float), axis=0)\nmales_xt_pct.plot(kind='bar', \n                  stacked=True, \n                  title='Male Survival Rate by Passenger Class')\nplt.xlabel('Passenger Class')\nplt.ylabel('Survival Rate')"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df_train[df_train['Embarked'].isnull()]"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Get the unique values of Embarked\nembarked_locs = sorted(df_train['Embarked'].unique(), key=lambda x: str(x))\n\nembarked_locs_mapping = dict(zip(embarked_locs, \n                                 range(0, len(embarked_locs) + 1)))\nembarked_locs_mapping"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df_train['Embarked_Val'] = df_train['Embarked'] \\\n                               .map(embarked_locs_mapping) \\\n                               .astype(int)\ndf_train.head()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df_train['Embarked_Val'].hist(bins=len(embarked_locs), range=(0, 3))\nplt.title('Port of Embarkation Histogram')\nplt.xlabel('Port of Embarkation')\nplt.ylabel('Count')\nplt.show()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "if len(df_train[df_train['Embarked'].isnull()] > 0):\n    df_train.replace({'Embarked_Val' : \n                   { embarked_locs_mapping[np.nan] : embarked_locs_mapping['S'] \n                   }\n               }, \n               inplace=True)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "embarked_locs = sorted(df_train['Embarked_Val'].unique())\nembarked_locs"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "embarked_val_xt = pd.crosstab(df_train['Embarked_Val'], df_train['Survived'])\nembarked_val_xt_pct = \\\n    embarked_val_xt.div(embarked_val_xt.sum(1).astype(float), axis=0)\nembarked_val_xt_pct.plot(kind='bar', stacked=True)\nplt.title('Survival Rate by Port of Embarkation')\nplt.xlabel('Port of Embarkation')\nplt.ylabel('Survival Rate')"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Set up a grid of plots\nfig = plt.figure(figsize=fizsize_with_subplots) \n\nrows = 2\ncols = 3\ncol_names = ('Sex_Val', 'Pclass')\n\nfor portIdx in embarked_locs:\n    for colIdx in range(0, len(col_names)):\n        plt.subplot2grid((rows, cols), (colIdx, portIdx - 1))\n        df_train[df_train['Embarked_Val'] == portIdx][col_names[colIdx]] \\\n            .value_counts().plot(kind='bar')"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df_train = pd.concat([df_train, pd.get_dummies(df_train['Embarked_Val'], prefix='Embarked_Val')], axis=1)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Feature: Age\nThe Age column seems like an important feature--unfortunately it is missing many values. We'll need to fill in the missing values like we did with Embarked.\n\nFilter to view missing Age values:"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df_train[df_train['Age'].isnull()][['Sex', 'Pclass', 'Age']].head()"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Determine the Age typical for each passenger class by Sex_Val. We'll use the median instead of the mean because the Age histogram seems to be right skewed."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# To keep Age in tact, make a copy of it called AgeFill \n# that we will use to fill in the missing ages:\ndf_train['AgeFill'] = df_train['Age']\n\n# Populate AgeFill\ndf_train['AgeFill'] = df_train['AgeFill'] \\\n                        .groupby([df_train['Sex_Val'], df_train['Pclass']]) \\\n                        .apply(lambda x: x.fillna(x.median()))"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Ensure AgeFill does not contain any missing values:"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "len(df_train[df_train['AgeFill'].isnull()])"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Plot a normalized cross tab for AgeFill and Survived:"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Set up a grid of plots\nfig, axes = plt.subplots(2, 1, figsize=fizsize_with_subplots)\n\n# Histogram of AgeFill segmented by Survived\ndf1 = df_train[df_train['Survived'] == 0]['Age']\ndf2 = df_train[df_train['Survived'] == 1]['Age']\nmax_age = max(df_train['AgeFill'])\naxes[0].hist([df1, df2], \n             bins=max_age / bin_size, \n             range=(1, max_age), \n             stacked=True)\naxes[0].legend(('Died', 'Survived'), loc='best')\naxes[0].set_title('Survivors by Age Groups Histogram')\naxes[0].set_xlabel('Age')\naxes[0].set_ylabel('Count')\n\n# Scatter plot Survived and AgeFill\naxes[1].scatter(df_train['Survived'], df_train['AgeFill'])\naxes[1].set_title('Survivors by Age Plot')\naxes[1].set_xlabel('Survived')\naxes[1].set_ylabel('Age')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Unfortunately, the graphs above do not seem to clearly show any insights. We'll keep digging further.\n\nPlot AgeFill density by Pclass:"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "for pclass in passenger_classes:\n    df_train.AgeFill[df_train.Pclass == pclass].plot(kind='kde')\nplt.title('Age Density Plot by Passenger Class')\nplt.xlabel('Age')\nplt.legend(('1st Class', '2nd Class', '3rd Class'), loc='best')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "When looking at AgeFill density by Pclass, we see the first class passengers were generally older then second class passengers, which in turn were older than third class passengers. We've determined that first class passengers had a higher survival rate than second class passengers, which in turn had a higher survival rate than third class passengers."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Set up a grid of plots\nfig = plt.figure(figsize=fizsize_with_subplots) \nfig_dims = (3, 1)\n\n# Plot the AgeFill histogram for Survivors\nplt.subplot2grid(fig_dims, (0, 0))\nsurvived_df = df_train[df_train['Survived'] == 1]\nsurvived_df['AgeFill'].hist(bins=max_age / bin_size, range=(1, max_age))\n\n# Plot the AgeFill histogram for Females\nplt.subplot2grid(fig_dims, (1, 0))\nfemales_df = df_train[(df_train['Sex_Val'] == 0) & (df_train['Survived'] == 1)]\nfemales_df['AgeFill'].hist(bins=max_age / bin_size, range=(1, max_age))\n\n# Plot the AgeFill histogram for first class passengers\nplt.subplot2grid(fig_dims, (2, 0))\nclass1_df = df_train[(df_train['Pclass'] == 1) & (df_train['Survived'] == 1)]\nclass1_df['AgeFill'].hist(bins=max_age / bin_size, range=(1, max_age))"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "In the first graph, we see that most survivors come from the 20's to 30's age ranges and might be explained by the following two graphs. The second graph shows most females are within their 20's. The third graph shows most first class passengers are within their 30's.\n\n# Feature: Family Size\nFeature enginering involves creating new features or modifying existing features which might be advantageous to a machine learning algorithm.\n\nDefine a new feature FamilySize that is the sum of Parch (number of parents or children on board) and SibSp (number of siblings or spouses):"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch']\ndf_train.head()"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Plot a histogram of FamilySize:"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df_train['FamilySize'].hist()\nplt.title('Family Size Histogram')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Plot a histogram of AgeFill segmented by Survived:"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Get the unique values of Embarked and its maximum\nfamily_sizes = sorted(df_train['FamilySize'].unique())\nfamily_size_max = max(family_sizes)\n\ndf1 = df_train[df_train['Survived'] == 0]['FamilySize']\ndf2 = df_train[df_train['Survived'] == 1]['FamilySize']\nplt.hist([df1, df2], \n         bins=family_size_max + 1, \n         range=(0, family_size_max), \n         stacked=True)\nplt.legend(('Died', 'Survived'), loc='best')\nplt.title('Survivors by Family Size')"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Based on the histograms, it is not immediately obvious what impact FamilySize has on survival. The machine learning algorithms might benefit from this feature.\n\nAdditional features we might want to engineer might be related to the Name column, for example honorrary or pedestrian titles might give clues and better predictive power for a male's survival.\n\n# Final Data Preparation for Machine Learning\nMany machine learning algorithms do not work on strings and they usually require the data to be in an array, not a DataFrame.\n\nShow only the columns of type 'object' (strings):"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df_train.dtypes[df_train.dtypes.map(lambda x: x == 'object')]"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Drop the columns we won't use:"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df_train = df_train.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], \n                         axis=1)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Drop the following columns:\n\n- The Age column since we will be using the AgeFill column instead.\n- The SibSp and Parch columns since we will be using FamilySize instead.\n- The PassengerId column since it won't be used as a feature.\n- The Embarked_Val as we decided to use dummy variables instead."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df_train = df_train.drop(['Age', 'SibSp', 'Parch', 'PassengerId', 'Embarked_Val'], axis=1)\ndf_train.dtypes"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Convert the DataFrame to a numpy array:"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "train_data = df_train.values\ntrain_data"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Data Wrangling Summary\n\nBelow is a summary of the data wrangling we performed on our training data set. We encapsulate this in a function since we'll need to do the same operations to our test set later."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "def clean_data(df, drop_passenger_id):\n    \n    # Get the unique values of Sex\n    sexes = sorted(df['Sex'].unique())\n    \n    # Generate a mapping of Sex from a string to a number representation    \n    genders_mapping = dict(zip(sexes, range(0, len(sexes) + 1)))\n\n    # Transform Sex from a string to a number representation\n    df['Sex_Val'] = df['Sex'].map(genders_mapping).astype(int)\n    \n    # Get the unique values of Embarked\n    embarked_locs = sorted(df['Embarked'].unique(), key=lambda x: str(x))\n\n    # Generate a mapping of Embarked from a string to a number representation        \n    embarked_locs_mapping = dict(zip(embarked_locs, \n                                     range(0, len(embarked_locs) + 1)))\n    \n    # Transform Embarked from a string to dummy variables\n    df = pd.concat([df, pd.get_dummies(df['Embarked'], prefix='Embarked_Val')], axis=1)\n    \n    # Fill in missing values of Embarked\n    # Since the vast majority of passengers embarked in 'S': 3, \n    # we assign the missing values in Embarked to 'S':\n    if len(df[df['Embarked'].isnull()] > 0):\n        df.replace({'Embarked_Val' : \n                       { embarked_locs_mapping[np.nan] : embarked_locs_mapping['S'] \n                       }\n                   }, \n                   inplace=True)\n    \n    # Fill in missing values of Fare with the average Fare\n    if len(df[df['Fare'].isnull()] > 0):\n        avg_fare = df['Fare'].mean()\n        df.replace({ None: avg_fare }, inplace=True)\n    \n    # To keep Age in tact, make a copy of it called AgeFill \n    # that we will use to fill in the missing ages:\n    df['AgeFill'] = df['Age']\n\n    # Determine the Age typical for each passenger class by Sex_Val.  \n    # We'll use the median instead of the mean because the Age \n    # histogram seems to be right skewed.\n    df['AgeFill'] = df['AgeFill'] \\\n                        .groupby([df['Sex_Val'], df['Pclass']]) \\\n                        .apply(lambda x: x.fillna(x.median()))\n            \n    # Define a new feature FamilySize that is the sum of \n    # Parch (number of parents or children on board) and \n    # SibSp (number of siblings or spouses):\n    df['FamilySize'] = df['SibSp'] + df['Parch']\n    \n    # Drop the columns we won't use:\n    df = df.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked'], axis=1)\n    \n    # Drop the Age column since we will be using the AgeFill column instead.\n    # Drop the SibSp and Parch columns since we will be using FamilySize.\n    # Drop the PassengerId column since it won't be used as a feature.\n    df = df.drop(['Age', 'SibSp', 'Parch'], axis=1)\n    \n    if drop_passenger_id:\n        df = df.drop(['PassengerId'], axis=1)\n    \n    return df"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Random Forest: Training\nCreate the random forest object:"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "from sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier(n_estimators=100)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Fit the training data and create the decision trees:"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Training data features, skip the first column 'Survived'\ntrain_features = train_data[:, 1:]\n\n# 'Survived' column values\ntrain_target = train_data[:, 0]\n\n# Fit the model to our training data\nclf = clf.fit(train_features, train_target)\nscore = clf.score(train_features, train_target)\n\"Mean accuracy of Random Forest: {0}\".format(score)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Random Forest: Predicting\nRead the test data:"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df_test = pd.read_csv('../input/test.csv')\ndf_test.head()"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Note the test data does not contain the column 'Survived', we'll use our trained model to predict these values."
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Data wrangle the test set and convert it to a numpy array\ndf_test = clean_data(df_test, drop_passenger_id=False)\ntest_data = df_test.values"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Take the decision trees and run it on the test data:"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# Get the test data features, skipping the first column 'PassengerId'\ntest_x = test_data[:, 1:]\n\n# Predict the Survival values for the test data\ntest_y = clf.predict(test_x)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Random Forest: Prepare for Kaggle Submission\nCreate a DataFrame by combining the index from the test data with the output of predictions, then write the results to the output:"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "df_test['Survived'] = test_y\ndf_test[['PassengerId', 'Survived']] \\\n    .to_csv('results-rf.csv', index=False)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Evaluate Model Accuracy\nSubmitting to Kaggle will give you an accuracy score. It would be helpful to get an idea of accuracy without submitting to Kaggle.\n\nWe'll split our training data, 80% will go to \"train\" and 20% will go to \"test\":"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "from sklearn import metrics\nfrom sklearn.cross_validation import train_test_split\n\n# Split 80-20 train vs test data\ntrain_x, test_x, train_y, test_y = train_test_split(train_features, \n                                                    train_target, \n                                                    test_size=0.20, \n                                                    random_state=0)\nprint (train_features.shape, train_target.shape)\nprint (train_x.shape, train_y.shape)\nprint (test_x.shape, test_y.shape)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Use the new training data to fit the model, predict, and get the accuracy score:"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "clf = clf.fit(train_x, train_y)\npredict_y = clf.predict(test_x)\n\nfrom sklearn.metrics import accuracy_score\nprint (\"Accuracy = %.2f\" % (accuracy_score(test_y, predict_y)))"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "model_score = clf.score(test_x, test_y)\nprint (\"Model Score %.2f \\n\" % (model_score))\n\nconfusion_matrix = metrics.confusion_matrix(test_y, predict_y)\nprint (\"Confusion Matrix \", confusion_matrix)\n\nprint (\"          Predicted\")\nprint (\"         |  0  |  1  |\")\nprint (\"         |-----|-----|\")\nprint (\"       0 | %3d | %3d |\" % (confusion_matrix[0, 0],\n                                   confusion_matrix[0, 1]))\nprint (\"Actual   |-----|-----|\")\nprint (\"       1 | %3d | %3d |\" % (confusion_matrix[1, 0],\n                                   confusion_matrix[1, 1]))\nprint (\"         |-----|-----|\")"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "Display the classification report:\n\nPrecision=TPTP+FP\nPrecision=TPTP+FP\nRecall=TPTP+FN\nRecall=TPTP+FN\nF1=2TP2TP+FP+FN"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "from sklearn.metrics import classification_report\nprint(classification_report(test_y, \n                            predict_y, \n                            target_names=['Not Survived', 'Survived']))"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": ""
 }
],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}, "nbformat": 4, "nbformat_minor": 0}