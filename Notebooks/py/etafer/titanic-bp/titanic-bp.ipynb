{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"collapsed":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"611f75e33b2d4c8139c36df06dd244ecb72a2ca2"},"cell_type":"markdown","source":"# Acquire data\n"},{"metadata":{"trusted":true,"_uuid":"be270f461b1f4d5667a78826099f51218480e0c4","collapsed":true},"cell_type":"code","source":"train_df=pd.read_csv('../input/train.csv',index_col=0)\ntest_df=pd.read_csv('../input/test.csv',index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1308dc2328497954dc674636d3d4c16dc82f504c","collapsed":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10717b776c616104f19599de4e917a6b50b38016","collapsed":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a1ce41dabb3edfbbb22832f93d9f7e092e59d2f0"},"cell_type":"markdown","source":"# Combine data"},{"metadata":{"trusted":true,"_uuid":"62df7e7a46012045c06661b9b6f1f84063abdf33","collapsed":true},"cell_type":"code","source":"y_train=train_df.pop('Survived')\nall_df=pd.concat((train_df,test_df),axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45f2b608029ccddfee51c9d09d917d539dfcfbe1","collapsed":true},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"da05d19cb55829c166648c2033acf20b34694732"},"cell_type":"code","source":"all_df.drop(['Name'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2ec20a851c87c2e4c036b1323d934040e8602fe6"},"cell_type":"code","source":"all_df.drop(['Ticket'],axis=1,inplace=True)\nall_df.drop(['Cabin'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bad672656b37f293c04a7f6f14a8f89b1d0f7bf","collapsed":true},"cell_type":"code","source":"all_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"904399a28c2c4b7708987f1d2a07001d4a3f7f4f"},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true,"_uuid":"6a625f0a97c7280e8a2fd1d056b55bdb72a29be7","collapsed":true},"cell_type":"code","source":"all_df['Pclass'].dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3bc515fc1e32692d703e4ef1519694cc6ebe148e","collapsed":true},"cell_type":"code","source":"all_df['Pclass']=all_df['Pclass'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abc12f9f5c97ebf2a1a596c74b2b6d2c2af84370","collapsed":true},"cell_type":"code","source":"all_df['Pclass'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"358360d6746aa7bdfdfc646d7cd18398a04833a6","collapsed":true},"cell_type":"code","source":"pd.get_dummies(all_df['Pclass'],prefix='Pclass').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6ff875e3422f5c1c37dc6c9bb6570efc544299c","collapsed":true},"cell_type":"code","source":"all_dummy_df=pd.get_dummies(all_df)\nall_dummy_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cce84e844dc6176f0b06c0c7f462003a0213ad1a","collapsed":true},"cell_type":"code","source":"all_dummy_df['SibSp'].value_counts()\n#all_dummy_df['Parch'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b33f288049c5c5e4d61d497579af5e79271568a6","collapsed":true},"cell_type":"code","source":"all_dummy_df.isnull().sum().sort_values(ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eea89cf74dd28c972a2515c473d25f7a5d54065d","collapsed":true},"cell_type":"code","source":"mean_cols= all_dummy_df.mean()\nmean_cols.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"62a6c0214eb47765d8c9c2f35895fd34782d1ede"},"cell_type":"code","source":"all_dummy_df=all_dummy_df.fillna(mean_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d85fd527eacd53c64af8a90ff7fe239f735db09a","collapsed":true},"cell_type":"code","source":"all_dummy_df['Fare']=np.log1p(all_dummy_df['Fare'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"018383d77b880ac8df1ed79f9291c3973f3dde83","collapsed":true},"cell_type":"code","source":"all_dummy_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8931c83e8bd60867125c113ebbbaab702a325b6b"},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true,"_uuid":"3b7c57fe1885363fa6b53df182b4634441329f1a","collapsed":true},"cell_type":"code","source":"dummy_train_df=all_dummy_df.loc[train_df.index]\ndummy_test_df=all_dummy_df.loc[test_df.index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"216f13d37ddee99230d5feb5038f6e8b846bc806"},"cell_type":"code","source":"X_train = dummy_train_df.values\nX_test = dummy_test_df.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8aec8b4c525dcc4896ab0a5ec57376b3a0229f6","collapsed":true},"cell_type":"code","source":"dummy_train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5811da7069fca0f9916f8b2cadc3cee93f972096"},"cell_type":"code","source":"def tanh(x):  \n    return np.tanh(x)\n\ndef tanh_deriv(x):  \n    return 1.0 - np.tanh(x)*np.tanh(x)\n\ndef logistic(x):  \n    return 1/(1 + np.exp(-x))\n\ndef logistic_derivative(x):  \n    return logistic(x)*(1-logistic(x))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2509caf790259449dbe17b945f22ac9b649d68c","collapsed":true},"cell_type":"code","source":"class NeuralNetwork:   \n    def __init__(self, layers, learning_rate,activation='tanh'):  \n        \"\"\"  \n        :param layers: A list containing the number of units in each layer.\n        Should be at least two values  \n        :param activation: The activation function to be used. Can be\n        \"logistic\" or \"tanh\"  \n        \"\"\"  \n        if activation == 'logistic':  \n            self.activation = logistic  \n            self.activation_deriv = logistic_derivative  \n        elif activation == 'tanh':  \n            self.activation = tanh  \n            self.activation_deriv = tanh_deriv\n        self.learning_rate=learning_rate\n        \n        self.weights = []  \n        for i in range(1, len(layers) - 1):  \n            self.weights.append((2*np.random.random((layers[i - 1] + 1, layers[i] + 1))-1)*0.25)  \n            self.weights.append((2*np.random.random((layers[i] + 1, layers[i + 1]))-1)*0.25)\n    \n    \n    def fit(self, X, y,epochs=10000):         \n        X = np.atleast_2d(X)         \n        temp = np.ones([X.shape[0], X.shape[1]+1])         \n        temp[:, 0:-1] = X  # adding the bias unit to the input layer         \n        X = temp         \n        y = np.array(y)\n    \n        for k in range(epochs):  \n            i = np.random.randint(X.shape[0])  \n            a = [X[i]]\n    \n            for l in range(len(self.weights)):  #going forward network, for each layer\n                a.append(self.activation(np.dot(a[l], self.weights[l])))  #Computer the node value for each layer (O_i) using activation function\n            error = y[i] - a[-1]  #Computer the error at the top layer\n            deltas = [error * self.activation_deriv(a[-1])] #For output layer, Err calculation (delta is updated error)\n            \n            #Staring backprobagation\n            for l in range(len(a) - 2, 0, -1): # we need to begin at the second to last layer \n                #Compute the updated error (i,e, deltas) for each node going from top layer to input layer \n                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_deriv(a[l]))  \n            deltas.reverse()  \n            for i in range(len(self.weights)):  \n                layer = np.atleast_2d(a[i])  \n                delta = np.atleast_2d(deltas[i])  \n                self.weights[i] += self.learning_rate * layer.T.dot(delta)\n                \n                \n    def predict(self, x):         \n        x = np.array(x)         \n        temp = np.ones(x.shape[0]+1)         \n        temp[0:-1] = x         \n        a = temp         \n        for l in range(0, len(self.weights)):             \n            a = self.activation(np.dot(a, self.weights[l]))         \n        return a\n    def predicts(self,X):\n        predictions=[]\n        for i in X:\n            predictions.append(self.predict(i))\n        return predictions\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b6ab29f8080ea1459827a20315c1d2d36e8af57"},"cell_type":"code","source":"import math\nparams=[0.001,0.01,0.03,0.05,0.07,0.1,0.2,0.3,0.4,0.5,0.6]\nRMSEs=[]\nfor param in params:\n    nn = NeuralNetwork([12,2,1],param,'tanh')\n    nn.fit(X_train,y_train)\n    y_predict=nn.predicts(X_train)\n    training_root_mean_squared_error=math.sqrt(metrics.mean_squared_error(y_predict,y_train))\n    RMSEs.append(training_root_mean_squared_error)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"126fba3b56c1aa9e72dc3cac8ebec7529ebd59cc"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nplt.plot(params, RMSEs)\nplt.title(\"learning_rate vs RMSE\");","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}