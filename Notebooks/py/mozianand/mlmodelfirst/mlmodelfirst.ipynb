{"nbformat_minor": 1, "metadata": {"language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "file_extension": ".py", "version": "3.6.4", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "pygments_lexer": "ipython3"}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat": 4, "cells": [{"execution_count": null, "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in # Store target variable of training data in a safe plac\n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import re\n", "from sklearn import tree\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.model_selection import GridSearchCV\n", "\n", "# Figures inline and set visualization style\n", "%matplotlib inline\n", "sns.set()\n", "\n", "# Import data\n", "df_train = pd.read_csv('../input/train.csv')\n", "df_test = pd.read_csv('../input/test.csv')\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": [], "metadata": {"_uuid": "281823d752c92ba4ac5723d8944db11c125bc19e", "_cell_guid": "dc9a17aa-dd37-4283-9b89-24f44876dda0", "collapsed": true}}, {"cell_type": "markdown", "source": ["I will drop the 'Survived' from the training dataset and create a new DataFrame data that consists of training and test sets combined. To have data cohrence for reference will store the target variable of the training data for safe keeping."], "metadata": {"_uuid": "a0762d6a62f3173e723388c096c8f90f47474e1a", "_cell_guid": "3156d98d-d03b-4e06-a9cc-5493cec383f4"}}, {"execution_count": null, "cell_type": "code", "source": ["# Store target variable of training data in a safe place\n", "survived_train = df_train.Survived\n", "\n", "# Concatenate training and test sets to create a new Merged_data\n", "Merged_data = pd.concat([df_train.drop(['Survived'], axis=1), df_test])\n", "\n", "# Check info Merged_data \n", "Merged_data.info()"], "outputs": [], "metadata": {"_uuid": "23e4ebc95e476abc814af5c3b13182e223a8419c", "_cell_guid": "d432ddd2-5a32-46bc-8fc9-214ebdbe4bdc", "collapsed": true}}, {"cell_type": "markdown", "source": ["   If you see above output counts there are missing values. In total 1309 Passanger are there out of which only 1046 have values. We need fill the missing values.  Fare also has missing values for 1 record"], "metadata": {"_uuid": "4f085c0e3a8877621c4368841ac8f1f154017e3a", "_cell_guid": "94f012a0-62e6-4e14-832e-e66475987714"}}, {"execution_count": null, "cell_type": "code", "source": ["# Fill the missing numerical variables\n", "Merged_data['Age'] = Merged_data.Age.fillna(Merged_data.Age.median())\n", "Merged_data['Fare'] = Merged_data.Fare.fillna(Merged_data.Fare.median())\n", "\n", "# Check out info of data\n", "Merged_data.info()"], "outputs": [], "metadata": {"_uuid": "06425413f605f665a505eef4f30e79cc4b06c575", "_cell_guid": "31a21e6f-2256-485c-b54b-682c2f3700a2", "collapsed": true}}, {"cell_type": "markdown", "source": ["I am planning to change values of Sex into 0 and 1 i.e Numbers..."], "metadata": {"_uuid": "cfa9d24be36875a195282dc1955259d36c7fa4de", "_cell_guid": "f1a24316-fb3e-41f0-96e9-ecf929b60d8e"}}, {"execution_count": null, "cell_type": "code", "source": ["Merged_data = pd.get_dummies(Merged_data, columns=['Sex'], drop_first=True)\n", "Merged_data.head()"], "outputs": [], "metadata": {"_uuid": "a66e0a0029cc9a4dd669b76516b3f7c6e821d31c", "_cell_guid": "3e8c7e62-30d0-4339-9bc7-32013eafb34d", "collapsed": true}}, {"cell_type": "markdown", "source": ["Use columns ['Sex_male', 'Fare', 'Age','Pclass', 'SibSp'] from the  DataFrame to build your first machine learning model."], "metadata": {"_uuid": "1e2c13b679ffe4be5b1602aae57a3c23c0ffd567", "_cell_guid": "4a219e54-96a4-4d1e-b79f-f2e6eb9a08bf"}}, {"execution_count": null, "cell_type": "code", "source": ["# Select columns and view head\n", "Merged_data = Merged_data[['Sex_male', 'Fare', 'Age','Pclass','SibSp']]\n", "Merged_data.head()"], "outputs": [], "metadata": {"_uuid": "cd1df4fa13d9ff48f83af0fae271316ffaed1225", "_cell_guid": "f4981234-1fbb-43b1-a517-ae274990959f", "collapsed": true}}, {"cell_type": "markdown", "source": ["  I am going to use a Decision Tree Classifier... But before fitting the model, let me split the data back in training and test data set"], "metadata": {"_uuid": "d5ddbf871619ddbff10d74b8931947a2a9b27661", "_cell_guid": "8a835e27-d08f-4119-8846-1c016d157d16"}}, {"execution_count": null, "cell_type": "code", "source": ["data_train = Merged_data.iloc[:891]\n", "data_test = Merged_data.iloc[891:]"], "outputs": [], "metadata": {"_uuid": "59046b5a9d7de342b311f5f3c2b169eeaa91c679", "_cell_guid": "dc0bec1e-ce74-474c-8157-09184ea8722b", "collapsed": true}}, {"cell_type": "markdown", "source": ["    Convert into arrays as the model or decision tree classfier works on arrays"], "metadata": {"_uuid": "9c0211147df9420790a18d154ba0615e137bbc59", "_cell_guid": "72df1837-999b-4a12-af92-23d703ec75ef"}}, {"execution_count": null, "cell_type": "code", "source": ["X = data_train.values\n", "test = data_test.values\n", "y = survived_train.values"], "outputs": [], "metadata": {"_uuid": "029ecfac3c1e05cbbcb0a682bb34de1c84861b03", "_cell_guid": "1b63259d-9a30-4b01-b6b1-8117a685036f", "collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["# Instantiate model and fit to data\n", "clf = tree.DecisionTreeClassifier(max_depth=3)\n", "clf.fit(X, y)"], "outputs": [], "metadata": {"_uuid": "1e1ca1d688d08ae7f25212c1a42d39d208eb8872", "_cell_guid": "f4a259f7-b660-45df-9619-3f087b54153b", "collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["# Make predictions and store in 'Survived' column of df_test\n", "Y_pred = clf.predict(test)\n", "df_test['Survived'] = Y_pred"], "outputs": [], "metadata": {"_uuid": "e09d2c2bee315830c6fbf03f261425b1d2347f6d", "_cell_guid": "0e4a07d0-3142-4f6f-8353-3190383f0946", "collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["#df_test[['PassengerId', 'Survived']].to_csv('2nd_dec_tree_version.csv', index=False)\n"], "outputs": [], "metadata": {"_uuid": "79d84b115a702e570fdb3a0e5833be3c2b81df67", "_cell_guid": "c492e699-91ef-4235-b212-54d8060fed5f", "collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["from sklearn.ensemble import RandomForestClassifier\n", "rfc = RandomForestClassifier(n_estimators=5000)\n", "rfc.fit(X, y)"], "outputs": [], "metadata": {"_uuid": "8d778f5507d6340da5f13225b1e0fad6f632f5f2", "_cell_guid": "deb61175-06b6-41c9-864f-38573941148f", "collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["rfc_pred =rfc.predict(test)\n", "df_test['Survived'] = rfc_pred\n", "df_test[['PassengerId', 'Survived']].to_csv('Randm_Forest_versionMD.csv', index=False)\n"], "outputs": [], "metadata": {"_uuid": "e89019a2b88af6777d7e288e5232df15e954e257", "_cell_guid": "d3bc72b3-2ef8-4178-aa5a-10c3a52b004d", "collapsed": true}}]}