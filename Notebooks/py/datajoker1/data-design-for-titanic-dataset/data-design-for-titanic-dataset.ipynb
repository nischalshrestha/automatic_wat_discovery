{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5f4c672e-85bd-1167-bc27-c8e4b6d1638e"
      },
      "source": [
        "Titanic data analysis\n",
        "---------------------\n",
        "\n",
        " 1. Load dataset\n",
        " 2. Data preprocessing\n",
        " 3. Data EDA\n",
        " 4. Evaluate Algorithms (Base line)\n",
        " 5. Prepare the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b3283448-5b38-799a-bad4-9ee15bf20b34"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "from pandas import set_option\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "# 1. Load dataset\n",
        "train_df = read_csv(\"../input/train.csv\")\n",
        "test_df = read_csv(\"../input/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b68f50e6-67ff-0e69-30bd-4b5c572c8958"
      },
      "outputs": [],
      "source": [
        "# 2. Data preprocessing\n",
        "# check shape (row and column count)\n",
        "print (train_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8b33d890-23c5-6b87-910c-284d3e54d64c"
      },
      "outputs": [],
      "source": [
        "# check few head datas  \n",
        "# we can see missing value (NaN)\n",
        "# and Name, PassengerId, Ticket columns is object type.\n",
        "train_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "47478796-d7bd-5529-aaff-4490754df6d1"
      },
      "outputs": [],
      "source": [
        "# check mssing value \n",
        "for col_name in train_df.columns.values:\n",
        "    col_null_ct = train_df[col_name].isnull().sum()\n",
        "    if col_null_ct.sum() > 0:\n",
        "        print (\"col_name:%s, count:%d\" % (col_name, col_null_ct))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9033ea11-a76f-3c31-066e-49f88eadab72"
      },
      "outputs": [],
      "source": [
        "# check type\n",
        "for col in train_df:\n",
        "    print (col, train_df[col].dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3897b146-acd3-429c-0759-c2c24fca9c19"
      },
      "outputs": [],
      "source": [
        "# check complexity\n",
        "train_df['Sex'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9d5fd7ae-d41c-5374-0275-6a945560bc1e"
      },
      "outputs": [],
      "source": [
        "# check complexity\n",
        "train_df['Embarked'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5eeeab2a-6a59-9757-e121-ee214d0ffb51"
      },
      "outputs": [],
      "source": [
        "# We set a naive Hypotheses is that drop all column having object type. (not consider to transform object to numeric)\n",
        "# Except Sex and Embarked column because they have less complexity\n",
        "train_df = train_df.drop(['Name','PassengerId','Ticket'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c6617682-3398-6b65-3a98-6f75660178f1"
      },
      "outputs": [],
      "source": [
        "# Drop the Cabin, Age column because they have many missing values.\n",
        "train_df = train_df.drop(['Cabin','Age'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "932523ec-6cd5-0ab9-a6fb-fdc4d1a893a9"
      },
      "outputs": [],
      "source": [
        "# Transform object to numeric\n",
        "train_df['Sex'] = train_df['Sex'].map( {'female': 1, 'male': 0} ).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9f322a1c-d2a0-f69a-617d-c244e304ceff"
      },
      "outputs": [],
      "source": [
        "# Check the Embarked values distribution\n",
        "train_df.groupby('Embarked').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fa5b07ca-c314-e2e1-ed51-b8ac79adb504"
      },
      "outputs": [],
      "source": [
        "# Fill missing value for Embarked\n",
        "train_df['Embarked'] = train_df['Embarked'].fillna('S')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "42e06134-feee-3aab-bd73-a45690bd34be"
      },
      "outputs": [],
      "source": [
        "# Transform object to numeric\n",
        "train_df['Embarked'] = train_df['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "efb9a68d-2ff6-d7ac-77f5-3b347a0754f2"
      },
      "outputs": [],
      "source": [
        "# check table\n",
        "train_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "54f54d41-1845-1037-7dc8-d0e3d19d55f6"
      },
      "outputs": [],
      "source": [
        "# 3. Data EDA\n",
        "# Set floating point precision to 3\n",
        "set_option( \"precision\" , 3)\n",
        "# Check descriptive statis metrics\n",
        "print(train_df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "feebaee8-d0ef-c0d0-4abd-f2ba0f26459f"
      },
      "outputs": [],
      "source": [
        "# Check the Data balance\n",
        "train_df.groupby('Survived').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "56366105-ec04-76b0-d6b2-645aac7345b5"
      },
      "outputs": [],
      "source": [
        "# Check density\n",
        "train_df.plot(kind= \"density\" , subplots=True, layout=(3,3), sharex=False, legend=False, fontsize=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0b65ab8d-9f92-2147-ee86-80a4ca1fc36a"
      },
      "outputs": [],
      "source": [
        "# Check middle and distribution\n",
        "train_df.plot(kind= \"box\" , subplots=True, layout=(3,3), sharex=False, sharey=False, fontsize=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "52e4fbcc-217a-c2f9-e75e-6321b3916302"
      },
      "outputs": [],
      "source": [
        "# Check correlation matrix\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(train_df.corr(), vmin=-1, vmax=1, interpolation= \"none\" )\n",
        "fig.colorbar(cax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "50ced69d-cff0-4d5d-6253-985433c7d661"
      },
      "outputs": [],
      "source": [
        "# 4. Evaluate Algorithms: Baseline\n",
        "\n",
        "# Test options and evaluation metric\n",
        "num_folds = 10\n",
        "seed = 7\n",
        "scoring = \"accuracy\"\n",
        "\n",
        "# Spot-Check Algorithms\n",
        "models = []\n",
        "models.append(( \"LR\" , LogisticRegression()))\n",
        "models.append(( \"LDA\" , LinearDiscriminantAnalysis()))\n",
        "models.append(( \"KNN\" , KNeighborsClassifier()))\n",
        "models.append(( \"CART\" , DecisionTreeClassifier()))\n",
        "models.append(( \"NB\" , GaussianNB()))\n",
        "models.append(( \"SVM\" , SVC()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "45543ffb-c8b7-cd47-328a-a8bc83c526ad"
      },
      "outputs": [],
      "source": [
        "# Split-out validation dataset\n",
        "array = train_df.values\n",
        "\n",
        "X = array[:,1:7].astype(float)\n",
        "Y = array[:,0]\n",
        "\n",
        "validation_size = 0.20\n",
        "seed = 7\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3d71be47-092f-990e-141b-6ad802986002"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
        "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print (msg)\n",
        "# We can see LogisticRegression is best performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9fcbdb9b-50bc-9dc2-4f0d-77e5747d0e32"
      },
      "outputs": [],
      "source": [
        "# We can transform all row data to have zero mean and unit variance\n",
        "# Standardize the dataset\n",
        "pipelines = []\n",
        "pipelines.append(( \"ScaledLR\" , Pipeline([( \"Scaler\" , StandardScaler()),( \"LR\" , LogisticRegression())])))\n",
        "pipelines.append(( \"ScaledLDA\" , Pipeline([( \"Scaler\" , StandardScaler()),( \"LDA\" , LinearDiscriminantAnalysis())])))\n",
        "pipelines.append(( \"ScaledKNN\" , Pipeline([( \"Scaler\" , StandardScaler()),( \"KNN\" , KNeighborsClassifier())])))\n",
        "pipelines.append(( \"ScaledCART\" , Pipeline([( \"Scaler\" , StandardScaler()),( \"CART\" , DecisionTreeClassifier())])))\n",
        "pipelines.append(( \"ScaledNB\" , Pipeline([( \"Scaler\" , StandardScaler()),( \"NB\" , GaussianNB())])))\n",
        "pipelines.append(( \"ScaledSVM\" , Pipeline([( \"Scaler\" , StandardScaler()),( \"SVM\" , SVC())])))\n",
        "results = []\n",
        "names = []\n",
        "for name, model in pipelines:\n",
        "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
        "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "# We can see SVM is best performance now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "971e38b6-8dc8-6ef5-c0e5-0262d510ca41"
      },
      "outputs": [],
      "source": [
        "# prepare predict the model\n",
        "test_df_bk = test_df\n",
        "test_df = test_df.drop(['Cabin','Age'], axis=1)\n",
        "test_df = test_df.drop(['Name','PassengerId','Ticket'], axis=1)\n",
        "test_df['Sex'] = test_df['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
        "test_df['Embarked'] = test_df['Embarked'].fillna('S')\n",
        "test_df['Embarked'] = test_df['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
        "test_df['Fare'] = test_df['Fare'].fillna(test_df['Fare'].mean())\n",
        "X_test = test_df.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ca27b90d-08d8-2d74-b5ba-f7eb6ddb57f3"
      },
      "outputs": [],
      "source": [
        "# 5. Prepare the model\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "rescaledX = scaler.transform(X_train)\n",
        "model = SVC()\n",
        "model.fit(rescaledX, Y_train)\n",
        "\n",
        "# estimate accuracy on validation dataset\n",
        "rescaledValidationX = scaler.transform(X_test)\n",
        "predictions = model.predict(rescaledValidationX)\n",
        "\n",
        "#create solution csv for submission\n",
        "PassengerId = np.array(test_df_bk['PassengerId']).astype(int)\n",
        "predictions = predictions.astype(int)\n",
        "submission = pd.DataFrame(predictions, PassengerId, columns=['Survived'])\n",
        "print(submission.shape)\n",
        "#submission.to_csv('Titanic_solution', index_label = ['PassengerId'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "dcdff262-3303-ae1a-100c-59ceeb714080"
      },
      "source": [
        "References\n",
        "----------\n",
        "\n",
        " - [http://machinelearningmastery.com/blog/][1]\n",
        "\n",
        "\n",
        "  [1]: http://machinelearningmastery.com/blog/"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}