{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib as plt\nimport seaborn as sns\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d590047eb3c3f67e481b29ba347559a3b59c3961","scrolled":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e053c07e03c798a6c17e04fcf3d8457bc80a12a"},"cell_type":"markdown","source":"# Análise dos Dados #\nFazer uns gráficos bonitinhos, só para tentarmos \"perceber\" os dados."},{"metadata":{"trusted":true,"_uuid":"816d0d9db6ad1f29e8260d28f46207751ace2be1"},"cell_type":"code","source":"# Set multiple plots distribution\nfigs, axs = plt.pyplot.subplots(nrows = 3, ncols = 3, figsize=(30,15))\n\nsns.barplot(x=\"Pclass\", y=\"Survived\", data=train_df, ax = axs[0][0])\nsns.barplot(x=\"Sex\", y=\"Survived\", data=train_df, ax = axs[0][1])\nsns.barplot(x=\"Parch\", y=\"Survived\", data=train_df, ax = axs[0][2])\nsns.barplot(x=\"SibSp\", y=\"Survived\", data=train_df, ax = axs[1][0])\nsns.boxplot(x=\"Survived\", y=\"Fare\", data=train_df[(train_df[\"Sex\"] == \"female\") & (train_df[\"Fare\"] < 100)], ax = axs[1][1])\nsns.scatterplot(x=\"Age\", y=\"Fare\", hue=\"Survived\", data=train_df[(train_df[\"Fare\"] < 60) & (train_df[\"Age\"] < 60)], ax = axs[1][2])\nsns.barplot(x=\"Embarked\", y=\"Survived\", data=train_df, ax=axs[2][1])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"def406a96375f26d1f1bc9085f2ca4d8aae27cdf"},"cell_type":"markdown","source":"Agora podiamos fazer mais gráficos, com outros fatores. Por exemplo, fazer gráficos só para homens, ou só para adultos. Se tiver paciência acrescento-os depois. "},{"metadata":{"_uuid":"e59571de43088a33fcdc9b0c6e2b7c897ae24efa"},"cell_type":"markdown","source":"# Feature Creation\nVamos criar:\n* Deck - Extraída de Cabin. A primeira letra representa o Deck em que ficava a Cabin.\n* AgeIsNaN - Exactamente o que diz. Indica se Age é ou não NaN."},{"metadata":{"trusted":true,"_uuid":"499633eee1e00a06706ef00032ff6a73ed8601c1"},"cell_type":"code","source":"def cab_to_deck(cab):\n    if type(cab) is float or cab[0] == 'T':\n        return \"N\"\n    else:\n        return cab[0]\n    \ntrain_df[\"Deck\"] = train_df[\"Cabin\"].apply(cab_to_deck)\ntest[\"Deck\"] = test[\"Cabin\"].apply(cab_to_deck)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75c2dc42854892995d52223a4c8f6260bbeff2c5"},"cell_type":"code","source":"cabin_is_nan = train_df[\"Cabin\"].isna().sum() / len(train_df[\"Cabin\"])\nprint(\"Percentage of NaN: \", cabin_is_nan*100)\n\nfigs, axs = plt.pyplot.subplots(ncols = 2, figsize = (30,5))\n\nsns.barplot(x=\"Deck\", y=\"Survived\", data=train_df, ax = axs[0])\nsns.countplot(x=\"Deck\", data=train_df, ax = axs[1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45d70b75c401c441087b2f6fe3c073e30bbfb4ba"},"cell_type":"markdown","source":"Ou seja, não temos dados para a Cabin, e consequentemente para o Deck, em 77% dos dados. Mas parece o facto de sabermos ou não em que Deck alguem estava é bastante relevante."},{"metadata":{"trusted":true,"_uuid":"8fa85f2ded6ac256954fbc25406c2c8c71616b9e"},"cell_type":"code","source":"# Criar a Feature\ntrain_df[\"AgeIsNaN\"] = train_df[\"Age\"].isna()\ntest[\"AgeIsNaN\"] = test[\"Age\"].isna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f664bcdbf75043067ce8800184366bd56a03bb93"},"cell_type":"code","source":"sns.barplot(x=\"AgeIsNaN\", y=\"Survived\", data=train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16e6e9c2be2956bf940c45720887240cd9937a0a"},"cell_type":"code","source":"# Substituir valores NaN em Age\ntrain_df[\"Age\"].fillna(train_df[\"Age\"].mean(), inplace=True)\ntest[\"Age\"].fillna(test[\"Age\"].mean(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"339e1fc32b7b4abdcb3c249657de3ca1022d7b9b"},"cell_type":"markdown","source":"# Processamento dos Dados #\nAgora vamos só tentar processar um bocado os dados, de modo a poderem ser usados melhores pelos modelos. \n* Vamos aplicar feature scaling a \"Fare\" e \"Age\".\n* One Hot Encoding a Pclass, Sex, SibSp, Parch, Deck e Embarked. \n* Vamos retirar Cabin e Ticket"},{"metadata":{"trusted":true,"_uuid":"3d1380bcc7dbd2cda33065215c0fd8dc3be85208"},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9d8c0db54008e20c3760517c25b43726fbe9195"},"cell_type":"code","source":"ids = test[\"PassengerId\"]\ntest = test.drop(columns = [\"PassengerId\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c432ab0a865e37cfcc515c1dbc76bf7a0279d0f1"},"cell_type":"code","source":"# Estabelecer um máximo para Fare, 150, para ter melhores resultados ao usar MinMaxScaler\ntrain_df.loc[train_df[\"Fare\"] > 150, \"Fare\"] = train_df.loc[train_df[\"Fare\"] > 150, \"Fare\"].apply(lambda x: 100)\ntest.loc[test[\"Fare\"] > 150, \"Fare\"] = test.loc[train_df[\"Fare\"] > 150, \"Fare\"].apply(lambda x: 100)\n\ntest[\"Fare\"].fillna(test[\"Fare\"].mean(), inplace = True)\n\nsns.distplot(train_df[\"Fare\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49eb61af139cdd78a4a48954221562bf9280fbae"},"cell_type":"code","source":"scaler = MinMaxScaler()\ntrain_df[[\"Age\", \"Fare\"]] = scaler.fit_transform(train_df[[\"Age\", \"Fare\"]])\ntest[[\"Age\", \"Fare\"]] = scaler.fit_transform(test[[\"Age\", \"Fare\"]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b097a5343663d11bdc46c97e8640b03bde8c923e"},"cell_type":"code","source":"train_df = train_df.drop(columns = ['Ticket', 'Cabin', 'Name'])\ntest = test.drop(columns = ['Ticket', 'Cabin', 'Name'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b66accfe8510f9d552abc3a25839802488d6443"},"cell_type":"code","source":"# Converter as features em dummies\npclass_dummies = pd.get_dummies(train_df[\"Pclass\"], prefix='pclass')\nsex_dummies = pd.get_dummies(train_df[\"Sex\"], prefix='sex')\n#sibsp_dummies = pd.get_dummies(train_df[\"SibSp\"], prefix='sibsp')\n#parch_dummies = pd.get_dummies(train_df[\"Parch\"], prefix='parch')\ndeck_dummies = pd.get_dummies(train_df[\"Deck\"], prefix='deck')\nembarked_dummies = pd.get_dummies(train_df[\"Embarked\"], prefix='embarked')\n\ntrain_df = train_df.join([pclass_dummies, sex_dummies, deck_dummies, embarked_dummies])\n\npclass_dummies = pd.get_dummies(test[\"Pclass\"], prefix='pclass')\nsex_dummies = pd.get_dummies(test[\"Sex\"], prefix='sex')\n#sibsp_dummies = pd.get_dummies(test[\"SibSp\"], prefix='sibsp')\n#parch_dummies = pd.get_dummies(test[\"Parch\"], prefix='parch')\ndeck_dummies = pd.get_dummies(test[\"Deck\"], prefix='deck')\nembarked_dummies = pd.get_dummies(test[\"Embarked\"], prefix='embarked')\n\ntest = test.join([pclass_dummies, sex_dummies, deck_dummies, embarked_dummies])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00d4ba2fa795962359ba27769e2fd78e840d59e2"},"cell_type":"code","source":"# Apagar antigas features convertidas, Ticket, Cabin e Name\ntrain_df = train_df.drop(columns = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Deck', 'Embarked'])\ntest = test.drop(columns = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Deck', 'Embarked'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f98f7374f86cc46c1ec4b5af75e8821902092d18"},"cell_type":"code","source":"# Separar as labels dos dados\ny = train_df[\"Survived\"]\nX = train_df.drop(columns = [\"Survived\", \"PassengerId\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7645f337a7a37c4bb67f8afd384ace0de839f8da"},"cell_type":"code","source":"# Separar os dados em casos de teste e de treino\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"646ae59c73c09acbb9e487a1ae96cbf1db08158d"},"cell_type":"markdown","source":"# Model making\nAgora que já temos todas as features prontas, podemos começar a criar Models. \nVamos experimentar:\n* SVM\n* Logistic Regression\n* Nearest Neighbours\n* Decision Tree\n* Random Forest\n* Gradient Boosted Decision Trees\n\n"},{"metadata":{"trusted":true,"_uuid":"10dcee49bae34dd4fb972f1190c819951e609028"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import svm\n\nfrom sklearn.model_selection import GridSearchCV, cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b2c8e7b39ccb845ea465042626040e6f3769fe6a"},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true,"_uuid":"aa3e829f4a072afc133eaf56e921682d1adfddf3"},"cell_type":"code","source":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4b68ff7fe8d0cbed82adf43f9da93ab37d86723"},"cell_type":"code","source":"print(logreg.score(X_train, y_train))\nprint(cross_val_score(logreg, X, y, cv = 10).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab775d614f050ac31f271e332640e80516c58acc"},"cell_type":"code","source":"parameters = {'C' : range(1, 20)}\n\ncv = GridSearchCV(logreg, parameters, cv = 10)\n\ncv.fit(X, y)\n\nprint(cv.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4140fb3cdea453edb897375f6502e25e4fbaca95"},"cell_type":"markdown","source":"### Nearest Neighbours"},{"metadata":{"trusted":true,"_uuid":"0700dd5177c52ff3e8c256df3d35b8455c825b88"},"cell_type":"code","source":"neighbours = KNeighborsClassifier()\nneighbours.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"724c6afbc810ea551eb5a69179fa73ddae397937"},"cell_type":"code","source":"print(neighbours.score(X_train, y_train))\nprint(cross_val_score(neighbours, X, y).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6657e450c0ceecf03a01933fd4634e147867cfe"},"cell_type":"code","source":"parameters = {'n_neighbors' : range(1, 35)}\n\ncv = GridSearchCV(neighbours, parameters)\n\ncv.fit(X, y)\n\nprint(cv.best_score_)\nprint(cv.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce756d104f2798e63339ad001c859bd27bda4127"},"cell_type":"code","source":"print(cv.best_estimator_.score(X, y))\nprint(cross_val_score(cv.best_estimator_, X, y, cv=10).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c44c345470be6e75204ce880d3ced2b1e83dea09"},"cell_type":"code","source":"predictions = cv.best_estimator_.predict(test)\n\nsubmission = pd.DataFrame({'PassengerId' : ids, 'Survived' : predictions})\n\nsubmission.to_csv('Neighbors.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e7687a1062528edc7540989ebc77dc2f75664f4"},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b6e49e90aeedc65efdc812a13f38ad1decd7e46"},"cell_type":"markdown","source":"### SVM"},{"metadata":{"trusted":true,"_uuid":"40d805060312a859bb538c11c3095c8a8d204599"},"cell_type":"code","source":"svc = svm.SVC(C = 100)\nsvc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea01cd33631f4d5b24ad368f31bc7b445d4d2756"},"cell_type":"code","source":"print(svc.score(X_train, y_train))\nprint(cross_val_score(svc, X, y).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0073f707533f66cc64fedf6d41e02499a41b0fe0"},"cell_type":"code","source":"parameters = {'C' : range(1, 100, 5), 'kernel' : ['rbf', 'poly'], 'degree' : [2, 3, 5, 7]}\n\ncv = GridSearchCV(svc, parameters)\n\ncv.fit(X, y)\n\nprint(cv.best_score_)\nprint(cv.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a5a693578c20000b38e741e68700d613e6a1b5f"},"cell_type":"code","source":"print(cv.best_estimator_.score(X, y))\nprint(cross_val_score(cv.best_estimator_, X, y, cv=10).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ff90e7451b2f0ddca9a3f62b792864fa1ab5789"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}