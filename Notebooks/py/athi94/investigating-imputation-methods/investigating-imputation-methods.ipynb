{"metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "version": "3.6.1", "file_extension": ".py", "mimetype": "text/x-python"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "cells": [{"outputs": [], "metadata": {"_uuid": "feea4052df657d457447d156f1020d6616c0f646", "_cell_guid": "762b10a8-05f0-4450-8449-bae7d5ccb19f"}, "cell_type": "markdown", "source": "An Investigation of Imputation Methods\n------------------------------------", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "c66c9a187266122b4fdc5b50ad650988f9e23603", "_cell_guid": "b57ada49-2e30-473d-9e6e-fa57afd87bc5"}, "cell_type": "markdown", "source": "### Data loading", "execution_count": null}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "6251a7617955afc0bfb5bd3cbb4358340f38c450", "_cell_guid": "f271bfd2-8246-485c-82fc-1f9e6610747c", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "import numpy as np\nimport pandas as pd\n\nnp.random.seed(7)\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')", "execution_count": 1}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "44f43996509540d908f166e8b3beb690031b7e5b", "_cell_guid": "f12a304c-6520-452e-8135-0cbfc223082c", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "import sys\nimport warnings\n\ndef enforceTypesTitanic(df):\n    try:\n        df.Survived = df.Survived.astype(\"category\")\n    except:\n        pass\n    df.Pclass = df.Pclass.astype(\"category\", categories=[1, 2, 3], ordered=True)\n    df.Sex = df.Sex.astype(\"category\")\n    df.Embarked = df.Embarked.astype(\"category\")\n    \n\nenforceTypesTitanic(train)\nenforceTypesTitanic(test)", "execution_count": 2}, {"outputs": [], "metadata": {"_uuid": "9f36576fed683bf0429450ef52fec336e3172b36", "_cell_guid": "60a9c965-1eb9-4199-9a1b-e24b0ccc7352", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "def naSummary(df):\n    return df.isnull().sum()\n\nnaSummary(train)", "execution_count": 3}, {"outputs": [], "metadata": {"_uuid": "2873910fccabd27b0fb5141ce3f42e6589e613b5", "_cell_guid": "e5d807cb-4a0c-403d-a215-41ca0cc37be4", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "naSummary(test)", "execution_count": 4}, {"outputs": [], "metadata": {"_uuid": "008a9e79ab99b1553bd002d0b745a85fa11f08a2", "_cell_guid": "602b7065-1c54-4a77-8e47-4836e68a0a05"}, "cell_type": "markdown", "source": "## Verifying Training and Test Sets Similar Distributions", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "1d0136391d9823a89a253cfbe01dcf5ffe3d6364", "_cell_guid": "ffd616ea-7280-44f5-acf4-cdc44848113f", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "%matplotlib inline\nimport seaborn as sns\nimport matplotlib.gridspec as gs\nimport matplotlib.pyplot as plt\nimport itertools\n\ndef distComparison(df1, df2):\n    a = len(df1.columns)\n    if a%2 != 0:\n        a += 1\n    \n    n = np.floor(np.sqrt(a)).astype(np.int64)\n    \n    while a%n != 0:\n        n -= 1\n    \n    m = (a/n).astype(np.int64)\n    coords = list(itertools.product(list(range(m)), list(range(n))))\n    \n    numerics = df1.select_dtypes(include=[np.number]).columns\n    cats = df1.select_dtypes(include=['category']).columns\n    \n    fig = plt.figure(figsize=(15, 15))\n    axes = gs.GridSpec(m, n)\n    axes.update(wspace=0.25, hspace=0.25)\n    \n    for i in range(len(numerics)):\n        x, y = coords[i]\n        ax = plt.subplot(axes[x, y])\n        col = numerics[i]\n        sns.kdeplot(df1[col].dropna(), ax=ax, label='df1').set(xlabel=col)\n        sns.kdeplot(df2[col].dropna(), ax=ax, label='df2')\n        \n    for i in range(0, len(cats)):\n        x, y = coords[len(numerics)+i]\n        ax = plt.subplot(axes[x, y])\n        col = cats[i]\n\n        df1_temp = df1[col].value_counts()\n        df2_temp = df2[col].value_counts()\n        df1_temp = pd.DataFrame({col: df1_temp.index, 'value': df1_temp/len(df1), 'Set': np.repeat('df1', len(df1_temp))})\n        df2_temp = pd.DataFrame({col: df2_temp.index, 'value': df2_temp/len(df2), 'Set': np.repeat('df2', len(df2_temp))})\n\n        sns.barplot(x=col, y='value', hue='Set', data=pd.concat([df1_temp, df2_temp]), ax=ax).set(ylabel='Percentage')\n        \n    \n        \ndistComparison(train.drop('Survived', 1), test)", "execution_count": 5}, {"outputs": [], "metadata": {"_uuid": "de2217f045c02397cf908b43a38ee9dc9b86fc6b", "_cell_guid": "eb108455-8d35-42b5-a6e6-0d644d30959e"}, "cell_type": "markdown", "source": "Create a baseline dataset with no other missing data.", "execution_count": null}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "c0752bdebb029986336696601ebed13ff61ed521", "_cell_guid": "2412eab3-ac8c-421c-b78d-44b12525f6e4", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "# Refer to Heads or Tails Pytanic kernel for the logic here, https://www.kaggle.com/headsortails/pytanic\n\ntrain.Embarked = train.Embarked.fillna('C')\n\ntrain['CabinKnown'] = pd.Categorical((train.Cabin.isnull() == False))\ntest['CabinKnown'] = pd.Categorical((test.Cabin.isnull() == False))\n\ntest.Fare = test.Fare.fillna(8.05)\n\ntrain = train.drop('Cabin', 1)\ntest = test.drop('Cabin', 1)", "execution_count": 6}, {"outputs": [], "metadata": {"_uuid": "9a31b0e3899434d8ad905765693eee5f0a866429", "_cell_guid": "681aee3b-eb7f-484d-a19e-60ebf4bbb90e", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "naSummary(train)", "execution_count": 7}, {"outputs": [], "metadata": {"_uuid": "cb38bd0baa748a18599ad5c09c76985f154cabb1", "_cell_guid": "dc91c968-cf18-4b2e-be7a-ae9ec3655943", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "naSummary(test)", "execution_count": 8}, {"outputs": [], "metadata": {"_uuid": "f4046a90e27ad0913eca82b47cc76c2d07850ccd", "_cell_guid": "d36d00c2-6fd3-4b5f-9140-3dff423e0b87"}, "cell_type": "markdown", "source": "## Missing at Random?\n\nMCAR = missing completely at random.\n\nIn essence, if we split the data into two more sets. Data missing and Data present. Then check whether the distribution of the variables in each of these sets is the same, we can assume the data is missing completely at random.", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "e3655f5dba68b4f2a4eb1e9633daee2a74a4bc54", "_cell_guid": "cee1ba00-736b-4b63-aca0-589d4a80acdd", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "age_present = train.dropna().drop('Age', 1)\nage_missing = train[train.isnull().any(axis=1)].drop('Age', 1)\n\nage_present.Parch = age_present.Parch.astype('category', categories=list(range(8)), ordered=True)\nage_missing.Parch = age_missing.Parch.astype('category', categories=list(range(8)), ordered=True)\n\nage_present.SibSp = age_present.SibSp.astype('category', categories=list(range(9)), ordered=True)\nage_missing.SibSp = age_missing.SibSp.astype('category', categories=list(range(9)), ordered=True)\n\ndistComparison(age_present.drop('Survived', 1), age_missing.drop('Survived', 1))", "execution_count": 9}, {"outputs": [], "metadata": {"_uuid": "0fee94f930b9a76b642e4182f2e0a073da427c6c", "_cell_guid": "ec01755d-01b8-45e8-b57a-7f83ff302927"}, "cell_type": "markdown", "source": "It looks like we can't verify the MCAR assumption. The explanation here seems to be that we're less likely to know the Age of those who died. As evidenced by the much greater proportion of lower class passengers, sharper peak in fare at low levels, and slight skewness towards males.\n\nMost significantly though it seems that those who Embarked at Q have a much higher rate of missing ages.\n\nNote: It would be better to use a more objective measure of MCAR such as Little's test, might do in the future.", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "1eb821dba55457db166b63b8bf943bb1f5a30164", "_cell_guid": "8be28abb-f498-450a-9d25-4771c432ecec"}, "cell_type": "markdown", "source": "## Baseline", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "5079fff2dea16b57d9c220e40b694a4dde489b38", "_cell_guid": "64668e8b-0ae7-4c4e-8062-afdaf708c9d4"}, "cell_type": "markdown", "source": "Use no `Age` data at all. Standard model will be a Random Forest Classifier with the displayed parameters, all test error estimates are obtained through a 10-fold Cross Validation.", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "b8cbe9474eb6ea90e1adf91b38baa619b61948d5", "_cell_guid": "9eb9a7fe-afd8-4986-b76b-adf4bc6337cd", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\ndef prepForModel(df):\n    new_df = df.copy()\n    new_df.Pclass = new_df.Pclass.astype(\"int\")\n    new_df.Sex.cat.categories = [0, 1]\n    new_df.Sex = new_df.Sex.astype(\"int\")\n    new_df.Embarked.cat.categories = [0, 1, 2]\n    new_df.Embarked = new_df.Embarked.astype(\"int\")\n    new_df.CabinKnown.cat.categories = [0, 1]\n    new_df.CabinKnown = new_df.CabinKnown.astype(\"int\")\n    return new_df\n\ntrain_cl = prepForModel(train)\ntest_cl = prepForModel(test)\n\nXcol = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Fare', 'Embarked', 'CabinKnown']\nYcol = 'Survived'\n\nX = train_cl.loc[:, Xcol]\nY = train_cl.loc[:, Ycol]\n\nXbase = X\nYbase = Y\n\nrf = RandomForestClassifier(n_estimators=1000,\n                           max_depth=None,\n                           min_samples_split=10)\n\nbaseline_err = cross_val_score(rf, X, Y, cv=10, n_jobs=-1).mean()\nprint(\"[BASELINE] Estimated RF Test Error (n = {}, 10-fold CV): {}\".format(len(X), baseline_err))", "execution_count": 10}, {"outputs": [], "metadata": {"_uuid": "bcad8d2354eb04f7139567624d27ac2d9e73ad5a", "_cell_guid": "9d2a87fb-4317-4fd2-a6db-f5bd62fb3362"}, "cell_type": "markdown", "source": "## Deletion", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "36c1b8c52a4081287d8ec87813b9ce1dab335680", "_cell_guid": "e33bf298-f2ea-4434-900a-b69bc9962271", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "Xdel = train_cl.dropna().loc[:, Xcol + ['Age']]\nYdel = train_cl.dropna().loc[:, Ycol]\n\ndeletion_err = cross_val_score(rf, Xdel, Ydel, cv=10, n_jobs=-1).mean()\nprint(\"[DELETION] Estimated RF Test Error (n = {}, 10-fold CV): {}\".format(len(Xdel), deletion_err))", "execution_count": 11}, {"outputs": [], "metadata": {"_uuid": "4dc1d8e53ddc961c92a334367201c89cdc21af3b", "_cell_guid": "a6ac5c2b-364b-476d-8786-dd9f0fd7a9cc"}, "cell_type": "markdown", "source": "## Mean Substitution", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "e712cf05d964833a58e3e4709ac83060254149b6", "_cell_guid": "004c75ef-2fcc-481f-a9db-f9d3e13d43ad", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "train_cl = prepForModel(train)\ntrain_cl.Age = train_cl.Age.fillna(train_cl.Age.mean(skipna=True))\n\nXcol = Xcol + ['Age']\n\nXmean = train_cl.loc[:, Xcol]\nYmean = train_cl.loc[:, Ycol]\n\nmean_err = cross_val_score(rf, Xmean, Ymean, cv=10, n_jobs=-1).mean()\nprint(\"[MEAN] Estimated RF Test Error (n = {}, 10-fold CV): {}\".format(len(Xmean), mean_err))", "execution_count": 12}, {"outputs": [], "metadata": {"_uuid": "ec26ebd70984436e825d406d2616830f0f12e9cc", "_cell_guid": "a52e28e5-1333-4c96-bda7-10b36c39c137"}, "cell_type": "markdown", "source": "## Deterministic and Random Regression", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "2a93932a19fbefa1771ec6cb4231ad9d03308731", "_cell_guid": "da1e76cc-e899-4c66-b0e0-7b8f244edb6a", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "train_cl = prepForModel(train)\ntrain_reg = train_cl.dropna()\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import preprocessing\n\nXrcol = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Fare', 'Embarked', 'CabinKnown']\nYrcol = 'Age'\n\nX_reg = train_reg.loc[:, Xrcol]\nY_reg = train_reg.loc[:, Yrcol]\n\nage_lm = LinearRegression()\nage_lm.fit(X_reg, Y_reg)\nabs_residuals = np.absolute(Y_reg - age_lm.predict(X_reg))\n\nnan_inds = train_cl.Age.isnull().nonzero()[0]\ntrain_cl2 = train_cl.copy()\n\nfor i in nan_inds:\n    train_cl.set_value(i, 'Age', age_lm.predict(train_cl.loc[i, Xrcol].values.reshape(1, -1)))\n\nXreg = train_cl.loc[:, Xcol]\nYreg = train_cl.loc[:, Ycol]\n    \nreg_err = cross_val_score(rf, Xreg, Yreg, cv=10, n_jobs=-1).mean()\nprint(\"[DETERMINISTIC REGRESSION] Estimated RF Test Error (n = {}, 10-fold CV): {}\".format(len(Xreg), reg_err))\n\nfor i in nan_inds:\n    detreg = age_lm.predict(train_cl2.loc[i, Xrcol].values.reshape(1, -1))\n    randreg = np.random.normal(detreg, np.random.choice(abs_residuals))\n    train_cl2.set_value(i, 'Age', randreg)\n    \nXrandreg = train_cl2.loc[:, Xcol]\nYrandreg = train_cl2.loc[:, Ycol]\n    \nrandreg_err = cross_val_score(rf, Xrandreg, Yrandreg, cv=10, n_jobs=-1).mean()\nprint(\"[RANDOM REGRESSION] Estimated RF Test Error (n = {}, 10-fold CV): {}\".format(len(Xrandreg), randreg_err))", "execution_count": 13}, {"outputs": [], "metadata": {"_uuid": "408dbaa3bdcefb881222e942070e050e36bd40f3", "_cell_guid": "30dc53c5-cb32-4d44-8d23-d2c806a9cd23"}, "cell_type": "markdown", "source": "## MICE", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "7711d1c85dd8a24028b042e4710b97a0ac5be993", "_cell_guid": "0fe7ab1f-4e5c-4d7a-af4c-988166038c09", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "from fancyimpute import MICE\n\ntrain_cl = prepForModel(train)\n\nX = train_cl.loc[:, Xcol]\nY = train_cl.loc[:, Ycol]\n\nXmice = MICE(n_imputations=200, impute_type='col', verbose=False).complete(X.as_matrix())\nYmice = Y\n\nmice_err = cross_val_score(rf, Xmice, Y, cv=10, n_jobs=-1).mean()\nprint(\"[MICE] Estimated RF Test Error (n = {}, 10-fold CV): {}\".format(len(Xmice), mice_err))", "execution_count": 14}, {"outputs": [], "metadata": {"_uuid": "5cb98a3c43ea86f8348b529623eb2cc39f3970c3", "_cell_guid": "d37c7551-67bd-4e7f-94d9-25a950021876"}, "cell_type": "markdown", "source": "## KNN (Standardized Features)", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "2115df6de2009ec96f1ca23793136d8d6d25ea69", "_cell_guid": "605caaa2-c1cf-4b51-a21f-7017044df283", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "from fancyimpute import KNN\nfrom sklearn.model_selection import StratifiedKFold\n\ntrain_cl = prepForModel(train)\n\nXcol = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Fare', 'Embarked', 'CabinKnown']\nX = train_cl.loc[:, Xcol + ['Age']]\nY = train_cl.loc[:, Ycol]\n\ndef standardize(s):\n    return s.sub(s.min()).div((s.max() - s.min()))\n\nXnorm = X.apply(standardize, axis=0)\nkvals = np.linspace(1, 100, 20, dtype='int64')\n\nknn_errs = []\nfor k in kvals:\n    knn_err = []\n    Xknn = KNN(k=k, verbose=False).complete(Xnorm)\n    knn_err = cross_val_score(rf, Xknn, Y, cv=10, n_jobs=-1).mean()\n\n    knn_errs.append(knn_err)\n    print(\"[KNN] Estimated RF Test Error (n = {}, k = {}, 10-fold CV): {}\".format(len(Xknn), k, np.mean(knn_err)))", "execution_count": 15}, {"outputs": [], "metadata": {"_uuid": "096ca7bc22cf73a4f2cc1c5856725f4b46b5afd9", "_cell_guid": "cebf6c9d-d62d-4379-914f-2767b4989e6a", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "sns.set_style(\"darkgrid\")\n_ = plt.plot(kvals, knn_errs)\n_ = plt.xlabel('K')\n_ = plt.ylabel('10-fold CV Error Rate')\n\nknn_err = max(knn_errs)\nk_opt = kvals[knn_errs.index(knn_err)]\n\nXknn = KNN(k=k_opt, verbose=False).complete(Xnorm)\nYknn = Y\n\nprint(\"[BEST KNN] Estimated RF Test Error (n = {}, k = {}, 10-fold CV): {}\".format(len(Xknn), k_opt, np.mean(knn_err)))", "execution_count": 16}, {"outputs": [], "metadata": {"_uuid": "c02e770675a39fd1b4c4e3f13639b852f5a24d7d", "_cell_guid": "b6b05aaf-e846-4225-95c0-e66f807e61ea"}, "cell_type": "markdown", "source": "# Summary", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "b93d5f9dc49de031155455631f9130841cd27d91", "_cell_guid": "96847d9e-e09f-48f4-a99f-2abd98331ae4", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "errs = {'BEST KNN (k = {})'.format(k_opt): knn_err,  \n        'DETERMINISTIC REGRESSION': reg_err, \n        'RANDOM REGRESSION': randreg_err,\n        'MICE': mice_err,\n        'MEAN': mean_err,\n        'DELETION': deletion_err, \n        'BASELINE': baseline_err}\n\nerr_df = pd.DataFrame.from_dict(errs, orient='index')\nerr_df.index.name = 'Imputation Method'\nerr_df.reset_index(inplace=True)\nerr_df.columns = ['Imputation', 'Test Error Estimate (10-fold CV)']\n\nax = sns.barplot(x=err_df.columns[1], y=err_df.columns[0], order=list.sort(list(errs.values())), data=err_df)\nax.set_xlabel(err_df.columns[1])\nax.set_ylabel('')\n_ = plt.xlim(0.8, 0.835)", "execution_count": 17}, {"outputs": [], "metadata": {"_uuid": "0b0662c970340536073cb6cd80fa88a67d389fb0", "_cell_guid": "5c22e43a-3546-4ce9-b512-2735c9388029"}, "cell_type": "markdown", "source": "# Kaggle Double Check", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "3cea86bdeb3c563abe2fd4553332c10adbc18428", "_cell_guid": "36972e5a-8f37-4010-9e3a-abc63185aebc", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "from operator import add\n\nnp.random.seed(7)\n\nXcol = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Fare', 'Embarked', 'CabinKnown']\nYcol = 'Survived'\n\nXbase.head()\ntrain_cl = prepForModel(train)\ntest_cl = prepForModel(test)\n\n# Baseline\nrf.fit(Xbase, Ybase)\nXbl_test = test_cl.loc[:, Xcol]\nbl_preds = rf.predict(Xbl_test)\n\nbl_submit = pd.DataFrame({'PassengerId': test_cl.PassengerId, 'Survived': bl_preds})\nbl_submit.to_csv(\"baseline.csv\", index=False) # Kaggle: 0.75120\n\n# Mean\nrf.fit(Xmean, Ymean)\n\nXmean_test = test_cl.loc[:, Xcol + ['Age']]\nXmean_test.Age = Xmean_test.Age.fillna(train_cl.Age.mean(skipna=True))\nmean_preds = rf.predict(Xmean_test)\n\nmean_submit = pd.DataFrame({'PassengerId': test_cl.PassengerId, 'Survived': mean_preds})\nmean_submit.to_csv(\"mean.csv\", index=False) # Kaggle: 0.75598\n\n# MICE\nrf.fit(Xmice, Ymice)\n\ncombine = pd.concat([train.drop('Survived', 1), test])\ncombine_cl = prepForModel(combine)\nXcomb = combine_cl.loc[:, Xcol + ['Age']]\nXmice_test = MICE(n_imputations=200, impute_type='col', verbose=False).complete(Xcomb.as_matrix())[len(train):]\nmice_preds = rf.predict(Xmice_test)\n\nmice_submit = pd.DataFrame({'PassengerId': test_cl.PassengerId, 'Survived': mice_preds})\nmice_submit.to_csv(\"mice.csv\", index=False)  # Kaggle: 0.75120\n\n\n# RANDOM REGRESSION\nrf.fit(Xrandreg, Yrandreg)\n\nnan_inds = test_cl.Age.isnull().nonzero()[0]\nXrandreg_test = test_cl.copy()\n\nfor i in nan_inds:\n    detreg = age_lm.predict(Xrandreg_test.loc[i, Xrcol].values.reshape(1, -1))\n    randreg = np.random.normal(detreg, np.random.choice(abs_residuals))\n    Xrandreg_test.set_value(i, 'Age', randreg)\n    \nXrandreg_test = Xrandreg_test.loc[:, Xcol + ['Age']]\nrandreg_preds = rf.predict(Xrandreg_test)\n\nrandreg_submit = pd.DataFrame({'PassengerId': test_cl.PassengerId, 'Survived': randreg_preds})\nrandreg_submit.to_csv(\"randreg.csv\", index=False)  # Kaggle: 0.75598\n    \n\n# DET. REGRESSION\nrf.fit(Xreg, Yreg)\n\nnan_inds = test_cl.Age.isnull().nonzero()[0]\nXreg_test = test_cl.copy()\n\nfor i in nan_inds:\n    Xreg_test.set_value(i, 'Age', age_lm.predict(Xreg_test.loc[i, Xrcol].values.reshape(1, -1)))\n    \nXreg_test = Xreg_test.loc[:, Xcol + ['Age']]\nreg_preds = rf.predict(Xreg_test)\n\nreg_submit = pd.DataFrame({'PassengerId': test_cl.PassengerId, 'Survived': reg_preds})\nreg_submit.to_csv(\"reg.csv\", index=False)  # Kaggle: 0.76077\n\n# KNN (k=47)\nrf.fit(Xknn, Yknn)\n\ntrain_plus_testna = pd.concat([train.drop('Survived', 1), test[test.isnull().any(axis=1)]])\ntrain_plus_testna = prepForModel(train_plus_testna)\n\nX = train_plus_testna.loc[:, Xcol + ['Age']]\n\nXnorm = X.apply(standardize, axis=0)\nXknn_test_age_imps = pd.Series(KNN(k=k_opt, verbose=False).complete(Xnorm)[len(train):, 7])\n\nXknn_test = test_cl.loc[:, Xcol + ['Age']]\nXknn_test = Xknn_test.apply(standardize, axis=0)\n\nnan_inds = Xknn_test.Age.isnull().nonzero()[0]\n\nfor i in range(len(nan_inds)):\n    Xknn_test.set_value(nan_inds[i], 'Age', Xknn_test_age_imps[i])\n    \nknn_preds = rf.predict(Xknn_test)\n\nknn_submit = pd.DataFrame({'PassengerId': test_cl.PassengerId, 'Survived': knn_preds})\nknn_submit.to_csv(\"knn.csv\", index=False)  # Kaggle: 0.75120", "execution_count": 18}, {"outputs": [], "metadata": {"_uuid": "9874f95af6e0c80f88648a3c593e004b0140e134", "_cell_guid": "45013707-92e3-4952-8024-8830e03e13c0"}, "cell_type": "markdown", "source": "# Questions\n\n* Why is there such a big discrepancy between CV test error estimate and the Kaggle test error?\n* Why do both fancyimpute methods (KNN and MICE) fail quite badly in practice?\n* Should I be applying imputations under data from the whole known set (training + test) or just training?", "execution_count": null}, {"outputs": [], "metadata": {"_uuid": "39de7559ecfa536ad2d89c167a00bac5e5fa869b", "_cell_guid": "18029010-d2ee-4972-a725-7daf47baffe3"}, "cell_type": "markdown", "source": "Seems like simple deterministic regression works best on kaggle right now.", "execution_count": null}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "539d6473f1ce76c9dfd5170e144ef6ca172b08da", "_cell_guid": "9c0a6d16-9a5c-4fbd-96b8-e74584b63a54", "trusted": false, "_execution_state": "idle"}, "cell_type": "code", "source": "", "execution_count": 18}], "nbformat_minor": 1, "nbformat": 4}