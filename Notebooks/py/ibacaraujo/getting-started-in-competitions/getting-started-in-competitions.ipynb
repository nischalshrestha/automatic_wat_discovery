{"cells": [{"source": ["# Learning machine learning competitions goals"], "metadata": {"_cell_guid": "f4dd7c23-8010-424c-92cd-4afb2e2bbf54", "_uuid": "3a86f2852fc354270ab2253477a3f9b9c0ae9981"}, "cell_type": "markdown"}, {"outputs": [], "source": ["# data analysis and wrangling\n", "import pandas as pd\n", "import numpy as np\n", "import random as rnd\n", "import xgboost as xgb\n", "\n", "# visualization\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "# machine learning\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.svm import SVC, LinearSVC\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.linear_model import Perceptron\n", "from sklearn.linear_model import SGDClassifier\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.ensemble import VotingClassifier\n", "from sklearn.ensemble import ExtraTreesClassifier\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.model_selection import StratifiedKFold\n", "from sklearn.feature_selection import SelectFromModel"], "metadata": {"_cell_guid": "3f3ffd40-f87f-e53c-6d40-fd3ce8f2360f", "_uuid": "1b05945ebad0dbebf6ec97b230d5ff7588eff66a", "collapsed": true, "_execution_state": "idle"}, "cell_type": "code", "execution_count": 105}, {"source": ["## Acquire data"], "metadata": {"_cell_guid": "238b027a-8430-50c4-4ebe-324e75c4c70a", "_uuid": "a774f2d134fc92b7eab0e68aa9ac23c7955e4428"}, "cell_type": "markdown"}, {"outputs": [], "source": ["train_df = pd.read_csv('../input/train.csv')\n", "test_df = pd.read_csv('../input/test.csv')\n", "\n", "targets = train_df.Survived\n", "train_df.drop('Survived', 1, inplace=True)\n", "    \n", "# merging train data and test data for future feature engineering\n", "combined = train_df.append(test_df)\n", "combined.reset_index(inplace=True)\n", "combined.drop('index', inplace=True, axis=1)"], "metadata": {"_cell_guid": "1fce35ae-cbb8-e3d8-38ab-411a1d08c89b", "_uuid": "7363b3c7d5d6148a3921d005faa2307eacb8f973", "collapsed": true, "_execution_state": "idle"}, "cell_type": "code", "execution_count": 107}, {"source": ["## Analyze by describing data"], "metadata": {"_cell_guid": "6bec4dd4-ec51-237a-50eb-960008910104", "_uuid": "1c89ed943e77c700c1c3c23bb369c219c0dd19ad"}, "cell_type": "markdown"}, {"outputs": [], "source": ["print(train_df.columns.values)"], "metadata": {"_cell_guid": "ebe92988-73e8-2775-f2d6-4c845c1f134e", "_uuid": "15eec9a71c52a98118fcdd4977984d8f8a3a857c", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 3}, {"outputs": [], "source": ["# preview the data\n", "train_df.head()"], "metadata": {"_cell_guid": "ce11cf40-fc8f-5566-2972-883b604380d8", "_uuid": "c0566a528ebfed5f08afe0e4321e9cb43a6d91ba", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 4}, {"outputs": [], "source": ["train_df.tail()"], "metadata": {"_cell_guid": "9a4727ee-d4d1-3745-26db-b81ec48be203", "_uuid": "f77627dfd1fda92bc8c4ab1f151f6ad86566b4dc", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 5}, {"outputs": [], "source": ["train_df.info()\n", "print('_'*40)\n", "test_df.info()"], "metadata": {"_cell_guid": "8aef1733-aed2-3067-6387-f460d551d916", "_uuid": "ab0ae911c36efd9e1dae44a6feadd0db9b643d5e", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 6}, {"outputs": [], "source": ["train_df.describe()"], "metadata": {"_cell_guid": "2a9551e7-a0c4-c287-2a44-9a1017f6896e", "_uuid": "90e5b01e92c19127d0fd9cb5ec2fa2814e9b4f3f", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 7}, {"outputs": [], "source": ["train_df.describe(include=['O'])"], "metadata": {"_cell_guid": "1d9db198-356f-8c47-d704-fd93a116e874", "_uuid": "def776eb1bf6e7b1215c0c3170db29212995dd9c", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 8}, {"source": ["## Analyze by pivoting data"], "metadata": {"_cell_guid": "228656c5-c281-b5f0-cc34-92cd7ae8b63d", "_uuid": "0fddbe341e558987ff4d43f3dcae753ac38c3438"}, "cell_type": "markdown"}, {"outputs": [], "source": ["train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"], "metadata": {"_cell_guid": "e7374eed-4edc-a2da-3f6d-ba573b710f78", "_uuid": "2beadb32417d39bac6462bb01edb0852467ff6cf", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 9}, {"outputs": [], "source": ["train_df[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"], "metadata": {"_cell_guid": "62c7074c-a875-ae9e-6dc5-d9ea10c7c96e", "_uuid": "a34ba77461c86d1a30d35e1feb30def7209b3c3e", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 10}, {"outputs": [], "source": ["train_df[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)"], "metadata": {"_cell_guid": "5e7d0970-da1a-0cd0-aa58-1e1ea27b01c4", "_uuid": "d0cdcecc462ef764688446c36a2874c3dfc86804", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 11}, {"outputs": [], "source": ["train_df[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)"], "metadata": {"_cell_guid": "162acf7e-7d45-7266-1b54-f43a4ce0449d", "_uuid": "a544699883e0412dd3ad4da79d6cb38cf1012e51", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 12}, {"source": ["## Wrangle data"], "metadata": {"_cell_guid": "30302493-878b-55f3-f1e3-decf6a2e93c1", "_uuid": "710314670119bd1f8ffdc19ce60f26809b586553"}, "cell_type": "markdown"}, {"outputs": [], "source": ["combined['Age'].fillna(combined['Age'].median(), inplace=True)"], "metadata": {}, "cell_type": "code", "execution_count": 109}, {"source": ["### Correcting by dropping features"], "metadata": {"_cell_guid": "eb33ea7b-fabe-7a27-e0d2-469dcd668ecf", "_uuid": "85b574c71d864d2ca72165e11b2bd34e01414203"}, "cell_type": "markdown"}, {"outputs": [], "source": ["print(\"Before\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)\n", "\n", "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n", "test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n", "combine = [train_df, test_df]\n", "\n", "print(\"After\", train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)"], "metadata": {"_cell_guid": "2d79d22f-f866-3fcf-fbc8-2536443a5f19", "_uuid": "e9156c9424f1691446df36be4a70a08a98c2c7ea", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 13}, {"source": ["### Creating new feature extracting from existing"], "metadata": {"_cell_guid": "12d89bbc-8390-f3e0-c9be-03e1c477a786", "_uuid": "973b7c491cb730806ac3bda43a0e41f5011c1313"}, "cell_type": "markdown"}, {"outputs": [], "source": ["for dataset in combine:\n", "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n", "\n", "pd.crosstab(train_df['Title'], train_df['Sex'])"], "metadata": {"_cell_guid": "78a78217-72c8-8780-ac46-17b3ec8befa7", "_uuid": "acc7fce4616c983e01f46ce76e0a91c49859836e", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 14}, {"outputs": [], "source": ["for dataset in combine:\n", "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Capt', 'Col', \\\n", "        'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n", "    \n", "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n", "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n", "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n", "    \n", "train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"], "metadata": {"_cell_guid": "081102a4-1fa7-d8fa-f79c-6f7f32dd0309", "_uuid": "b0a47fb7ebd920dbb6267ef88f8dc13fab2defbf", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 15}, {"outputs": [], "source": ["title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n", "for dataset in combine:\n", "    dataset['Title'] = dataset['Title'].map(title_mapping)\n", "    dataset['Title'] = dataset['Title'].fillna(0)\n", "    \n", "train_df.head()"], "metadata": {"_cell_guid": "86168b69-2e26-6ccc-2c68-f1459f7d1957", "_uuid": "37581e5ab5690fa5d28f5f0170f28e5442ea4880", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 16}, {"outputs": [], "source": ["train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\n", "test_df = test_df.drop(['Name'], axis=1)\n", "combine = [train_df, test_df]\n", "train_df.shape, test_df.shape"], "metadata": {"_cell_guid": "fd70f411-4549-e4a0-75d1-0a7f4b627c48", "_uuid": "af2cf3f161923e9a535e39e92f4bd99f1bdeeec9", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 17}, {"source": ["### Converting a categorical feature"], "metadata": {"_cell_guid": "e6df81e1-c341-e308-976b-799ab2494f52", "_uuid": "18bb3693e9d404bd9cfd515534ae4bb40f90b47e"}, "cell_type": "markdown"}, {"outputs": [], "source": ["for dataset in combine:\n", "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n", "    \n", "train_df.head()"], "metadata": {"_cell_guid": "9bbd7486-1a94-e7c1-f6e3-c9bd1e969a99", "_uuid": "2bf47da9ac7db8d29aac32d128a6555c6384fb06", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 18}, {"source": ["### Completing a numerical continuous feature"], "metadata": {"_cell_guid": "c62541a7-0d91-8adc-53d1-9f0c1276a56a", "_uuid": "6e0e9b6f0547250f7ba12cacfee9677a3f9a6a29"}, "cell_type": "markdown"}, {"outputs": [], "source": ["guess_ages = np.zeros((2, 3))\n", "guess_ages"], "metadata": {"_cell_guid": "fc40e171-8452-c84b-fa44-6d0d0127481e", "_uuid": "8e9c0dd488549abc526d92805591a21f90b0d567", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 19}, {"outputs": [], "source": ["for dataset in combine:\n", "    for i in range(0, 2):\n", "        for j in range(0, 3):\n", "            guess_df = dataset[(dataset['Sex'] == i) & (dataset['Pclass'] == j+1)]['Age'].dropna()\n", "            \n", "            age_guess = guess_df.median()\n", "            \n", "            guess_ages[i, j] = int(age_guess / 0.5 + 0.5) * 0.5\n", "            \n", "    for i in range(0, 2):\n", "        for j in range(0, 3):\n", "            dataset.loc[(dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n", "                        'Age'] = guess_ages[i, j]\n", "            \n", "    dataset['Age'] = dataset['Age'].astype(int)\n", "\n", "train_df.head()"], "metadata": {"_cell_guid": "f98f0cc3-a38f-ad01-d741-cc930190cdf1", "_uuid": "38b0d687fddf9e64787a393593cbc93b8966c899", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 20}, {"outputs": [], "source": ["train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\n", "train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)"], "metadata": {"_cell_guid": "68fee3de-1089-4214-a4ca-2ad4e09e14a0", "_uuid": "5d3a119d88ef7f99253dc7455722883db61851a5", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 21}, {"outputs": [], "source": ["for dataset in combine:\n", "    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0\n", "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n", "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n", "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n", "    dataset.loc[dataset['Age'] > 64, 'Age'] = 4\n", "train_df.head()"], "metadata": {"_cell_guid": "df211015-3407-442c-b877-46fe50015b02", "_uuid": "25213bb2b4c83d52866c15f145513db895f02721", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 22}, {"outputs": [], "source": ["train_df = train_df.drop(['AgeBand'], axis=1)\n", "combine = [train_df, test_df]\n", "train_df.head()"], "metadata": {"_cell_guid": "63655cfd-d861-45ac-8811-fd1c87ea9287", "_uuid": "ac0ab377d4933a2854f6af7e1896c975ddf0a335", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 23}, {"source": ["### Create new feature combining existing features"], "metadata": {"_cell_guid": "af98b28e-7a8f-4d20-bad8-791f6cf706c0", "_uuid": "5e7ff34ff008c3305ba21e69c688d6620f7420e3", "_execution_state": "idle"}, "cell_type": "markdown"}, {"outputs": [], "source": ["for dataset in combine:\n", "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n", "\n", "train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)"], "metadata": {"_cell_guid": "4fdd1e52-bd9b-4b76-93d7-c620e9972a54", "_uuid": "fdf174fbc3ffa23e6c069aac5d23e697364ac18e", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 24}, {"outputs": [], "source": ["for dataset in combine:\n", "    dataset['IsAlone'] = 0\n", "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n", "    \n", "train_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()"], "metadata": {"_cell_guid": "56f61b1b-4836-4fd0-a179-a01bccf07658", "_uuid": "6692524cd726efd767697a27caecc4a25c5e93fb", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 25}, {"outputs": [], "source": ["train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n", "test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n", "combine = [train_df, test_df]\n", "\n", "train_df.head()"], "metadata": {"_cell_guid": "69355d67-09c8-4782-996c-146f477b9169", "_uuid": "9fd0944782543eab56f14e552647233153c00967", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 26}, {"outputs": [], "source": ["for dataset in combine:\n", "    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n", "    \n", "train_df.loc[:, ['Age*Class', 'Age', 'Pclass']]"], "metadata": {"_cell_guid": "8de7769b-faac-43e1-adae-84339a00f1fe", "_uuid": "6e142e1a51ed233a3511207a4376b3d8bfe737af", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 27}, {"source": ["### Completing a categorical feature"], "metadata": {"_cell_guid": "9d6a2879-dd59-4c9c-9ae0-8454518ca1a0", "_uuid": "d111abcf89c3dbb62d6f732175f9de94c0d40f1f", "_execution_state": "idle"}, "cell_type": "markdown"}, {"outputs": [], "source": ["freq_port = train_df.Embarked.dropna().mode()[0]\n", "freq_port"], "metadata": {"_cell_guid": "0b9350d0-6f71-4d52-b43c-9ea09d30d3b8", "_uuid": "2a5b4318e9ba7eac6101b371f9000a595d27bbc7", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 28}, {"outputs": [], "source": ["for dataset in combine:\n", "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n", "    \n", "train_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)"], "metadata": {"_cell_guid": "e705edb4-ee3e-4605-99dd-e0778ad6f7fa", "_uuid": "27edbba03468ac249862d740eebcf96053470ca4", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 29}, {"source": ["### Converting categorical feature to numeric"], "metadata": {"_cell_guid": "493e852c-edfb-4c08-a52d-5490b92e3985", "_uuid": "620259d39e273fc8949a4fbb87e61134cc37500a", "_execution_state": "idle"}, "cell_type": "markdown"}, {"outputs": [], "source": ["for dataset in combine:\n", "    dataset['Embarked'] = dataset['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n", "\n", "train_df.head()"], "metadata": {"_cell_guid": "8c9432c3-0a29-4404-868c-d3d34c8c3f04", "_uuid": "5fea3782524ca3c1248be01ca96c992151998839", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 30}, {"source": ["### Quick completing and converting a numeric feature"], "metadata": {"_cell_guid": "3cb91444-9165-4200-89c3-b61cb029e0a7", "_uuid": "609657847fb79669d668485960eb235e4e999521", "_execution_state": "idle"}, "cell_type": "markdown"}, {"outputs": [], "source": ["train_df['Fare'].fillna(train_df['Fare'].dropna().median(), inplace=True)\n", "train_df.head()\n", "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n", "test_df.head()"], "metadata": {"_cell_guid": "eb601587-7cda-4a7d-ab14-db13462f79fd", "_uuid": "3ffecce63c091efbe19319f6eb230d092ed491f1", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 31}, {"outputs": [], "source": ["train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\n", "train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)"], "metadata": {"_cell_guid": "e084c922-a9e1-40ca-9e67-11e3b457aa00", "_uuid": "b1a4733bdedc63323fcd724982a297659c7fee83", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 32}, {"outputs": [], "source": ["for dataset in combine:\n", "    dataset.loc[dataset['Fare'] <= 7.91, 'Fare'] = 0\n", "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n", "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare'] = 2\n", "    dataset.loc[dataset['Fare'] > 31, 'Fare'] = 3\n", "    dataset['Fare'] = dataset['Fare'].astype(int)\n", "    \n", "train_df = train_df.drop(['FareBand'], axis=1)\n", "combine = [train_df, test_df]\n", "\n", "train_df.head(10)"], "metadata": {"_cell_guid": "07594b0d-460d-4fa2-8e25-14b070f7d262", "_uuid": "99031a60abd874d9b55f48bcf5f0948cca08dc81", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 33}, {"outputs": [], "source": ["test_df.head(10)"], "metadata": {"_cell_guid": "47c8b3db-2d7d-4926-9cff-ff5e74401529", "_uuid": "4a2a48693c3f11ad1f5068024793cdd1ef198a67", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 34}, {"source": ["## Feature engineering"], "metadata": {}, "cell_type": "markdown"}, {"outputs": [], "source": ["def get_titles():\n", "\n", "    global combined\n", "    \n", "    # we extract the title from each name\n", "    combined['Title'] = combined['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n", "    \n", "    # a map of more aggregated titles\n", "    Title_Dictionary = {\n", "                        \"Capt\":       \"Officer\",\n", "                        \"Col\":        \"Officer\",\n", "                        \"Major\":      \"Officer\",\n", "                        \"Jonkheer\":   \"Royalty\",\n", "                        \"Don\":        \"Royalty\",\n", "                        \"Sir\" :       \"Royalty\",\n", "                        \"Dr\":         \"Officer\",\n", "                        \"Rev\":        \"Officer\",\n", "                        \"the Countess\":\"Royalty\",\n", "                        \"Dona\":       \"Royalty\",\n", "                        \"Mme\":        \"Mrs\",\n", "                        \"Mlle\":       \"Miss\",\n", "                        \"Ms\":         \"Mrs\",\n", "                        \"Mr\" :        \"Mr\",\n", "                        \"Mrs\" :       \"Mrs\",\n", "                        \"Miss\" :      \"Miss\",\n", "                        \"Master\" :    \"Master\",\n", "                        \"Lady\" :      \"Royalty\"\n", "\n", "                        }\n", "    \n", "    # we map each title\n", "    combined['Title'] = combined.Title.map(Title_Dictionary)"], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 110}, {"outputs": [], "source": ["get_titles()"], "metadata": {}, "cell_type": "code", "execution_count": 111}, {"outputs": [], "source": ["grouped_train = combined.head(891).groupby(['Sex','Pclass','Title'])\n", "grouped_median_train = grouped_train.median()\n", "\n", "grouped_test = combined.iloc[891:].groupby(['Sex','Pclass','Title'])\n", "grouped_median_test = grouped_test.median()"], "metadata": {}, "cell_type": "code", "execution_count": 112}, {"outputs": [], "source": ["def process_age():\n", "    \n", "    global combined\n", "    \n", "    # a function that fills the missing values of the Age variable\n", "    \n", "    def fillAges(row, grouped_median):\n", "        if row['Sex']=='female' and row['Pclass'] == 1:\n", "            if row['Title'] == 'Miss':\n", "                return grouped_median.loc['female', 1, 'Miss']['Age']\n", "            elif row['Title'] == 'Mrs':\n", "                return grouped_median.loc['female', 1, 'Mrs']['Age']\n", "            elif row['Title'] == 'Officer':\n", "                return grouped_median.loc['female', 1, 'Officer']['Age']\n", "            elif row['Title'] == 'Royalty':\n", "                return grouped_median.loc['female', 1, 'Royalty']['Age']\n", "\n", "        elif row['Sex']=='female' and row['Pclass'] == 2:\n", "            if row['Title'] == 'Miss':\n", "                return grouped_median.loc['female', 2, 'Miss']['Age']\n", "            elif row['Title'] == 'Mrs':\n", "                return grouped_median.loc['female', 2, 'Mrs']['Age']\n", "\n", "        elif row['Sex']=='female' and row['Pclass'] == 3:\n", "            if row['Title'] == 'Miss':\n", "                return grouped_median.loc['female', 3, 'Miss']['Age']\n", "            elif row['Title'] == 'Mrs':\n", "                return grouped_median.loc['female', 3, 'Mrs']['Age']\n", "\n", "        elif row['Sex']=='male' and row['Pclass'] == 1:\n", "            if row['Title'] == 'Master':\n", "                return grouped_median.loc['male', 1, 'Master']['Age']\n", "            elif row['Title'] == 'Mr':\n", "                return grouped_median.loc['male', 1, 'Mr']['Age']\n", "            elif row['Title'] == 'Officer':\n", "                return grouped_median.loc['male', 1, 'Officer']['Age']\n", "            elif row['Title'] == 'Royalty':\n", "                return grouped_median.loc['male', 1, 'Royalty']['Age']\n", "\n", "        elif row['Sex']=='male' and row['Pclass'] == 2:\n", "            if row['Title'] == 'Master':\n", "                return grouped_median.loc['male', 2, 'Master']['Age']\n", "            elif row['Title'] == 'Mr':\n", "                return grouped_median.loc['male', 2, 'Mr']['Age']\n", "            elif row['Title'] == 'Officer':\n", "                return grouped_median.loc['male', 2, 'Officer']['Age']\n", "\n", "        elif row['Sex']=='male' and row['Pclass'] == 3:\n", "            if row['Title'] == 'Master':\n", "                return grouped_median.loc['male', 3, 'Master']['Age']\n", "            elif row['Title'] == 'Mr':\n", "                return grouped_median.loc['male', 3, 'Mr']['Age']\n", "    \n", "    combined.head(891).Age = combined.head(891).apply(lambda r : fillAges(r, grouped_median_train) if np.isnan(r['Age']) \n", "                                                      else r['Age'], axis=1)\n", "    \n", "    combined.iloc[891:].Age = combined.iloc[891:].apply(lambda r : fillAges(r, grouped_median_test) if np.isnan(r['Age']) \n", "                                                      else r['Age'], axis=1)"], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 113}, {"outputs": [], "source": ["process_age()"], "metadata": {}, "cell_type": "code", "execution_count": 114}, {"outputs": [], "source": ["def process_names():\n", "    \n", "    global combined\n", "    # we clean the Name variable\n", "    combined.drop('Name',axis=1,inplace=True)\n", "    \n", "    # encoding in dummy variable\n", "    titles_dummies = pd.get_dummies(combined['Title'],prefix='Title')\n", "    combined = pd.concat([combined,titles_dummies],axis=1)\n", "    \n", "    # removing the title variable\n", "    combined.drop('Title',axis=1,inplace=True)"], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 115}, {"outputs": [], "source": ["process_names()"], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 116}, {"outputs": [], "source": ["def process_fares():\n", "    \n", "    global combined\n", "    # there's one missing fare value - replacing it with the mean.\n", "    combined.head(891).Fare.fillna(combined.head(891).Fare.mean(), inplace=True)\n", "    combined.iloc[891:].Fare.fillna(combined.iloc[891:].Fare.mean(), inplace=True)"], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 117}, {"outputs": [], "source": ["process_fares()"], "metadata": {}, "cell_type": "code", "execution_count": 118}, {"outputs": [], "source": ["def process_embarked():\n", "    \n", "    global combined\n", "    # two missing embarked values - filling them with the most frequent one (S)\n", "    combined.head(891).Embarked.fillna('S', inplace=True)\n", "    combined.iloc[891:].Embarked.fillna('S', inplace=True)\n", "    \n", "    \n", "    # dummy encoding \n", "    embarked_dummies = pd.get_dummies(combined['Embarked'],prefix='Embarked')\n", "    combined = pd.concat([combined,embarked_dummies],axis=1)\n", "    combined.drop('Embarked',axis=1,inplace=True)"], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 119}, {"outputs": [], "source": ["process_embarked()"], "metadata": {}, "cell_type": "code", "execution_count": 120}, {"outputs": [], "source": ["def process_cabin():\n", "    \n", "    global combined\n", "    \n", "    # replacing missing cabins with U (for Uknown)\n", "    combined.Cabin.fillna('U', inplace=True)\n", "    \n", "    # mapping each Cabin value with the cabin letter\n", "    combined['Cabin'] = combined['Cabin'].map(lambda c : c[0])\n", "    \n", "    # dummy encoding ...\n", "    cabin_dummies = pd.get_dummies(combined['Cabin'], prefix='Cabin')\n", "    \n", "    combined = pd.concat([combined,cabin_dummies], axis=1)\n", "    \n", "    combined.drop('Cabin', axis=1, inplace=True)"], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 121}, {"outputs": [], "source": ["process_cabin()"], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 122}, {"outputs": [], "source": ["def process_sex():\n", "    \n", "    global combined\n", "    # mapping string values to numerical one \n", "    combined['Sex'] = combined['Sex'].map({'male':1,'female':0})"], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 123}, {"outputs": [], "source": ["process_sex()"], "metadata": {}, "cell_type": "code", "execution_count": 124}, {"outputs": [], "source": ["def process_pclass():\n", "    \n", "    global combined\n", "    # encoding into 3 categories:\n", "    pclass_dummies = pd.get_dummies(combined['Pclass'], prefix=\"Pclass\")\n", "    \n", "    # adding dummy variables\n", "    combined = pd.concat([combined,pclass_dummies],axis=1)\n", "    \n", "    # removing \"Pclass\"\n", "    \n", "    combined.drop('Pclass',axis=1,inplace=True)"], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 125}, {"outputs": [], "source": ["process_pclass()"], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 126}, {"outputs": [], "source": ["def process_ticket():\n", "    \n", "    global combined\n", "    \n", "    # a function that extracts each prefix of the ticket, returns 'XXX' if no prefix (i.e the ticket is a digit)\n", "    def cleanTicket(ticket):\n", "        ticket = ticket.replace('.','')\n", "        ticket = ticket.replace('/','')\n", "        ticket = ticket.split()\n", "        ticket = map(lambda t : t.strip(), ticket)\n", "        ticket = filter(lambda t : not t.isdigit(), ticket)\n", "        if len(ticket) > 0:\n", "            return ticket[0]\n", "        else: \n", "            return 'XXX'\n", "    \n", "\n", "    # Extracting dummy variables from tickets:\n", "\n", "    combined['Ticket'] = combined['Ticket'].map(cleanTicket)\n", "    tickets_dummies = pd.get_dummies(combined['Ticket'], prefix='Ticket')\n", "    combined = pd.concat([combined, tickets_dummies], axis=1)\n", "    combined.drop('Ticket', inplace=True, axis=1)"], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 127}, {"outputs": [], "source": ["def process_family():\n", "    \n", "    global combined\n", "    # introducing a new feature : the size of families (including the passenger)\n", "    combined['FamilySize'] = combined['Parch'] + combined['SibSp'] + 1\n", "    \n", "    # introducing other features based on the family size\n", "    combined['Singleton'] = combined['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n", "    combined['SmallFamily'] = combined['FamilySize'].map(lambda s: 1 if 2<=s<=4 else 0)\n", "    combined['LargeFamily'] = combined['FamilySize'].map(lambda s: 1 if 5<=s else 0)"], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 128}, {"outputs": [], "source": ["process_family()"], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 129}, {"outputs": [], "source": ["combined.drop('Ticket', inplace=True, axis=1)\n", "combined.drop('PassengerId', inplace=True, axis=1)"], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 130}, {"source": ["## Modeling"], "metadata": {}, "cell_type": "markdown"}, {"outputs": [], "source": ["def recover_train_test_target():\n", "    global combined\n", "    \n", "    train0 = pd.read_csv('../input/train.csv')\n", "    \n", "    targets = train0.Survived\n", "    train = combined.head(891)\n", "    test = combined.iloc[891:]\n", "    \n", "    return train, test, targets"], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 131}, {"outputs": [], "source": ["train, test, targets = recover_train_test_target()"], "metadata": {}, "cell_type": "code", "execution_count": 132}, {"outputs": [], "source": ["clf = RandomForestClassifier(n_estimators=50, max_features='sqrt')\n", "clf = clf.fit(train, targets)"], "metadata": {}, "cell_type": "code", "execution_count": 133}, {"outputs": [], "source": ["model = SelectFromModel(clf, prefit=True)\n", "train_reduced = model.transform(train)\n", "train_reduced.shape"], "metadata": {}, "cell_type": "code", "execution_count": 135}, {"outputs": [], "source": ["test_reduced = model.transform(test)\n", "test_reduced.shape"], "metadata": {}, "cell_type": "code", "execution_count": 136}, {"outputs": [], "source": ["run_gs = False\n", "\n", "if run_gs:\n", "    parameter_grid = {\n", "                 'max_depth' : [4, 6, 8],\n", "                 'n_estimators': [50, 10],\n", "                 'max_features': ['sqrt', 'auto', 'log2'],\n", "                 'min_samples_split': [1, 3, 10],\n", "                 'min_samples_leaf': [1, 3, 10],\n", "                 'bootstrap': [True, False],\n", "                 }\n", "    forest = RandomForestClassifier()\n", "    cross_validation = StratifiedKFold(targets, n_folds=5)\n", "\n", "    grid_search = GridSearchCV(forest,\n", "                               scoring='accuracy',\n", "                               param_grid=parameter_grid,\n", "                               cv=cross_validation)\n", "\n", "    grid_search.fit(train, targets)\n", "    model = grid_search\n", "    parameters = grid_search.best_params_\n", "\n", "    print('Best score: {}'.format(grid_search.best_score_))\n", "    print('Best parameters: {}'.format(grid_search.best_params_))\n", "else: \n", "    parameters = {'bootstrap': False, 'min_samples_leaf': 3, 'n_estimators': 50, \n", "                  'min_samples_split': 10, 'max_features': 'sqrt', 'max_depth': 6}\n", "    \n", "    model = RandomForestClassifier(**parameters)\n", "    model.fit(train, targets)"], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 137}, {"outputs": [], "source": ["Y_pred = model.predict(test).astype(int)"], "metadata": {"collapsed": true}, "cell_type": "code", "execution_count": 138}, {"source": ["## Model, predict and solve"], "metadata": {"_cell_guid": "1b9ddef4-678f-45ed-bdc8-edf8eb5eed47", "_uuid": "bd2fd45668a45da562922354926b4ab36a6c3f40", "_execution_state": "idle"}, "cell_type": "markdown"}, {"outputs": [], "source": ["X_train = train_df.drop(\"Survived\", axis=1)\n", "Y_train = train_df[\"Survived\"]\n", "X_test = test_df.drop(\"PassengerId\", axis=1).copy()\n", "X_train.shape, Y_train.shape, X_test.shape"], "metadata": {"_cell_guid": "e0fbaca0-94f7-473d-bf30-e52dec0896d0", "_uuid": "1f48955c437c30ebde37c2f08b07493551c762d3", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 35}, {"outputs": [], "source": ["# Logistic Regression\n", "\n", "logreg = LogisticRegression()\n", "logreg.fit(X_train, Y_train)\n", "Y_pred = logreg.predict(X_test)\n", "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n", "acc_log"], "metadata": {"_cell_guid": "b370d1f0-7158-4821-b5e5-0dfc486074a5", "_uuid": "00ae851599340d39705ae13c1fd2a09a271d70ab", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 36}, {"outputs": [], "source": ["coeff_df = pd.DataFrame(train_df.columns.delete(0))\n", "coeff_df.columns = ['Feature']\n", "coeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n", "\n", "coeff_df.sort_values(by='Correlation', ascending=False)"], "metadata": {"_cell_guid": "80cacf96-a066-40b8-a34a-ef04ff9691dd", "_uuid": "1cdd5dc881294794d350b8fbc5e910aac2518914", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 37}, {"outputs": [], "source": ["# Support Vector Machines\n", "\n", "svc = SVC()\n", "svc.fit(X_train, Y_train)\n", "Y_pred = svc.predict(X_test)\n", "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n", "acc_svc"], "metadata": {"_cell_guid": "0ea57f03-6019-498c-b4f2-0ba0ee30bdb5", "_uuid": "bd5f5016445006ca5f85358a6356ff78e6423373", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 38}, {"outputs": [], "source": ["knn = KNeighborsClassifier(n_neighbors = 3)\n", "knn.fit(X_train, Y_train)\n", "Y_pred = knn.predict(X_test)\n", "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n", "acc_knn"], "metadata": {"_cell_guid": "8de8358f-345c-4496-b55c-f33984158588", "_uuid": "aa8510a64a495ec443b62254351d4fd2c1522886", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 39}, {"outputs": [], "source": ["# Gaussian Naive Bayes\n", "\n", "gaussian = GaussianNB()\n", "gaussian.fit(X_train, Y_train)\n", "Y_pred = gaussian.predict(X_test)\n", "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n", "acc_gaussian"], "metadata": {"_cell_guid": "503aeec3-cc3f-46ca-907a-4c9bf6fe0438", "_uuid": "35fe4f35d1ab4a13da346e1839498252e38b4c82", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 40}, {"outputs": [], "source": ["# Perceptron\n", "\n", "perceptron = Perceptron()\n", "perceptron.fit(X_train, Y_train)\n", "Y_pred = perceptron.predict(X_test)\n", "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n", "acc_perceptron"], "metadata": {"_cell_guid": "78432f3c-7099-4c3b-a29d-e4a9ceda5d48", "_uuid": "8d50569ec4e7dd54be215b63eb76210ba2b95ffe", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 41}, {"outputs": [], "source": ["# Linear SVC\n", "\n", "linear_svc = LinearSVC()\n", "linear_svc.fit(X_train, Y_train)\n", "Y_pred = linear_svc.predict(X_test)\n", "acc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\n", "acc_linear_svc"], "metadata": {"_cell_guid": "13539553-c498-4bf5-9326-32b450cd935b", "_uuid": "670b10dd390b00d7c8dc2216524eda1099f0c475", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 42}, {"outputs": [], "source": ["# Stochastic Gradient Descent\n", "\n", "sgd = SGDClassifier()\n", "sgd.fit(X_train, Y_train)\n", "Y_pred = sgd.predict(X_test)\n", "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n", "acc_sgd"], "metadata": {"_cell_guid": "d8972564-eb70-4918-84a4-1e1ae4a94039", "_uuid": "feef35166d93cdb861ff46b6bc99e3a22037e584", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 43}, {"outputs": [], "source": ["# Decision Tree\n", "\n", "decision_tree = DecisionTreeClassifier()\n", "decision_tree.fit(X_train, Y_train)\n", "Y_pred = decision_tree.predict(X_test)\n", "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n", "acc_decision_tree"], "metadata": {"_cell_guid": "86939fbd-f5ec-41ed-b26e-f67ce8f11be3", "_uuid": "4c99178c43a2682a7d4db4500ef4825dd8ee82b4", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 44}, {"outputs": [], "source": ["# Random Forest\n", "\n", "random_forest = RandomForestClassifier(n_estimators=100)\n", "random_forest.fit(X_train, Y_train)\n", "Y_pred = random_forest.predict(X_test)\n", "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n", "acc_random_forest"], "metadata": {"_cell_guid": "5b953f5e-85c5-4dd9-ab3f-8f28890d72e8", "_uuid": "d5a3ef0feb1968bcc607fe40ed7cfa4f044263ce", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 45}, {"outputs": [], "source": ["# XGBoost\n", "\n", "gbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.5)\n", "gbm.fit(X_train, Y_train)\n", "Y_pred = gbm.predict(X_test)\n", "acc_gbm = round(gbm.score(X_train, Y_train) * 100, 2)\n", "acc_gbm"], "metadata": {"_cell_guid": "681caa64-ea18-46d7-afed-d20154576d7c", "_uuid": "44cf674515d88c9c16d0fe909592694052d3ca10"}, "cell_type": "code", "execution_count": 46}, {"outputs": [], "source": ["# Voting Classifier\n", "\n", "ensemble = VotingClassifier(estimators=[('svc', svc), ('random_forest', random_forest), \n", "                                        ('decision_tree', decision_tree), ('gbm', gbm)])\n", "ensemble = ensemble.fit(X_train, Y_train)\n", "Y_pred = ensemble.predict(X_test)"], "metadata": {"_cell_guid": "b4683899-f627-4a9e-83e8-353f1b63cb7b", "_uuid": "ff9dc68027b854a33a2eb05895866b294a479ca1", "collapsed": true}, "cell_type": "code", "execution_count": 47}, {"outputs": [], "source": ["kfold = StratifiedKFold(n_splits=10)"], "metadata": {"_cell_guid": "c6d91024-7400-418d-bbe0-ece685a17d28", "_uuid": "1515b994d986c7d6765ea1ee2a09d206679eecd6", "collapsed": true}, "cell_type": "code", "execution_count": 48}, {"outputs": [], "source": ["# Extra Trees Classifier\n", "\n", "extra_trees = ExtraTreesClassifier()\n", "\n", "ex_param_grid = {\"max_depth\": [None],\n", "                \"max_features\": [1, 3, 8],\n", "                \"min_samples_split\": [2, 3, 10],\n", "                \"min_samples_leaf\": [1, 3, 10], \n", "                \"bootstrap\": [False],\n", "                \"n_estimators\": [100, 300], \n", "                \"criterion\": [\"gini\"]}\n", "\n", "gs_extra_trees = GridSearchCV(extra_trees, param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\")\n", "\n", "gs_extra_trees.fit(X_train, Y_train)\n", "\n", "extra_trees_best = gs_extra_trees.best_estimator_\n", "\n", "Y_pred = extra_trees_best.predict(X_test)"], "metadata": {"_cell_guid": "fcdf532e-c0f1-42d1-b529-f064c0714d3b", "_uuid": "3a9c0aac8053877c42f1ddb3f5ea2c6fac9287d8", "collapsed": true}, "cell_type": "code", "execution_count": 49}, {"source": ["## Model evaluation"], "metadata": {"_cell_guid": "e4886743-c58f-426f-baf5-8ea1849f68b4", "_uuid": "973e2fbf2d7c65bdd908b7bf5f497fd50c8357f5", "_execution_state": "idle"}, "cell_type": "markdown"}, {"outputs": [], "source": ["models = pd.DataFrame({\n", "    'Model' : ['Support Vector Machines', 'KNN', 'Logistic Regression',\n", "              'Random Forest', 'Naive Bayes', 'Perceptron',\n", "              'Stochastic Gradient Descent', 'Linear SVC',\n", "              'Decision Tree', 'XGBoost'],\n", "    'Score' : [acc_svc, acc_knn, acc_log,\n", "              acc_random_forest, acc_gaussian, acc_perceptron,\n", "              acc_sgd, acc_linear_svc, acc_decision_tree, acc_gbm]})\n", "models.sort_values(by='Score', ascending=False)"], "metadata": {"_cell_guid": "1373359d-938a-4a43-b638-5b48916edf60", "_uuid": "6b76443ec8d074e696a69902915e007b37c964d3", "_execution_state": "idle"}, "cell_type": "code", "execution_count": 50}, {"outputs": [], "source": ["submission = pd.DataFrame({\n", "    \"PassengerId\": test_df[\"PassengerId\"],\n", "    \"Survived\": Y_pred\n", "})\n", "submission.to_csv('submission.csv', index=False)"], "metadata": {"_cell_guid": "d2ac89de-069e-4a70-b6b9-a3461f5f550d", "_uuid": "02fcabdf9a43c3312ccfcaee08d426a6dae2fb3d", "collapsed": true, "_kg_hide-output": false, "_execution_state": "idle"}, "cell_type": "code", "execution_count": 139}, {"source": ["## References\n", "\n", "This notebook was done based on the [Titanic Data Science Solutions](https://www.kaggle.com/ibacaraujo/titanic-data-science-solutions) tutorial"], "metadata": {"_cell_guid": "89e4bed8-dc28-411d-b27d-52bdd4519da5", "_uuid": "4a376440123099891f18c3dab005f4959ece50d1", "_execution_state": "idle"}, "cell_type": "markdown"}], "nbformat_minor": 1, "metadata": {"_is_fork": false, "language_info": {"nbconvert_exporter": "python", "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "pygments_lexer": "ipython3", "version": "3.6.3", "codemirror_mode": {"name": "ipython", "version": 3}}, "_change_revision": 0, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat": 4}