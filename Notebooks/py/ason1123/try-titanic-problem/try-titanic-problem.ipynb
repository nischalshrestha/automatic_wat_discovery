{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "559fc271-b1a6-ef99-5d3c-e0e8088fbcf7"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8c896c17-171d-1ee7-597e-c8d42d285039"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import re as re\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "600601f6-7f5e-be50-c1cc-a6fac8cf0aea"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7de166a6-1a79-48e6-b167-52692b2ccb8a"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "train_df = pd.read_csv( '../input/train.csv')\n",
        "test_df = pd.read_csv( '../input/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3052d117-62cc-b299-c478-3338b34bc90f"
      },
      "outputs": [],
      "source": [
        "# Store our passenger ID \n",
        "PassengerId = test_df['PassengerId']\n",
        "PassengerId.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "11831cf0-0021-1629-c1b5-978f561ace30"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c352e575-f4b0-f9b4-159c-7d9c877db432"
      },
      "outputs": [],
      "source": [
        "#creat a total data\n",
        "train_df['source']= 'train'\n",
        "test_df['source'] = 'test'\n",
        "full_df=pd.concat([train_df, test_df],ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b2d282a4-b71d-82f5-2364-9cb61bfa419a"
      },
      "outputs": [],
      "source": [
        "# remove all nulls in 'Fare'\n",
        "full_df['Fare'] = full_df['Fare'].fillna(full_df['Fare'].median())\n",
        "# full_df['Fare'] = full_df['Fare'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8a6d19a2-04da-b6dc-3f1a-e001bc7269d2"
      },
      "outputs": [],
      "source": [
        "# remove all nulls in 'Age'\n",
        "full_df['Age'] = full_df['Age'].fillna(full_df['Age'].median())\n",
        "# full_df['Age'] = full_df['Age'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0c95602f-e865-a94c-0941-d20fc5a74ff9"
      },
      "outputs": [],
      "source": [
        "# remove all nulls in 'Embarked'\n",
        "full_df['Embarked'] = full_df['Embarked'].fillna('S')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "377d3b1b-cffa-8591-1b28-b2972df05e15"
      },
      "outputs": [],
      "source": [
        "\n",
        "# replacing missing cabins with U (for Uknown)\n",
        "full_df[ 'Cabin' ] = full_df.Cabin.fillna( 'U' )\n",
        "\n",
        "# mapping each Cabin value with the cabin letter\n",
        "full_df[ 'Cabin' ] = full_df[ 'Cabin' ].map( lambda c : c[0] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1ae641d9-9af0-f7c8-3a2a-cee29eb0da16"
      },
      "outputs": [],
      "source": [
        "\n",
        "def cleanTicket( ticket ):\n",
        "    ticket = ticket.replace( '.' , '' )\n",
        "    ticket = ticket.replace( '/' , '' )\n",
        "    ticket = ticket.split()\n",
        "    ticket = map( lambda t : t.strip() , ticket )\n",
        "    ticket = list(filter( lambda t : not t.isdigit() , ticket ))\n",
        "    if len( ticket ) > 0:\n",
        "        return ticket[0]\n",
        "    else: \n",
        "        return 'XXX'\n",
        "\n",
        "\n",
        "full_df[ 'Ticket' ] = full_df[ 'Ticket' ].map( cleanTicket )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5a63ba8b-4d9a-7fe9-c662-0a232d2ab080"
      },
      "outputs": [],
      "source": [
        "# 'Title'\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# plan 1:\n",
        "# def get_title(name):\n",
        "#     title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
        "#     # If the title exists, extract and return it.\n",
        "#     if title_search:\n",
        "#         return title_search.group(1)\n",
        "#     return \"\"\n",
        "\n",
        "# full_df['Title'] = full_df['Name'].apply(get_title)\n",
        "\n",
        "# full_df['Title'] = full_df['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
        "# 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "\n",
        "# full_df['Title'] = full_df['Title'].replace('Mlle', 'Miss')\n",
        "# full_df['Title'] = full_df['Title'].replace('Ms', 'Miss')\n",
        "# full_df['Title'] = full_df['Title'].replace('Mme', 'Mrs')\n",
        "\n",
        "\n",
        "# plan 2:\n",
        "# title = pd.DataFrame()\n",
        "# # we extract the title from each name\n",
        "full_df[ 'Title' ] = full_df[ 'Name' ].map( lambda name: name.split( ',' )[1].split( '.' )[0].strip() )\n",
        "\n",
        "# a map of more aggregated titles\n",
        "Title_Dictionary = {\n",
        "                    \"Capt\":       \"Officer\",\n",
        "                    \"Col\":        \"Officer\",\n",
        "                    \"Major\":      \"Officer\",\n",
        "                    \"Jonkheer\":   \"Royalty\",\n",
        "                    \"Don\":        \"Royalty\",\n",
        "                    \"Sir\" :       \"Royalty\",\n",
        "                    \"Dr\":         \"Officer\",\n",
        "                    \"Rev\":        \"Officer\",\n",
        "                    \"the Countess\":\"Royalty\",\n",
        "                    \"Dona\":       \"Royalty\",\n",
        "                    \"Mme\":        \"Mrs\",\n",
        "                    \"Mlle\":       \"Miss\",\n",
        "                    \"Ms\":         \"Mrs\",\n",
        "                    \"Mr\" :        \"Mr\",\n",
        "                    \"Mrs\" :       \"Mrs\",\n",
        "                    \"Miss\" :      \"Miss\",\n",
        "                    \"Master\" :    \"Master\",\n",
        "                    \"Lady\" :      \"Royalty\"\n",
        "\n",
        "                    }\n",
        "\n",
        "# we map each title\n",
        "full_df[ 'Title' ] = full_df.Title.map( Title_Dictionary )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "75e02805-b9b6-7b1a-24ed-91e400427f09"
      },
      "outputs": [],
      "source": [
        "# # 'Age' plan 4:  after 'Title'\n",
        "# full_df['AgeFill']=full_df['Age']\n",
        "# mean_ages = np.zeros(4)\n",
        "# mean_ages[0]=np.average(full_df[full_df['Title'] == 'Miss']['Age'].dropna())\n",
        "# mean_ages[1]=np.average(full_df[full_df['Title'] == 'Mrs']['Age'].dropna())\n",
        "# mean_ages[2]=np.average(full_df[full_df['Title'] == 'Mr']['Age'].dropna())\n",
        "# mean_ages[3]=np.average(full_df[full_df['Title'] == 'Master']['Age'].dropna())\n",
        "# full_df.loc[ (full_df.Age.isnull()) & (full_df.Title == 'Miss') ,'AgeFill'] = mean_ages[0]\n",
        "# full_df.loc[ (full_df.Age.isnull()) & (full_df.Title == 'Mrs') ,'AgeFill'] = mean_ages[1]\n",
        "# full_df.loc[ (full_df.Age.isnull()) & (full_df.Title == 'Mr') ,'AgeFill'] = mean_ages[2]\n",
        "# full_df.loc[ (full_df.Age.isnull()) & (full_df.Title == 'Master') ,'AgeFill'] = mean_ages[3]\n",
        "\n",
        "\n",
        "# # one null in 'AgeFill' is needed to be solved\n",
        "# age_avg = full_df['AgeFill'].mean()\n",
        "# age_std = full_df['AgeFill'].std()\n",
        "# age_null_count = full_df['AgeFill'].isnull().sum()\n",
        "# age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
        "# full_df['AgeFill'][np.isnan(full_df['AgeFill'])] = age_null_random_list\n",
        "# full_df['AgeFill'] = full_df['AgeFill'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9c288b44-08ef-216f-ccc8-2e64825892ca"
      },
      "outputs": [],
      "source": [
        "# 'Family'\n",
        "\n",
        "full_df['Family'] = full_df['Parch'] + full_df['SibSp'] + 1\n",
        "\n",
        "full_df[ 'Family_Single' ] = full_df[ 'Family' ].map( lambda s : 1 if s == 1 else 0 )\n",
        "full_df[ 'Family_Small' ]  = full_df[ 'Family' ].map( lambda s : 1 if 2 <= s <= 4 else 0 )\n",
        "full_df[ 'Family_Large' ]  = full_df[ 'Family' ].map( lambda s : 1 if 5 <= s else 0 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8e9024e6-5cd8-52c0-003f-39e71cd019fc"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7509df18-2307-a930-3137-0baf49de93b4"
      },
      "outputs": [],
      "source": [
        "# remove useless features\n",
        "# full_df = full_df.drop(['Cabin','Age','Name','PassengerId'], axis=1)\n",
        "\n",
        "# full_df = full_df.loc[:,['source','Survived','AgeFill','Fare','Embarked','Cabin_head','Pclass','Sex','Title','Ticket','Family_Single','Family_Small','Family_Large']]\n",
        "\n",
        "full_df = full_df.loc[:,['source','Survived','Age','Fare','Embarked','Cabin','Family','Family_Single','Family_Small','Family_Large','Pclass','Sex','Title','Ticket']]\n",
        "\n",
        "\n",
        "full_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "dccb82e6-2277-3f4c-b0a6-0200a7ae4d0c"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8b916791-1fdc-8499-832d-975149885b82"
      },
      "outputs": [],
      "source": [
        "# One-Hot encoding\n",
        "# var_to_encode = ['Cabin_head','Ticket','HighLow', 'Embarked', 'Pclass', 'Title', 'Person', 'Sex', 'CabinClass', 'TicketClass', 'Age_bins', 'Age_bins*Class', 'Fare_bins'] # need encoding feature list\n",
        "\n",
        "var_to_encode = ['Embarked','Cabin','Pclass','Sex','Title','Ticket']\n",
        "\n",
        "full_df = pd.get_dummies(full_df, columns=var_to_encode)\n",
        "full_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "088b918c-d13b-2605-1060-b3ff241f0d1a"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "457ba2fc-eb3e-4501-ce09-52a5ca341c2d"
      },
      "outputs": [],
      "source": [
        "# split the full data\n",
        "train = full_df.loc[full_df['source']=='train']\n",
        "test = full_df.loc[full_df['source']=='test']\n",
        "\n",
        "train_y = train['Survived'].astype(int)\n",
        "train_X = train.drop(['source','Survived'],axis=1)\n",
        "test_X = test.drop(['source','Survived'],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7d981d23-f464-6c0e-e882-4f92d867d8c7"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "64c1e5e7-81f5-1167-9b6b-d52cd6efaa63"
      },
      "outputs": [],
      "source": [
        "# Standardize features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X_scaler = StandardScaler()\n",
        "train_X = X_scaler.fit_transform(train_X)\n",
        "test_X = X_scaler.transform(test_X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c8e1dbc6-a9a5-51d9-4222-cd3e0463f0ed"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8693e0d0-9559-ef96-006b-52a76034ca60"
      },
      "outputs": [],
      "source": [
        "# classifier comparison\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(),\n",
        "    SVC(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GradientBoostingClassifier(),\n",
        "    GaussianNB(),\n",
        "    LinearDiscriminantAnalysis(),\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "    LogisticRegression()]\n",
        "\n",
        "log_cols = [\"Classifier\", \"Accuracy\"]\n",
        "log = pd.DataFrame(columns=log_cols)\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0) #0.1\n",
        "acc_dict = {}\n",
        "\n",
        "for train_index, test_index in sss.split(train_X, train_y):\n",
        "#     X_train, X_test = train_X.iloc[train_index], train_X.iloc[test_index]\n",
        "#     y_train, y_test = train_y.iloc[train_index], train_y.iloc[test_index]\n",
        "    X_train_v, X_test_v = train_X[train_index], train_X[test_index]\n",
        "    y_train_v, y_test_v = train_y[train_index], train_y[test_index]\n",
        "\n",
        "    for clf in classifiers:\n",
        "        name = clf.__class__.__name__\n",
        "        clf.fit(X_train_v, y_train_v)\n",
        "        train_predictions = clf.predict(X_test_v)\n",
        "        acc = accuracy_score(y_test_v, train_predictions)\n",
        "        if name in acc_dict:\n",
        "            acc_dict[name] += acc\n",
        "        else:\n",
        "            acc_dict[name] = acc\n",
        "\n",
        "for clf in acc_dict:\n",
        "    acc_dict[clf] = acc_dict[clf] / 10.0\n",
        "    log_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=log_cols)\n",
        "    log = log.append(log_entry)\n",
        "\n",
        "acc_df = log.sort_values(by='Accuracy',ascending = False)\n",
        "acc_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ed7077c3-93f7-929f-526e-5226f7a97b3d"
      },
      "outputs": [],
      "source": [
        "plt.xlabel('Accuracy')\n",
        "plt.title('Classifier Accuracy')\n",
        "\n",
        "sns.set_color_codes(\"muted\")\n",
        "sns.barplot(x='Accuracy', y='Classifier', data=acc_df, color=\"b\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b98519d3-37ec-f28d-1548-be66bf4eab24"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b6776e0c-9d64-8600-c4ba-24495a29583a"
      },
      "outputs": [],
      "source": [
        "# Create Numpy arrays of train, test and label\n",
        "y_train = train_y # Creates an array of label\n",
        "x_train = train_X # Creates an array of the train data\n",
        "x_test = test_X # Creats an array of the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0f91e74c-ea88-1f56-8297-a343a117543f"
      },
      "outputs": [],
      "source": [
        "# K-Folds cross-validation\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "ntrain = train.shape[0]\n",
        "ntest = test.shape[0]\n",
        "SEED = 0 # for reproducibility\n",
        "NFOLDS = 10 # set folds for out-of-fold prediction  # 15\n",
        "# kf = KFold(ntrain, n_splits= NFOLDS, random_state=SEED)\n",
        "kf = KFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "def kfolds_pre(clf, x_train, y_train, x_test):\n",
        "    kfolds_train = np.zeros((ntrain,))\n",
        "    kfolds_test = np.zeros((ntest,))\n",
        "    kfolds_test_all = np.empty((NFOLDS, ntest))\n",
        "\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
        "        x_tr = x_train[train_index]\n",
        "        y_tr = y_train[train_index]\n",
        "        x_te = x_train[test_index]\n",
        "        \n",
        "        clf.fit(x_tr, y_tr)\n",
        "\n",
        "        kfolds_train[test_index] = clf.predict(x_te)\n",
        "        kfolds_test_all[i, :] = clf.predict(x_test)\n",
        "\n",
        "    kfolds_test[:] = kfolds_test_all.mean(axis=0)\n",
        "    return kfolds_train.reshape(-1, 1), kfolds_test.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c325d582-5b9f-301e-ee24-6ddd6c98d4ae"
      },
      "outputs": [],
      "source": [
        "kn = KNeighborsClassifier()\n",
        "svc = SVC()\n",
        "dt = DecisionTreeClassifier()\n",
        "rf = RandomForestClassifier()\n",
        "ab = AdaBoostClassifier()\n",
        "gb = GradientBoostingClassifier()\n",
        "gnb = GaussianNB()\n",
        "ld = LinearDiscriminantAnalysis()\n",
        "qd = QuadraticDiscriminantAnalysis()\n",
        "lr = LogisticRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "edb44f98-84cc-e2e2-5852-50dcb326bd37"
      },
      "outputs": [],
      "source": [
        "# Create train and test predictions. These base results will be used as new features\n",
        "gb_kfolds_train, gb_kfolds_test = kfolds_pre(gb, x_train, y_train, x_test) # GradientBoostingClassifier\n",
        "rf_kfolds_train, rf_kfolds_test = kfolds_pre(rf,x_train, y_train, x_test) # RandomForestClassifier\n",
        "svc_kfolds_train, svc_kfolds_test = kfolds_pre(svc, x_train, y_train, x_test) # SVC\n",
        "lr_kfolds_train, lr_kfolds_test = kfolds_pre(lr, x_train, y_train, x_test) # LogisticRegression\n",
        "ab_kfolds_train, ab_kfolds_test = kfolds_pre(ab, x_train, y_train, x_test) # AdaBoostClassifier\n",
        "kn_kfolds_train, kn_kfolds_test = kfolds_pre(kn, x_train, y_train, x_test) # KNeighborsClassifier\n",
        "ld_kfolds_train, ld_kfolds_test = kfolds_pre(kn, x_train, y_train, x_test) # LinearDiscriminantAnalysis\n",
        "gnb_kfolds_train, gnb_kfolds_test = kfolds_pre(kn, x_train, y_train, x_test) # GaussianNB\n",
        "dt_kfolds_train, dt_kfolds_test = kfolds_pre(kn, x_train, y_train, x_test) # DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6c54d849-e59f-ff56-d3c1-8b57fd75b7df"
      },
      "outputs": [],
      "source": [
        "# Concatenate the output of the classifiers on the first level\n",
        "\n",
        "x_train_1 = np.concatenate(( lr_kfolds_train, gb_kfolds_train, ld_kfolds_train, dt_kfolds_train, svc_kfolds_train), axis=1)\n",
        "x_test_1 = np.concatenate(( lr_kfolds_test, gb_kfolds_test, ld_kfolds_test, dt_kfolds_test, svc_kfolds_test), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2004e898-c470-b6f4-e062-2f3582469727"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "55ff6ea4-2a3e-c18f-14ea-71e9ff10f28c"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "# make the final prediction\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "gbm = xgb.XGBClassifier(\n",
        " learning_rate = 0.02,\n",
        " n_estimators= 2000, #2000\n",
        " max_depth= 4,#4\n",
        " min_child_weight= 2,\n",
        " gamma=0.9, #1,0.9               \n",
        " subsample=0.8,\n",
        " colsample_bytree=0.8,\n",
        " objective= 'binary:logistic',\n",
        " nthread= -1,\n",
        " scale_pos_weight=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "25094fbe-8742-a7fb-2d64-5166e2df4ed5"
      },
      "outputs": [],
      "source": [
        "clf = gbm\n",
        "\n",
        "clf.fit(x_train_1, train_y)\n",
        "predictions = clf.predict(x_test_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b06922ef-2989-e792-9d8f-16e3cf9d2447"
      },
      "outputs": [],
      "source": [
        "test = clf.predict(x_train_1)\n",
        "acc = accuracy_score(train_y, test)\n",
        "acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "66d80cc6-7786-7d9a-f2f7-4b2f054f62bd"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fca00126-5697-ef6c-ec36-71c173f51f9e"
      },
      "outputs": [],
      "source": [
        "result = pd.DataFrame({ 'PassengerId': PassengerId,\n",
        "                            'Survived': predictions })\n",
        "result.to_csv(\"mysubmission6.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9f123b28-0e9d-5219-5663-9a78ea4a0097"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}