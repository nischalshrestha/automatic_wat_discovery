{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport sklearn\nimport scipy as sp\n\nimport random\nimport sys\nimport time\n\nimport IPython\nfrom IPython import display\n\nimport warnings\nwarnings.filterwarnings('ignore')\nprint('-'*25)\n\nimport os\nprint(os.listdir(\"../input\"))\nprint('-'*25)","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"e0f3ed05-cecd-428d-a609-1496b3c7ec9a","collapsed":true,"_uuid":"46474c47a70309da3ac1ee1b97915babba28a038","trusted":true},"cell_type":"code","source":"# common model algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\nfrom xgboost import XGBRegressor\n\n#common model helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\n#visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nfrom pandas.tools.plotting import scatter_matrix\n\n#configure visualization defaults\n%matplotlib inline\nmpl.style.use('ggplot')\nsns.set_style('white')\npylab.rcParams['figure.figsize'] = 12,8","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"43275fe3-6f63-4bd2-9681-796904e7d1b5","_uuid":"04f01d15258e273ecc0062e8e956a1f1d08f9d9b","scrolled":true,"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/featureengineering-titanic-procedure/fe_rfrage_scaled_data.csv')\ntrain_raw = pd.read_csv('../input/titanic/train.csv')\nprint(df.info())","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"7ce64d78-f3a7-41ac-9e86-e4c19cf90f26","collapsed":true,"_uuid":"6ba5f98d3373f6cdc6c41031122ddadceecbc9be","trusted":true},"cell_type":"code","source":"feature_columns = 'Parch|Pclass|SibSp|Family_Survival|Sex_Code|Embarked_.*|Title_.*|Cabin_.*|Age_scaled|Fare_scaled'\ndf_data_x = df.filter(regex = feature_columns)\ndf_data_y = df['Survived']\n\ndf_train_x = df_data_x.iloc[:891, :]  # 前891个数据是训练集\ndf_train_y = df_data_y.iloc[:891]\n\ndf_test_x = df_data_x.iloc[891:, :]\ndf_test_output = df.iloc[891:, :][['PassengerId','Survived']]","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"712d8d38-78ec-4f8a-aabb-595ed7ab7348","_uuid":"1db699613ebdb57d242225cfeabab29f81bcaf0b"},"cell_type":"markdown","source":"# 4. 模型融合  \n机器学习的套路是：  \n·先选择一个基础模型，进行训练和预测，最快建立起一个pipeline。  \n·在此基础上用交叉验证和GridSearch对模型调参，查看模型的表现。  \n·用模型融合进行多个模型的组合，用投票的方式（或其他）来预测结果。  \n一般来说，模型融合得到的结果会比单个模型的要好。  "},{"metadata":{"_cell_guid":"b5141bad-147b-48ad-aa0f-c1fa1812bf6a","_uuid":"b979512910c46c291fd6c3cea3e9c9d47af916b5"},"cell_type":"markdown","source":"## 4.1 用默认参数算数个模型的CV，从中选取较好的进行进一步的调参+learningcurves+融合"},{"metadata":{"_cell_guid":"b459b83b-ec6e-4b3c-b2c4-9f40d4ae25ac","_uuid":"ae0987feb569f21e7cfe105f17f79dea26a12446","scrolled":true,"trusted":true},"cell_type":"code","source":"cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0)\n\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(),\n    linear_model.Perceptron(),\n    #Navies Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    #Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n    #SVM\n    svm.SVC(probability=True),\n    svm.NuSVC(probability=True),\n    svm.LinearSVC(),\n    #Trees    \n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n    #Discriminant Analysis\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n    XGBClassifier()    \n    ]\n\nMLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\nMLA_compare = pd.DataFrame(columns = MLA_columns)\n\n# MLA_predict = df_train_y\nMLA_predict = {}\n\nrow_index = 0\nfor alg in MLA:\n\n    #set name and parameters\n    MLA_name = alg.__class__.__name__\n    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n    \n    #score model with cross validatiel_selection.\n    cv_results = model_selection.cross_validate(alg, df_train_x, df_train_y, cv  = cv_split,return_train_score=True)\n\n    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n    \n    #save MLA predictions - see section 6 for usage\n    alg.fit(df_train_x, df_train_y)\n    MLA_predict[MLA_name] = alg.predict(df_train_x)\n    \n    row_index+=1\n    \n\nMLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = MLA_compare, color = 'm')\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')\n\nMLA_compare","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"417bdab7-9d3f-4f0e-8d12-f960c8fcef5e","_uuid":"6d6963c7b175d2e01ccf9a4261ffd402f63d98e0"},"cell_type":"markdown","source":"* 选择ExtraTreesClassifier以上的模型进行进一步的调参+融合"},{"metadata":{"_cell_guid":"cc524ebb-87ae-4a80-bdca-93ba6a1f1838","_uuid":"5612314f268743773a0f1287243e0d19742f74ed"},"cell_type":"markdown","source":"## 4.2 hyperparameter tunning for best models for ensembling"},{"metadata":{"_cell_guid":"69974139-776b-4ef4-9ff8-62006bf6e39e","collapsed":true,"_uuid":"fb3056b73d1485cab885fd01ccd429a95b0b4767","trusted":true},"cell_type":"code","source":"vote_est = [\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc', ensemble.ExtraTreesClassifier()),\n    ('gbc', ensemble.GradientBoostingClassifier()),\n    ('rfc', ensemble.RandomForestClassifier()),\n    ('gpc', gaussian_process.GaussianProcessClassifier()),\n    ('lr', linear_model.LogisticRegressionCV()),\n    ('bnb', naive_bayes.BernoulliNB()),\n    ('gnb', naive_bayes.GaussianNB()),\n    ('knn', neighbors.KNeighborsClassifier()),\n    ('svc', svm.SVC(probability=True)),\n    ('xgb', XGBClassifier())\n]\n\ngrid_n_estimator = [10, 50, 100, 300, 500]\ngrid_ratio = [.5, .8, 1.0]\ngrid_learn = [.001, .005, .01, .05, .1]\ngrid_max_depth = [2, 4, 6, 8, 10]\ngrid_criterion = ['gini', 'entropy']\ngrid_bool = [True, False]\ngrid_seed = [0]\n\ngrid_param = [\n    # AdaBoostClassifier\n    {\n        'n_estimators':grid_n_estimator,\n        'learning_rate':grid_learn,\n        'random_state':grid_seed\n    },\n    # BaggingClassifier\n    {\n        'n_estimators':grid_n_estimator,\n        'max_samples':grid_ratio,\n        'random_state':grid_seed\n    },\n    # ExtraTreesClassifier\n    {\n        'n_estimators':grid_n_estimator,\n        'criterion':grid_criterion,\n        'max_depth':grid_max_depth,\n        'random_state':grid_seed\n    },\n    # GradientBoostingClassifier\n    {\n        'learning_rate':grid_learn,\n        'n_estimators':grid_n_estimator,\n        'max_depth':grid_max_depth,\n        'random_state':grid_seed,\n\n    },\n    # RandomForestClassifier\n    {\n        'n_estimators':grid_n_estimator,\n        'criterion':grid_criterion,\n        'max_depth':grid_max_depth,\n        'oob_score':[True],\n        'random_state':grid_seed\n    },\n    # GaussianProcessClassifier\n    {\n        'max_iter_predict':grid_n_estimator,\n        'random_state':grid_seed\n    },\n    # LogisticRegressionCV\n    {\n        'fit_intercept':grid_bool,  # default: True\n        'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n        'random_state':grid_seed\n    },\n    # BernoulliNB\n    {\n        'alpha':grid_ratio,\n    },\n    # GaussianNB\n    {},\n    # KNeighborsClassifier\n    {\n        'n_neighbors':range(6, 25),\n        'weights':['uniform', 'distance'],\n        'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute']\n    },\n    # SVC\n    {\n        'C':[1, 2, 3, 4, 5],\n        'gamma':grid_ratio,\n        'decision_function_shape':['ovo', 'ovr'],\n        'probability':[True],\n        'random_state':grid_seed\n    },\n    # XGBClassifier\n    {\n        'learning_rate':grid_learn,\n        'max_depth':[1, 2, 4, 6, 8, 10],\n        'n_estimators':grid_n_estimator,\n        'seed':grid_seed\n    }\n]","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"5fc6c1f7-9381-402d-a740-d76054ec5a9b","_uuid":"e8b0d090692020da2bb3456b38991fcdd5d401cd"},"cell_type":"markdown","source":"tune hyperparameter  \n可以更改ensemble的模型试试"},{"metadata":{"scrolled":true,"_cell_guid":"5e3c5d62-0593-44a2-aa64-1b761d56f018","_uuid":"bb3c66bbd93bc405e910e66d55d8810ac6fd4211","trusted":true},"cell_type":"code","source":"start_total = time.perf_counter()\nN = 0\nfor clf, param in zip (vote_est, grid_param):  \n    start = time.perf_counter()     \n    cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0) \n    if 'n_estimators' not in param.keys():\n        print(clf[1].__class__.__name__, 'GridSearchCV')\n        best_search = model_selection.GridSearchCV(estimator = clf[1], param_grid = param, cv = cv_split, scoring = 'accuracy')\n        best_search.fit(df_train_x, df_train_y)\n        best_param = best_search.best_params_\n    else:\n        print(clf[1].__class__.__name__, 'RandomizedSearchCV')\n        best_search2 = model_selection.RandomizedSearchCV(estimator = clf[1], param_distributions = param, cv = cv_split, scoring = 'accuracy')\n        best_search2.fit(df_train_x, df_train_y)\n        best_param = best_search2.best_params_\n    run = time.perf_counter() - start\n\n    print('The best parameter for {} is {} with a runtime of {:.2f} seconds.'.format(clf[1].__class__.__name__, best_param, run))\n    clf[1].set_params(**best_param) \n\nrun_total = time.perf_counter() - start_total\nprint('Total optimization time was {:.2f} minutes.'.format(run_total/60))\n","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"423e2253-7e77-433e-a65f-02f50c3dba68","_uuid":"323a16009d2fbf6c034f5d3ed5c51230c1f4f838"},"cell_type":"markdown","source":"## 4.3训练模型，并且查看融合模型CV值，可供前面各种改进的最终参考"},{"metadata":{"_cell_guid":"ef4d7abd-8897-46b0-b684-bcc0413cc5e1","_uuid":"86f559f22bf4da9cb2585676ef7f313602f908c1","trusted":true},"cell_type":"code","source":"grid_hard = ensemble.VotingClassifier(estimators = vote_est , voting = 'hard')\ngrid_hard_cv = model_selection.cross_validate(grid_hard, df_train_x, df_train_y, cv = cv_split, scoring = 'accuracy')\n# grid_hard.fit(df_train_x, df_train_y)\n\nprint(\"Hard Voting w/Tuned Hyperparameters Training w/bin score mean: {:.2f}\". format(grid_hard_cv['train_score'].mean()*100)) \nprint(\"Hard Voting w/Tuned Hyperparameters Test w/bin score mean: {:.2f}\". format(grid_hard_cv['test_score'].mean()*100))\nprint(\"Hard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- {:.2f}\". format(grid_hard_cv['test_score'].std()*100*3))\nprint('-'*10)\n\ngrid_soft = ensemble.VotingClassifier(estimators = vote_est , voting = 'soft')\ngrid_soft_cv = model_selection.cross_validate(grid_soft, df_train_x, df_train_y, cv = cv_split, scoring = 'accuracy')\n# grid_soft.fit(df_train_x, df_train_y)\n\nprint(\"Soft Voting w/Tuned Hyperparameters Training w/bin score mean: {:.2f}\". format(grid_soft_cv['train_score'].mean()*100)) \nprint(\"Soft Voting w/Tuned Hyperparameters Test w/bin score mean: {:.2f}\". format(grid_soft_cv['test_score'].mean()*100))\nprint(\"Soft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- {:.2f}\". format(grid_soft_cv['test_score'].std()*100*3))\n","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"ff66c80d-f6cb-45d4-a4cb-c3817d847383","_uuid":"4549562ceda17bb51b0c164a5930b2e88d3932c8"},"cell_type":"markdown","source":"## 4.4 画learning curves  \n对模型融合选择作出参考  \n对过拟合数据：  \n· 做feature selection  \n· 提供更多数据"},{"metadata":{"_cell_guid":"4c34c9db-68d2-4770-8b6c-6575fa0ad009","_uuid":"3dfe2e5dd00323cadfa08025c04b0ceb769533b0","scrolled":true,"trusted":true},"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"Generate a simple plot of the test and training learning curve\"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = model_selection.learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt\n\nX = df_train_x\ny = df_train_y\ncv_lc = model_selection.ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n\nfor alg in vote_est:\n    plot_learning_curve(alg[1], alg[0], X, y, ylim=(0.6, 1.01), cv=cv_lc)\n    plt.show()","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"9b52e989-c789-46a1-84bb-85f84d219a91","_uuid":"53bc563ac0424b988466ed53bd2fa9df63cec84e"},"cell_type":"markdown","source":"## 4.5 看看这几个模型之间的区分度，判断是否适合ensemble"},{"metadata":{"_cell_guid":"3e48f995-7560-433d-9b0c-d463f18fab9a","_uuid":"e384372c0dfc9a851f7b69b9d2f65a6ff8bea3c0","scrolled":true,"trusted":true},"cell_type":"code","source":"test_survived = {}\nfor alg in vote_est:\n    alg[1].fit(df_train_x,df_train_y)\n    test_survived[alg[0]] = pd.Series(alg[1].predict(df_test_x))\nensemble_results = pd.concat(test_survived, axis=1)\ng=sns.heatmap(ensemble_results.corr(),annot=True)","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"071e58a5-f935-41c1-a281-c71730691319","_uuid":"c955f26248dd2cc5c52dcdc6f605f7bd3a64b462"},"cell_type":"markdown","source":"## 4.6 模型最终预测结果"},{"metadata":{"_cell_guid":"85319554-4b11-49e4-a38a-e7e1c4be8136","_uuid":"912bf8bb6659e011a846109b8ab1bb9620081bf1"},"cell_type":"markdown","source":"# 6. 提交结果"},{"metadata":{"_cell_guid":"35b2f7fc-91a0-4bc1-8eec-848cffd040e9","_uuid":"d668f948e3bfed50813031ee13471971de5f998e","trusted":true},"cell_type":"code","source":"grid_hard.fit(df_train_x, df_train_y)\ndf_test_output['Survived'] = grid_hard.predict(df_test_x)\ndf_test_output['Survived'] = df_test_output['Survived'].astype(int)\ndf_test_output.to_csv('model_titanic_procedure.csv', index = False)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4b14534e77456754e6e483f1c26505a07177fef9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}