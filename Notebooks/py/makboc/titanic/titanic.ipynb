{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "25ab80b7-3ec7-0f79-0450-a1c83fff2cb5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "52f5716b-eae8-2c6a-ec60-670f4addb55e"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1341597a-277d-54c8-9422-0bcda7c35af6"
      },
      "outputs": [],
      "source": [
        "import csv as csv\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn import linear_model as lm\n",
        "from sklearn import metrics, ensemble\n",
        "from sklearn.cross_validation import train_test_split\n",
        "from sklearn import decomposition\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "from itertools import combinations\n",
        "pd.options.display.max_columns = 2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "83376fd4-1c10-6253-d367-fe014c2c4516"
      },
      "outputs": [],
      "source": [
        "def update_columns(df, test=False):\n",
        "    if test:\n",
        "        df.columns = [\n",
        "            'passanger_id', 'p_class', 'name', 'sex', 'age', 'sib_sp',\n",
        "            'parch', 'ticket', 'fare', 'cabin', 'embarked'\n",
        "        ]\n",
        "    else:        \n",
        "        df.columns = [\n",
        "            'passanger_id', 'survived', 'p_class', 'name', 'sex', 'age', 'sib_sp',\n",
        "            'parch', 'ticket', 'fare', 'cabin', 'embarked'\n",
        "        ]\n",
        "    \n",
        "def read_train_data():\n",
        "    df = pd.read_csv('../input/train.csv')\n",
        "    update_columns(df)\n",
        "    return df\n",
        "\n",
        "def read_test_data():\n",
        "    df = pd.read_csv('../input/test.csv')\n",
        "    update_columns(df, test=True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bc6bfa92-95c2-2fe9-dc76-50df875e15b8"
      },
      "outputs": [],
      "source": [
        "def enrich_df(df):\n",
        "    df = pd.concat([df, pd.get_dummies(df.p_class, prefix='class')], axis=1)\n",
        "    df['age_2'] = df.age.apply(lambda x: x ** 2).fillna(0)\n",
        "    df['age'] = df.age.fillna(0)\n",
        "    df['has_age'] = (df.age > 0).apply(int)\n",
        "    df = pd.concat([df, pd.get_dummies(df.sex, prefix='sex')], axis=1)\n",
        "    df['siblings_1'] = (df.sib_sp == 1).apply(int)\n",
        "    df['siblings_2'] = (df.sib_sp == 2).apply(int)\n",
        "    df['siblings_3'] = (df.sib_sp == 3).apply(int)\n",
        "    df['siblings_4p'] = (df.sib_sp >= 4).apply(int)\n",
        "    df['parch_1'] = (df.parch == 1).apply(int)\n",
        "    df['parch_2'] = (df.parch == 2).apply(int)\n",
        "    df['parch_3'] = (df.parch == 3).apply(int)\n",
        "    df['parch_4p'] = (df.parch >= 4).apply(int)\n",
        "    df['fare'] = df.fare.fillna(0)\n",
        "    df['log_fare'] = df.fare.apply(lambda x: np.log1p(x))\n",
        "    df['num_cabins'] = df.cabin.apply(lambda x: 0 if x is np.nan else len(x.split(' ')))\n",
        "    df['cabin_group'] = df.cabin.apply(lambda x: 'u' if x is np.nan else x[0].lower())\n",
        "    df = pd.concat([df, pd.get_dummies(df.cabin_group, prefix='cabin_group')], axis=1)\n",
        "    df['embarked'] = df.embarked.fillna('U').apply(lambda x: x.lower())\n",
        "    df = pd.concat([df, pd.get_dummies(df.embarked, prefix='embarked')], axis=1)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fc8a67b7-1f98-73e9-b791-6ab3b96b248a"
      },
      "outputs": [],
      "source": [
        "train = read_train_data()\n",
        "test = read_test_data()\n",
        "\n",
        "train = enrich_df(train)\n",
        "test = enrich_df(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7b072232-be95-3e5d-2da0-f815cdf42826"
      },
      "outputs": [],
      "source": [
        "train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a04658aa-06da-3aae-639c-4ff20ddfbfb7"
      },
      "outputs": [],
      "source": [
        "features = [\n",
        "    'class_1', 'class_2', 'has_age', 'age',\n",
        "    #'age_2', \n",
        "    'sex_male',\n",
        "    'sib_sp',\n",
        "    #'siblings_1', 'siblings_2', 'siblings_3', 'siblings_4p',\n",
        "    'parch', \n",
        "    #'parch_1', 'parch_2', 'parch_3', 'parch_4p',\n",
        "    'log_fare',\n",
        "    'num_cabins',\n",
        "    'cabin_group_b', 'cabin_group_c', 'cabin_group_d', 'cabin_group_e',\n",
        "    'cabin_group_f', 'cabin_group_a',# 'cabin_group_u',\n",
        "    'embarked_q', 'embarked_s'\n",
        "]\n",
        "y = train.survived.values\n",
        "X = train[features]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "X_valid = test[features]\n",
        "\n",
        "X_train = X_train.copy()\n",
        "X_test = X_test.copy()\n",
        "y_train = y_train.copy()\n",
        "y_test = y_test.copy()\n",
        "X_valid = X_valid.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "06e84457-be38-e7ac-241f-8356ebb42664"
      },
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "42e1031c-1eb0-83a6-514e-fbe2919704a1"
      },
      "source": [
        "### Transformation/Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0c2bd269-1488-b43e-1382-347c3d7d781b"
      },
      "outputs": [],
      "source": [
        "X_train.age.apply(lambda x: np.sqrt(x)).plot(kind='hist');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "821091de-9f23-16f1-8de8-bff374812bc8"
      },
      "outputs": [],
      "source": [
        "X_train.age_2.apply(lambda x: np.power(x, 0.3)).plot(kind='hist');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cef9ae1d-bcf2-b268-7d19-21d2310e213f"
      },
      "outputs": [],
      "source": [
        "X_train['age'] = X_train.age.apply(lambda x: np.sqrt(x))\n",
        "X_test['age'] = X_test.age.apply(lambda x: np.sqrt(x))\n",
        "X_valid['age'] = X_valid.age.apply(lambda x: np.sqrt(x))\n",
        "\n",
        "#X_train['age_2'] = X_train.age_2.apply(lambda x: np.power(x, 0.3))\n",
        "#X_test['age_2'] = X_test.age_2.apply(lambda x: np.power(x, 0.3))\n",
        "#X_valid['age_2'] = X_valid.age_2.apply(lambda x: np.power(x, 0.3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "103a9278-b76f-3936-bea2-6f7b5f12065e"
      },
      "outputs": [],
      "source": [
        "age_mean = np.mean(X_train['age'][X_train['age'].gt(0)])\n",
        "age_std = np.std(X_train['age'][X_train['age'].gt(0)])\n",
        "\n",
        "#age_2_mean = np.mean(X_train['age_2'][X_train['age_2'].gt(0)])\n",
        "#age_2_std = np.std(X_train['age_2'][X_train['age_2'].gt(0)])\n",
        "\n",
        "log_fare_mean = np.mean(X_train['log_fare'])\n",
        "log_fare_std = np.std(X_train['log_fare'])\n",
        "\n",
        "print([age_mean, age_std])\n",
        "#print([age_2_mean, age_2_std])\n",
        "print([log_fare_mean, log_fare_std])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e120c83f-2415-c1ea-023c-b7eab7e279eb"
      },
      "outputs": [],
      "source": [
        "X_train['age'] = X_train.age.apply(lambda x: (x - age_mean) / age_std if x > 0 else x)\n",
        "X_test['age'] = X_test.age.apply(lambda x: (x - age_mean) / age_std if x > 0 else x)\n",
        "X_valid['age'] = X_valid.age.apply(lambda x: (x - age_mean) / age_std if x > 0 else x)\n",
        "\n",
        "#X_train['age_2'] = X_train.age_2.apply(lambda x: (x - age_2_mean) / age_2_std if x > 0 else x)\n",
        "#X_test['age_2'] = X_test.age_2.apply(lambda x: (x - age_2_mean) / age_2_std if x > 0 else x)\n",
        "#X_valid['age_2'] = X_valid.age_2.apply(lambda x: (x - age_2_mean) / age_2_std if x > 0 else x)\n",
        "\n",
        "X_train['log_fare'] = X_train.log_fare.apply(lambda x: (x - log_fare_mean) / log_fare_std)\n",
        "X_test['log_fare'] = X_test.log_fare.apply(lambda x: (x - log_fare_mean) / log_fare_std)\n",
        "X_valid['log_fare'] = X_valid.log_fare.apply(lambda x: (x - log_fare_mean) / log_fare_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d9be06f0-59e3-b1ba-52d1-9ac47639c6a9"
      },
      "outputs": [],
      "source": [
        "for var_a, var_b in combinations(X_train.columns, 2):\n",
        "    X_train[var_a + '_' + var_b] = X_train[var_a] * X_train[var_b]\n",
        "    X_test[var_a + '_' + var_b] = X_test[var_a] * X_test[var_b]\n",
        "    X_valid[var_a + '_' + var_b] = X_valid[var_a] * X_valid[var_b]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3f9b5b33-d48f-cef6-1cf2-bb611d958a89"
      },
      "outputs": [],
      "source": [
        "X_train.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3181bb02-84a3-862f-ed28-3a2bf0279629"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f60e7e26-df52-5e5d-b41c-a41b27d2f0c2"
      },
      "outputs": [],
      "source": [
        "lr_model = lm.LogisticRegression()\n",
        "lr_model = lr_model.fit(X=X_train, y=y_train)\n",
        "\n",
        "y_train_hat_lr = lr_model.predict(X_train)\n",
        "y_test_hat_lr = lr_model.predict(X_test)\n",
        "\n",
        "print(metrics.classification_report(y_train, y_train_hat_lr))\n",
        "print(metrics.classification_report(y_test, y_test_hat_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "73b238f7-0c3a-1c5e-0391-1c403e581970"
      },
      "source": [
        "#### Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f4d37f06-9040-6846-8c02-5ba27335932a"
      },
      "outputs": [],
      "source": [
        "gb_model = ensemble.GradientBoostingClassifier()\n",
        "gb_model = gb_model.fit(X=X_train, y=y_train)\n",
        "y_train_hat_gb = gb_model.predict(X_train)\n",
        "y_test_hat_gb = gb_model.predict(X_test)\n",
        "y_valid_hat_gb = gb_model.predict(X_valid)\n",
        "print(metrics.classification_report(y_train, y_train_hat_gb))\n",
        "print(metrics.classification_report(y_test, y_test_hat_gb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2d778f01-dd93-2c41-a9bc-dda5461a51f7"
      },
      "source": [
        "#### RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "319332fe-24f3-d626-3820-dc1e229a1aaa"
      },
      "outputs": [],
      "source": [
        "rf_model = ensemble.RandomForestClassifier()\n",
        "rf_model = rf_model.fit(X=X_train, y=y_train)\n",
        "y_train_hat_rf = rf_model.predict(X_train)\n",
        "y_test_hat_rf = rf_model.predict(X_test)\n",
        "print(metrics.classification_report(y_train, y_train_hat_rf))\n",
        "print(metrics.classification_report(y_test, y_test_hat_rf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ec7b4b4e-11a2-565d-d8ab-b77a81659d3b"
      },
      "source": [
        "#### AdaBoost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e0614cc0-97ac-bd59-95e5-c44952565b45"
      },
      "outputs": [],
      "source": [
        "ab_model = ensemble.AdaBoostClassifier()\n",
        "ab_model = ab_model.fit(X=X_train, y=y_train)\n",
        "y_train_hat_ab = ab_model.predict(X_train)\n",
        "y_test_hat_ab = ab_model.predict(X_test)\n",
        "print(metrics.classification_report(y_train, y_train_hat_ab))\n",
        "print(metrics.classification_report(y_test, y_test_hat_ab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "333caf48-9e04-4bd7-f129-22df7fcf5b20"
      },
      "source": [
        "#### Bagging Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1c8be5aa-a106-363e-b78b-d43d3f2e3987"
      },
      "outputs": [],
      "source": [
        "bc_model = ensemble.BaggingClassifier()\n",
        "bc_model = bc_model.fit(X=X_train, y=y_train)\n",
        "y_train_hat_bc = bc_model.predict(X_train)\n",
        "y_test_hat_bc = bc_model.predict(X_test)\n",
        "print(metrics.classification_report(y_train, y_train_hat_bc))\n",
        "print(metrics.classification_report(y_test, y_test_hat_bc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6b97220a-ae11-c445-1120-0f91653cae1e"
      },
      "source": [
        "#### Extra Trees Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "38b63f41-1e88-1da1-a5f8-fa659a24fa0b"
      },
      "outputs": [],
      "source": [
        "et_model = ensemble.ExtraTreesClassifier()\n",
        "et_model = et_model.fit(X=X_train, y=y_train)\n",
        "y_train_hat_et = et_model.predict(X_train)\n",
        "y_test_hat_et = et_model.predict(X_test)\n",
        "print(metrics.classification_report(y_train, y_train_hat_et))\n",
        "print(metrics.classification_report(y_test, y_test_hat_et))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ede7bea3-449b-6d29-c591-d7b34c72df48"
      },
      "source": [
        "#### MLP Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5db5f441-55a8-d4c7-b32d-f0b3ecbdfbdf"
      },
      "outputs": [],
      "source": [
        "ml_model = MLPClassifier(activation='relu', hidden_layer_sizes=(10),\n",
        "                      batch_size=200, learning_rate='adaptive', max_iter=1000)\n",
        "ml_model = ml_model.fit(X=X_train, y=y_train)\n",
        "y_train_hat_ml = ml_model.predict(X_train)\n",
        "y_test_hat_ml = ml_model.predict(X_test)\n",
        "print(metrics.classification_report(y_train, y_train_hat_ml))\n",
        "print(metrics.classification_report(y_test, y_test_hat_ml))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d978ddf3-32b2-71ed-8728-cc895a1b3797"
      },
      "source": [
        "#### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0ec945dd-9d19-04d2-7224-eaa57c879cd7"
      },
      "outputs": [],
      "source": [
        "sv_model = SVC(probability=True, C=1, gamma=0.1, kernel='rbf')\n",
        "sv_model = sv_model.fit(X=X_train, y=y_train)\n",
        "y_train_hat_sv = sv_model.predict(X_train)\n",
        "y_test_hat_sv = sv_model.predict(X_test)\n",
        "print(metrics.classification_report(y_train, y_train_hat_sv))\n",
        "print(metrics.classification_report(y_test, y_test_hat_sv))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f934297b-c835-5fb3-5217-278af47caaf2"
      },
      "outputs": [],
      "source": [
        "n_folds = 5\n",
        "cv = StratifiedKFold(n_folds)\n",
        "C_range = 10.0 ** np.arange(-4, 4)\n",
        "gamma_range = 10.0 ** np.arange(-4, 4)\n",
        "param_grid = dict(gamma=gamma_range.tolist(), C=C_range.tolist())\n",
        "svr = SVC(kernel='rbf')\n",
        "grid = GridSearchCV(estimator=svr, param_grid=param_grid, \n",
        "                    n_jobs=1, cv=list(cv.split(X_train, y_train)))\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"The best classifier is: \", grid.best_estimator_)\n",
        "#print(grid.grid_scores_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "404185da-8a22-5cde-6fc9-a60a62ea5890"
      },
      "source": [
        "#### Voting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "029454a8-9c16-b982-57f8-8dcba6a7f0ea"
      },
      "outputs": [],
      "source": [
        "vc_model = ensemble.VotingClassifier(estimators=[\n",
        "    ('lr_model', lr_model),\n",
        "    ('gb_model', gb_model),\n",
        "    ('rf_model', rf_model),\n",
        "    ('ab_model', ab_model),\n",
        "    ('bc_model', bc_model),\n",
        "    ('et_model', et_model),\n",
        "    ('ml_model', ml_model),\n",
        "    ('sv_model', sv_model)\n",
        "], voting='soft')\n",
        "vc_model = vc_model.fit(X=X_train, y=y_train)\n",
        "print(metrics.classification_report(y_train, vc_model.predict(X_train)))\n",
        "print(metrics.classification_report(y_test, vc_model.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "338dfbeb-17f1-6cd4-6737-e6896bd553ad"
      },
      "source": [
        "### Errors Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ef170aca-4e44-772d-16e0-7fbefefee0e7"
      },
      "outputs": [],
      "source": [
        "X_temp = X_train.copy()\n",
        "X_temp['y'] = y_train\n",
        "X_temp['y_hat'] = y_train_hat_lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "97605f87-3f92-4a1b-28b1-27296ffbb6a4"
      },
      "outputs": [],
      "source": [
        "X_temp.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0dadc4a1-9f84-04e1-29d4-71434e94e73e"
      },
      "source": [
        "### Submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "67c809e5-9e0b-7be2-204c-59f1c76b760c"
      },
      "outputs": [],
      "source": [
        "model = vc_model\n",
        "\n",
        "passenger_id = test.passanger_id.values\n",
        "survived = model.predict(X_valid)\n",
        "\n",
        "predictions_file = open(\"my_submission.csv\", \"w\")\n",
        "open_file_object = csv.writer(predictions_file)\n",
        "open_file_object.writerow([\"PassengerId\",\"Survived\"])\n",
        "open_file_object.writerows(zip(passenger_id, survived))\n",
        "predictions_file.close()\n",
        "\n",
        "print(check_output([\"ls\"]).decode(\"utf8\"))"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}