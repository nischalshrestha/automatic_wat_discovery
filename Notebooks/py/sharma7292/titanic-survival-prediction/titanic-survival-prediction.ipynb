{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# **Titanic Survival Prediction** #\n\nSiddharth Sharma\n\n***Introduction***\n\nThe premise of the problem is to categorise passengers into 'Survived', and 'Not survived' categories, who were onboard the Titanic before it sank.\nThe Titanic classification problem provides ample opportunity in implementing and learning key aspects of Data cleansing, Feature analysis and Feature engineering.\n\n****The notebook is divided into these 4 key parts:***\n\n1.  Data Loading\n2. Data Visualisation and primary cleansing\n3. Feature Analysis\n4. Feature Engineering\n5. Data Compilation\n5. Modeling\n"},{"metadata":{"_uuid":"54f245e3ee8a648ee902713cefe775a2026fa63e"},"cell_type":"markdown","source":"## 1. Data Loading"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"### Ignore Deprecation and Future Warnings\nimport warnings\nwarnings.filterwarnings('ignore', category = DeprecationWarning) \nwarnings.filterwarnings('ignore', category = FutureWarning) \n\n### Standard Inputs\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set(style='white', context='notebook', palette='deep')\nplt.style.use('bmh')                    # Use bmh's style for plotting\n\nfrom collections import Counter\n\n### Sklearn Imports\n\n# Standards\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.grid_search import GridSearchCV\n\n\n### Load Data\n\ntrain=pd.read_csv('../input/train.csv')\ntest=pd.read_csv('../input/test.csv')\nIDtest = test[\"PassengerId\"]\n\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b3bb2a2427fd81891f08e8baec985b99b8dea12"},"cell_type":"markdown","source":"   ## 2. Data Visualisation and data cleansing"},{"metadata":{"trusted":true,"_uuid":"7191cbeea9b8b92113de0c398e1c0ca7169d7b37","scrolled":false},"cell_type":"code","source":"# Visualising Train and Test data\n\ntrain.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"6ed403b1c2d5a1bbdb8c77a8c546d97655b553ac"},"cell_type":"code","source":"test.head(5) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f7a8bf1f997dd51cd2272a22b11b4fdc63fec46"},"cell_type":"markdown","source":"\n### Preliminary Data Assessment\n\nThe Train dataset has the following data categories:\n\n    1. Numerical Data   : PassengerId,Pclass, Age, SibSp, Parch, Fare\n    2. Categorical Data : Name, Sex, Ticket, Cabin, Embarked\n\nOf the aforementioned data categories in the Train set:\n*         **PassengerId** is a unique ID corresponding to each passenger.\n*         **Survived** is the flag indicating whether the passenger Survived(=1) or died (=0)\n\n\n### Primary Data Cleansing:\n\nThe raw data provided has the following issues which need to be tacked:\n\n    1. Numerical data may have outliers present, these outlier tend to skew the data which is detrimental for the classification algorithms.\n    2. Both numerical and categorical data may have missing or NaN values for certain passengers. These need to be appropriately rectified before using it\n"},{"metadata":{"_uuid":"43e0642fe302c3c038aef5ddffc1a5e9cc3e7573"},"cell_type":"markdown","source":"**Outlier Detection:**\nOutliers in the numerical data is detected using the Inter-quartile Range Method.\n\nThe function reads a dataframe,and returns a list of indices of the dataframe having more\nthan 'n' outliers according to IQR method"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"c331e0043d0617edd67de216fae543a88846df96"},"cell_type":"code","source":"# Outlier Detection (Interquartile Range)\n\ndef IQR_outlier(df,n,features):\n  \n    outlier_indices=[]\n    \n    #Iterating over features(columns)\n    \n    for col in features:\n        Q1=np.percentile(df[col],25)\n        Q3=np.percentile(df[col],75)\n        \n        # Interquartile range\n        IQR=Q3-Q1\n        \n        # outlier step\n        outlier_step=1.5*IQR\n        \n        outlier_list_col=df[(df[col]<Q1-outlier_step)|(df[col]>Q3+outlier_step)].index\n        print('Total Number Outliers of',col,' : ',len(outlier_list_col))\n        print('Percentage of Outliers of',col,' : ',np.round(len(outlier_list_col)/len(df[col])*100),'%')\n        outlier_indices.extend(outlier_list_col)\n        \n    outlier_indices=Counter(outlier_indices)\n    multiple_outliers=list(k for k, v in outlier_indices.items() if v>n)\n    \n    return multiple_outliers\n\nnum_features=['Age','SibSp','Parch','Fare']\n\nOutliers_to_drop=IQR_outlier(train,2,num_features)\n\nprint('Total number of Outlier indices : ', len(Outliers_to_drop))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7109526f94342096763d5b8bc32d41bb411bde75","scrolled":true},"cell_type":"code","source":"train.loc[Outliers_to_drop,num_features]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a54633321e89ec8dde3029db371e7a854c073171"},"cell_type":"markdown","source":"Overall there there 10 passenger data having more than 2 of its feaures as outliers.\nAnother key observation is that Age in the Train dataset has no outlier according to the IQR method.\n"},{"metadata":{"trusted":true,"_uuid":"48fd4bd6eb6d60c8b6a5080e36eed782d41e0a1e"},"cell_type":"code","source":"# Visualing Age, SibSp, Parch and Fare data with and without outliers\n\nnum_features=['Age','SibSp','Parch','Fare']\n\nfor feature in num_features:\n    plt.figure()\n    g=sns.boxplot(x=feature,data=train)\n\nprint('Skewness :')\nprint(train[num_features].skew())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5d81f2cdc0cccb46ce94b434a4678cb6437f2f3"},"cell_type":"markdown","source":"As previously observed the Skewness is the least in Age, and most in Fare.\nA Skewness value between [-0.5 : 0.5] corresponds to the data being normally distributed. \nA value greater than 1 is symptomatic of highly skewed data.\n\nWe'll drop outliers and check how the skewness is affected."},{"metadata":{"trusted":true,"_uuid":"0ba0923a557c22a74cd22bfa8d81b77b5d3e8886"},"cell_type":"code","source":"### Dropping outliers\ntrain_temp=train.copy()\ntrain_temp=train_temp.drop(Outliers_to_drop,axis=0).reset_index(drop=True)\n\nprint('Skewness in Data without outliers :')\nprint(train_temp[num_features].skew())\n\nfor feature in num_features:\n    plt.figure()\n    g=sns.boxplot(x=feature,data=train_temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b73c62d0da843bceeb9c38836370b9985b1b11e"},"cell_type":"code","source":"print('Skewness in Data with outliers :')\nprint(train[num_features].skew())\n\nprint('Skewness in Data without outliers :')\nprint(train_temp[num_features].skew())\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f8aed89bd848b950e4ce617c2dcf08df22bca64"},"cell_type":"markdown","source":"\nUpon dropping the outliers the skewness of SibSp has improved, but is still positively skewed. Moreso, the skewness for Parch and Fare has considerably increased.\n\n**Therefore we won't drop the outliers in the data**."},{"metadata":{"_uuid":"6dc829c458b7fdf1ba3879e09370b8bae14c6c4b"},"cell_type":"markdown","source":"**Null Value Detection**\n\nWe will now identify the various features that have missing or NaN values as entries.\n\nThese need to be logically imputed for both the Train and Test set.\n\nSo we will combine the two sets. There can be a case made for possible data leakage as imputation would be done using data from both the sets. \nBut it would be wiser to use all available data for imputing the data.\nAlso the model will be eventually evaluated with the hold-out set, so it will generalise better. "},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"05572d58c1ffbff8d301c86b365f48eb10dc8a78"},"cell_type":"code","source":"## Joining Train and Test set to get same number of features during categorical conversion\n\ntrain_len = len(train)\ndataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\n \nprint('Dataset shape :',dataset.shape)\n\n# Fill empty and NaNs with NaN        \n\ndataset=dataset.fillna(np.nan)\n\ndataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"59a7055ae782575e7accc64ba05d7d1d9a7508fe"},"cell_type":"markdown","source":"Survived missing values are because of the Test set, where we eventually have to predict the Survived values"},{"metadata":{"trusted":true,"_uuid":"6f7204d667d6b7aece9f13c33e151a8b991319f2"},"cell_type":"code","source":"# Information\n\ntrain.info()\ntrain.dtypes\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"10f5a604806e3e3993310f871926ccc049d381b7"},"cell_type":"code","source":"# Data Summary\n\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d147d86943abb9909ff792a74418a5876f94791"},"cell_type":"markdown","source":"## 3. Feature Analysis\n\nIn this section we will analyse the different numerical and categorical features of the combined dataset.\nThe multiple features would be analysed to gauge their distribution in the dataset, and their correlation with each other as well.\n\nWe will start by calculating the correlation between the numerical variables with respect to each other, and also with our target variable, 'Survived' "},{"metadata":{"trusted":true,"_uuid":"0447d634e50cd385ad1ecdf6c304fabf1050f9af"},"cell_type":"code","source":"### Correlation matrix in numerical values\n\nnum_features.insert(0,'Survived')\ng=sns.heatmap(train[num_features].corr(),annot=True, fmt = \".2f\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb20678dcc54b0af92b8e146787dd88d3d529da0"},"cell_type":"markdown","source":"Key takeaways from the correlation plot:\n\n1.  Of the 4 numerical features, Fare correlates the best with Survived, our Target variable.\n2.  Age has  a strong correlation with SibSp\n            This makes sense because Age would have a role to play with the number of Siblings or the fact that he/she has a spouse.\n3.  SibSp and Parch are also strongly correlated. Also the correlation is positive, which means that both increase and decrease together. "},{"metadata":{"_uuid":"5808d041d65c256ac787bf0331f48ec9b8932afa"},"cell_type":"markdown","source":">  ### **Numerical Features**\n\n#### ** 1.  Age **\n\n    Age is a numerical variable have float type data input. Therefore we would study its distribution in the dataset "},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"5103d29f8ead2725abbe2077423e0f2227b4a0dd"},"cell_type":"code","source":"print('Skew:',train.Age.skew())\ntrain.Age.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65e212680c917f2445f1ac4545ae5a2af4358b25"},"cell_type":"code","source":"# Explore Age vs Survived\n\n# Plotting the distribution of Age amongst passengers who survived and wthose who didn't.\ng = sns.FacetGrid(train, col='Survived')\ng = g.map(sns.distplot, \"Age\")\n\n# Overlapping the two plots\nplt.figure()\ng = sns.kdeplot(train[\"Age\"][(train[\"Survived\"] == 0) & (train[\"Age\"].notnull())], color=\"Red\", shade = True)\ng = sns.kdeplot(train[\"Age\"][(train[\"Survived\"] == 1) & (train[\"Age\"].notnull())], ax =g, color=\"Blue\", shade= True)\ng.set_xlabel(\"Age\")\ng.set_ylabel(\"Frequency\")\ng = g.legend([\"Not Survived\",\"Survived\"])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"450309fd9d25b2e1765f92bc16a824dad0be5109"},"cell_type":"markdown","source":"As we can see from the distribution plot, Age is almost normally distributed in the Train dataset.\nBut the distribution is somewhat different in the two subpopulations.\n\n **Very young passenger** (0-10) seem to have a high probability of survival.\n**Old passengers** (60-80) seem to have lower probability of survival.\n\nTherefore, even though Age doesn't correlate well with Survived, Age categories may. \n"},{"metadata":{"_uuid":"5f8f4fd6370526d7484324a53f731f1631dc404a"},"cell_type":"markdown","source":"#### ** 2.  SibSp ** \n        \n        SibSp would be analysed in terms of its frequency distribution in the Train dataset"},{"metadata":{"trusted":true,"_uuid":"ede98fa9ac20ea10dad4e8bfc048dc2777b4ab08"},"cell_type":"code","source":"# Explore SibSp feature vs Survived\n\ng = sns.catplot(x=\"SibSp\",y=\"Survived\",data=train,kind=\"bar\", height = 6 , palette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e35a9cb061e0a9dccffb23f04b74072a2fef46ca"},"cell_type":"markdown","source":"Passengers having low SibSp( 1 or 2)  values have a higher chance of surviving as compared to those without siblings/spouses (SibSp=0) and those having many siblings (SibSp>=3)"},{"metadata":{"_uuid":"00cdc434918ced50dde37c47e345e37db5b41e36"},"cell_type":"markdown","source":"#### ** 3. Parch ** \n        \n       Parch would be analysed in terms of its frequency distribution in the Train dataset"},{"metadata":{"trusted":true,"_uuid":"f24fdf3bad8740b2374664bd0b9830103c8e491b"},"cell_type":"code","source":"# Explore Parch feature vs Survived\ng=sns.catplot(x='Parch',y='Survived',data=train,kind='bar',height=6,palette='muted')\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10507f848df4b6b30f9eb66ca406e1224bf148b4"},"cell_type":"markdown","source":"Different family sizes have varying survival probablilities.\nSmall families(Parch = 1,2) have higher survival probabilities than Single (Parch= 0), Medium(Parch= 3,4), and Large(Parch= 5,6) families.\n\nThe std deviation for Parch=3 is pretty high. \nThis was previously observed when we were identifying outliers in the data (24% of the Parch data in the Train dataset was identified as outlier)"},{"metadata":{"_uuid":"370a3cb7ffd7e2d706968be3dfc276257eb513db"},"cell_type":"markdown","source":"#### ** 4. Fare** \n        \n       Fare is a numerical variable have float type data input. Therefore we would study its distribution in the dataset "},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"a8eea155cd5d15d63918bd9c9fd0c5596deefb7d"},"cell_type":"code","source":"dataset[\"Fare\"].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2693aeca38ed508254c0fdb23a33108e714b27a"},"cell_type":"code","source":"# Imputing the 1 missing value with median value of the combined dataset\ndataset[\"Fare\"]=dataset[\"Fare\"].fillna(dataset[\"Fare\"].median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ea7607d39e814b334316c00bef4c9488efe1e91"},"cell_type":"code","source":"# Explore Fare distribution\ng=sns.distplot(dataset['Fare'],label='Skewness: %2f'%(dataset['Fare'].skew()))\ng.legend(loc='best')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"404e2993c74693d21ccaf1ac3d76b313cfbf840e"},"cell_type":"markdown","source":"The data is highly skewed towards the left. This will affect the overall distribution if fed like this in the classification models.\nWe would thus take the natural log of the data, thereby reducing the skewness. "},{"metadata":{"trusted":true,"_uuid":"b1f70abdbd057bc0b7e30908d7e2ae9115e8756d"},"cell_type":"code","source":"dataset[\"Fare\"] = dataset[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7c52d2e1979354f0639914cd901cf09cbcba446"},"cell_type":"code","source":"g=sns.distplot(dataset['Fare'],label='Skewness: %2f'%(dataset['Fare'].skew()))\ng.legend(loc='best')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e55fa05557d4928d7b0d69afd221d6b8f3a0820c"},"cell_type":"markdown","source":"The data seems normally distributed now. This can now be used for further analysis"},{"metadata":{"_uuid":"310cf8c3b15170ce8d8b76d272e4cf3729d84f94"},"cell_type":"markdown","source":">  ### **Categorical Features**\n\n\n#### **5. Sex**"},{"metadata":{"trusted":true,"_uuid":"ccb72a67e8f5b961c37ad29fbfc92be1732f6904"},"cell_type":"code","source":"### Sex\n\ng=sns.catplot(x='Sex',y='Survived',data=train,kind='bar')\ntrain[['Sex','Survived']].groupby('Sex').mean()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c86e7c3346192ac08c7892c79ac687d1651a388"},"cell_type":"markdown","source":"The probability of survival is a lot higher for Females than Males."},{"metadata":{"trusted":true,"_uuid":"a5f6e280a44c97de0dc2e225f9ff8cddf8f52921"},"cell_type":"code","source":"# Converting sex to categorical values 0: male, 1:female\n\ndataset['Sex']=dataset['Sex'].map({'male':0,'female':1})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a6a0b8f1b4f757906233d1553f0327acf9ae341"},"cell_type":"markdown","source":"#### **6. Pclass**"},{"metadata":{"trusted":true,"_uuid":"bc3ad9bcf4e78648033e0ea45160af94b7c93333"},"cell_type":"code","source":"### Pclass\n\ng=sns.catplot('Pclass','Survived',hue='Sex',data=train,kind='bar')\ng=sns.catplot('Pclass','Survived',data=train,kind='bar')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b64739b798f25c82622759fb05acd9f8630edc3"},"cell_type":"markdown","source":"The probability of survival is highest for the members of the Pclass 1, followed by Pclass 2. This confirms the fact that the evacuation was prioritised with respect to class.\nAlso,  it can be observed that more women survived than men in all classes."},{"metadata":{"_uuid":"cf02995dd1fbf44b9beeef91744680b31c967301"},"cell_type":"markdown","source":"#### **7. Embarked**"},{"metadata":{"trusted":true,"_uuid":"a741a6e38ed0fd6f51c986ec5f22b6551ae0df48"},"cell_type":"code","source":"print('Number of Null entries: ',dataset['Embarked'].isnull().sum())\nprint('Most common dock: ',dataset.Embarked.mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60445afcee6a54d2af02337f5e29f1b746394ffc","scrolled":true},"cell_type":"code","source":"# Filling Embarked with most common dock \n\ndataset['Embarked']=dataset['Embarked'].fillna('S')\n\n# Exploring Embarked\n\ng=sns.catplot(x='Embarked',y='Survived',data=train,kind='bar')\n\n# Exploring embarked with Pclass\n\ng=sns.catplot(x='Embarked',y='Survived',hue='Pclass',data=train,kind='bar')\ng=sns.catplot(x='Pclass',col='Embarked',data=train,kind='count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e9ac5ae799715f33713d306cac1ee404d632101"},"cell_type":"markdown","source":"* Of the three ports,  C has the highest survival rate, followed by S.\n* From the count plot, it can be further deduced that most of the passengers boarding from C were in 1st class. \n* Maximum number of passengers boarded from S\n* Most of passengers from S, and Q were from the 3rd class."},{"metadata":{"_uuid":"eca6a15e8c1ec96adf769857838a4ee54528042f"},"cell_type":"markdown","source":"#### **7. Name**"},{"metadata":{"trusted":true,"_uuid":"82ff82f27edd6806ffa90c72e80663d5ae0e4414"},"cell_type":"code","source":"dataset.Name.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c52a795383270517aaa67a3696ebd82e0777298"},"cell_type":"markdown","source":"The variable Name on it's own may not be a useful addition for our classification problem. We would try and learn Titles of the passengers aboard. (We will do this in the Feature Engineering section)"},{"metadata":{"_uuid":"2b6932080e2d673241cae4c05a17c2d73fb12ced"},"cell_type":"markdown","source":"#### **8. Cabin**"},{"metadata":{"trusted":true,"_uuid":"00de2b7bb57f7700c113c1f43effe62d55818fc0"},"cell_type":"code","source":"# Visualising Cabin data\ndataset.Cabin.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2bea4591a22ba1d855f8b34c30c59741107a0ea"},"cell_type":"code","source":"display(dataset.Cabin.shape)\nprint('Number of null values : ', dataset.Cabin.isnull().sum())\nprint('Percentage of null values : ', round(dataset.Cabin.isnull().sum()/dataset.Cabin.shape[0]*100),'%')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae99a88095f9c5785ed2860377f965fd6dbc9666"},"cell_type":"markdown","source":"A major chunk of Cabin values are missing in the combined dataset.\nWe would thus impute the missing data in the Feature engineering section."},{"metadata":{"_uuid":"9965d9ad22bb9f640d95123ab6e3868d6bd45f04"},"cell_type":"markdown","source":"#### **9. Ticket**"},{"metadata":{"trusted":true,"_uuid":"b41bbae8d2b7083893d702edc59981b4b9beef8a"},"cell_type":"code","source":"dataset.Ticket.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e10f0d5cb554e4f7e5a1b1dde659d79138bfbfb8"},"cell_type":"markdown","source":"There are Ticket entries having Prefixes that may be of significance, as it may indicate the level of the ship. Different class tickets would also have different prefixes. Therefore a lot can be learned from the Tickets as well."},{"metadata":{"_uuid":"e83821fa84b7d23cc44d68a469e5f6686f1fe94f"},"cell_type":"markdown","source":"## 3. Feature Engineering\n\nNow that we have analysed the various features, there are a few modifications that we need to make to the existng dataset before it becomes usable for model training and evaluation.\n\nKey aspects of Feature engineering are:\n1.  Data imputation\n2. Modifying existing features\n3. Identifying new features"},{"metadata":{"_uuid":"71201e7502c00dadb757ed280ec33f6ea47b10fa"},"cell_type":"markdown","source":"### Data Imputation"},{"metadata":{"trusted":true,"_uuid":"6f5921e27da24ee4e15ebda6194cd17e00a0ce73"},"cell_type":"code","source":"# Identifying missing values in the dataset\n\ndataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88415d729607214ddc11d791676e8fae9b7d75d9"},"cell_type":"markdown","source":"#### 1. Age\n\nThere are 263 missing values in the Age category.\nWe will identify the different features that may be correlated with Age and use them while imputing missing data"},{"metadata":{"trusted":true,"_uuid":"b863e2106347a0f3d5bc9be5040e7c4067d094c3"},"cell_type":"code","source":"# Features most correlated with age\ng=sns.heatmap(dataset[['Age','Fare','Parch','Pclass','Sex','SibSp']].corr(),annot=True,fmt='.2f')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b2d6a93df72a2400eed64025a29e8755986cd844"},"cell_type":"markdown","source":"* Of the 4 aforementioned features, Sex is the least correlated with Age.  \n* Pclass is the most,  with a value of -0.41. This means that the Age and Pclass are inversely related. A lower Pclass in value(1,2, or 3) has passengers which are older.\n* A similar negative correlation is there with SibSp, and Parch as well. More the number of siblings or children a passenger has, his/her age would be relatively less.\n* Age and Fare have a positive correlation. This means that Older passengers are more likely to pay higher than younger ones. This may well be because Fare and Pclass are highly correlated (-0.69), and since class 1 passengers are more likely to be older, they would be paying a higher fare than the younger ones.\n\n\nWe will further look at factor plots comparing Age with SibSp, Sex, Parch, Pclass,"},{"metadata":{"trusted":true,"_uuid":"457894d0a23eede85970080831104bd548119a75","scrolled":false},"cell_type":"code","source":"g=sns.catplot(y='Age',x='SibSp',data=dataset,kind='box')\n\ng=sns.catplot(y='Age',x='Sex',data=dataset,kind='box')\ng=sns.catplot(y='Age',x='Sex',hue='Pclass',data=dataset,kind='box')\n\ng=sns.catplot(y='Age',x='Parch',data=dataset,kind='box')\n\ng=sns.catplot(y='Age',x='Pclass',data=dataset,kind='box')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2be8b04f067bad8b56fd734036ec92a6ea84a9e1"},"cell_type":"markdown","source":"* Age vs SibSp :  An increase in the number of simblings indicates a passenger who's relatively young. Matches with the previous correlation matrix\n* Age vs Sex :  The distribution is fairly similar for the two sexes.  Sex is thus not a good indicator of Age. Also, the higher class passengers are older than lower class passengers for both sex sub populations.\n* Age vs Parch : It indicates a trend slightly different that what was inferred from the correlation matrix. More the number of childer, older is the person expected to be.\n* Age vs Pclass :  As previously observed, The Class 1 passengers are older than Class 2 , and Class 2 are older than Class 3.\n"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"7921ddfa76fee1d0149b84fd4e83fc95f2513608"},"cell_type":"code","source":"plt.figure()\ng=sns.lineplot(x='Pclass',y='Fare',data=dataset)\nplt.figure()\ng=sns.lineplot(x='Age',y='Fare',data=dataset)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c9254ebbfbc6b130525f987fdcb06d47f756519"},"cell_type":"markdown","source":"Fare seems fairly monotonic with Pclass. We can this simply use Pclass for Age imputation.\n\n\n\nOf the above mentioned features we would use **Parch, SibSb, Pclass** for filling missing Age values.\n\n***Imputation methodology :***\n\nWe would identify Age rows having similar Parch, Pclass, and SibSp values to that of the passenger not having an Age value, and use their median Age value for imputation. In a condition where no other passenger has the same value of Parch, Pclass and SibSp, we would impute the missing Age with the global median."},{"metadata":{"trusted":true,"_uuid":"02f0d969b184843512b1c023bdf4e2beba6f922a"},"cell_type":"code","source":"## Fill Age with the median age of similar rows according to Pclass, Parch and SibSp\n\n# Index of NaN age rows\nindex_NaN_age = dataset[\"Age\"][dataset.Age.isnull()].index\n\nfor i in index_NaN_age :\n    age_med = dataset[\"Age\"].median()\n    age_pred = dataset[\"Age\"][((dataset['SibSp'] == dataset['SibSp'][i]) & (dataset['Parch'] == dataset['Parch'][i]) & (dataset['Pclass'] == dataset['Pclass'][i]))].median()\n    if not np.isnan(age_pred) :\n        dataset['Age'].iloc[i] = age_pred\n    else :\n        dataset['Age'].iloc[i] = age_med\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"52a944f27ee0af05ccd40e32d704a158a58e276f"},"cell_type":"code","source":"dataset.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b91aa06efb609ef68813cacfba488ff5d37b3b1"},"cell_type":"markdown","source":"Now only Cabin has missing values, these will be imputed as we further modify the existing dataset."},{"metadata":{"_uuid":"04fb266bdccebad9743b13a3c4514b4604c47480"},"cell_type":"markdown","source":"### 2. Modifying existing features\n\n\n\n"},{"metadata":{"_uuid":"b29d21ca679150a4312b967d3ff389f4674ba58e"},"cell_type":"markdown","source":"#### 1. Cabin"},{"metadata":{"trusted":true,"_uuid":"40adc75d4533a278f24f138e6796e2c485684b32"},"cell_type":"code","source":"dataset.Cabin[dataset.Cabin.notna()].head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d9304e61c0b2448396a1513ba0cd5754e30dab4"},"cell_type":"markdown","source":"The first letter of the Cabin indicates the level at which it is situated. During the time of evacuation, it is highly likely that the Cabin value may have a bearing on the probability of survival."},{"metadata":{"trusted":true,"_uuid":"2d31db25f5712d5480188ae70bc76e056f7c734c"},"cell_type":"code","source":"## Replacing each Cabin entry with the first letter, and replacing the missing cabin entries with 'X'\n\ndataset.Cabin=pd.Series(['X' if pd.isnull(i) else i[0] for i in dataset.Cabin])                        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d9b6824ffbb1b9925301c8463a4a7ccc20b4561"},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c1e4f8c6f35749c48d8e18825a6fa48308911db"},"cell_type":"code","source":"print('Mean : ', dataset[['Cabin','Survived']].groupby('Cabin').mean())\nprint('Count : ', dataset[['Cabin','Survived']].groupby('Cabin').count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f258a6793c6816238b5c9548159e14bcac80b76"},"cell_type":"code","source":"g=sns.catplot(x='Cabin',y='Survived',data=dataset,kind='bar', order=['A','B','C','D','E','F','G','T','X']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba65c6a7edeea12003772614313b1c116fb1d381"},"cell_type":"markdown","source":"As it can be seen from the count values, most of the Cabin entries were missing. \nAlso due to very less number of entries in the  known Cabins (A to T), the distribution has high variance.\n\nOne key inference that can be drawn, is that the Survival probability is a lot lower for passengers who have their cabin entries missing."},{"metadata":{"trusted":true,"_uuid":"39d40a446e113caad21c937736d5e27156e09592"},"cell_type":"markdown","source":"#### 2. Name\n\nAs discussed previously, Titles can be extracted from the Name of the passengers, these may hold useful information regarding the survival probability of the passenger"},{"metadata":{"trusted":true,"_uuid":"d563cfd7eceab65fff27679cb5965b505d85c6cf","scrolled":true},"cell_type":"code","source":"dataset.Name.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b9d958537f916d9e0a7540ccce404d965ecadea"},"cell_type":"code","source":"# The title is mentioned as the 2 word in the string\n\ndataset['Title']=pd.Series([i.split(',')[1].split('.')[0].strip() for i in dataset.Name])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2b766b6ab79e7f65c16ff4033351ac27725b7d3"},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e46d6089fd3c9425bc3285760938bb3154c00b50"},"cell_type":"code","source":"g=sns.countplot(x='Title',data=dataset)\ng = plt.setp(g.get_xticklabels(), rotation=45)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"640e30ce8ba7e786bacc6573549a3bddeb9fe174"},"cell_type":"markdown","source":"There are several titles with the very least frequency. So, it makes sense to put them in fewer buckets. We would replace Mlle and Ms with Miss and Mme by Mrs as these are French titles. Also we will club all the other titles under 'Rare'.\n\n\n**We will create categories from these titles:**\n\n    0: Master\n    1: Miss(Miss, Ms, Mlle)\n    2: Mrs(Mrs,Mme)\n    3: Mr\n    4: Rare (Dr, Rev, Col, Major, Capt,Dona, Jonkheer, Countess, Sir, Lady, Don)\n\n"},{"metadata":{"trusted":true,"_uuid":"dfaa26856eb175d6e9ee532234c70f9ea65dbc8e"},"cell_type":"code","source":"# Convert to categorical values Title \ndataset[\"Title\"] = dataset[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ndataset[\"Title\"] = dataset[\"Title\"].replace(['Ms', 'Mlle'], 'Miss')\ndataset[\"Title\"] = dataset[\"Title\"].replace(['Mme'], 'Mrs')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74f3a459f58b0bb5e235dc1ef23ac8fb09b6c8ff"},"cell_type":"code","source":"dataset[['Name','Title']].head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"859ae75fa58ccaa37c639734fbbef9c13c432d15"},"cell_type":"markdown","source":"#### 3. Ticket\n\nAs discussed previously, there are Ticket entries having Prefixes that may be of significance, as it may indicate the level of the ship. "},{"metadata":{"trusted":true,"_uuid":"2e18b7461016e92ef7cf78b039c879b3c799a3c6"},"cell_type":"code","source":"dataset['Ticket'].head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c807f9b2cabf7937cc419bebc0c54b00567b703"},"cell_type":"markdown","source":"Some Ticket entries have just numerical data, while some have alphanumeric prefixes.\nwe would try and club ticket entries ahving the same prefixes together, also all entries having no prefixes would be clubbed separately."},{"metadata":{"trusted":true,"_uuid":"bb4a566e73c4f844032c74bae2cd0f6aed87fe2f"},"cell_type":"code","source":"## Treat Ticket by extracting the ticket prefix. When there is no prefix it returns X.\n\nTicket=[]\nfor i in list(dataset['Ticket']):\n    if i.isdigit():\n        Ticket.append('X')\n        \n    else:\n        Ticket.append(i.split(' ')[0])\n\ndataset['Ticket']=Ticket","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eecdf3038819763fd5a8bfd0127016b122edb4f8"},"cell_type":"code","source":"dataset.Ticket.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbe273ebacd3ba1a6a862fb99d0138d547653973"},"cell_type":"code","source":"dataset.Ticket.unique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b9dfd2db552b5dd806314cf7738ea266317e3a9"},"cell_type":"markdown","source":"It can be observed that a lot of prefixes have character values( \" / \"  ,  '\" . \"  ) \nWe would try and remove these characters, and use only the reduced alphanumeric prefixes as categories.\n"},{"metadata":{"trusted":true,"_uuid":"8233a23af8389fe40007f7236f49749c7fb6c981"},"cell_type":"code","source":"Ticket = []\nfor i in list(dataset.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"/\",\"\").strip()) #Take prefix\n    else:\n        Ticket.append(i)\n\ndataset['Ticket']=Ticket","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"caacd6ce36e580206698d7b1b731630d3521f688"},"cell_type":"code","source":"dataset.Ticket.unique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f145a4ee417690c3998ca0ebdfe7ee3c8fa7b5b"},"cell_type":"markdown","source":"### 3. Identifying new features"},{"metadata":{"_uuid":"ffdb798b6a836e302ecbfae03a2095690bba1ea2"},"cell_type":"markdown","source":"#### 1. Family size\n\nThe size of the family may be an important factor since a larger family size would make it difficult during evacuation. \nFamily size will be calculated using SibSp and Parch"},{"metadata":{"trusted":true,"_uuid":"6d3a1adff2e0900477aee6d59eb0296dd1c9dbb7"},"cell_type":"code","source":"# Create a family size descriptor from SibSp and Parch\n\ndataset[\"Fsize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1\n\ng = sns.factorplot(x=\"Fsize\",y=\"Survived\",data = dataset)\ng = g.set_ylabels(\"Survival Probability\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c968d4dc89d86cccd1da2c4a9ac3421bfdcf5a6d"},"cell_type":"markdown","source":"It can be infered from the above plot that a small to medium family (2-4) has a higher survival probability than individuals ( Fsize=1) and large families (5 and above) \n\nWe would further convert Fsize into categorical bins"},{"metadata":{"trusted":true,"_uuid":"96077d93f12fcdff1615f26aa8f85533a8ace1da"},"cell_type":"code","source":"dataset[\"Fsize\"].replace(to_replace = [1], value = 'Single', inplace = True)\ndataset[\"Fsize\"].replace(to_replace = [2], value = 'Small', inplace = True)\ndataset[\"Fsize\"].replace(to_replace = [3,4], value = 'Medium', inplace = True)\ndataset[\"Fsize\"].replace(to_replace = [5,6,7,8,11], value = 'Large', inplace = True)\n\ng=sns.catplot(x='Fsize',y='Survived',data=dataset,kind='bar',order=['Single','Small','Medium','Large'] ) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2e7b4b5e79ed58a44d05bd29f34107cdd9eb0ee"},"cell_type":"markdown","source":"Small and Medium size families have the highest survival probability, followed by Single. Large families have the poorest survival probability. \nThis may be because of difficulty arising in evacuating large families."},{"metadata":{"_uuid":"7a901d5484adb311327d6c54fc6ca6757e61b0a4"},"cell_type":"markdown","source":"## 4. Data Compilation"},{"metadata":{"_uuid":"cdb564da7623d479d74ce73c852a20983e29f8bd"},"cell_type":"markdown","source":"We would now compile all the features necessary for Survival prediction in the test set.\nSubsequently we will remove the unnecessary ones.\n"},{"metadata":{"trusted":true,"_uuid":"f641f183d245c2ed94ffa531ed2a594870f93b70"},"cell_type":"code","source":"dataset.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a492260200d6e084452b22594e9cd9f96f282d4"},"cell_type":"code","source":"# Converting categorical data to usable form\n\ndataset = pd.get_dummies(dataset, columns = [\"Cabin\"], prefix=\"Cab\")\ndataset = pd.get_dummies(dataset, columns = [\"Embarked\"], prefix=\"Em\")\ndataset = pd.get_dummies(dataset, columns = [\"Fsize\"], prefix=\"Fam\") \ndataset = pd.get_dummies(dataset, columns = [\"Pclass\"], prefix=\"Pc\")\ndataset = pd.get_dummies(dataset, columns = [\"Title\"], prefix=\"Title\") \ndataset = pd.get_dummies(dataset, columns = [\"Ticket\"], prefix=\"Tick\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b43926e3a8c3575e9d82689b9a9d768deb288d44"},"cell_type":"code","source":"# Dropping the unnecessary variables\n# labels : Name, Passenger Id\ndataset.drop(labels = ['Name','PassengerId'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9648e7031237d6e2a49b9c93c7e4525a2d0f52a8"},"cell_type":"code","source":"dataset.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53d0944ebb24c3c905c0a7c21577581b888d9527"},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcd42c09425fe0d49e0171b63f654746f3eac401"},"cell_type":"code","source":"from sklearn.decomposition import PCA\ndataset1=dataset.copy()\n\ndataset1.drop(labels='Survived',axis=1,inplace=True)\npca=PCA(0.999,whiten=True).fit(dataset1)\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\ndata=pca.transform(dataset1)\n\ndata.shape\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5cc6581e87581c688e2787876f63e788417eb0a"},"cell_type":"markdown","source":"#### The data can now be used to train and test classification models"},{"metadata":{"_uuid":"5a429e89320b72b5c21ca228198e329704cae54c"},"cell_type":"markdown","source":"## 5. Modeling"},{"metadata":{"trusted":true,"_uuid":"f8613afab64dd966a1e2980aa0a4cc3b64229a5c"},"cell_type":"code","source":"#train=dataset[:train_len]\n#test=dataset[train_len:]\n\n#test.drop(labels='Survived',axis=1,inplace=True)\n\n#train['Survived']=train['Survived'].astype(int)\n\n#Y_train=train['Survived']\n\n#X_train=train.drop(labels='Survived',axis=1)\n\nY_train=dataset[:train_len]['Survived']\nX_train=data[:train_len]\ntest=data[train_len:]\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0aa2246972b83aa90f9e5aa638196d7ed3eb93c"},"cell_type":"code","source":"#train=dataset[:train_len]\n#test=dataset[train_len:]\n\n#test.drop(labels='Survived',axis=1,inplace=True)\n\n#train['Survived']=train['Survived'].astype(int)\n\n#Y_train=train['Survived']\n\n#X_train=train.drop(labels='Survived',axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae76a49aa83370a6c7e88ae5b455d7821e3b9275"},"cell_type":"code","source":"#X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93cd450a3ce89a2e75cdf91917ff2b76fb04583a"},"cell_type":"code","source":"#Y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db0d6a6d3e5c7a89eb60483d5aaf6eedc6f570cf"},"cell_type":"markdown","source":"### 1. Simple Modeling\n\n\nComparing 5 popular classifiers and evaluate the mean accuracy of each of them by a stratified kfold cross validation procedure.\n* SVC\n* Decision Tree\n* Random Forest\n* KNN\n* Logistic regression\n"},{"metadata":{"trusted":true,"_uuid":"80aa871abeeb924547fdcafa2f6b71a40b51b224"},"cell_type":"code","source":"### Model Imports\n\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d97f2b7ba86f895acadfb5f7c42b4bbee5c544fa"},"cell_type":"code","source":"# Cross validate model with Kfold stratified cross val\nkfold = StratifiedKFold(n_splits=10) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f715130c7caa7b4c1a58afd004202b2c9e39dd8"},"cell_type":"code","source":"# Modeling step to test differents algorithms \n\nrandom_state = 42\nclassifiers = []\nclassifiers.append(SVC(random_state=random_state))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LogisticRegression(random_state = random_state))\n\ncv_results = [] \nfor classifier in classifiers :\n    cv_results.append(cross_val_score(classifier, X_train, y = Y_train, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n\ncv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n\ncv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"RandomForest\",\"KNeighbours\",\"LogisticRegression\"]})\n\ng = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9eb00fffb74df62ff7b6ad757443d2684a5c556b"},"cell_type":"code","source":"cv_res.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa2a9be904a5da4aeaa405fcfa95810223108b1d"},"cell_type":"markdown","source":"Of the 5 classifiers, SVC, Random Forest and Logistic Regression have the best cross validation performance.\n\nWe would now try and tune the hyper parameters for the above classifiers, so as to maximise their accuracy."},{"metadata":{"_uuid":"1bfee5a3a4c4db2962b0b3362d7f2672a219d1da"},"cell_type":"markdown","source":"### 2. Hyperparameter tuning\n\nWe would use Grid Search Cross validation approach to fine tune the parameters fro different classifiers "},{"metadata":{"_uuid":"57add3043b2570d268bdb68d3e21a75206e940b0"},"cell_type":"markdown","source":"#### 1. SVC Classifier"},{"metadata":{"trusted":true,"_uuid":"36c18db3b912ed94328574172e1eeb3e41e38ab4"},"cell_type":"code","source":"SVMC = SVC(probability=True)\n\nsvc_param_grid = {'kernel': ['rbf'], 'gamma': [ 0.001, 0.01, 0.1, 1],'C': [1, 10, 50, 100,200,300, 1000]}\n\ngsSVMC = GridSearchCV(SVMC,param_grid = svc_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsSVMC.fit(X_train,Y_train)\n\nSVMC_best = gsSVMC.best_estimator_\n\n# Best score\ngsSVMC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a038695ade32efaf3659b18af29b170b5221c2be"},"cell_type":"markdown","source":"#### 2. Decision Tree Classifier"},{"metadata":{"trusted":true,"_uuid":"024f548d6d789458f9016dcc619dd9c9d10b6e30"},"cell_type":"code","source":"DTC = DecisionTreeClassifier()\n\ndt_param_grid = {'max_features': ['auto', 'sqrt', 'log2'],'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], \n                 'min_samples_leaf':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],'random_state':[42]}\n\ngsDTC = GridSearchCV(DTC,param_grid = dt_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsDTC.fit(X_train,Y_train)\n\nDTC_best = gsDTC.best_estimator_\n\n# Best score\ngsDTC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8124eed8347064322bee92aad495026436ae6578"},"cell_type":"markdown","source":"#### 3. Random Forest Classifier"},{"metadata":{"trusted":true,"_uuid":"e42e06fa13c6dd26df8786a9846e11f5fec67e4d"},"cell_type":"code","source":"RFC = RandomForestClassifier()\n\nrf_param_grid = {\"max_depth\": [None],\"max_features\": [1, 3, 10],\"min_samples_split\": [2, 3, 10],\"min_samples_leaf\": [1, 3, 10],\n                 \"bootstrap\": [False],\"n_estimators\" :[100,300],\"criterion\": [\"gini\"]}\n\n\ngsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsRFC.fit(X_train,Y_train)\n\nRFC_best = gsRFC.best_estimator_\n\n# Best score\ngsRFC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e1c0b972ac495a0246e99b8bc95b678b4ec02d37"},"cell_type":"markdown","source":"#### 4. Logistic Regression Classifier"},{"metadata":{"trusted":true,"_uuid":"d16f87666e5c253117f83e41d16d8cfe0eb7e122"},"cell_type":"code","source":"LRC = LogisticRegression() \n\nlr_param_grid = {'penalty':['l1', 'l2'],'C': np.logspace(0, 4, 10)}\n\ngsLRC=GridSearchCV(LRC,param_grid=lr_param_grid,cv=kfold,scoring='accuracy', n_jobs= 4, verbose = 1)\n\ngsLRC.fit(X_train,Y_train)\n\nLRC_best = gsLRC.best_estimator_\n\n# Best score\ngsLRC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85e482bf28fddb91981caeb5b169659869ac7413"},"cell_type":"markdown","source":"#### 5. KNN Classifier"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"20eb29c26a6a5bbac49fe5bd13c671293d48d6ac"},"cell_type":"code","source":"KNNC = KNeighborsClassifier()\nknn_param_grid = {'n_neighbors':[3, 4, 5, 6, 7, 8],'leaf_size':[1, 2, 3, 5],\n              'weights':['uniform', 'distance'],'algorithm':['auto', 'ball_tree','kd_tree','brute']}\n\ngsKNNC=GridSearchCV(KNNC,param_grid=knn_param_grid,cv=kfold,scoring='accuracy',n_jobs=4,verbose=1)\n\ngsKNNC.fit(X_train,Y_train)\n\nKNN_best=gsKNNC.best_estimator_\n\n# Best score\ngsKNNC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb9c1e981e47c1ae34aff4742e0e19147e9a0a40"},"cell_type":"markdown","source":"After hyper parameter tuning, SVC is the best performing classifier, followed by RF and LR. \nKNN is still the least accurate of the 5."},{"metadata":{"_uuid":"1845a2d627e0e934630f0f3850d3c9aa453ffd22"},"cell_type":"markdown","source":"###  3. Plot learning curves\n\nLearning curves are a good way to see the overfitting effect on the training set and the effect of the training size on the accuracy."},{"metadata":{"trusted":true,"_uuid":"bbf6bf88805ee4045c051dfcadd2fe62cd730f49"},"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"Generate a simple plot of the test and training learning curve\"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    \n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt\n\ng = plot_learning_curve(gsSVMC.best_estimator_,\"SVC learning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsDTC.best_estimator_,\"DT learning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsRFC.best_estimator_,\"RF learning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsLRC.best_estimator_,\"LR learning curves\",X_train,Y_train,cv=kfold)\ng = plot_learning_curve(gsKNNC.best_estimator_,\"KNN learning curves\",X_train,Y_train,cv=kfold)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06b0b825c29ef6f5852cdd62e7fd5f7fff28edc0"},"cell_type":"markdown","source":"Decision Tree and KNN tend to overfit the training set. Their performance can be improved with increasing the training set size\nSVC and LR are better generalised and have their Training score and CV score converging to the same value"},{"metadata":{"_uuid":"be30d68ec871525b853d7d086f72590df890722b"},"cell_type":"markdown","source":"### 4. Feature importance of tree based classifiers\n\nIn order to see the most informative features for the prediction of passengers survival, the feature importance for the 2 tree based classifiers is displayed."},{"metadata":{"trusted":true,"_uuid":"a8dbfdbb9ff6cb99f0b8585f088bc0475c16c15b","scrolled":true},"cell_type":"code","source":"'''\nnames_classifiers = [(\"RandomForest\",RFC_best),(\"Desicion Tree\",DTC_best)]\n\nfor nclassifier in range(2):\n    name = names_classifiers[nclassifier][0]\n    classifier = names_classifiers[nclassifier][1] \n    indices = np.argsort(classifier.feature_importances_)[::-1][:40]\n    plt.figure(figsize=(8,8))\n    g = sns.barplot(y=X_train.columns[indices][:40],x = classifier.feature_importances_[indices][:40] , orient='h')\n    g.set_xlabel(\"Relative importance\",fontsize=12)\n    g.set_ylabel(\"Features\",fontsize=12)\n    g.tick_params(labelsize=9)\n    g.set_title(name + \" : feature importance\")\n'''    \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e41c37d1c73952ba91eb123ddf74123ed79a83a9"},"cell_type":"markdown","source":"We note that the two classifiers have different top features according to the relative importance. \n\nIt means that their predictions are not based on the same features. Nevertheless, they share some common important features for the classification , for example 'Fare', 'Title_Mr', 'Title_Mr's' and 'Age'.\n\n**According to the feature importance of this 2 classifiers, the prediction of the survival seems to be more associated with the Age, the Sex, the family size and the social standing of the passengers than the location in the boat.**"},{"metadata":{"_uuid":"d02a6df8d81ceb99ab6a1c84c4440d9fd07bc1b1"},"cell_type":"markdown","source":"### 5. Test Data prediction\n\n\nWe would now predict the survival probability of the passengers in the Test dataset.\n \n We would drop KNN as its performance has been the least accurate of the 5 classifiers."},{"metadata":{"trusted":true,"_uuid":"441c8005831a1c55f27b326944ba850cfe5b0b3a"},"cell_type":"code","source":"test_Survived_SVMC = pd.Series(SVMC_best.predict(test), name=\"SVC\")\ntest_Survived_DTC = pd.Series(DTC_best.predict(test), name=\"DTC\")\ntest_Survived_RFC = pd.Series(RFC_best.predict(test), name=\"RFC\")\ntest_Survived_LRC = pd.Series(LRC_best.predict(test), name=\"LRC\")\n\n\n# Concatenate all classifier results\nensemble_results = pd.concat([test_Survived_SVMC,test_Survived_DTC,test_Survived_RFC,test_Survived_LRC],axis=1)\n\n\ng= sns.heatmap(ensemble_results.corr(),annot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d6ffbd801b34793251024926cf8f23162c66adf"},"cell_type":"markdown","source":"The prediction seems to be quite similar for the 4 classifiers. Although the prediction is fairly similar there are a few differences in the output. \nWe would thus consider an ensembling vote. "},{"metadata":{"_uuid":"267923924c6d57fbabf4cb0e84b98c0210ecf14d"},"cell_type":"markdown","source":"### 5. Ensemble Modeling using Voting Classifier\n\nArgument \"soft\" would be passed to the voting parameter to take into account the probability of each vote."},{"metadata":{"trusted":true,"_uuid":"7d255c30032b98a1bdf98eace682417d78dc451b"},"cell_type":"code","source":"votingC = VotingClassifier(estimators=[('svc', SVMC_best),('rfc', RFC_best), ('lrc', LRC_best)], voting='soft', n_jobs=4)\n\nvotingC = votingC.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bda061cd539a1582c2f2f004d4de2ece581420f5"},"cell_type":"markdown","source":"### 6. Prediction and Submission"},{"metadata":{"trusted":true,"_uuid":"a3b924ca058a679c4d2ea393a8ee2b63804c0bad"},"cell_type":"code","source":"'''\ntest_Survived = pd.Series(votingC.predict(test), name=\"Survived\")\n\nresults = pd.concat([IDtest,test_Survived],axis=1)\n\nresults.to_csv(\"Titanic_test_set_prediction.csv\",index=False)\n\n'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"479a44e63ea07bd8b8e9f91c3ec5dd6ae45dd555"},"cell_type":"code","source":"test_Survived = votingC.predict(test).astype(int)\nsubmission = pd.DataFrame({\n        \"PassengerId\": IDtest,\n        \"Survived\": test_Survived\n    })\nsubmission.to_csv('Titanic_test_prediction_V9.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"695d1e4fbe70710aef044d125f0daab9b55772ab"},"cell_type":"code","source":"accuracy_score(Y_train,votingC.predict(X_train))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}