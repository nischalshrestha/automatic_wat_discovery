{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ccd27b8b-9d62-0855-958f-1f47e54fa758"
      },
      "source": [
        "Simple neural network with 1 hidden layer, for prediction of Titanic survival"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "_cell_guid": "ebf055c7-1cef-5810-9da6-d284a4f90fbf"
      },
      "source": [
        "Preperaning data for NN. Clearing all null cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d710e639-96fe-806f-36a3-f26c6ca41885"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv as csv\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "    \n",
        "def getNumber(x):\n",
        "    search = re.search(r\"\\d+\", x)\n",
        "    if search:\n",
        "        return search.group(0)\n",
        "    return 0\n",
        "def getLetter(x):\n",
        "    search = re.search(r\"\\D+\", x)\n",
        "    if search:\n",
        "        return ord(search.group(0)[0])\n",
        "    return 0\n",
        "\n",
        "def getLastName(x):\n",
        "    search = re.search(r\"\\w+\", x)\n",
        "    if search:\n",
        "        return search.group(0)\n",
        "    return \"\"\n",
        "\n",
        "def getTitle(x):\n",
        "    search = re.search(r\" (\\S+)\\.\", x)\n",
        "    if search:\n",
        "        return search.group(1)\n",
        "    return \"\"    \n",
        "\n",
        "\n",
        "train_input = pd.read_csv(\"../input/train.csv\", dtype={\"Age\": np.float64})\n",
        "test_input = pd.read_csv(\"../input/test.csv\", dtype={\"Age\": np.float64})\n",
        "\n",
        "TRAINSIZE = train_input.shape[0]\n",
        "\n",
        "df = pd.concat([train_input, test_input], ignore_index=True)\n",
        "\n",
        "TitleMap = {}\n",
        "\n",
        "\n",
        "df['NameTitle'] = df['Name'].apply(getTitle)\n",
        "df.loc[df[df['NameTitle'] == 'Ms'].index, 'NameTitle'] = 'Miss'\n",
        "\n",
        "for index, item in enumerate(df['NameTitle'].unique()):\n",
        "    TitleMap[item] = index + 1\n",
        "\n",
        "df['Gender']  = df.Sex.map({'female':0, 'male':1}).astype(int)\n",
        "df[\"Family\"] = df.Name.map(getLastName)  \n",
        "df['NameLength'] = df[\"Name\"].apply(lambda x: len(x))\n",
        "\n",
        "df['NameTitleCat'] = df.NameTitle.map(TitleMap).astype(int)\n",
        "\n",
        "df['CabinInt'] = df.Cabin.dropna().map(getNumber).astype(int)\n",
        "df['CabinLetter'] = df.Cabin.dropna().map(getLetter).astype(int)    \n",
        "\n",
        "uniqueFamily = df[\"Family\"].unique()\n",
        "\n",
        "df[\"FamilyMemberOnBoard\"]  = 1\n",
        "for name in uniqueFamily:\n",
        "    number = df[df['Family'] == name].groupby('Family').PassengerId.nunique()[0]\n",
        "    df.loc[df['Family'] == name,\"FamilyMemberOnBoard\"] = number;\n",
        "\n",
        "df['AgeIsNull'] = pd.isnull(df.Age).astype(int)\n",
        "\n",
        "features_for_age_prediction = ['Pclass', 'SibSp','Parch','Gender','FamilyMemberOnBoard','NameLength','NameTitleCat']    \n",
        "age_prediction_linear_regressor = LinearRegression()\n",
        "age_X_train = df[features_for_age_prediction][df['Age'].notnull()]\n",
        "age_Y_train = df['Age'][df['Age'].notnull()]\n",
        "age_prediction_linear_regressor.fit(age_X_train, np.ravel(age_Y_train))\n",
        "\n",
        "df['AgeFill'] = df['Age']\n",
        "df.loc[df[df['Age'].isnull()].index, 'AgeFill'] = age_prediction_linear_regressor.predict(df[features_for_age_prediction][df['Age'].isnull()])\n",
        "\n",
        "uniqueChildFamily = df[df[\"AgeFill\"] <= 15][\"Family\"].unique();\n",
        "df[\"HasChild\"] = 0\n",
        "\n",
        "df.loc[(df[\"AgeFill\"] > 15 )& (df[\"Family\"].isin(uniqueChildFamily)),\"HasChild\"] = 1\n",
        "\n",
        "df['FamilySize'] = df.SibSp + df.Parch\n",
        "\n",
        "features_for_fare_prediction = ['Pclass', 'SibSp','Parch','Gender','FamilyMemberOnBoard','NameLength','NameTitleCat']    \n",
        "fare_prediction_linear_regressor = LinearRegression()\n",
        "fare_X_train = df[features_for_age_prediction][df['Fare'].notnull()]\n",
        "fare_Y_train = df['Fare'][df['Fare'].notnull()]\n",
        "fare_prediction_linear_regressor.fit(fare_X_train, np.ravel(fare_Y_train))\n",
        "\n",
        "df.loc[df[df['Fare'].isnull()].index, 'Fare'] = fare_prediction_linear_regressor.predict(df[features_for_fare_prediction][df['Fare'].isnull()])\n",
        "\n",
        "\n",
        "if len(df.Fare[ df.Fare.isnull() ]) > 0:\n",
        "    median_fare = np.zeros(3)\n",
        "    for f in range(0,3):                                              # loop 0 to 2\n",
        "        median_fare[f] = df[ df.Pclass == f+1 ]['Fare'].dropna().median()\n",
        "    for f in range(0,3):                                              # loop 0 to 2\n",
        "        df.loc[ (df.Fare.isnull()) & (df.Pclass == f+1 ), 'Fare'] = median_fare[f]\n",
        "\n",
        "if len(df.Cabin[ df.Cabin.isnull() ]) > 0:\n",
        "    median_cabinLetter = np.ones(df.FamilySize.max()+1)\n",
        "    for f in range(0,df.FamilySize.max()+1):       \n",
        "        if len(df.Cabin[ (df.FamilySize == f)].dropna()) > 0:\n",
        "            median_cabinLetter[f] = df[ df.FamilySize == f ]['CabinLetter'].dropna().median()\n",
        "        else:\n",
        "            median_cabinLetter[f] = df['CabinLetter'].dropna().median()\n",
        "    for f in range(0,df.FamilySize.max()+1):                                              # loop 0 to 2\n",
        "        df.loc[ (df.CabinLetter.isnull()) & (df.FamilySize == f), 'CabinLetter'] = median_cabinLetter[f]\n",
        "\n",
        "    df.loc[df['CabinInt'].isnull(),'CabinInt'] = df['CabinInt'].dropna().median()\n",
        "\n",
        "df[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")\n",
        "df[\"EmbarkedInt\"] =df[\"Embarked\"].map({\"S\":0, \"C\":1, \"Q\":2}).astype(int)\n",
        "\n",
        "\n",
        "# randomize our data to have train and test set different every time\n",
        "#df.reindex(np.random.permutation(df.index))\n",
        "df_number = df.drop(['PassengerId', 'Family','Name', 'Age','Sex', 'Ticket', 'Cabin', 'Embarked','NameTitle'], axis=1)\n",
        "\n",
        "testids = df['PassengerId'].values[TRAINSIZE::];\n",
        "\n",
        "df_number = df_number/(df_number.max() - df_number.min())\n",
        "\n",
        "key_features = ['Pclass','FamilySize','Fare','Gender','AgeFill','HasChild','FamilyMemberOnBoard','NameLength', 'NameTitleCat']\n",
        "\n",
        "test_data = df_number[key_features].values[TRAINSIZE::]\n",
        "\n",
        "X_data = df_number[key_features].values[0:TRAINSIZE]\n",
        "y_data= df_number[['Survived']].values[0:TRAINSIZE]"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "_cell_guid": "0ab642e4-fbf3-c50c-5bc2-a144cb8ea79a"
      },
      "source": [
        "Deviding training data to actual train data and crossvalidation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e6de802f-50ae-fa92-d704-642856b46512"
      },
      "outputs": [],
      "source": [
        "X_train = X_data[0:700]\n",
        "y_train = y_data[0:700]\n",
        "\n",
        "X_test = X_data[700::]\n",
        "y_test = y_data[700::]"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "_cell_guid": "48d813a9-6f79-ce98-8fc4-ee611ebfe31e"
      },
      "source": [
        "Creating Neural Network in tensorflow\n",
        "\n",
        "All summary function commented to prevent creating a lot of log during debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "63d1b7d9-84e5-feea-2cbd-b92ff57a52d2"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.3\n",
        "trainning_epochs= 10000\n",
        "display_step = 500\n",
        "\n",
        "threshold = 0.75\n",
        "\n",
        "TRAINSIZE = tf.constant( np.float32(X_train.shape[0]))\n",
        "LAMBDA = tf.constant(0.0001)\n",
        "\n",
        "n_hidden_1 = 5\n",
        "n_input = X_data.shape[1]\n",
        "n_output = 1\n",
        "n_sampels = X_data.shape[0]\n",
        "\n",
        "X = tf.placeholder(\"float\",[None,n_input])\n",
        "y = tf.placeholder(\"float\",[None,n_output])\n",
        "\n",
        "weights_1 = tf.Variable(tf.random_normal([n_input, n_hidden_1]))\n",
        "weights_2 = tf.Variable(tf.random_normal([n_hidden_1, n_output]))\n",
        "bias_1 = tf.Variable(tf.random_normal([n_hidden_1]))\n",
        "bias_2 = tf.Variable(tf.random_normal([n_output]))\n",
        "\n",
        "def forwardprop(x):\n",
        "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights_1),bias_1))\n",
        "    #tf.summary.histogram('weights_1', weights_1)\n",
        "    #tf.summary.histogram('bias_1', weights_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights_2),bias_2)\n",
        "    layer_2_sigmoid = tf.nn.sigmoid(layer_2)\n",
        "    #tf.summary.histogram('weights_2', weights_2)\n",
        "    #tf.summary.histogram('bias_2', bias_2)\n",
        "    return layer_2_sigmoid,  layer_2, layer_1\n",
        "\n",
        "y_hat, y_hat_witout_sigmoid,_ = forwardprop(X)\n",
        "\n",
        "is_greater = tf.greater(y_hat, threshold)\n",
        "prediction = tf.to_int32(is_greater)\n",
        "correct_prediction = tf.equal(prediction, tf.to_int32(y_hat))\n",
        "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "cost_J= tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(y_hat_witout_sigmoid, y))\n",
        "#tf.summary.scalar('cost_J', cost_J)\n",
        "cost_reg = tf.mul(LAMBDA , tf.add(tf.reduce_sum(tf.pow(weights_1, 2)),tf.reduce_sum(tf.pow(weights_2, 2))))\n",
        "#tf.summary.scalar('cost_reg', cost_reg)\n",
        "\n",
        "cost = cost_J + cost_reg\n",
        "#tf.summary.scalar('cost', cost)\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "_cell_guid": "dee4420c-a6e8-129f-1fec-5157ea9af5e8"
      },
      "source": [
        "Teaching Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "438c505e-8904-fdea-cb0e-cc36c4734758"
      },
      "outputs": [],
      "source": [
        "75#summary = tf.summary.merge_all()\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "J = []\n",
        "testJ = []\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth=True\n",
        "with tf.Session(config=config) as sess:\n",
        "    #summary_writer = tf.summary.FileWriter(\"log4/\", sess.graph)\n",
        "    sess.run(init)\n",
        "    \n",
        "    for epoch in range(trainning_epochs):\n",
        "        \n",
        "        #_,c,summary_str = sess.run([optimizer, cost,summary], feed_dict={X: batch_xs})\n",
        "        #_,c,summary_str = sess.run([optimizer, cost,summary], feed_dict={X: X_data, y: y_data}) \n",
        "        _,c = sess.run([optimizer, cost], feed_dict={X: X_train, y: y_train}) \n",
        "        c_test = sess.run([cost], feed_dict={X: X_test, y: y_test})      \n",
        "        #summary_writer.add_summary(summary_str,epoch)    \n",
        "        J.append(c)\n",
        "        testJ.append(c_test)\n",
        "        if epoch % display_step == 0:\n",
        "            print(\"Epoch:\", '%04d' % (epoch+1),\n",
        "                  \"cost=\", \"{:.9f}\".format(c))\n",
        "            \n",
        "    print(\"Optimization Finished!\")\n",
        "    weights_1_data = sess.run([weights_1], feed_dict={X: X_test, y: y_test})[0]  \n",
        "    weights_2_data = sess.run([weights_2], feed_dict={X: X_test, y: y_test})[0]  \n",
        "    y_predict_test, accuracy = sess.run([prediction,accuracy_op], feed_dict={X: X_test})  \n",
        "    test_result  = sess.run([prediction], feed_dict={X: test_data})[0]  "
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "_cell_guid": "720ddfd4-50e2-2c17-1f16-7a914d96333f"
      },
      "source": [
        "Ploting of learning Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "595402d0-1204-4080-5195-21221f559020"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.plot(J,label=\"J\")\n",
        "plt.plot(testJ, label=\"testJ\")\n",
        "plt.grid(1)\n",
        "plt.legend(loc='upper center', shadow=True)\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Cost')"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "_cell_guid": "59adeeac-e4c2-b1f6-ad69-3e4da410d37b"
      },
      "source": [
        "Displaying Precision / Recall / F1 score and Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5379ea25-038a-4e5d-840e-884c0153b4f9"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print (\"validation accuracy:\", accuracy)\n",
        "print (\"Precision\", metrics.precision_score(y_test, y_predict_test))\n",
        "print (\"Recall\", metrics.recall_score(y_test, y_predict_test))\n",
        "print (\"f1_score\", metrics.f1_score(y_test, y_predict_test))\n",
        "print (\"confusion_matrix\")\n",
        "print (metrics.confusion_matrix(y_test, y_predict_test))"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "_cell_guid": "7c9932e9-1c85-15d7-5630-b813947f4e47"
      },
      "source": [
        "Drawing weights of hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "89c91620-c2f1-0d50-945d-133931f8b12d"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "neuron_weight = weights_1_data\n",
        "\n",
        "plt.set_cmap(\"plasma\")\n",
        "plt.axis('off')\n",
        "plt.imshow(neuron_weight)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "_cell_guid": "bc743874-8f8c-f9b7-73a0-ae5fe3d2d558"
      },
      "source": [
        "Drawing weights of output layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a68b9aca-99d1-ae53-a97a-947ff8e55318"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "neuron_weight = weights_2_data\n",
        "\n",
        "plt.set_cmap(\"plasma\")\n",
        "plt.axis('off')\n",
        "plt.imshow(neuron_weight)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "_cell_guid": "1f7c7aa5-c8b6-2761-7267-5538c4082679"
      },
      "source": [
        "Submiting data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "209e9b54-b791-d6db-b238-64718c81ba8a"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({\n",
        "        \"PassengerId\": testids,\n",
        "        \"Survived\": test_result.T[0]\n",
        "    })\n",
        "\n",
        "submission.to_csv(\"titanic_NN_tensorflow.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}