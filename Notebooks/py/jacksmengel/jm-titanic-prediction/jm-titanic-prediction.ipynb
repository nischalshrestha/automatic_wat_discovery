{"metadata": {"language_info": {"name": "python", "mimetype": "text/x-python", "file_extension": ".py", "nbconvert_exporter": "python", "version": "3.6.4", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3"}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat": 4, "nbformat_minor": 1, "cells": [{"metadata": {"_cell_guid": "5f4f547d-432b-439f-807b-4f32395fa2cf", "collapsed": true, "_uuid": "bbd5c0438394a79af040b72afcdc6eae40ebd489"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "# data analysis and wrangling\n", "import pandas as pd\n", "import numpy as np\n", "import random as rnd\n", "\n", "# visualization\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "# machine learning\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.svm import SVC, LinearSVC\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.linear_model import Perceptron\n", "from sklearn.linear_model import SGDClassifier\n", "from sklearn.tree import DecisionTreeClassifier\n", "\n", "test_df = pd.read_csv(\"../input/test.csv\")\n", "train_df = pd.read_csv(\"../input/train.csv\")\n", "\n", "# pclass\n", "#print(train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n", "\n", "# sex\n", "#print(train_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n", "\n", "# number of siblings / spouses\n", "#print(train_df[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n", "\n", "# number of parents\n", "#print(train_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n", "\n", "#g = sns.FacetGrid(train_df, col='Survived')\n", "#h = g.map(plt.hist, 'Age', bins=20)\n", "#print(h)\n", "\n", "grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', size=2.2, aspect=1.6)\n", "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n", "grid.add_legend()\n", "print(grid)\n", "\n", "grid3 = sns.FacetGrid(train_df, row='Embarked', col='Survived', size=2.2, aspect=1.6)\n", "grid3.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\n", "grid3.add_legend()\n", "print(grid3)\n", "\n", "# wrangle data\n", "\n", "train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\n", "test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\n", "print(test_df.head())\n", "combine = [train_df, test_df]\n", "\n", "# convert NaN ages to average age\n", "avg_age = train_df['Age'].mean()\n", "for dataset in combine:\n", "    dataset.loc[(dataset.Age.isnull()),'Age'] = avg_age\n", "combine = [train_df, test_df]\n", "\n", "# does name have a title in it?\n", "for dataset in combine:\n", "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n", "combine = [train_df, test_df]\n", "\n", "grid4 = pd.crosstab(train_df['Title'], train_df['Sex'])\n", "print(grid4)\n", "\n", "for dataset in combine:\n", "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n", " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n", "\n", "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n", "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n", "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n", "    \n", "combine = [train_df, test_df]\n", "train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n", "\n", "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n", "for dataset in combine:\n", "    dataset['Title'] = dataset['Title'].map(title_mapping)\n", "    dataset['Title'] = dataset['Title'].fillna(0)\n", "combine = [train_df, test_df]\n", "# Drop name feature, not useful anymore\n", "train_df = train_df.drop(['Name', 'PassengerId'], axis=1)\n", "test_df = test_df.drop(['Name'], axis=1)    \n", "\n", "# replace NULLs with median values for Pclass/gender groupings\n", "\n", "# first, take a look at the various groupings in histogram form\n", "grid5 = sns.FacetGrid(train_df, row='Pclass', col='Sex', size=2.2, aspect=1.6)\n", "grid5.map(plt.hist, 'Age', alpha=.5, bins=20)\n", "grid5.add_legend()\n", "\n", "\n", "# create age bands -> five different buckets in population\n", "train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\n", "train_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)\n", "\n", "# replace Age with bucket\n", "for dataset in combine:    \n", "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n", "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n", "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n", "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n", "    dataset.loc[ dataset['Age'] > 64, 'Age']\n", "combine = [train_df, test_df]\n", "# then, drop AgeBand\n", "train_df = train_df.drop(['AgeBand'], axis=1)\n", "combine = [train_df, test_df]\n", "\n", "# create combined field of Siblinds and parent/children -> size of family\n", "for dataset in combine:\n", "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n", "combine = [train_df, test_df]\n", "train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n", "\n", "# check if someone is alone\n", "for dataset in combine:\n", "    dataset['IsAlone'] = 0\n", "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n", "combine = [train_df, test_df]\n", "# what's correlation to survival?\n", "train_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()\n", "\n", "train_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n", "test_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n", "combine = [train_df, test_df]\n", "\n", "# create column combining Pclass and Age\n", "for dataset in combine:\n", "    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n", "combine = [train_df, test_df]\n", "train_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)\n", "\n", "# fill in missing \"embarked\" values\n", "# C is most common:\n", "freq_port = train_df.Embarked.dropna().mode()[0]\n", "\n", "for dataset in combine:\n", "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n", "combine = [train_df, test_df]\n", "train_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n", "\n", "# Create numeric Port column (converting alpha values to numbers)\n", "for dataset in combine:\n", "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n", "combine = [train_df, test_df]\n", "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\n", "\n", "# Create bucket for fare\n", "train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\n", "train_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)\n", "\n", "for dataset in combine:\n", "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n", "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n", "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n", "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n", "    dataset['Fare'] = dataset['Fare'].astype(int)\n", "combine = [train_df, test_df]\n", "train_df = train_df.drop(['FareBand'], axis=1)\n", "\n", "\n", "combine = [train_df, test_df]\n", "\n", "# Convert gender to number\n", "for dataset in combine:\n", "    dataset['Sex'] = dataset['Sex'].map( {'male': 0, 'female': 1} ).astype(int)\n", "combine = [train_df, test_df]\n", "\n", "# Data is now ready to be plugged into a model!!!\n", "\n", "#Use logistic regression\n", "#https://en.wikipedia.org/wiki/Logistic_regression\n", "\n", "# first, set up variables to compare\n", "X_train = train_df.drop(\"Survived\", axis=1)\n", "Y_train = train_df[\"Survived\"]\n", "X_test  = test_df.drop(\"PassengerId\", axis=1).copy()\n", "\n", "# Example of logistic regression\n", "#logreg = LogisticRegression()\n", "#logreg.fit(X_train, Y_train)\n", "#Y_pred = logreg.predict(X_test)\n", "#acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n", "\n", "# Example of Support Vector Machines\n", "# https://en.wikipedia.org/wiki/Support_vector_machine\n", "#coeff_df = pd.DataFrame(train_df.columns.delete(0))\n", "#coeff_df.columns = ['Feature']\n", "#coeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n", "#coeff_df.sort_values(by='Correlation', ascending=False)\n", "#svc = SVC()\n", "#svc.fit(X_train, Y_train)\n", "#Y_pred = svc.predict(X_test)\n", "#acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n", "\n", "# Example of \"K nearest neighbors\" or j-NN\n", "#https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm\n", "#knn = KNeighborsClassifier(n_neighbors = 3)\n", "#knn.fit(X_train, Y_train)\n", "#Y_pred = knn.predict(X_test)\n", "#acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n", "\n", "# Example of Naive Bayes classifiers\n", "#https://en.wikipedia.org/wiki/Naive_Bayes_classifier\n", "#gaussian = GaussianNB()\n", "#gaussian.fit(X_train, Y_train)\n", "#Y_pred = gaussian.predict(X_test)\n", "#acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n", "\n", "#Example of Perceptron\n", "#https://en.wikipedia.org/wiki/Perceptron\n", "#perceptron = Perceptron()\n", "#perceptron.fit(X_train, Y_train)\n", "#Y_pred = perceptron.predict(X_test)\n", "#acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n", "\n", "# Example of random forest\n", "# https://en.wikipedia.org/wiki/Random_forest\n", "random_forest = RandomForestClassifier(n_estimators=100)\n", "random_forest.fit(X_train, Y_train)\n", "Y_pred = random_forest.predict(X_test)\n", "random_forest.score(X_train, Y_train)\n", "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n", "acc_random_forest\n", "\n", "submission = pd.DataFrame({\n", "        \"PassengerId\": test_df[\"PassengerId\"],\n", "        \"Survived\": Y_pred\n", "    })\n", "\n", "submission.to_csv('jsm_submission.csv', index=False)"]}]}