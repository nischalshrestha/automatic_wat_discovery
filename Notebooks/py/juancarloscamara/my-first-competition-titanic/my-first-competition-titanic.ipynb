{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"input_train_path = '../input/train.csv'\ninput_test_path = '../input/test.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"74b4f9227c5379856e980ee63aa10e3eacc2d6e4"},"cell_type":"code","source":"input_train = pd.read_csv(input_train_path)\ninput_test = pd.read_csv(input_test_path)\n\nprint('====Format for the train file===')\ninput_train.info()\n\nprint('====Format for the test file===')\ninput_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37e2cb958051637a3b6ae15b536536f813b7f482"},"cell_type":"code","source":"print('====Header for the train file===')\ninput_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40d5ce8ea8770256239aa83b3989503f63e278f0"},"cell_type":"code","source":"print('===Header for the test file===')\ninput_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dae47fdcffc138f07dbc33efed890f52d3569260"},"cell_type":"code","source":"# From the previous fields we see some things:\n# - Cabin field is almost emptied in both files, train and test\n# - Age field has Not valid values in both files, train and test, for some of the records\n# - Fare is a field that potentially does not make sense to be related with the possibility of surviving or not - correlation necessary\n# - Ticket is a field that potentially does not make sense to be related with the possibility of surviving or not - correlation necessary. However, not empty fields. We´ll keept it\n# - Embarked is a field that potentially does not make sense to be related with the possibility of surviving or not - correlation necessary\n# - Name is a field that could be divided and analyzed, but right now does not make sense to be related with survival\n# - Sex is a field that make sense to analyzed, but it´s string. Conversion is necessary\n\n# Let´s start aplying this changes in Train file\n\nfeatures = ['PassengerId', 'Survived', 'Pclass', 'Sex', 'SibSp', 'Parch']\ninput_train_featured = input_train[features]\n\ninput_train_featured.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"3bb732ccd87aaa094c50fdb8da240b2884d929c1"},"cell_type":"code","source":"# Mapping Sex columnt to a series\nSex_map = {'male' : 0, 'female' : 1}\ninput_train_featured.Sex = input_train_featured.Sex.map(Sex_map)\n\ninput_train_featured.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da75173457d0a9e9c51103bd5400779dabbdadca"},"cell_type":"code","source":"# Extract Survived variable and featured dataset\ninput_train_featured_X = input_train_featured[['PassengerId', 'Pclass', 'Sex', 'SibSp', 'Parch']]\ninput_train_featured_y = input_train_featured.Survived","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed4d15319871acf8dac9dbf18d0e0fb7dcbd2cbc"},"cell_type":"code","source":"# Now that we have a full train numeric dataset let´s proceed\n# to create the models, fit, predict and see which one has a better MAE\nfrom sklearn.model_selection import train_test_split\n\ntmp_train_X, tmp_val_X, tmp_train_y, tmp_val_y = train_test_split(input_train_featured_X, input_train_featured_y, random_state = 5, test_size = 0.1)\n\nprint(\"=== Train X dataset for modeling ===\")\ntmp_train_X.info()\nprint(\"=== Val X dataset for modeling ===\")\ntmp_val_X.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bea09ac287ee89ac39fa11962760b7bf66533594"},"cell_type":"code","source":"# Let´s see with DecisionTreRegressor, which is the MAE, for the different max_leaf_nodes values\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_absolute_error\n\ndef get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n    model = DecisionTreeRegressor(max_leaf_nodes = max_leaf_nodes, random_state = 5)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n\n# compare MAE with differing values of max_leaf_nodes\nmaes = []\nnodes = [2,3,4,5,10,20,25,30,40, 50,75,100,200,250,300, 500,600,700,800,900,1000,1500,2000,2500,3000,4000, 5000]\nfor max_leaf_nodes in nodes:\n    my_mae = get_mae(max_leaf_nodes, tmp_train_X, tmp_val_X, tmp_train_y, tmp_val_y)\n    print(\"Max leaf nodes: %f  \\t\\t Mean Absolute Error:  %f\" %(max_leaf_nodes, my_mae))\n    maes.append(my_mae)\n\n    \nprint(\"Best index %d, best mae %f\" %(nodes[maes.index(min(maes))], min(maes)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba2fba4a0a5e653bb77d18b13531bd05b13bd011"},"cell_type":"code","source":"# Let´s see with RandomForestRegressor, which is the MAE\nfrom sklearn.ensemble import RandomForestRegressor\n\ndef get_mae_randomforest(train_X, val_X, train_y, val_y):\n    model = RandomForestRegressor(random_state = 5)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n\nmy_mae = get_mae_randomforest(tmp_train_X, tmp_val_X, tmp_train_y, tmp_val_y)\nprint(\"Mean Absolute Error:  %f\" %( my_mae))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"116b7cf14cc6650961196f5694ee385b23503927"},"cell_type":"code","source":"# It can be seen that MAE for Decision is better than one for RandomForest, for a given max_leaf_nodes attribute.\n# We will proceed creating a new modeling for the whole dataset, not only 90%, and proceed with executing the estimation for the test.csv\n\nfinal_model = DecisionTreeRegressor(max_leaf_nodes=250, random_state = 5)\nfinal_model.fit(input_train_featured_X, input_train_featured_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"893d614c579d0f779da123cb96bcf0c982553343"},"cell_type":"code","source":"# Not it´s time for applying the same changes we applied for the train dataset\ntest_features = ['PassengerId', 'Pclass', 'Sex', 'SibSp', 'Parch']\ninput_test_featured = input_test[test_features]\n\nSex_map = {'male' : 0, 'female' : 1}\ninput_test_featured.Sex = input_test_featured.Sex.map(Sex_map)\n\ninput_test_featured.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2bb76c55b074f7275437eb9382ce0e9f2b084cee"},"cell_type":"code","source":"predictions = final_model.predict(input_test_featured)\nprint(predictions)\n\nmy_submission = pd.DataFrame({'PassengerId': input_test_featured.PassengerId, 'Survived': predictions})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bc8da724b79a75b6a741d255a8b1d7e05fb2969"},"cell_type":"code","source":"# For some reason, I am receiving 0.041666... values in the dataset. I´m still investigating why, I didn´t expect them.\n# As the values are quite small, I will assume they can be rounded to 0\n\npredictions2 = predictions.round()\nprint(predictions2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6f049d24822cebc03f10a562316d1b71777727b"},"cell_type":"code","source":"my_submission2 = pd.DataFrame({'PassengerId': input_test_featured.PassengerId, 'Survived': predictions2})\n# you could use any filename. We choose submission here\nmy_submission2.to_csv('submission2.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"794cb5fcd9e2da9db83eb94d912e1053a29c8f7e"},"cell_type":"code","source":"predictions3 = final_model.predict(input_test_featured).astype(int)\nprint(predictions3)\n\nmy_submission3 = pd.DataFrame({'PassengerId': input_test_featured.PassengerId, 'Survived': predictions3})\n# you could use any filename. We choose submission here\nmy_submission3.to_csv('submission3.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02fb58c22e6c3f217ca28fcc2d22dca88081328f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}