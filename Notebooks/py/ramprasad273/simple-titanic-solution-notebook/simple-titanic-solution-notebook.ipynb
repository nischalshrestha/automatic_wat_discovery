{"cells":[{"metadata":{"_uuid":"5726398c0f2686447abe411664ae1e9c4dea6579"},"cell_type":"markdown","source":"#  Kaggle - Titanic Solution Notebook"},{"metadata":{"_uuid":"d2ca701aa1ea3888018ffeff2b3598091993326f"},"cell_type":"markdown","source":"### Competition Description\n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n\n### Practice Skills\n\n* Binary classification\n\n* Python and R basics\n"},{"metadata":{"_uuid":"d3a986a4a6dd2cff965e8c880f6443d11d6e577b"},"cell_type":"markdown","source":"### Collecting the Data\n\nThe training and test data are available on Kaggle.\n\nYou can download directly from here [here](https://www.kaggle.com/c/titanic/data) \n\n\n### Data Dictionary\n\n \n| Variable                | Definition                                    |  Key                                            |\n|:------------------------|----------------------------------------------:|------------------------------------------------:|\n| survival                | Survival                                      |  0 = No, 1 = Yes                                |   \n| pclass                  | Ticket class                                  |  1 = 1st, 2 = 2nd, 3 = 3rd                      |\n| sex                     | Sex                                           |                                                 |\n| Age                     | Age in years                                  |                                                 |\n| sibsp                   | # of siblings / spouses aboard the Titanic    |                                                 |\n| parch                   | # of parents / children aboard the Titanic    |                                                 |\n| ticket                  | Ticket number                                 |  0 = No, 1 = Yes                                |\n| fare                    | Passenger fare\t                              |  0 = No, 1 = Yes                                |\n| cabin                   | Cabin number                                  |  0 = No, 1 = Yes                                |\n| embarked                | Port of Embarkation                           |  C = Cherbourg, Q = Queenstown, S = Southampton |   \n|-------------------------|-----------------------------------------------|-------------------------------------------------|\n\n### Variable Notes\n\npclass: A proxy for socio-economic status (SES)\n1st = Upper\n2nd = Middle\n3rd = Lower\n\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nsibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fiancÃ©s were ignored)\n\nparch: The dataset defines family relations in this way...\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.\n"},{"metadata":{"trusted":true,"_uuid":"0fc46885c4ba747dea68b1c9e72896654cea9e4f"},"cell_type":"code","source":"#############################################################\n#        Step 1: Import libraries                           #\n#############################################################\n\n \nimport pandas as pd\nimport numpy as np\n\n# Visual representation libraries\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Machine learning Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3bc4b4bccd8d3a7eeee886891b62ecee663ffa4a"},"cell_type":"code","source":"#############################################################\n#        Step 2: load the datasets                          #\n#############################################################\n\nprint('Load the datasets...')\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\nprint ('Train dataset: %s'%(str(train.shape)))\nprint ('Test  dataset: %s'%(str(test.shape)))\n\n\ntrain.head()\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee7259493666924b61f8420df733df6a2c2028de"},"cell_type":"markdown","source":"After loadin the train and test datasets, we can get the information about the total number of rows and coulmns. \n\n  #### Training Dataset \n    Columns: 12\n    Rows   : 981\n\n  #### Test Dataset\n    Columns: 11\n    Rows   : 418\n\n\n"},{"metadata":{"trusted":true,"_uuid":"4f57c7b0b608fa08f153174d8c99c3ccfe363137"},"cell_type":"code","source":"# Combining train and test dataset\ntrain_test_data = [train, test] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1bd9e76eb93df30679f1435fe98ed14b3ae0367"},"cell_type":"code","source":"#############################################################\n#       Step 3: Data Exploration                            #\n#############################################################\n\n# describe() method shows values like count, mean, standard deviation, etc. of numeric data types.\ntrain.describe()\n\n# describe(include = ['O']) will show the descriptive statistics of object data types. \ntrain.describe(include=['O'])\n\n\n# Get the total missing values present in columns of both train and test dataset\ntrain.isnull().sum()\ntest.isnull().sum()\n\n# Survival rate from train data\nsurvived = train[train['Survived']==1]\nnot_survived = train[train['Survived']==0]\n\nprint(\"---------------------------\")\nprint(\"From the training dataset:\")\nprint(\"---------------------------\")\nprint(\"  Total Passengers : %i\"\\\n      %(len(train)))\nprint(\"\")\nprint(\"  Total Survivors  : %i\"\\\n      %(len(survived)))\n\nprint(\"  Survival Rate    : %i %% \"\\\n     % (1.*len(survived)/len(train)*100.0))\nprint(\"-------------------------\")\nprint(\"  Total Casuality  : %i\"\\\n      %(len(not_survived)))\n\nprint(\"  Fatality Rate    : %i %% \"\\\n     % (1.*len(not_survived)/len(train)*100.0))\nprint(\"-------------------------\")\n\n# Check for missing data & list them \nmissingData = pd.concat([train.isnull().sum(), test.isnull().sum()], axis=1, keys=['Training Dataset', 'Test Dataset']) \nprint('')\nprint('Nan data present in the datasets')\nprint('')\nprint(missingData[missingData.sum(axis=1) > 0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10fca6cde5a3666d4b8416c252cb76ac93ea13ba"},"cell_type":"markdown","source":"#### Observations:\n\nFrom the training dataset we get the below details:\n\n  1. There were 891 passengers of which only 38% survived.\n  2. There are some missing data present in both training and test datasets.\n  3. Age column has the highest number of missing data which is present in both the datasets.\n  4. Cabin also has missing data in both the datasets.\n  5. Embarked column has 2 missing data only in the training datasets.\n  6. Fare column has one missing data in the test dataset.\n\n\n\n\n"},{"metadata":{"_uuid":"aad2e7f2a432be5657c423fc912e86a37ea5c975"},"cell_type":"markdown","source":"For the next step we will try to visualize the data.\n\nVisualizing the data helps us understanding the data better and this will help us in getting the dataset well prepared for \nthe Model training.\n\nBelow is the function \"bar_chart\" which will take in a feature as a parameter and provide us the bar chart.\n\nThe Bar chart will show how the survival of a passenger varies with different features and its subtypes.\n"},{"metadata":{"trusted":true,"_uuid":"937e05d6cd0170741c73a5183fdbf6afcc683a5d"},"cell_type":"code","source":"#############################################################\n#       Step 4: Data Visualization                          #\n#############################################################\n\ndef bar_chart(feature):\n    survived = train[train['Survived']==1][feature].value_counts()\n    not_survived = train[train['Survived']==0][feature].value_counts()\n    df = pd.DataFrame([survived,not_survived])\n    df.index = ['Survived','Casuality']\n    df.plot(kind='bar',stacked=True, figsize=(7,5))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6146da7d6dc8fee42ea77fff98ec302923e8b3a4"},"cell_type":"code","source":"bar_chart('Sex')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fabc917439028664994b4739fb5ebf3216f4ebe8"},"cell_type":"code","source":"bar_chart('Pclass')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1eeb883fb0101fb53b77ccc2a3565a6f837e7c9c"},"cell_type":"code","source":"bar_chart('SibSp')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57201acdf14a7aeb1573b51b6bbfef0c0e5f1135"},"cell_type":"code","source":"bar_chart('Parch')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"543f872de8a96c8ed2dfee08d3f72a4b974adf57"},"cell_type":"code","source":"bar_chart('Embarked')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f6ddee67c4a689f7b134ba5a8d9a6958978fe95"},"cell_type":"markdown","source":"The Above bar chart just tells us how the survival varies with each features.\nNow in the below section we are going to see how each features impacts the survial of a passenger. "},{"metadata":{"trusted":true,"_uuid":"6107e7a6995d8926327cfde7da9c54723ac23087"},"cell_type":"code","source":"#############################################################\n#      Step 5: Relationship Features and Survival           #\n#############################################################\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8be1977af4014ac211482023abd87730d8dc6b23"},"cell_type":"markdown","source":"#### Pclass vs. Survival"},{"metadata":{"trusted":true,"_uuid":"699f3aea667d16aec1ed94a8769798b84517daaa"},"cell_type":"code","source":"#Pclass vs. Survival\n\ntrain.Pclass.value_counts()\ntrain.groupby('Pclass').Survived.value_counts()\ntrain[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean()\nsns.barplot(x='Pclass', y='Survived', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c301a861d7597b25dd5d21e1ccd346531554a876"},"cell_type":"code","source":"# Class vs Survived\nprint(train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived',\n                                                                                                   ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e428db12049b4b7978dc04d090cdde8c19d4154f"},"cell_type":"markdown","source":"#### Observations:\n    1. The passengers in the 1st class have the highest survival rate of 63%.\n    2. The passengers in the 2nd ticket class have survival rate of almost 47%.\n    3. The 3rd class passengers have the lowest survival percentage which is 24%."},{"metadata":{"_uuid":"4a6adf4b205acd4dd16393517a8750bbb41a3ce3"},"cell_type":"markdown","source":"#### Sex vs. Survival"},{"metadata":{"trusted":true,"_uuid":"6e7263078e05442c37514450a6a7b6415b45ef32"},"cell_type":"code","source":"#Sex vs. Survival\ntrain.Sex.value_counts()\ntrain.groupby('Sex').Survived.value_counts()\ntrain[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean()\nsns.barplot(x='Sex', y='Survived', data=train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"246fc57f01882c82fb0213b93cd4971729096fcf"},"cell_type":"code","source":"# Class vs Survived\nprint(train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived',\n                                                                                                   ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22763de3286897ade8294764e9d2955b7a9a5042"},"cell_type":"markdown","source":"#### Observations\n    1. Female survival percentage is more than that of male.\n    2. 74% of the surviors were female and only 19% men survived."},{"metadata":{"_uuid":"a328bb4056c652b2048ac75d6972b96801c7b43f"},"cell_type":"markdown","source":"#### Pclass & Sex vs. Survival\nLets check the survival rate when compared to the pclass and sex"},{"metadata":{"trusted":true,"_uuid":"258007943fa8741c2ee60a4d127758beecb3f1a1"},"cell_type":"code","source":"#Pclass & Sex vs. Survival\ntab = pd.crosstab(train['Pclass'], train['Sex'])\nprint (tab)\n\ntab.div(tab.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True)\nplt.xlabel('Pclass')\nplt.ylabel('Percentage')\n\nsns.factorplot('Sex', 'Survived', hue='Pclass', size=5, aspect=2, data=train)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cccd3a6a18e358e5d44b0ac33c064b37f3f95f75"},"cell_type":"markdown","source":"#### Observations:\n    1. From the 1st class passengers, 122 male and 94 female survived.\n    2. 76 female and 108 male from the 2nd class survived.\n    3. 144 female and 347 male passengers from the 3rd class survived.  \n    4. 1st class passenger survival rate is higher than other classes.\n    5. 3rd class passenger survival rate is lowest when compared to other classes.\n    "},{"metadata":{"trusted":true,"_uuid":"93189526e65af529e28ec4b83c32de2263732138"},"cell_type":"code","source":"#Pclass, Sex & Embarked vs. Survival\nsns.factorplot(x='Pclass', y='Survived', hue='Sex', col='Embarked', data=train)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4f6acb040eb74a012c2b51bae91467af02b7bde"},"cell_type":"markdown","source":"#### Embarked vs. Survived"},{"metadata":{"trusted":true,"_uuid":"354715d1c8fb255c58e71be4d725d49e09b37165"},"cell_type":"code","source":"#Embarked vs. Survived\ntrain.Embarked.value_counts()\ntrain.groupby('Embarked').Survived.value_counts()\ntrain[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean()\nsns.barplot(x='Embarked', y='Survived', data=train)\n\nprint(train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived',\n                                                                                                   ascending=False))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b529de0145e0828537d1a641674d8ce5f618e3ef"},"cell_type":"markdown","source":"#### Observations\n    1.The passengers embarked from Cherbourg has the highest survival percentage which is 55.\n    2.The passengers embarked from Queenstown has the survival percentage of 39.\n    3.The passengers embarked from Southampton has the lowest survival percentage of 34.\n    "},{"metadata":{"_uuid":"ac321ec85092bbcd9c54eef9b3c97bb991e9b3d3"},"cell_type":"markdown","source":"#### SibSp vs. Survival"},{"metadata":{"trusted":true,"_uuid":"a386792db9032f5c7016a01aa8fff2e57fabe982"},"cell_type":"code","source":"#SibSp vs. Survival\ntrain.SibSp.value_counts()\ntrain.groupby('SibSp').Survived.value_counts()\ntrain[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean()\nsns.barplot(x='SibSp', y='Survived', ci=None, data=train) # ci=None will hide the error bar\n\nprint(train[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad50bc78307a567b0f888a67ceb17f9f21a90161"},"cell_type":"markdown","source":"#### Observations:\n    1. The survival rate of a passenger is high when he/she has a siblings / spouse onboard the titanic.\n    2. When there are no siblings / spouse, the survival rate is 34%.\n    3. When there is 1 siblings / spouse onboard the survival rate is highest which is 53%.\n    4. When there are 2 siblings / spouse onboard the survival rate is 46%.\n    5. Survival rate is low when there are more than 2 siblings / spouse.   \n    "},{"metadata":{"_uuid":"28e7a5da2c8d76982c2b38da33b623eba11c6c80"},"cell_type":"markdown","source":"#### Parch vs. Survival"},{"metadata":{"trusted":true,"_uuid":"e79e0ace9f54a2e3e213452d6758a8871fda608e"},"cell_type":"code","source":"#Parch vs. Survival\ntrain.Parch.value_counts()\ntrain.groupby('Parch').Survived.value_counts()\ntrain[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean()\nsns.barplot(x='Parch', y='Survived', ci=None, data=train)\n\nprint(train[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e96676488cdf3becd1901f31061040a70f0855d"},"cell_type":"markdown","source":"#### Observations\n    1. When there are 5 parents / children members onboard the Titanic the survival rate is very low i.e. 20%.    \n    2. The survival rate is highest (60%) when there are 3 parents / children members.\n    3. The rate dips when the number of parents / children increases.\n    4. When there is no parents / children onboard the survival rate is 34%\n    "},{"metadata":{"trusted":true,"_uuid":"4a91280cd6556edbb030299a23f8c0220174df06"},"cell_type":"code","source":"#Correlating Features\nplt.figure(figsize=(15,6))\nsns.heatmap(train.drop('PassengerId',axis=1).corr(), vmax=0.6, square=True, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ae3ad0a658dc8c1e11a4c9328cc75f0e83973ed"},"cell_type":"markdown","source":"#### Observations\n   1. Correlation index of 1 means perfect correlation and -1 means anti-correlation.\n   2. Positive or negative correlations with the Survived feature are valuable.\n   3. Strong correlations between two other features would suggest that only one of them is necessary for our model."},{"metadata":{"trusted":true,"_uuid":"d38d01f3974604528905982ca8575cf8ba3d8213"},"cell_type":"code","source":"#############################################################\n#      Step 5: Feature engineering                          #\n#############################################################","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c44a7b35ad25dd1d96120b09cdea7a61613a8eb6"},"cell_type":"markdown","source":"### Featur Engineering\n\n#### 1. Name\n     \n     * We create Title from the name feature.\n     * Then we map the title to numeric values\n     * We create a new mapping others which will have the other titles like 'Don', 'Dr', 'Major', 'Rev', 'Sir',etc\n     * So there are in total 5 groupings made from the title"},{"metadata":{"trusted":true,"_uuid":"f61377ba45343f6c81d177828abad58aa19fa97d"},"cell_type":"code","source":"#Name\n\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n\ntrain['Title'].value_counts()\n\ntest['Title'].value_counts()\n\n\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col', \\\n    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Other')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Other\": 5}\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    \nbar_chart('Title')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f2256ac03c372e5133258055867abc03ce9f0fdf"},"cell_type":"markdown","source":"#### 2. Sex\n     \n     *  We map male as 0 and female as 1"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"8e9b4840b0f9086f7cb851e683c696054e8f3115"},"cell_type":"code","source":"#Sex\nsex_mapping = {\"male\": 0, \"female\": 1}\nfor dataset in train_test_data:\n    dataset['Sex'] = dataset['Sex'].map(sex_mapping)\n\nbar_chart('Sex')\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76669215c63d226ff9d0a29b6226f0a2c957cd6d"},"cell_type":"markdown","source":"#### 3. Age\n\n     * For the first step we fill the missing value in age field by the median age grouped by title.\n     * We then create a age bands like 0-15  as 0,\n                                       16-32 as 1,\n                                       33-48 as 2,\n                                       49-63 as 3 and \n                                       64 and above as 4"},{"metadata":{"trusted":true,"_uuid":"eca79de0cf416b4ba8b7861731bb28ac52ad60d2"},"cell_type":"code","source":"#Age\n\ntrain[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\ntest[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\n\nfor dataset in train_test_data:    \n    dataset.loc[ dataset['Age'] <= 15, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 49) & (dataset['Age'] <= 63), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 63, 'Age'] = 4\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"229980b7503985bea351a9eb74784811a58a2757"},"cell_type":"markdown","source":"#### 4.Embarked\n\n     * For embark field we map fill the missing values with S (mode)\n     * We then map the ports with numeric values S-->0,C-->1 and Q-->2"},{"metadata":{"trusted":true,"_uuid":"02a38a4e999b89f9fdc8690f1be0d19f633d6d29"},"cell_type":"code","source":"#Embarked\n\n\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n\nembarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\n\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)\n    \n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d37f6140d84d8d3aebef8810a2a85a8d1a356ac"},"cell_type":"markdown","source":"#### 5.Fare\n\n     * We fill in the missing values in fare band with the median values grouped by the pclass features.\n     * The reason is simple the fare value depends on the Pclass ticket.\n     * We then create a fare band and then we group them"},{"metadata":{"trusted":true,"_uuid":"7e8501ab13dc092e3ac4439ca49b6c6bc3928708"},"cell_type":"code","source":"#Fare\n\ntrain[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\n\nfor dataset in train_test_data:\n    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\ntrain['FareBand'] = pd.qcut(train['Fare'], 4)\n\nprint (train[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean())\n\nfor dataset in train_test_data:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a14d8db0a6e28abf0c9491a3d68c15efcd184e15"},"cell_type":"markdown","source":"#### 6. Cabin\n         * Fill the missing values by taking the median value grouped by Pclass and cabin\n         * We then create a cabin mapping and group them together"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"9c36cdf70fc086a1af5aad41c80fbc850590b462"},"cell_type":"code","source":"#Cabin\n\ntrain.Cabin.value_counts()\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]\n\nPclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\nPclass2 = train[train['Pclass']==2]['Cabin'].value_counts() \nPclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3]) \ndf.index = ['1st class','2nd class', '3rd class'] \ndf.plot(kind='bar',stacked=True, figsize=(10,5))\ncabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)\n\ntrain[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58a543119d952620a088b0c72f6a45a20c8201a3"},"cell_type":"markdown","source":"#### 7. Family size"},{"metadata":{"trusted":true,"_uuid":"2a592f53a7b012d6b2e40e296730e90c1b83c39d"},"cell_type":"code","source":"#Family size\ntrain[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntest[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1\n\nfamily_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\nfor dataset in train_test_data:\n    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)\n\n\n#8.SibSp & Parch Feature\nfor dataset in train_test_data:\n    dataset['FamilySize'] = dataset['SibSp'] +  dataset['Parch'] + 1\n\nprint (train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())\n\nprint(\"---------------------------------------------\")\n\nfor dataset in train_test_data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n    \nprint (train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ecfe559dd4a8ac5fa78633b764788b2111e7441f"},"cell_type":"markdown","source":"#### 8. Pclass"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"30361e8670f6fb6bf63253c91d57208bc0b715b6"},"cell_type":"code","source":"#Pclass\n\nPclass1 = train[train['Pclass']==1]['Embarked'].value_counts()\nPclass2 = train[train['Pclass']==2]['Embarked'].value_counts()\nPclass3 = train[train['Pclass']==3]['Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57e7db2f62c63342a6e6ee3eb67ace12e7232a97"},"cell_type":"code","source":"#############################################################\n#      Step 6: Feature Selection                            #\n#############################################################","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9a84cb262115a15d7795670eceb2c67f5c9000a"},"cell_type":"code","source":"# delete unnecessary feature from dataset\n\nprint(\"Before\", train.shape, test.shape, train_test_data[0].shape, train_test_data[1].shape)\nfeatures_drop = ['Name', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'FamilySize']\ntrain = train.drop(features_drop, axis=1)\ntest = test.drop(features_drop, axis=1)\ntrain = train.drop(['PassengerId', 'FareBand'], axis=1)\ntest_pred  = test.drop(\"PassengerId\", axis=1).copy()\n\nprint(\"After\", train.shape, test.shape, train_test_data[0].shape, train_test_data[1].shape)\n\ntrain_data = train.drop('Survived', axis=1)\ntarget = train['Survived']\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"006015af8a3c6057e72e4c1a1204522cdc73852f"},"cell_type":"code","source":"train_data.shape, target.shape, test_pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8508f8588c12e7a14669dbd4ab034fc65907d9f"},"cell_type":"code","source":"#############################################################\n#      Step 7: Applying Different Models                    #\n#############################################################","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34705d29851ddfd3cbf041045824c897b5d6f6ca"},"cell_type":"code","source":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(train_data, target)\nY_pred = logreg.predict(test_pred)\nlogistic_acc = round(logreg.score(train_data, target) * 100, 2)\nlogistic_acc\n\ncoeff_df = pd.DataFrame(train.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)\n\n\n# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(train_data, target)\nY_pred = svc.predict(test_pred)\nsvc_acc = round(svc.score(train_data, target) * 100, 2)\nsvc_acc\n\n# Knn\nknn = KNeighborsClassifier(n_neighbors = 5)\nknn.fit(train_data, target)\nY_pred = knn.predict(test_pred)\nknn_acc = round(knn.score(train_data, target) * 100, 2)\nknn_acc\n\n# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(train_data, target)\nY_pred = gaussian.predict(test_pred)\ngaussian_acc = round(gaussian.score(train_data, target) * 100, 2)\ngaussian_acc\n\n# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(train_data, target)\nY_pred = decision_tree.predict(test_pred)\ndecision_tree_acc = round(decision_tree.score(train_data, target) * 100, 2)\ndecision_tree_acc\n\n# Random Forest\nrandom_forest = RandomForestClassifier(n_estimators=250)\nrandom_forest.fit(train_data, target)\nY_pred = random_forest.predict(test_pred)\nrandom_forest.score(train_data, target)\nrandom_forest_acc = round(random_forest.score(train_data, target) * 100, 2)\nrandom_forest_acc\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13906edd905f2e178c7064f27e6a0704be88af20"},"cell_type":"code","source":"from xgboost import XGBClassifier\nclassifier = XGBClassifier(max_depth=1000, n_estimators=1500, learning_rate=0.09)\nclassifier.fit(train_data,target)\nY_pred = classifier.predict(test_pred)\nclassifier.score(train_data, target)\nacc_xgb = round(classifier.score(train_data, target) * 100, 2)\nacc_xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43fe130ddd6ea3522d85e006d4eec8a37792c43e"},"cell_type":"code","source":"#############################################################\n#      Step 8: Model Selection                              #\n#############################################################","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec9ce3a47c2a8eed10c385e09ec4d391193b0b4b"},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Logistic Regression', 'Support Vector Machines','KNN',\n              'Naive Bayes','Decision Tree','Random Forest','XGBoost'],\n    'Score': [ logistic_acc, svc_acc,knn_acc,gaussian_acc\n              ,decision_tree_acc,random_forest_acc,acc_xgb ]})\nmodels.sort_values(by='Score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb3bdd1d9a8a134e3107057822e1f6c25662bab9"},"cell_type":"code","source":"#############################################################\n#      Step 8: Result Submission                            #\n#############################################################","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82413f7bfe132004c6dbcd58fba7922458facbd8"},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\n\nsubmission.to_csv('submission.csv', index=False)\nsubmission = pd.read_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c1893fdfc7bd54d086e76d87554096636832303"},"cell_type":"markdown","source":"The accuracy for random forest is high as per the table. Hence we submit the result \nof the model applied to Kaggle."},{"metadata":{"trusted":true,"_uuid":"1153be598bdb53c9d1b329f30010fa5b7d7ad3d0"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}