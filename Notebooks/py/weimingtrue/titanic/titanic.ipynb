{"cells":[{"metadata":{"_cell_guid":"406b3d5e-63b8-45ce-8efb-e893e49bb89c","_uuid":"781d734876bc9987e68d45aab12710b027e278a3"},"cell_type":"markdown","source":"## Contents:\n* [Summary](#sec1)\n* [Setting up](#sec2)\n* [Intuitive observation](#sec3)\n* [EDA](#sec4)\n* [Data Cleaning](#sec5)\n* [Preprocessing](#sec6)\n* [Feature Engineering](#sec7)\n* [A Closer Look at Processed Data ](#sec8)\n* [Feature Selection](#sec9)\n* [Tuning  Hyperparameters](#sec10)\n* [Training Models](#sec11)\n* [Making Predications and Submission](#sec12)\n\n\n## Summary<a class=\"anchor\" id=\"sec1\"></a>\n\nThis is my first attemp for a Kaggle competetion. \nAfter many trials and reserach, I managed to improve my score from 0.77033 to 0.79425 .\nIt may not seem a drastic increase, but my standing in this competetion went from 4000 to 2000!\nAlthough there's still room for imporvement, I will leave this notebook as is until I have more free time. \n\nIn this work, I first applied some basic data EDA, then ventured into feature engineering and feature selection.\nWhen training machine learning models, I tried to separate data into subgroups by theri travel companion(family, acquiantance and alone) and applied models best fit each group, with a pessimistic voting process. My reasonings are individuals in such tragedy are generally ill-fated, if a small fraction of algorithms predicted one to be victim, he/she would likely be so.\nI used this [dataquest notebook](https://github.com/dataquestio/solutions/blob/master/Mission188Solution.ipynb) as a template, and tried a few different machine learning algorithms along the way. \n\nSome of my original ideas include: \n1. Find family, cabin and ticket information in the whole dataset (test + train). \n    a. Last names are extracated and combined with other ticket info to locate unique families which are not defined under the scope of 'Parch' and 'SibSp'.\n    b. Passengers travelling in the same cabin or on the same ticket are assumed to be acquiantance. \n3. VIPs, passengers with important title (e.g. Duchess) or simply rich(suite passengers).\n4. Age divisions that reflect the social reality of early 20th century, when \"teenager\" as an age group does not exist but most people start working at 12 or 15. "},{"metadata":{"_cell_guid":"a98a576c-8778-41aa-ae2b-19f0670ebde3","_uuid":"e0d427b5c1cbbdc2f39b4ca7808a81f995244a1f"},"cell_type":"markdown","source":"## Setting up<a class=\"anchor\" id=\"sec2\"></a>\nSetting up environment, loading data and some minor corrections in dataset. \nThis notebook is based on Python 3. "},{"metadata":{"_cell_guid":"39302bfc-53dd-4143-b3c0-c78220720008","_uuid":"69bf125e06aa748c859339569bba90887b0b7777","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nimport re\nimport pandas as pd\nimport numpy as np\nfrom IPython.display import display, HTML\n\n#For Kaggle \ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n#For win machine, csv files stored at the same folder as notebook\n#train = pd.read_csv('train.csv')\n#test = pd.read_csv('test.csv')\n\n#The PassengerId col is made for indexing, especially when one plan to merge train and test for feature engineering \ntrain = train.set_index(\"PassengerId\")\ntest = test.set_index(\"PassengerId\")\n\ntrain_sur = train['Survived']\n#keep survival data, add back after preprocess\ncombined = pd.concat([train.drop(\"Survived\",axis=1),test])\ntrain.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4dd4fa16-5e39-475e-a1d7-507eaee3689c","_uuid":"3514881efc8ac577a5175ef9aed19fa938b21686","collapsed":true,"trusted":true},"cell_type":"code","source":"combined.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"71fb1443-be3f-4592-a0b0-64c0df8846fc","_uuid":"47df91a025dab83485e76794c1cc20bd6419ee95","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"test.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"47df6ad3-59ab-4b95-96fb-ba1f2ff3ee2c","_uuid":"8ba36a80fe4d6275049555d4c3b6c6c742b1769e"},"cell_type":"markdown","source":"## Intuitive observation<a class=\"anchor\" id=\"sec3\"></a>\nSome observations from the data summary:\n\n1. 20% of age info is missing from train and test, this make it hard to draw creditble info from this factor;\n2. Only 20% of Cabin info is avaliable in train and test;\n3. A few passengers' Embarked port and Fare info missing, can be filled with average fare or most popular port;"},{"metadata":{"_cell_guid":"c096d884-119e-4db6-9364-45854249360a","_uuid":"3875712d5f9b18093fa130724c6237458936388c","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"combined.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5e787166-1f10-4882-9211-e644a7b8d90b","_uuid":"43a658b5957605478af53e3b1d2e04cb30c95572","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"combined[combined[\"Embarked\"].isna()]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4cb334de-f261-46f4-8d49-86f8c0510e93","_uuid":"97f03f7d5e3e853f6f2696f36f77259c52e00324","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"combined[combined[\"Fare\"].isna()]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"33f0e0d2-6f64-4fcf-bb7a-cbe1ff3610ac","_uuid":"55bb69140e571ef46b02d0f5a8d156c7b24496c7"},"cell_type":"markdown","source":"A closer look at the data reveals:\n4. Ticket column composed of a prefix and number, could be used to identify groups. \n5. Fare is the total price of a ticket. multiple passenger could be on the same ticket, a per person fare will be better to describe the travel expense, and the ticket holder's socio-economical status;\n6. Name format LastName, Ttile. First [Middle Name (Nee)];\n7. Wives share the name of their husbands."},{"metadata":{"_cell_guid":"0d8987c9-dd22-411b-9be7-5cdce83a2982","_uuid":"c3eb0e175d405459936b8d993ce35e08c6397d89"},"cell_type":"markdown","source":"## EDA <a class=\"anchor\" id=\"sec4\"></a>\nNext up we will make some simple plots to help understanding the basic landscape of features that have significant impact on passengers' survival. \nFirst is a age/sex survival histogram:"},{"metadata":{"_cell_guid":"4e1c6131-f843-4907-bd84-26c59c019289","_uuid":"5b9121982aed5bc9b02b1cd7d0ac8f32f3eca389","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"sur =train[train[\"Survived\"] == 1].copy()\ndec = train[train[\"Survived\"] == 0].copy()\n#nbins  = 1 + log2(N) ~ 11\nsur[\"Age\" ].plot(kind='hist',alpha=0.5,color='red',bins=11)\ndec[\"Age\"].plot(kind='hist',alpha=0.5,color='blue',bins=11,title =\"Death/Survival count by by age, na are filled as -0.5\" )\nplt.legend(['Survived','Died'])\nplt.show()\nsur_no_na= sur[sur[\"Age\"]> 0]\ndec_no_na = dec[dec[\"Age\"]> 0] \nbins = [-5,5,15,30,45,60,100]\nsur_no_na[\"Age\" ].plot(kind='hist',alpha=0.5,color='red',bins=bins)\ndec_no_na[\"Age\"].plot(kind='hist',alpha=0.5,color='blue',bins=bins,title =\"Death/Survival count by Age groups, w/O missing values\" )\nplt.xticks(bins,[\"NA\",\"Infant\",\"Child\",\"Yound Adult\",\"Adult\",\"Middle Age\",\"Senior\"])\nplt.legend(['Survived','Died'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c7fff18e-6c08-43e1-9ee2-e2adfc2f27ed","_uuid":"867511dd3ac762494dac9554ba07686c749a22b7"},"cell_type":"markdown","source":"Some simple observation:\n1. Very high fatality rate for male teenagers and older\n2. High survival rate(>50%) for infant of both sexes\n3. High survival rate (>50%) for female of all ages, except child\n4. Child is the only age group (5-12) that male has a higher survivor rate than female\n\nThe following plot shows different survival rates among different passenger class. "},{"metadata":{"_cell_guid":"7085fdee-ce6e-4f21-9105-5d2ef6fe26c8","_uuid":"1fa9ebb9e9d6e0732fdb1b1431e4bb2a8ac18faf","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"#nbins  = 3\nfrom matplotlib.ticker import FormatStrFormatter\nss  = train.pivot_table(index=[\"Pclass\",\"Sex\"],values='Survived').copy()\nss.plot(kind='bar',alpha=0.5,color='red',title=\"Survival rate of each sex across different classes\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b7ce6a62-f767-4b0e-aee2-4873e29e432d","_uuid":"14bf0247af7ed9578a652473a86b9f092ed77cd7"},"cell_type":"markdown","source":"## Data Cleaning <a class=\"anchor\" id=\"sec5\"></a>\n\nSome simple deas: \n1. Divide age columns into different groups. \n2. Extract cabin info and store in a two-way dictionary to associate people \n3. Extract last name, main name (first + second, if any), titles from the name column.\n4. Use real fare (per person fare) for fare classification\n5. Ticket prifix and No. can be used to associate people as well"},{"metadata":{"_cell_guid":"f6bfbea2-c61b-41e8-aabc-fc17df4af31e","_uuid":"35f78ff06611a7eb2870d28138842dd06a1bed34","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"def process_na(df):\n    \"\"\"Fill na w. most probable values\"\"\"\n    df[\"Embarked\"] = df[\"Embarked\"].fillna( df[\"Embarked\"].mode().iloc[0])\n    df[\"Cabin\"] = df[\"Cabin\"].fillna(\"Unknown\")\n    return df\n\ndef process_age(df):\n    \"\"\"20% of age info is missing, handle with care\"\"\"\n    df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n    cut_pts = [-1, 0, 5, 15, 30, 45, 65, 100]\n    #Given the accident took place in the early 2oth century, \n    #it make sense to category age by the standard then.\n    #I should probably differentiate age groups between male and female,\n    #but the improvement maybe marginal, will try next time\n    age_labels = [\"NA\",          #[-1]\n                  \"Infant\",      #[0-5) \n                  \"Child\",       #[5,15)\n                  \"Young Adult\", #[15,30)\n                  \"Adult\",       #[30,45)\n                  \"Middle Age\",  #[45,65)\n                  \"Senior\"]      #[65,100)\n    df[\"Age_cat\"] = pd.cut(df[\"Age\"],cut_pts, labels=age_labels)\n    return df\ncombined = process_na(combined)\ncombined = process_age(combined)\ncombined[combined[\"Fare\"].isna()]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c442f8fa-14c8-4bce-92fb-2c1d77e895db","_uuid":"f1628c4bcb7abc2a0484baaf47d38ddf7b1701f1"},"cell_type":"markdown","source":"Next we fix NA in fare column, using average vlaues of same class and embarked port.\n\nIdeally, I sould place this step after calculating real fare, i.e., per person fare, but there's only one passenger traveling with missing fare info, and records shows he travels alone. \nSo will just proceed here, to avoid the trouble of flagging a na value in the data.\n\nAfter filling all NAs, we generated this grid plot to demonstrate pair-wise relation in the dataset. "},{"metadata":{"_cell_guid":"1473ded2-9b77-468b-8007-951575c1a49f","_uuid":"599cf5e76d05ce78606c60a17d10d6a4fff3ffc4","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"Fare_nas = combined.loc[combined[\"Fare\"].isnull()]\nFare_pt = combined.pivot_table(index=[\"Pclass\",\"Embarked\"],values='Fare').copy()\n\nfor i in Fare_nas.index:\n    p,e = test.at[i,\"Pclass\"], test.at[i,\"Embarked\"]\n    if i in combined.index:\n        combined.loc[i,\"Fare\"] = float(Fare_pt.loc[p,e])\n        \ng = sns.PairGrid(combined)\ng.map_diag(plt.hist)\ng.map_offdiag(plt.scatter);","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bd943f66-cae8-4d46-8a2d-2b315ce2747b","_uuid":"a29d2bf7762248271a61c1a1645c2ae9f3108589"},"cell_type":"markdown","source":"Simple observations from the Pclass row:\n1. Number of passengers in class 1 and 2 sum to that of class 3.\n2. Age distribution seems uniform in all three class.\n3. Passengers in class 3 have more larger families.\n4. There seems to be two tier of fare in class 1, searching online and I find there are two special suites in class 1, apart from normal cabins.  \n\nMoving on to age row:\n1. The age-Sibsp chart seems normal: the elder one is, the less sibling or spouse he/she may have.\n2. The flipped pyramid structure in age-Parch chart also seems in its natural form.\n3. As age is uniformly distributed in all pclass, so should fare.\n\nNext is the SibSp row: \n1. The two arms in the distribution both represents large families, from the perspective of either paretns and children.\n2. In SibSp-Fare, the larger your family, the less expensive your ticket would be. \n\nOn Parch row:\n1. Same as SibSp-Fare, family size implies cheaper fare."},{"metadata":{"_cell_guid":"b8be4e6a-4a74-4ae1-9c66-b825f4322537","_uuid":"57ee2ebb54f4d9ac54aeae34ff319988ef8d55fd"},"cell_type":"markdown","source":"## Preprocessing  <a class=\"anchor\" id=\"sec6\"></a>\nNow I move to extract more info from the dataset. \nSome obvious goals are :\n1. Titles: e.g., doctors, officers or royalty. These people may have socio-economical status that impact their survival.\n2. Couples: in titanic dataset, couples share the same name, this makes it easy to match them. Once we find a couple and their family, we can set their rols in the family. Such roles have definitive impact on their survival rate.\n3. Ticket information can help group passengers:\n    a. many passengers traveled with acquiantance, colleagues, friends etc. While their bond is not as strong as family, these connection still plays a part on their survival rate.\n    b. some familiy members may not share the same last name, like a father-in-law or a maid, but their bond is at least better than acquiantance. It's necessray to sort such relations out."},{"metadata":{"_cell_guid":"6ed47b68-30c7-48bb-9ce7-cf782d74544b","_uuid":"0671fff316e813a051e9893f617a61cd46aed162","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"cabin_cat = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T', 'U']\nocp_info = dict()\n# ocp_info is a two way dictionary that stores all ocupy info, it is more ideal to store in a matrix, but this will work\n\n#Credit: https://github.com/matthagy/titanic-families\nname_rgx = re.compile(r'''\n^                 # Explicit start\n       \\s*\n  ([^,]+)         # Last Name: 1\n     , \\s+\n  ([^.]+) \\.      # Title:2\n       \\s+\n  ([^(\"]+)?       # Main name:3\n       \\s*\n  (?:\n    \"([^\"]+)\"     # Nick name:4\n  )?\n       \\s*\n  (?:             # Other name:5\n     \\(\n        ([^)]+)\n      \\)\n   )?\n''', re.VERBOSE)\n\ndef process_fare(df):\n    \"\"\"Process the fare using real fare, i.e. per person fare\n    Apart 1st, 2nd and 3rd class, there were two luxury first class suites on titanic, which I marked as Luxury.\n    I do not want to look up the price range but based my division on the fare distribution. \n    \"\"\"       \n    cut_points = [-1,1,10,25,60,1000]\n    label_names = [\"free\",       # [0]Free ticket, ship crew \n                   \"third\",    # [1,10)Third class tickets\n                   \"second\",   # [10,25)econd class tickets\n                   \"first\",   # [25,60)First class tickets\n                   \"luxury\"]     #[60,1000) Upper first class tickets\n    df[\"Fare_cat\"] = pd.cut(df[\"real_fare\"],cut_points,labels=label_names)\n    return df\n\n\ndef process_titles_lastname(df):\n    \"\"\"Extract and categorize the title and last name from the name column \"\"\"\n    for pid in df.index:\n        name = df.at[pid,\"Name\"]\n        m = name_rgx.match(name)\n        if not m:\n            raise ValueError('bad name %r' % (name,))\n        df.loc[pid,\"LastName\"] = m.group(1).strip()\n        df.loc[pid,\"Title\"] = m.group(2).strip()        \n        if m.group(3) is not None:\n            df.loc[pid,\"MainName\"] = m.group(3).strip()\n        else:\n            df.loc[pid,\"MainName\"] = \"\"\n                    \n        if m.group(4) is not None:\n            df.loc[pid,\"OtherName\"] = m.group(4).strip()\n        else:\n            df.loc[pid,\"OtherName\"] = \"\"\n                    \n        if m.group(5) is not None:\n            df.loc[pid,\"NickName\"] = m.group(5).strip()\n        else:\n            df.loc[pid,\"NickName\"] = \"\"\n            \n    titles = {\n        \"Mr\" :         \"Mr\",\n        \"Mme\":         \"Mrs\",\n        \"Ms\":          \"Mrs\",\n        \"Mrs\" :        \"Mrs\",\n        \"Master\" :     \"Master\",\n        \"Mlle\":        \"Miss\",\n        \"Miss\" :       \"Miss\",\n        #Will differentiate by pclass for all officer and royalty\n        \"Capt\":        \"Officer\",        \n        \"Major\":       \"Officer\",        \n        \"Col\":         \"Officer\",       \n        \"Dr\":          \"Officer\",\n        \"Rev\":         \"Officer\",        \n        \"Jonkheer\":    \"Royalty\",\n        \"Dona\":        \"Royalty\",\n        \"Don\":         \"Royalty\",\n        \"Sir\" :        \"Royalty\",\n        \"Lady\" :       \"Royalty\",        \n        \"the Countess\": \"Royalty\"  \n    }\n    \n    df[\"Title\"] = df[\"Title\"].map(titles)\n    #Add embarked and ticket info to lastname can distinguish different families of the same last name.\n    df[\"LastName\"] = (df[\"LastName\"]+ df[\"Embarked\"] + df[\"Pclass\"].apply(str) + \n                     df[\"Ticket_Prfx\"] + df[\"Ticket_Range\"])\n    \n    return df\n\ndef process_cabin(df):\n    \"\"\"\n    This function generate a two-way dictionary, ocp_info, where each passenger's cabin info and \n    each cabin's passgener info is stored.\n\n   \n    \"\"\"\n    cabin_info = df[\"Cabin\"].to_dict()\n    \n    for pid in cabin_info.keys():\n        if pid not in ocp_info.keys():\n            ocp_info[pid] = []\n        \n        for cab in cabin_info[pid].split():\n            #df.loc[pid,\"Cabin_\"+cab[0]] += 1\n            ocp_info[pid].append(cab)\n            if cab in ocp_info.keys():\n                ocp_info[cab].append(pid)\n            else:\n                ocp_info[cab] = [pid]\n    \n    return df\n   \ndef create_dummies(df,column_name):\n    \"\"\"Create Dummy Columns (One Hot Encoding) from a single Column\n\n    Usage\n    ------\n\n    train = create_dummies(train,\"Age\")\n    \"\"\"\n    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n    df = pd.concat([df,dummies],axis=1)\n    return df\n\ndef process_ticket(df):\n    extracted_tickets  = df[\"Ticket\"].str.extract('([0-9]+)$',expand=False)\n    extracted_tk_pref  = df[\"Ticket\"].str.extract('^(.+) [0-9]+$',expand=False)\n    extracted_tickets = list(map(lambda x: 0 if x is np.nan else int(x), extracted_tickets))\n    extracted_tk_range = list(map(lambda x: 0 if x is np.nan else str(int(x/100)), extracted_tickets))\n    extracted_tk_pref = list(map(lambda x: \"No.\" if x is np.nan else x, extracted_tk_pref))\n    df[\"Ticket_No\"] = extracted_tickets\n    df[\"Ticket_Range\"] = extracted_tk_range\n    df[\"Ticket_Prfx\"] = extracted_tk_pref\n    return df\n\ndef preprocess(df):  \n    df = process_cabin(df)\n    df = process_ticket(df)\n    \n    df = process_titles_lastname(df)\n    \"\"\"\n    for col in [\"Sex\",\"Age_cat\"]:#\"Pclass\",\"Cabin_cat\",\"Age\"\n        df = create_dummies(df,col)    \"\"\"\n    return df\n\ndef assign_Age_cat(age):\n    \"\"\"This function is used to assign age cat for those with no age info, based on an educated guess.\"\"\"\n    if 0 < age < 5:        cat = \"Infant\"\n    elif 5 <= age < 15:    cat = \"Child\"\n    elif 15 <= age < 30:   cat = \"Young Adult\"\n    elif 30 <= age < 45:   cat = \"Adult\"\n    elif 45 <= age < 65:   cat = \"Middle Age\"\n    elif 65 <= age < 100:  cat = \"Senior\"\n    else:                  cat = \"NA\"\n    \n    return cat\n\ndef assign_ac_by_title(title):\n    \"\"\"This function is used to assign age cat simply from title, this will result in a lot error\"\"\"\n\n    if title == \"Miss\" or title == \"Master\":\n        return \"Child\"\n    \n    if title == \"Mr\"  or  title == \"Mrs\":\n        return \"Young Adult\"    \n    \n    if title == \"Officer\":\n        return \"Middle Age\"\n    \n    if title == \"Royalty\":        \n        return \"Senior\"\n    \n    return \"NA\"\n\n\ncombined[\"immediate_family\"] = combined[\"Parch\"] + combined[\"SibSp\"]\n\ncombined = preprocess(combined)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9e88cc05-35f9-44bc-961d-18e96ca0db92","_uuid":"49365470a28ac5b795d25e1cd0e1f4b103e67746"},"cell_type":"markdown","source":"Next we try to fill out missing age info, reaonably. The ages are divided to the following groups:<br>\nInfant(<5), Child(5-15),  Young Adult(15-30), Adult(30-45),Middle Age(45-65),Senior(65-100)<br>\n1. If a passenger, has immediate family, try to guess age group from that\n2. If a passenger travels with a family group, but has no family on board, try to fit he/she to a friend, servant, maid role, based on sociao-eco\n3. If a passenger travels with acquaitance, try to use the mean age group "},{"metadata":{"_cell_guid":"07927672-d858-40af-bd45-b39a8424d26d","_uuid":"f45d48eee1a5089b2604c1bc70ceedeeaee8c40f","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"#Assign three kinds of travel group \n#1 family, has same last name, same or successive ticket number\n#2 passengers on same ticket or passengers share a cabin as acquaintance\n#3 alone\n\nfamilies = list(set(combined[\"LastName\"]))\n\ncombined[\"family_size\"] = 1\ncombined[\"n_cabin_mates\"] = 1\ncombined[\"n_ticket_holders\"] = 1\n\ncombined[\"group_id\"]= 0\ncombined[\"group_type\"] = \"0\"\ncombined[\"group_size\"] = 1\n\ncp_id = 0\ncombined[\"cp_id\"] = -1\ncombined[\"family_has_couple\"] = 0\nfor pid in combined.index:\n    if combined.loc[pid,\"cp_id\"] != -1:\n        continue\n    cp = combined[combined[\"MainName\"] == combined.loc[pid,\"MainName\"]]\n    if len(cp) == 2:       \n        \n        if ( set(combined.loc[cp.index,\"Sex\"]) == set([\"female\",\"male\"])) and        (combined.loc[cp.index[0],\"Age\"] > 15 or combined.loc[cp.index[0],\"Age\"] < 0) and         (combined.loc[cp.index[1],\"Age\"] > 15 or combined.loc[cp.index[1],\"Age\"] < 0):\n             \n            \n            #Needs fixing, a Dr. and Mrs will not be considered as couple\n            combined.loc[cp.index,\"cp_id\"] = cp_id\n            cp_id += 1    ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c3f0a45d-46c8-4a94-a8ce-3fe9cc5682d7","_uuid":"738d8cea842020626a27446333083bd9ed064d8e"},"cell_type":"markdown","source":"## Feature Engineering<a class=\"anchor\" id=\"sec7\"></a>\nDigging further to find family information"},{"metadata":{"_cell_guid":"17dcec2e-606f-433e-9be5-13d002300ece","_uuid":"1c17fbb70f9d924b024e8e30cc55a177abdde126","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"f_dict = dict(zip(families, range(len(families))))\ng_counter  =len(f_dict)\ncombined[\"family_has_children\"] = 0\ncombined[\"family_has_senior\"] = 0\ncombined[\"family_role\"] = \"no_role\"\nfor ln in families:\n    f_group = combined[combined[\"LastName\"] == ln]\n    fs = max(len(f_group.index),combined.loc[f_group.index,\"immediate_family\"].max())\n    #Kaggle data doesn't contain all passengers, so parch + sibsp is more reliable than last name look up\n    #Although, kaggle data itself contains a few errors.\n    #if a passenger has a family, assign he/she to the family group\n    combined.loc[f_group.index, \"family_size\"] = fs\n    combined.loc[f_group.index, \"group_id\"] = f_dict[ln]\n    n_children, n_seniors  = 0, 0\n    for f_member in f_group.index:\n        age, title = combined.loc[f_member,\"Age\"],combined.loc[f_member,\"Title\"]\n        if 0< age <= 15 or title == \"Miss\" or title == \"Master\":\n            combined.loc[f_member,\"family_role\"] = \"Child\"\n            n_children += 1\n            continue\n        if age > 65:\n            combined.loc[f_member,\"family_role\"] = \"Senior\"\n            n_seniors += 1\n            continue\n        if combined.loc[f_member,\"cp_id\"] != -1:\n            if combined.loc[f_member,\"Sex\"] == \"male\":\n                combined.loc[f_member,\"family_role\"] = \"Father\"\n            else:\n                combined.loc[f_member,\"family_role\"] = \"Mother\"\n        \n            \n    combined.loc[f_group.index,\"family_has_children\"] = n_children\n    combined.loc[f_group.index,\"family_has_senior\"] = n_seniors\n\n    if fs > 1:\n        combined.loc[f_group.index, \"group_type\"] = \"family\"\n        combined.loc[f_group.index, \"group_size\"] = fs\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"34aed91e-de65-4269-a998-93349d00d6ac","_uuid":"beaadffbd226d4aa496e8cdb9d68a9eaf769c5f1"},"cell_type":"markdown","source":"Next we work on ticket info and cabin info\n\nTry to guess age info based on title, family info, travel company(use average of respective group)\nNext we will try to find family or travel group for travelers.\n\n1. Search through families: \n    a. if one has a unique last name, label the group_label as lone traveler, with group_size 1 \n    b. if one has more than one family, label it  travel_group as the family name, with proper group_size \n\n2. Search ticket info to find travel groups.\n     a. For lone travelers, check if ticket/cabin is unique:\n        i. if so a real loner\n        ii. use fellow traveler's  label if same ticket, or cabin, increase corresponding group size\n     b. For families, check if everyone has same/consecutive ticket cabin number.\n        \n3. From these processes, we will generate the following attributes: group_label and group_size"},{"metadata":{"_cell_guid":"9a8dc00e-e85d-470a-aa9d-10580aa529f3","_uuid":"725ae21362ef7d0d1d5b83306bb4d9a4a753b2df","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"tk_lst = list(set(combined[\"Ticket\"]))\nfor tk in tk_lst:\n    t_group = combined[combined[\"Ticket\"] ==  tk]\n    combined.loc[t_group.index, \"n_ticket_holders\"] = len(t_group.index)\n    n_t  = len(t_group.index)\n    for tm in t_group.index:\n        combined.loc[tm, \"real_fare\"] = combined.loc[tm, \"Fare\"] / n_t\ncombined = process_fare(combined)        \n\nfor pid in combined.index:\n    t_group = combined[combined[\"Ticket\"] == combined.loc[pid,\"Ticket\"]]\n    \n    if combined.loc[pid,\"group_type\"] != \"0\":\n        continue\n    ln = combined[\"LastName\"].at[pid]\n\n    if ocp_info[pid] != ['Unknown']:#Has cabin info\n        cabin_lst =[x for x in ocp_info[pid]]\n        #All the cabins in the ticket\n        c_group  = list(set([traveler for cabin in cabin_lst for traveler in ocp_info[cabin] if len(cabin)>1]))\n        combined.loc[c_group, \"n_cabin_mates\"] = len(c_group)\n    else:\n        #passenger with no cabin info are assumed to be alone.\n        combined.loc[pid,\"n_cabin_mates\"] = 1\n        c_group  = []\n\n    co_travelers = pd.Index(sorted(set(list(t_group.index) +  c_group)))\n    #index of fellow travelers\n    dominant_ln = combined.loc[co_travelers,\"LastName\"].value_counts().index[0]\n    dominant_fs = len(combined[combined[\"LastName\"] == dominant_ln].index)\n    dominant_fg = combined[combined[\"group_id\"] == f_dict[dominant_ln]].index    \n    #Assign group next:     \n    \n    #if a lone passenger shares cabin/ticket with a family, assign this passenger to the family\n    if  dominant_ln != ln and dominant_fs > 1:\n        co_travelers = pd.Index(sorted(set(list(t_group.index) +  c_group + list(dominant_fg))))\n        for p in co_travelers:\n            combined.loc[p, \"group_type\"] = \"family\"\n            combined.loc[p, \"group_size\"] = len(co_travelers)\n            combined.loc[p, \"group_id\"] = f_dict[dominant_ln]\n\n    #else if a group of passenger travels together, assign as travel companions      \n    elif dominant_fs == 1 and len(co_travelers)> 1:\n\n        for p in co_travelers:\n            combined.loc[p,\"group_type\"] = \"acquaintance\"\n            combined.loc[p,\"group_size\"] = len(co_travelers)\n            combined.loc[p,\"group_id\"] = g_counter       \n\n        g_counter += 1\n    else:\n        combined.loc[pid, \"group_type\"] = \"alone\"\n        combined.loc[pid, \"group_size\"] = 1","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9ee52b1a-11c0-4da7-ada1-6962034ad0d9","_uuid":"844bd7afec6e60dec106a5cccfa9996751b30194","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"#Assign age cat for couples, if both NA, assume Middle age\nfor couple_id in range(cp_id):\n    cp = combined[combined[\"cp_id\"] == couple_id].index\n    age_cats = set(combined.loc[cp,\"Age_cat\"])\n    # mark has couple in the family \n    tag = combined[combined[\"group_id\"] == combined.loc[cp[0],\"group_id\"] ]\n    combined.loc[tag.index,\"family_has_couple\"] = combined.loc[cp[0], \"cp_id\"]\n    if \"NA\" not in age_cats:\n        continue\n    \n    if age_cats == set([\"NA\"]):\n        combined.loc[cp,\"Age_cat\"] = \"Middle Age\"\n    elif \"NA\" in age_cats:\n        non_NA_cat = list(age_cats - set([\"NA\"]))[0]\n        combined.loc[cp,\"Age_cat\"] = non_NA_cat","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"afb74e19-811e-4dfb-8921-b300f699781f","_uuid":"9ad365d05427ed61c91248585a407c026a4a54d4"},"cell_type":"markdown","source":"VIPs are passengers of high social status, female VIPs have good survival chance, while male VIP face terrible fate.\nFor now, VIP are assigned to passegners with sernior titles, or passenger with luxury tickets. "},{"metadata":{"_cell_guid":"314a32c7-fd1f-41d2-a79c-a81d3d81babc","_uuid":"7b516315cb042a63fd6483b93e0e0804818093ed","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"combined[\"isVIP\"] = 0\n\nfor pid in combined.index:\n    if (combined.loc[pid,\"Fare_cat\"] == \"luxury\") or (combined.loc[pid,\"Pclass\"] == \"One\" and (combined.loc[pid,\"Title\"] == \"Officer\"))  or (combined.loc[pid,\"Title\"] == \"Royalty\"):\n        combined.loc[pid,\"isVIP\"] = 1\n        if combined.loc[pid,\"cp_id\"] != -1: #\"family\":\n            cp = combined[combined[\"cp_id\"] == combined.loc[pid,\"cp_id\"] ]\n            combined.loc[cp.index,\"isVIP\"] = 1","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"30af348e-c73b-4818-9bdb-3117eb56e828","_uuid":"4ee97176abc8778438c7adc45fbd7ed4ab2ae380"},"cell_type":"markdown","source":"Ship crew naturally bare more responsibly in situation like this, and the existance of free tickets provided an easy way to locate them.\nI actually looked up some of passengers with free tickets are actually crew members of another ship, but still they volunteered to serve in the chaos."},{"metadata":{"_cell_guid":"d0adfd91-e491-49eb-bbb8-bf92ade7c6cc","_uuid":"0a6b5adcaacde74c8c577737d8f6b0eae363dfa9","collapsed":true,"trusted":true},"cell_type":"code","source":"combined[\"isCrew\"] = 0\n\nstaff = combined[combined[\"real_fare\"] == 0].index\ncombined.loc[staff,\"isCrew\"] = 1","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0e145b1c-9818-448d-9f4b-e25ff4ffb7f2","_uuid":"a29b639318a6913639604c3795b42034a2561870","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"for pid in combined.index:\n    if combined.loc[pid,\"Age_cat\"] != \"NA\":\n        continue\n        \n    if combined.loc[pid,\"group_type\"] == \"acquaintance\":\n        aq_group = combined[\n            (combined[\"group_id\"] == combined.loc[pid,\"group_id\"]) \n            & (combined[\"Age\"] > 0)]\n        aq_avg_age =aq_group[\"Age\"].mean()\n        combined.loc[pid,\"Age_cat\"] = assign_Age_cat(aq_avg_age)\n        if combined.loc[pid,\"Age_cat\"] != \"NA\":        continue\n        \n    if combined.loc[pid,\"group_type\"] == \"family\":\n        f_group = combined[combined[\"group_id\"] == combined.loc[pid,\"group_id\"]]\n        if combined.loc[pid,\"family_has_couple\"] != 0:\n            cp = combined[combined[\"cp_id\"] == combined.loc[pid,\"family_has_couple\"]]\n            couple_age =  combined.loc[cp.index, \"Age\"]\n            if combined.loc[pid,\"Parch\"] == 2:\n                child_age = max(couple_age.min() - 18, 0.5)\n                combined.loc[pid,\"Age_cat\"] = assign_Age_cat(child_age)                \n                if combined.loc[pid,\"Age_cat\"] != \"NA\":        continue\n        #group has couple, try to assign member as ch,par\n    tmp_group = combined[\n        (combined[\"Pclass\"] == combined.loc[pid,\"Pclass\"]) &\n        (combined[\"Title\"] == combined.loc[pid,\"Title\"]) &\n        (combined[\"Embarked\"] == combined.loc[pid,\"Embarked\"]) &\n        (combined[\"Age\"] > 0)]\n    avg_age = tmp_group[\"Age\"].mean()        \n    combined.loc[pid,\"Age_cat\"] = assign_Age_cat(avg_age)\n    if combined.loc[pid,\"Age\"] == \"NA\":\n        combined.loc[pid,\"Age_cat\"] = assign_ac_by_title(combined.loc[pid,\"Title\"])\n        print(combined.loc[pid,\"Age_cat\"])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"258cce19-06ca-4702-9c02-9982da45e40e","_uuid":"9494fa547108a32e867801d9dbaf4890672063a4","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"int_to_eng = dict({1:\"First\",\n                  2:\"Second\",\n                  3:\"Third\"})\ncombined[\"Pclass\"] = combined[\"Pclass\"].map(int_to_eng)\ncombined[\"Pclass_Sex\"] =  combined[\"Sex\"] +  combined[\"Pclass\"]\n#combined.drop(\"family_size\",axis=1, inplace=True)\ncombined = create_dummies(combined,[\"Pclass_Sex\",\"family_role\",\"Age_cat\"])#,\"group_type\"])  \ncombined.to_csv(\"combined.csv\")\ntrain = combined.loc[train.index].copy()\ntrain[\"Survived\"] = train_sur\ntest = combined.loc[test.index].copy()   \nprint(\"Done Preprocessing!\\n\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e3959daf-e4e4-4512-bf43-96aee306bfec","_uuid":"c0e9aa7f582d9cd31c7c4bb5c8e4a53f4e9916af"},"cell_type":"markdown","source":"## A Closer Look at Processed Data<a class=\"anchor\" id=\"sec8\"></a>\nNow let's take a look at the features we generated.\nSome of the features I'm interested:\n1. Group size: how will this impact survival rate?\n2. Group type: family, acquiantance or lone traveler\n3. Survival rate for married couple, as well as their group sizes\n4. Survival rate for officer and royalty.\n5. Father/Mother survival rate"},{"metadata":{"_cell_guid":"296fa5a9-8595-45d7-b9d6-40132bf828ce","_uuid":"27fdf5fe107076506f1a8573e00fef787fb0d5a9","collapsed":true,"scrolled":false,"trusted":true},"cell_type":"code","source":"family_in_trian = train[train[\"group_type\"]==\"family\"]\nf_gs = family_in_trian.pivot_table(index=[\"group_size\"],values='Survived').copy()\nf_gs.plot(kind=\"bar\",label=\"Survival\",color=\"Red\",alpha=0.5, title=\"Survival rate VS family size\")\n \nf_gs = family_in_trian.pivot_table(index=[\"immediate_family\"],values='Survived').copy()\nf_gs.plot(kind=\"bar\",label=\"Survival\",color=\"Red\",alpha=0.5, title=\"Survival rate VS immediate family size\")\n#Odd group size 1 family, investigate\n#Seems necessary to differentiate small (2-4 members) families to larger ones(5-11)\n#The different fate of famiies, maybe due to how many under age members there are \n#and how many adults are avaliable to look after them. \nfp_gs = family_in_trian.pivot_table(index=[\"Pclass\"],values='Survived').copy()\nfp_gs.plot(kind=\"bar\",label=\"Survival\",color=\"Red\",alpha=0.5, title=\" Family Survival rate in different class\")\n#Has 0 or more than 3 immediate family is an indicator of vulnerability, while 1-3 immediate family helps with survival \n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8a9218b6-e798-4253-83be-af890eb7ee53","_uuid":"5ac370af9295e879700be4f1efc011bcaa6dbfef","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"acq_in_train =  train[train[\"group_type\"]==\"acquaintance\"]\naq_gs = acq_in_train.pivot_table(index=[\"Pclass\",\"group_size\"],values='Survived').copy()\naq_gs.plot(kind=\"bar\",color=\"Red\",alpha=0.5\n           , title=\"Survival rate of acquiantance groups of different sizes in 3 classes\")\n#acquaintance group have higher survival rate in first class. \n#Mid size groups fare better, but why no group larger than 3 in 3rd class?","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"521a3a0a-9db5-4764-bc4e-80add3afffa1","_uuid":"d77fd2487999264b5f75e87a2df129a678cd0c6c"},"cell_type":"markdown","source":"We want to make sure those passengers in a family but have no immediate family (i.e. Parch + SibSp = 0) have different survival rate compare to those travel alone. These following tables show these two group indeed had different fate."},{"metadata":{"_cell_guid":"c554b346-1831-465d-9e42-68a5033b63a1","_uuid":"4938396ba6c64946a68609f797bbf3e21cf381cb","collapsed":true,"trusted":true},"cell_type":"code","source":"f_alone = train[(train[\"group_type\"] == \"alone\") &(train[\"Sex\"] == \"female\")]\nm_alone = train[(train[\"group_type\"] == \"alone\") &(train[\"Sex\"] == \"male\")]\nf_no_imf = train[(train[\"group_type\"] == \"family\") &(train[\"immediate_family\"] == 0)]\nm_no_imf = train[(train[\"group_type\"] == \"family\") &(train[\"Sex\"] == \"female\") &(train[\"immediate_family\"] == 0)]\ndf1 = pd.crosstab(f_alone.Pclass, f_alone.Survived)\ndf2 = pd.crosstab(m_alone.Pclass, m_alone.Survived)\ndf3 = pd.crosstab(f_no_imf.Pclass, f_no_imf.Survived)\ndf4 = pd.crosstab(m_no_imf.Pclass, m_no_imf.Survived)\ndf1 = df1.style.set_caption(\"Female travels alone\") \ndisplay(df1)\ndf3 = df3.style.set_caption(\"Female without immediate family\")\ndisplay(df3)\n\ndf2 = df2.style.set_caption(\"Male travels alone\")\ndisplay(df2)\ndf4 = df4.style.set_caption(\"Male without immediate family\")\ndisplay(df4)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ac5ed26e-6a6f-4adf-8ad4-fe09af34ebfc","_uuid":"e56239a6eb3d728343fc7fdcef34e25792284c43","collapsed":true,"scrolled":false,"trusted":true},"cell_type":"code","source":"bins = [-5,5,15,30,45,60,100]\nfigs, axes = plt.subplots(nrows=2, ncols=2 ,squeeze=True)\nfigs.set_figheight(15)\nfigs.set_figwidth(15)\nfemale_alone_s = train[(train[\"group_type\"] == \"alone\")&(train[\"Sex\"]==\"female\")&(train[\"Survived\"] == 1)].copy()\nfemale_alone_d = train[(train[\"group_type\"] == \"alone\")&(train[\"Sex\"]==\"female\")&(train[\"Survived\"] == 0)].copy()\nmale_alone_s = train[(train[\"group_type\"] == \"alone\")&(train[\"Sex\"]==\"male\")&(train[\"Survived\"] == 1)].copy()\nmale_alone_d = train[(train[\"group_type\"] == \"alone\")&(train[\"Sex\"]==\"male\")&(train[\"Survived\"] == 0)].copy()\n\nlone_f_in_fg_s = train[(train[\"group_type\"]==\"family\")&(train[\"immediate_family\"]== 0)\n                     &(train[\"Sex\"]==\"female\")&(train[\"Survived\"]==1)].copy()\nlone_f_in_fg_d = train[(train[\"group_type\"]==\"family\")&(train[\"immediate_family\"]== 0)\n                     &(train[\"Sex\"]==\"female\")&(train[\"Survived\"]==0)].copy()\n\nlone_m_in_fg_s = train[(train[\"group_type\"]==\"family\")&(train[\"immediate_family\"]== 0)\n                     &(train[\"Sex\"]==\"male\")&(train[\"Survived\"]==1)].copy()\nlone_m_in_fg_d = train[(train[\"group_type\"]==\"family\")&(train[\"immediate_family\"]== 0)\n                     &(train[\"Sex\"]==\"male\")&(train[\"Survived\"]==0)].copy()\nfemale_alone_s['Age_cat'].value_counts(sort=False).plot(kind=\"bar\",alpha=0.5,color='red',ax=axes[0,0])\nfemale_alone_d['Age_cat'].value_counts(sort=False).plot(kind=\"bar\",alpha=0.5,color='blue'\n                ,title=\"Female lone traveler survival count by age\",ax=axes[0,0])\n#plt.legend(['Survived','Died'])\n\nmale_alone_s['Age_cat'].value_counts(sort=False).plot(kind=\"bar\",alpha=0.5,color='red',ax=axes[0,1])\nmale_alone_d['Age_cat'].value_counts(sort=False).plot(kind=\"bar\",alpha=0.5,color='blue'\n                ,title=\"Male lone traveler survival count by age\",ax=axes[0,1])\n#plt.legend(['Survived','Died'])\n#plt.show()\n\nlone_f_in_fg_s['Age_cat'].value_counts(sort=False).plot(kind=\"bar\",alpha=0.5,color='red',ax=axes[1,0])\nlone_f_in_fg_d['Age_cat'].value_counts(sort=False).plot(kind=\"bar\",alpha=0.5,color='blue'\n                ,title=\"Female traveler with no immediate family survival count by age\",ax=axes[1,0])\n#plt.legend(['Survived','Died'])\n\nlone_m_in_fg_s['Age_cat'].value_counts(sort=False).plot(kind=\"bar\",alpha=0.5,color='red',ax=axes[1,1])\nlone_m_in_fg_d['Age_cat'].value_counts(sort=False).plot(kind=\"bar\",alpha=0.5,color='blue'\n                ,title=\"Male traveler with no immediate family survival count by age\",ax=axes[1,1])\n\naxes[0,0].legend(['Survived','Died'])\naxes[0,1].legend(['Survived','Died'])\naxes[1,0].legend(['Survived','Died'])\naxes[1,1].legend(['Survived','Died'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c5607e3d-b742-428b-b460-2afb858edba6","_uuid":"349d66d8534818393e74e41529a966e68e9f5a76","collapsed":true,"scrolled":false,"trusted":true},"cell_type":"code","source":"#Survival rate for married couple\n#Father and Mother survival rate by pclass\nfigs, axes = plt.subplots(nrows=2, ncols=2 ,squeeze=True)\nfigs.set_figheight(15)\nfigs.set_figwidth(15)\ntrain[\"Pclass\"] = train[\"Pclass\"].map({\n    \"First\":1,\n    \"Second\":2,\n    \"Third\":3\n})\ndad_s = train[(train[\"family_role\"] == \"Father\")&(train[\"Survived\"] == 1)].copy()\nmom_s = train[(train[\"family_role\"] == \"Mother\")&(train[\"Survived\"] == 1)].copy()\n\ndad_d = train[(train[\"family_role\"] == \"Father\")&(train[\"Survived\"] == 0)].copy()\nmom_d = train[(train[\"family_role\"] == \"Mother\")&(train[\"Survived\"] == 0)].copy()\n\ndad_s['Age_cat'].value_counts(sort=False).plot(kind=\"bar\",alpha=0.5,color='red',ax=axes[0,0])\ndad_d['Age_cat'].value_counts(sort=False).plot(kind=\"bar\",alpha=0.5,color='blue'\n                                           ,title=\"Fathers survival count by age\",ax=axes[0,0])\n\nmom_s['Age_cat'].value_counts(sort=False).plot(kind=\"bar\",alpha=0.5,color='red',ax=axes[0,1])\nmom_d['Age_cat'].value_counts(sort=False).plot(kind=\"bar\",alpha=0.5,color='blue'\n                ,title=\"Mothers survival count by age\",ax=axes[0,1])\n\ndad_s['Pclass'].value_counts(sort=False).plot(kind=\"bar\",alpha=0.5,color='red',ax=axes[1,0])\ndad_d['Pclass'].value_counts(sort=False).plot(kind=\"bar\",alpha=0.5,color='blue'\n                                          ,title=\"Fathers survival count by Pclass\",ax=axes[1,0])\n\nmom_d['Pclass'].value_counts(sort=False).plot(kind=\"bar\",alpha=0.5,color='blue',ax=axes[1,1])\n#no mother died in first class, if this is placed after wife_s, it won't show pclass =1 \nmom_s['Pclass'].value_counts(sort=False).plot(kind=\"bar\",alpha=0.5,color='red'\n                ,title=\"Mothers survival count by Pclass\",ax=axes[1,1])\n\n\naxes[0,0].legend(['Survived','Died'])\naxes[0,1].legend(['Survived','Died'])\naxes[1,0].legend(['Survived','Died'])\naxes[1,1].legend(['Died','Survived'])\nplt.show()\ntrain[\"Pclass\"] = train[\"Pclass\"].map({\n    1:\"First\",\n    2:\"Second\",\n    3:\"Third\"\n})","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0c1111eb-9f20-4964-b153-cbea6f553c74","_uuid":"99db2761e4b89452792502811b01d1158cea285d"},"cell_type":"markdown","source":"Above charts showed surival rate for fathers and mothers have significant difference in different classes."},{"metadata":{"_cell_guid":"06a668b6-cad0-4b72-9ed5-4a43308a4575","_uuid":"c6853402d75d38dccbbf38ed6e6517b4c942b99e","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"officer = train[train[\"Title\"] == \"Officer\"]\nroyalty = train[train[\"Title\"] == \"Royalty\"]\n\"\"\"figs, axes = plt.subplots(nrows=2, ncols=2 ,squeeze=True)\nfigs.set_figheight(15)\nfigs.set_figwidth(15) \"\"\"\nop = officer.pivot_table(index=[\"Sex\",\"Age_cat\"],values='Survived').copy()\nop.plot(kind=\"bar\",color=\"Red\",alpha=0.5\n           , title=\"Survival rate of officers\")\nrp = royalty.pivot_table(index=[\"Sex\",\"Age_cat\"],values='Survived').copy()\nrp.plot(kind=\"bar\",color=\"Red\",alpha=0.5\n           , title=\"Survival rate of royalty\")\n#VIP female officer, royalty has high survival rate","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"de4d5521-7ad8-42f5-b724-fcc6b1fe4f52","_uuid":"bd51d48ac00b014b49bf7285b61b69fd2faef99f"},"cell_type":"markdown","source":"## Feature Selection <a class=\"anchor\" id=\"sec9\"></a>"},{"metadata":{"_cell_guid":"d0a3d534-fd30-4a13-b8de-0fe40f2edc96","_uuid":"701ebd5266094ca4d4c40877965819c149587539","collapsed":true,"scrolled":false,"trusted":true},"cell_type":"code","source":"#I think we have done enough work for data cleaning, let's start fitting data to model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.cluster import KMeans\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ndef select_features(df,model):\n    # Remove non-numeric columns, columns that have null values\n    df = df.select_dtypes([np.number]).dropna(axis=1)\n    all_X = df.drop([\"Survived\",\"Ticket_No\",\"Fare\",\"Age\"],axis=1)\n    all_y = df[\"Survived\"]\n    \n    clf = eval(model)#RandomForestClassifier(random_state=1)\n    selector = RFECV(clf,cv=10)\n    selector.fit(all_X,all_y)\n    \n    best_columns = list(all_X.columns[selector.support_])\n    print(model,\"\\nBest Columns \\n\"+\"-\"*12+\"\\n{}\\n\".format(best_columns))\n    \n    return best_columns\n\nfamily_in_train = train[train[\"group_type\"] == \"family\"].copy()\nbasic_cols = ['SibSp', 'Parch', 'Age_cat_NA', 'Age_cat_Infant', 'Age_cat_Child', 'Age_cat_Young Adult', 'Age_cat_Adult',\n 'Age_cat_Middle Age', 'Age_cat_Senior', 'isVIP', 'isCrew','Pclass_Sex_femaleFirst', 'Pclass_Sex_femaleSecond', 'Pclass_Sex_femaleThird',\n 'Pclass_Sex_maleFirst', 'Pclass_Sex_maleSecond', 'Pclass_Sex_maleThird']\n\nfamily_cols = [\"family_has_children\",\"family_has_couple\",\"family_has_senior\",\n               \"family_role\", \"SibSp\",\"Parch\",\"OtherName\",\"NickName\",\"cp_id\",\n              \"family_role_Father\",\"family_role_Mother\",\"family_role_Senior\",\"family_role_Child\",\n               \"family_role_no_role\"\n              ]\ngroup_cols = [\"group_type\",\"group_size\",\"group_id\",\"n_cabin_mates\",\"n_ticket_holders\"]\n\nacq_in_train= train[train[\"group_type\"]  == \"acquaintance\"].copy()\nacq_in_train = acq_in_train.drop(family_cols, axis=1) \n\nalone_in_train = train[train[\"group_type\"]  == \"alone\"].copy()\nalone_in_train =  alone_in_train.drop(family_cols + group_cols, axis=1)\n\n\n\nLR_cols = [select_features(family_in_train, \"LogisticRegression()\"),\n           select_features(acq_in_train, \"LogisticRegression()\"),\n           select_features(alone_in_train, \"LogisticRegression()\")]\nKNN_result =  [family_cols + group_cols + basic_cols,group_cols + basic_cols, basic_cols]\nSVC_result = [family_cols + group_cols + basic_cols,group_cols + basic_cols, basic_cols]\n\nRF_cols = [select_features(family_in_train, \"RandomForestClassifier(random_state=1)\"),\n           select_features(acq_in_train, \"RandomForestClassifier(random_state=1)\"),\n           select_features(alone_in_train, \"RandomForestClassifier(random_state=1)\")]\n\nAdaboost_cols = [select_features(family_in_train, \"AdaBoostClassifier(random_state=1)\"),\n                 select_features(acq_in_train, \"AdaBoostClassifier(random_state=1)\"),\n                 select_features(alone_in_train, \"AdaBoostClassifier(random_state=1)\")]\n\nGBT_cols = [select_features(family_in_train, \"GradientBoostingClassifier(random_state=1)\"),\n            select_features(acq_in_train, \"GradientBoostingClassifier(random_state=1)\"),\n            select_features(alone_in_train, \"GradientBoostingClassifier(random_state=1)\")]\n\n\nBagging_result = [family_cols + group_cols + basic_cols,group_cols + basic_cols, basic_cols]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"61c7a161-c946-44c2-951d-ad5c868bf902","_uuid":"6e62621768094cb71b88b3bbc27b322f710ea4c6"},"cell_type":"markdown","source":"## Tuning Hyper-parameters<a class=\"anchor\" id=\"sec10\"></a>"},{"metadata":{"_cell_guid":"a1b77f0d-5095-475c-b1c0-6030454e8dd3","_uuid":"7b20a49314feec5ef7f9b264821f89ff9da1bce6","collapsed":true,"scrolled":false,"trusted":true},"cell_type":"code","source":"train_by_type = [family_in_train, acq_in_train, alone_in_train]\n\ndef select_model(df,features,model_number):\n    models_CV = [\n        {\n            \"name\": \"LogisticRegression\",\n            \"estimator\": LogisticRegression(),\n            \"hyperparameters\":\n                {\n                    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n                }\n        },\n        {\n            \"name\": \"KNeighborsClassifier\",\n            \"estimator\": KNeighborsClassifier(),\n            \"hyperparameters\":\n                {\n                    \"n_neighbors\": range(2,20),\n                    \"weights\": [\"distance\", \"uniform\"],\n                    \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n                    \"p\": [1,2]\n                }\n        },\n        {\n         \"name\":\"SVC\",\n         \"estimator\": SVC(random_state=1),\n         \"hyperparameters\":  \n            {\n                \"C\":range(1,10,2),\n                \"gamma\":[0.1, 0.5, 1]# [0.001, 0.01, 0.1, 1],\n            }\n            \n        },   \n        {\n            \"name\": \"RandomForestClassifier\",\n            \"estimator\": RandomForestClassifier(random_state=1),\n            \"hyperparameters\":\n                {\n                    \"n_estimators\": [4, 6, 9],\n                    \"criterion\": [\"entropy\", \"gini\"],\n                    \"max_depth\": [2, 5, 10],\n                    \"max_features\": [\"log2\", \"sqrt\"],\n                    \"min_samples_leaf\": [1, 5, 8],\n                    \"min_samples_split\": [2, 3, 5]\n\n                }\n        },    \n        {\n        \"name\":\"AdaBoost\",\n        \"estimator\": AdaBoostClassifier(random_state=1) ,\n        \"hyperparameters\":  \n            {\n                \"n_estimators\":[50,100, 200],\n                \"learning_rate\":[0.4,0.7,1]\n                #[b/100 for b in range(10,101,10)]                \n            }\n            \n        },    \n        {\n        \"name\":\"GradienBoostTree\",\n        \"estimator\": GradientBoostingClassifier(random_state=1) ,\n        \"hyperparameters\":  \n            {\n                \"n_estimators\":[50,100, 200],\n                \"learning_rate\":[0.4,0.7,1],\n                'max_depth':[1, 2, 3]\n            }\n            \n        },\n        {\n        \"name\":\"Bagging\",\n        \"estimator\": BaggingClassifier(random_state=1) ,\n        \"hyperparameters\":  \n            {\n                \"max_samples\":[0.3,0.5,0.7],\n                \"max_features\":[0.2,0.5,0.8]\n            }\n            \n        }\n    ]\n    model = models_CV[model_number]\n    all_X = df[features]\n    all_y = df[\"Survived\"]\n\n    # List of dictionaries, each containing a model name,\n    # it's estimator and a dict of hyperparameters\n     \n    print(model['name'])\n    print('-'*len(model['name']))\n    grid = GridSearchCV(model[\"estimator\"],\n                        param_grid=model[\"hyperparameters\"],\n                        cv=10)\n    grid.fit(all_X,all_y)\n    model[\"best_params\"] = grid.best_params_\n    model[\"best_score\"] = grid.best_score_\n    model[\"best_model\"] = grid.best_estimator_\n    \n    print(\"Best Score: {}\".format(model[\"best_score\"]))\n    print(\"Best Parameters: {}\\n\".format(model[\"best_params\"]))\n\n    return model\n\nLR_result = [[],[], []]\nKNN_result =  [[],[], []]\nSVC_result = [[],[], []]\nRF_result =  [[],[], []]#np.zeros([3,1])\nAdaboost_result =  [[],[], []]\nGBT_result =  [[],[], []]\nBagging_result =  [[],[], []]\n\nfor group_type in range(3):  \n    LR_result[group_type] = select_model(train_by_type[group_type], LR_cols[group_type], 0)\n    \n    KNN_result[group_type] = select_model(train_by_type[group_type], LR_cols[group_type], 1)\n    SVC_result[group_type] = select_model(train_by_type[group_type], LR_cols[group_type], 2)\n    RF_result[group_type] = select_model(train_by_type[group_type], RF_cols[group_type],3)\n    Adaboost_result[group_type] = select_model(train_by_type[group_type], Adaboost_cols[group_type], 4)\n    GBT_result[group_type] = select_model(train_by_type[group_type], GBT_cols[group_type], 5)\n    Bagging_result[group_type] = select_model(train_by_type[group_type], GBT_cols[group_type],6)\n    ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3426188d-58fa-4cd0-8dc5-c36e204d958c","_uuid":"e6eaddde213f8c6bd71fc043d4b0005a15e2e5de","collapsed":true,"trusted":true},"cell_type":"code","source":"\nscores = {\n    \"Algorithms\":[\"family\",\"acquiantance\",\"alone\"],\n    \"LR\":\n    [\n    LR_result[0][\"best_score\"], \n    LR_result[1][\"best_score\"], \n    LR_result[2][\"best_score\"]\n          ],\n    \"KNN\":\n    [\n        KNN_result[0][\"best_score\"], \n        KNN_result[1][\"best_score\"], \n        KNN_result[2][\"best_score\"]\n    ],\n    \"SVC\":\n    [\n        SVC_result[0][\"best_score\"], \n        SVC_result[1][\"best_score\"], \n        SVC_result[2][\"best_score\"]\n    ],\n    \"RF\":\n    [\n        RF_result[0][\"best_score\"],  \n        RF_result[1][\"best_score\"], \n        RF_result[2][\"best_score\"]\n    ] , \n    \"Adaboost\":\n    [\n        Adaboost_result[0][\"best_score\"], \n        Adaboost_result[1][\"best_score\"], \n        Adaboost_result[2][\"best_score\"]\n    ], \n    \"GBT\":\n    [\n        GBT_result[0][\"best_score\"], \n        GBT_result[1][\"best_score\"], \n        GBT_result[2][\"best_score\"]\n    ],\n    \"Bagging\":\n    [\n        Bagging_result[0][\"best_score\"], \n        Bagging_result[1][\"best_score\"],\n        Bagging_result[2][\"best_score\"]\n    ]\n}\n\n \nn_algs = 4\nscore_df =pd.DataFrame(scores).set_index(\"Algorithms\").T\ndisplay(score_df)\nprint(\"Best models for passengers with family:\\n\", score_df.nlargest(n_algs,\"family\")[\"family\"],\"\\n\")\nprint(\"Best models for passengers with acquiantance:\\n\", score_df.nlargest(n_algs,\"acquiantance\")[\"acquiantance\"],\"\\n\")\nprint(\"Best models for passengers alone:\\n\", score_df.nlargest(n_algs,\"alone\")[\"alone\"],\"\\n\")\nfml_algs = list(score_df.nlargest(n_algs,\"family\").index)\nacq_algs = list(score_df.nlargest(n_algs,\"acquiantance\").index)\nalo_algs = list(score_df.nlargest(n_algs,\"alone\").index)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c2da84cb-bc4c-4cca-b9fd-f137ae6ed158","_uuid":"8c841f27160d89acb4d53c4effb5d8640d066df0"},"cell_type":"markdown","source":"## Training Models<a class=\"anchor\" id=\"sec11\"></a>\n\nCross validated accuracy scores listed in above table:\n\n\nThe final model will use the three best performing algorithms for each group of passengers, and the prediction result will be a veto mechanism, i.e., if any algorithm predicts a passenger to be fatal, he/she will be considered as victim. "},{"metadata":{"_cell_guid":"5edd1427-dde5-4998-88ed-307ec7f4668b","_uuid":"c5e6419d498c67c06c00d2fabb0a19e96f9c7adc","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"models = [[\n    LR_result[0][\"best_model\"], \n    LR_result[1][\"best_model\"], \n    LR_result[2][\"best_model\"]\n          ],\n    [\n        KNN_result[0][\"best_model\"], \n        KNN_result[1][\"best_model\"], \n        KNN_result[2][\"best_model\"]\n    ],\n    [\n        SVC_result[0][\"best_model\"], \n        SVC_result[1][\"best_model\"], \n        SVC_result[2][\"best_model\"]\n    ],\n    [\n        RF_result[0][\"best_model\"],  \n        RF_result[1][\"best_model\"], \n        RF_result[2][\"best_model\"]\n    ] , \n    [\n        Adaboost_result[0][\"best_model\"], \n        Adaboost_result[1][\"best_model\"], \n        Adaboost_result[2][\"best_model\"]\n    ], \n    [\n        GBT_result[0][\"best_model\"], \n        GBT_result[1][\"best_model\"], \n        GBT_result[2][\"best_model\"]\n    ],\n    [\n        Bagging_result[0][\"best_model\"], \n        Bagging_result[1][\"best_model\"],\n        Bagging_result[2][\"best_model\"]\n    ]\n]\n \ncols = [\n    LR_cols,\n    LR_cols,\n    LR_cols,\n    RF_cols,\n    Adaboost_cols,\n    GBT_cols,\n    GBT_cols\n]\n\nholdout_ids = [\n    test[test[\"group_type\"] == \"family\"].index, \n    test[test[\"group_type\"] == \"acquaintance\"].index, \n    test[test[\"group_type\"] == \"alone\"].index\n]\n\ntotal_result= pd.DataFrame()\nfrom collections import OrderedDict \nmodel_names = [\"LR\",\"KNN\",\"SVC\",\"RF\",\"Adaboost\",\"GBT\",\"Bagging\"]\nfor model_id in range(len(models)):\n    \n    model_result = pd.DataFrame()\n    for group_type in range(len(holdout_ids)):      \n        group_ids = holdout_ids[group_type]\n        holdout_data = test.loc[group_ids, cols[model_id][group_type]]\n        predictions = models[model_id][group_type].predict(holdout_data)\n        group_result =pd.DataFrame({ \"PassengerId\": group_ids,\n                        model_names[model_id]: predictions}).set_index(\"PassengerId\")\n        #\n        model_result = model_result.append([group_result])\n    #print(model_result)\n    #model_result = pd.DataFrame(OrderedDict(sorted(model_result.items())))\n    total_result = pd.concat([total_result, model_result.sort_index()], axis=1, join_axes=[model_result.index])\ntotal_result.describe()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"35683107-484c-4acf-8a75-9a452458af3f","_uuid":"272b55f2c089c0ee19e641076a4928840e2fe74f","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"### total_result[\"Survived\"] = 0\nfamily_in_test = test[test[\"group_type\"] == \"family\"].index#pd.Index(list(test[test[\"group_type\"] == \"family\"].index ))\nacq_in_test = test[test[\"group_type\"] == \"acquaintance\"].index\nalone_in_test = test[test[\"group_type\"] == \"alone\"].index\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4bc9c0b0-47b7-4ac7-bce9-11f559c8ea71","_uuid":"5e6d37b2d0ef3f343db6002176c57f824c4da664","collapsed":true,"trusted":true},"cell_type":"code","source":"\"\"\"\n#total_result.loc[family_in_test, \"Survived\"]  =  total_result.loc[family_in_test,  \"RF\"] \n#+ total_result.loc[family_in_test,\"GBT\"] + total_result.loc[family_in_test]\ntotal_result.loc[family_in_test, \"Survived\"]= (total_result.loc[family_in_test,  [\"RF\",\"GBT\",\"Bagging\",\"Adaboost\"]].sum(axis=1) == 3).astype(int)\ntotal_result.loc[acq_in_test, \"Survived\"] = (total_result.loc[acq_in_test,  [\"LR\",\"Bagging\",\"GBT\"]].sum(axis=1) == 3).astype(int)\ntotal_result.loc[alone_in_test, \"Survived\"] = (total_result.loc[alone_in_test,  [\"KNN\",\"GBT\",\"RF\"]].sum(axis=1) == 3).astype(int)\n\"\"\"\ntotal_result.loc[family_in_test, \"Survived\"]= (total_result.loc[family_in_test,  fml_algs].sum(axis=1) >= n_algs -1).astype(int)\ntotal_result.loc[acq_in_test, \"Survived\"] = (total_result.loc[acq_in_test,  acq_algs].sum(axis=1)  >= n_algs -1).astype(int)\ntotal_result.loc[alone_in_test, \"Survived\"] = (total_result.loc[alone_in_test,alo_algs].sum(axis=1) >= n_algs - 1).astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0253e772-c10b-4297-a108-10f8189104be","_uuid":"820afb6feb75ac90ad873f0c1ff2b73894d4c713"},"cell_type":"markdown","source":"## Making Predications and Submission<a class=\"anchor\" id=\"sec12\"></a>"},{"metadata":{"_cell_guid":"13ada4dc-0518-43d2-bbc7-68d444fc3677","_uuid":"08254908cfd87cd85599b2fb641e818e0803357e","collapsed":true,"scrolled":false,"trusted":true},"cell_type":"code","source":"submission = total_result.sort_index().reset_index().copy()\nsubmission = submission[[\"PassengerId\",\"Survived\"]].astype(int)\nsubmission.to_csv(\"Kaggle_final.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}