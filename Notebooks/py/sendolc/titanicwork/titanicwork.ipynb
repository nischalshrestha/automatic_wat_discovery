{"cells":[
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "\n%matplotlib inline\nimport numpy as np \nimport pandas as pd\n\n\ntitanic_train = pd.read_csv(\"../input/train.csv\", dtype={\"Age\": np.float64}, ) \ntitanic_test = pd.read_csv(\"../input/test.csv\", dtype={\"Age\": np.float64}, )\n\nprint(\"\\n\\nSummary statistics of training data\") \nprint(titanic_train.describe())   \n#learn variables' info \nprint(\"\\ninfo of variables in titanic_train\\n\")\ntitanic_train.info()\nprint(\"\\ninfo of variables in titanic_test\\n\")\ntitanic_test.info()\n"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#titanic_train[\"Embarked\"] = titanic_train[\"Embarked\"].fillna(\"S\")\n#titanic_train.loc[titanic_train[\"Embarked\"]==\"S\", \"Embarked\"] = 0\n#titanic_train.loc[titanic_train[\"Embarked\"]==\"C\", \"Embarked\"] = 1\n#titanic_train.loc[titanic_train[\"Embarked\"]==\"Q\", \"Embarked\"] = 2\ntitanic_train.drop([\"Embarked\"], axis=1,inplace=True)\ntitanic_test.drop([\"Embarked\"], axis=1,inplace=True)\n\ntitanic_train.loc[titanic_train[\"Sex\"]==\"male\", \"Sex\"] = 0\ntitanic_train.loc[titanic_train[\"Sex\"]==\"female\", \"Sex\"] = 1\ntitanic_test.loc[titanic_test[\"Sex\"]==\"male\", \"Sex\"] = 0\ntitanic_test.loc[titanic_test[\"Sex\"]==\"female\", \"Sex\"] = 1\n\ntitanic_test[\"Fare\"] = titanic_test[\"Fare\"].fillna(titanic_test[\"Fare\"].median())\naverage_age_train  = titanic_train[\"Age\"].mean()\nstd_age_train       = titanic_train[\"Age\"].std()\naverage_age_test   = titanic_test[\"Age\"].mean()\nstd_age_test       = titanic_test[\"Age\"].std()\n\nrand_1 = np.random.randint(average_age_train - std_age_train, average_age_train + std_age_train)\nrand_2 = np.random.randint(average_age_test - std_age_test, average_age_test + std_age_test)\ntitanic_train[\"Age\"] = titanic_train[\"Age\"].fillna(rand_1)\ntitanic_test[\"Age\"] = titanic_test[\"Age\"].fillna(rand_2 )"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "\ntitanic_train[\"Family\"] = titanic_train[\"SibSp\"] + titanic_train[\"Parch\"]\ntitanic_train[\"NameLength\"] = titanic_train[\"Name\"].apply(lambda x: len(x))\n\nimport re\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    if title_search:\n        return title_search.group(1)\n    return \"\"\ntitles = titanic_train[\"Name\"].apply(get_title)\n\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\nfor k,v in title_mapping.items():\n    titles[titles == k] = v\n\n\ntitanic_train[\"Title\"] = titles\n\ntitles = titanic_test[\"Name\"].apply(get_title)\n\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2, \"Dona\": 10}\nfor k,v in title_mapping.items():\n    titles[titles == k] = v\ntitanic_test[\"Title\"] = titles\n\n\n"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#Linear Regression\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_validation import KFold\n\npredictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Title\"]\nalg = LinearRegression()\nkf = KFold(titanic_train.shape[0], n_folds=3, random_state=1)\npredictions = []\nprint(kf)\nfor train ,test in kf:\n    train_predictors= (titanic_train[predictors].iloc[train,:])\n    train_target = titanic_train[\"Survived\"].iloc[train]\n    alg.fit(train_predictors, train_target)\n    test_predictions = alg.predict(titanic_train[predictors].iloc[test,:])\n    predictions.append(test_predictions)\n    \npredictions = np.concatenate(predictions, axis=0)\npredictions[predictions > .5] = 1\npredictions[predictions <=.5] = 0\nsumm=sum(predictions == titanic_train[\"Survived\"])\naccuracy=float(summ)/len(predictions)\nprint(accuracy)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#Logistic Regression\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn import cross_validation\nalg = LogisticRegression(random_state=1)\nscores = cross_validation.cross_val_score(alg, titanic_train[predictors], titanic_train[\"Survived\"], cv=3)\nprint(scores.mean())"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#Random forests\nfrom sklearn import cross_validation\nfrom sklearn.ensemble import RandomForestClassifier\n\npredictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Title\"]\n\nalg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=2 )\nscores = cross_validation.cross_val_score(alg, titanic_train[predictors], titanic_train[\"Survived\"], cv=3)\nprint(scores.mean())"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "from sklearn.ensemble import GradientBoostingClassifier\n\nalgorithms = [\n    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Title\" ]],\n    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\",  \"Title\", \"Age\"]]\n]\n\nkf = KFold(titanic_train.shape[0], n_folds=3, random_state=1)\n\npredictions = []\nfor train, test in kf:\n    train_target = titanic_train[\"Survived\"].iloc[train]\n    full_test_predictions = []\n    for alg, predictors in algorithms:\n        alg.fit(titanic_train[predictors].iloc[train,:], train_target)\n        test_predictions = alg.predict_proba(titanic_train[predictors].iloc[test,:].astype(float))[:,1]\n        full_test_predictions.append(test_predictions)\n    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2\n    test_predictions[test_predictions <= .5] = 0\n    test_predictions[test_predictions > .5] = 1\n    predictions.append(test_predictions)\n\npredictions = np.concatenate(predictions, axis=0)\nsumm=sum(predictions == titanic_train[\"Survived\"])\naccuracy=float(summ)/len(predictions)\nprint(accuracy)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "algorithms = [\n    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors],\n    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"Title\", \"Age\"]]\n]\n\nfull_predictions = []\nfor alg, predictors in algorithms:\n    alg.fit(titanic_train[predictors], titanic_train[\"Survived\"])\n    predictions = alg.predict_proba(titanic_test[predictors].astype(float))[:,1]\n    full_predictions.append(predictions)\n\npredictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\npredictions[predictions <= .5] = 0\npredictions[predictions > .5] = 1\npredictions = predictions.astype(int)\nsubmission = pd.DataFrame({\n        \"PassengerId\": titanic_test[\"PassengerId\"],\n        \"Survived\": predictions\n    })\nsubmission.to_csv(\"kaggle.csv\", index=False)\n#alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=2 )\n#alg.fit(titanic_train[predictors], titanic_train[\"Survived\"])\n#predictions = alg.predict(titanic_test[predictors])\n#submission = pd.DataFrame({\n#        \"PassengerId\": titanic_test[\"PassengerId\"],\n#       \"Survived\": predictions\n#    })\n#submission.to_csv(\"kaggle.csv\", index=False)"
 }
],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}, "nbformat": 4, "nbformat_minor": 0}