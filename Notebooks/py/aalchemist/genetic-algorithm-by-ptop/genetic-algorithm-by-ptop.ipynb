{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport re as re\n\ntrain = pd.read_csv('../input/train.csv', header = 0, dtype={'Age': np.float64})\ntest  = pd.read_csv('../input/test.csv' , header = 0, dtype={'Age': np.float64})\nids = test['PassengerId']\nfull_data = [train, test]\n\nprint (train.info())\nprint (test.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"be0936d4b8e8712b3f2d16c9fc36ded50c0776a3","collapsed":true},"cell_type":"code","source":"print (train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"28e5685d75fe479b39c84a63eee231ee0888361e"},"cell_type":"markdown","source":"filling the null values in ages by sampling from a normal distribution with mean , varience calculated from data "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"for dataset in full_data:\n    age_avg \t   = dataset['Age'].mean()\n    age_std \t   = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    \n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\n    \ntrain['CategoricalAge'] = pd.cut(train['Age'], 5)\n\nprint (train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c636f84760368d30c575c87cf30138184792a1e"},"cell_type":"markdown","source":"Filling the null values in Embarked by the maximum occured value 'S'"},{"metadata":{"trusted":true,"_uuid":"a885091455ae0e24cc3132aa9c72268f3914170a","collapsed":true},"cell_type":"code","source":"import random\nfor dataset in full_data:\n    a=random.choice(['S','C','Q'])\n    dataset['Embarked'] = dataset['Embarked'].fillna(\"S\")\nprint (train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d86c867cf2d15f84c819c5a954a40d546e9c6d8"},"cell_type":"markdown","source":"Seeing the effect of FARE on survival "},{"metadata":{"trusted":true,"_uuid":"74fb1a6531dd1bbbea67170e596054da2f1c073b","collapsed":true},"cell_type":"code","source":"for dataset in full_data:\n    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\ntrain['CategoricalFare'] = pd.qcut(train['Fare'], 4)\nprint (train[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6e593dc3e6968546ccb61cf84563b9bf6f23407a"},"cell_type":"markdown","source":"Categoriging based on having a cabin or not . NULL value in cabit row denotes not having a cabin . then seeing it's effect on survival "},{"metadata":{"trusted":true,"_uuid":"8adc58d5be68aa401f25d9bbc982f6035d0ef3c0","collapsed":true},"cell_type":"code","source":"for dataset in full_data:\n    dataset['Cabin'] = dataset['Cabin'].fillna('0')\n#train['CategoricalFare'] = pd.qcut(train['Fare'], 4)\nfor dataset in full_data:\n    dataset.loc[ dataset['Cabin'] != '0', 'Cabin'] = '1'\n    dataset['Cabin'] = dataset['Cabin'].astype(int)\nprint (train[['Cabin', 'Survived']].groupby(['Cabin'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7be9c0c26f28b4475d3596d8fc72db323b9237fb"},"cell_type":"markdown","source":"separating title from names"},{"metadata":{"trusted":true,"_uuid":"bbc173b9f5331806b5886cef4151bbcb952073e3","collapsed":true},"cell_type":"code","source":"def get_title(name):\n\ttitle_search = re.search(' ([A-Za-z]+)\\.', name)\n\t# If the title exists, extract and return it.\n\tif title_search:\n\t\treturn title_search.group(1)\n\treturn \"\"\n\nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)\n\nprint(pd.crosstab(train['Title'], train['Sex']))\nfor dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\nprint (train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b6d6e3ad461102c7ed68115c1ad50408486821a","collapsed":true},"cell_type":"code","source":"for dataset in full_data:\n    # Mapping Sex\n    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n    \n    # Mapping titles\n    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    \n    # Mapping Embarked\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n    \n    \n    # Mapping Fare\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n    #dataset['Fare']=dataset['Fare']/max(dataset['Fare'])\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    \n    # Mapping Age\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']                           = 4\n    #dataset['Age']=dataset['Age']/max(dataset['Age'])\n\n# Feature Selection . \ndrop_elements = ['PassengerId', 'Name', 'Ticket'\n                 ]\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n\n\ntest  = test.drop(drop_elements, axis = 1)\n\nprint (train.head(10))\n\ntrain = train.values\ntest  = test.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcb61e9f0e3122c94764227365c59f2e917b32a5","collapsed":true},"cell_type":"code","source":"from keras.utils import np_utils\nX = train[0::, 1::]\ny = train[0::, 0]\n#Y=np_utils.to_categorical(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32d26ee43cdc71a7e7d29ed192a97afe783557e5","collapsed":true},"cell_type":"code","source":"from tpot import TPOTClassifier\nmodel = TPOTClassifier(generations=10,population_size=100,random_state=433, verbosity=2)\nmodel.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c77f437ae932e7feba605fc8fce36bc7d8df7990","collapsed":true},"cell_type":"code","source":"#model.fit(train[0::, 1::], train[0::, 0])\nresult = model.predict(test)\n#result=[np.argmax(pred) for pred in result]\npdtest = pd.DataFrame({'PassengerId': ids,\n                            'Survived': result})\npdtest.to_csv('gptest.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}