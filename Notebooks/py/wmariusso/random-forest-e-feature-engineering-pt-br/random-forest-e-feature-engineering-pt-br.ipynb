{"metadata": {"_is_fork": false, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "_change_revision": 36}, "nbformat_minor": 1, "cells": [{"metadata": {"_cell_guid": "7f95a895-3cd8-4b43-93f7-3f800939bdbd", "_uuid": "38f8706db53a20595ce48bd14989a85ba05f5eea"}, "cell_type": "markdown", "source": ["# Titanic - RandomForest e Features Engineering\n", "Este notebook cria um modelo baseado no dataset do Titanic e usando RandomForests. Esse notebook trata de dados faltantes, features categ\u00f3ricas e um pouco de feature engineering."]}, {"metadata": {"_cell_guid": "57ee0cd4-fcde-4186-8568-8319850b28b5", "_uuid": "0713d935f312824e50c944610037ce64af65cd7e"}, "cell_type": "markdown", "source": ["Vamos come\u00e7ar importando as bibliotecas b\u00e1sicas que vamos usar."]}, {"metadata": {"_cell_guid": "cfdaacbc-23a3-423d-8d4d-120939ac7383", "_uuid": "cefaee44150a26045c95891d12f70350c630e0b4", "collapsed": true}, "cell_type": "code", "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline"], "outputs": [], "execution_count": 5}, {"metadata": {"_cell_guid": "e56f8e5e-8f5b-4965-9e69-4510f4f66520", "_uuid": "359dd8978a7d3982f24c21a81516e25490fce93f"}, "cell_type": "markdown", "source": ["Pr\u00f3ximo passo: carregando os dados a partir dos CSVs disponibilizados no Kaggle. Estamos usando a biblioteca pandas para esse prop\u00f3sito."]}, {"metadata": {"_cell_guid": "3ab4c525-a5cb-4183-9468-c1dd005c4c78", "_uuid": "971f834ca694c6b425b41c9cd3483ff6b8590cbe"}, "cell_type": "code", "source": ["# Vamos iniciar o notebook importanto o Dataset\n", "titanic_df = pd.read_csv(\"../input/train.csv\")\n", "test_df    = pd.read_csv(\"../input/test.csv\")\n", "\n", "# Podemos observar as primeiras linhas dele.\n", "titanic_df.head()"], "outputs": [], "execution_count": 6}, {"metadata": {"_cell_guid": "9416a636-3a5d-4201-92b3-b37fd28960e9", "_uuid": "bb049b26e6b2bfe3e59b24bfbd2e66da353066ed"}, "cell_type": "markdown", "source": ["Vamos come\u00e7ar com o b\u00e1sico de tratamento desse dataset. Importante: tudo que fizermos vamos fazer no dataset de treinamento e tamb\u00e9m de teste."]}, {"metadata": {"_cell_guid": "f8a971fe-1d80-42f6-81b6-86e5778f6852", "_uuid": "185df1d7dd626702f791fa2f8b1c63cf74c51db9"}, "cell_type": "markdown", "source": ["## Tratando a Idade - Imputation"]}, {"metadata": {"_cell_guid": "cbb6b24a-0697-4538-aecb-64747e7b748c", "_uuid": "14fba7bf4763c668e256bc45a8bc93d86fac378b"}, "cell_type": "markdown", "source": ["Nos casos anteriores, avisamos que idade tinha campos vazios."]}, {"metadata": {"_cell_guid": "efbcfaa8-e4aa-440c-b2b5-28f2cae72505", "_uuid": "6568c0324d5844edd71be79d4071be6dbec5b151"}, "cell_type": "code", "source": ["titanic_df[pd.isnull(titanic_df['Age'])]"], "outputs": [], "execution_count": 7}, {"metadata": {"_cell_guid": "03736f64-4ae1-4078-9bb0-adbbad0e52b1", "_uuid": "a59da8ba48673692ca5c643bfea55766325bab8a"}, "cell_type": "markdown", "source": ["Teremos que preencher isso de algum jeito. Uma abordagem comum nesses casos \u00e9 usar uma m\u00e9dia ou mediana. Vamos usar aqui a mediana do dataset - mas poder\u00edamos agrupar por sexo, por exemplo. Fica a seu crit\u00e9rio fazer isso de forma mais fancy. ;)"]}, {"metadata": {"_cell_guid": "3d5e2b85-c71e-455a-9577-8588ba0c4451", "_uuid": "edf5ef131a7021e231d757d669266daf4a332661"}, "cell_type": "code", "source": ["age_median = titanic_df['Age'].median()\n", "print(age_median)"], "outputs": [], "execution_count": 8}, {"metadata": {"_cell_guid": "dda6161a-cf5c-44c4-ac1e-8c619996808a", "_uuid": "d70c7ed51b823e4289888412ebf10853bf1edbb9", "collapsed": true}, "cell_type": "code", "source": ["titanic_df['Age'] = titanic_df['Age'].fillna(age_median)\n", "test_df['Age'] = test_df['Age'].fillna(age_median)"], "outputs": [], "execution_count": 9}, {"metadata": {"_cell_guid": "11fe15a1-b1dc-4dbf-a90d-946a3e68110f", "_uuid": "d969856f728adbb8039ef0de37342a27207c943d"}, "cell_type": "markdown", "source": ["\u00d3timo! Um problema a menos. Essa t\u00e9cnica que usamos \u00e9 chamada de \"imputation\"."]}, {"metadata": {"_cell_guid": "dff76cef-c609-4b34-ae84-c17604cbd3a5", "_uuid": "1a273727c91f66dfa7e549d59cc865ed9a2c57ff"}, "cell_type": "markdown", "source": ["## Tratando G\u00eanero - LabelEncoding"]}, {"metadata": {"_cell_guid": "6cc1b95f-82b4-41f0-85d1-973ea88c0378", "_uuid": "6ca1f7a59ced3969ac113c82afabc33e4babd11d"}, "cell_type": "markdown", "source": ["Pr\u00f3ximo passo: vamos tratar das features categ\u00f3ricas. Queremos transformar features que s\u00e3o de m\u00faltiplas categorias em dados num\u00e9ricos que podemos trabalhar. O caso mais \u00f3bivo \u00e9 sexo."]}, {"metadata": {"_cell_guid": "ec2b42ab-3ab6-422a-9faf-1b751c4423aa", "_uuid": "0378b2abc0d196910bbaf5abe2cc8702cdd6b3dc"}, "cell_type": "code", "source": ["import seaborn as sns\n", "sns.countplot(titanic_df['Sex']);"], "outputs": [], "execution_count": 10}, {"metadata": {"_cell_guid": "4b722684-f294-4244-9722-e54df9164048", "_uuid": "1b25bc997f3a540eda887cc5baf8b83e4d198630"}, "cell_type": "markdown", "source": ["Vamos usar aqui um transformer do sklearn chamado LabelEncoder. Ele transforma a primeira categoria no n\u00famero 0, a segunda no n\u00famero 1 e assim por diante."]}, {"metadata": {"_cell_guid": "2eb34bc5-656b-4f40-b265-ce7826a7401f", "_uuid": "ad34fce2c89fef61f7bc90d887dda810823544d1"}, "cell_type": "code", "source": ["from sklearn.preprocessing import LabelEncoder\n", "sex_encoder = LabelEncoder()\n", "\n", "sex_encoder.fit(list(titanic_df['Sex'].values) + list(test_df['Sex'].values))"], "outputs": [], "execution_count": 11}, {"metadata": {"_cell_guid": "0c529374-5c8b-4adc-bd27-921340a19d82", "_uuid": "f898c511fd488f95673d3d8a33d381174eebc8a1"}, "cell_type": "code", "source": ["sex_encoder.classes_"], "outputs": [], "execution_count": 12}, {"metadata": {"_cell_guid": "f1a30867-4c5e-43bf-9704-b39a328636cd", "_uuid": "eefc124368f88b35969baafceda99e0ab926bdc0", "collapsed": true}, "cell_type": "code", "source": ["titanic_df['Sex'] = sex_encoder.transform(titanic_df['Sex'].values)\n", "test_df['Sex'] = sex_encoder.transform(test_df['Sex'].values)"], "outputs": [], "execution_count": 13}, {"metadata": {"_cell_guid": "a2e89c06-952b-4021-b037-5f923f63aed7", "_uuid": "50ef29fc161a6a37966d36617007d567bd73c2d2"}, "cell_type": "code", "source": ["sns.countplot(titanic_df['Sex']);"], "outputs": [], "execution_count": 14}, {"metadata": {"_cell_guid": "b9b7daf4-8627-43bd-8600-eb32e12f196d", "_uuid": "9edf7123c5bbb399e9e60dd970e204d9e6ccdc14"}, "cell_type": "markdown", "source": ["Ok, a feature Sex j\u00e1 est\u00e1 devidamente encodada. Vamos dar mais uma espiada nos dados?"]}, {"metadata": {"_cell_guid": "9ff3ef92-2588-4fcc-ab8d-ad81844b84b3", "_uuid": "fed4681fb7ecb63e13750116cfa6521fd1f4ce18"}, "cell_type": "code", "source": ["titanic_df.head()"], "outputs": [], "execution_count": 15}, {"metadata": {"_cell_guid": "91df0568-a89e-4198-9741-2b8a5e4b820a", "_uuid": "d6b48ada7b6cd3f59882e3113215fd243ae292a0"}, "cell_type": "markdown", "source": ["J\u00e1 temos mais colunas num\u00e9ricas. Vamos estudar o impacto de adicionar essas colunas no nosso modelo. Vamos usar o nosso modelo anterior."]}, {"metadata": {"_cell_guid": "194a9aaa-2353-4cb8-ad05-eb7d43917f75", "_uuid": "5356a02f1ba33723daa1779722cbf35e17a908e0", "collapsed": true}, "cell_type": "code", "source": ["feature_names = ['Pclass', 'SibSp', 'Parch', 'Fare']"], "outputs": [], "execution_count": 16}, {"metadata": {"_cell_guid": "671eef09-2448-499c-a3d8-ba2f65d23e44", "_uuid": "04cdb18cb35d09ff4dcbe91b298020752983a7e0"}, "cell_type": "code", "source": ["from sklearn.model_selection import train_test_split\n", "train_X, valid_X, train_y, valid_y = train_test_split(titanic_df[feature_names].as_matrix(), \n", "                                                      titanic_df['Survived'].as_matrix(),\n", "                                                      test_size=0.2,\n", "                                                      random_state=42)\n", "                                                      \n", "                                                      \n", "print(train_X.shape)\n", "print(valid_X.shape)                                           \n", "print(train_y.shape)\n", "print(valid_y.shape)"], "outputs": [], "execution_count": 17}, {"metadata": {"_cell_guid": "694119ce-cb24-4085-ad65-58737d78c108", "_uuid": "9ddfcdc898b72d8923e745d072c5d3b2946c1702"}, "cell_type": "code", "source": ["from sklearn.ensemble import RandomForestClassifier\n", "rf_clf = RandomForestClassifier(random_state=42, n_estimators=200, max_depth=7)\n", "rf_clf.fit(train_X, train_y)\n", "print(rf_clf.score(train_X, train_y))\n", "print(rf_clf.score(valid_X, valid_y))"], "outputs": [], "execution_count": 18}, {"metadata": {"_cell_guid": "381be881-8aa0-4bd5-b0f4-08afd1b44740", "_uuid": "66c71fff633e68aee7399e32f563f164241dc631"}, "cell_type": "code", "source": ["import seaborn as sns\n", "sns.barplot(rf_clf.feature_importances_, feature_names);"], "outputs": [], "execution_count": 19}, {"metadata": {"_cell_guid": "1cca98ac-8b97-4715-87f0-212c07047ae3", "_uuid": "2c498707bb13fc2bfb8500e65f812f58ffb23408"}, "cell_type": "markdown", "source": ["Vamos incluir algumas features adicionais"]}, {"metadata": {"_cell_guid": "380ee53f-007f-4ea1-ba8a-9dacbda7b6ed", "_uuid": "d4fcad95cbf36821ece1ca9c1c5a8594a2c58972"}, "cell_type": "code", "source": ["feature_names = ['Pclass', 'SibSp', 'Parch', 'Fare', 'Age', 'Sex']\n", "\n", "from sklearn.model_selection import train_test_split\n", "train_X, valid_X, train_y, valid_y = train_test_split(titanic_df[feature_names].as_matrix(), \n", "                                                      titanic_df['Survived'].as_matrix(),\n", "                                                      test_size=0.2,\n", "                                                      random_state=42)\n", "                                                      \n", "                                                      \n", "print(train_X.shape)\n", "print(valid_X.shape)                                           \n", "print(train_y.shape)\n", "print(valid_y.shape)\n", "\n", "rf_clf = RandomForestClassifier(random_state=42, n_estimators=200, max_depth=10)\n", "rf_clf.fit(train_X, train_y)\n", "print(rf_clf.score(train_X, train_y))\n", "print(rf_clf.score(valid_X, valid_y))\n", "\n", "sns.barplot(rf_clf.feature_importances_, feature_names);"], "outputs": [], "execution_count": 20}, {"metadata": {"_cell_guid": "9627e5db-ecf4-42f4-a07d-47c2080149fa", "_uuid": "ca44c4320aee99abd7beb4f5dee9c029c7804796"}, "cell_type": "markdown", "source": ["Melhoramos um pouco o nosso score de valida\u00e7\u00e3o. Depois de incluir as novas features no modelo, agora Sexo passa a ser a feature mais importante."]}, {"metadata": {"_cell_guid": "2f0e3c36-6a4f-4d12-9864-e8d04606f83c", "_uuid": "a5bddd31bdf897e04c75eb3a6f99370912a0b36a"}, "cell_type": "markdown", "source": ["## Feature Engineering - T\u00edtulo"]}, {"metadata": {"_cell_guid": "22d346e2-cafd-47ff-99e2-359659f78eac", "_uuid": "156c37731d4f7db656a29204ab4e557336b9620c"}, "cell_type": "markdown", "source": ["Feature Engineering \u00e9 uma t\u00e9cnica que envolve criar novas features - em geral a partir de outras. Vamos usar essa t\u00e9cnica para extrair o t\u00edtulo a partir do nome."]}, {"metadata": {"_cell_guid": "491c3462-d850-4e8e-9553-d5210c6b0163", "_uuid": "b5c9848aac65079b3c2ed84ac0f034c5b1c9c7fc"}, "cell_type": "code", "source": ["titanic_df.head()['Name']"], "outputs": [], "execution_count": 21}, {"metadata": {"_cell_guid": "069325fe-1515-4819-b9d4-4a6b62ce405c", "_uuid": "c7ae3862529c13d70ddef64c1266e094b1511c50", "collapsed": true}, "cell_type": "code", "source": ["import re\n", "def extract_title(name):\n", "    x = re.search(', (.+?)\\.', name)\n", "    if x:\n", "        return x.group(1)\n", "    else:\n", "        return ''"], "outputs": [], "execution_count": 26}, {"metadata": {"_cell_guid": "20dc4a56-fa21-4e78-b886-2000c0741146", "_uuid": "ef5f47ff90d2d34f08875b038f92606da7778a25", "collapsed": true}, "cell_type": "code", "source": ["titanic_df['Title'] = titanic_df['Name'].apply(extract_title)\n", "test_df['Title'] = test_df['Name'].apply(extract_title)"], "outputs": [], "execution_count": 27}, {"metadata": {"_cell_guid": "5fdfdf00-7616-4769-9f22-b3b5f8a9fc2b", "_uuid": "2115a3c588db2fef742ddaea58615835197a9211"}, "cell_type": "code", "source": ["titanic_df.head()"], "outputs": [], "execution_count": 28}, {"metadata": {"_cell_guid": "d89ee4c7-2233-4b59-a5e8-6f2095ba0c9a", "_uuid": "64f74eaf3c86913ab12a3d2bc5d435a8a7d2e29d"}, "cell_type": "markdown", "source": ["## OneHotEncoding"]}, {"metadata": {"_cell_guid": "fc34b94f-434d-4cd1-8ebf-4784bd1b087a", "_uuid": "690d011e0200519b84fe24ecfb251b4cedca4616"}, "cell_type": "markdown", "source": ["Agora vamos trabalhar com features que s\u00e3o MultiCategoricas. "]}, {"metadata": {"_cell_guid": "16b096ef-cba8-4a46-8e70-0a357198a06c", "_uuid": "bd74b78a2e28e5ba90f28cd9a52bf4959e3edc50", "collapsed": true}, "cell_type": "code", "source": [], "outputs": [], "execution_count": null}, {"metadata": {"_cell_guid": "550ca290-4cba-4267-aca8-6ff4e21b9ccc", "_uuid": "d134c2af20d8b98c1513e9dbc19f83efbc631d96"}, "cell_type": "code", "source": ["from sklearn.preprocessing import OneHotEncoder\n", "from sklearn.feature_extraction import DictVectorizer\n", "\n", "feature_names = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Title']\n", "dv = DictVectorizer()\n", "dv.fit(titanic_df[feature_names].append(test_df[feature_names]).to_dict(orient='records'))\n", "dv.feature_names_"], "outputs": [], "execution_count": 29}, {"metadata": {"_cell_guid": "94a1eb18-7753-4cde-bc21-ce56d70b6c27", "_uuid": "9497323e048d60b408921e511c1b1ba3f4827558"}, "cell_type": "code", "source": ["train_X, valid_X, test_y, valid_y = train_test_split(dv.transform(titanic_df[feature_names].to_dict(orient='records')),\n", "                                                     titanic_df['Survived'],\n", "                                                     test_size=0.2,\n", "                                                     random_state=42)"], "outputs": [], "execution_count": 30}, {"metadata": {"_cell_guid": "5645b306-473e-434c-a33a-2173762e569f", "_uuid": "bafb0f49f3eb453e39f67e1950c446f1089b5d1b"}, "cell_type": "code", "source": ["train_X.shape"], "outputs": [], "execution_count": 31}, {"metadata": {"_cell_guid": "e918d290-c8d9-42d8-bd24-a4538f03f0f8", "_uuid": "5d239a43049aa8234f0b3b7f771d8769e46d17ec"}, "cell_type": "code", "source": ["from sklearn.model_selection import train_test_split\n", "rf_clf = RandomForestClassifier(random_state=42, n_estimators=200, max_depth=10)\n", "rf_clf.fit(train_X, train_y)\n", "print(rf_clf.score(train_X, train_y))\n", "print(rf_clf.score(valid_X, valid_y))\n", "\n", "sns.barplot(rf_clf.feature_importances_, dv.feature_names_);"], "outputs": [], "execution_count": 32}, {"metadata": {"_cell_guid": "738de6f7-3589-4d85-832f-d353a2ec7754", "_uuid": "14b6572b82c866945b5ccadebfa3ab6b8cd3c25f"}, "cell_type": "markdown", "source": ["## Exerc\u00edcio\n", "A coluna Embarked cont\u00e9m o porto de embarque do passageiro. Algumas linhas n\u00e3o est\u00e3o preenchidas."]}, {"metadata": {"_cell_guid": "33cab3b9-012f-4813-bf1e-851d7ee7b02b", "_uuid": "d858ce4298a82dec21aba65573037a96d8c95d11"}, "cell_type": "code", "source": ["titanic_df[pd.isnull(titanic_df['Embarked'])]"], "outputs": [], "execution_count": 33}, {"metadata": {"_cell_guid": "8e44acd6-61eb-40ad-98f2-b411803d9fd8", "_uuid": "ba195a27200c7dd02bb043d1c8a184b06a16e306"}, "cell_type": "markdown", "source": ["- Implemente uma estrat\u00e9gia para fazer Imputation do porto de embarque desses passageiros. \n", "- Em seguida, fa\u00e7a o OneHotEncoding para que eles entrem na lista de Features do Modelo. Essas novas features melhoram o modelo de alguma forma?\n", "- Crie uma nova feature, com o tamanho da familia. O tamanho da fam\u00edlia \u00e9 derivado de Parch e SibSp\n", "- Inclua essa nova feature no modelo. Ela melhora o modelo de alguma forma?"]}, {"metadata": {"_cell_guid": "13f1f8d8-3aa3-4486-a5dc-3e9adb0d86cb", "_uuid": "e655dac9d11474269d3cc50132811a81b655f09d"}, "cell_type": "markdown", "source": ["## Submiss\u00e3o do Arquivo"]}, {"metadata": {"_cell_guid": "db40194c-bed1-4a52-85a7-dffd7ebbbc80", "_uuid": "b3b20ba2b83b1948d77c5074a5c993ed362d5a7b"}, "cell_type": "code", "source": ["train_X = dv.transform(titanic_df[feature_names].to_dict(orient='records'))\n", "train_y = titanic_df['Survived']\n", "\n", "rf_clf = RandomForestClassifier(random_state=42, max_depth=10, n_estimators=200)\n", "rf_clf.fit(train_X, train_y)"], "outputs": [], "execution_count": 34}, {"metadata": {"_cell_guid": "db4b5c0d-a940-4767-865c-e227ccfed1ca", "_uuid": "eeb8fae220b7a73f019779b659da55bdc093894f"}, "cell_type": "markdown", "source": ["Infelizmente no dataset de teste, um dos passageiros est\u00e1 com Fare vazio. :-(\n", "\n", "Para conseguirmos evoluir, vamos setar o Fare vazio para 0.0"]}, {"metadata": {"_cell_guid": "eb4fd386-c667-427a-a77b-7c5410a8fbe0", "_uuid": "5d898280f9fa1e0bfdf357599ca01d8cef2c6194", "collapsed": true}, "cell_type": "code", "source": ["test_df['Fare'] = test_df['Fare'].fillna(0)"], "outputs": [], "execution_count": 35}, {"metadata": {"_cell_guid": "219369f2-3edd-4b01-be40-324221b84345", "_uuid": "dd6cea0b6d784adedf805873ef3175f4206ee635"}, "cell_type": "markdown", "source": ["Lembra que o sklean trabalha com matrizes numpy, certo?"]}, {"metadata": {"_cell_guid": "bb402d71-2657-44d0-96e3-3ef487336a1a", "_uuid": "fdd7cba5592dc67369abe280250faca91c4545da"}, "cell_type": "code", "source": ["test_X = dv.transform(test_df[feature_names].to_dict(orient='records'))\n", "print(test_X.shape)"], "outputs": [], "execution_count": 36}, {"metadata": {"_cell_guid": "74870742-9e87-4999-b124-77288d4786b4", "_uuid": "a34547b8ed84667b0cb55d1982f3b4629788d048"}, "cell_type": "markdown", "source": ["Legal. Temos 418 amostras. Vamos usar o nosso modelo pra prever a sobreviv\u00eancia dessas 418 pessoas."]}, {"metadata": {"_cell_guid": "5e6d2dab-5f9e-46fc-985a-7df6561b38d9", "_uuid": "003d3275952d51da4556dfe1e7389b77e06f332b", "collapsed": true}, "cell_type": "code", "source": ["y_pred = rf_clf.predict(test_X)"], "outputs": [], "execution_count": 37}, {"metadata": {"_cell_guid": "02b8e058-ef8b-4d4c-91b0-451971e5f353", "_uuid": "1d64bd405488d84b3d153011de22271ce3d51046"}, "cell_type": "code", "source": ["y_pred"], "outputs": [], "execution_count": 38}, {"metadata": {"_cell_guid": "13651e8a-8dd6-40cb-82ed-283125b4269e", "_uuid": "2045b9680c92ad99d7d049f96d0b57d6fbb1592b", "collapsed": true}, "cell_type": "markdown", "source": ["\u00d3timo! J\u00e1 temos aquilo que precis\u00e1vamos. Pr\u00f3ximo passo agora \u00e9 empacotar num arquivo CSV e submeter no Kaggle."]}, {"metadata": {"_cell_guid": "bfaf9efd-dad4-4395-9e5b-5cdfb8065266", "_uuid": "0a7b3520483e08ab2de47b0585b75a1e770bc4a8", "collapsed": true}, "cell_type": "code", "source": ["submission_df = pd.DataFrame()"], "outputs": [], "execution_count": 39}, {"metadata": {"_cell_guid": "517caad7-ec58-4efb-b969-45da5f5d3bf9", "_uuid": "5d244d700f2d270d143bed13b9b1bca744b46afe"}, "cell_type": "code", "source": ["submission_df['PassengerId'] = test_df['PassengerId']\n", "submission_df['Survived'] = y_pred\n", "submission_df"], "outputs": [], "execution_count": 40}, {"metadata": {"_cell_guid": "42d0e8a0-43a5-41bd-b2e5-44dd807b1f80", "_uuid": "3cb052fbda74d35ad323e2888b9f2a3792ab1d5a", "collapsed": true}, "cell_type": "code", "source": ["submission_df.to_csv('feature_engineering.csv', index=False)"], "outputs": [], "execution_count": 41}, {"metadata": {"_cell_guid": "45fd8658-57ba-4109-a19c-f40fa6b7a7cd", "_uuid": "7d66014b8ecbeda7a9ef91592255a65f53b72776"}, "cell_type": "markdown", "source": ["Por favor, anote aqui para refer\u00eancia: quanto foi o seu score de treinamento do modelo? E no dataset de Valida\u00e7\u00e3o? Quanto foi o seu score na submiss\u00e3o do Kaggle?"]}, {"metadata": {"_cell_guid": "52323189-010b-4f87-838d-96dbc93533b7", "_uuid": "deb0eec844cadabe8d707634da9f2bd6da59b107", "collapsed": true}, "cell_type": "code", "source": [], "outputs": [], "execution_count": null}], "nbformat": 4}