{"metadata": {"_is_fork": false, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "_change_revision": 0, "language_info": {"file_extension": ".py", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "name": "python", "version": "3.5.2", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python"}}, "nbformat": 4, "cells": [{"metadata": {}, "cell_type": "markdown", "source": ["# Titanic - RandomForest e Features Num\u00e9ricas\n", "Este notebook cria um modelo baseado no dataset do Titanic e usando RandomForests. Para esse caso espec\u00edfico, estamos usando apenas features num\u00e9ricas."]}, {"metadata": {}, "cell_type": "markdown", "source": ["Vamos come\u00e7ar importando as bibliotecas b\u00e1sicas que vamos usar."]}, {"metadata": {"_cell_guid": "cfdaacbc-23a3-423d-8d4d-120939ac7383", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Pr\u00f3ximo passo: carregando os dados a partir dos CSVs disponibilizados no Kaggle. Estamos usando a biblioteca pandas para esse prop\u00f3sito."]}, {"metadata": {"_cell_guid": "3ab4c525-a5cb-4183-9468-c1dd005c4c78"}, "execution_count": null, "cell_type": "code", "source": ["# Vamos iniciar o notebook importanto o Dataset\n", "titanic_df = pd.read_csv(\"../input/train.csv\")\n", "test_df    = pd.read_csv(\"../input/test.csv\")\n", "\n", "# Podemos observar as primeiras linhas dele.\n", "titanic_df.head()"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Vamos usar a biblioteca scikit-learn para treinar um modelo. Como a maior parte das bibliotecas para Machine Learning, o tratamento \u00e9 de dados num\u00e9ricos. Dessa forma, vamos isolar as colunas num\u00e9ricas. As colunas n\u00e3o num\u00e9ricas ser\u00e3o tratadas no futuro.\n", "\n", "A Feature `Age` tamb\u00e9m \u00e9 num\u00e9rica, mas algumas linhas n\u00e3o est\u00e3o preenchidas. Vamos trat\u00e1-la posteriormente junto com as colunas n\u00e3o num\u00e9ricas.\n"]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["numeric_features = ['Pclass', 'SibSp', 'Parch', 'Fare']"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["\u00c9 poss\u00edvel isolar apenas um subcojunto das colunas do DataFrame pandas, passando uma lista como index da subscription."]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "source": ["titanic_df[numeric_features].head()"], "outputs": []}, {"metadata": {}, "execution_count": null, "cell_type": "code", "source": ["from sklearn.model_selection import train_test_split\n", "train_X, valid_X, train_y, valid_y = train_test_split(titanic_df[numeric_features].as_matrix(), \n", "                                                      titanic_df['Survived'].as_matrix(),\n", "                                                      test_size=0.2,\n", "                                                      random_state=42)\n", "                                                      \n", "                                                      \n", "print(train_X.shape)\n", "print(valid_X.shape)                                           \n", "print(train_y.shape)\n", "print(valid_y.shape)"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Ok. A matriz `train_X` tem 712 linhas e 4 colunas. O array `train_y` tem 712 valores, representando cada uma das 712 amostras que foram separados para o treinamento. Vamos visualiz\u00e1-los, apenas para fins did\u00e1ticos.\n", "\n", "20% dos dados foram separados para valida\u00e7\u00e3o - i.e. - tuning de parametros"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "source": ["train_X"], "outputs": []}, {"metadata": {}, "execution_count": null, "cell_type": "code", "source": ["train_y"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["\u00d3timo! Vamos agora trabalhar com o nosso modelo. Nesse caso espec\u00edfico, vamos usar uma RandomForest.\n", "\n", "O par\u00e2metro random_state \u00e9 para garantir que sempre que executarmos esse c\u00f3digo tenhamos os mesmos resultados. O par\u00e2metro n_estimator \u00e9 um hiperpar\u00e2metro ajust\u00e1vel, com o qual vamos brincar. Tamb\u00e9m podemos brincar com max_depth, como fizemos com DecisionTree"]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["from sklearn.ensemble import RandomForestClassifier\n", "rf_clf = RandomForestClassifier(random_state=42, n_estimators=10, max_depth=5)"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Criamos a estrutura b\u00e1sica do modelo. Hora de trein\u00e1-lo."]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "source": ["rf_clf.fit(train_X, train_y)"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Com nosso modelo treinado, vamos avaliar a qualidade dele. Esse modelo de DecisionTree usa como m\u00e9trica de score a acur\u00e1cia, ou seja: qual a taxa de acerto."]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "source": ["print(rf_clf.score(train_X, train_y))\n", "print(rf_clf.score(valid_X, valid_y))"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Do mesmo jeito que podemos fazer em uma DecisionTree, \u00e9 poss\u00edvel extrair a import\u00e2ncia das features pra poder explicar pro seu chefe..."]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "source": ["rf_clf.feature_importances_"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Que tal um gr\u00e1fico pra mostrar pro chefe?"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "source": ["import seaborn as sns\n", "sns.barplot(rf_clf.feature_importances_, numeric_features);"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Na real, uma RandomForest \u00e9 uma combina\u00e7\u00e3o de DecisionTreeClassifier. T\u00e1 a\u00ed a prova:"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "source": ["rf_clf.estimators_"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Qual \u00e9 a vantagem ent\u00e3o? Emsembling! Combinar v\u00e1rios modelos diferentes evita overfitting e suaviza os pontos fracos dos modelos individuais."]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Exerc\u00edcio\n", "Voc\u00ea consegue melhorar a acur\u00e1cia desse modelo? Fa\u00e7a testes usando diferentes valores para max_depth e n_estimators. Se preferir, pode brincar com os outros par\u00e2metros. Qual a melhor acur\u00e1cia no dataset de valida\u00e7\u00e3o que voc\u00ea conseguiu?"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Pergunta: qual o melhor max_depth e n_estimators que voc\u00ea encontrou? Vamos us\u00e1-lo em seguida."]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["optimal_max_depth = 5 # coloque aqui o max_depth que voce encontrou\n", "optimal_n_estimators = 10 # coloque aqui o n_estimators que voce encontrou"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Vamos usar um truquezinho agora. Agora que j\u00e1 tunamos os par\u00e2metros, vamos usar todos os dados pra treinar o modelo. N\u00e3o faz sentido mais ter separa\u00e7\u00e3o entre treino e valida\u00e7\u00e3o."]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "source": ["rf_clf = RandomForestClassifier(random_state=42, max_depth=optimal_max_depth, n_estimators=optimal_n_estimators)\n", "rf_clf.fit(titanic_df[numeric_features].as_matrix(), titanic_df['Survived'].as_matrix())"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Infelizmente no dataset de teste, um dos passageiros est\u00e1 com Fare vazio. :-(\n", "\n", "Para conseguirmos evoluir, vamos setar o Fare vazio para 0.0"]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["test_df['Fare'] = test_df['Fare'].fillna(0)"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Lembra que o sklean trabalha com matrizes numpy, certo?"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "source": ["test_X = test_df[numeric_features].as_matrix()\n", "print(test_X.shape)"], "outputs": []}, {"metadata": {}, "execution_count": null, "cell_type": "code", "source": ["test_X"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Legal. Temos 418 amostras. Vamos usar o nosso modelo pra prever a sobreviv\u00eancia dessas 418 pessoas."]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["y_pred = rf_clf.predict(test_X)"], "outputs": []}, {"metadata": {}, "execution_count": null, "cell_type": "code", "source": ["y_pred"], "outputs": []}, {"metadata": {"collapsed": true}, "cell_type": "markdown", "source": ["\u00d3timo! J\u00e1 temos aquilo que precis\u00e1vamos. Pr\u00f3ximo passo agora \u00e9 empacotar num arquivo CSV e submeter no Kaggle."]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["submission_df = pd.DataFrame()"], "outputs": []}, {"metadata": {}, "execution_count": null, "cell_type": "code", "source": ["submission_df['PassengerId'] = test_df['PassengerId']\n", "submission_df['Survived'] = y_pred\n", "submission_df"], "outputs": []}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["submission_df.to_csv('basic_random_forest.csv', index=False)"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Por favor, anote aqui para refer\u00eancia: quanto foi o seu score de treinamento do modelo? E no dataset de Valida\u00e7\u00e3o? Quanto foi o seu score na submiss\u00e3o do Kaggle?"]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "source": [], "outputs": []}], "nbformat_minor": 1}