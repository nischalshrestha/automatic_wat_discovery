{"cells":[{"metadata":{"_uuid":"0e719e161e575d6abf34a55fc89b2f7939595cac"},"cell_type":"markdown","source":"# 80% accuracy in a dead-simple, fair and non-overfitting model\n\n### If you like it, upvote it.  =]"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Default imports from Kaggle\nimport numpy as np\nimport pandas as pd\nimport os\nprint(os.listdir(\"../input\"))\n\n# Custom imports\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Handy in order to display maps inside notebook\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def show_correlation(df, feature_name, target_name, plot=True, plot_kind='bar'):\n    ''' Shows the \"correlation\" (in a not necessarily statistic meaning) between a feature and its target. '''\n    try:\n        print('corr', df[feature_name].corr(df[target_name]))\n    except:\n        pass\n\n    gb = df[[feature_name, target_name]].groupby(feature_name).agg('mean')\n    print(gb)\n    \n    if plot:\n        gb.plot(kind=plot_kind)\n\n\ndef onehot(df, column_name):\n    ''' Transforms a particular categorical field in \"onehot\" so it can be used for the classification models. '''\n    return pd.concat([df, pd.get_dummies(df[column_name], prefix='_OneHot{}'.format(column_name))], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e17d315ba8be77bed85807260460763d3a0ef1e2"},"cell_type":"code","source":"df = pd.read_csv('../input/train.csv')\ndf['_NumRelatives'] = df['Parch'] + df['SibSp']\ndf['_AgeBin'] = pd.cut(df['Age'], 8)\n\ndel df['Cabin']  # Just because it contains a lot of NaN/null values\ndf.dropna(inplace=True)\n\ndf = onehot(df, 'Sex')\ndf = onehot(df, 'Pclass')  # Despite being numeric this is a categorical feature (numeric value per se doesn't make sense here; after all values act more like labels) \n\n# Brief overview of our dataframe\nprint('*' * 10)\nprint(df.info())\n\n# Elaborate about our dataframe so we can decide what to use as our model features\nprint('*' * 10)\nshow_correlation(df, 'Pclass', 'Survived')\n\nprint('*' * 10)\nshow_correlation(df, 'Sex', 'Survived')\n\nprint('*' * 10)\nshow_correlation(df, '_AgeBin', 'Survived')\n\nprint('*' * 10)\nshow_correlation(df, '_NumRelatives', 'Survived')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7615f4b6b2c501fb0f06685668fc1fd852bfbcb2"},"cell_type":"code","source":"relevant_features = [\n    '_OneHotPclass_1', '_OneHotPclass_2', '_OneHotPclass_3',\n    '_OneHotSex_male', '_OneHotSex_female',\n    'Age',\n    '_NumRelatives'\n]\n\nX = df[relevant_features]\ny = df['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  # We have too few data, so prioritize this for the training set.\n\ninner_clf = LogisticRegression(penalty='l1', solver='liblinear')\nclf = make_pipeline(\n    MinMaxScaler(),  # Scale our features to be within 0..1\n    SelectFromModel(inner_clf),  # Remove unnecessary features (mitigating risk of overfitting)\n    inner_clf,  # Apply the classifier per se\n)\nclf.fit(X_train, y_train)\n\nscores = cross_val_score(clf, X_test, y_test, cv=10)\nprint('Accuracy score: ~{:.2f}%'.format(np.mean(scores) * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55c3c70914afb624b897a1e2a22c63c5bb4309fc"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}