{"cells":[{"metadata":{"_uuid":"d975a8f8a3a79fa8e57086383ff7c3761a44b0e5"},"cell_type":"markdown","source":"This script takes as an input the CSV files from the Kaggle Titanic Dataset (https://www.kaggle.com/c/titanic)\nThese CSV files contain information on Passenger ID, Ticket Price, Age, Sex, etc.\nThe 'training data' file contains a column titled 'Survived', while the 'testing data' file does not contain the column titled 'Survived'.\nThis script uses the aforementioned data to predict whether or not each passenger survived.","outputs":[],"execution_count":null},{"metadata":{"_uuid":"ace878393697491f244817326a19630021a9b624"},"cell_type":"markdown","source":"*Step 1: Import Modules*","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"5bd9a03d-da8a-4972-98cb-9c8fe03acd63","_uuid":"762c961a4e091428ba743b4633127f5bfb3322e3","collapsed":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport itertools\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, learning_curve, GridSearchCV\n#from sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import confusion_matrix\n%matplotlib inline\n\n# os.chdir('/Users/ptm/desktop/Current_working_directory')\n# trainingData = pd.read_csv('train.csv')\n# testingData = pd.read_csv('test.csv')\ntrainingData = pd.read_csv('../input/train.csv')\ntestingData = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da2ba68874cc28f7a556d5f50e229ef08aa119ad"},"cell_type":"markdown","source":"*Step 2: Inspect Data*","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"a2cb4e3e-ced7-4689-8aa7-e645f7e36ee1","_kg_hide-output":false,"_uuid":"6233805bbb2ee3f3392a364998b214bee14f0048","trusted":true},"cell_type":"code","source":"def describeTheData(input):\n    \"\"\" \n    Describe: (1) the name of each column; (2) the number of values in each column; \n    (3) the number of missing/NaN values in each column; (4) the contents of the first 5 rows; and\n    (5) the contents of the last 5 rows.\n    \"\"\"  \n    print('\\nColumn Values:\\n')\n    print(input.columns.values)\n    print('\\nValue Counts:\\n')\n    print(input.info())\n    print('\\nNull Value Counts:\\n')\n    print(input.isnull().sum())\n    print('\\nFirst Few Values:\\n')\n    print(input.head())\n    print('\\nLast Few Values:\\n')\n    print(input.tail())\n    print('')\ndescribeTheData(trainingData)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fef91f6dd8304552b14c59c252d16eecb6f96c4d"},"cell_type":"markdown","source":"*Step 3: Plot Data*","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"30ebff61-7807-4fe4-9439-0ca62ff9b6d0","_uuid":"e7839ed41c535b7a895f6aada804e4fd698119b6","trusted":true},"cell_type":"code","source":"def plotAgeDistribution(input):\n    \"\"\" \n    Plot the distribution of ages for passengers that either did or did not survive the sinking of the Titanic.\n    \"\"\"  \n    sns.set_style(\"whitegrid\")\n    distributionOne = sns.FacetGrid(input, hue=\"Survived\",aspect=2)\n    distributionOne.map(plt.hist, 'Age', bins=12)\n    distributionOne.add_legend()\n    distributionOne.set_axis_labels('Age', 'Count')\n    distributionOne.fig.suptitle('Survival Probability vs Age (Blue = Died; Orange = Survived)')\n    distributionTwo = sns.FacetGrid(input, hue=\"Survived\",aspect=2)\n    distributionTwo.map(sns.kdeplot,'Age',shade= True)\n    distributionTwo.set(xlim=(0, input['Age'].max()))\n    distributionTwo.add_legend()\n    distributionTwo.set_axis_labels('Age', 'Proportion')\n    distributionTwo.fig.suptitle('Survival Probability vs Age (Blue = Died; Orange = Survived)')\nplotAgeDistribution(trainingData)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a0e9cef7f4c68161aac6183b98f52541d790b27"},"cell_type":"markdown","source":"*Step 4: Minimize Dataset*","outputs":[],"execution_count":null},{"metadata":{"_uuid":"24fcd53673276f5eba330fb6cb61dc852f6c8a65"},"cell_type":"markdown","source":"Hmm... it looks like passengers that were less than five years old were much more likely\nto have survived, but maybe there is not much of a correlation for any other age group.\nAs you can see, it is a bit tricky to extract meaning from all of this data.\nMaybe it would be easier to understand if we started out with a much smaller dataset?\nFor the sake of simplicity, we are going to delete a bunch of columns, leaving us with \nonly the core of our dataset.  Don't worry, we will replace these missing features later, \nin addition to also creating some new features.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"3195fcf1-a502-44f4-b7f8-71c3e7fa4ff2","_uuid":"6a65c5346fb2dff88fcb66ce16460d810f5667b2","collapsed":true,"trusted":true},"cell_type":"code","source":"trainingData = trainingData.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Embarked', 'Cabin'], axis=1)\ntestingData = testingData.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Embarked', 'Cabin'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4999f62aa2e39dc44e0f1b5a536505933034c22e"},"cell_type":"markdown","source":"*Step 5: Preprocess Data*","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"d5acb8f4-768d-4c68-b050-d238c0aa3663","_uuid":"f66003bfa95836824c0460c3a6d22b59dd2ca698","collapsed":true,"trusted":true},"cell_type":"code","source":"def replaceMissingValuesWithMedianValues(input):\n    input['Fare'].fillna(input['Fare'].dropna().median(), inplace=True)   \n    input['Age'].fillna(input['Fare'].dropna().median(), inplace=True)\nreplaceMissingValuesWithMedianValues(trainingData)\nreplaceMissingValuesWithMedianValues(testingData)\n\ndef sexToBinary(input):\n    \"\"\" 0 = \"female\" and 1 = \"male\".\"\"\" \n    trainingData[\"Sex\"] = trainingData[\"Sex\"].astype(\"category\")\n    trainingData[\"Sex\"].cat.categories = [0,1]\n    trainingData[\"Sex\"] = trainingData[\"Sex\"].astype(\"int\")\nsexToBinary(trainingData)\nsexToBinary(testingData)\n\ndef ageToCategory(input):\n    \"\"\" \n    0 = \"ages between 0 and 4\", 1 = \"ages between 4 and 12\",\n    2 = \"ages between 12 and 18\", 3 = \"ages between 18 and 60\", and 4 = \"ages between 60 and 150\".\n    \"\"\" \n    input['Age'] = input.Age.fillna(-0.5)\n    bins = (-0.01, 4, 12, 18, 60, 150)\n    categories = pd.cut(input.Age, bins, labels=False)\n    input.Age = categories\nageToCategory(trainingData)\nageToCategory(testingData)\n\ndef fareToCategory(input):\n    \"\"\" \n    0 = \"ticket price < $10\", 1 = \"$10<X<$20\", 2 = \"$20<X<$30\", \n    and 3 = \"ticket price > $30\".\n    \"\"\" \n    input['Fare'] = input.Fare.fillna(-0.5)\n    bins = (-0.01, 10, 20, 30, 1000)\n    categories = pd.cut(input.Fare, bins, labels=False)\n    input.Fare = categories\nfareToCategory(trainingData)\nfareToCategory(testingData)\n\n# Next we will need to split up our training data, setting aside 20% of the training data for cross-validation testing, such that we can avoid potentially overfitting the data.\nxValues = trainingData.drop(['Survived'], axis=1)\nyValues = trainingData['Survived']\nX_train, X_test, Y_train, Y_test = train_test_split(xValues, yValues, test_size=0.2, random_state=23)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"420194e5b3ec2c680b08019360b08d5eba87210d"},"cell_type":"markdown","source":"*Step 6: Describe new data*","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"363b15a7-02fc-4882-916e-958c6475383f","_uuid":"dc39084ffbd5b3df71e280645cdeeaabc168383d","trusted":true},"cell_type":"code","source":"def describeDataAgain(input):\n    \"\"\" \n    The output is as follows: (1) the name of each column; (2) the contents of the first 5 rows; and\n    (3) the number of missing/NaN values in each column; \n    \"\"\" \n    print('\\nNew summary of data after making changes:\\n')\n    print('Column Values:\\n')\n    print(input.columns.values)\n    print('\\nFirst Few Values:\\n')\n    print(input.head())\n    print('\\nNull Value Counts:\\n')\n    print(input.isnull().sum())\n    print(\"\")\ndescribeDataAgain(trainingData)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"94289856-fe17-49f7-88c8-9fbba4e320b6","_uuid":"a24f7bbe53838883cfd6da22759e25d76546e066","trusted":true},"cell_type":"code","source":"def makeAHeatMap(input):\n    \"\"\"  heatmap showing the relationship between each numerical feature \"\"\"  \n    plt.figure(figsize=[8,6])\n    heatmap = sns.heatmap(input.corr(), vmax=1.0, square=True, annot=True)\n    heatmap.set_title('Pearson Correlation Coefficients')\nmakeAHeatMap(trainingData)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4560ba6fb944e2136a6737b7107e7fcfca20bdce"},"cell_type":"markdown","source":"It looks like there is a pretty good correlation between surivival probability and ticket price, ticket class, and gender.  Let's explore this in more detail.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"ed1c69a1-50fb-482c-a101-b563bdca1fc7","_uuid":"0aad602a45c1399f442e3862d7140cb8d3892661","trusted":true},"cell_type":"code","source":"def pivotTheData(input):\n    print('\\nPivot Tables:\\n')\n    print(input[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n    print('')\n    print(input[[\"Fare\", \"Survived\"]].groupby(['Fare'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n    print('')\n    print(input[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n    print('')\n    return\npivotTheData(trainingData)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9098030d00d539da3342fa0e3ef8007392451eda"},"cell_type":"markdown","source":"*Step 7: Plot new data*","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"271c0492-2d2d-4604-a51d-563feba04133","_uuid":"287a0664e8b42b3b5dbde42e0a1836b900e93ba3","trusted":true},"cell_type":"code","source":"def plotTheData(input):\n    \"\"\" \n    The output is as follows: (1) survival probability vs gender; (2) survival probability vs ticket class; \n    and (3) survival probability vs gender vs ticket class.\n    \"\"\"  \n    plt.figure(figsize=[10,6])\n    plt.subplot(221)\n    plotOne = sns.barplot('Sex', 'Survived', data=input, capsize=.1)\n    plotOne.set_title('Survival Probability vs Gender (Blue=Female, Green=Male)')\n    plt.subplot(222)\n    plotTwo = sns.barplot('Pclass', 'Survived', data=input, capsize=.1, linewidth=2.5, facecolor=(1, 1, 1, 0), errcolor=\".2\", edgecolor=\".2\")\n    plotTwo.set_title('Survival Probability vs Ticket Class')\nplotTheData(trainingData)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9263f121af1e01c791c2d8e180ecad91cf87f948"},"cell_type":"markdown","source":"We can see here that women have a higher probability of survival as compared to men.\nSimilarly, passengers with First Class tickets have a higher probability of surivival than those without.\nNow let's look at both variables at the same time.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"4f193718-9a92-4d1d-874f-95dbc85e462a","_uuid":"01d8fb32b70730ce954879fef62ab7b04690212b","trusted":true},"cell_type":"code","source":"def plotTheDataAgain(input):\n    \"\"\" \n    The output is as follows: (1) survival probability vs gender; (2) survival probability vs ticket class; \n    and (3) survival probability vs gender vs ticket class.\n    \"\"\"  \n    plt.figure(figsize=[8,5])\n    plotThree = sns.pointplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=input,\n                  palette={1: \"green\", 0: \"blue\"},\n                  markers=[\"*\", \"o\"], linestyles=[\"-\", \"--\"]);\n    plotThree.set_title('Survival Probability vs Gender vs Ticket Class (Blue=Female, Green=Male)')\nplotTheDataAgain(trainingData)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce03e4ed19290c0b6ecce2b38b822fd114e4d5b9"},"cell_type":"markdown","source":"It looks like the passengers with the highest probability of survival were female passengers with First Class tickets.  Great!  This means that our classification algorithms should have something good to work with.  Next we will identify a suitable classification algorithm that we can use to predict whether or not a given passenger might survive.","outputs":[],"execution_count":null},{"metadata":{"_uuid":"fa196df0eb455d85ddd647429d897e1b9fe90ed5"},"cell_type":"markdown","source":"*Step 8: Compare classification algorithms*","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"afc2062a-94f8-451c-8cf1-cf88c84a1c41","_uuid":"92627c39fce9b754339d45ccb0bbc54b00434d9a","trusted":true},"cell_type":"code","source":"def compareABunchOfDifferentModelsAccuracy(a,b,c,d):\n    print('\\nCompare Multiple Classifiers:\\n')\n    print('K-Fold Cross-Validation Accuracy:\\n')\n    models = []\n    models.append(('LR', LogisticRegression()))\n    models.append(('RF', RandomForestClassifier()))\n    models.append(('KNN', KNeighborsClassifier()))\n    models.append(('SVM', SVC()))\n    models.append(('LSVM', LinearSVC()))\n    models.append(('GNB', GaussianNB()))\n    models.append(('DTC', DecisionTreeClassifier()))\n    models.append(('GBC', GradientBoostingClassifier()))\n    models.append(('LDA', LinearDiscriminantAnalysis())) \n    resultsAccuracy = []\n    names = []\n    for name, model in models:\n        model.fit(a, b)\n        kfold = model_selection.KFold(n_splits=10, random_state=7)\n        accuracy_results = model_selection.cross_val_score(model, a, b, cv=kfold, scoring='accuracy')\n        resultsAccuracy.append(accuracy_results)\n        names.append(name)\n        accuracyMessage = \"%s: %f (%f)\" % (name, accuracy_results.mean(), accuracy_results.std())\n        print(accuracyMessage)\n    # boxplot algorithm comparison\n    fig = plt.figure()\n    fig.suptitle('Algorithm Comparison: Accuracy')\n    ax = fig.add_subplot(111)\n    plt.boxplot(resultsAccuracy)\n    ax.set_xticklabels(names)\n    ax.set_ylabel('Cross-Validation: Accuracy Score')\n    plt.show()\ncompareABunchOfDifferentModelsAccuracy(X_train, Y_train, X_test, Y_test)\n\ndef defineModels():\n    print('\\nLR = LogisticRegression')\n    print('RF = RandomForestClassifier')\n    print('KNN = KNeighborsClassifier')\n    print('SVM = Support Vector Machine SVC')\n    print('LSVM = LinearSVC')\n    print('GNB = GaussianNB')\n    print('DTC = DecisionTreeClassifier')\n    print('GBC = GradientBoostingClassifier')\n    print('LDA = LinearDiscriminantAnalysis\\n')\ndefineModels()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"60576c8c-16e1-41da-9b63-1337d4288d2a","_uuid":"6b0fbe3b758375fdd7c88a76fb75399bf94c8ca9","trusted":true},"cell_type":"code","source":"def compareABunchOfDifferentModelsF1Score(a,b,c,d):\n    print('\\nCompare Multiple Classifiers:\\n')\n    print('F1 Score:\\n')\n    models = []\n    models.append(('LR', LogisticRegression()))\n    models.append(('RF', RandomForestClassifier()))\n    models.append(('KNN', KNeighborsClassifier()))\n    models.append(('SVM', SVC()))\n    models.append(('LSVM', LinearSVC()))\n    models.append(('GNB', GaussianNB()))\n    models.append(('DTC', DecisionTreeClassifier()))\n    models.append(('GBC', GradientBoostingClassifier()))\n    models.append(('LDA', LinearDiscriminantAnalysis()))\n    resultsF1 = []\n    names = []\n    for name, model in models:\n        model.fit(a, b)\n        kfold = model_selection.KFold(n_splits=10, random_state=7)\n        f1_results = model_selection.cross_val_score(model, a, b, cv=kfold, scoring='f1_macro')\n        resultsF1.append(f1_results)\n        names.append(name)\n        f1Message = \"%s: %f (%f)\" % (name, f1_results.mean(), f1_results.std())\n        print(f1Message)\n    fig = plt.figure()\n    fig.suptitle('Algorithm Comparison: F1 Score')\n    ax = fig.add_subplot(111)\n    plt.boxplot(resultsF1)\n    ax.set_xticklabels(names)\n    ax.set_ylabel('Cross-Validation: F1 Score')\n    plt.show()\ncompareABunchOfDifferentModelsF1Score(X_train, Y_train, X_test, Y_test)\ndefineModels()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a1035baa-69dc-47a9-89ca-6694e5a402f9","_uuid":"aefafb5d9882a58949096b47ebb882cf40eed11d","trusted":true},"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"\n    Plots a learning curve. http://scikit-learn.org/stable/modules/learning_curve.html\n    \"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt\nplot_learning_curve(LogisticRegression(), 'Learning Curve For Logistic Regression Classifier', X_train, Y_train, (0.75,0.95), 10)\nplot_learning_curve(KNeighborsClassifier(), 'Learning Curve For K Neighbors Classifier', X_train, Y_train, (0.75,0.95), 10)\nplot_learning_curve(SVC(), 'Learning Curve For SVM Classifier', X_train, Y_train, (0.75,0.95), 10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ecedd059bebe3e5ae4b1c1be85c30db40a3395d"},"cell_type":"markdown","source":"It looks like maybe the Support Vector Machine algorithm is the best classifier to use for this application.  The learning curve\nyou see here for the Support Vector Machine suggests that we do not suffer too much from either overfitting or bias.","outputs":[],"execution_count":null},{"metadata":{"_uuid":"3790417b7cf8790feafb00ad158035131c3f9a22"},"cell_type":"markdown","source":"Step 9: Optimize Parameters","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"7d4f32c2-ebe3-4ec8-97bc-a805d24cf744","_uuid":"c3491f12e19668add1fff59827a5c9025cc61eb1","trusted":true},"cell_type":"code","source":"def selectParametersForLR(a, b, c, d):\n    model = LogisticRegression()\n    parameters = {'C': [0.01, 0.1, 0.5, 1.0, 5.0, 10, 25, 50, 100],\n                  'solver' : ['newton-cg', 'lbfgs', 'liblinear']}\n    accuracy_scorer = make_scorer(accuracy_score)\n    grid_obj = GridSearchCV(model, parameters, scoring=accuracy_scorer, error_score = 0.01)\n    grid_obj = grid_obj.fit(a, b)\n    model = grid_obj.best_estimator_\n    model.fit(a, b)\n    print('\\nSelected Parameters for LR:\\n')\n    print(model)\n    print('')\n#    predictions = model.predict(c)\n#    print(accuracy_score(d, predictions))\n#    print('Logistic Regression - Training set accuracy: %s' % accuracy_score(d, predictions))\n    kfold = model_selection.KFold(n_splits=10, random_state=7)\n    accuracy = model_selection.cross_val_score(model, a, b, cv=kfold, scoring='accuracy')\n    mean = accuracy.mean() \n    stdev = accuracy.std()\n    print('\\nLogistic Regression - Training set accuracy: %s (%s)' % (mean, stdev))\nselectParametersForLR(X_train, Y_train, X_test, Y_test)\n\ndef selectParametersForSVM(a, b, c, d):\n    model = SVC()\n    parameters = {'C': [0.01, 0.1, 0.5, 1.0, 5.0, 10, 25, 50, 100],\n                  'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n    accuracy_scorer = make_scorer(accuracy_score)\n    grid_obj = GridSearchCV(model, parameters, scoring=accuracy_scorer)\n    grid_obj = grid_obj.fit(a, b)\n    model = grid_obj.best_estimator_\n    model.fit(a, b)\n    print('\\nSelected Parameters for SVM:\\n')\n    print(model)\n#    predictions = model.predict(c)\n#    print(accuracy_score(d, predictions))\n#    print('Logistic Regression - Training set accuracy: %s' % accuracy_score(d, predictions))\n    kfold = model_selection.KFold(n_splits=10, random_state=7)\n    accuracy = model_selection.cross_val_score(model, a, b, cv=kfold, scoring='accuracy')\n    mean = accuracy.mean() \n    stdev = accuracy.std()\n    print('\\nSupport Vector Machine - Training set accuracy: %s (%s)' % (mean, stdev))\nselectParametersForSVM(X_train, Y_train, X_test, Y_test)\n\ndef selectParametersForKNN(a, b, c, d):\n\n    model = KNeighborsClassifier()\n    parameters = {'n_neighbors': [5, 10, 25, 50],\n                  'algorithm': ['ball_tree', 'kd_tree'],\n                  'leaf_size': [5, 10, 25, 50]}\n    accuracy_scorer = make_scorer(accuracy_score)\n    grid_obj = GridSearchCV(model, parameters, scoring=accuracy_scorer)\n    grid_obj = grid_obj.fit(a, b)\n    model = grid_obj.best_estimator_\n    model.fit(a, b)\n    print('\\nSelected Parameters for KNN:\\n')\n    print(model)\n#    predictions = model.predict(c)\n#    print(accuracy_score(d, predictions))\n#    print('Logistic Regression - Training set accuracy: %s' % accuracy_score(d, predictions))\n    kfold = model_selection.KFold(n_splits=10, random_state=7)\n    accuracy = model_selection.cross_val_score(model, a, b, cv=kfold, scoring='accuracy')\n    mean = accuracy.mean() \n    stdev = accuracy.std()\n    print('\\nK-Nearest Neighbors Classifier - Training set accuracy: %s (%s)' % (mean, stdev))\n    print('')\nselectParametersForKNN(X_train, Y_train,  X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ecf76e41f194b334f33f1d3c1836c973025ee520"},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (5,5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\ndict_characters = {0: 'Did Not Survive', 1: 'Survived'}\n\ndef runSVMconfusion(a,b,c,d):\n    classifier = SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\n    classifier.fit(a, b)\n    kfold = model_selection.KFold(n_splits=10, random_state=7)\n    accuracy = model_selection.cross_val_score(classifier, a, b, cv=kfold, scoring='accuracy')\n    mean = accuracy.mean() \n    stdev = accuracy.std()\n    print('SKlearn Multi-layer Perceptron NN - Training set accuracy: %s (%s)\\n' % (mean, stdev))\n    prediction = classifier.predict(c)\n    cnf_matrix = confusion_matrix(d, prediction)\n    np.set_printoptions(precision=2)\n    class_names = dict_characters \n    plt.figure()\n    plot_confusion_matrix(cnf_matrix, classes=class_names,title='Confusion matrix')\nplot_learning_curve(SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False), 'Learning Curve For SVM Classifier', X_train, Y_train, (0.75,0.95), 10)\nrunSVMconfusion(X_train, Y_train,  X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"670d144a-2c13-43a6-aeae-5647c8269891","_uuid":"623e5ce098efa6e832387287d8a8577614b687df","collapsed":true,"trusted":true},"cell_type":"code","source":"# It looks like our model can predict with about 70-75% accuracty whether or not a given\n# passenger survived the sinking of the Titanic despite using only a minimal dataset.  That is pretty good!\n\n#testingData2 = pd.read_csv('test.csv')\n#model = SVC()s\n#model.fit(X_train, Y_train)\n#prediction = model.predict(testingData)\n#submission = pd.DataFrame({\n#    \"PassengerId\": testingData2[\"PassengerId\"],\n#    \"Survived\": prediction})\n#submission.to_csv('new_submission.csv', index=False)\n\n# to finish the submission process, upload the file 'new_submission.csv' to Kaggle\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"nbformat":4,"nbformat_minor":1}