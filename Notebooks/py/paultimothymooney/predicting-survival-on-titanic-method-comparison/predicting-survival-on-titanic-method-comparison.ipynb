{"cells":[{"metadata":{"_uuid":"d33895cb99537c87358a356e921595cda7cbc015","_cell_guid":"a55477a9-5127-4369-ba28-6c73c7671929"},"cell_type":"markdown","source":"This script takes as an input the CSV files from the Kaggle Titanic Dataset (https://www.kaggle.com/c/titanic).  These CSV files contain information on Passenger ID, Ticket Price, Age, Sex, etc.  This script uses the aforementioned data to predict whether or not each passenger survived.","outputs":[],"execution_count":null},{"metadata":{"_uuid":"a1dd0886cd75f58345df03224c232a96c85f11e0","_cell_guid":"7594e58b-1de3-4153-83e3-e4576a37c0cf"},"cell_type":"markdown","source":"\tTABLE OF CONTENTS\n    a.\tPart One: 75% Accuracy with a Minimal Dataset\n        i.\tLoad Data\n        ii.\tProcess Data\n        iii.\tDescribe Data \n        iv.\tMake Predictions \n        v.\tSubmit Predictions \n    b.\tPart Two: 80% Accuracy with an Expanded Dataset\n        i.\tLoad Data\n        ii.\tProcess Data\n        iii.\tEngineer Data\n        iv.  Select Features \n        v.\tMake Predictions \n        vi.\tSubmit Predictions \n","outputs":[],"execution_count":null},{"metadata":{"_uuid":"5cf99b7c0bbd27772ea5c23a7cb36af7aa8ce8d0","_cell_guid":"bfdde9f7-8439-48bb-bfa9-c6dc62502475"},"cell_type":"markdown","source":"*Step 1: Import Modules*","outputs":[],"execution_count":null},{"metadata":{"_uuid":"f233fe1a22306dcb1538c7b58c92e2443760d094","_cell_guid":"a34ed82b-1421-46e8-9925-1c1b66125409","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport itertools\nfrom __future__ import print_function\nfrom sklearn import model_selection\nfrom sklearn.model_selection import KFold, cross_val_score, StratifiedKFold, StratifiedKFold, GridSearchCV, train_test_split, learning_curve\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.datasets import make_classification\nfrom sklearn.metrics import make_scorer, accuracy_score, confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.neural_network import MLPClassifier as MLPC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import PCA\nfrom keras.models import Sequential\nfrom keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n%matplotlib inline\n#os.chdir('/Users/ptm/desktop/Current_working_directory')\n\n#trainingData = pd.read_csv('train.csv')\n#testingData = pd.read_csv('test.csv')\ntrainingData = pd.read_csv('../input/train.csv')\ntestingData = pd.read_csv('../input/test.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6750fd247c8cc853291bcf3eb3b4aa93304de34b","_cell_guid":"74c19b50-c11d-4bf3-a75d-0624d31ae6a7"},"cell_type":"markdown","source":"*Step 2: Describe Data*","outputs":[],"execution_count":null},{"metadata":{"_uuid":"2652e1a60f6f0438817760b9a89aac666b4d6f53","_cell_guid":"2d7ad2c1-9b6a-4647-a739-d4fc1b4b766c","trusted":true},"cell_type":"code","source":"def describeTheData(input):\n    \"\"\" \n    Describe: (1) the name of each column; (2) the number of values in each column; \n    (3) the number of missing/NaN values in each column; (4) the contents of the first 5 rows; and\n    (5) the contents of the last 5 rows.\n    \"\"\"  \n    print('\\nColumn Values:\\n')\n    print(input.columns.values)\n    print('\\nValue Counts:\\n')\n    print(input.info())\n    print('\\nNull Value Counts:\\n')\n    print(input.isnull().sum())\n    print('\\nFirst Few Values:\\n')\n    print(input.head())\n    print('\\nLast Few Values:\\n')\n    print(input.tail())\n    print('')\ndescribeTheData(trainingData)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f26650419f0f31c133a03b958defbaa8a3dce420","_cell_guid":"a77d9f19-9e52-4254-a186-30a8eb6217ed"},"cell_type":"markdown","source":"*Step 3: Plot Data*","outputs":[],"execution_count":null},{"metadata":{"_uuid":"a58765dbc37504637fffa1945dcc21506a4bee91","_cell_guid":"aaa1200a-ab42-4d60-864e-e558421162f6","trusted":true},"cell_type":"code","source":"def plotAgeDistribution(input):\n    \"\"\" \n    Plot the distribution of ages for passengers that either did or did not survive the sinking of the Titanic.\n    \"\"\"  \n    sns.set_style(\"whitegrid\")\n    distributionOne = sns.FacetGrid(input, hue=\"Survived\",aspect=2)\n    distributionOne.map(plt.hist, 'Age', bins=12)\n    distributionOne.add_legend()\n    distributionOne.set_axis_labels('Age', 'Count')\n    distributionOne.fig.suptitle('Survival Probability vs Age (Blue = Died; Orange = Survived)')\n    distributionTwo = sns.FacetGrid(input, hue=\"Survived\",aspect=2)\n    distributionTwo.map(sns.kdeplot,'Age',shade= True)\n    distributionTwo.set(xlim=(0, input['Age'].max()))\n    distributionTwo.add_legend()\n    distributionTwo.set_axis_labels('Age', 'Proportion')\n    distributionTwo.fig.suptitle('Survival Probability vs Age (Blue = Died; Orange = Survived)')\nplotAgeDistribution(trainingData)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6714412a6866ebba08bf79b8e9a95884df1ac1c1","_cell_guid":"9cd0d0c9-a0e9-4cf6-b171-0da1102cde36"},"cell_type":"markdown","source":"*Step 4: Minimize Dataset*","outputs":[],"execution_count":null},{"metadata":{"_uuid":"7e2c92ded1873c237048e673590c8ee6d5aaadb8","_cell_guid":"d116c65c-0dbc-4574-881e-baa48994d127","collapsed":true,"trusted":true},"cell_type":"code","source":"trainingData = trainingData.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Embarked', 'Cabin'], axis=1)\ntestingData = testingData.drop(['PassengerId', 'Name', 'SibSp', 'Parch', 'Ticket', 'Embarked', 'Cabin'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dcc22eecbc6c28a708d999d0a47256ba592c5a9c","_cell_guid":"49322bed-4f3f-4bad-abb3-8bab3e3eeed8"},"cell_type":"markdown","source":"*Step 5: Preprocess Data*","outputs":[],"execution_count":null},{"metadata":{"_uuid":"190d1f74d61eca56d1df9f5d7a16afacd6dc3284","_cell_guid":"797b3e24-c65a-4f66-b628-81abca80339e","collapsed":true,"trusted":true},"cell_type":"code","source":"def replaceMissingValuesWithMedianValues(input):\n    input['Fare'].fillna(input['Fare'].dropna().median(), inplace=True)   \n    input['Age'].fillna(input['Fare'].dropna().median(), inplace=True)\nreplaceMissingValuesWithMedianValues(trainingData)\nreplaceMissingValuesWithMedianValues(testingData)\n\ndef sexToBinary(input):\n    \"\"\" 0 = \"female\" and 1 = \"male\".\"\"\" \n    trainingData[\"Sex\"] = trainingData[\"Sex\"].astype(\"category\")\n    trainingData[\"Sex\"].cat.categories = [0,1]\n    trainingData[\"Sex\"] = trainingData[\"Sex\"].astype(\"int\")\nsexToBinary(trainingData)\nsexToBinary(testingData)\n\ndef ageToCategory(input):\n    \"\"\" \n    0 = \"ages between 0 and 4\", 1 = \"ages between 4 and 12\",\n    2 = \"ages between 12 and 18\", 3 = \"ages between 18 and 60\", and 4 = \"ages between 60 and 150\".\n    \"\"\" \n    input['Age'] = input.Age.fillna(-0.5)\n    bins = (-0.01, 4, 12, 18, 60, 150)\n    categories = pd.cut(input.Age, bins, labels=False)\n    input.Age = categories\nageToCategory(trainingData)\nageToCategory(testingData)\n\ndef fareToCategory(input):\n    \"\"\" \n    0 = \"ticket price < $10\", 1 = \"$10<X<$20\", 2 = \"$20<X<$30\", \n    and 3 = \"ticket price > $30\".\n    \"\"\" \n    input['Fare'] = input.Fare.fillna(-0.5)\n    bins = (-0.01, 10, 20, 30, 1000)\n    categories = pd.cut(input.Fare, bins, labels=False)\n    input.Fare = categories\nfareToCategory(trainingData)\nfareToCategory(testingData)\n\n# Next we will need to split up our training data, setting aside 20% of the training data for cross-validation testing, such that we can avoid potentially overfitting the data.\nxValues = trainingData.drop(['Survived'], axis=1)\nyValues = trainingData['Survived']\nX_train, X_test, Y_train, Y_test = train_test_split(xValues, yValues, test_size=0.2, random_state=23)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"771b3d86089b4efefb8219b1ffd51d66eff62396","_cell_guid":"ac79af51-04d7-46b7-9b0d-1b7897cb6f5f"},"cell_type":"markdown","source":"*Step 6: Describe new data*","outputs":[],"execution_count":null},{"metadata":{"_uuid":"5fc4e4208c98187826181d1b1ac19c1484d4f218","_cell_guid":"baf89c00-24f4-486d-8928-55438f682516","trusted":true},"cell_type":"code","source":"def describeDataAgain(input):\n    \"\"\" \n    The output is as follows: (1) the name of each column; (2) the contents of the first 5 rows; and\n    (3) the number of missing/NaN values in each column; \n    \"\"\" \n    print('\\nNew summary of data after making changes:\\n')\n    print('Column Values:\\n')\n    print(input.columns.values)\n    print('\\nFirst Few Values:\\n')\n    print(input.head())\n    print('\\nNull Value Counts:\\n')\n    print(input.isnull().sum())\n    print(\"\")\ndescribeDataAgain(trainingData)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"170171d25ce7e8b9f0d02a14bb5ed882ad84df93","_cell_guid":"f84e92e0-58f2-4cae-861a-dc7af94dc9ed","trusted":true},"cell_type":"code","source":"def makeAHeatMap(input):\n    \"\"\"  heatmap showing the relationship between each numerical feature \"\"\"  \n    plt.figure(figsize=[8,6])\n    heatmap = sns.heatmap(input.corr(), vmax=1.0, square=True, annot=True)\n    heatmap.set_title('Pearson Correlation Coefficients')\nmakeAHeatMap(trainingData)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f944aa37b080e6732d710b8651695e7323f3fd36","_cell_guid":"54852fea-7bdc-4a95-b9fa-93162b04eadb"},"cell_type":"markdown","source":"It looks like there is a pretty good correlation between surivival probability and ticket price, ticket class, and gender. Let's explore this in more detail.","outputs":[],"execution_count":null},{"metadata":{"_uuid":"e94ad2df859a1ac00f6773e705a08e857df38796","_cell_guid":"8a874911-09d0-4b1f-9c1c-ec86d0719b03","trusted":true},"cell_type":"code","source":"def pivotTheData(input):\n    print('\\nPivot Tables:\\n')\n    print(input[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n    print('')\n    print(input[[\"Fare\", \"Survived\"]].groupby(['Fare'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n    print('')\n    print(input[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False))\n    print('')\n    return\npivotTheData(trainingData)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08fb48c2956477eff2c0e99dbc90e956ec72c60a","_cell_guid":"ca747381-c48d-4b81-92ca-df5a6427c818"},"cell_type":"markdown","source":"*Step 7: Plot new data*","outputs":[],"execution_count":null},{"metadata":{"_uuid":"2b3ef56ddeae4b58d54b6913252ec9ae4e685ba1","_cell_guid":"c7ce3162-3337-4207-80d0-bf58959bb79a","trusted":true},"cell_type":"code","source":"def plotTheData(input):\n    \"\"\" \n    The output is as follows: (1) survival probability vs gender; (2) survival probability vs ticket class; \n    and (3) survival probability vs gender vs ticket class.\n    \"\"\"  \n    plt.figure(figsize=[10,6])\n    plt.subplot(221)\n    plotOne = sns.barplot('Sex', 'Survived', data=input, capsize=.1)\n    plotOne.set_title('Survival Probability vs Gender (Blue=Female, Green=Male)')\n    plt.subplot(222)\n    plotTwo = sns.barplot('Pclass', 'Survived', data=input, capsize=.1, linewidth=2.5, facecolor=(1, 1, 1, 0), errcolor=\".2\", edgecolor=\".2\")\n    plotTwo.set_title('Survival Probability vs Ticket Class')\nplotTheData(trainingData)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4530f01081c3977693b025e021af2f73ff7467a0","_cell_guid":"265a014d-b53c-488d-93c3-8d303ab0480f"},"cell_type":"markdown","source":"We can see here that women have a higher probability of survival as compared to men. Similarly, passengers with First Class tickets have a higher probability of surivival than those without. Now let's look at both variables at the same time.","outputs":[],"execution_count":null},{"metadata":{"_uuid":"7f9b36847947f55ced45a4e9851e25a554c162e9","_cell_guid":"f20f665d-f249-4fc6-af92-da7723b4bff0","trusted":true},"cell_type":"code","source":"def plotTheDataAgain(input):\n    \"\"\" \n    The output is as follows: (1) survival probability vs gender; (2) survival probability vs ticket class; \n    and (3) survival probability vs gender vs ticket class.\n    \"\"\"  \n    plt.figure(figsize=[8,5])\n    plotThree = sns.pointplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=input,\n                  palette={1: \"green\", 0: \"blue\"},\n                  markers=[\"*\", \"o\"], linestyles=[\"-\", \"--\"]);\n    plotThree.set_title('Survival Probability vs Gender vs Ticket Class (Blue=Female, Green=Male)')\nplotTheDataAgain(trainingData)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55744e9ccd5f00ac217a06ea6fd42cacac81d9eb","_cell_guid":"79662821-f7a8-4273-8346-dbe4790ae39f"},"cell_type":"markdown","source":"It looks like the passengers with the highest probability of survival were female passengers with First Class tickets. Great! This means that our classification algorithms should have something good to work with. Next we will identify a suitable classification algorithm that we can use to predict whether or not a given passenger might survive.","outputs":[],"execution_count":null},{"metadata":{"_uuid":"9e8433506f782a90e59be03582cd85dc89700241","_cell_guid":"8290034c-16f6-46c5-b623-3397adef1b53"},"cell_type":"markdown","source":"*Step 8: Compare classification algorithms*","outputs":[],"execution_count":null},{"metadata":{"_uuid":"14ad19b9baa0e0850c72ecb4cdb6f01a6e3d8091","_cell_guid":"9dc13fbd-228a-4295-aa69-0f6665d4f90d","trusted":true},"cell_type":"code","source":"def compareABunchOfDifferentModelsAccuracy(a,b,c,d):\n    print('\\nCompare Multiple Classifiers:\\n')\n    print('K-Fold Cross-Validation Accuracy:\\n')\n    models = []\n    models.append(('LR', LogisticRegression()))\n    models.append(('RF', RandomForestClassifier()))\n    models.append(('KNN', KNeighborsClassifier()))\n    models.append(('SVM', SVC()))\n    models.append(('LSVM', LinearSVC()))\n    models.append(('GNB', GaussianNB()))\n    models.append(('DTC', DecisionTreeClassifier()))\n    models.append(('GBC', GradientBoostingClassifier()))\n    models.append(('LDA', LinearDiscriminantAnalysis())) \n    resultsAccuracy = []\n    names = []\n    for name, model in models:\n        model.fit(a, b)\n        kfold = model_selection.KFold(n_splits=10, random_state=7)\n        accuracy_results = model_selection.cross_val_score(model, a,b, cv=kfold, scoring='accuracy')\n        resultsAccuracy.append(accuracy_results)\n        names.append(name)\n        accuracyMessage = \"%s: %f (%f)\" % (name, accuracy_results.mean(), accuracy_results.std())\n        print(accuracyMessage)\n    # boxplot algorithm comparison\n    fig = plt.figure()\n    fig.suptitle('Algorithm Comparison: Accuracy')\n    ax = fig.add_subplot(111)\n    plt.boxplot(resultsAccuracy)\n    ax.set_xticklabels(names)\n    ax.set_ylabel('Cross-Validation: Accuracy Score')\n    plt.show()\ncompareABunchOfDifferentModelsAccuracy(X_train, Y_train, X_test, Y_test)\n\ndef defineModels():\n    print('\\nLR = LogisticRegression')\n    print('RF = RandomForestClassifier')\n    print('KNN = KNeighborsClassifier')\n    print('SVM = Support Vector Machine SVC')\n    print('LSVM = LinearSVC')\n    print('GNB = GaussianNB')\n    print('DTC = DecisionTreeClassifier')\n    print('GBC = GradientBoostingClassifier')\n    print('LDA = LinearDiscriminantAnalysis\\n')\ndefineModels()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33d75c7299ec9ab6ce885aa377c824794cecf19c","_cell_guid":"13a560ca-248d-4145-b60f-6724b897f188","trusted":true},"cell_type":"code","source":"def compareABunchOfDifferentModelsF1Score(a,b,c,d):\n    print('\\nCompare Multiple Classifiers:\\n')\n    print('F1 Score:\\n')\n    models = []\n    models.append(('LR', LogisticRegression()))\n    models.append(('RF', RandomForestClassifier()))\n    models.append(('KNN', KNeighborsClassifier()))\n    models.append(('SVM', SVC()))\n    models.append(('LSVM', LinearSVC()))\n    models.append(('GNB', GaussianNB()))\n    models.append(('DTC', DecisionTreeClassifier()))\n    models.append(('GBC', GradientBoostingClassifier()))\n    models.append(('LDA', LinearDiscriminantAnalysis()))\n    resultsF1 = []\n    names = []\n    for name, model in models:\n        model.fit(a, b)\n        kfold = model_selection.KFold(n_splits=10, random_state=7)\n        f1_results = model_selection.cross_val_score(model, a,b, cv=kfold, scoring='f1_macro')\n        resultsF1.append(f1_results)\n        names.append(name)\n        f1Message = \"%s: %f (%f)\" % (name, f1_results.mean(), f1_results.std())\n        print(f1Message)\n    fig = plt.figure()\n    fig.suptitle('Algorithm Comparison: F1 Score')\n    ax = fig.add_subplot(111)\n    plt.boxplot(resultsF1)\n    ax.set_xticklabels(names)\n    ax.set_ylabel('Cross-Validation: F1 Score')\n    plt.show()\ncompareABunchOfDifferentModelsF1Score(X_train, Y_train, X_test, Y_test)\ndefineModels()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4bf5cba28dd3691c496b15feef40d395627fa623","_cell_guid":"785be2c7-03e8-4415-b973-1adfd51d94db","trusted":true},"cell_type":"code","source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"\n    Plots a learning curve. http://scikit-learn.org/stable/modules/learning_curve.html\n    \"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt\nplot_learning_curve(LogisticRegression(), 'Learning Curve For Logistic Regression Classifier', X_train, Y_train, (0.75,0.95), 10)\nplot_learning_curve(KNeighborsClassifier(), 'Learning Curve For K Neighbors Classifier', X_train, Y_train, (0.75,0.95), 10)\nplot_learning_curve(SVC(), 'Learning Curve For SVM Classifier', X_train, Y_train, (0.75,0.95), 10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5751da0aee9f831afce36c8a1657e8aa4e8a56a6","_cell_guid":"07c7c86e-b59d-45c5-bf64-ce3bf0b6bcba"},"cell_type":"markdown","source":"It looks like maybe the Support Vector Machine algorithm is the best classifier to use for this application. The learning curve you see here for the Support Vector Machine suggests that we do not suffer too much from either overfitting or bias.","outputs":[],"execution_count":null},{"metadata":{"_uuid":"cefbfedd059e870daab5546ff86f4a445301e584","_cell_guid":"25b830a6-18e3-46c8-acfc-ab0bb073ab65"},"cell_type":"markdown","source":"*Step 9: Optimize Parameters*","outputs":[],"execution_count":null},{"metadata":{"_uuid":"b8693bb56efd37fd4a377898bd050bf92eb6ce8f","_cell_guid":"80d805e9-5927-4ab5-a0bf-3ec42c57886a","trusted":true},"cell_type":"code","source":"def selectParametersForLR(a, b, c, d):\n    model = LogisticRegression()\n    parameters = {'C': [0.01, 0.1, 0.5, 1.0, 5.0, 10, 25, 50, 100],\n                  'solver' : ['newton-cg', 'lbfgs', 'liblinear']}\n    accuracy_scorer = make_scorer(accuracy_score)\n    grid_obj = GridSearchCV(model, parameters, scoring=accuracy_scorer, error_score = 0.01)\n    grid_obj = grid_obj.fit(a, b)\n    model = grid_obj.best_estimator_\n    model.fit(a, b)\n    print('\\nSelected Parameters for LR:\\n')\n    print(model)\n    print('')\n#    predictions = model.predict(c)\n#    print(accuracy_score(d, predictions))\n#    print('Logistic Regression - Training set accuracy: %s' % accuracy_score(d, predictions))\n    kfold = model_selection.KFold(n_splits=10, random_state=7)\n    accuracy = model_selection.cross_val_score(model, a,b, cv=kfold, scoring='accuracy')\n    mean = accuracy.mean() \n    stdev = accuracy.std()\n    print('\\nLogistic Regression - Training set accuracy: %s (%s)' % (mean, stdev))\nselectParametersForLR(X_train, Y_train, X_test, Y_test)\n\ndef selectParametersForSVM(a, b, c, d):\n    model = SVC()\n    parameters = {'C': [0.01, 0.1, 0.5, 1.0, 5.0, 10, 25, 50, 100],\n                  'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n    accuracy_scorer = make_scorer(accuracy_score)\n    grid_obj = GridSearchCV(model, parameters, scoring=accuracy_scorer)\n    grid_obj = grid_obj.fit(a, b)\n    model = grid_obj.best_estimator_\n    model.fit(a, b)\n    print('\\nSelected Parameters for SVM:\\n')\n    print(model)\n#    predictions = model.predict(c)\n#    print(accuracy_score(d, predictions))\n#    print('Logistic Regression - Training set accuracy: %s' % accuracy_score(d, predictions))\n    kfold = model_selection.KFold(n_splits=10, random_state=7)\n    accuracy = model_selection.cross_val_score(model, a,b, cv=kfold, scoring='accuracy')\n    mean = accuracy.mean() \n    stdev = accuracy.std()\n    print('\\nSupport Vector Machine - Training set accuracy: %s (%s)' % (mean, stdev))\nselectParametersForSVM(X_train, Y_train, X_test, Y_test)\n\ndef selectParametersForKNN(a, b, c, d):\n\n    model = KNeighborsClassifier()\n    parameters = {'n_neighbors': [5, 10, 25, 50],\n                  'algorithm': ['ball_tree', 'kd_tree'],\n                  'leaf_size': [5, 10, 25, 50]}\n    accuracy_scorer = make_scorer(accuracy_score)\n    grid_obj = GridSearchCV(model, parameters, scoring=accuracy_scorer)\n    grid_obj = grid_obj.fit(a, b)\n    model = grid_obj.best_estimator_\n    model.fit(a, b)\n    print('\\nSelected Parameters for KNN:\\n')\n    print(model)\n#    predictions = model.predict(c)\n#    print(accuracy_score(d, predictions))\n#    print('Logistic Regression - Training set accuracy: %s' % accuracy_score(d, predictions))\n    kfold = model_selection.KFold(n_splits=10, random_state=7)\n    accuracy = model_selection.cross_val_score(model, a,b, cv=kfold, scoring='accuracy')\n    mean = accuracy.mean() \n    stdev = accuracy.std()\n    print('\\nK-Nearest Neighbors Classifier - Training set accuracy: %s (%s)' % (mean, stdev))\n    print('')\nselectParametersForKNN(X_train, Y_train,  X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d7ef1fabe6bbee0955c085576a7c794b1d66223","_cell_guid":"ca898e39-199b-4ed5-b2b4-5dc14bf4f37d","trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (5,5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\ndict_characters = {0: 'Did Not Survive', 1: 'Survived'}\n\ndef runSVMconfusion(a,b,c,d):\n    classifier = SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\n    classifier.fit(a, b)\n    kfold = model_selection.KFold(n_splits=10, random_state=7)\n    accuracy = model_selection.cross_val_score(classifier, a,b, cv=kfold, scoring='accuracy')\n    mean = accuracy.mean() \n    stdev = accuracy.std()\n    print('SKlearn Multi-layer Perceptron NN - Training set accuracy: %s (%s)\\n' % (mean, stdev))\n    prediction = classifier.predict(c)\n    cnf_matrix = confusion_matrix(d, prediction)\n    np.set_printoptions(precision=2)\n    class_names = dict_characters \n    plt.figure()\n    plot_confusion_matrix(cnf_matrix, classes=class_names,title='Confusion matrix')\nplot_learning_curve(SVC(C=50, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False), 'Learning Curve For SVM Classifier', X_train, Y_train, (0.75,0.95), 10)\nrunSVMconfusion(X_train, Y_train,  X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01b49eb826f5b038862156b6a6101362b4ed3c7c","_cell_guid":"26f9f366-dbdb-4922-aa6a-0e411ebe3643"},"cell_type":"markdown","source":"It looks like our model can predict with about 70-75% accuracty whether or not a given passenger survived the sinking of the Titanic despite using only a minimal dataset.  That is pretty good!  Now we will try to improve our score by using the full dataset instead of the minimal dataset that we used above..","outputs":[],"execution_count":null},{"metadata":{"_uuid":"b6e5adb4d6cfc15ff934358b02183419540150ad","_cell_guid":"7d3c3f5a-df63-4929-9107-0b386959066d","collapsed":true},"cell_type":"markdown","source":"Part Two: 80% Accuracy with an Expanded Dataset\n\nIn Part One we achieved >75% accuracy by using a minimal dataset.\nIn Part Two we will achieve >80% accuracy by using an expanded dataset.","outputs":[],"execution_count":null},{"metadata":{"_uuid":"6e6663d475dd94a43e5223606fcfce5c15e79b14","_cell_guid":"8059cfe5-e398-48e5-bc4a-c69a04b9e4f6"},"cell_type":"markdown","source":"*Step 10: Load Preprocess the Full Dataset*","outputs":[],"execution_count":null},{"metadata":{"_uuid":"e8a04ab06e634974db018d65b80606506aa94fc3","_cell_guid":"fb3bb02a-f43c-402d-b51f-dba2865a5cef","collapsed":true,"trusted":true},"cell_type":"code","source":"#trainingData = pd.read_csv('train.csv')\n#testingData = pd.read_csv('test.csv')\ntrainingData = pd.read_csv('../input/train.csv')\ntestingData = pd.read_csv('../input/test.csv')\ntrainingData['is_test'] = 0 # this will be helpful when we split up the data again later\ntestingData['is_test'] = 1 \nfullData = pd.concat((trainingData, testingData), axis=0)\nfullData = fullData.drop(['PassengerId'], axis=1)\n\ndef replaceMissingWithMedian(dataframe):\n    \"\"\" Replace missing values wiht median values\"\"\"\n    dataframe['Fare'].fillna(fullData['Fare'].dropna().median(), inplace=True)   \n    dataframe['Age'].fillna(fullData['Age'].dropna().median(), inplace=True)\n    dataframe['Cabin'].fillna('Z', inplace=True)\n    dataframe['Embarked'].fillna('S', inplace=True)\n    dataframe = dataframe.fillna(-0.5)\nreplaceMissingWithMedian(fullData)\n\ndef replaceAgeNumbersWithCategories(dataframe):\n    \"\"\"Replace age numbers with age categories\"\"\"\n    dataframe['Age'] = dataframe.Age.fillna(-0.5)\n    bins = (-0.01, 4, 12, 18, 60, 150)\n    categories = pd.cut(dataframe.Age, bins, labels=False)\n    dataframe.Age = categories\nreplaceAgeNumbersWithCategories(fullData)\n\ndef replaceFareNumbersWithCategories(dataframe):\n    \"\"\"Replace fare numbers with fare categories\"\"\"\n    dataframe['Fare'] = dataframe.Fare.fillna(-0.5)\n    bins = (-0.01, 10, 20, 30, 1000)\n    categories = pd.cut(dataframe.Fare, bins, labels=False)\n    dataframe.Fare = categories\nreplaceFareNumbersWithCategories(fullData)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29e63d90ae15d0b2a56ba0697e044d528b7cfc02","_cell_guid":"8a64bda0-5aa6-4859-b495-a7912894ab93"},"cell_type":"markdown","source":"*Step 11: Engineer New Features*","outputs":[],"execution_count":null},{"metadata":{"_uuid":"d7827164e43a4f3196ac24261f44c6660ae192f3","_cell_guid":"18b09448-1422-4357-9827-ba5576a4d38a","trusted":true},"cell_type":"code","source":"def makeFeatureNameTitle(dataframe):\n    \"\"\" make feature Name Title from out feature Name\"\"\"\n    name = dataframe['Name']\n    full_name = name.str.split(', ', n=0, expand=True)\n    last_name = full_name[0]\n    titles = full_name[1].str.split('.', n=0, expand=True)\n    titles = titles[0]\n    dataframe['Name'] = titles\n    newTitles = titles.replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    dataframe['Name'] = newTitles\nmakeFeatureNameTitle(fullData)\n\ndef extractCabinLetterDeleteOther(dataframe):\n    \"\"\" Extract Cabin Letter from Cabin Name and Delete all other info\"\"\"\n    dataframe['Cabin'] = dataframe['Cabin'].str[0]    \n    # Extract Family Size from SibSp + Parch and then make new family size groups\n    dataframe['FamilySize'] = dataframe['SibSp'] + dataframe['Parch'] + 1\n    dataframe['FamilySize'] = dataframe.FamilySize.fillna(-0.5)\n    bins = (-1, 1, 2, 4, 6, 1000)\n    categories = pd.cut(dataframe.FamilySize, bins, labels=False)\n    dataframe['FamilySize'] = categories\nextractCabinLetterDeleteOther(fullData)\n\ndef extractTicketPrefix(dataframe):\n    \"\"\"Extract whether or not the Ticket Number has a Prefix (possibly indicating special privileges)\"\"\"\n    Ticket = []\n    for i in list(dataframe.Ticket):\n        if not i.isdigit() :\n            Ticket.append(\"1\")\n        else:\n            Ticket.append(\"0\")     \n    dataframe[\"Ticket\"] = Ticket\nextractTicketPrefix(fullData)\n\n# https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html\nfullData = pd.get_dummies(fullData, columns=['Pclass', 'Sex', 'Embarked', 'Age', 'Fare', 'Cabin', 'Name', 'FamilySize', 'Ticket'])\n# Now we split the combined data back into training and testing data since we have finished with the feature engineering\ntrainingData = fullData[fullData['is_test'] == 0]\ntestingData = fullData[fullData['is_test'] == 1]\n# Describe the data\ndescribeDataAgain(trainingData)\n\n#http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n#http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\nX = trainingData.drop(['Survived', 'is_test'], axis=1)\ny = trainingData['Survived']\nxValues = X\nyValues = y.values.ravel()\nX_train, X_test, Y_train, Y_test = train_test_split(xValues, yValues, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6344d694500a729d1c7beff84d8854a1974180e2","_cell_guid":"a8822700-d1a4-413f-9c7b-d0f1dc5e2166"},"cell_type":"markdown","source":"*Step 12: Compare Classification Algorithms*","outputs":[],"execution_count":null},{"metadata":{"_uuid":"ba33982d4ee51f0530b2315c972c68e3f126db40","_cell_guid":"77b9bb71-27c9-40b5-9ee8-8cec091f9441","trusted":true},"cell_type":"code","source":"compareABunchOfDifferentModelsAccuracy(X_train, Y_train, X_test, Y_test)\ndefineModels()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4464c5dbcfc840e0c6163f0d890c2a93047a8e9","_cell_guid":"d14300af-d049-4b6a-ae9a-7f10137d1134","trusted":true},"cell_type":"code","source":"# http://scikit-learn.org/stable/modules/learning_curve.html\ndef plotLotsOfLearningCurves(a,b):\n    \"\"\"Now let's plot a bunch of learning curves\n    # http://scikit-learn.org/stable/modules/learning_curve.html\n    \"\"\"\n    models = []\n    models.append(('LR', LogisticRegression()))\n    models.append(('RF', RandomForestClassifier()))\n    models.append(('KNN', KNeighborsClassifier()))\n    models.append(('SVM', SVC()))\n    models.append(('LSVM', LinearSVC()))\n    #models.append(('GNB', GaussianNB()))\n    #models.append(('DTC', DecisionTreeClassifier()))\n    models.append(('GBC', GradientBoostingClassifier()))\n    #models.append(('LDA', LinearDiscriminantAnalysis()))\n    for name, model in models:\n        plot_learning_curve(model, 'Learning Curve For %s Classifier'% (name), a,b, (0.75,0.95), 10)\nplotLotsOfLearningCurves(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c32a8ffaa36dd3278e4b575935ba1bd993b57c83","_cell_guid":"6eb50c3b-9ddf-4a3f-a921-c7be64b90843"},"cell_type":"markdown","source":"*Step 13: Feature Selection*","outputs":[],"execution_count":null},{"metadata":{"_uuid":"a32b74ac9edbed9faf0830226eb1fdd9d7c9355d","_cell_guid":"9b25a48b-5263-4a80-aa39-895911721f30","trusted":true},"cell_type":"code","source":"def determineOptimalFeatureNumber(a,b):\n    \"\"\"\n    #http://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html\n    \"\"\"\n    models = []\n    models.append(('LR', LogisticRegression()))\n    models.append(('RF', RandomForestClassifier()))\n    #models.append(('KNN', KNeighborsClassifier()))\n    #models.append(('SVM', SVC()))\n    models.append(('LSVM', LinearSVC()))\n    #models.append(('GNB', GaussianNB()))\n    models.append(('DTC', DecisionTreeClassifier()))\n    models.append(('GBC', GradientBoostingClassifier()))\n    #models.append(('LDA', LinearDiscriminantAnalysis()))\n    for name, model in models:\n        # Create the RFE object and compute a cross-validated score.\n        currentModel = model\n        # The \"accuracy\" scoring is proportional to the number of correct\n        # classifications\n        rfecv = RFECV(estimator=currentModel, step=1, cv=StratifiedKFold(2), scoring='accuracy')\n        rfecv.fit(a,b)\n        print(\"Optimal number of features : %d\" % rfecv.n_features_)\n        # Plot number of features VS. cross-validation scores\n        plt.figure()\n        plt.xlabel(\"Number of features selected for %s\" % (name))\n        plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n        plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n        plt.show()\ndetermineOptimalFeatureNumber(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"edb538a196fb9c7207b996e2d4083141426fe092","_cell_guid":"b1d0a003-171d-46a1-a875-f01daf742019","trusted":true},"cell_type":"code","source":"#Run LinearSVC\ndef runLinearSVC(a,b,c,d):\n    \"\"\"Run LinearSVC w/ Kfold CV\"\"\"\n    model = LinearSVC()\n    model.fit(a,b)\n    kfold = model_selection.KFold(n_splits=10)\n    accuracy = model_selection.cross_val_score(model, a,b, cv=kfold, scoring='accuracy')\n    mean = accuracy.mean() \n    stdev = accuracy.std()\n    print('LinearSVC - Training set accuracy: %s (%s)' % (mean, stdev))\n    print('')\nrunLinearSVC(X_train, Y_train, X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee1e8353750a49f5debbfa47c8fa708b254b13a5","_cell_guid":"dc25b012-6124-4e24-af52-b478e215f023","trusted":true},"cell_type":"code","source":"# Identify best feature coefficients (coef_) and/or feature importance (feature_importances_)\nmodel = LinearSVC()\nmodel.fit(X_train,Y_train) # Needed to initialize coef_\ncolumns = X_train.columns\ncoefficients = model.coef_.reshape(X_train.columns.shape[0], 1)\nabsCoefficients = abs(coefficients)\nfullList = pd.concat((pd.DataFrame(columns, columns = ['Variable']), pd.DataFrame(absCoefficients, columns = ['absCoefficient'])), axis = 1).sort_values(by='absCoefficient', ascending = False)\nprint('LinearSVC - Feature Importance:\\n')\nprint(fullList)\nprint('')\n# Remove all but the most helpful features\ntopTwenty = fullList[:15]\nfeatureList = topTwenty.values\nfeatureList = pd.DataFrame(featureList)\nfeaturesOnly = featureList[0]\nfeaturesOnly = list(featuresOnly)\nfeaturesOnly += ['is_test', 'Survived']\nfullData = fullData[featuresOnly]\ntrainingData = fullData[fullData['is_test'] == 0]\ntestingData = fullData[fullData['is_test'] == 1]\n#g = sns.heatmap(trainingData[featuresOnly].corr(),cmap=\"BrBG\",annot=False)\n\n# Let's see if we improved our accuracy scores\nX = trainingData.drop(['Survived', 'is_test'], axis=1)\ny = trainingData['Survived']\nxValues = X\nyValues = y.values.ravel()\nX_train, X_test, Y_train, Y_test = train_test_split(xValues, yValues, test_size=0.2)\nprint('\\nDataset reduced to the following columns:\\n')\nprint(X_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7709d6817c2822b9fa24659c8e5c51473333826","_cell_guid":"173e6281-33c8-4383-b424-4a3b455e54db","trusted":true},"cell_type":"code","source":"print('\\nAfter feature selection:\\n')\nrunLinearSVC(X_train, Y_train, X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5af884e49c4aaecee793d853d608c2037c494446","_cell_guid":"5fce1e94-39ae-4ef5-86c2-b50f6b81ac60","trusted":true},"cell_type":"code","source":"print('After Feature Selection\\n')\ncompareABunchOfDifferentModelsAccuracy(X_train, Y_train, X_test, Y_test)\ndefineModels()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0beb0792957bc6d725a013b5fac433a65e6d33bb","_cell_guid":"616fc688-f861-487a-8b05-d53004e62e2c","trusted":true},"cell_type":"code","source":"g = sns.heatmap(X_train.corr(),cmap=\"BrBG\",annot=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23152cc90b2c9d1a5d72088a40866f42f2b60596","_cell_guid":"a87d3a0b-1d97-4392-bb3f-70412078decd"},"cell_type":"markdown","source":"Some of these features are highly correlated.  This can cause problems for some algorithms such as linear classifiers.  As such, we will now transform our features to make them no longer be correlated this is done by applying a transformation and dimensionality reduction to the data this process is called principal component analysis (PCA).  Fore more info, see the following documentaion: http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html , http://scikit-learn.org/stable/modules/decomposition.html#pca","outputs":[],"execution_count":null},{"metadata":{"_uuid":"34fc877be9f5605bd37d0e5512a3e58be195903d","_cell_guid":"22f717a1-fd18-44ce-9e62-c17bf7eb5596","trusted":true},"cell_type":"code","source":"# Minimum percentage of variance we want to be described by the resulting transformed components\nvariance_pct = .99\n# Create PCA object\npca = PCA(n_components=variance_pct)\n# Transform the initial features\nX_transformed = pca.fit_transform(X,y)\n# Create a data frame from the PCA'd data\npcaDataFrame = pd.DataFrame(X_transformed) \n#print(pcaDataFrame.shape[1], \" components describe \", str(variance_pct)[1:], \"% of the variance\")\n# Redefine X_train, X_test, Y_train, Y_test\nxValues = pcaDataFrame\nyValues = y.values.ravel()\nX_train, X_test, Y_train, Y_test = train_test_split(xValues, yValues, test_size=0.2)\n# Now do it to the test data as well\ntestingData = testingData.drop(['Survived', 'is_test'], axis=1)\ntestingData = pca.fit_transform(testingData)\ntestingData = pd.DataFrame(testingData) \n# There are fewer numbers of features now (dimensionality reduction)\n# The features are no longer correlated, as illustrated below:\ng = sns.heatmap(X_train.corr(),cmap=\"BrBG\",annot=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fad1c3b4c212b560e641156ebd16ddbbf42a5312","_cell_guid":"94e436b8-084a-4edd-9ee6-b3ef82c6c747"},"cell_type":"markdown","source":"*Step 14: Evaluate Classification Algorithms After Feature Selection*","outputs":[],"execution_count":null},{"metadata":{"_uuid":"3b162304b0a6ec4f37aa0b302e80ce2ab0fbea17","_cell_guid":"2cb86d6a-e00b-457f-8262-db0d7654c38b","trusted":true},"cell_type":"code","source":"print('\\nAfter feature selection + PCA:\\n')\nrunLinearSVC(X_train, Y_train, X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6ff2b69379f52e4251d590cedf59fd87d147de6","_cell_guid":"15a940d7-96df-46b2-b94d-b426cfcc9e0e","trusted":true},"cell_type":"code","source":"print('After Feature Selection + PCA\\n')\ncompareABunchOfDifferentModelsAccuracy(X_train, Y_train, X_test, Y_test)\ndefineModels()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4fc61eb11b6514524db1d4d69626c231203ff748","_cell_guid":"76d00e3e-10d5-422f-bf63-7e6f8c224cd9","trusted":true},"cell_type":"code","source":"plot_learning_curve(LinearSVC(), 'Learning Curve For %s Classifier'% ('LinearSVC'), X_train, Y_train, (0.75,0.95), 10)\nplot_learning_curve(LogisticRegression(), 'Learning Curve For %s Classifier'% ('LogisticRegression'), X_train, Y_train, (0.75,0.95), 10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df05484cd6a3ce8819d772a6c4a7f9fd3bfd0b08","_cell_guid":"f6a64abf-987e-4c4e-8246-36993923f456","trusted":true},"cell_type":"code","source":"def selectParametersForLSVM(a, b, c, d):\n    \"\"\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n    http://scikit-learn.org/stable/modules/grid_search.html#grid-search\"\"\"\n    model = LinearSVC()\n    parameters = {'C': [0.00001, 0.001, .01, 0.1, 0.5, 1.0, 5.0, 10, 25, 50, 100, 1000]}\n    accuracy_scorer = make_scorer(accuracy_score)\n    grid_obj = GridSearchCV(model, parameters, scoring=accuracy_scorer)\n    grid_obj = grid_obj.fit(a, b)\n    model = grid_obj.best_estimator_\n    model.fit(a, b)\n    print('Selected Parameters for LSVM:')\n    print('')\n    print(model)\n    print('')\n#    predictions = model.predict(c)\n#    print(accuracy_score(d, predictions))\n#    print('Logistic Regression - Training set accuracy: %s' % accuracy_score(d, predictions))\n    kfold = model_selection.KFold(n_splits=10)\n    accuracy = model_selection.cross_val_score(model, a,b, cv=kfold, scoring='accuracy')\n    mean = accuracy.mean() \n    stdev = accuracy.std()\n    print('Linear Support Vector Machine - Training set accuracy: %s (%s)' % (mean, stdev))\n    print('')\n    return\nselectParametersForLSVM(X_train, Y_train, X_test, Y_test)\nrunLinearSVC(X_train, Y_train, X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f745e1905ffcb7dd50021d56373ed7761edd921d","_cell_guid":"9608cd60-1104-47ad-8e5f-65a97db84e9f","trusted":true},"cell_type":"code","source":"def runMLPC(a,b,c,d):\n    classifier = MLPC(activation='relu', max_iter=1000)\n    classifier.fit(a, b)\n    kfold = model_selection.KFold(n_splits=10)\n    accuracy = model_selection.cross_val_score(classifier, a,b, cv=kfold, scoring='accuracy')\n    mean = accuracy.mean() \n    stdev = accuracy.std()\n    print('SKlearn Multi-layer Perceptron NN - Training set accuracy: %s (%s)' % (mean, stdev))\n    print('')\nrunMLPC(X_train, Y_train,  X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63513e6efe88e695908e2e6a42eddc4774a45dae","_cell_guid":"7a23814a-2b51-443c-aa22-36f838cdf172","trusted":true},"cell_type":"code","source":"def selectParametersForMLPC(a, b, c, d):\n    \"\"\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n    http://scikit-learn.org/stable/modules/grid_search.html#grid-search\"\"\"\n    model = MLPC()\n    parameters = {'verbose': [False],\n                  'activation': ['logistic', 'relu'],\n                  'max_iter': [1000, 2000], 'learning_rate': ['constant', 'adaptive']}\n    accuracy_scorer = make_scorer(accuracy_score)\n    grid_obj = GridSearchCV(model, parameters, scoring=accuracy_scorer)\n    grid_obj = grid_obj.fit(a, b)\n    model = grid_obj.best_estimator_\n    model.fit(a, b)\n    print('Selected Parameters for Multi-Layer Perceptron NN:\\n')\n    print(model)\n    print('')\n#    predictions = model.predict(c)\n#    print(accuracy_score(d, predictions))\n#    print('Logistic Regression - Training set accuracy: %s' % accuracy_score(d, predictions))\n    kfold = model_selection.KFold(n_splits=10)\n    accuracy = model_selection.cross_val_score(model, a,b, cv=kfold, scoring='accuracy')\n    mean = accuracy.mean() \n    stdev = accuracy.std()\n    print('SKlearn Multi-Layer Perceptron - Training set accuracy: %s (%s)' % (mean, stdev))\n    print('')\nselectParametersForMLPC(X_train, Y_train,  X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c2a56cf245824825ca2e15430512886ff716f38","_cell_guid":"5b545402-c7de-465e-a0b7-ccfb414356ff"},"cell_type":"markdown","source":"*Step 15: Evaluate Ensemble Voting Classification Strategy*","outputs":[],"execution_count":null},{"metadata":{"_uuid":"89adff2d763c5979ae3d19df344c80b0a1bf2bd3","_cell_guid":"d010a288-c5a5-4b5f-9ab9-63872124c0d5"},"cell_type":"markdown","source":"To try to get an even higher score, I will now combine the MLPC and LSVC/SVM methods by using a new method called ensemble voting.  This new method should help to avoid overfitting by taking into consideration both MLPC and SVMs predictions.  To learn more about the VotingClassifier function, see the following documentation:\nhttp://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\nhttp://scikit-learn.org/stable/modules/ensemble.html#voting-classifier","outputs":[],"execution_count":null},{"metadata":{"_uuid":"d0dcd9c6f110843a756242b64747c609119d663f","_cell_guid":"088b5ccc-0bdb-4f82-bc5f-77f1a0719abb","trusted":true},"cell_type":"code","source":"def runVotingClassifier(a,b,c,d):\n    \"\"\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n    http://scikit-learn.org/stable/modules/ensemble.html#voting-classifier\"\"\"\n    global votingC, mean, stdev # eventually I should get rid of these global variables and use classes instead.  in this case i need these variables for the submission function.\n    votingC = VotingClassifier(estimators=[('LSVM', LinearSVC(C=0.0001, class_weight=None, dual=True, fit_intercept=True,\n         intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n         multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n         verbose=0)), ('MLPC', MLPC(activation='logistic', alpha=0.0001, batch_size='auto',\n           beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n           hidden_layer_sizes=(100,), learning_rate='constant',\n           learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n           nesterovs_momentum=True, power_t=0.5, random_state=None,\n           shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n           verbose=False, warm_start=False))], voting='hard')  \n    votingC = votingC.fit(a,b)   \n    kfold = model_selection.KFold(n_splits=10)\n    accuracy = model_selection.cross_val_score(votingC, a,b, cv=kfold, scoring='accuracy')\n    meanC = accuracy.mean() \n    stdevC = accuracy.std()\n    print('Ensemble Voting Method - Training set accuracy: %s (%s)' % (meanC, stdevC))\n    print('')\n    return votingC, meanC, stdevC\nrunVotingClassifier(X_train,Y_train,X_test,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b25bfe419048ec0d76c7b2f766d1daca5c3bb87","_cell_guid":"9b647d46-1ed0-4942-8fde-424257d79a2c","trusted":true},"cell_type":"code","source":"model = votingC\nmodel.fit(X_train, Y_train)\nprediction = model.predict(X_test)\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(Y_test, prediction)\nnp.set_printoptions(precision=2)\n# Plot non-normalized confusion matrix\nclass_names = [\"Survived\", \"Did Not Survive\"]\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix, without normalization')\n# Plot normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n                      title='Normalized confusion matrix')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a2496be27f8a9f75ed4092d47196b54fd79808bc","_cell_guid":"6095f364-5eef-44f0-a8c6-9b117490548d"},"cell_type":"markdown","source":"It looks like our model can predict with about 80%-85% accuracty whether or not a given passenger survived the sinking of the Titanic.  That is pretty good!  It looks like when we make an error, the error tends to be to predict \"did not survive\" for someone who actually did survive.  So there is still room for improvement. But for now, I am satisfied with the performance of our current models.  After all, the sinking of the Titanic was a very chaotic event.","outputs":[],"execution_count":null},{"metadata":{"_uuid":"b729f149c5c58e683781bcd002084b557265d563","_cell_guid":"8a13d2c6-6893-431a-a0d7-a264e1540a89","collapsed":true,"trusted":true},"cell_type":"code","source":"# # Submission with Ensemble Voting Classification Method\n# testingData2 = pd.read_csv('../input/test.csv')\n# model = votingC\n# model.fit(X_train, Y_train)\n# prediction = model.predict(testingData)\n# prediction = prediction.astype(int)\n# submission = pd.DataFrame({\n#     \"PassengerId\": testingData2[\"PassengerId\"],\n#     \"Survived\": prediction})\n# submission.to_csv('_new_submission_ensemble.csv', index=False)\n# # to finish the submission process, upload the file '_new_submission_.csv' to Kaggle","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d88393665757df671589ff5435fd7c536fd91dbc","_cell_guid":"607aede6-e97f-4b02-aa13-a5f92eaf2a25","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}