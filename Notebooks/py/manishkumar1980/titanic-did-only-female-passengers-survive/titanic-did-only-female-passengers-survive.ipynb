{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-output": false, "_uuid": "0b20455bd3a0ed2da01660cce662462b2a37f6d6", "collapsed": true, "_cell_guid": "f3b1361b-0c67-4bd1-bc47-7c9c4c354a85", "_kg_hide-input": true}, "outputs": [], "source": ["# Importing the numpy and pandas libraries\n", "import numpy as np\n", "import pandas as pd"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-output": false, "_uuid": "7ef8167d6a612f523c0e8e23bf2dc4d70c8ccc4f", "_cell_guid": "a27a8a9b-9825-45e1-b3ac-d3597d36f468", "_kg_hide-input": true}, "outputs": [], "source": ["# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "50855d1034579cc2294b8a7a6ad8a5263a13fa9e", "_cell_guid": "568f5890-d720-470b-a195-df9e0a824223"}, "outputs": [], "source": ["# Data Preprocessing - Importing the dataset\n", "# Vector X contains Pclass, Sex, Age, Sibsp and Parch columns\n", "# Vector Y contains Survived column\n", "dataset = pd.read_csv('../input/train.csv')\n", "X = dataset.iloc[:, [2,4,5,6,7,11]].values\n", "y = dataset.iloc[:, 1:2].values\n", "\n", "# Removing 2 rows with Nan Embarked\n", "X = np.delete(X, (61, 829), axis=0)\n", "y = np.delete(y, (61, 829), axis=0)\n", "print(X[61:66])\n", "# print(y)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-output": false, "_uuid": "2c9f4194a10cfe761281e0bb34c42f197d7aa48e", "collapsed": true, "_cell_guid": "7364aafb-6b78-4dda-8590-0967d638c37d", "_kg_hide-input": true}, "outputs": [], "source": ["# Data Preprocessing - Replacing the missing Age values with average age of the dataset\n", "from sklearn.preprocessing import Imputer\n", "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n", "imputer = imputer.fit(X[:,2:3])\n", "X[:, 2:3] = imputer.transform(X[:, 2:3])\n", "# print(X)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "66dd0711666b19055caa506463c5e1ffdf76297c", "_cell_guid": "1ffc9696-7c1c-4d88-80aa-718721937af8"}, "outputs": [], "source": ["# Data Preprocessing - Encoding the Categorical Data for 'PClass' and 'Sex'\n", "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n", "labelencoder_X = LabelEncoder()\n", "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])\n", "X[:, 1] = labelencoder_X.fit_transform(X[:, 1])\n", "X[:, 5] = labelencoder_X.fit_transform(X[:, 5])\n", "onehotencoder = OneHotEncoder(categorical_features = [0,1,5])\n", "X = onehotencoder.fit_transform(X).toarray()\n", "print (X[0:6,0:8])\n", "# print (y)\n", "\n", "# Encoded Columns of X:\n", "# Index 0 - Pclass value 1\n", "# Index 1 - Pclass value 2\n", "# Index 2 - Pclass value 3\n", "# Index 3 - Sex value 'female'\n", "# Index 4 - Sex value 'male'\n", "# Index 5 - Embarked value 'C'\n", "# Index 6 - Embarked value 'Q'\n", "# Index 7 - Embarked value 'S'\n", "\n", "# Avoiding the Dummy Variable Trap\n", "# Removing the first column from each set of Dummy Variables for Pclass and Sex.\n", "# This removes the column representing Pclass value 1 and and Sex value 'female' respectively.\n", "X=X[:,[1,2,4,6,7,8,9,10]]\n", "print(X[0:6,0:8])\n", "\n", "# Final Indexes of X after removing one column each from both the Dummy Variable sets for Pclass and Sex:\n", "# Index 0 - Pclass value 2\n", "# Index 1 - Pclass value 3\n", "# Index 2 - Sex value 'male'\n", "# Index 3 - Embarked value 'Q'\n", "# Index 4 - Embarked value 'S'\n", "# Index 5 - Age\n", "# Index 6 - SibSp\n", "# Index 7 - Parch"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "e09db38be30fe5cab2e6bbbf207d6269d487a8b0", "_cell_guid": "32cb7e83-8f4b-4b9a-8604-5bf613ae9d6f"}, "outputs": [], "source": ["# Data Preprocessing - Creating the Training and the Test Set\n", "# There is a Test set provided with this exercise but that is to be used for submission purposes as it does not have Survived values\n", "# So, Splitting the dataset into the Training set and Test set to evaluate the performance of my Machine Learning Model\n", "from sklearn.model_selection import train_test_split\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n", "# print(X_train)\n", "# print(y_train)\n", "# print(X_test)\n", "# print(y_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "e1288bf20b5b34c7f1627d7f5e88f2990cb820ea", "collapsed": true, "_cell_guid": "faaf7e72-c606-44cc-a151-cc9e2b5527c2"}, "outputs": [], "source": ["# Data Preprocessing - Applying Feature Scaling\n", "from sklearn.preprocessing import StandardScaler\n", "sc = StandardScaler()\n", "X_train = sc.fit_transform(X_train)\n", "X_test = sc.transform(X_test)\n", "# print(X_train)\n", "# print(X_test)\n", "# print(y_train)\n", "# print(y_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "cb0055b542bc433ea27af2925338e1da42fb5f25", "_cell_guid": "6da45c49-b23a-4dd9-a592-dcc692044807"}, "outputs": [], "source": ["# Applying LDA\n", "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n", "# lda = LDA(n_components = 3)\n", "# X_train = lda.fit_transform(X_train, y_train.ravel())\n", "# X_test = lda.transform(X_test)\n", "\n", "# Applying Kernel PCA\n", "#from sklearn.decomposition import KernelPCA\n", "#kpca = KernelPCA(n_components = 2, kernel = 'rbf')\n", "#X_train = kpca.fit_transform(X_train)\n", "#X_test = kpca.transform(X_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "8ba9b80ca779c5c5d16a389154890f5b4ffb866b", "collapsed": true, "_cell_guid": "f9ed3f17-8757-4050-9810-85a5de034592"}, "outputs": [], "source": ["# Creating the Machine Learning Model using Random Forest Classification method\n", "# The optimal hyper parameters for the classifier has been optimized using Grid Search later in this code\n", "# from sklearn.ensemble import RandomForestClassifier\n", "# classifier = RandomForestClassifier(n_estimators = 12, criterion = 'gini', max_features = 'auto', random_state = 34)\n", "# classifier.fit(X_train, y_train.ravel())\n", "\n", "# Creating the Machine Learning Model using SVM method\n", "from sklearn.svm import SVC\n", "classifier = SVC(C = 0.3, gamma = 0.2, kernel = 'rbf', random_state = 0)\n", "classifier.fit(X_train, y_train.ravel())\n", "\n", "\n", "# Predicting the Test set results\n", "y_pred = classifier.predict(X_test)\n", "# print(y_test)\n", "# print(y_pred)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "12d802147b08b586d02aae6d6a2eb328e2c581be", "_cell_guid": "3ec341d9-0841-4ef3-9d6c-51ab823673f4"}, "outputs": [], "source": ["# Evaluating the Performance of the Machine Learning Model (classifier) - By creating a confusion matrix\n", "from sklearn.metrics import confusion_matrix\n", "cm = confusion_matrix(y_test, y_pred.ravel())\n", "print(cm)\n", "\n", "# Evaluating the Performance of the Machine Learning Model (classifier) - By applying k-Fold Cross Validation\n", "from sklearn.model_selection import cross_val_score\n", "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train.ravel(), cv = 10)\n", "mean=accuracies.mean()\n", "std=accuracies.std()\n", "print(mean)\n", "print(std)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "269439dba79a2b51a8decff2b586d06305b5f5c8", "_cell_guid": "59ee973a-1cf7-4044-9099-8550a8509f67"}, "source": ["# Applying Grid Search - For choosing the best model and the optimal values for the hyper parameters of the classifier\n", "\n", "from sklearn.model_selection import GridSearchCV\n", "parameters = [{'n_estimators': [12, 13, 14, 15, 16],\n", "               'criterion': ['entropy', 'gini'],\n", "               'max_features':['auto','sqrt','log2'],\n", "                'random_state':[30, 31, 32, 33, 34]}\n", "             ]\n", "grid_search = GridSearchCV(estimator = classifier,\n", "                           param_grid = parameters,\n", "                           scoring = 'accuracy',\n", "                           cv = 10,\n", "                           n_jobs = -1)\n", "grid_search = grid_search.fit(X_train, y_train.ravel())\n", "best_accuracy = grid_search.best_score_\n", "best_parameters = grid_search.best_params_\n", "print(best_accuracy)\n", "print(best_parameters)\n", "\n", "#Best Parameters - {'criterion': 'gini', 'max_features': 'auto', 'n_estimators': 14, 'random_state': 32}\n", "# These values are applied above in the Classifier"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "5db6808a629014dbb105a3c1d31740d59e1100a6", "_cell_guid": "7a08b26f-f47f-4ce4-b87c-2a88ee455618"}, "outputs": [], "source": ["# Applying Grid Search - For choosing the best model and the optimal values for the hyper parameters of the SVM classifier\n", "\n", "from sklearn.model_selection import GridSearchCV\n", "parameters = [{'C':[0.30, 0.325, 0.35, 0.375, 0.40],\n", "               'kernel': ['rbf'],\n", "               'gamma' : [0.16, 0.17, 0.18, 0.19, 0.20],\n", "               'random_state':[0, 5, 10]}\n", "             ]\n", "grid_search = GridSearchCV(estimator = classifier,\n", "                           param_grid = parameters,\n", "                           scoring = 'accuracy',\n", "                           cv = 10,\n", "                           n_jobs = -1)\n", "print('started...')\n", "grid_search = grid_search.fit(X_train, y_train.ravel())\n", "print('ended...')\n", "best_accuracy = grid_search.best_score_\n", "best_parameters = grid_search.best_params_\n", "print(best_accuracy)\n", "print(best_parameters)\n", "\n", "#Best Parameters - {'C': 0.75, 'gamma' : 0.25, 'kernel' : 'rbf', 'random_state': 0}\n", "# These values are applied above in the Classifier"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "894f957454cd5cd3bc4fe50fc39f88aaa1a472ed", "_cell_guid": "dcabf12a-84a4-469e-ba4c-a50aafd37de3"}, "outputs": [], "source": ["# Data Preprocessing - Importing the Test Set provided for submission\n", "dataset = pd.read_csv('../input/test.csv')\n", "X1 = dataset.iloc[:, [1,3,4,5,6,10]].values\n", "# print(X1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "fde0eaf5ec6457d12b0b62d397d4ab06d97764ee", "collapsed": true, "_cell_guid": "7f04716e-7739-4567-80c2-a0594a4c42f7"}, "outputs": [], "source": ["# Data Preprocessing - Replacing missing Age values with average age in the Test Set\n", "from sklearn.preprocessing import Imputer\n", "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n", "imputer = imputer.fit(X1[:,2:3])\n", "X1[:, 2:3] = imputer.transform(X1[:, 2:3])\n", "# print(X1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "a39f0e418638026f8468820e0d1e9b64f6b43851", "_cell_guid": "d0af758e-49d4-4569-8f2d-9ba26a9020e9"}, "outputs": [], "source": ["# Data Preprocessing - Encoding Categorical Data for 'PClass' and 'Sex' in the Test Set\n", "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n", "labelencoder_X1 = LabelEncoder()\n", "X1[:, 0] = labelencoder_X1.fit_transform(X1[:, 0])\n", "X1[:, 1] = labelencoder_X1.fit_transform(X1[:, 1])\n", "X1[:, 5] = labelencoder_X1.fit_transform(X1[:, 5])\n", "onehotencoder1 = OneHotEncoder(categorical_features = [0,1,5])\n", "X1 = onehotencoder1.fit_transform(X1).toarray()\n", "# print (X1[0:11,:])\n", "\n", "#Encoded Columns:\n", "# Index 0 - Pclass value 1\n", "# Index 1 - Pclass value 2\n", "# Index 2 - Pclass value 3\n", "# Index 3 - Sex value 'female'\n", "# Index 4 - Sex value 'male'\n", "\n", "# Avoiding the Dummy Variable Trap\n", "# Removing one dummy column each for Pclass and Sex i.e values 1 and 'female' respectively\n", "X1=X1[:,[1,2,4,6,7,8,9,10]]\n", "# print(X1)\n", "\n", "#Final Indexes:\n", "# Index 0 - Pclass value 2\n", "# Index 1 - Pclass value 3\n", "# Index 2 - Sex value 'male'\n", "# Index 3 - Age\n", "# Index 4 - SibSp\n", "# Index 5 - Parch"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "d28d9eece3c2d0581eb109b072e86fc176a46846", "collapsed": true, "_cell_guid": "5464d339-6513-4fea-966e-3c1d74f153dd"}, "outputs": [], "source": ["# Data Preprocessing - Defining the new Test set with the sample data provided in the exercise to evaluate whether all the female passengers got saved.\n", "X1_test = X1\n", "# print (X1_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "23a6e1551483e6206ad3ea324c4ef9a2df6eb851", "collapsed": true, "_cell_guid": "643da959-bfdf-4810-8464-4d8267ab2046"}, "outputs": [], "source": ["# Data Preprocessing -  Feature Scaling\n", "from sklearn.preprocessing import StandardScaler\n", "sc1 = StandardScaler()\n", "X1_test = sc1.fit_transform(X1_test)\n", "# print(X1_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "7a23ec073e31f130efeb1da0cb3cb817a8b6cd06", "_cell_guid": "dee02adf-72f6-47a1-b553-5b2bf85ef3a1"}, "outputs": [], "source": ["# Predicting the Test set results\n", "y1_pred = classifier.predict(X1_test)\n", "# print(y1_pred)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "9bf1152280f62510357ee1d6296edb647024ff71", "_cell_guid": "47ecf3c6-ff17-4aa1-a9a3-80573fb7fdc9"}, "outputs": [], "source": ["# Preparing the output in the desired format of PassengerID in the first column and Survival Prediction in the second column with the correct headers\n", "passengerID = dataset.iloc[:, 0:1].values\n", "# print (passengerID)\n", "result_set=np.column_stack((passengerID,y1_pred))\n", "columnnames = [_ for _ in ['PassengerID','Survived']]\n", "output = pd.DataFrame(result_set, columns=columnnames)\n", "print(output)\n", "\n", "# Dumping the predictions of the provided Test Set in the output.csv file\n", "output.to_csv('rbf.csv', index=False, header=True, sep=',')"]}], "nbformat_minor": 1, "metadata": {"language_info": {"file_extension": ".py", "name": "python", "pygments_lexer": "ipython3", "version": "3.6.3", "mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4}