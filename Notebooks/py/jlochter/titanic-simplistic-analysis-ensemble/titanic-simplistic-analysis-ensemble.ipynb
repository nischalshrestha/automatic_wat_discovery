{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df  = pd.read_csv('../input/test.csv')\n\nprint('Shape for training and testing dataset')\nprint('Train', train_df.shape)\nprint('Test', test_df.shape)\n\nprint()\nprint('Show which field has missing values in training dataset')\nprint(train_df.isna().sum())\n\nprint()\nprint('Show which field has missing values in testing dataset')\nprint(test_df.isna().sum())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b862813e2007d1bc7f3c503acfffe52603fc40e6"},"cell_type":"code","source":"## create a title field\nimport re\n\nrare_title = ['Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']\n\ntitles = train_df.Name.tolist()\ntitles = [re.sub('(.*, )|(\\\\..*)', '', t) for t in titles]\ntrain_df['Title'] = titles\n\ntitles = test_df.Name.tolist()\ntitles = [re.sub('(.*, )|(\\\\..*)', '', t) for t in titles]\ntest_df['Title'] = titles\n\ntrain_df.loc[train_df.Title == 'Mlle', 'Title'] = 'Miss'\ntrain_df.loc[train_df.Title == 'Ms', 'Title'] = 'Miss'\ntrain_df.loc[train_df.Title == 'Mme', 'Title'] = 'Mrs'\ntrain_df.loc[train_df.Title.isin(rare_title), 'Title'] = 'Rare'\n\ntest_df.loc[test_df.Title == 'Mlle', 'Title'] = 'Miss'\ntest_df.loc[test_df.Title == 'Ms', 'Title'] = 'Miss'\ntest_df.loc[test_df.Title == 'Mme', 'Title'] = 'Mrs'\ntest_df.loc[test_df.Title.isin(rare_title), 'Title'] = 'Rare'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f8f538f826055a6287965df80259ed9c721c91a"},"cell_type":"code","source":"## To fix missing values in a lazy manner, drop those fields\n\ntrain_df.drop(columns=['Age','Name','Ticket','Cabin'], inplace=True)\ntest_df.drop(columns=['Age','Name','Ticket','Cabin'], inplace=True)\n\nprint('Shape for training and testing dataset')\nprint('Train', train_df.shape)\nprint('Test', test_df.shape)\nprint()\n\n## But we still need to fill those Embarked in training dataset and that fare one in testing dataset\nprint('The uniques values for Embarked field:')\nprint(train_df.Embarked.unique())\ntrain_df.Embarked.fillna('C', inplace=True)\n\nprint()\nprint('The fare average for Fare field in testing dataset:')\nfare_mean = test_df.Fare.mean()\nprint(fare_mean)\ntest_df.Fare.fillna(fare_mean, inplace=True)\n\nprint()\nprint('Show which field has missing values in training dataset')\nprint(train_df.isna().sum())\n\nprint()\nprint('Show which field has missing values in testing dataset')\nprint(test_df.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c3b2ea291ab0be0788e4c3af432ce964573d04f"},"cell_type":"code","source":"## Converting fields to categorical and show its correlation\n\ntrain_X = pd.get_dummies(data=train_df,columns=['Title','Pclass','Parch','Sex','SibSp','Embarked'])\ntest_X  = pd.get_dummies(data=test_df, columns=['Title','Pclass','Parch','Sex','SibSp','Embarked'])\n\ntrain_Y = train_X.Survived\ntest_PassengerId = test_X.PassengerId\n\ntrain_X.drop(columns=['PassengerId'], inplace=True)\ntest_X.drop(columns=['PassengerId'], inplace=True)\n\ncorr = train_X.corr()\nf, ax = plt.subplots(figsize=(10, 10)) \ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, cmap=cmap, vmax=1.0, square=True, linewidths=.3, cbar_kws={\"shrink\": .5}, ax=ax) \nplt.show()\n\ntrain_X.drop(columns=['Survived'], inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df97429a992aaf02a27c2b3204280f8576d7619c"},"cell_type":"code","source":"## after dummies, check for shapes and fill columns to match them\nprint('Shapes:')\nprint(train_X.shape)\nprint(test_X.shape)\n\nprint()\nprint('Show columns for each dataset:')\nprint('Train:', sorted(train_X.columns))\nprint('Test:', sorted(test_X.columns))\n\ntrain_X['Parch_9'] = 0\n\nprint('Shapes:')\nprint(train_X.shape)\nprint(test_X.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1eac9aa03f1c2f3ddf7ffc6da9767ee80a8ea1ae"},"cell_type":"code","source":"## do machine learning magick \nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import VotingClassifier\n\nclf1 = LogisticRegression(random_state=1)\nclf2 = RandomForestClassifier(random_state=1)\nclf3 = MultinomialNB()\nclf4 = SVC(kernel='rbf', probability=True)\n\neclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3), ('svm', clf4)], voting='hard')\n\nfor clf, label in zip([clf1, clf2, clf3, clf4, eclf], ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'SVM', 'Ensemble']):\n    scores = cross_val_score(clf, train_X, train_Y, cv=10, scoring='accuracy')\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n    \neclf.fit(train_X, train_Y)\neclf_pred = eclf.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3aea4cec2b7d9feba07719b2df63120cdba7a67"},"cell_type":"code","source":"## generates output\n\nsubmission = pd.DataFrame(\n    {'PassengerId': test_PassengerId, 'Survived': eclf_pred},\n    columns = ['PassengerId', 'Survived'])\nsubmission.to_csv('submission.csv', index = False)\n\nprint(os.listdir('.'))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}