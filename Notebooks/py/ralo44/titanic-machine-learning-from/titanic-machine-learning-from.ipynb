{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"markdown","source":"\n\n\nThe objective of this competition is to know who passengers were likely to survive at Titanic's accident\nWe are exploring differents topics since visualizing, report, and present the problem solving steps and to find the final solution.\nFirst is neccesary to import packages to work with.\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc5134163458680d0551c6e35e4b082e2fb0e9b5"},"cell_type":"markdown","source":"Importing data"},{"metadata":{"trusted":true,"_uuid":"3c54c77f28625469adc11965d7f57e40bdd34bc5"},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ndata = train.append(test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b252067f8d3d1597d39666cdb17a15289506bee"},"cell_type":"code","source":"print('Train has {} files and {} columns'.format(train.shape[0], train.shape[1]))\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"b60f9844e9da6d617089962b8995ad96b646becd"},"cell_type":"markdown","source":"To know the total of columns"},{"metadata":{"trusted":true,"_uuid":"012cd4d82a01809491d0d9614af4fe93655dd229"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a47875996821683070b10a2e3f87a305bc1c0208"},"cell_type":"markdown","source":"To know the first 6 rows of train data"},{"metadata":{"trusted":true,"_uuid":"5f4de4483454f4968b76cc907ee1c7b3f6b4eebf"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"644a6be63ccf2815142157b50b8753b6518e865f"},"cell_type":"code","source":"print('Train has {} files and {} columns'.format(test.shape[0], test.shape[1]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bea21dea267bb1240c4a597dd3d8b451dd0178ea"},"cell_type":"code","source":"test.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d906225984dff269680f6f68657cfe356ec875ae"},"cell_type":"code","source":"test.info()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c9cd36b281a0344fddd7e9c73953ee2d2e98e6b1"},"cell_type":"markdown","source":"To know how many different int values are for each column"},{"metadata":{"trusted":true,"_uuid":"cd105d04e29a49fc25b3c03f54c76814a5c34747"},"cell_type":"code","source":"train.select_dtypes(int).nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"691eae60625012359ab46f36a52f0805b41cc787"},"cell_type":"code","source":"test.select_dtypes(int).nunique() \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7568e85a699b9d975e00d093e588291233495735"},"cell_type":"markdown","source":"**Clean Data**\nWrangle, prepare, cleanse the data\nDetecting null values on each column "},{"metadata":{"trusted":true,"_uuid":"e6d27b45dd72e8f269d2b76202b5efab49faace3"},"cell_type":"code","source":"print('Empty values by column in Train ', (train.isnull().sum()))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"731dae70774aa086c7880353f5f20119bf25e50d"},"cell_type":"code","source":"print('Empty values by column in Test ',(test.isnull().sum()))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8422649481b39ed259713181c062fa9613779598"},"cell_type":"markdown","source":"Working with Title and Name columns to fill out Age Nan values "},{"metadata":{"trusted":true,"_uuid":"79442c5df8c95d41bde2687ee5ff744b8f7ac0e7"},"cell_type":"code","source":"data['Title'] = data['Name']\n\nfor name_string in data['Name']:\n    data['Title'] = data['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n\n\nmapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr', 'Don': 'Mr', 'Mme': 'Miss',\n          'Jonkheer': 'Mr', 'Lady': 'Mrs', 'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\ndata.replace({'Title': mapping}, inplace=True)\ntitles = ['Dr', 'Master', 'Miss', 'Mr', 'Mrs', 'Rev']\nfor title in titles:\n    age_to_impute = data.groupby('Title')['Age'].median()[titles.index(title)]\n    data.loc[(data['Age'].isnull()) & (data['Title'] == title), 'Age'] = age_to_impute\n    \n# Substituting Age values in TRAIN and TEST:\ntrain['Age'] = data['Age'][:891]\ntest['Age'] = data['Age'][891:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3b98497df417bb6e848de2d7e7251572aa8c7de"},"cell_type":"markdown","source":"Create new column joining Parch and SibSp columns "},{"metadata":{"trusted":true,"_uuid":"aad5b764594e7af39170afeef926f47af8c31107"},"cell_type":"code","source":"data['Family_Size'] = data['Parch'] + data['SibSp']\n\ntrain['Family_Size'] = data['Family_Size'][:891]\ntest['Family_Size'] = data['Family_Size'][891:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4dadb89dc695a5fa276b3e7e0167f7aedb03338"},"cell_type":"markdown","source":"Drop unnecesary columns"},{"metadata":{"trusted":true,"_uuid":"f4e3152d5a088b18e4b027f62e86877eb6387192"},"cell_type":"code","source":"drop_column = [ 'Cabin', 'Ticket',  'Parch', 'SibSp', 'Name', 'Embarked']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f44eabda32b4c9d932a3cd4dc8552f2363d3412c"},"cell_type":"code","source":"train.drop(drop_column, axis = 1, inplace = True)\ntest.drop(drop_column, axis = 1, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6df3fadb66f7e6e162bec0878a9debdbc975d9a6"},"cell_type":"markdown","source":"Mapping str values to convert into float\n"},{"metadata":{"trusted":true,"_uuid":"9c7866a30cb58180347f0913c2b4515dfda3fc74"},"cell_type":"code","source":"mapping = {'male':1, 'female':0}\ntrain['Sex'] = train['Sex'].replace(mapping).astype(np.float64)\ntest['Sex'] = test['Sex'].replace(mapping).astype(np.float64)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00b610f2d1854615f238740cc684ca81ddb1d72e"},"cell_type":"markdown","source":"**Fill NaN values on Test"},{"metadata":{"trusted":true,"_uuid":"a2a2a5ae0cd320e261942a76cc14b778271ba30a"},"cell_type":"code","source":"\ntest['Fare'].fillna(value = test['Fare'].mode()[0], inplace = True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3450ca6365de3064752d68a1a1ca99c290526788"},"cell_type":"markdown","source":"Detect outliers"},{"metadata":{"trusted":true,"_uuid":"3d6584d72eedcabe774fc690521bc5016efd3139"},"cell_type":"code","source":"from collections import Counter\ndef detect_outliers(df,n,features):\n\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers\nOutliers_to_drop = detect_outliers(train,2,[[\"Pclass\", \"Sex\", \"Age\", \"Fare\",\"Family_Size\",\"Survived\"]])\ntrain.loc[Outliers_to_drop]\n\ntrain = train.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9255b8efa8ebcc5c74188eb8635f43e2409561f4"},"cell_type":"markdown","source":"**Plotting**"},{"metadata":{"trusted":true,"_uuid":"c65239015196c786d7816574f280344a1a14deeb"},"cell_type":"markdown","source":"To determine if Fare influence in Survival rate"},{"metadata":{"trusted":true,"_uuid":"e34b0aac482162847c0dbbeef748b297403bcb59"},"cell_type":"code","source":"plt.figure(figsize=[16,18])\nplt.subplot(234)\nplt.hist(x = [train[train['Survived']==1]['Fare'], train[train['Survived']==0]['Fare']], \n         stacked=True, color = ['g','r'],label = ['Survived','Dead'])\nplt.title('Fare Histogram by Survival')\nplt.xlabel('Fare ($)')\nplt.ylabel('# of Passengers')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"796c35b66ea3f853b7bc44438d9872c482fd49e9"},"cell_type":"markdown","source":"Barplot to determine Survival by Class"},{"metadata":{"trusted":true,"_uuid":"59d4307a622e46aab9a64ac6727947f4ae4610bb"},"cell_type":"code","source":"sns.barplot(x=\"Pclass\", y=\"Survived\", data=train)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Distribution of Survival by class\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33c0bea3c2cc05f0e3abbb414c794f1982dfab50"},"cell_type":"markdown","source":"**Correlation**"},{"metadata":{"trusted":true,"_uuid":"fdc4822885035f93d1b4ca147b51cd110461a788"},"cell_type":"code","source":"def correlation_heat(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorrelation_heat(train[[\"Pclass\", \"Sex\", \"Age\",  \"Fare\",\"Survived\"]])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ea4fd4b0b1ae521354944bcc380cf9b9a500fdd"},"cell_type":"markdown","source":"**Splitting data**"},{"metadata":{"trusted":true,"_uuid":"afa850e07eeabd027f2459b064fd849e05e8d6c6"},"cell_type":"code","source":"features = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Family_Size\"]\n#Columns to wrok with in Train\nX_train = train[features] #define training features set\ny_train = train[\"Survived\"] \n#Columns to work with in Test\nX_test = test[features] #define testing features set\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a00a5c139eeb40eaf1305bdedf071147d9fb8a8"},"cell_type":"markdown","source":"Infer missing data from known data"},{"metadata":{"_uuid":"bb22dcea4f9c82974e6d1bb77f6abf9c01f27a28"},"cell_type":"markdown","source":"to create validation data set"},{"metadata":{"trusted":true,"_uuid":"232389b19a07a2801f70b899dade99c4165170b8"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nX_training, X_valid, y_training, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0) \n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de906199c9e6a59ba180d6d06555567d3742ca85"},"cell_type":"markdown","source":"**Score data**"},{"metadata":{"trusted":true,"_uuid":"21245bd1cf68d8142dedaa76097e72dce5d14e77"},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import f1_score, make_scorer\nfrom sklearn.ensemble import RandomForestClassifier\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e0bc7039a15a8f2260e8f5c7accf1790acb091d4"},"cell_type":"markdown","source":"**Supervised Learning Estimators\n**\nHere we are detecting wich is the best model to predict the passengers status in test "},{"metadata":{"trusted":true,"_uuid":"d6adb6c487c2904fe8080081e698c09be3ccd002"},"cell_type":"code","source":"from sklearn.svm import LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import LogisticRegressionCV, RidgeClassifierCV\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nimport warnings \nfrom sklearn.exceptions import ConvergenceWarning\nfrom sklearn.metrics import f1_score, make_scorer\n\nscorer = make_scorer(f1_score, greater_is_better=True, average = 'macro')\n\nwarnings.filterwarnings('ignore', category = ConvergenceWarning)\nwarnings.filterwarnings('ignore', category = DeprecationWarning)\nwarnings.filterwarnings('ignore', category = UserWarning)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b80a15a7c82cd92b215df66434eb34f2672ac81"},"cell_type":"markdown","source":"Create a function to stock results of each model"},{"metadata":{"trusted":true,"_uuid":"3571d0cd955bf78ef8cff74161b56fa64eca7ae0"},"cell_type":"code","source":"model_results = pd.DataFrame(columns = ['model', 'cv_mean', 'cv_std'])\n\ndef cv_model(X_train, y_train, model, name, model_results = None, sort = True):\n    #10 fold cross validation model##\n    cv_scores = cross_val_score(model, X_train, y_train, cv = 10,\n                                scoring = scorer, n_jobs = -1)\n    print('Mean ', round(cv_scores.mean(), 5),'STd', round(cv_scores.std(), 5))\n    if model_results is not None:\n        model_results = model_results.append(pd.DataFrame({'model':name,\n                                                'cv_mean': cv_scores.mean(),\n                                                'cv_std' : cv_scores.std()},\n                                                index = [0]), ignore_index = True)\n    return model_results\n\nmodel_results = cv_model(X_train, y_train, LinearSVC(), 'LSVC', \n                         model_results)\n\nmodel_results = cv_model(X_train, y_train, \n                         GaussianNB(), 'GNB', model_results)\n\nmodel_results = cv_model(X_train, y_train, \n                         MLPClassifier(hidden_layer_sizes=(16, 32, 64, 64, 32)),\n                         'MLP', model_results)\n\nmodel_results = cv_model(X_train, y_train, \n                          LinearDiscriminantAnalysis(), \n                          'LDA', model_results)\n\nmodel_results = cv_model(X_train, y_train, \n                         RidgeClassifierCV(), 'RIDGE', model_results)\n\nfor n in [5, 10, 20]:\n    print('\\nKNN with {n} neighbors\\n', n)\n    model_results = cv_model(X_train, y_train, \n                             KNeighborsClassifier(n_neighbors = n),\n                             n, model_results)\n    \nfrom sklearn.ensemble import ExtraTreesClassifier\n\nmodel_results = cv_model(X_train, y_train, \n                         ExtraTreesClassifier(n_estimators = 100, random_state = 10),\n                         'EXT', model_results)\n\nmodel_results = cv_model(X_train, y_train,\n                          RandomForestClassifier(100, random_state=10),\n                              'RF', model_results)\nfrom xgboost import XGBClassifier\nmodel_results = cv_model(X_train, y_train,\n                          XGBClassifier(n_estimators= 100, random_state=10),\n                              'XGB', model_results)\n\nmodel_results.set_index('model', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a39d212b0f6ac89c6985c3f2d6d6d1eaaf2a9343","trusted":true},"cell_type":"code","source":"print(model_results)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62de5ff1fc43d655e9039bf099c2dbabd56c8fb9","trusted":true},"cell_type":"code","source":"model_results['cv_mean'].plot.bar(color = 'orange', figsize = (8, 6),\n                                  yerr = list(model_results['cv_std']))\nplt.title('Model F1 Score Results');\nplt.ylabel('Mean F1 Score (with error bar)');\nmodel_results.reset_index(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c00602b103f84c9478e662c880485128cd841cd4"},"cell_type":"markdown","source":"**Predict most accuracy output XGBoost **"},{"metadata":{"_uuid":"c13cd876e3885fc01e97c0c0c95d29ed0261ea20","trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer, accuracy_score \n\nxg_clf = XGBClassifier()\nparameters_rf = {'n_estimators' : [200],'learning_rate': [0.1],\n              'max_depth': [4], \"min_child_weight\":[6], \"gamma\":[0], \"subsample\":[0.80] \n                              }\n\n\ngrid_rf = GridSearchCV(xg_clf, parameters_rf, scoring=make_scorer(accuracy_score))\n#make_scorer(accuracy_score)\ngrid_rf.fit(X_training, y_training)\nxg_clf = grid_rf.best_estimator_\n\npred_xg = xg_clf.predict(X_valid)\nacc_xg = accuracy_score(y_valid, pred_xg)\nprint(\"The Score for XGBoost is: \" + str(acc_xg))\nprint(\"The best Score for XGBoost is: \" + str(grid_rf.best_score_))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"801f112ae0160acb61f4f27e1aeeb56bf7a2b31e"},"cell_type":"markdown","source":" **Predict most accuracy output RandomForest Classifier **"},{"metadata":{"trusted":true,"_uuid":"2f01f8376c92568fec4aa8ca279a643a64c98b62"},"cell_type":"code","source":"\n\n\nrf_clf = RandomForestClassifier()\n\nparameters_rf = {\"n_estimators\": [4, 5, 6, 7, 8, 9, 10, 15], \"criterion\": [\"gini\", \"entropy\"], \"max_features\": [\"auto\", \"sqrt\", \"log2\"], \n                 \"max_depth\": [2, 3, 5, 10], \"min_samples_split\": [2, 3, 5, 10]}\n\ngrid_rf = GridSearchCV(rf_clf, parameters_rf, scoring=make_scorer(accuracy_score))\ngrid_rf.fit(X_training, y_training)\n\nrf_clf = grid_rf.best_estimator_\n\nrf_clf.fit(X_training, y_training)\npred_rf = rf_clf.predict(X_valid)\nacc_rf = accuracy_score(y_valid, pred_rf)\n\nprint(\"The Score for Random Forest is: \" + str(acc_rf))\n\nprint(\"The best Score for Random Forest is: \" + str(grid_rf.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d189ab60d75386b38320351083f406ee0e5489df"},"cell_type":"markdown","source":"Export a submission file with the predictions of test Dataset"},{"metadata":{"trusted":true,"_uuid":"62b362793821e9e51108c8ac3c1c05100819fbf9"},"cell_type":"code","source":"submission_predictions = rf_clf.predict(X_test)\nsubmission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"],\n         \"Survived\": submission_predictions})\n \nsubmission.to_csv(\"titanicprediction.csv\", index=False)\nprint(submission.shape)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}