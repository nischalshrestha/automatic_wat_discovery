{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Titanic Survival Prediction\n#import pandas library for reading csv file \nimport pandas as pd\n\n#import numpy for numerical computation\n\nimport numpy as np\n\n#load train and test data\ntitanic = pd.read_csv(\"../input/train.csv\")\ntitanic_test = pd.read_csv(\"../input/test.csv\")\n\n#print first five rows of datafrTme\ntitanic.head(1)\n#titanic_test.head(5).T\n\n#shape is for number of rows and columns\ntitanic.shape\n#titanic_test.shape\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Describe gives statistical information about numerical columns in the dataset\ntitanic.describe()\n#we can see age having missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"baa3f3c3ff9af455fb54bbed7fcc24b27232c162"},"cell_type":"code","source":"titanic.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93bad9242b54bcd570efd783a60f9d52c402eadc"},"cell_type":"code","source":"#check number of null values in respective columns of train data\nnull_columns = titanic.columns[titanic.isnull().any()]\ntitanic.isnull().sum()\n#We have null values in Age, Cabin,Embarked columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3bc42abdb55554f8d05ecb16c2f46540e8157e0c"},"cell_type":"code","source":"# now check null value in test data\ntitanic_test.isnull().sum()\n#we can see null value in Age,Fare, Cabin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f373fa7c640f2b998bc9a9ff8306885f1056010e"},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(font_scale=1)\n\n#pd.options.display.mpl_style = 'default'\nlabels = []\nvalues = []\nfor col in null_columns:\n    labels.append(col)\n    values.append(titanic[col].isnull().sum())\nind = np.arange(len(labels))\nwidth=0.6\nfig, ax = plt.subplots(figsize=(12,5))\nrects = ax.barh(ind, np.array(values), color='black')\nax.set_yticks(ind+((width)/2.))\nax.set_yticklabels(labels, rotation='vertical')\nax.set_xlabel(\"Count of missing values\")\nax.set_ylabel(\"Column Names\")\nax.set_title(\"Variables with missing values\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"361f71c1f182dc1d0951fb7984646fd99e2e121f"},"cell_type":"code","source":"titanic.hist(bins=15,figsize=(12,7),grid=False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fec02ba1f1a4fa100b62c6f0792c7e5a3d78ca2"},"cell_type":"code","source":"g = sns.FacetGrid(titanic, col=\"Sex\", row=\"Survived\", margin_titles=True)\ng.map(plt.hist, \"Age\",color=\"black\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34448a039ba5064bcf1b7652b8cf633013ba3fdc"},"cell_type":"code","source":"g = sns.FacetGrid(titanic, hue=\"Survived\", col=\"Pclass\", margin_titles=True,\n                  palette={1:\"seagreen\", 0:\"gray\"})\ng=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfccb674d5ba212b19b19918bbade7ba30a43810"},"cell_type":"code","source":"g = sns.FacetGrid(titanic, hue=\"Survived\", col=\"Sex\", margin_titles=True,\n                palette=\"Set1\",hue_kws=dict(marker=[\"^\", \"v\"]))\ng.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\nplt.subplots_adjust(top=0.8)\ng.fig.suptitle('Survival by Gender , Age and Fare');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0696482a6e15ece6dc4fdd12183e68ee3ae3604"},"cell_type":"code","source":"titanic.Embarked.value_counts().plot(kind='bar', alpha=0.55)\nplt.title(\"Passengers per boarding location\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d172f333a6a5bc760d9a7e3d41da4ac869dc9441"},"cell_type":"code","source":"sns.set(font_scale=1)\ng = sns.factorplot(x=\"Sex\", y=\"Survived\", col=\"Pclass\",\n                    data=titanic, saturation=.5,\n                    kind=\"bar\", ci=None, aspect=.6)\n(g.set_axis_labels(\"\", \"Survival Rate\")\n    .set_xticklabels([\"Men\", \"Women\"])\n    .set_titles(\"{col_name} {col_var}\")\n    .set(ylim=(0, 1))\n    .despine(left=True))  \nplt.subplots_adjust(top=0.8)\ng.fig.suptitle('How many Men and Women Survived by Passenger Class');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e91e8ac3d683f13ed8e893b1bb2995a08c3bd197"},"cell_type":"code","source":"titanic.Age[titanic.Pclass == 1].plot(kind='kde')    \ntitanic.Age[titanic.Pclass == 2].plot(kind='kde')\ntitanic.Age[titanic.Pclass == 3].plot(kind='kde')\n # plots an axis lable\nplt.xlabel(\"Age\")    \nplt.title(\"Age Distribution within classes\")\n# sets our legend for our graph.\nplt.legend(('1st Class', '2nd Class','3rd Class'),loc='best') ;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29bbce49a130a44f1cb1435937038e481b3e17c4"},"cell_type":"code","source":"corr=titanic.corr()#[\"Survived\"]\nplt.figure(figsize=(10, 10))\n\nsns.heatmap(corr, vmax=.8, linewidths=0.01,\n            square=True,annot=True,cmap='YlGnBu',linecolor=\"white\")\nplt.title('Correlation between features');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7946fae3525fb4f41cf2f20101b9e057ae918d3b"},"cell_type":"code","source":"#correlation of features with target variable\ntitanic.corr()[\"Survived\"]\n#Looks like Pclass has got highest negative correlation with \"Survived\" followed by Fare, Parch and Age","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c34ef79fb0977a994bbb97097a23ca3bbd9fa969"},"cell_type":"markdown","source":"**Missing Value Imputation**\nIts important to fill missing values, because some machine learning algorithms can't accept them eg SVM.\n\nBut filling missing values with mean/median/mode is also a prediction which may not be 100% accurate, instead you can use models like Decision Trees and Random Forest which handle missing values very well.\n\nEmbarked Column\n\n"},{"metadata":{"trusted":true,"_uuid":"3aa89ee372d7a19d35843a5fbc4255776ed8bf39"},"cell_type":"code","source":"#Lets check which rows have null Embarked column\ntitanic[titanic['Embarked'].isnull()]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18f3f75d28f0ad86fc48ac1ae55de2fd1525790f"},"cell_type":"code","source":"titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna('C')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e8fe6df143842f3bd28890f87d6673ae0f2c4f8"},"cell_type":"code","source":"#there is an empty fare column in test set\ntitanic_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17806d9a1edb99885e1481a6fd97cef999758d90"},"cell_type":"code","source":"#Fare Column\ntitanic_test[titanic_test['Fare'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39821cf2ca85bfc164aa502138d07897040d4ddf"},"cell_type":"code","source":"#we can replace missing value in fare by taking median of all fares of those passengers \n#who share 3rd Passenger class and Embarked from 'S' \ndef fill_missing_fare(df):\n    median_fare=df[(df['Pclass'] == 3) & (df['Embarked'] == 'S')]['Fare'].median()\n#'S'\n       #print(median_fare)\n    df[\"Fare\"] = df[\"Fare\"].fillna(median_fare)\n    return df\n\ntitanic_test=fill_missing_fare(titanic_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"667f08875c023f60f9aa278267861c89326ff6f7"},"cell_type":"code","source":"titanic[\"Deck\"]=titanic.Cabin.str[0]\ntitanic_test[\"Deck\"]=titanic_test.Cabin.str[0]\ntitanic[\"Deck\"].unique() # 0 is for null values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fff95b2b3db746d45a85087862ef4f1fe3d13156"},"cell_type":"code","source":"# Create a family size variable including the passenger themselves\ntitanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]+1\ntitanic_test[\"FamilySize\"] = titanic_test[\"SibSp\"] + titanic_test[\"Parch\"]+1\nprint(titanic[\"FamilySize\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d831ec28442ec41be67f2bf5b08ea409a076c394"},"cell_type":"code","source":"# Discretize family size\ntitanic.loc[titanic[\"FamilySize\"] == 1, \"FsizeD\"] = 'singleton'\ntitanic.loc[(titanic[\"FamilySize\"] > 1)  &  (titanic[\"FamilySize\"] < 5) , \"FsizeD\"] = 'small'\ntitanic.loc[titanic[\"FamilySize\"] >4, \"FsizeD\"] = 'large'\n\ntitanic_test.loc[titanic_test[\"FamilySize\"] == 1, \"FsizeD\"] = 'singleton'\ntitanic_test.loc[(titanic_test[\"FamilySize\"] >1) & (titanic_test[\"FamilySize\"] <5) , \"FsizeD\"] = 'small'\ntitanic_test.loc[titanic_test[\"FamilySize\"] >4, \"FsizeD\"] = 'large'\nprint(titanic[\"FsizeD\"].unique())\nprint(titanic[\"FsizeD\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7127c1daa6aeefd1dac59259bfd6f85a0c363a7b"},"cell_type":"code","source":"g = sns.factorplot(\"Survived\", col=\"Deck\", col_wrap=4,\n                    data=titanic[titanic.Deck.notnull()],\n                    kind=\"count\", size=2.5, aspect=.8);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7b34af0eb60de21b44a2fd98ddcaf13325c445a"},"cell_type":"code","source":"titanic = titanic.assign(Deck=titanic.Deck.astype(object))\ng = sns.FacetGrid(titanic, col=\"Pclass\", sharex=False,\n                  gridspec_kws={\"width_ratios\": [5, 3, 3]})\ng.map(sns.boxplot, \"Deck\", \"Age\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb4360befb3ac532d2af48618c22080aa6c991d8"},"cell_type":"code","source":"titanic.Deck.fillna('Z', inplace=True)\ntitanic_test.Deck.fillna('Z', inplace=True)\ntitanic[\"Deck\"].unique() # Z is for null values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e634e81e4db93a6c057bf268c1a5d995798f315"},"cell_type":"code","source":"# Create a family size variable including the passenger themselves\ntitanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]+1\ntitanic_test[\"FamilySize\"] = titanic_test[\"SibSp\"] + titanic_test[\"Parch\"]+1\nprint(titanic[\"FamilySize\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3fb4025f1e58d54cae7dc5136839b3f3fb962e5"},"cell_type":"code","source":"# Discretize family size\ntitanic.loc[titanic[\"FamilySize\"] == 1, \"FsizeD\"] = 'singleton'\ntitanic.loc[(titanic[\"FamilySize\"] > 1)  &  (titanic[\"FamilySize\"] < 5) , \"FsizeD\"] = 'small'\ntitanic.loc[titanic[\"FamilySize\"] >4, \"FsizeD\"] = 'large'\n\ntitanic_test.loc[titanic_test[\"FamilySize\"] == 1, \"FsizeD\"] = 'singleton'\ntitanic_test.loc[(titanic_test[\"FamilySize\"] >1) & (titanic_test[\"FamilySize\"] <5) , \"FsizeD\"] = 'small'\ntitanic_test.loc[titanic_test[\"FamilySize\"] >4, \"FsizeD\"] = 'large'\nprint(titanic[\"FsizeD\"].unique())\nprint(titanic[\"FsizeD\"].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0628cd0905bb6a37d0f0430259f501fd35f6c371"},"cell_type":"code","source":"sns.factorplot(x=\"FsizeD\", y=\"Survived\", data=titanic);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"757f3d3de2f640cd12aa95ef37f16d47401dde95"},"cell_type":"code","source":"#Create feture for length of name \n# The .apply method generates a new series\ntitanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))\n\ntitanic_test[\"NameLength\"] = titanic_test[\"Name\"].apply(lambda x: len(x))\n#print(titanic[\"NameLength\"].value_counts())\n\nbins = [0, 20, 40, 57, 85]\ngroup_names = ['short', 'okay', 'good', 'long']\ntitanic['NlengthD'] = pd.cut(titanic['NameLength'], bins, labels=group_names)\ntitanic_test['NlengthD'] = pd.cut(titanic_test['NameLength'], bins, labels=group_names)\n\nsns.factorplot(x=\"NlengthD\", y=\"Survived\", data=titanic)\nprint(titanic[\"NlengthD\"].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"972e0a89f206e84dae4978b9c55ac3d077cac807"},"cell_type":"code","source":"import re\n\n#A function to get the title from a name.\ndef get_title(name):\n    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    #If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n\n#Get all the titles and print how often each one occurs.\ntitles = titanic[\"Name\"].apply(get_title)\nprint(pd.value_counts(titles))\n\n\n#Add in the title column.\ntitanic[\"Title\"] = titles\n\n# Titles with very low cell counts to be combined to \"rare\" level\nrare_title = ['Dona', 'Lady', 'Countess','Capt', 'Col', 'Don', \n                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']\n\n# Also reassign mlle, ms, and mme accordingly\ntitanic.loc[titanic[\"Title\"] == \"Mlle\", \"Title\"] = 'Miss'\ntitanic.loc[titanic[\"Title\"] == \"Ms\", \"Title\"] = 'Miss'\ntitanic.loc[titanic[\"Title\"] == \"Mme\", \"Title\"] = 'Mrs'\ntitanic.loc[titanic[\"Title\"] == \"Dona\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Lady\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Countess\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Capt\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Col\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Don\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Major\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Rev\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Sir\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Jonkheer\", \"Title\"] = 'Rare Title'\ntitanic.loc[titanic[\"Title\"] == \"Dr\", \"Title\"] = 'Rare Title'\n\n#titanic.loc[titanic[\"Title\"].isin(['Dona', 'Lady', 'Countess','Capt', 'Col', 'Don', \n#                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']), \"Title\"] = 'Rare Title'\n\n#titanic[titanic['Title'].isin(['Dona', 'Lady', 'Countess'])]\n#titanic.query(\"Title in ('Dona', 'Lady', 'Countess')\")\n\ntitanic[\"Title\"].value_counts()\n\n\ntitles = titanic_test[\"Name\"].apply(get_title)\nprint(pd.value_counts(titles))\n\n#Add in the title column.\ntitanic_test[\"Title\"] = titles\n\n# Titles with very low cell counts to be combined to \"rare\" level\nrare_title = ['Dona', 'Lady', 'Countess','Capt', 'Col', 'Don', \n                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']\n\n# Also reassign mlle, ms, and mme accordingly\ntitanic_test.loc[titanic_test[\"Title\"] == \"Mlle\", \"Title\"] = 'Miss'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Ms\", \"Title\"] = 'Miss'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Mme\", \"Title\"] = 'Mrs'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Dona\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Lady\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Countess\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Capt\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Col\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Don\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Major\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Rev\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Sir\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Jonkheer\", \"Title\"] = 'Rare Title'\ntitanic_test.loc[titanic_test[\"Title\"] == \"Dr\", \"Title\"] = 'Rare Title'\n\ntitanic_test[\"Title\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff25f5499761d5ab8394cdaafdb9af287e271c07"},"cell_type":"code","source":"#Ticket column\ntitanic[\"Ticket\"].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88fc92c33bb05c83eefe8d15806e249e1e0e561c"},"cell_type":"code","source":"titanic[\"TicketNumber\"] = titanic[\"Ticket\"].str.extract('(\\d{2,})', expand=True)\ntitanic[\"TicketNumber\"] = titanic[\"TicketNumber\"].apply(pd.to_numeric)\n\n\ntitanic_test[\"TicketNumber\"] = titanic_test[\"Ticket\"].str.extract('(\\d{2,})', expand=True)\ntitanic_test[\"TicketNumber\"] = titanic_test[\"TicketNumber\"].apply(pd.to_numeric)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2cc84f51080140498729c423394398be5ca1cd9"},"cell_type":"code","source":"#some rows in ticket column dont have numeric value so we got NaN there\ntitanic[titanic[\"TicketNumber\"].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce2daeb2c36f2ba6c6c4fb723fd6aa1315c62977"},"cell_type":"code","source":"titanic.TicketNumber.fillna(titanic[\"TicketNumber\"].median(), inplace=True)\ntitanic_test.TicketNumber.fillna(titanic_test[\"TicketNumber\"].median(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ccc2a103a0199e97d6e173854e46159aca522c63"},"cell_type":"markdown","source":"**Convert Categorical variables into Numerical ones**"},{"metadata":{"trusted":true,"_uuid":"588c339593b7b018642120d44d3d366745dd671d"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n\nlabelEnc=LabelEncoder()\n\ncat_vars=['Embarked','Sex',\"Title\",\"FsizeD\",\"NlengthD\",'Deck']\nfor col in cat_vars:\n    titanic[col]=labelEnc.fit_transform(titanic[col])\n    titanic_test[col]=labelEnc.fit_transform(titanic_test[col])\n\ntitanic.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"277c85cdd3af3a12a5d576588bc6de5e885d8044"},"cell_type":"markdown","source":"Age Column\n\nAge seems to be promising feature. So it doesnt make sense to simply fill null values out with median/mean/mode.\n\nWe will use Random Forest algorithm to predict ages."},{"metadata":{"_uuid":"1ac5931154975aaac09cd9e9bad05da6551f1078"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"ddd8ec02363979bfac905a8b0e79aaf29a17e032"},"cell_type":"code","source":"fig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,4))\naxis1.set_title('Original Age values - Titanic')\naxis2.set_title('New Age values - Titanic')\n\n# get average, std, and number of NaN values in titanic_df\naverage_age_titanic   = titanic[\"Age\"].mean()\nstd_age_titanic       = titanic[\"Age\"].std()\ncount_nan_age_titanic = titanic[\"Age\"].isnull().sum()\n\n# get average, std, and number of NaN values in test_df\naverage_age_test   = titanic_test[\"Age\"].mean()\nstd_age_test       = titanic_test[\"Age\"].std()\ncount_nan_age_test = titanic_test[\"Age\"].isnull().sum()\n\n# generate random numbers between (mean - std) & (mean + std)\nrand_1 = np.random.randint(average_age_titanic - std_age_titanic, average_age_titanic + std_age_titanic, size = count_nan_age_titanic)\nrand_2 = np.random.randint(average_age_test - std_age_test, average_age_test + std_age_test, size = count_nan_age_test)\n\n# plot original Age values\n# NOTE: drop all null values, and convert to int\ntitanic['Age'].dropna().astype(int).hist(bins=70, ax=axis1)\n# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)\n\n# fill NaN values in Age column with random values generated\ntitanic[\"Age\"][np.isnan(titanic[\"Age\"])] = rand_1\ntitanic_test[\"Age\"][np.isnan(titanic_test[\"Age\"])] = rand_2\n\n# convert from float to int\ntitanic['Age'] = titanic['Age'].astype(int)\ntitanic_test['Age']    = titanic_test['Age'].astype(int)\n        \n# plot new Age Values\ntitanic['Age'].hist(bins=70, ax=axis2)\n# test_df['Age'].hist(bins=70, ax=axis4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b40a9c18eea53b09c71c16f12ffb82963e8635a7"},"cell_type":"code","source":"with sns.plotting_context(\"notebook\",font_scale=1.5):\n    sns.set_style(\"whitegrid\")\n    sns.distplot(titanic[\"Age\"].dropna(),\n                 bins=80,\n                 kde=False,\n                 color=\"tomato\")\n    plt.title(\"Age Distribution\")\n    plt.ylabel(\"Count\")\n    plt.xlim((15,100));","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9132bc180c4a49367543ed62408e89dd27dd6140"},"cell_type":"markdown","source":"**Feature Scaling**\nWe can see that Age, Fare are measured on different scales, so we need to do Feature Scaling first before we proceed with predictions."},{"metadata":{"trusted":true,"_uuid":"d4a17ae7e5d65f709207e673afeb3fecb933e4a4"},"cell_type":"code","source":"from sklearn import preprocessing\n\nstd_scale = preprocessing.StandardScaler().fit(titanic[['Age', 'Fare']])\ntitanic[['Age', 'Fare']] = std_scale.transform(titanic[['Age', 'Fare']])\n\n\nstd_scale = preprocessing.StandardScaler().fit(titanic_test[['Age', 'Fare']])\ntitanic_test[['Age', 'Fare']] = std_scale.transform(titanic_test[['Age', 'Fare']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"062831cc911c50469fa36554538999ba97cbef7e"},"cell_type":"code","source":"#Correlation of features with target\ntitanic.corr()[\"Survived\"]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4f57066e7a65a78d9ffd64c835f775dded1c9d9"},"cell_type":"markdown","source":"**Predict Survival**"},{"metadata":{"trusted":true,"_uuid":"2d4991f68f3e62bc259b904df0c29d365b1a7506"},"cell_type":"code","source":"#Linear Regression\n\n# Import the linear regression class\nfrom sklearn.linear_model import LinearRegression\n# Sklearn also has a helper that makes it easy to do cross validation\nfrom sklearn.cross_validation import KFold\n\n# The columns we'll use to predict the target\npredictors = [\"Pclass\", \"Sex\", \"Age\",\"SibSp\", \"Parch\", \"Fare\",\n              \"Embarked\",\"NlengthD\", \"FsizeD\", \"Title\",\"Deck\"]\ntarget=\"Survived\"\n# Initialize our algorithm class\nalg = LinearRegression()\n\n# Generate cross validation folds for the titanic dataset.  It return the row indices corresponding to train and test.\n# We set random_state to ensure we get the same splits every time we run this.\nkf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n\npredictions = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"688015bf79fd567e04bf917c7466974f5513314c"},"cell_type":"code","source":"for train, test in kf:\n    # The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.\n    train_predictors = (titanic[predictors].iloc[train,:])\n    # The target we're using to train the algorithm.\n    train_target = titanic[target].iloc[train]\n    # Training the algorithm using the predictors and target.\n    alg.fit(train_predictors, train_target)\n    # We can now make predictions on the test fold\n    test_predictions = alg.predict(titanic[predictors].iloc[test,:])\n    predictions.append(test_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e6f7c6be48bdddef4ad4f682ba91d3b6596fcca"},"cell_type":"code","source":"predictions = np.concatenate(predictions, axis=0)\n# Map predictions to outcomes (only possible outcomes are 1 and 0)\npredictions[predictions > .5] = 1\npredictions[predictions <=.5] = 0\n\n\naccuracy=sum(titanic[\"Survived\"]==predictions)/len(titanic[\"Survived\"])\naccuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61264c76b041e7b0f0223af22fb4eb9ab44de1ad"},"cell_type":"code","source":"#Logistic Regression\nfrom sklearn import cross_validation\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import ShuffleSplit\n\npredictors = [\"Pclass\", \"Sex\", \"Fare\", \"Embarked\",\"Deck\",\"Age\",\n              \"FsizeD\", \"NlengthD\",\"Title\",\"Parch\"]\n\n# Initialize our algorithm\nlr = LogisticRegression(random_state=1)\n# Compute the accuracy score for all the cross validation folds.\ncv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=50)\n\nscores = cross_val_score(lr, titanic[predictors], \n                                          titanic[\"Survived\"],scoring='f1', cv=cv)\n# Take the mean of the scores (because we have one for each fold)\nprint(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c67d2e7df5fe0f53a8eb0487ad371ecc21b75d31"},"cell_type":"code","source":"from sklearn import cross_validation\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.cross_validation import KFold\nfrom sklearn.model_selection import cross_val_predict\n\nimport numpy as np\npredictors = [\"Pclass\", \"Sex\", \"Age\",\n              \"Fare\",\"NlengthD\",\"NameLength\", \"FsizeD\", \"Title\",\"Deck\"]\n\n# Initialize our algorithm with the default paramters\n# n_estimators is the number of trees we want to make\n# min_samples_split is the minimum number of rows we need to make a split\n# min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends (the bottom points of the tree)\nrf = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, \n                            min_samples_leaf=1)\nkf = KFold(titanic.shape[0], n_folds=5, random_state=1)\ncv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=50)\n\npredictions = cross_validation.cross_val_predict(rf, titanic[predictors],titanic[\"Survived\"],cv=kf)\npredictions = pd.Series(predictions)\nscores = cross_val_score(rf, titanic[predictors], titanic[\"Survived\"],\n                                          scoring='f1', cv=kf)\n# Take the mean of the scores (because we have one for each fold)\nprint(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6059f0c0a9112e8e85a8bca294d91515d2185ed3"},"cell_type":"code","source":"predictors = [\"Pclass\", \"Sex\", \"Age\",\n              \"Fare\",\"NlengthD\",\"NameLength\", \"FsizeD\", \"Title\",\"Deck\",\"TicketNumber\"]\nrf = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=9,min_samples_split=6, min_samples_leaf=4)\nrf.fit(titanic[predictors],titanic[\"Survived\"])\nkf = KFold(titanic.shape[0], n_folds=5, random_state=1)\npredictions = cross_validation.cross_val_predict(rf, titanic[predictors],titanic[\"Survived\"],cv=kf)\npredictions = pd.Series(predictions)\nscores = cross_val_score(rf, titanic[predictors], titanic[\"Survived\"],scoring='f1', cv=kf)\n# Take the mean of the scores (because we have one for each fold)\nprint(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0ae65e2c3faf4fa55023516dc4f15587055c7e7"},"cell_type":"code","source":"importances=rf.feature_importances_\nstd = np.std([rf.feature_importances_ for tree in rf.estimators_],\n             axis=0)\nindices = np.argsort(importances)[::-1]\nsorted_important_features=[]\nfor i in indices:\n    sorted_important_features.append(predictors[i])\n#predictors=titanic.columns\nplt.figure()\nplt.title(\"Feature Importances By Random Forest Model\")\nplt.bar(range(np.size(predictors)), importances[indices],\n       color=\"r\", yerr=std[indices], align=\"center\")\nplt.xticks(range(np.size(predictors)), sorted_important_features, rotation='vertical')\n\nplt.xlim([-1, np.size(predictors)]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93330fb819c798148ed1a3a23821e34a31a0d6a7"},"cell_type":"code","source":"#Gradient Boosting\nimport numpy as np\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.cross_validation import KFold\n%matplotlib inline\nimport matplotlib.pyplot as plt\n#predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\",\n #             \"FsizeD\", \"Embarked\", \"NlengthD\",\"Deck\",\"TicketNumber\"]\npredictors = [\"Pclass\", \"Sex\", \"Age\",\n              \"Fare\",\"NlengthD\", \"FsizeD\",\"NameLength\",\"Deck\",\"Embarked\"]\n# Perform feature selection\nselector = SelectKBest(f_classif, k=5)\nselector.fit(titanic[predictors], titanic[\"Survived\"])\n\n# Get the raw p-values for each feature, and transform from p-values into scores\nscores = -np.log10(selector.pvalues_)\n\nindices = np.argsort(scores)[::-1]\n\nsorted_important_features=[]\nfor i in indices:\n    sorted_important_features.append(predictors[i])\n\nplt.figure()\nplt.title(\"Feature Importances By SelectKBest\")\nplt.bar(range(np.size(predictors)), scores[indices],\n       color=\"seagreen\", yerr=std[indices], align=\"center\")\nplt.xticks(range(np.size(predictors)), sorted_important_features, rotation='vertical')\n\nplt.xlim([-1, np.size(predictors)]);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a898ff3f716a08b768cf80917bdf5de887ff0ff3"},"cell_type":"code","source":"\nfrom sklearn import cross_validation\nfrom sklearn.linear_model import LogisticRegression\npredictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\",\"NlengthD\",\n              \"FsizeD\", \"Title\",\"Deck\"]\n\n# Initialize our algorithm\nlr = LogisticRegression(random_state=1)\n# Compute the accuracy score for all the cross validation folds.  \ncv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=50)\nscores = cross_val_score(lr, titanic[predictors], titanic[\"Survived\"], scoring='f1',cv=cv)\nprint(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce9b3b874651804b45e794e223c0bac28a7785bd"},"cell_type":"code","source":"#AdaBoost \nfrom sklearn.ensemble import AdaBoostClassifier\npredictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\",\"NlengthD\",\n              \"FsizeD\", \"Title\",\"Deck\",\"TicketNumber\"]\nadb=AdaBoostClassifier()\nadb.fit(titanic[predictors],titanic[\"Survived\"])\ncv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=50)\nscores = cross_val_score(adb, titanic[predictors], titanic[\"Survived\"], scoring='f1',cv=cv)\nprint(scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40bc898f11f70e382a4d37f771f45f6409273388"},"cell_type":"code","source":"#Maximum Voting ensemble and Submission\npredictions=[\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\",\"NlengthD\",\n              \"FsizeD\", \"Title\",\"Deck\",\"NameLength\",\"TicketNumber\"]\nfrom sklearn.ensemble import VotingClassifier\neclf1 = VotingClassifier(estimators=[\n        ('lr', lr), ('rf', rf), ('adb', adb)], voting='soft')\neclf1 = eclf1.fit(titanic[predictors], titanic[\"Survived\"])\npredictions=eclf1.predict(titanic[predictors])\npredictions\n\ntest_predictions=eclf1.predict(titanic_test[predictors])\n\ntest_predictions=test_predictions.astype(int)\nsubmission = pd.DataFrame({\n        \"PassengerId\": titanic_test[\"PassengerId\"],\n        \"Survived\": test_predictions\n    })\n\nsubmission.to_csv(\"titanic_submission.csv\", index=False)\nprint(submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3933c9b13bd9c51de93b4021ffb1f7ad27261200"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}