{"cells":[{"metadata":{"_cell_guid":"3ef3fe80-1061-4ac2-bf59-7c2834a1236e","_uuid":"59ae72bb5e68fce1f87571c8bdfc1d559e19591b","collapsed":true,"trusted":true},"cell_type":"code","source":"# Kaggleのススメかた\n## トレインデータ、テストデータの統計を確認 \n## 適当に特徴量を追加-> 例: Sibpar(兄弟・パートナー)とParch(親子共)から家族カラムの追加、Fareから運賃分布を区切る、NameのMr.Mrs/Miss/Captain/Col/Dr...\n## 前処理を頑張る（新しい特徴量の追加、データの正規化）\n## 適当なアルゴリズムを書く \n## 動くことを確認する \n## トレインデータ、テストデータの統計を確認 \n## 改善を確認する \n## 繰り返す\n\n# 前処理\n## 欠損値(Null)の補正\n## 外れ値の検出と処理\n## ダミー変数の作成\n## 連続データの離散化\n## 特徴量選択\n## 入力データの余計なデータ正規化？\n## 入力データの一般的なテータ型を推測する？ -> 例: Tickets\n","execution_count":59,"outputs":[]},{"metadata":{"_cell_guid":"191d7a23-312f-4ef6-9e96-94530fdb57db","_uuid":"7b6c1ff95b157430db500b7549995de9551df9b1","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nprint(os.listdir(\"../input\"))","execution_count":60,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":true},"cell_type":"code","source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":61,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Grasp Column Info\ndf_train = pd.read_csv(\"../input/train.csv\")\ndf_test = pd.read_csv(\"../input/test.csv\")\ndf_gender_submission = pd.read_csv('../input/gender_submission.csv')\ndf_train.head(5)","execution_count":62,"outputs":[]},{"metadata":{"_cell_guid":"3f1ff0fe-7535-4127-90b4-4c7110578827","_uuid":"927670c92d48a9158f98d6473615fa94dd7876c5","trusted":true},"cell_type":"code","source":"#  Read Frame\nprint('-'*40)\nprint('-'*10, \" Shapes \", '-'*10)\nprint('-'*40)\nprint('submission data: ', df_gender_submission.shape)\n\nprint('-'*40)\nprint('-'*10, \" Train Data Info \", '-'*10)\nprint('-'*40)\nprint('train data: ', df_train.shape)\nprint(df_train.columns)\ndf_train.info()\nprint(df_train.isnull().sum())\n\nprint('-'*40)\nprint('-'*10, \" Test Data Info \", '-'*10)\nprint('-'*40)\nprint('test data: ', df_test.shape)\nprint(df_test.columns)\ndf_test.info()\n\nprint('-'*40)\nprint('-'*10, \" Stats  \", '-'*10)\nprint('-'*40)\ndf_full = pd.concat([df_train, df_test], axis = 0, ignore_index=True)\nprint(df_full.shape)\ndf_full.describe() # Summary  Statistics, df_full.describe(include='all') displays all types of data. By default, it only displays integer type stats","execution_count":63,"outputs":[]},{"metadata":{"_cell_guid":"85696f92-0598-48cb-bdec-2cc6d6c1b291","_uuid":"110de0b3680cb8dcf6bf79d40eda23dba2c13715","trusted":true},"cell_type":"code","source":"# Checking stats\nplt.subplot(1, 2, 1)\nsns.countplot(x='Survived', hue='Sex', data=df_train)\nplt.title('Survival rate by Sex')\nplt.xticks([0,1],['Dead', \"Alive\"])\nplt.ylim(0, 500)\ndf_train[['Survived','Sex']].groupby(['Sex']).mean()\n\nplt.subplot(1, 2, 2)\nsns.countplot(x='Survived', hue='Pclass', data=df_train)\nplt.title('Survival rate  by Ticket Class')\nplt.xticks([0,1],['Dead', \"Alive\"])\nplt.ylim(0, 500)\ndf_train[['Survived','Pclass']].groupby(['Pclass'],  as_index=False).mean()","execution_count":64,"outputs":[]},{"metadata":{"_cell_guid":"2dd24575-8b65-4419-b853-4f71bfec4b80","_uuid":"2c82d05f0c7603833570cc15c307e0830b3f23c0","trusted":true},"cell_type":"code","source":"# Checking stats\nsns.distplot(df_train['Age'].dropna(), kde=False, bins=30, label='Whole')\nsns.distplot(df_train[df_train['Survived'] == 0].Age.dropna(), kde=False, bins=30, label='Dead')\nsns.distplot(df_train[df_train['Survived'] == 1].Age.dropna(), kde=False, bins=30, label='Alive')\nplt.title('Histogram of Age')\nplt.legend()\n\ndf_train['CategoricalAge'] = pd.cut(df_train['Age'], 8)\ndf_train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean()","execution_count":65,"outputs":[]},{"metadata":{"_cell_guid":"7c0f6988-bfcc-461b-b621-7b059eecc252","_uuid":"01953bff113e9990522ab2132a18af0bf18e343e","trusted":true},"cell_type":"code","source":"# Checking stats\nplt.subplot(1, 2, 1)\nsns.countplot(x='SibSp', data = df_train)\nplt.title('# of siblings/partner')\ndf_train['SibSp_0_1_2over'] = [i if i <= 1 else 2 for i in df_train['SibSp']]\n\nplt.subplot(1, 2, 2)\nsns.countplot(x='Survived', hue='SibSp_0_1_2over', data=df_train)\nplt.legend(['0','1','2 < '],loc='upper right')\nplt.title('Survival rate by #of sib/partner')\ndf_train[['SibSp_0_1_2over', 'Survived']].groupby(['SibSp_0_1_2over']).mean()","execution_count":66,"outputs":[]},{"metadata":{"_cell_guid":"7f2a8c67-7c43-4455-8872-be77f4e5911b","_uuid":"e303a5cb400ee93286aba244c173dea2931b9e32","trusted":true},"cell_type":"code","source":"# Checking stats\nplt.subplot(1, 2, 1)\nsns.countplot(x='Parch', data = df_train)\nplt.title('# of parents/children')\n\nplt.subplot(1, 2, 2)\ndf_train['Parch_0_1_2_3over'] = [i if i <= 2 else 3 for i in df_train['Parch']]\nsns.countplot(x='Survived', hue='Parch_0_1_2_3over', data=df_train)\nplt.legend(['0','1','2,','3 < '],loc='upper right')\nplt.title('Survival rate by #of Parents/Children')\ndf_train[['Parch_0_1_2_3over', 'Survived']].groupby(['Parch_0_1_2_3over']).mean()","execution_count":67,"outputs":[]},{"metadata":{"_cell_guid":"73d72181-d703-4161-b816-b759cae494f9","_uuid":"7073405b29cce9983ca62d6f7eb180d5bcb46538","trusted":true},"cell_type":"code","source":"# Adding New Fature 1\n# SibSpとParchの統計から、１人で乗船している場合の生存率が低い事が判明した。\n# そこから家族数の統計を作成する\n## SibSpとParchが同上している家族の数。１を足すと家族の人数になる。\ndf_train['FamilySize']=df_train['SibSp'] + df_train['Parch']+1 \n\ndf_train['IsAlone'] = 0\ndf_train.loc[df_train['FamilySize'] == 1, 'IsAlone' ] = 1\nsns.countplot(x='Survived', hue='IsAlone', data=df_train)\nplt.xticks([0,1],['Dead',\"Alive\"])\nplt.legend(['Not Alone','Alone'],loc='upper right')\nplt.title('Survival rate of being Alone')","execution_count":68,"outputs":[]},{"metadata":{"_cell_guid":"09af3e65-4ec0-48fa-aff8-125e758a7f17","_uuid":"7a8f29abcfe25ab9b0513bda69bd3b8353cb22db","trusted":true},"cell_type":"code","source":"# Adding New Feature 2\nsns.distplot(df_train['Fare'].dropna(), kde=False, hist=True) #kde = kernel density distribution\nplt.title('Distribution of Fare')\n\ndf_train['CategoricalFare'] = pd.cut(df_train['Fare'], 4)\ndf_train[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean()","execution_count":69,"outputs":[]},{"metadata":{"_cell_guid":"957a6373-5566-4c29-b2d6-c73c93fac263","_uuid":"bd83b005fdb4911cf53571a9a4be204b9da9c01c","collapsed":true,"trusted":true},"cell_type":"code","source":"# Extract new fature(prefix)\nset(df_train.Name.str.extract('([A-Za-z]+)\\.', expand=False))\nimport collections\n\ndf_train[\"Title\"] = df_train.Name.str.extract('([A-Za-z]+)\\.', expand=False)\ndf_test[\"Title\"] = df_test.Name.str.extract('([A-Za-z]+)\\.', expand=False)\ndf_train.groupby('Title').mean()['Age'] # Master's average age is 4.6 meaning it's Child. Age can influence survival rate, so this can be an useful feature.\n\ndef title_to_num(title):\n    if title == 'Master':\n        return 1\n    elif title == 'Miss':\n        return 2\n    elif title == 'Mr':\n        return 3\n    elif title == 'Mrs':\n        return 4\n    else:\n        return 5\n\ndf_train['Title_num'] = [title_to_num(i) for i in df_train['Title']]\ndf_test['Title_num'] = [title_to_num(i) for i in df_test['Title']]\n                    ","execution_count":70,"outputs":[]},{"metadata":{"_cell_guid":"967091ec-1c0c-4a58-9ffb-a44276f256a3","_uuid":"fd8ef42262fbabec284ebca180a5ab1334831698","trusted":true},"cell_type":"code","source":"# To Improve Score\n## Drop not important feature\n## Utilize following Features\n### Use Title_num generated from Name\n### Check order of embarked and check survival rate, guess why there are differences\n### Research how `cabin` works and generate the feature\n## Guess and change Random Forest's hyper parameter. Use Grid Search\n## Check other kernels using random forest\n## Use different algorithm\n\n# 再ロード\ndf_train = pd.read_csv(\"../input/train.csv\")\ndf_test = pd.read_csv(\"../input/test.csv\")\n\n# 前処理\n## Ageの欠損値をPclassごとの平均値で保管 \ndef impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        if Pclass == 1:\n            return 39 # Pclass 1 の年齢の中央値\n        elif Pclass == 2:\n            return 30\n        else:\n            return 25\n    else:\n        return Age\n        \ndf_train['Age'] = df_train[['Age','Pclass']].apply(impute_age, axis=1)\ndf_test['Age'] = df_test[['Age','Pclass']].apply(impute_age, axis=1)\n\ndf_train[\"Title\"] = df_train.Name.str.extract('([A-Za-z]+)\\.', expand=False)\ndf_test[\"Title\"] = df_test.Name.str.extract('([A-Za-z]+)\\.', expand=False)\ndef title_to_num(title):\n    if title == 'Master':\n        return 1\n    elif title == 'Miss':\n        return 2\n    elif title == 'Mr':\n        return 3\n    elif title == 'Mrs':\n        return 4\n    else:\n        return 5\n\ndf_train['Title_num'] = [title_to_num(i) for i in df_train['Title']]\ndf_test['Title_num'] = [title_to_num(i) for i in df_test['Title']]\n\n## 乗船港の欠損値の補完: \n### 欠損データ\ndf_train[df_train['Embarked'].isnull()]\n### 特に出掛かりになる情報がないので、乗船者が多い乗船港「C」で補完\ndf_train.loc[df_train['PassengerId'].isin([62,830]), 'Embarked']='C'\n\n## 運賃の欠損値を平均値で補完\n### 乗客クラスごとの運賃の平均値\ndf_train[['Pclass','Fare']].groupby('Pclass').mean()\n### 欠損値。Pclassが3なので、↑で求めた運賃の平均値を適用\ndf_test[df_test['Fare'].isnull()]\ndf_test.loc[df_test['PassengerId'] == 1044, 'Fare'] = 13.675550\n\nprint('-'*40)\nprint('-'*10, \" df_trainの欠損値  \", '-'*10)\nprint('-'*40)\nprint(df_train.isnull().sum())\n\nprint('-'*40)\nprint('-'*10, \" df_testの欠損値  \", '-'*10)\nprint('-'*40)\nprint(df_test.isnull().sum())\n\ngenders = {'male':0, 'female':1}\ndf_train['Sex'] = df_train['Sex'].map(genders)\ndf_test['Sex'] = df_test['Sex'].map(genders)\n\n##  ダミー変数化\n# df_train = pd.get_dummies(df_train, columns=['Embarked'])\n# df_test = pd.get_dummies(df_test, columns=['Embarked'])\ndf_train['Embarked'] = df_train['Embarked'].map({'S':0, 'C':1, 'Q': 2}).astype(int)\ndf_test['Embarked'] = df_test['Embarked'].map({'S':0, 'C':1, 'Q': 2}).astype(int)\n\n## 連続変数の離散化（Age, Fare)\ndata = [df_train, df_test]\nfor df in data:\n    df.loc[df['Fare'] <=7.91, 'Fare'] = 0\n    df.loc[ (df['Fare'] > 7.91) & (df['Fare'] <= 14.454), 'Fare'] = 1\n    df.loc[ (df['Fare'] > 14.454) & (df['Fare'] <= 31), 'Fare'] = 2\n    df.loc[ df['Fare'] > 31, 'Fare'] = 3\n    df['Fare'] = df['Fare'].astype(int)\n\n    df.loc[df['Age'] <=16, 'Age'] = 0\n    df.loc[ (df['Age'] > 16) & (df['Age'] <= 32), 'Age'] = 1\n    df.loc[ (df['Age'] > 32) & (df['Age'] <= 48), 'Age'] = 2\n    df.loc[ df['Age'] > 48, 'Age'] = 3\n    df['Age'] = df['Age'].astype(int)\n    \n    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n    df['IsAlone'] = 0\n    df.loc[df['FamilySize'] == 1, 'IsAlone' ] = 1\n    \n## 不要な列の削除\ndf_train.drop(['Name','Cabin','Ticket', 'SibSp', 'Parch', 'IsAlone','Title','Embarked','Age'], axis=1, inplace=True)\ndf_test.drop(['Name','Cabin','Ticket', 'SibSp', 'Parch', 'IsAlone','Title','Embarked','Age'], axis=1, inplace=True)\n    \n# Random FOrest\nX_train = df_train.drop(['PassengerId', 'Survived'], axis=1)\nY_train = df_train['Survived']\nX_test = df_test.drop('PassengerId',axis=1).copy()\n\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(random_state=1)\n\n# Learn to predict Y_train from X_train (Over Estimation - it learns a model from X-train and Y_train and use it to predict Y_train from X_train)\nrf.fit(X_train, Y_train)\nacc_log = round(rf.score(X_train, Y_train) * 100, 2)\nprint(round(acc_log,2,), '%')\n\n# Cross Validation\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score \n\n## Splitting data in 3 parts. Use 2 as training data, and 1 as testing data.\n### Repeat  3 times so that individual data becomes testing data for at least 1 time.\nskf = StratifiedKFold(n_splits=3)\nfor train_idx, test_idx in skf.split(X_train, Y_train):\n    X_cv_train = X_train.iloc[train_idx]\n    Y_cv_train = Y_train.iloc[train_idx]\n    \n    X_cv_test = X_train.iloc[test_idx]\n    Y_cv_test = Y_train.iloc[test_idx]\n    \n    # Learning\n    rf.fit(X_cv_train, Y_cv_train)\n    \n    # Predicting\n    pred = rf.predict(X_cv_test)\n    print(round(accuracy_score(Y_cv_test,  pred)*100, 2))\n    \n# Now use this model to make submission data\nrf.fit(X_train, Y_train)\nY_pred = rf.predict(X_test)\nsubmission = pd.DataFrame({'PassengerId': df_test['PassengerId'],'Survived': Y_pred})\nsubmission.to_csv('submission.csv', index=False)\n\n\nprint('-'*40)\nprint('-'*10, \" Importance Feature\", '-'*10)\nprint('-'*40)\nfor i,k in zip(X_train.columns, rf.feature_importances_):\n    print(i,round(k,4))\n\nX_train.head()","execution_count":82,"outputs":[]},{"metadata":{"_cell_guid":"a4c1e025-b706-4e0e-a4e2-50466eb4c72c","_uuid":"d842f37a9691f821db31b578d982716547e3c139","trusted":true,"collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}