{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"#1.import package\nimport types\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\nfrom pandas import Series,DataFrame\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn import preprocessing\nfrom sklearn.cross_validation import KFold,train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import svm\nfrom sklearn.neighbors.nearest_centroid import NearestCentroid\nfrom sklearn.linear_model import LogisticRegression,Perceptron\nfrom sklearn.tree import DecisionTreeClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04a278102f7410e2a7c5ccad52b7218f4c48b56e","collapsed":true},"cell_type":"code","source":"train_data = pd.read_csv(r\"../input/train.csv\")\ntest_data = pd.read_csv(r\"../input/test.csv\")\nprint(\"training data's shape:\",train_data.shape)\nprint(train_data.head())\nprint(\"test data's shape:\",test_data.shape)\nprint(test_data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3aad176e4500914712b29e459201712ab93c7320","collapsed":true},"cell_type":"code","source":"#3.exploratory Data Analysis\n#3.1 show data info\nprint(\"--------------training data information---------------\")\nprint(train_data.info())\nprint(\"--------------  test data information  ---------------\")\nprint(test_data.info())\nprint(train_data['Survived'].value_counts())\n#3.2 show survived info\ntrain_data['Survived'].astype(int).plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92f346a0a17743ae26c036e5d1ac37aea6d516a0","collapsed":true},"cell_type":"code","source":"#Age with Survived\nprint(\"range of Age \",train_data[\"Age\"].max(),train_data[\"Age\"].min())\nmean_Age = train_data[\"Age\"].mean()\nstd_Age = train_data[\"Age\"].std()\nnull_count_Age_train = train_data[\"Age\"].isnull().sum()\nnull_count_Age_test = test_data[\"Age\"].isnull().sum()\ntrain_data[\"Age\"][np.isnan(train_data[\"Age\"])] = np.random.randint(mean_Age - std_Age,mean_Age+ std_Age,null_count_Age_train)\ntest_data[\"Age\"][np.isnan(test_data[\"Age\"])] = np.random.randint(mean_Age - std_Age,mean_Age+ std_Age,null_count_Age_test)\n#feature importance\ngrid = sns.FacetGrid(train_data,hue='Survived',size=4,palette='seismic')\ngrid.map(plt.scatter, \"PassengerId\", \"Age\")\ngrid.add_legend()\ngrid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e41245381110a6195c94c243c8e8e0ad67e38de6"},"cell_type":"code","source":"#Ticket with Survived,\nnull_count_Ticket_train = train_data[\"Ticket\"].isnull().sum()\nnull_count_Ticket_test = test_data[\"Ticket\"].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eefa9e5bbd3007a2d44248282c60438714930f63","collapsed":true},"cell_type":"code","source":"#Fare with Survived\nprint(\"range of Fare \",train_data[\"Fare\"].max(),train_data[\"Fare\"].min())\nmean_Fare = train_data[\"Fare\"].mean()\nstd_Fare = train_data[\"Fare\"].std()\nnull_count_Fare_train = train_data[\"Fare\"].isnull().sum()\nnull_count_Fare_test = test_data[\"Fare\"].isnull().sum()\n\nif null_count_Fare_train != 0:\n    train_data[\"Fare\"][np.isnan(train_data[\"Fare\"])] = np.random.randint(mean_Fare - std_Fare,mean_Fare+ std_Fare,null_count_Fare_train)\nif null_count_Fare_test != 0:\n    test_data[\"Fare\"][np.isnan(test_data[\"Fare\"])] = np.random.randint(mean_Fare - std_Fare,mean_Fare+ std_Fare,null_count_Fare_test)\n# sns.countplot(x='Survived',hue='Fare',data  = train_data,order=[1,0],ax=axis3)\ngrid = sns.FacetGrid(train_data,hue='Survived',size=5,palette='seismic')\ngrid.map(plt.scatter, \"PassengerId\", \"Fare\")\ngrid.add_legend()\ngrid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b2aa6b8611da47d1b8d45ecba573b2ca92194de","collapsed":true},"cell_type":"code","source":"##discreate values\nfig,axis = plt.subplots(figsize=(8,8))\n#Pclass with Survived\nnull_count_Pclass_train = train_data['Pclass'].isnull().sum()\nnull_count_Pclass_test = test_data['Pclass'].isnull().sum()\nprint(\"num of Pclass's null value: \",null_count_Pclass_train)\nprint(\"num of Pclass's null value: \",null_count_Pclass_test)\nmean_Pclass = train_data['Pclass'].mean()\n\ntrain_data['Pclass'][np.isnan(train_data['Pclass'])] = int(mean_Pclass) + 1\ntest_data['Pclass'][np.isnan(test_data['Pclass'])] = int(mean_Pclass) + 1\nsns.countplot(x='Survived',hue='Pclass',data  = train_data,order=[1,0],ax=axis)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"745c7b33acb70e7767edc63431c102f922148b7a","collapsed":true},"cell_type":"code","source":"#Sex with Survived\nfig,axis = plt.subplots(figsize=(8,8))\nnull_count_Sex_train = train_data['Sex'].isnull().sum()\nnull_count_Sex_test = test_data['Sex'].isnull().sum()\nprint(\"num of Sex's train null value: \",null_count_Sex_train)\nprint(\"num of Sex's test null value: \",null_count_Sex_test)\n\n# train_data['Sex'][np.isnan(train_data['Sex'])] = \"male\"\n# test_data['Sex'][np.isnan(test_data['Sex'])] = \"male\"\nsns.countplot(x='Survived',hue='Sex',data  = train_data,order=[1,0],ax=axis)\nsex_map = {\"male\":0,\"female\":1}\ntrain_data['Sex'] = train_data['Sex'].map(sex_map)\ntest_data['Sex'] = test_data['Sex'].map(sex_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b082662aa02e88083c37f1d32fc49ea4c7c12d4b","collapsed":true},"cell_type":"code","source":"#SibSp with Survived\nfig,axis = plt.subplots(figsize=(8,8))\nnull_count_SibSp_train = train_data['SibSp'].isnull().sum()\nnull_count_SibSp_test = test_data['SibSp'].isnull().sum()\nprint(\"num of SibSp's train null value: \",null_count_SibSp_train)\nprint(\"num of SibSp's test null value: \",null_count_SibSp_test)\nmean_SibSp = train_data['SibSp'].mean()\ntrain_data['SibSp'][np.isnan(train_data['SibSp'])] = int(mean_SibSp) + 1\ntest_data['SibSp'][np.isnan(test_data['SibSp'])] = int(mean_SibSp) + 1\nsns.countplot(x='Survived',hue='SibSp',data  = train_data,order=[1,0],ax=axis)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3bfb8a1fc00d3c996497c0c4281476be039c465","collapsed":true},"cell_type":"code","source":"#Parch with Survived\nfig,axis = plt.subplots(figsize=(8,8))\nnull_count_Parch_train = train_data['Parch'].isnull().sum()\nnull_count_Parch_test = test_data['Parch'].isnull().sum()\nprint(\"num of Parch's train null value: \",null_count_Parch_train)\nprint(\"num of Parch's test null value: \",null_count_Parch_test)\nmean_Parch = train_data['Parch'].mean()\n\ntrain_data['Parch'][np.isnan(train_data['Parch'])] = int(mean_Parch) + 1\ntest_data['Parch'][np.isnan(test_data['Parch'])] = int(mean_Parch) + 1\n\nsns.countplot(x='Survived',hue='Parch',data  = train_data,order=[1,0],ax=axis)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"246efdbd9e7ffa886222447099154eab323a884e","collapsed":true},"cell_type":"code","source":"#Cabin with Survived\nnull_count_Cabin_train = train_data['Cabin'].isnull().sum()\nnull_count_Cabin_test = test_data['Cabin'].isnull().sum()\nprint(\"num of Cabin's train null value: \",null_count_Cabin_train)\nprint(\"num of Cabin's test null value: \",null_count_Cabin_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7146b3062b135c8fe6e36fc2e254e48495c2077","collapsed":true},"cell_type":"code","source":"#Embarked with Survived\nfig,axis = plt.subplots(figsize=(8,8))\ntrain_data['Embarked'] = train_data['Embarked'].fillna('S')\ntest_data['Embarked'] = test_data['Embarked'].fillna('S')\nsns.countplot(x='Survived',hue='Embarked',data = train_data,order=[0,1],ax=axis)\nembkarked_map = {\"S\":0,\"C\":1,\"Q\":3}\ntrain_data['Embarked'] = train_data['Embarked'].map(embkarked_map)\ntest_data['Embarked'] = test_data['Embarked'].map(embkarked_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"17015df9929de2149aece9f17d45f6539a7bc431"},"cell_type":"code","source":"# 3.5 drop data\ntrain_data = train_data.drop(['PassengerId'],axis = 1)\ntrain_data = train_data.drop(['Name'],axis = 1)\ntrain_data = train_data.drop(['Ticket'],axis = 1)\ntrain_data = train_data.drop(['Cabin'],axis = 1)\n\n# test_data = test_data.drop(['PassengerId'],axis = 1)\ntest_data = test_data.drop(['Name'],axis = 1)\ntest_data = test_data.drop(['Ticket'],axis = 1)\ntest_data = test_data.drop(['Cabin'],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d02f301eb6959a99beee56b41b8a60a192416bbc","collapsed":true},"cell_type":"code","source":"# 3.6 show correlation between features exclude survived column.\nfig,ax = plt.subplots(figsize=(12,12))\ncmap = sns.cubehelix_palette(start = 1, rot = 3, gamma=0.8, as_cmap = True)\nsns.heatmap(train_data.corr(),cmap=cmap,annot=True,linewidths=.5,fmt='.1f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"87ce40399b14ad0ddea566aa7fcd9cf5a4efa1e7"},"cell_type":"code","source":"#4.1 split training data and validation data\nY_train_data = train_data['Survived']\nX_train_data = train_data.drop('Survived',axis=1)\nX_train,X_val ,y_train,y_val= train_test_split(X_train_data,Y_train_data,test_size=0.3,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d05536889d0e41a3698f4ebec5c4a2df30b2787d","collapsed":true},"cell_type":"code","source":"#4.2 select a model:randomforest\nclf = RandomForestClassifier(n_estimators=100)\nclf.fit(X_train,y_train)\nimportance_df = pd.DataFrame(clf.feature_importances_,columns=['feature_Temp'],index=X_train.columns)\nimportance_df.sort_values(by=['feature_Temp'],ascending=True, inplace=True)\nprint('feature importance rank:\\n',importance_df)\nimportance_df.plot(kind='barh',stacked = True).get_figure()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81cdb9ceb31945604968c1a4830c9f9fc331e65b","collapsed":true},"cell_type":"code","source":"#4.3 validate\ny_pred = clf.predict(X_val)\nacc = accuracy_score(y_pred,y_val)\nprint(\"validation accuracy: \",acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e9c17ea90e66b7915ce72147a36819bbdfe3848","collapsed":true},"cell_type":"code","source":"#4.4 test and submission\ntest_data_dropId = test_data.drop(['PassengerId'],axis=1)\npredict_test = clf.predict(test_data_dropId)\nsubmission = pd.DataFrame({\n    \"PassengerId\":test_data['PassengerId'],\n    'Survived':predict_test\n})\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}