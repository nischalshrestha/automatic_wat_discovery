{"nbformat": 4, "nbformat_minor": 1, "metadata": {"language_info": {"version": "3.6.3", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "nbconvert_exporter": "python"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "cells": [{"source": ["**Titanic disaster problem**\n", "\n", "This is my firts approach trying to solve titanic problem. It uses some models with titanic_train dataset to determine the best model, after that this choosen one is used to predict values with titanic_test."], "cell_type": "markdown", "metadata": {}}, {"source": ["#Import basic libraries\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "import seaborn as sns"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#Metrics and library to implement cross validation\n", "from sklearn.cross_validation import train_test_split\n", "from sklearn import metrics\n", "#Models\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.svm import SVC, LinearSVC\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.neighbors import KNeighborsClassifier"], "cell_type": "code", "metadata": {"collapsed": true}, "execution_count": null, "outputs": []}, {"source": ["#Read data sets\n", "titanic_train = pd.read_csv('../input/train.csv')\n", "titanic_test = pd.read_csv('../input/test.csv')"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#Inspect titanic train\n", "titanic_train.info()"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#Inspect titanic test\n", "titanic_test.info()"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#Missing data train\n", "sns.heatmap(data=titanic_train.isnull(),cmap='viridis',yticklabels=False,cbar=False)"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#Missing data test\n", "sns.heatmap(data=titanic_test.isnull(),cmap='viridis',yticklabels=False,cbar=False)\n"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#Explore data sets \n", "\n", "#Survived\n", "sns.set_style('whitegrid')\n", "sns.countplot(x='Survived',data=titanic_train)\n", "sns.distplot(titanic_train['Survived'],kde=False,rug=True)"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#Survived and Class\n", "sns.set_style('whitegrid')\n", "sns.countplot(x='Survived',data=titanic_train, hue='Pclass')"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#Survived and Sex\n", "sns.set_style('whitegrid')\n", "sns.countplot(x='Survived',data=titanic_train, hue='Sex')"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#Survived and Fare\n", "sns.set_style('whitegrid')\n", "sns.jointplot(x='Survived',data=titanic_train, y='Fare')"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#Age column in titanic_train\n", "sns.set_style('whitegrid')\n", "sns.distplot(titanic_train['Age'].dropna(),kde=False,bins=30)"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#Age column in titanic_test\n", "sns.set_style('whitegrid')\n", "sns.distplot(titanic_test['Age'].dropna(),kde=False,bins=30)"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#Fix missing data in Age column\n", "age_first_class = titanic_train[titanic_train['Pclass']==1]['Age'].mean()\n", "age_second_class = titanic_train[titanic_train['Pclass']==2]['Age'].mean()\n", "age_third_class = titanic_train[titanic_train['Pclass']==3]['Age'].mean()\n"], "cell_type": "code", "metadata": {"collapsed": true}, "execution_count": null, "outputs": []}, {"source": ["#Function to replace missing values in Age column with the in that passenger's\n", "#class\n", "def impute_age(cols):\n", "    Age = cols[0]\n", "    Pclass = cols[1]\n", "    \n", "    if pd.isnull(Age):\n", "        if Pclass == 1:\n", "            return age_first_class\n", "        elif Pclass == 2:\n", "            return age_second_class\n", "        else:\n", "            return age_third_class\n", "    else:\n", "        return Age\n", "    \n", "    "], "cell_type": "code", "metadata": {"collapsed": true}, "execution_count": null, "outputs": []}, {"source": ["#Replace missing values in column Age\n", "titanic_train['Age'] = titanic_train[['Age','Pclass']].apply(impute_age,axis=1)\n", "titanic_test['Age'] = titanic_test[['Age','Pclass']].apply(impute_age,axis=1)\n"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#Let's check the heatmap again \n", "#first titanic_train\n", "sns.heatmap(data=titanic_train.isnull(),cmap='coolwarm',cbar=False,yticklabels=False)"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#titanic_test\n", "sns.heatmap(data=titanic_test.isnull(),cmap='coolwarm',cbar=False,yticklabels=False)"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#Remove cabin column\n", "titanic_train.drop('Cabin',axis=1, inplace=True)\n", "titanic_test.drop('Cabin',axis=1, inplace=True)"], "cell_type": "code", "metadata": {"collapsed": true}, "execution_count": null, "outputs": []}, {"source": ["#Get dummies of categorial columns\n", "sex_train = pd.get_dummies(titanic_train['Sex'],drop_first=True)\n", "embark_train =pd.get_dummies(titanic_train['Embarked'],drop_first=True) \n", "sex_test = pd.get_dummies(titanic_test['Sex'],drop_first=True)\n", "embark_test = pd.get_dummies(titanic_test['Embarked'],drop_first=True)"], "cell_type": "code", "metadata": {"collapsed": true}, "execution_count": null, "outputs": []}, {"source": ["#Remove categorical columns and other columns that are useless\n", "titanic_train.drop(['PassengerId','Embarked','Sex','Ticket','Name'],axis=1,inplace=True)\n", "titanic_test.drop(['Embarked','Ticket','Name','Sex'],axis=1,inplace=True)\n", "\n", "#Concat dummies to the dataset\n", "titanic_train = pd.concat([titanic_train,sex_train,embark_train],axis=1)\n", "titanic_test = pd.concat([titanic_test,sex_test,embark_test],axis=1)\n", "\n", "\n", "#Fill null value in Fare column\n", "titanic_test['Fare'].fillna(titanic_train['Fare'].median(),inplace=True)\n"], "cell_type": "code", "metadata": {"collapsed": true}, "execution_count": null, "outputs": []}, {"source": ["#Define training and testing sets\n", "X_train = titanic_train.drop(\"Survived\", axis=1)\n", "Y_train = titanic_train['Survived']\n"], "cell_type": "code", "metadata": {"collapsed": true}, "execution_count": null, "outputs": []}, {"source": ["#Cross validation\n", "#Split trainint set into training and test set\n", "X_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, \n", "                                                    test_size = 0.3, \n", "                                                    random_state = 6)"], "cell_type": "code", "metadata": {"collapsed": true}, "execution_count": null, "outputs": []}, {"source": ["#Logistic Regression\n", "logModel = LogisticRegression(random_state=0)\n", "logModel.fit(X_train,y_train)\n", "\n", "y_pred = logModel.predict(X_test)\n", "metrics.accuracy_score(y_test,y_pred)"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#SVM \n", "svc = SVC()\n", "svc.fit(X_train,y_train)\n", "\n", "y_pred_1 = svc.predict(X_test)\n", "metrics.accuracy_score(y_test,y_pred_1)"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["dtree = DecisionTreeClassifier()\n", "dtree.fit(X_train,y_train)\n", "\n", "y_pred_2 = dtree.predict(X_test)\n", "metrics.accuracy_score(y_test,y_pred_2)"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#Random Forest\n", "rfc = RandomForestClassifier()\n", "rfc.fit(X_train,y_train)\n", "\n", "y_pred_3 = rfc.predict(X_test)\n", "metrics.accuracy_score(y_test,y_pred_3)\n"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#KNN\n", "knn = KNeighborsClassifier(n_neighbors=1)\n", "knn.fit(X_train,y_train)\n", "\n", "y_pred_4 = knn.predict(X_test)\n", "metrics.accuracy_score(y_test,y_pred_4)\n"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": ["#Predict values using real test set\n", "X_test = titanic_test.drop(\"PassengerId\",axis=1)\n", "\n", "#Logistic Regression got the best score\n", "from sklearn.linear_model import LogisticRegression\n", "\n", "y_pred = logModel.predict(X_test)"], "cell_type": "code", "metadata": {"collapsed": true}, "execution_count": null, "outputs": []}, {"source": ["#Submission\n", "\n", "submission = pd.DataFrame({\"PassengerId\":titanic_test[\"PassengerId\"],\n", "                           \"Survived\":y_pred})\n", "\n", "#np.savetxt('predictions.csv',predictions.astype(np.int),fmt='%d', delimiter=\",\",)\n", "\n", "submission.to_csv('titanic.csv',index=False)"], "cell_type": "code", "metadata": {"collapsed": true}, "execution_count": null, "outputs": []}, {"source": ["**Final Thoughts**\n", "\n", "My next step is to understand the techniques to avoid overfitting and how to use them in this model. Please let me know your suggestions, all of them will be appreciated\n", "Thanks"], "cell_type": "markdown", "metadata": {}}]}