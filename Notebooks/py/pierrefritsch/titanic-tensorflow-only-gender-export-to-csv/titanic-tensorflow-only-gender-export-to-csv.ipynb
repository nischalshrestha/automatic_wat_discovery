{"cells":[{"metadata":{"_uuid":"729c6a1d6c3364e78d91f55d4e64d9f4a0d750d4"},"cell_type":"markdown","source":"This kernel can be used as a starting point for experimenting with the Titanic dataset to generate survival predictions. \n\nIt reads the dataset using [pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html), uses the TensorFlow [LinearClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier) estimator, considering only the passenger gender as feature. Finally, it exports predictions to a CSV file that can be uploaded to Kaggle, resulting in a whopping 76.6 % public score.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"529209b1-4584-44b7-b6f3-7e7cf708d32c","_uuid":"c1a2662a99045e4e5a2ac9f551aef950f1321bf2","collapsed":true,"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\n# make TensorFlow less verbose\ntf.logging.set_verbosity(tf.logging.ERROR)\n\n# read the dataset\ntrain_data = pd.read_csv(\"../input/train.csv\")\ntest_data = pd.read_csv(\"../input/test.csv\")\n\n# drop unused columns\nUNUSED_COLUMNS = [\"Name\", \"Ticket\", \"Age\", \"Cabin\", \"Embarked\", \"Fare\"]\ntrain_data = train_data.drop(UNUSED_COLUMNS, axis=1)\ntest_data = test_data.drop(UNUSED_COLUMNS, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b3e2caed-44c2-4d89-8e58-5d8d00ad2dee","_uuid":"e10b7c30348ceb8ab08de2ed83e9771d4fbc7566","collapsed":true,"trusted":true},"cell_type":"code","source":"# sample 80% for train data\ntrain_set = train_data.sample(frac=0.8, replace=False, random_state=42)\n# the other 20% is reserved for cross validation\ncv_set = train_data.loc[ set(train_data.index) - set(train_set.index)]\n\n# define features\nsex_feature = tf.feature_column.categorical_column_with_vocabulary_list(\n    'Sex', ['female','male']\n)\n\nfeature_columns = [ sex_feature ]\n\nestimator = tf.estimator.LinearClassifier(\n    feature_columns=feature_columns)\n\n# train input function\ntrain_input_fn = tf.estimator.inputs.pandas_input_fn(\n      x=train_set.drop('Survived', axis=1),\n      y=train_set.Survived,\n      num_epochs=None, # for training, use as many epochs as necessary\n      shuffle=True,\n      target_column='target',\n)\n\ncv_input_fn = tf.estimator.inputs.pandas_input_fn(\n      x=cv_set.drop('Survived', axis=1),\n      y=cv_set.Survived,\n      num_epochs=1, # only to score\n      shuffle=False\n)\n\nestimator.train(input_fn=train_input_fn, steps=10)\n\nscores = estimator.evaluate(input_fn=cv_input_fn)\nprint(\"\\nTest Accuracy: {0:f}\\n\".format(scores['accuracy']))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"469f745f-fc0e-4054-bb45-269ec1244c92","_uuid":"19094caba74ee93fe60ebe9eb49badab6db3231e","collapsed":true,"trusted":true},"cell_type":"code","source":"test_input_fn = tf.estimator.inputs.pandas_input_fn(\n      x=test_data,\n      num_epochs=1, # only to predict\n      shuffle=False \n)\n\npredictions = list(estimator.predict(input_fn=test_input_fn))\npredicted_classes = [prediction['class_ids'][0] for prediction in predictions]\nevaluation = test_data['PassengerId'].copy().to_frame()\nevaluation[\"Survived\"] = predicted_classes\nevaluation.to_csv(\"evaluation_submission.csv\", index=False) # Public Score: 0.76555\nevaluation.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"94fa2e7b-41a8-48c8-a8b9-30cc4d068d95","_uuid":"7fd71532741818041f3dec58e2f93961d3d81256","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}