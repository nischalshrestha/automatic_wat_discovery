{"nbformat": 4, "nbformat_minor": 1, "metadata": {"language_info": {"mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py", "version": "3.6.1", "name": "python"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "cells": [{"execution_count": null, "outputs": [], "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "metadata": {"_cell_guid": "2ea5b860-2e78-4edc-9083-3c29ce4d98d6", "_uuid": "79060850739e5f5b375927e8cddb76dcdcbe8f16"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["# data analysis and wrangling\n", "import pandas as pd\n", "import numpy as np\n", "\n", "# visualization\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "# machine learning\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.svm import SVC, LinearSVC\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.tree import DecisionTreeClassifier\n", "from xgboost import XGBClassifier"], "metadata": {"_cell_guid": "942ee8aa-9790-4d33-87b4-50c341e172b7", "collapsed": true, "_uuid": "ff0e426dd88364173d979c7f899b8af78345a042"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["train_df = pd.read_csv('../input/train.csv')\n", "test_df = pd.read_csv('../input/test.csv')\n", "combine_df = pd.concat([train_df,test_df])"], "metadata": {"_cell_guid": "4aab98e6-8f77-4977-875f-e03743d3582b", "collapsed": true, "_uuid": "9e917c3d9711817eb88cb0496a3b891162928622"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["#Title\n", "combine_df['Title'] = combine_df['Name'].apply(lambda x: x.split(', ')[1]).apply(lambda x: x.split('.')[0])\n", "combine_df['Title'] = combine_df['Title'].replace(['Don','Dona', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col','Sir','Dr'],'Mr')\n", "combine_df['Title'] = combine_df['Title'].replace(['Mlle','Ms'], 'Miss')\n", "combine_df['Title'] = combine_df['Title'].replace(['the Countess','Mme','Lady','Dr'], 'Mrs')\n", "df = pd.get_dummies(combine_df['Title'],prefix='Title')\n", "combine_df = pd.concat([combine_df,df],axis=1)\n", "\n", "#Name_length\n", "combine_df['Name_Len'] = combine_df['Name'].apply(lambda x: len(x))\n", "combine_df['Name_Len'] = pd.qcut(combine_df['Name_Len'],5)\n", "\n", "#Dead_female_family & Survive_male_family\n", "combine_df['Surname'] = combine_df['Name'].apply(lambda x:x.split(',')[0])\n", "dead_female_surname = list(set(combine_df[(combine_df.Sex=='female') & (combine_df.Age>=12)\n", "                              & (combine_df.Survived==0) & ((combine_df.Parch>0) | (combine_df.SibSp > 0))]['Surname'].values))\n", "survive_male_surname = list(set(combine_df[(combine_df.Sex=='male') & (combine_df.Age>=12)\n", "                              & (combine_df.Survived==1) & ((combine_df.Parch>0) | (combine_df.SibSp > 0))]['Surname'].values))\n", "combine_df['Dead_female_family'] = np.where(combine_df['Surname'].isin(dead_female_surname),0,1)\n", "combine_df['Survive_male_family'] = np.where(combine_df['Surname'].isin(survive_male_surname),0,1)\n", "combine_df = combine_df.drop(['Name','Surname'],axis=1)"], "metadata": {"_cell_guid": "c36e3ede-5f95-4aa6-ac2c-3a8e6c4c07b5", "collapsed": true, "_uuid": "a240fa0c7459673078b4ccd1778777a013ade568"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["#Age & isChild\n", "group = combine_df.groupby(['Title', 'Pclass'])['Age']\n", "combine_df['Age'] = group.transform(lambda x: x.fillna(x.median()))\n", "combine_df = combine_df.drop('Title',axis=1)\n", "\n", "combine_df['IsChild'] = np.where(combine_df['Age']<=12,1,0)\n", "combine_df['Age'] = pd.cut(combine_df['Age'],5)\n", "combine_df = combine_df.drop('Age',axis=1)"], "metadata": {"_cell_guid": "a9c2c94b-60ee-4012-ae02-24c9d63f3da7", "collapsed": true, "_uuid": "b7c6afdac168a34001b2eb08784375c4c6dcd28a"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["#FamilySize\n", "combine_df['FamilySize'] = np.where(combine_df['SibSp']+combine_df['Parch']==0, 'Alone',\n", "                                    np.where(combine_df['SibSp']+combine_df['Parch']<=3, 'Small', 'Big'))\n", "df = pd.get_dummies(combine_df['FamilySize'],prefix='FamilySize')\n", "combine_df = pd.concat([combine_df,df],axis=1).drop(['SibSp','Parch','FamilySize'],axis=1)"], "metadata": {"_cell_guid": "cc2d616b-bb63-418c-ab10-a721e96a9d15", "collapsed": true, "_uuid": "294a486ad7fa29ff0c9997f27fbb383ed8140a9d"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["#Ticket\n", "combine_df['Ticket_Lett'] = combine_df['Ticket'].apply(lambda x: str(x)[0])\n", "combine_df['Ticket_Lett'] = combine_df['Ticket_Lett'].apply(lambda x: str(x))\n", "\n", "combine_df['High_Survival_Ticket'] = np.where(combine_df['Ticket_Lett'].isin(['1', '2', 'P']),1,0)\n", "combine_df['Low_Survival_Ticket'] = np.where(combine_df['Ticket_Lett'].isin(['A','W','3','7']),1,0)\n", "combine_df = combine_df.drop(['Ticket','Ticket_Lett'],axis=1)"], "metadata": {"_cell_guid": "890bfe02-dc5d-4593-9b13-5f477ff71be9", "collapsed": true, "_uuid": "ca6bb5beae36c7b52eb6fa8e84ab3c1a098318ab"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["#Embarked\n", "combine_df = combine_df.drop('Embarked',axis=1)"], "metadata": {"_cell_guid": "569b39b1-1d89-4e45-a1d7-53ca837c2631", "collapsed": true, "_uuid": "edc32a8333c880ba53fe1f2a81d05fb20878c8ce"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["#Cabin\n", "combine_df['Cabin_isNull'] = np.where(combine_df['Cabin'].isnull(),0,1)\n", "combine_df = combine_df.drop('Cabin',axis=1)"], "metadata": {"_cell_guid": "b7d10d32-ce52-471d-8d9e-93f4cfd7e1bd", "collapsed": true, "_uuid": "fb36d564f38fbd65ddf10bccde141e707ba7cd29"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["#PClass\n", "df = pd.get_dummies(combine_df['Pclass'],prefix='Pclass')\n", "combine_df = pd.concat([combine_df,df],axis=1).drop('Pclass',axis=1)"], "metadata": {"_cell_guid": "1d44afb3-cf09-415f-aa83-a9a0844514fe", "collapsed": true, "_uuid": "9e2920df7f8c5264f23a7e0aab549cbc52c579e5"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["#Sex\n", "df = pd.get_dummies(combine_df['Sex'],prefix='Sex')\n", "combine_df = pd.concat([combine_df,df],axis=1).drop('Sex',axis=1)"], "metadata": {"_cell_guid": "e47a66f1-0569-4d00-82ae-2b5bc55752f0", "collapsed": true, "_uuid": "189166e9b8ff0e457085e59b7bc744acb6cae30d"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["#Fare\n", "combine_df['Fare'].fillna(combine_df['Fare'].dropna().median(),inplace=True)\n", "combine_df['Low_Fare'] = np.where(combine_df['Fare']<=8.662,1,0)\n", "combine_df['High_Fare'] = np.where(combine_df['Fare']>=26,1,0)\n", "combine_df = combine_df.drop('Fare',axis=1)"], "metadata": {"_cell_guid": "eae7a401-55bc-4dbc-a285-d8b3ad96c76a", "collapsed": true, "_uuid": "3ceef9ad6f03c9f3b7bd3689ad90068daf063448"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["features = combine_df.drop([\"PassengerId\",\"Survived\"], axis=1).columns\n", "le = LabelEncoder()\n", "for feature in features:\n", "    le = le.fit(combine_df[feature])\n", "    combine_df[feature] = le.transform(combine_df[feature])"], "metadata": {"_cell_guid": "59198e46-7f2f-47dd-8256-2decf3fb8c30", "collapsed": true, "_uuid": "272eb24e5d5e7c7a94ab40c3954cd85056ea85cc"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["X_all = combine_df.iloc[:891,:].drop([\"PassengerId\",\"Survived\"], axis=1)\n", "Y_all = combine_df.iloc[:891,:][\"Survived\"]\n", "X_test = combine_df.iloc[891:,:].drop([\"PassengerId\",\"Survived\"], axis=1)"], "metadata": {"_cell_guid": "c6449f63-9cad-46e1-85b9-047e39b7085a", "collapsed": true, "_uuid": "f811bc77ca961f0c3199fab9fe161faf56765a36"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["logreg = LogisticRegression()\n", "score = 0\n", "for i in range(0,100):\n", "    num_test = 0.20\n", "    X_train, X_cv, Y_train, Y_cv = train_test_split(X_all, Y_all, test_size=num_test)\n", "    logreg.fit(X_train, Y_train)\n", "    acc_log = round(logreg.score(X_cv, Y_cv) * 100, 2)\n", "    score+=acc_log\n", "score/100"], "metadata": {"_cell_guid": "a77da155-3578-42b0-9b5d-b04cf307aaac", "_uuid": "b167936e05224908a65425418866310b133799a1"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["coeff_df = pd.DataFrame()\n", "coeff_df['Feature'] = features\n", "coeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n", "coeff_df.sort_values(by='Correlation', ascending=False)"], "metadata": {"_cell_guid": "6a3cda03-d04c-4b7e-910d-88206510feea", "_uuid": "0964c027337483cfa8a294d7bb7daf6bf9a1861a"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["svc = SVC()\n", "score = 0\n", "for i in range(0,100):\n", "    num_test = 0.20\n", "    X_train, X_cv, Y_train, Y_cv = train_test_split(X_all, Y_all, test_size=num_test)\n", "    svc.fit(X_train, Y_train)\n", "    acc_svc = round(svc.score(X_cv, Y_cv) * 100, 2)\n", "    score+=acc_svc\n", "score/100"], "metadata": {"_cell_guid": "86a64cc2-eed5-406e-bba8-9a007169886f", "_uuid": "be2ce314e2325b5fee061e083069e0cc130d474b"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["knn = KNeighborsClassifier(n_neighbors = 3)\n", "score = 0\n", "for i in range(0,100):\n", "    num_test = 0.20\n", "    X_train, X_cv, Y_train, Y_cv = train_test_split(X_all, Y_all, test_size=num_test)\n", "    knn.fit(X_train, Y_train)\n", "    acc_knn = round(knn.score(X_cv, Y_cv) * 100, 2)\n", "    score+=acc_knn\n", "score/100"], "metadata": {"_cell_guid": "f501ce02-092a-4fb0-9c5e-4c44836f76e3", "_uuid": "ba2646306b46e69878d7c49c438a6546f7cf6af4"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["# Decision Tree\n", "decision_tree = DecisionTreeClassifier()\n", "score = 0\n", "for i in range(0,100):\n", "    num_test = 0.20\n", "    X_train, X_cv, Y_train, Y_cv = train_test_split(X_all, Y_all, test_size=num_test)\n", "    decision_tree.fit(X_train, Y_train)\n", "    acc_decision_tree = round(decision_tree.score(X_cv, Y_cv) * 100, 2)\n", "    score+=acc_decision_tree\n", "score/100"], "metadata": {"_cell_guid": "4e455962-5971-4c7e-8b0c-7fee323cdb1b", "_uuid": "81d44c03028e71ba6f4e5ff1703a8a994eea0317"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["# Random Forest\n", "random_forest = RandomForestClassifier(n_estimators=300,min_samples_leaf=4,class_weight={0:0.745,1:0.255})\n", "score = 0\n", "for i in range(0,100):\n", "    num_test = 0.20\n", "    X_train, X_cv, Y_train, Y_cv = train_test_split(X_all, Y_all, test_size=num_test)\n", "    random_forest.fit(X_train, Y_train)\n", "    acc_random_forest = round(random_forest.score(X_cv, Y_cv) * 100, 2)\n", "    score+=acc_random_forest\n", "score/100"], "metadata": {"_cell_guid": "17931967-ece1-4ec0-ad35-d34dc90b4ecd", "_uuid": "5c794097250b8abf6bc1303a7405fafca06f3a4b"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["#XGBoost\n", "xgb = XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)\n", "score = 0\n", "for i in range(0,100):\n", "    num_test = 0.20\n", "    X_train, X_cv, Y_train, Y_cv = train_test_split(X_all, Y_all, test_size=num_test)\n", "    xgb.fit(X_train, Y_train)\n", "    acc_xgb = round(xgb.score(X_cv, Y_cv) * 100, 2)\n", "    score+=acc_xgb\n", "score/100"], "metadata": {"_cell_guid": "1de62d35-fc58-47ca-b0c7-cd3d5e2b32cd", "_uuid": "c2d6f4f56f8ae2de4e363a2b1cb4626f349fb7c0"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["random_forest.fit(X_all, Y_all)\n", "Y_test = random_forest.predict(X_test).astype(int)\n", "submission = pd.DataFrame({\n", "        \"PassengerId\": test_df[\"PassengerId\"],\n", "        \"Survived\": Y_test\n", "    })\n", "submission.to_csv('submission.csv', index=False)"], "metadata": {"_cell_guid": "b26a9634-3b73-47e1-abb2-33c0d7f600d9", "collapsed": true, "_uuid": "61a9e4f0eb4c86e0ae260067188028f00576f47f"}}, {"execution_count": null, "outputs": [], "cell_type": "code", "source": ["feature_importance = pd.DataFrame()\n", "feature_importance['feature'] = features\n", "feature_importance['importance'] = random_forest.feature_importances_\n", "feature_importance.sort_values(by='importance', ascending=True, inplace=True)\n", "feature_importance.set_index('feature', inplace=True)\n", "feature_importance.plot(kind='barh', figsize=(10, 10))"], "metadata": {"_cell_guid": "7ad779c8-0080-437d-853f-2ea9c9850988", "_uuid": "ce427f7f1adb20bce4bfb31df05e264952ca5b54"}}]}