{"cells": [{"outputs": [], "metadata": {"collapsed": false, "_uuid": "122ab5693b5bb1736ed307010d6ae3882171da6b", "_execution_state": "idle", "_cell_guid": "962472fa-4c36-4aa0-a0d6-210acb62921b"}, "cell_type": "markdown", "execution_count": null, "source": "\u53c2\u8003\u4e86[Anisotropic][1]\u7684kernel\n\n\n  [1]: https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "179c24346dcd57c3c3493017553e4fdbe3b9f898", "_execution_state": "idle", "_cell_guid": "06089f0b-fec7-453f-a3f5-e9b19b9eceb8"}, "cell_type": "markdown", "execution_count": null, "source": "## 1. \u76f8\u5173\u5305\u7684\u5bfc\u5165"}, {"outputs": [], "metadata": {"_cell_guid": "31d698f1-8ccd-4be8-a2f3-c9b82b31ee59", "_uuid": "890c02cc286dd6e8c8acf31118df8b0bc61b3fc9", "_execution_state": "idle", "trusted": false}, "cell_type": "code", "execution_count": null, "source": "# Load in our libraries\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for the stacking\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.cross_validation import KFold;\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nfrom sklearn import preprocessing"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "9d43e3a7744d344773c388594cc675da58f0859b", "_execution_state": "idle", "_cell_guid": "32c7b03b-8855-4ba7-a446-66cb79148adf"}, "cell_type": "markdown", "execution_count": null, "source": "## 2. \u6570\u636e\u9884\u5904\u7406\n\n\u8fd9\u91cc\u7684\u9884\u5904\u7406\u65b9\u6cd5\u548c\u4e0a\u4e00\u7bc7[First Try in Titanic][1]\u4e2d\u7684\u4e00\u6837\u3002\n\n\n  [1]: https://www.kaggle.com/shenglei/first-try-in-titanic"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "80988cf7f138ed30f95fa583bd00adfb1da925e5", "_execution_state": "idle", "trusted": false, "_cell_guid": "a389c97c-516c-4d4a-b957-d85ed7d48bff"}, "cell_type": "code", "execution_count": null, "source": "train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\n\n# \u8865\u5145embarked\u7684\u7f3a\u5931\u503c\ntrain['Embarked'] = train['Embarked'].fillna('C')\n\n# \u8865\u5145fare\u7684\u7f3a\u5931\u503c\nfare_median = test[(test['Pclass'] == 3) & (test['Embarked'] == 'S')]['Fare'].median()\ntest['Fare'] = test['Fare'].fillna(fare_median)\n\n# \u63d0\u53d6\u65b0\u7684\u7279\u5f81Deck\ntrain['Deck'] = train['Cabin'].str[0]\ntest['Deck'] = test['Cabin'].str[0]\ntrain['Deck'] = train['Deck'].fillna('Z')\ntest['Deck'] = test['Deck'].fillna('Z')\n\n# \u63d0\u53d6\u65b0\u7684\u7279\u5f81family type\ntrain['Family'] = train['SibSp'] + train['Parch'] + 1\ntest['Family'] = test['SibSp'] + test['Parch'] + 1\n\ntrain.loc[train['Family'] == 1, 'FamilyType'] = 'singleton'\ntrain.loc[(train['Family'] > 1) & (train['Family'] < 5), 'FamilyType'] = 'small'\ntrain.loc[train['Family'] > 4, 'FamilyType'] = 'large'\n\ntest.loc[test['Family'] == 1, 'FamilyType'] = 'singleton'\ntest.loc[(test['Family'] > 1) & (test['Family'] < 5), 'FamilyType'] = 'small'\ntest.loc[test['Family'] > 4, 'FamilyType'] = 'large'\n\n# \u63d0\u53d6\u65b0\u7684\u7279\u5f81title\ndef get_title(name):\n    title = re.compile('(.*, )|(\\\\..*)').sub('',name)\n    return title\n\ntitles = train['Name'].apply(get_title)\ntrain['Title'] = titles\n\ntitles = test['Name'].apply(get_title)\ntest['Title'] = titles\n\nrare_title = ['Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don', \n                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']\ntrain.loc[train[\"Title\"] == \"Mlle\", \"Title\"] = 'Miss'\ntrain.loc[train[\"Title\"] == \"Ms\", \"Title\"] = 'Miss'\ntrain.loc[train[\"Title\"] == \"Mme\", \"Title\"] = 'Mrs'\ntrain.loc[train[\"Title\"] == \"Dona\", \"Title\"] = 'Rare Title'\ntrain.loc[train[\"Title\"] == \"Lady\", \"Title\"] = 'Rare Title'\ntrain.loc[train[\"Title\"] == \"Countess\", \"Title\"] = 'Rare Title'\ntrain.loc[train[\"Title\"] == \"Capt\", \"Title\"] = 'Rare Title'\ntrain.loc[train[\"Title\"] == \"Col\", \"Title\"] = 'Rare Title'\ntrain.loc[train[\"Title\"] == \"Don\", \"Title\"] = 'Rare Title'\ntrain.loc[train[\"Title\"] == \"Major\", \"Title\"] = 'Rare Title'\ntrain.loc[train[\"Title\"] == \"Rev\", \"Title\"] = 'Rare Title'\ntrain.loc[train[\"Title\"] == \"Sir\", \"Title\"] = 'Rare Title'\ntrain.loc[train[\"Title\"] == \"Jonkheer\", \"Title\"] = 'Rare Title'\ntrain.loc[train[\"Title\"] == \"Dr\", \"Title\"] = 'Rare Title'\n\ntest.loc[test[\"Title\"] == \"Mlle\", \"Title\"] = 'Miss'\ntest.loc[test[\"Title\"] == \"Ms\", \"Title\"] = 'Miss'\ntest.loc[test[\"Title\"] == \"Mme\", \"Title\"] = 'Mrs'\ntest.loc[test[\"Title\"] == \"Dona\", \"Title\"] = 'Rare Title'\ntest.loc[test[\"Title\"] == \"Lady\", \"Title\"] = 'Rare Title'\ntest.loc[test[\"Title\"] == \"Countess\", \"Title\"] = 'Rare Title'\ntest.loc[test[\"Title\"] == \"Capt\", \"Title\"] = 'Rare Title'\ntest.loc[test[\"Title\"] == \"Col\", \"Title\"] = 'Rare Title'\ntest.loc[test[\"Title\"] == \"Don\", \"Title\"] = 'Rare Title'\ntest.loc[test[\"Title\"] == \"Major\", \"Title\"] = 'Rare Title'\ntest.loc[test[\"Title\"] == \"Rev\", \"Title\"] = 'Rare Title'\ntest.loc[test[\"Title\"] == \"Sir\", \"Title\"] = 'Rare Title'\ntest.loc[test[\"Title\"] == \"Jonkheer\", \"Title\"] = 'Rare Title'\ntest.loc[test[\"Title\"] == \"Dr\", \"Title\"] = 'Rare Title'\n\n# \u8f6c\u53d8\u79bb\u6563\u6570\u636e\u4e3aone-hot\nlabelEnc=LabelEncoder()\n\ncat_vars=['Embarked','Sex',\"Title\",\"FamilyType\",'Deck']\nfor col in cat_vars:\n    train[col]=labelEnc.fit_transform(train[col])\n    test[col]=labelEnc.fit_transform(test[col])\n    \n# Age\u7f3a\u5931\u503c\u586b\u5145\ndef fill_missing_age(data):\n    \n    #Feature set\n    features = data[['Age','Embarked','Fare', 'Parch', 'SibSp',\n                 'Title','Pclass','Family',\n                 'FamilyType', 'Deck']]\n    # Split sets into train and prediction\n    train  = features.loc[ (data.Age.notnull()) ]# known Age values\n    prediction = features.loc[ (data.Age.isnull()) ]# null Ages\n    \n    # All age values are stored in a target array\n    y = train.values[:, 0]\n    \n    # All the other values are stored in the feature array\n    X = train.values[:, 1::]\n    \n    # Create and fit a model\n    rtr = RandomForestRegressor(n_estimators=2000, n_jobs=-1)\n    rtr.fit(X, y)\n    \n    # Use the fitted model to predict the missing values\n    predictedAges = rtr.predict(prediction.values[:, 1::])\n    \n    # Assign those predictions to the full data set\n    data.loc[ (data.Age.isnull()), 'Age' ] = predictedAges \n    \n    return data\n\ntrain=fill_missing_age(train)\ntest=fill_missing_age(test)\n\n# \u6570\u636e\u5f52\u4e00\u5316\nstd_scale = preprocessing.StandardScaler().fit(train[['Age', 'Fare']])\ntrain[['Age', 'Fare']] = std_scale.transform(train[['Age', 'Fare']])\n\n\nstd_scale = preprocessing.StandardScaler().fit(test[['Age', 'Fare']])\ntest[['Age', 'Fare']] = std_scale.transform(test[['Age', 'Fare']])"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "4d5916332cc2acb084e4aeddf46586a820354881", "_execution_state": "idle", "trusted": false, "_cell_guid": "651c479a-9ca5-4357-bf57-cb7a4508ae49"}, "cell_type": "code", "execution_count": null, "source": "train.info()"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "6b3bc671abb1b637f5aab8b2db1f294ad5a30e71", "_execution_state": "idle", "_cell_guid": "bb1c797d-1048-4975-8f3a-fd27b19c5289"}, "cell_type": "markdown", "execution_count": null, "source": "## 3. \u6a21\u578b\u8bad\u7ec3"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "072abd736931106efdb378721e78f7605d42c1bd", "_execution_state": "idle", "_cell_guid": "2c8ade3a-eb5d-49e3-847e-8eb40668a732"}, "cell_type": "markdown", "execution_count": null, "source": "\u6574\u4e2astacking\u7684\u8fc7\u7a0b\u5982\u4e0b\u6240\u793a\uff1a\n\n![overall model][1]\n\n\n  [1]: http://upload-images.jianshu.io/upload_images/1398446-52194077ee5d5160.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "18bb3140c7f7cc3f3b317b5ed8a3835a4ece2047", "_execution_state": "idle", "trusted": false, "_cell_guid": "77244903-f911-4777-a734-d74df65277d2"}, "cell_type": "code", "execution_count": null, "source": "n_train = train.shape[0]\nn_test = test.shape[0]\nSEED = 0\nN_FOLDS = 5\nkf = KFold(n_train, n_folds=N_FOLDS, random_state=SEED)\n\nprint(n_train)\nprint(n_test)"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "2ab4da742870a36686117fe7e09e1b98ff968a13", "_execution_state": "idle", "trusted": false, "_cell_guid": "59790b27-c3f7-4084-a1d4-393a9ca85ae4"}, "cell_type": "code", "execution_count": null, "source": "class SklearnHelper(object):\n    def __init__(self, classifier, seed=0, params=None):\n        params['random_state'] = seed\n        self.classifier = classifier(**params)\n        \n    def train(self, X_train, y_train):\n        self.classifier.fit(X_train, y_train)\n    \n    def predict(self, X_test):\n        return self.classifier.predict(X_test)\n    \n    def fit(self, X_train, y_train):\n        return self.classifier.fit(X_train, y_train)\n    \n    def feature_importances(self, X_train, y_train):\n        print(self.classifier.fit(X_train, y_train).feature_importances_)"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "91f08b9db02e775b980411aba1b64a57ac96b493", "_execution_state": "idle", "trusted": false, "_cell_guid": "d3534cf0-5d58-4592-bbe7-41627171c84b"}, "cell_type": "code", "execution_count": null, "source": "def get_K_Fold(classifier, X_train, y_train, X_test):\n    new_train = np.zeros((n_train, )) # shape = [891, 1]\n    new_test = np.zeros((n_test, )) # shape = [418, 1]\n    each_fold_test_records = np.empty((N_FOLDS, n_test))\n    \n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = X_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = X_train[test_index]\n        \n        # \u751f\u6210\u65b0\u7684\u8bad\u7ec3\u96c6\n        classifier.train(x_tr, y_tr) # \u4f7f\u7528k-1\u4efd\u4f5c\u4e3a\u8bad\u7ec3\u96c6\n        new_train[test_index] = classifier.predict(x_te) # 1\u4efd\u4f5c\u4e3a\u6d4b\u8bd5\u96c6\uff0c\u9884\u6d4by_te\n        \n        # \u751f\u6210\u65b0\u7684\u6d4b\u8bd5\u96c6\n        each_fold_test_records[i, :] = classifier.predict(X_test)\n        \n    new_test[:] = each_fold_test_records.mean(axis=0)\n    return new_train.reshape(-1, 1), new_test.reshape(-1 ,1)"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "79b7cac01377a15038ef841eaefe6a0b4735e779", "_execution_state": "idle", "trusted": false, "_cell_guid": "285d3d23-3b41-41cc-9a1e-9d50fdbc01bf"}, "cell_type": "code", "execution_count": null, "source": "# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth': 8,\n    'min_samples_leaf': 2,\n    'verbose': 0\n}\n\n# AdaBoost parameters\nada_params = {\n    'n_estimators': 500,\n    'learning_rate' : 0.75\n}\n\n# Gradient Boosting parameters\ngb_params = {\n    'n_estimators': 500,\n     #'max_features': 0.2,\n    'max_depth': 5,\n    'min_samples_leaf': 2,\n    'verbose': 0\n}\n\n# Support Vector Classifier parameters \nsvc_params = {\n    'kernel' : 'linear',\n    'C' : 0.025\n    }"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "9b88ce8acb702e3157e38cf09f7282c57898bad6", "_execution_state": "idle", "trusted": false, "_cell_guid": "3b18ea47-65bc-4c54-ad65-60b2a1edf3fc"}, "cell_type": "code", "execution_count": null, "source": "# Random Forest Model\nrf = SklearnHelper(classifier=RandomForestClassifier, seed=SEED, params=rf_params)\n\n# Extra Tree Model\net = SklearnHelper(classifier=ExtraTreesClassifier, seed=SEED, params=et_params)\n\n# AdaBoost Model\nada = SklearnHelper(classifier=AdaBoostClassifier, seed=SEED, params=ada_params)\n\n# Gradient Boosting Model\ngb = SklearnHelper(classifier=GradientBoostingClassifier, seed=SEED, params=gb_params)\n\n# Support Vector Classifier Model\nsvc = SklearnHelper(classifier=SVC, seed=SEED, params=svc_params)"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "4e4b973648cd2bd793f9ab15eda25e28b5f55ede", "_execution_state": "idle", "trusted": false, "_cell_guid": "923c3499-9aff-4b42-8adb-4b0181ba3dbf"}, "cell_type": "code", "execution_count": null, "source": "features = [\"Pclass\", \"Sex\", \"Age\",\"SibSp\", \"Parch\", \"Fare\",\n             \"Embarked\", \"FamilyType\", \"Title\",\"Deck\"]\n\ny_train = train['Survived'].ravel()\nX_train = train[features].values\nX_test = test[features].values\n\nPassengerId = test['PassengerId']\n"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "6add96e47de900548bf9066d6e2dd79223372200", "_execution_state": "idle", "_cell_guid": "011d7c60-a3ec-4d3d-8f2f-4d306f7f8ad0"}, "cell_type": "markdown", "execution_count": null, "source": "### 3.1 \u7b2c\u4e00\u5c42\u6a21\u578b"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "601bdc6432f3b582cece552aa0217fda8c900a2a", "_execution_state": "idle", "trusted": false, "_cell_guid": "c67957a4-158d-43d1-bd6c-3f3d1d4cb9c5"}, "cell_type": "code", "execution_count": null, "source": "# Random Forest Model\nrf_new_train, rf_new_test = get_K_Fold(rf, X_train, y_train, X_test)\n\n# Extra Tree Model\net_new_train, et_new_test = get_K_Fold(et, X_train, y_train, X_test)\n\n# AdaBoost Model\nada_new_train, ada_new_test = get_K_Fold(ada, X_train, y_train, X_test)\n\n# Gradient Boosting Model\ngb_new_train, gb_new_test = get_K_Fold(gb, X_train, y_train, X_test)\n\n# Support Vector Classifier Model \nsvc_new_train, svc_new_test = get_K_Fold(svc, X_train, y_train, X_test)"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "6b92b8eef19a1a39ab81bd560c98670bdd0fd75a", "_execution_state": "idle", "_cell_guid": "71c318cc-1ea4-43ce-b9b1-08eedfe6d060"}, "cell_type": "markdown", "execution_count": null, "source": "### 3.2 \u7b2c\u4e8c\u5c42\u6a21\u578b"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "9aa9e34da3319db6adfbcebfd320afe69c928933", "_execution_state": "idle", "trusted": false, "_cell_guid": "75fe0310-ad57-441e-bc4c-f17a361018d1"}, "cell_type": "code", "execution_count": null, "source": "base_predictions_train = pd.DataFrame( {'RandomForest': rf_new_train.ravel(),\n     'ExtraTrees': et_new_train.ravel(),\n     'AdaBoost': ada_new_train.ravel(),\n      'GradientBoost': gb_new_train.ravel()\n    })\n\nbase_predictions_train.head()"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "52d0aabefe9ffe7e820b97f669d1ab57146f7217", "_execution_state": "idle", "trusted": false, "_cell_guid": "1725d031-8407-4140-a87f-96b4d3c84c9a"}, "cell_type": "code", "execution_count": null, "source": "new_X_train = np.concatenate(( et_new_train, rf_new_train, ada_new_train, gb_new_train, svc_new_train), axis=1)\nnew_X_test = np.concatenate(( et_new_test, rf_new_test, ada_new_test, gb_new_test, svc_new_test), axis=1)\n\nprint(new_X_train.shape)\nprint(new_X_test.shape)"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "f68a65115dd1d8a2fc307da52695c8154618d025", "_execution_state": "idle", "trusted": false, "_cell_guid": "e2d080b5-ad66-4b66-b4c7-13d8a0bb525b"}, "cell_type": "code", "execution_count": null, "source": "gbm = xgb.XGBClassifier(\n    #learning_rate = 0.02,\n n_estimators= 2000,\n max_depth= 4,\n min_child_weight= 2,\n #gamma=1,\n gamma=0.9,                        \n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread= -1,\n scale_pos_weight=1).fit(new_X_train, y_train)\n\npredictions = gbm.predict(new_X_test)"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "d76c1e08fad1dca434ace4f889359e24dace168a", "_execution_state": "idle", "trusted": false, "_cell_guid": "09e49998-d901-4c1b-8e6b-13ed7784de76"}, "cell_type": "code", "execution_count": null, "source": "StackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId,\n                            'Survived': predictions })\nStackingSubmission.to_csv(\"StackingSubmission.csv\", index=False)"}, {"outputs": [], "metadata": {"collapsed": false, "_uuid": "1c1bd924f791dbcbd1e06807872946aec1df4a7b", "_execution_state": "idle"}, "cell_type": "markdown", "execution_count": null, "source": "## 4. \u603b\u7ed3\n\n\u540c\u6837\u7684\u6570\u636e\u5904\u7406\u65b9\u5f0f\u5728\u4f7f\u7528\u4e86stacking\u4e4b\u540e\uff0c\u7ed3\u679c\u63d0\u5347\u4e86\uff0c\u539f\u672c\u6700\u540e\u7684\u662flinear regression\u76840.78947\uff0c\u73b0\u5728\u662f0.79426"}], "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"version": "3.6.1", "nbconvert_exporter": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "name": "python", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat_minor": 0, "nbformat": 4}