{"nbformat_minor": 1, "cells": [{"source": ["# Declaring my environment"], "cell_type": "markdown", "metadata": {"_uuid": "ec25cd8bd22c93b5b60696985d8c421acd7fff9f", "_cell_guid": "10210a5a-f1e0-4536-a2b4-a87aa8096098"}}, {"source": ["\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import tensorflow as tf\n", "from tensorflow.python.framework import ops\n", "import matplotlib.pyplot as plt"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "0681f41bfa8b4f126d284326f4c2e1be304579a4", "collapsed": true, "_cell_guid": "afc34899-f80e-4a44-b8d7-7076cf13246d"}, "execution_count": 1}, {"source": ["# Data Reading"], "cell_type": "markdown", "metadata": {"_uuid": "4c41887cb00227c7478fe2d6bb6725a14a99a5e4", "_cell_guid": "79cadbd0-5fe6-4e37-8e88-8bf48ee009d1"}}, {"source": ["def read_data(file_name):\n", "    \"\"\" Read training/test data \"\"\"\n", "    data = pd.read_csv('../input/'+file_name+'.csv')\n", "    return data"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "773dcbf0513374aee4ddb5f34818078daf521ec9", "collapsed": true, "_cell_guid": "73bb15be-db63-4e18-a765-19062091b388"}, "execution_count": 2}, {"source": ["# Data Cleaning and Normalization"], "cell_type": "markdown", "metadata": {"_uuid": "1a0026ab458c87829ae57f0ef3c4fcf1ba757778", "_cell_guid": "769373e7-f2aa-4c05-b70b-c9ec44d37da1"}}, {"source": ["def prepare_age(data):\n", "    \"\"\"Fill the missing data (nan) with average age \"\"\"\n", "    age = data['Age']\n", "    mean_age = age.mean()\n", "    var_age = age.var()\n", "    age[age.isnull()] = mean_age\n", "    age = age - mean_age\n", "    age = age / var_age\n", "    #print(\"Age is \"+str(age))\n", "    return age.as_matrix()"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "85cbc635e14fd1ee96580eca5c35f852d47f6751", "collapsed": true, "_cell_guid": "90b7184f-aaa9-4dee-bb91-c77058f95f15"}, "execution_count": 3}, {"source": ["def prepare_fare(data):\n", "    \"\"\" Read Fare Data and Normalize it \"\"\"\n", "    fare = data['Fare']\n", "    mean_fare = fare.mean()\n", "    var_fare = fare.var()\n", "    fare = fare - mean_fare\n", "    fare = fare / var_fare\n", "    return fare.as_matrix()"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "53ee4eec59b5def20050b262a22b47168628dbbf", "collapsed": true, "_cell_guid": "cc3eb788-4516-4a17-a569-323eefe679fe"}, "execution_count": 4}, {"source": ["def prepare_sex(data):\n", "    \"\"\" Transform the male into 0 and female into 1 \"\"\"\n", "    sex = data['Sex']\n", "    sex = np.where(sex=='male',0,1)\n", "    #print(\"sex is \"+str(sex))\n", "    return sex"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "bf7be94d413dcaf21e79543e605800ce04cf5499", "collapsed": true, "_cell_guid": "aae4e58d-06e0-4814-889c-759dc7e5f189"}, "execution_count": 5}, {"source": ["def prepare_embarquation(data):\n", "    \"\"\" Transforms the embarquation \"\"\"\n", "    embarked = data['Embarked']\n", "    embarked[embarked.isnull()] = 3\n", "    embarked = np.where(embarked=='C', 0, embarked)\n", "    embarked = np.where(embarked=='Q', 1, embarked)\n", "    embarked = np.where(embarked=='S', 2, embarked)\n", "    #Normalize\n", "    mean_embarked = embarked.mean()\n", "    var_embarked = embarked.var()\n", "    embarked = embarked - mean_embarked\n", "    embarked = embarked / var_embarked\n", "    \n", "    return embarked"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "4ea5ff396bddd43d6c45811aaff2a46530610487", "collapsed": true, "_cell_guid": "fabef6c5-c8e1-46e6-8558-8d0a02f2eb2f"}, "execution_count": 6}, {"source": ["def prepare_sibligs(data):\n", "    \"\"\" Prepare the SibSp data \"\"\"\n", "    sib = data['SibSp']\n", "    mean_sib = sib.mean()\n", "    var_sib = sib.var()\n", "    sib = sib - mean_sib\n", "    sib = sib / var_sib\n", "    return sib"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "8c612916e290f4a7efb0d70a2910a4b4d0ae696f", "collapsed": true, "_cell_guid": "d32626f5-6985-4397-8e88-24175ad3cf19"}, "execution_count": 7}, {"source": ["def prepare_parch(data):\n", "    \"\"\" Prepare the Parch data \"\"\"\n", "    parch = data['Parch']\n", "    mean_parch = parch.mean()\n", "    var_parch = parch.var()\n", "    parch = parch - mean_parch\n", "    parch = parch / var_parch\n", "    return parch"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "4e995b1b663e64fa048d9882bbf8bc778ea43f30", "collapsed": true, "_cell_guid": "e84f3166-82c8-423b-831b-716c09b09a83"}, "execution_count": 8}, {"source": ["## This is inpired by [Nadin](https://www.kaggle.com/nadintamer/titanic-survival-predictions-beginner)"], "cell_type": "markdown", "metadata": {"_uuid": "c3e8bc365356b67849133529966af2e8e2650276", "_cell_guid": "aedf8c6e-b387-4260-81b9-b466054febd9"}}, {"source": ["def prepare_family_size(data):\n", "    \"\"\" Merges the SibSp and Parch into family size then normalize \"\"\"\n", "    parch = data['Parch']\n", "    sib = data['SibSp']\n", "    #merge\n", "    family_size = parch + sib\n", "    \n", "    #normalize\n", "    mean_family_size = family_size.mean()\n", "    var_family_size = family_size.var()\n", "    family_size = family_size - mean_family_size\n", "    family_size = family_size / var_family_size\n", "    return family_size\n", "    "], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "0dd50a8a3847e6ff1f6ac8d7711e3fb14f517ac8", "collapsed": true, "_cell_guid": "48f40582-c2c6-4613-839a-a398b7eb5449"}, "execution_count": 9}, {"source": ["\n", "# Normalize Features"], "cell_type": "markdown", "metadata": {"_uuid": "827f5603b8ef48720b7b56c80b7fcf4c5a7c460a", "_cell_guid": "40771363-e4cf-4b0e-9b1a-e905c13b5472"}}, {"source": ["def normalize_features(data):\n", "    \"\"\" Normalize the features from the data \"\"\"  \n", "    age = prepare_age(data)\n", "    sex = prepare_sex(data)\n", "    embark = prepare_embarquation(data)\n", "    fare = prepare_fare(data)\n", "    sib = prepare_sibligs(data)\n", "    parch = prepare_parch(data)\n", "    family_size = prepare_family_size(data)\n", "    X_train = np.column_stack((sex, age, family_size, embark))\n", "    return X_train.T\n", "    "], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "4b309383f3ffb07d2c4fdaca2ffd6b78faa04d02", "collapsed": true, "_cell_guid": "5c60945a-3f64-488b-80ef-1382ed36cfe9", "_kg_hide-output": false, "_kg_hide-input": false}, "execution_count": 10}, {"source": ["# Prepare Training Data\n"], "cell_type": "markdown", "metadata": {"_uuid": "a3e6e74247279cff9b22d5a74ffe54bc6083765a", "_cell_guid": "4ef498ad-5e11-481a-bfc6-de3e3051e421"}}, {"source": ["def prepare_training_data():\n", "    \"\"\" Read Training data and clean it \"\"\"\n", "    pd.set_option('mode.chained_assignment', None)\n", "    data = read_data('train')\n", "    X_train = normalize_features(data)\n", "    Y_train = np.reshape(data['Survived'].as_matrix(), (X_train.shape[1],1)).T\n", "\n", "    return X_train, Y_train"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "cb76fab0c699f3f896a5f7b91c3425afbd79ab03", "collapsed": true, "_cell_guid": "6024df4a-fab9-4baf-8c09-e8642580fafe"}, "execution_count": 11}, {"source": ["# Prepare Test Data"], "cell_type": "markdown", "metadata": {"_uuid": "2290608dc9081028af392411e967b37a37bcef4b", "_cell_guid": "67e6cf32-052c-434d-84ad-59c6695d8300"}}, {"source": ["def prepare_test_data():\n", "    \"\"\" Read Test data and clean it \"\"\"\n", "    pd.set_option('mode.chained_assignment', None)\n", "    data = read_data('test')\n", "    X_test = normalize_features(data)\n", "    return X_test"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "a0d8f43e7964ba9ba672c05cd4d222472266c7e9", "collapsed": true, "_cell_guid": "331cc362-bd7f-499d-942d-7c33636ea7a7"}, "execution_count": 12}, {"source": ["# Neural Network Architecture Initialization"], "cell_type": "markdown", "metadata": {"_uuid": "30410c450b7fc116835a5d4bc63948933fbbb1c5", "_cell_guid": "8957babe-bd8f-4e3f-985e-4cf8dc68fccd"}}, {"source": ["def initialize_Parameters(nb_features):\n", "    \"\"\"Init parameters of W and b: 3 layers with:\n", "    l = index of the layer\n", "    W[l] = (n[l], n[l-1])\n", "    b[l] = (n[l], 1)\n", "    dW[l] = (n[l], n[l-1])\n", "    db[l] = (n[l], 1)\n", "    We will try the following:\n", "           O\n", "        O  O\n", "        O  O  O\n", "    X   O  O  O  O Y_hat\n", "        O  O  O\n", "           O  O\n", "           O  O\n", "           \n", "    n[0] = nb_features\n", "    n[1] = 5 5 \n", "    n[2] = 7 8 \n", "    n[3] = 6 6\n", "    n[4] = 1 4\n", "    n[5] = 1\n", "    \"\"\"\n", "    W1 = tf.get_variable(\"W1\", [5, nb_features], initializer = tf.contrib.layers.xavier_initializer())\n", "    b1 = tf.get_variable(\"b1\", [5,1], initializer = tf.zeros_initializer())\n", "    W2 = tf.get_variable(\"W2\", [8,5], initializer = tf.contrib.layers.xavier_initializer())\n", "    b2 = tf.get_variable(\"b2\", [8,1], initializer = tf.zeros_initializer())\n", "    W3 = tf.get_variable(\"W3\", [6,8], initializer = tf.contrib.layers.xavier_initializer())\n", "    b3 = tf.get_variable(\"b3\", [6,1], initializer = tf.zeros_initializer())\n", "    W4 = tf.get_variable(\"W4\", [4,6], initializer = tf.contrib.layers.xavier_initializer())\n", "    b4 = tf.get_variable(\"b4\", [4,1], initializer = tf.zeros_initializer())\n", "    W5 = tf.get_variable(\"W5\", [1,4], initializer = tf.contrib.layers.xavier_initializer())\n", "    b5 = tf.get_variable(\"b5\", [1,1], initializer = tf.zeros_initializer())\n", "    \n", "    parameters = {\"W1\": W1, \"b1\": b1,\n", "                  \"W2\": W2, \"b2\": b2,\n", "                  \"W3\": W3, \"b3\": b3,\n", "                  \"W4\": W4, \"b4\": b4,\n", "                  \"W5\": W5, \"b5\": b5\n", "                 }\n", "    return parameters\n", "\n"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "eb7c80f70f3f366d1f598f02a3323fe53147c70e", "collapsed": true, "_cell_guid": "32041db3-786c-404f-8169-aa63af8fd3ee"}, "execution_count": 13}, {"source": ["# Forward Propagation"], "cell_type": "markdown", "metadata": {"_uuid": "764b049991b0ed241faf51cef720b29713045503", "_cell_guid": "30669f3a-041d-4de0-8318-4706d62c12e0"}}, {"source": ["def forward_propagation(X, parameters):\n", "    \"\"\"\n", "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n", "    \n", "    Arguments:\n", "    X -- input dataset placeholder, of shape (input size, number of examples)\n", "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\", \"W4\", \"b4\"\n", "                  the shapes are given in initialize_parameters\n", "\n", "    Returns:\n", "    Z4 -- the output of the last LINEAR unit\n", "    \"\"\"\n", "    \n", "    # Retrieve the parameters from the dictionary \"parameters\" \n", "    W1 = parameters['W1']\n", "    b1 = parameters['b1']\n", "    W2 = parameters['W2']\n", "    b2 = parameters['b2']\n", "    W3 = parameters['W3']\n", "    b3 = parameters['b3']\n", "    W4 = parameters['W4']\n", "    b4 = parameters['b4']\n", "    W5 = parameters['W5']\n", "    b5 = parameters['b5']\n", "    \n", "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n", "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n", "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n", "    A2 = tf.nn.relu(Z2)                                    # A1 = relu(Z1)\n", "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z2 = np.dot(W2, a1) + b2\n", "    A3 = tf.nn.relu(Z3)                                    # A1 = relu(Z1)\n", "    Z4 = tf.add(tf.matmul(W4, A3), b4) \n", "    A4 = tf.nn.relu(Z4)                                    # A1 = relu(Z1)\n", "    Z5 = tf.add(tf.matmul(W5, A4), b5) # Z2 = np.dot(W2, a1) + b2\n", "\n", "    return Z5"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "f8d13449c1d4653a35c3e397e77b03aa09dc84d2", "collapsed": true, "_cell_guid": "b0c6dfa8-adc9-4c1c-9feb-427f7e9308de"}, "execution_count": 14}, {"source": ["# Creating Placeholders for TF"], "cell_type": "markdown", "metadata": {"_uuid": "e20f7a39f7b982cb56718a1cfcb21dadd2836ef7", "_cell_guid": "78c66718-17f8-4422-8185-3879869a9b34"}}, {"source": ["def create_placeholders(n_x, n_y):\n", "    \"\"\"\n", "    Creates the placeholders for the tensorflow session.\n", "    \n", "    Arguments:\n", "    n_x -- scalar, size of an titanic passenger entry \n", "    n_y -- scalar, number of output, here survived or not \n", "    \n", "    Returns:\n", "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n", "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n", "    \n", "    Tips:\n", "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n", "      In fact, the number of examples during test/train is different.\n", "    \"\"\"\n", "    X = tf.placeholder(dtype=tf.float32, shape=([n_x, None]), name=\"X\")\n", "    Y = tf.placeholder(dtype=tf.float32, shape=([n_y, None]), name=\"Y\")\n", "    \n", "    return X, Y"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "a69d8679cdc3176d42ea9c837af352dde4c6e76c", "collapsed": true, "_cell_guid": "b5382e60-0f0b-4437-a7b4-685ae807dd5d"}, "execution_count": 15}, {"source": ["# Cost Computation"], "cell_type": "markdown", "metadata": {"_uuid": "ee5fa3343f96540d6964929f88841869fd1bf8ab", "_cell_guid": "3b69f504-0de9-4f9f-ab78-dec87b35b341"}}, {"source": ["def compute_cost(Z, Y):\n", "    \"\"\"\n", "    Computes the cost\n", "    \n", "    Arguments:\n", "    Z4 -- output of forward propagation \n", "    Y -- \"true\" labels vector placeholder, same shape as Z4\n", "    \n", "    Returns:\n", "    cost - Tensor of the cost function\n", "    \"\"\"\n", "    \n", "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n", "    logits = tf.transpose(Z)\n", "    labels = tf.transpose(Y)\n", "    #cost = tf.reduce_mean(tf.squared_difference(tf.sigmoid(logits), labels))\n", "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels))\n", "    \n", "    return cost"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "634891bd9e1d4d628d4ebc4df0f91cffe68c74b5", "collapsed": true, "_cell_guid": "b4cfe07d-3574-4f0a-b1c3-4024075f6de9"}, "execution_count": 16}, {"source": ["# Plot Cost"], "cell_type": "markdown", "metadata": {"_uuid": "55a2a9236184e4c9880389069724fdd5b84ed289", "_cell_guid": "1790ff2a-dcdb-46fc-b504-79a49e8d6060"}}, {"source": ["def plot_cost(costs, learning_rate):\n", "    \"\"\" Plots the costs \"\"\"\n", "    plt.plot(np.squeeze(costs))\n", "    plt.ylabel('cost')\n", "    plt.xlabel('iterations (per tens)')\n", "    plt.title(\"Learning rate =\" + str(learning_rate))\n", "    plt.show()"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "e322e0c69543abb00a6248511218c12b8924a2a5", "collapsed": true, "_cell_guid": "f4bc9f97-27f0-45b9-b788-aef57c199afe"}, "execution_count": 17}, {"source": ["# Model\n"], "cell_type": "markdown", "metadata": {"_uuid": "2fcaf030d2e6b952759a455bed30e07c51067b2a", "_cell_guid": "f9ebf934-6d4c-4fc1-82f0-4c5654d8fd9f"}}, {"source": ["def train_predict_model(learning_rate, epoch, X_train, Y_train, X_test):\n", "    \"\"\" Training Model \"\"\"\n", "\n", "    #create placeholders for TF for X and Y\n", "    X, Y = create_placeholders(X_train.shape[0], Y_train.shape[0])\n", "\n", "    #initialize parameters\n", "    parameters = initialize_Parameters(X_train.shape[0])\n", "    #compute Forward Propagation\n", "    Z4 = forward_propagation(X, parameters)\n", "\n", "    #compute Cost: Forward Propagation\n", "    cost = compute_cost(Z4, Y)\n", "\n", "    #Backward Propagation\n", "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n", "    \n", "    # To keep track of the cost\n", "    costs = []\n", "\n", "    #print(\"X_train \"+str(X_train))\n", "    init = tf.global_variables_initializer()\n", "\n", "    with tf.Session() as sess:\n", "        sess.run(init)\n", "        for i in range(1,epoch):        \n", "            #feed with the training sets\n", "            _ , calculated_cost = sess.run([optimizer, cost], feed_dict={X: X_train, Y: Y_train})\n", "            # Print the cost every \n", "            #if i % 100 == 0:\n", "                #print (\"Cost after iteration %i: %f\" % (i, calculated_cost))\n", "            if i % 50 == 0:\n", "                costs.append(calculated_cost)\n", "        \n", "        # plot the cost\n", "        plot_cost(costs, learning_rate)\n", "\n", "        # save the parameters in a variable\n", "        parameters = sess.run(parameters)\n", "        #print (\"Parameters have been trained!\")\n", "\n", "        y_pred_proba = tf.cast(tf.nn.sigmoid(Z4),dtype = tf.float32);\n", "        y_pred_class = tf.cast(tf.greater(y_pred_proba, 0.5),'float')\n", "        accuracy = tf.reduce_mean(tf.cast(tf.equal(y_pred_class, Y ), 'float'))\n", "    \n", "        prediction=tf.argmax(tf.nn.sigmoid(Z4))\n", "        sess.run([prediction],  feed_dict={X: X_train, Y: Y_train})\n", "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n", "        \n", "        prediction_test = sess.run(y_pred_class, feed_dict={X:X_test})\n", "        #print(\"Predicted :\"+str(prediction_Test))\n", "        \n", "        return prediction_test\n", "    "], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "c77247c9cbe7b8c80f71f8ff93efff1293c6d39b", "collapsed": true, "_cell_guid": "1f5320f2-b984-4f9c-b74c-496d58aea392"}, "execution_count": 18}, {"source": ["# Main"], "cell_type": "markdown", "metadata": {"_uuid": "bcdd23adfdafced1e4804814904af7c3c61400ad", "_cell_guid": "6f79f181-7ef5-4104-bc55-d35cb9cdc7ee"}}, {"source": ["#Main\n", "ops.reset_default_graph() \n", "from subprocess import check_output\n", "#clean training Set\n", "X_train, Y_train = prepare_training_data()\n", "#clean test set\n", "X_test = prepare_test_data()\n", "\n", "#train and predict\n", "prediction_test = train_predict_model(learning_rate=0.0001, epoch=40000, X_train= X_train\n", "                                 , Y_train = Y_train, X_test = X_test)\n", "\n", "#transform values to binary\n", "prediction_test = np.where( prediction_test < 1, 0, 1) \n", "# prepare the output submission\n", "data = read_data('test')\n", "submission = pd.DataFrame({\n", "        \"PassengerId\": data[\"PassengerId\"],\n", "        \"Survived\": prediction_test.reshape(X_test.shape[1])\n", "    })\n", "\n", "submission.to_csv('submission.csv', index=False)\n", "#print(str(submission))\n", "print(check_output([\"ls\", \".\"]).decode(\"utf8\"))\n", "\n"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "d491c90dda712267fe16b04a522e03ed8437a12d", "_cell_guid": "36790300-d67b-4a2e-86e9-7a113359d3dc"}, "execution_count": 19}, {"source": [], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "c582584dc1b54991a86a28b113355e0ec3f19065", "collapsed": true, "_cell_guid": "b4cb047b-f68b-467b-a73a-a1aa89c8c6b7"}, "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "version": "3.6.4", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}