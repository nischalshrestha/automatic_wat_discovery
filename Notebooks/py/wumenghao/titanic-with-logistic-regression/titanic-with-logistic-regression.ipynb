{"cells":[{"metadata":{"_uuid":"376a7d436b8510a1b4fa207b5c6058fe19e280bd"},"cell_type":"markdown","source":"# This is a forked programme. Solving tasks using Logistics Regression."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# read files\npath = '../input'\ntest = pd.read_csv(path + '/test.csv')\ntest_shape = test.shape\nprint('test_shape',test_shape)\n\ntrain = pd.read_csv(path + '/train.csv')\ntrain_shape = train.shape\nprint('train_shape',train_shape)\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cc8747a3e9f31b1b8e1471cb96693a120edf9b0"},"cell_type":"code","source":"# segment data by sex and calculate the mean. compare the relationship between Survived and Sex\nimport matplotlib.pyplot as plt\n\nsex_pivot = train.pivot_table(index='Sex',values = 'Survived')\nsex_pivot # from the result shows, females survived in higher proportions than males did.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"845364c36b9da7100b2eea97094a7e6f0bb72985"},"cell_type":"code","source":"# segment data by Pclass.\n\npclass_pivot = train.pivot_table(index='Pclass', values = 'Survived')\n#pclass_pivot\npclass_pivot.plot.bar()\nplt.show() # the survived factor also relates to classes.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cafab13f86b07ac640daf6ec5e327f67d7d25ab2"},"cell_type":"code","source":"# Sex and PClass are categorical features. Now let's check the age column. Age column is a continuous numerical column. \n#One way to look at distribution of values in a continuous numerical set is to use histograms. \n#We can create two histograms to compare visually the those that survived vs those who died across different age ranges:\ntrain['Age'].describe()\n# Age is fractional if passengers are less than one. Some ages info are missing. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d0daf634d8eb487094ded380b6427b30fd4f28d"},"cell_type":"code","source":"train[train['Survived'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6105de91332b7a85fcc7c11242aea1061e6009f4"},"cell_type":"code","source":"survived = train[train['Survived'] == 1]\ndied = train[train['Survived'] == 0]\n\nsurvived['Age'].plot.hist(alpha=0.5, color='red', bins=50)\n#plt.legend()\n#plt.show()\ndied['Age'].plot.hist(alpha=0.5, color='blue', bins=50)\nplt.legend(['Survived','Died'])\nplt.show()\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42497d49f59169dd87bd8f2c68149a8acfff6ab1"},"cell_type":"code","source":"# separate continuous feature into a categorical feature by dividing it into ranges\ndef process_age(df, cut_points, label_names):\n    df['Age'] = df['Age'].fillna(-0.5)  # filling the missing data, Replace all NaN elements.\n    df['Age_categories'] = pd.cut(df['Age'], cut_points, labels=label_names)\n    return df\n\ncut_points = [-1, 0, 5, 12, 18, 35, 60, 100]\nlabel_names = ['Missing', 'Infant', 'Child', 'Teenager', 'Young Adult', 'Adult', 'Senior']\n\ntrain = process_age(train, cut_points, label_names)\ntest = process_age(test, cut_points, label_names)\n\n#train.head(10)\nage_cat_pivot = train.pivot_table(index='Age_categories', values='Survived')\n#train.pivot_table(index='Age_categories', values='Survived')\nage_cat_pivot.plot.bar()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1394fde741f77f904ab3b274e50778628bf23fdb"},"cell_type":"code","source":"# prepare the colums for machine learning. convert our values into numbers\n#train['Pclass'].value_counts()\n\n#column_name = 'Pclass'\n#df = train\n#dummies = pd.get_dummies(df[column_name], prefix=column_name)\n#dummies.head()\n\ndef create_dummies(df,column_name):\n    dummies = pd.get_dummies(df[column_name], prefix=column_name)\n    df = pd.concat([df, dummies], axis=1)\n    return df\n\ntrain = create_dummies(train, 'Pclass')\ntest = create_dummies(test,'Pclass')\n\ntrain = create_dummies(train, 'Sex')\ntest = create_dummies(test,'Sex')\n\ntrain = create_dummies(train, 'Age_categories')\ntest = create_dummies(test,'Age_categories')\n\ntrain.head()\n#train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d09d07b6a9cc02298c03a614f66d7631711f538b"},"cell_type":"code","source":"# Now, the data has been repared. \n# Logistics Regression\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\n# using fit() method to train model.\ncolumns = ['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n       'Age_categories_Missing','Age_categories_Infant',\n       'Age_categories_Child', 'Age_categories_Teenager',\n       'Age_categories_Young Adult', 'Age_categories_Adult',\n       'Age_categories_Senior']\nlr.fit(train[columns], train['Survived'])\n\n#Congratulations, you've trained your first machine learning model! \n#Our next step is to find out how accurate our model is, and to do that, we'll have to make some predictions.\n#train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a1a218cfd83803cc3c53fe66e496031ae33a713"},"cell_type":"code","source":"# find Out accurate.\n# split train dataframe into two \nfrom sklearn.model_selection import train_test_split\n\nholdout = test # for discretion the test, we rename it as holdout \n\ncolumns = ['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n       'Age_categories_Missing','Age_categories_Infant',\n       'Age_categories_Child', 'Age_categories_Teenager',\n       'Age_categories_Young Adult', 'Age_categories_Adult',\n       'Age_categories_Senior']\n\nall_X = train[columns]\nall_y = train['Survived']\n\n# test_size control the proportions of data are split into,\ntrain_X, test_X, train_y, test_y = train_test_split(all_X, all_y, test_size = 0.2, random_state = 0)\n\ntrain_X.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6807824184fea716a8e8c01f5f6c3e689be093ae"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\nlr = LogisticRegression()\nlr.fit(train_X, train_y)\npredictions = lr.predict(test_X)\n\naccuracy = accuracy_score(test_y, predictions)\naccuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d852278bb8ab20af1728625c2b66c958aa0660a7"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nconf_matrix = confusion_matrix(test_y, predictions)\npd.DataFrame(conf_matrix, columns=['Survived','Died'], index=[['Survived','Died']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa144ee6facf42efa231d4b12c8a85544701223a"},"cell_type":"code","source":"# get more accurate error measurement by cross validation\n# this test data is quite small so it probabily overfitting. We can use cross validation to train and test our model\nfrom sklearn.model_selection import cross_val_score\nimport numpy as np\n\nscores = cross_val_score(lr, all_X, all_y, cv=10)\nnp.mean(scores)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a5df38e916d17948f2804986ce339df60bc4a1d"},"cell_type":"code","source":"#holdout.head()\nlr.fit(all_X, all_y)\nholdout_predictions = lr.predict(holdout[columns])\nholdout_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdcc46c14d7f70025dedc531bdb6b659658fd615"},"cell_type":"code","source":"# submission\nholdout_ids = holdout['PassengerId']\nsubmission_df = {'PassengerId': holdout_ids, \n                 'Survived': holdout_predictions}\nsubmission = pd.DataFrame(submission_df)\nsubmission.to_csv('titanic_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}