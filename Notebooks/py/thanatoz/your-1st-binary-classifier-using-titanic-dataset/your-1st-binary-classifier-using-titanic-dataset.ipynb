{"cells":[{"metadata":{"_uuid":"5b994d61b62560a2bdb233d5d2ce9ff07319edbd"},"cell_type":"markdown","source":"# Binary classification using Keras  \n### A systematic approach to your first competition submission for\n### Titanic: Machine Learning from Disaster\n\nThis notebook contains the systematic approach to solving [Titanic: Machine Learning from Disaster](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjXzcGbiJPcAhWCfSsKHTbaBkAQFggoMAA&url=https%3A%2F%2Fwww.kaggle.com%2Fc%2Ftitanic&usg=AOvVaw3u32GjGoKUk5tZpQiCIcHU) contest using Keras framework.\n\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\nWe will apply deep learning to achieve maximum possible accuracy."},{"metadata":{"_uuid":"f9b1b2708cf6ea485f358d0a7353a9df3eb336a0"},"cell_type":"markdown","source":"We will first process the data using *Pandas* framework. Clean it, normalize and then finally we will use it in our network for training and testing."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"We can see that we have 3 files in our contest. We will process the train.csv and test.csv together to maintain a homogenity all through our data"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5ca4b38b303bc177ab70b3b78fc40477508180bf"},"cell_type":"code","source":"# Reading the data\ndf=pd.read_csv('../input/train.csv')\ndft=pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76a217912870a60f411b0fccc9de109ee4e4eb51","scrolled":true},"cell_type":"code","source":"# Let's see what all data is there in our training dataset\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"183cbafad843ed708b8cc46e0b17e1e14661e5e0"},"cell_type":"code","source":"# And the data in our testing dataset\ndft.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47a639eb79cd47440554ff9ca8782f6c43b65b0d"},"cell_type":"markdown","source":"Now, to preprocess our data, we will perform the following options:\n- Fill all the empty cells will 0 or col.mean() (Here we have chosen 0)\n- convert the string to integers such that male=0 and female=1\n- As the 'PassengerId' column is not useful for training, we will discard that column\n- Discard all the useless columns that does not contain arithmetic data and keep the rest\n- Store the reduced dataframe into new dataframe\nand finally visualize the data"},{"metadata":{"trusted":true,"_uuid":"bc3d014bd48a07b9f44df3c0bd4cbac00b85b42e"},"cell_type":"code","source":"df=df.fillna(0)\ndft=dft.fillna(0)\ndf=df.replace(['male','female'],[0,1])\ndft=dft.replace(['male','female'],[0,1])\ndf=df.drop(columns=['PassengerId'])\nout_targets=dft['PassengerId'].values\ncols=[i for i in df.describe()]\ncolt=[i for i in dft.describe()]\ndf_reduced=df[cols]\ndft_red=dft[colt[1:]]\ndf_reduced.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4010f06dc9677cb7e8e6ea1d75ec0a246a3d6c6"},"cell_type":"code","source":"dft_red.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bbd48780e35a3b4cda3a6e5106e9dc34fe16159e"},"cell_type":"markdown","source":"Seperate the training dataset and test dataset, Normaize it before and then proceed "},{"metadata":{"trusted":true,"_uuid":"c43011c695fd5c77df06e1e1089ba2b8ef9e6d0b"},"cell_type":"code","source":"train_labels = df_reduced['Survived'].values\ndf_reduced=df_reduced.drop(columns=['Survived'])\ntrain_data=df_reduced.values\ntest_data=dft_red.values\nprint(train_data.shape, train_labels.shape)\nprint(test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22d354f436bce1f4c040eb8bdee5e3b7e771f413","collapsed":true},"cell_type":"code","source":"mean=train_data.mean(axis=0)\nstd=train_data.std(axis=0)\ntrain_data-=mean\ntrain_data/=std\n\nmeant=test_data.mean(axis=0)\nstdt=test_data.std(axis=0)\ntest_data-=mean\ntest_data/=std","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c9b88676a44597696a994e2e8ca98eb46d5755e1"},"cell_type":"markdown","source":"## Its finally time to create our model\n\n### Creating the network\n\nAs this is supposed to classify the review into positives and negetives. There is need to only output a single value. Such type of classification is called as **Binary Classification**.\n\nArchitecture of a simple binary classifier could be as shown below:\n\n![network](https://cdn-images-1.medium.com/max/1600/0*hzIQ5Fs-g8iBpVWq.jpg \"Network Architecture\")\n\nWe would be using *keras Sequential* model for this purspose which could be imported using `from keras import models` and the layers in the model could be defined  by calling layers `from keras import layers`"},{"metadata":{"trusted":true,"_uuid":"e6a9986dfbc7d9e0d9e4b303b9b0ea12269ef5bf","collapsed":true},"cell_type":"code","source":"from keras import models, layers, optimizers","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94b26135d4e47affc40a95964ddcf0a1f4422b0b"},"cell_type":"markdown","source":"##### Split into training and testing data and spliting the validation set\nSplit complete data into training and testing data using a sklearn function `train_test_data`\nto maintain homogenous distribution, we will also shuffle our dataset\nFurther we will take to first 200 points and create a validation dataset\nFor this, we follow the following model\n![Image](http://www.cs.nthu.edu.tw/~shwu/courses/ml/labs/08_CV_Ensembling/fig-holdout.png \"test,train,validation split\")\n\nor in a simpler way\n![dataset split](https://cdn-images-1.medium.com/max/889/1*Nv2NNALuokZEcV6hYEHdGA.png)"},{"metadata":{"trusted":true,"_uuid":"719a615556fe030f5663b9621529bb80478db868","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(train_data, train_labels, test_size=0.20, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"9ca0628dec57ffc3e80fe7a1bb8e647f995dde7f"},"cell_type":"code","source":"print(x_train.shape, x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"812d525018eefd3eef926f2a06f48a319fba02f6"},"cell_type":"code","source":"index=200\nx_val=x_train[:index]\ny_val=y_train[:index]\npartial_x_train = x_train[index:]\npartial_y_train=y_train[index:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a5cf05a33507f1417c0f624f75db7aacf890de9"},"cell_type":"markdown","source":"### Importing all the imports for performance visualization"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7d0d9d1b1a11e52bf214433eaa9bd32c7e99f8f7"},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport numpy as np\n%matplotlib inline\nimport seaborn as sns\nsns.set_style('dark')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed29f85af231b13e61fc3ca39de2a23cbca4f8dc"},"cell_type":"markdown","source":"### The network architecture\n\nThe model contains two fully connected hidden layers each containing 16 units.\n```\nmodel.add(layers.Dense(10, activation='relu', input_shape=(6,)))\nmodel.add(layers.Dense(10, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n```\nfor the first two layers, we have used the *ReLU (Rectified Linear Unit)* and for the last output layer, we will be using the *Sigmoid* activation\n\n![activation function](http://numpydl.readthedocs.io/en/latest/_images/init_0.svg \"Sigmoid and ReLU\")\n\nAs we are working on a smaller dataset with somewhat larger network, our model could overfit and its accuracy could be affected.\nIn order to overcome this, we will introduce a regulaization technique called as Dropout here.\nDropout could be visualized as follows\n![Dropout](https://www.learnopencv.com/wp-content/uploads/2018/06/dropoutAnimation.gif)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0524b71ef9a759f431e2b699ee9e642c431a010c"},"cell_type":"code","source":"model=models.Sequential()\nmodel.add(layers.Dense(10, activation='relu', input_shape=(6,)))\nmodel.add(layers.Dropout(0.3))\nmodel.add(layers.Dense(10, activation='relu'))\nmodel.add(layers.Dropout(0.6))\nmodel.add(layers.Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6e5164f77529a4c28fe41c6cc5a3914470c3312e"},"cell_type":"markdown","source":"Finally after deciding the right number of bones to pick, we are ready with our structure. The only need now is to put everything together and create a create a final body of the model.\nA few things are also required beforehand compiling the model. These are:\n+ [Optimizer](http://www.deeplearningbook.org/contents/optimization.html)\n+ [Loss function](https://www.quora.com/What-does-loss-mean-in-deep-neural-networks)\n+ [Metrics](https://machinelearningmastery.com/custom-metrics-deep-learning-keras-python/)\n\nFor the choice of optimizer, we have chosen \n- [*RMSprop*](https://medium.com/100-days-of-algorithms/day-69-rmsprop-7a88d475003b) as our optimizer function\n- [*Binary_crossentropy*] as our loss function\n\nWe will need to set all our hyperparameters in our optimizer before using it in our network"},{"metadata":{"trusted":true,"_uuid":"4efaaa1d90938745bb21d38fd06eb5fb0e9ee2d0","collapsed":true},"cell_type":"code","source":"sgd = optimizers.SGD(lr=0.001, decay=1e-6 ,momentum=0.9)\n# adm = optimizers.Adam(lr=0.1, decay=1e-6)\nmodel.compile(optimizer=sgd,\n             loss='binary_crossentropy',\n             metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"948244e2536361b9962f18b4d9a63313978559bb"},"cell_type":"markdown","source":"After compiling our model, we will need to fit our data into the model\nThe fitting of data can be done directly but it is always better to create a validation set and feed the model with the remaining data so that easy model evaluvation could be done.\nWe will follow both the approaches and see the difference in the loss matrics graph."},{"metadata":{"_uuid":"fc76d296e966e07b1ca62cd0eb846e9b8fa49740"},"cell_type":"markdown","source":"#### Data fitting into the model"},{"metadata":{"trusted":true,"_uuid":"8a51cbbe4fe31366e85ee31c820da70ca7c262a7","collapsed":true},"cell_type":"code","source":"history = model.fit(partial_x_train, partial_y_train,\n                   epochs=500,\n                   batch_size=32,\n                   validation_data=(x_val,y_val),\n                   verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"354b4baf053ab355b668f4fb72ca7248f33219fc"},"cell_type":"markdown","source":"### Visualizing the model performance\n\nmetrics visualizations could be carried out using matplotlib pyplot"},{"metadata":{"trusted":true,"_uuid":"21e959ceeff1d397ab65bd0f3474dcb6803c54d6"},"cell_type":"code","source":"hist = history.history\nacc=hist['acc']\na=200\nb=len(acc)\nval_loss=hist['val_loss'][a:b]\nloss=hist['loss'][a:b]\nval_acc=hist['val_acc']\nepc = range(1,(b-a)+1)\n\nplt.figure(figsize=(15,4))\nplt.clf()\nplt.subplot(1,2,1)\nplt.plot(epc, loss, 'r', label='Training_loss')\nplt.plot(epc, val_loss, 'b', label='Validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nepc=range(1,len(acc)+1)\nplt.subplot(1,2,2)\nplt.plot(epc, acc, 'r', label='Training_acc')\nplt.plot(epc, val_acc, 'b', label='Validation acc')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('accuracy')\nplt.legend()\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d8a2cda1b6f067d1ddd028a34c125468b21b0e9"},"cell_type":"markdown","source":"We can evaluvate our model now on the test data we split in our previous steps"},{"metadata":{"trusted":true,"_uuid":"941a2f0528baeb5883681fc5ecfe1f865efd1466"},"cell_type":"code","source":"model=models.Sequential()\nmodel.add(layers.Dense(10, activation='relu', input_shape=(6,)))\nmodel.add(layers.Dropout(0.3))\nmodel.add(layers.Dense(10, activation='relu'))\nmodel.add(layers.Dropout(0.6))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nsgd = optimizers.SGD(lr=0.001, decay=1e-6 ,momentum=0.9)\n# adm = optimizers.Adam(lr=0.1, decay=1e-6)\nmodel.compile(optimizer=sgd,\n             loss='binary_crossentropy',\n             metrics=['accuracy'])\n\nmodel.fit(train_data, train_labels,\n                   epochs=500,\n                   batch_size=32,\n                   verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b2a37b42638e93191933861d17d9ade32d5369b"},"cell_type":"code","source":"results = model.evaluate(x_test, y_test)\nresults","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"beb23c94ca1f28213985a394c708f38fecf481c6","collapsed":true},"cell_type":"code","source":"predictions=model.predict(test_data)\n# predictions\npred=[1 if predictions[i]>0.25 else 0 for i in range(len(test_data))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca886f5e8d7bb140c6f2b2acbf54cf77a3716f35"},"cell_type":"code","source":"pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d9682097775745df95eb2e9b88699cd0fa94ee8f"},"cell_type":"code","source":"res=pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c52fcdc311606f674806c061481bd30651358e4"},"cell_type":"code","source":"pd.read_csv('../input/gender_submission.csv').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9934c498283b053488c95f832dc1518fcfcb284d"},"cell_type":"code","source":"res['PassengerId']=out_targets\nres['Survived']=pred\nres.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"273872a14daf24bfc3858c1e926b3d6a5a32ce7c"},"cell_type":"code","source":"res.to_csv('Submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"199548cc878b40c7fa7a88c2e552e0b434e8fac8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}