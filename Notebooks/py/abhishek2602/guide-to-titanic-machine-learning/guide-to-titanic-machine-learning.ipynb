{"cells":[{"metadata":{"_uuid":"605047e667a69920624aedf31eb54a70e60737c2"},"cell_type":"markdown","source":"# Importing Packages and Collecting Data"},{"metadata":{"trusted":false,"_uuid":"7b08750f1dd404acbd541d14f08b6eb128ea0b73"},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore', category = DeprecationWarning)\nwarnings.filterwarnings('ignore', category = FutureWarning)\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as mn\nfrom scipy import stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bd6075ae54fb7a780c831ff190586c175c80d77e"},"cell_type":"code","source":"plt.style.use('bmh')\nsns.set_style({'axes.grid':False})\n\nfrom IPython.display import Markdown\ndef bold(string):\n    display(Markdown(string))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7dfa36a6373b11a1a0e032312c3814b07f2e8e7c"},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\nbold('**Preview of Train Data:**')\ndisplay(train.head(2))\n\ntest = pd.read_csv('../input/test.csv')\nbold('**Preview of Test Data:**')\ndisplay(test.head(2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f7faa5f119f1dec4c9150e2bd906e216fb5379a"},"cell_type":"markdown","source":"# Variable Description and Identification"},{"metadata":{"_uuid":"01b0f7ecbed555a55c14f0e32399c7b038683a46"},"cell_type":"markdown","source":"## Variable Description"},{"metadata":{"trusted":false,"_uuid":"b5e2fa18257176c5d402b03b22c9dab3656ce6af"},"cell_type":"code","source":"merged = pd.concat([train, test], sort = False)\nbold('**Preview of Merged Data:**')\ndisplay(merged.head(2))\n\nbold('**Shape of the Merged Data:**')\ndisplay(merged.shape)\n\nbold('**Name of the Variables:**')\ndisplay(merged.columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56ebf2a741e669739e314d8bed712a1f20b22288"},"cell_type":"markdown","source":"## Categorical and Numerical Variables"},{"metadata":{"_uuid":"2bb287fda2390b38439731fb0d2ea0dbf4d26182"},"cell_type":"markdown","source":"**Categorical Variable:** Survived, Sex, Pclass, Embarked, Cabin, Name, Ticket, SibSp, and Parch.\n\n**Numerical Variable:** Fare, Age, and PassengerId."},{"metadata":{"_uuid":"c480e89bb996ec9947b0c96fb65a14f483a5d4bb"},"cell_type":"markdown","source":"## Variable Data Types"},{"metadata":{"trusted":false,"_uuid":"b66478f05cbb016bd56dcfa5db9ad91b90acc752"},"cell_type":"code","source":"bold('**Data Types of Our Variables:**')\ndisplay(merged.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5853e2015bce45a51328688e18306ac1953c486"},"cell_type":"markdown","source":"# Univariate Analysis"},{"metadata":{"_uuid":"0c6a40c7a85aadf5ea8db0980959d72915d4ca26"},"cell_type":"markdown","source":"## Categorical Variables"},{"metadata":{"trusted":false,"_uuid":"a85a2fc849b1445aeac4139cf0d8a51111b1ee0d"},"cell_type":"code","source":"# 1. Function for displaying bar labels in absolute scale.\ndef abs_bar_labels():\n    font_size = 15\n    plt.ylabel('Absolute Frequency', fontsize = font_size)\n    plt.xticks(rotation = 0, fontsize = font_size)\n    plt.yticks([])\n    \n    #Set individual bar labels in absolute number\n    for x in ax.patches:\n        ax.annotate(x.get_height(), (x.get_x() + x.get_width()/2., x.get_height()), ha = 'center', va = 'center', xytext = (0, 7), textcoords = 'offset points', fontsize = font_size, color = 'black')\n        \n# 2. Function for displaying bar labels in relative scale.\ndef pct_bar_labels():\n    font_size = 15\n    plt.ylabel('Relative Frequency (%)', fontsize = font_size)\n    plt.xticks(rotation = 0, fontsize = font_size)\n    plt.yticks([])\n    \n    #Set individual bar labels in proportional scale\n    for x in ax1.patches:\n        ax.annotate(str(x.get_height()) + '%', (x.get_x() + x.get_width()/2., x.get_height()), ha = 'center', va = 'center', xytext = (0, 7), textcoords = 'offset points', fontsize = font_size, color = 'black')\n        \n# 3. Fuction to create a dataframe of absolute and relative frequency of each variable. And plot absolute and relative frequency.\ndef absolute_and_relative_freq(variable):\n    global  ax, ax1 \n    # Dataframe of absolute and relative frequency\n    absolute_frequency = variable.value_counts()\n    relative_frequency = round(variable.value_counts(normalize = True)*100, 2)\n    # Was multiplied by 100 and rounded to 2 decimal points for percentage.\n    df = pd.DataFrame({'Absolute Frequency':absolute_frequency, 'Relative Frequency(%)':relative_frequency})\n    print('Absolute & Relative Frequency of',variable.name,':')\n    display(df)\n    \n    # This portion plots absolute frequency with bar labeled.\n    fig_size = (18,5)\n    font_size = 15\n    title_size = 18\n    ax =  absolute_frequency.plot.bar(title = 'Absolute Frequency of %s' %variable.name, figsize = fig_size)\n    ax.title.set_size(title_size)\n    abs_bar_labels()  # Displays bar labels in abs scale.\n    plt.show()\n    \n    # This portion plots relative frequency with bar labeled.\n    ax1 = relative_frequency.plot.bar(title = 'Relative Frequency of %s' %variable.name, figsize = fig_size)\n    ax1.title.set_size(title_size)\n    pct_bar_labels() # Displays bar labels in relative scale.\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f1feb533edd3b779807fe2da3932995a634c8a52"},"cell_type":"markdown","source":"### Survived"},{"metadata":{"trusted":false,"_uuid":"f988cdad7ad50b54a3bac55e72762d7cba56c2e3"},"cell_type":"code","source":"absolute_and_relative_freq(merged.Survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c1caeea7b2c7d2e6e38dbe5ed9cec01f7bca129"},"cell_type":"markdown","source":"### Sex"},{"metadata":{"trusted":false,"_uuid":"8001cf78875cfc95b161ad8973fda9a35e972423"},"cell_type":"code","source":"absolute_and_relative_freq(merged.Sex)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3dbf77020804118bd143f03dcbbd99fcb14ac3a"},"cell_type":"markdown","source":"### Pclass"},{"metadata":{"trusted":false,"_uuid":"b4d02e4f53f9334cf8aac0e70516e8d913b606f7"},"cell_type":"code","source":"absolute_and_relative_freq(merged.Pclass)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"346771128b664d31d4357b1eb3ad0162ad74534a"},"cell_type":"markdown","source":"### Embarked"},{"metadata":{"trusted":false,"_uuid":"a0f6533622e90ad8763d9a8a3fce3e85a3d349e9"},"cell_type":"code","source":"absolute_and_relative_freq(merged.Embarked)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64e1d09245b220d985a0eaff8e6b401c9b7595b7"},"cell_type":"markdown","source":"### Cabin"},{"metadata":{"trusted":false,"_uuid":"9f09c5a1fcac84005d75e4373235b33d0d822a77"},"cell_type":"code","source":"abs_freq_cabin = merged.Cabin.value_counts(dropna = False)\nbold('**Categories of Cabin:**')\ndisplay(abs_freq_cabin.head())\n\nbold('**Total Categories in Cabin:**')\ndisplay(abs_freq_cabin.count())\n\nbold('**Preview of Cabin:**')\ndisplay(merged.Cabin.head(7))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2ee1758262ebe173e17f85bb561ae857c6677cb"},"cell_type":"markdown","source":"### Name"},{"metadata":{"trusted":false,"_uuid":"266955e6d15e5d0c1db7e3d4de6384787ed6cac4"},"cell_type":"code","source":"bold('**Total Categories in Name:**')\ndisplay(merged.Name.value_counts().count())\n\nbold('**Preview Name:**')\ndisplay(merged.Name.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6144242a648b27f68195d723d520b9347b02a05"},"cell_type":"markdown","source":"### Ticket"},{"metadata":{"trusted":false,"_uuid":"c8433d7ac7036897f1cf8cd7db138870adb86e91"},"cell_type":"code","source":"bold('**Total Groups in Ticket:**')\ndisplay(merged.Ticket.value_counts().count())\n\nbold('**Preview of Ticket:**')\ndisplay(merged.Ticket.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4247ef9409575c02cd19ac0f01ad9f6b6a8fbd83"},"cell_type":"markdown","source":"### SibSp"},{"metadata":{"trusted":false,"_uuid":"496a85af0c43edb66c248affb99aeaebd9b8116b"},"cell_type":"code","source":"absolute_and_relative_freq(merged.SibSp)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61dabbb52db1f256241dc4ad7ebf880ec765f6e9"},"cell_type":"markdown","source":"### Parch"},{"metadata":{"trusted":false,"_uuid":"9140f39e80bacb0d305970c9e02a08ad734bc942"},"cell_type":"code","source":"absolute_and_relative_freq(merged.Parch)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"846069149cc814f7c28684dbbc9eebc9e13fb7bb"},"cell_type":"markdown","source":"## Numberical variables"},{"metadata":{"trusted":false,"_uuid":"8e59c60deda33d7a05f86977b360e2a7ec976bd2"},"cell_type":"code","source":"#1. Plot Histogram\ndef histogram(variable):\n    global ax\n    font_size = 15\n    fig_size = (18, 7)\n    title_size = 18\n    ax = variable.plot.hist(figsize = fig_size, color = 'salmon')\n    plt.xlabel('%s' %variable.name, fontsize = font_size)\n    plt.xticks(fontsize = font_size)\n    plt.title('%s' %variable.name + ' Distribution with Histogram', fontsize = title_size)\n    abs_bar_labels()\n    plt.show()\n    \n#2.Plot density plot .\ndef density_plot(variable):\n    fig_size = (18, 7)\n    font_size = 15\n    title_size = 18\n    plt.figure(figsize = fig_size)\n    variable.plot.hist(density = True, color = 'coral')\n    variable.plot.kde(style = 'k--')\n    plt.xlabel('%s'%variable.name, fontsize = font_size)\n    plt.ylabel('Density', fontsize = font_size)\n    plt.xticks(fontsize = font_size)\n    plt.yticks(fontsize = font_size)\n    plt.title('%s ' %variable.name + 'Distribution with Density Plot & Histogram', fontsize = title_size)\n    plt.show()\n    \n#3.Calculate descriptive statistics.\ndef summary_stats(variable):\n    stats = variable.describe()\n    skew = pd.Series(variable.skew(), index = ['skewness'])\n    df_stats = pd.DataFrame(pd.concat([skew, stats], sort = False), columns = [variable.name])\n    df_stats.index.name = 'Stats'\n    display(df_stats)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca4e02fb6068857687b78a8a272fe17cddc3c79d"},"cell_type":"markdown","source":"### Fare"},{"metadata":{"trusted":false,"_uuid":"8f065109ed8f24aec1c31bb4da65b7d7ad1dde44"},"cell_type":"code","source":"histogram(merged.Fare)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9479150fbe66f9d808090c49d9c4b868af1784e1"},"cell_type":"code","source":"density_plot(merged.Fare)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5f0b6d935a990716daaede3b65ea2d8f2dfa335e"},"cell_type":"code","source":"bold('**Summary Stats of Fare:**')\nsummary_stats(merged.Fare)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2224bccfbfabb3572105d730e1add0ec4db36eb"},"cell_type":"markdown","source":"### Age"},{"metadata":{"trusted":false,"_uuid":"ab77fd76222d575909d5429aa0c715385d4db010"},"cell_type":"code","source":"histogram(merged.Age)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"69c5f312b9cbee0da11391b676e8f4678bf7a56e"},"cell_type":"code","source":"density_plot(merged.Age)\nbold('**Summary of Age:**')\nsummary_stats(merged.Age)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0218fab3a55ad59bdc5693e5690288470063b7c5"},"cell_type":"markdown","source":"### PassengerId"},{"metadata":{"trusted":false,"_uuid":"8c97482e1ad03c8f2b6130ef11421f82f7e372a8"},"cell_type":"code","source":"display(merged.PassengerId.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"611df561e19ff74bb4481d9af53cdaf7309cb900"},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"_uuid":"ed82e7611bafe09e4a2122bfeaaba148115ab5ce"},"cell_type":"markdown","source":"## Process Cabin"},{"metadata":{"trusted":false,"_uuid":"f75d8f364f9cf110aad9f46e6cbcbd7266460c16"},"cell_type":"code","source":"bold('**Preview of Cabin:**')\ndisplay(merged.Cabin.head())\n\nbold('**Missing Values in Cabin:**')\ndisplay(merged.Cabin.isnull().sum())\n\nbold('**Total Categories in Cabin before Processing:**')\ndisplay(merged.Cabin.value_counts(dropna = False).count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"caa96b3cbda9a3998212591dd2493f3ae9e8913c"},"cell_type":"code","source":"merged.Cabin.fillna(value = 'X', inplace = True)\n\nmerged.Cabin = merged.Cabin.apply(lambda x : x[0])\nbold('**Cabin Categories after Processing:**')\ndisplay(merged.Cabin.value_counts())\n\nabsolute_and_relative_freq(merged.Cabin)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"27bd984c142eea299a4f9bac81a31fa4cfa77d66"},"cell_type":"markdown","source":"## Process Name"},{"metadata":{"trusted":false,"_uuid":"10ed1fd5070ff2e28e256e1ff219f4e8292171f5"},"cell_type":"code","source":"display(merged.Name.head(8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"49acafade724995fbf829361b39fb3fa290ccc2b"},"cell_type":"code","source":"merged['Title'] = merged.Name.str.extract('([A-Za-z]+)\\.')\n\ndisplay(merged.Title.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"271ce2cf8b1d003b5bd1ecddfb2603d0a2543e26"},"cell_type":"code","source":"merged.Title.replace(to_replace = ['Dr', 'Rev', 'Col', 'Major', 'Capt'], value = 'Officer', inplace = True)\n\nmerged.Title.replace(to_replace = ['Dona', 'Jonkheer', 'Countess', 'Sir', 'Lady', 'Don'], value = 'Aristocrat', inplace = True)\n\nmerged.Title.replace({'Mlle':'Miss', 'Ms':'Miss', 'Mme':'Mrs'}, inplace = True)\n\nabsolute_and_relative_freq(merged.Title)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b6447d5df8bf51638b9a271a6084582c54b87f6"},"cell_type":"markdown","source":"## Process SibSp & Parch"},{"metadata":{"trusted":false,"_uuid":"eaaa44b6e761183f505d82964d7d381f0cea57dc"},"cell_type":"code","source":"#Merge SibSp and Parch to create a variable Family_Size.\nmerged['Family_size'] = merged.SibSp + merged.Parch + 1\ndisplay(merged.Family_size.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"82c53f1a1fa2e00e7f39f0181a30bbb3b0662650"},"cell_type":"code","source":"#Create buckets of single, small, medium, and large and then put respective values into them.\nmerged.Family_size.replace(to_replace = [1], value = 'single', inplace = True)\nmerged.Family_size.replace(to_replace = [2,3], value = 'small', inplace = True)\nmerged.Family_size.replace(to_replace = [4,5], value = 'medium', inplace = True)\nmerged.Family_size.replace(to_replace = [6,7,8,11], value = 'large', inplace = True)\n\nabsolute_and_relative_freq(merged.Family_size)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a3ac81af5aed95acac4757587a1a2c3e26e0ac54"},"cell_type":"markdown","source":"## Process Ticket"},{"metadata":{"trusted":false,"_uuid":"b93a5411662e7c8643c796c1728b54febcfea8cf"},"cell_type":"code","source":"display(merged.Ticket.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3d31973d5559ff01cd40c88e8ad02afea1f79ada"},"cell_type":"code","source":"ticket = []\nfor x in list(merged.Ticket):\n    if x.isdigit():\n        ticket.append('N')\n    else:\n        ticket.append(x.replace('.','').replace('/','').strip().split(' ')[0])\n        \nmerged.Ticket = ticket\n\nbold('**Categories of Tickets:**')\ndisplay(merged.Ticket.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5ce0e589d5c0aa00b4560e92c045d60df18eed12"},"cell_type":"code","source":"merged.Ticket = merged.Ticket.apply(lambda x : x[0])\nbold('**Ticket after Processing:**')\ndisplay(merged.Ticket.value_counts())\n\nabsolute_and_relative_freq(merged.Ticket)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"428ba3f1077800b91ed29c4f7cf04f5f45d23a49"},"cell_type":"markdown","source":"# Outliners Detection"},{"metadata":{"trusted":false,"_uuid":"2e53e7eb573f8897a220a2e7fadc3a72752aa11c"},"cell_type":"code","source":"def outliers(variable):\n    global filtered\n    # Calculate 1st, 3rd quartiles and iqr.\n    q1, q3 = variable.quantile(0.25), variable.quantile(0.75)\n    iqr = q3 - q1\n    \n    # Calculate lower fence and upper fence for outliers\n    l_fence, u_fence = q1 - 1.5*iqr , q3 + 1.5*iqr   # Any values less than l_fence and greater than u_fence are outliers.\n    \n    # Observations that are outliers\n    outliers = variable[(variable<l_fence) | (variable>u_fence)]\n    print('Total Outliers of', variable.name,':', outliers.count())\n    \n    # Drop obsevations that are outliers\n    filtered = variable.drop(outliers.index, axis = 0)\n\n    # Create subplots\n    out_variables = [variable, filtered]\n    out_titles = [' Distribution with Outliers', ' Distribution Without Outliers']\n    title_size = 25\n    font_size = 18\n    plt.figure(figsize = (25, 15))\n    for ax, outlier, title in zip(range(1,3), out_variables, out_titles):\n        plt.subplot(2, 1, ax)\n        sns.boxplot(outlier).set_title('%s' %outlier.name + title, fontsize = title_size)\n        plt.xticks(fontsize = font_size)\n        plt.xlabel('%s' %outlier.name, fontsize = font_size)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ab1d97c8ab594b8e40c66a4e2d9cad1c555b218"},"cell_type":"markdown","source":"## Outliners Detection for Age"},{"metadata":{"trusted":false,"_uuid":"92731382013404cd766e09080e712e222eb5e760"},"cell_type":"code","source":"outliers(merged.Age)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dad01749a08a3da198cbe8bfb5388011596e86e1"},"cell_type":"markdown","source":"## Outliers Detection for Fare"},{"metadata":{"trusted":false,"_uuid":"12ee8e17f0e3b3d807f761c5bd657854f08f8095"},"cell_type":"code","source":"outliers(merged.Fare)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5047203baa9453d288b0ab1f9e3a2ef312b5661"},"cell_type":"markdown","source":"# Imputing Missing Variables"},{"metadata":{"trusted":false,"_uuid":"ff1db8e24ea06a05e8cf4ffd7f4a9ab3b52c1edf"},"cell_type":"code","source":"mn.matrix(merged)\nbold('**Values Missing in Each Variable:**')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3aa93ca272cd826abab28c0b615de7b9b8af0627"},"cell_type":"code","source":"bold('**Missing Values of Each Variables:**')\ndisplay(merged.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"68ea2d1aa54e4fbc5cfd2849df0416290ea862a5"},"cell_type":"markdown","source":"## Imput Embarked & Fare"},{"metadata":{"trusted":false,"_uuid":"3afd4b57dd3f1e779c742321bcc915a0f2206e0c"},"cell_type":"code","source":"#Impute missing values of Embarked. Embarked is a categorical variable where S is the most frequent.\nmerged.Embarked.fillna(value = 'S', inplace = True)\n\n#Impute missing values of Fare. Fare is a numerical variable with outliers. Hence it will be imputed by median.\nmerged.Fare.fillna(value = merged.Fare.median(), inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5b83f9145b66c94610874c0ab2f0340279ef791"},"cell_type":"markdown","source":"## Impute Age"},{"metadata":{"trusted":false,"_uuid":"ae99f1477384796c612808469d4d98b0c4ddc3e5"},"cell_type":"code","source":"correlation = merged.loc[:, ['Sex', 'Pclass', 'Embarked', 'Title', 'Family_size', 'Parch', 'SibSp', 'Cabin', 'Ticket']]\nfig, axes = plt.subplots(nrows = 3, ncols = 3, figsize = (25,25))\nfor ax, column in zip(axes.flatten(), correlation.columns):\n    sns.boxplot(x = correlation[column], y = merged.Age, ax = ax)\n    ax.set_title(column, fontsize = 23)\n    ax.tick_params(axis = 'both', which = 'major', labelsize = 20)\n    ax.tick_params(axis = 'both', which = 'minor', labelsize = 20)\n    ax.set_ylabel('Age', fontsize = 20)\n    ax.set_xlabel('')\nfig.suptitle('Variables Associated with Age', fontsize = 30)\nfig.tight_layout(rect = [0, 0.03, 1, 0.95])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"33d9e12c7d9977b6ad8a81cd9f338a117c11b912"},"cell_type":"code","source":"#Let's plot correlation heatmap to see which variable is highly correlated with Age and if our boxplot interpretation holds true. We need to convert categorical variable into numerical to plot correlation heatmap. So convert categorical variables into numerical.\nfrom sklearn.preprocessing import LabelEncoder\ncorrelation = correlation.agg(LabelEncoder().fit_transform)\ncorrelation['Age'] = merged.Age\ncorrelation = correlation.set_index('Age').reset_index()\n\nplt.figure(figsize = (20,7))\nsns.heatmap(correlation.corr(), cmap = 'BrBG', annot = True)\nplt.title('Variables Correlated with Age', fontsize = 18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d3421472c65ed56b6d8997b2e985b629b6dd0f34"},"cell_type":"code","source":"#Impute Age with median of respective columns (i.e., Title and Pclass)\nmerged.Age = merged.groupby(['Title', 'Pclass'])['Age'].transform(lambda x: x.fillna(x.median()))\n\n#So by now we should have variables with no missing values.\nbold('**Missing Values after Imputation:**')\ndisplay(merged.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9005e182658b6e0c64ca111c6a195ae155e9bbf"},"cell_type":"markdown","source":"# Bivariate Analysis"},{"metadata":{"_uuid":"bedd56ee962519643d36d57197d8f78a8c40b47a"},"cell_type":"markdown","source":"## Numerical & Categorical Variables"},{"metadata":{"trusted":false,"_uuid":"d3f4cf29b3c2b75f122bbabb8efab38b8d4b88f7"},"cell_type":"code","source":"#Let's split the train and test data for bivariate analysis since test data has no Survived values. We need our target variable without missing values to conduct the association test with predictor variables\ndf_train = merged.iloc[:891, :]\ndf_test = merged.iloc[891:, :]\ndf_test = df_test.drop(columns = ['Survived'], axis = 1)\n\n#1.Create a function that creates boxplot between categorical and numerical variables and calculates biserial correlation.\ndef boxplot_and_correlation(cat,num):\n    '''cat = categorical variable, and num = numerical variable.'''\n    plt.figure(figsize = (18,7))\n    title_size = 18\n    font_size = 15\n    ax = sns.boxplot(x = cat, y = num)\n    \n    # Select boxes to change the color\n    box = ax.artists[0]\n    box1 = ax.artists[1]\n    \n    # Change the appearance of that box\n    box.set_facecolor('red')\n    box1.set_facecolor('green')\n    plt.title('Association between Survived & %s' %num.name, fontsize = title_size)\n    plt.xlabel('%s' %cat.name, fontsize = font_size)\n    plt.ylabel('%s' %num.name, fontsize = font_size)\n    plt.xticks(fontsize = font_size)\n    plt.yticks(fontsize = font_size)\n    plt.show()\n    print('Correlation between', num.name, 'and', cat.name,':', stats.pointbiserialr(num, cat))\n\n#2.Create another function to calculate mean when grouped by categorical variable. And also plot the grouped mean.\ndef nume_grouped_by_cat(num, cat):\n    global ax\n    font_size = 15\n    title_size = 18\n    grouped_by_cat = num.groupby(cat).mean().sort_values( ascending = False)\n    grouped_by_cat.rename ({1:'survived', 0:'died'}, axis = 'rows', inplace = True) # Renaming index\n    grouped_by_cat = round(grouped_by_cat, 2)\n    ax = grouped_by_cat.plot.bar(figsize = (18,5)) \n    abs_bar_labels()\n    plt.title('Mean %s ' %num.name + ' of Survivors vs Victims', fontsize = title_size)\n    plt.ylabel('Mean ' + '%s' %num.name, fontsize = font_size)\n    plt.xlabel('%s' %cat.name, fontsize = font_size)\n    plt.xticks(fontsize = font_size)\n    plt.yticks(fontsize = font_size)\n    plt.show()\n    \n#3.This function plots histogram of numerical variable for every class of categorical variable.\ndef num_hist_by_cat(num,cat):\n    font_size = 15\n    title_size = 18\n    plt.figure(figsize = (18,7))\n    num[cat == 1].hist(color = ['g'], label = 'Survived', grid = False)\n    num[cat == 0].hist(color = ['r'], label = 'Died', grid = False)\n    plt.yticks([])\n    plt.xticks(fontsize = font_size)\n    plt.xlabel('%s' %num.name, fontsize = font_size)\n    plt.title('%s ' %num.name + ' Distribution of Survivors vs Victims', fontsize = title_size)\n    plt.legend()\n    plt.show()\n    \n#4.Create a function to calculate anova between numerical and categorical variable.\ndef anova(num, cat):\n    from scipy import stats\n    grp_num_by_cat_1 = num[cat == 1] # Group our numerical variable by categorical variable(1). Group Fair by survivors\n    grp_num_by_cat_0 = num[cat == 0] # Group our numerical variable by categorical variable(0). Group Fare by victims\n    f_val, p_val = stats.f_oneway(grp_num_by_cat_1, grp_num_by_cat_0) # Calculate f statistics and p value\n    print('Anova Result between ' + num.name, ' & '+ cat.name, ':' , f_val, p_val)  \n    \n#5.Create another function that calculates Tukey's test between our nemurical and categorical variable.\ndef tukey_test(num, cat):\n    from statsmodels.stats.multicomp import pairwise_tukeyhsd\n    tukey = pairwise_tukeyhsd(endog = num,   # Numerical data\n                             groups = cat,   # Categorical data\n                             alpha = 0.05)   # Significance level\n    \n    summary = tukey.summary()   # See test summary\n    print(\"Tukey's Test Result between \" + num.name, ' & '+ cat.name, ':' )  \n    display(summary)   ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a9ff33053edd67231331fee8baa37ae9fc90abe"},"cell_type":"markdown","source":"### Fare & Survived"},{"metadata":{"trusted":false,"_uuid":"e4f62363f2edae8923f53125b1f2b5994279960f"},"cell_type":"code","source":"boxplot_and_correlation(df_train.Survived, df_train.Fare)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"45bcd11fa4d4fa124a05322d29193c4a07097b5f"},"cell_type":"code","source":"nume_grouped_by_cat(df_train.Fare, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e0f237c7e0820fc0d27c7506ba9b4ab035bb67fc"},"cell_type":"code","source":"num_hist_by_cat(df_train.Fare, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"15b3942af3b920f5752972b86f312043b66dfad2"},"cell_type":"code","source":"anova(df_train.Fare, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"02a749b425d6b51cd240c8c701a162f9fb763a98"},"cell_type":"code","source":"tukey_test(df_train.Fare, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0994f158572a2934294c8a14e5e89860d66d325c"},"cell_type":"markdown","source":"### Age & Survived"},{"metadata":{"trusted":false,"_uuid":"db5ce2531ed2195f453709ed9487377fb27387a5"},"cell_type":"code","source":"boxplot_and_correlation(df_train.Survived, df_train.Age)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2d923bb0bf43c05739fa83c9a89ea4a6761630ee"},"cell_type":"code","source":"nume_grouped_by_cat(df_train.Age, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a5148dd08a4459df0edc0d6d2f35ccaf256fe583"},"cell_type":"code","source":"num_hist_by_cat(df_train.Age, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"0d8b4f5bf2d262e95d6a49cf5e53f61ee9e752d0"},"cell_type":"code","source":"anova(df_train.Age, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3128bc8f298c74051b5e86fa0c049a7e06bdc08e"},"cell_type":"markdown","source":"## Categorical & Categorical Variables"},{"metadata":{"trusted":false,"_uuid":"71477c9504feb62a22c5ddd57e3cde6846b7f0e8"},"cell_type":"code","source":"'''#1.Create a function that calculates absolute and relative frequency of Survived variable by a categorical variable. And then plots the absolute and relative frequency of Survived by a categorical variable.'''\ndef crosstab(cat, cat_target):\n    '''cat = categorical variable, cat_target = our target categorical variable.'''\n    global ax, ax1\n    fig_size = (18, 5)\n    title_size = 18\n    font_size = 15\n    cat_grouped_by_cat_target = pd.crosstab(index = cat, columns = cat_target)\n    cat_grouped_by_cat_target.rename({0:'Victims', 1:'Survivors'}, axis = 'columns', inplace = True)  # Renaming the columns\n    pct_cat_grouped_by_cat_target = round(pd.crosstab(index = cat, columns = cat_target, normalize = 'index')*100, 2)\n    pct_cat_grouped_by_cat_target.rename({0:'Victims(%)', 1:'Survivors(%)'}, axis = 'columns', inplace = True)\n    \n    # Plot absolute frequency of Survived by a categorical variable\n    ax =  cat_grouped_by_cat_target.plot.bar(color = ['r', 'g'], title = 'Absolute Count of Survival and Death by %s' %cat.name, figsize = fig_size)\n    ax.title.set_size(fontsize = title_size)\n    abs_bar_labels()\n    plt.xlabel(cat.name, fontsize = font_size)\n    plt.show()\n    \n    # Plot relative frequrncy of Survived by a categorical variable\n    ax1 = pct_cat_grouped_by_cat_target.plot.bar(color = ['r', 'g'], title = 'Percentage Count of Survival and Death by %s' %cat.name, figsize = fig_size)\n    ax1.title.set_size(fontsize = title_size)\n    pct_bar_labels()\n    plt.xlabel(cat.name, fontsize = font_size)\n    plt.show()\n    \n'''#2.Create a function to calculate chi_square test between a categorical and target categorical variable.'''\ndef chi_square(cat, cat_target):\n    cat_grouped_by_cat_target = pd.crosstab(index = cat, columns = cat_target)\n    test_result = stats.chi2_contingency (cat_grouped_by_cat_target)\n    print('Chi Square Test Result between Survived & %s' %cat.name + ':')\n    display(test_result)\n\n'''#3.Finally create another function to calculate Bonferroni-adjusted pvalue for a categorical and target categorical variable.'''\ndef bonferroni_adjusted(cat, cat_target):\n    dummies = pd.get_dummies(cat)\n    for columns in dummies:\n        crosstab = pd.crosstab(dummies[columns], cat_target)\n        print(stats.chi2_contingency(crosstab))\n    print('\\nColumns:', dummies.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f934c04cb0cbdd1c96cb98217c92ecdb403479a9"},"cell_type":"code","source":"crosstab(df_train.Sex, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5d2837299c70ffc5ba6f6e5f3b4ba9a2a8be8c35"},"cell_type":"code","source":"chi_square(df_train.Sex, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff9d5d4b846ccfd1efc4beedfc61b2f0ddf9e199"},"cell_type":"markdown","source":"### Pclass & Survived"},{"metadata":{"trusted":false,"_uuid":"c7c7e4710ca576bc8c0d850bbc8bd2008a6ae898"},"cell_type":"code","source":"crosstab(df_train.Pclass, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e3d628372609779fd6a78eebc33b5ed0dfe653ca"},"cell_type":"code","source":"chi_square(df_train.Pclass, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"680ae1000ef37f5ffaadcbefdf82ca119d3e48af"},"cell_type":"code","source":"bonferroni_adjusted(df_train.Pclass, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c7a0beac97582aca5e4f3f7446c90b11929438d"},"cell_type":"markdown","source":"### Embarked & Survived"},{"metadata":{"trusted":false,"_uuid":"d579ce12523092417a616392f6a434cf51725af5"},"cell_type":"code","source":"crosstab(df_train.Embarked, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3f65a920b65cab3e240646fd879de6e149c8bec2"},"cell_type":"code","source":"chi_square(df_train.Embarked, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2b00ce4caf4248883ebca561e4e833a32b82fb3f"},"cell_type":"code","source":"bonferroni_adjusted(df_train.Embarked, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4db8fcd516d0f6ed83e874498a80e1fe0d41d190"},"cell_type":"markdown","source":"### SibSp & Survived"},{"metadata":{"trusted":false,"_uuid":"343d31a462a0db4bc153d867d5cdd30aefcadf50"},"cell_type":"code","source":"crosstab(df_train.SibSp, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"60fc4f088b449efa5e17fd72e8aea2a60c7448b0"},"cell_type":"code","source":"chi_square(df_train.SibSp, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bea35a6d768c82e6f5a0b9030ac4aab4c0e64f22"},"cell_type":"markdown","source":"### Parch & Survived"},{"metadata":{"trusted":false,"_uuid":"c0cc06627ecafb498d9d5b476bc82dd565027435"},"cell_type":"code","source":"crosstab(df_train.Parch, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3fc40bdb8e5e86a678a7f2a6e90fb0087ad64b28"},"cell_type":"code","source":"chi_square(df_train.Parch, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ff23447e1d31d22682dbe0c11bc1d506d67200a"},"cell_type":"markdown","source":"### Title & Survived"},{"metadata":{"trusted":false,"_uuid":"2fa9e9662b42b2786c80a95ff1512694329bc96d"},"cell_type":"code","source":"crosstab(df_train.Title, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d0221afffd34dc0d60f1031506be74cc3136fbdf"},"cell_type":"code","source":"chi_square(df_train.Title, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a18ceeb30a8730e89fe37c31b169108597a4b1af"},"cell_type":"markdown","source":"### Family_size & Survived"},{"metadata":{"trusted":false,"_uuid":"a05759415998f2be949882b55e93b92a9157bb47"},"cell_type":"code","source":"crosstab(df_train.Family_size, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6cdf9449e23baf139cd1f67e2d201d3f4cb1f7c6"},"cell_type":"code","source":"chi_square(df_train.Family_size, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9329da74290aabc23ef1f4e69c81e7654b470cfd"},"cell_type":"code","source":"bonferroni_adjusted(df_train.Family_size, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19bf1d9eed9658d8a64aeea6dcc8599ecd16f285"},"cell_type":"markdown","source":"### Cabin & Survived"},{"metadata":{"trusted":false,"_uuid":"5b9a3cb81f96ef82c0b606f14da6aeedd36f5a05"},"cell_type":"code","source":"crosstab(df_train.Cabin, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5b74f26a3a557efd5f3ede1856c2a7af5fc7e98a"},"cell_type":"code","source":"chi_square(df_train.Cabin, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30f66ace69bef7833264a239a5b5a28d159b6e50"},"cell_type":"markdown","source":"### Ticket & Survived"},{"metadata":{"trusted":false,"_uuid":"9d4b07eeb8098136385751778df35a76e550f405"},"cell_type":"code","source":"crosstab(df_train.Ticket, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"8ab510179ff067eea6ddbc8cac22f8f65b79c1e5"},"cell_type":"code","source":"chi_square(df_train.Ticket, df_train.Survived)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f914e7a475cd7d624ec168fdb81dbe16c73459f"},"cell_type":"markdown","source":"# Multivariate Analysis"},{"metadata":{"trusted":false,"_uuid":"6a6e3bd4e50ae518ffc8ea12f8078d5d784c8aec"},"cell_type":"code","source":"'''Create a function that plots the impact of 3 predictor variables at a time on a target variable.'''\ndef multivariate_analysis(cat1, cat2, cat3, cat_target):\n    font_size = 15\n    grouped = round(pd.crosstab(index = [cat1, cat2, cat3], columns = cat_target, normalize = 'index')*100, 2)\n    grouped.rename({0:'Died%', 1:'Survived%'}, axis = 1, inplace = True)\n    grouped.plot.bar(color = ['r', 'g'], figsize = (18,5))\n    plt.xlabel(cat1.name + ',' + cat2.name + ',' + cat3.name, fontsize = font_size)\n    plt.ylabel('Relative Frequency (%)', fontsize = font_size)\n    plt.xticks(fontsize = font_size)\n    plt.yticks(fontsize = font_size)\n    plt.legend(loc = 'best')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d0dfb9a26478e55cf4b685414d95aa6b589075c"},"cell_type":"markdown","source":"## (Pclass, Sex, Cabin) vs Survived"},{"metadata":{"trusted":false,"_uuid":"edd06b754a7452351468924541993dee819cd41a"},"cell_type":"code","source":"multivariate_analysis(df_train.Pclass, df_train.Sex, df_train.Cabin, df_train.Survived)\nbold('**Findings: Sex male seems to be deciding factor for death.**')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8fffc765069aff3506e1018209d63e27c33e4464"},"cell_type":"markdown","source":"## (Pclass, Sex, Embarked) vs Survived"},{"metadata":{"trusted":false,"_uuid":"c85d5f99261e16161445c1770445d3c76b53e1d6"},"cell_type":"code","source":"multivariate_analysis(df_train.Pclass, df_train.Sex, df_train.Embarked, df_train.Survived)\nbold('**Findings: Again Sex male seems to be deciding factor for death and female for survival.**')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"09c591795d3b4b18d9219973a7e2ea64c33496a6"},"cell_type":"markdown","source":"## (Pclass, Sex, SibSp) vs Survived"},{"metadata":{"trusted":false,"_uuid":"e10fc5e4caf7ee989d3e2f17adaf141705e15270"},"cell_type":"code","source":"multivariate_analysis(df_train.Pclass, df_train.Sex, df_train.SibSp, df_train.Survived)\nbold('**Findings: Bigger SibSp and male is responsible more for death.**')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e59ec3657f1baf0041676bbe570c5609357ff5e"},"cell_type":"markdown","source":"## (Pclass, Sex, Parch) vs Survived "},{"metadata":{"trusted":false,"_uuid":"3830a1aade7890ae43e7f735cdd9e2e26bc14f86"},"cell_type":"code","source":"multivariate_analysis(df_train.Pclass, df_train.Sex, df_train.Parch, df_train.Survived)\nbold('**Findings: Bigger Parch and Sex male is responsible more for death.**')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c4c903311b61651f42230daf646d06682e7960e"},"cell_type":"markdown","source":"## (Pclass, Sex, Title) vs Survived "},{"metadata":{"trusted":false,"_uuid":"b8f52b5e26c44d1de330a2492262b77409a8ffad"},"cell_type":"code","source":"multivariate_analysis(df_train.Pclass, df_train.Sex, df_train.Title, df_train.Survived)\nbold('**Findings: Findings: Passengers with sex male and title mr mostly died.**')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64e079dfc89fce0a7302b04d22e97cd806aaaaa8"},"cell_type":"markdown","source":"## (Pclass, Sex, Family_size) vs Survived"},{"metadata":{"trusted":false,"_uuid":"4f517f3a80df8d12e796d0e3a6803eb9ca51349e"},"cell_type":"code","source":"multivariate_analysis(df_train.Pclass, df_train.Sex, df_train.Family_size, df_train.Survived)\nbold('**Findings: Sex male, family_size single and large greatly influence the death ratio.**')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bd0197f7e9e303f04c4539c02a0dfcf58e5a3d5"},"cell_type":"markdown","source":"## (Pclass, Sex, Ticket) vs Survived "},{"metadata":{"trusted":false,"_uuid":"bb2ea86609b718db34351a84abb620037ba56b37"},"cell_type":"code","source":"multivariate_analysis(df_train.Pclass, df_train.Sex, df_train.Ticket, df_train.Survived)\nbold('**Findings: Sex female, ticket p and w mostly survived.**')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76f537a4dd4cc5dcaf13f91f46cdb7331c324031"},"cell_type":"markdown","source":"## (Pclass, Title, Cabin) vs Survived "},{"metadata":{"trusted":false,"_uuid":"80b1bf692cda732c07dd5b0a672168dbf9dc3caa"},"cell_type":"code","source":"multivariate_analysis(df_train.Pclass, df_train.Title, df_train.Cabin, df_train.Survived)\nbold('**Findings: Title mrs, master and cabin x had best survival ratio.**')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1fe58f1e1fa6ec7323c426044d9ddce2a26dab7d"},"cell_type":"markdown","source":"## (Family_size, Sex, Cabin) vs Survived "},{"metadata":{"trusted":false,"_uuid":"e427be69cc5f024ead68c2f3ff5e483144ad2daf"},"cell_type":"code","source":"multivariate_analysis(df_train.Family_size, df_train.Sex, df_train.Cabin, df_train.Survived)\nbold('**Findings: Family_size small, medium and sex female had best survival chance.**')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a62076360c1c353009172fa97494a68037a0815"},"cell_type":"markdown","source":"## (Sex, Title, Family_size) vs Survived"},{"metadata":{"trusted":false,"_uuid":"0eb96060aa0242397f9975141048e593542e9e9d"},"cell_type":"code","source":"multivariate_analysis(df_train.Sex, df_train.Title, df_train.Family_size, df_train.Survived)\nbold('**Findings: Title aristocrat, sex female and family_size small mostly survived.**')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c582363c89b648926272c6a45d3aa8f453ed386"},"cell_type":"markdown","source":"## (Sex, Title, Cabin) vs Survived "},{"metadata":{"trusted":false,"_uuid":"bc7c64c4d813c8bd8d08d6a2f53c08d7ffed0fb0"},"cell_type":"code","source":"multivariate_analysis(df_train.Sex, df_train.Title, df_train.Cabin, df_train.Survived)\nbold('**Findings: findings: Title aristocrat, miss, mrs and sex female mostly survived.**')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eed2e0cf099aa5a7323a2148a238c95a1e7ba3db"},"cell_type":"markdown","source":"## (Sex, Title, Embarked) vs Survived Â¶"},{"metadata":{"trusted":false,"_uuid":"029c7ab38a4d2099d7d0730ba173426d495b1a6a"},"cell_type":"code","source":"multivariate_analysis(df_train.Sex, df_train.Title, df_train.Embarked, df_train.Survived)\nbold('**Findings: Embarked c, sex female and title master and aristocrat had best survival rate.**')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be0e4e10191d112906dba69866b851f3ca48e672"},"cell_type":"markdown","source":"## (Sex, Title, Ticket) vs Survived"},{"metadata":{"trusted":false,"_uuid":"f7cb7584968d350c94c90dc2aa1221dde3b51261"},"cell_type":"code","source":"multivariate_analysis(df_train.Sex, df_train.Title, df_train.Ticket, df_train.Survived)\nbold('**Findings: Ticker n, w and sex male and title mr mostly died.**')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"baa44d3ea62536ae2fd4303488efffa5e3903328"},"cell_type":"markdown","source":"# Data Transformation"},{"metadata":{"_uuid":"2a70afad68428d591a64b2fd23075cb410da5725"},"cell_type":"markdown","source":"## Binning Continuous Variables"},{"metadata":{"_uuid":"fe42becd151d41af67341efa7a00427de936c96e"},"cell_type":"markdown","source":"### Binning Age"},{"metadata":{"trusted":false,"_uuid":"ac9b6b2f56d9b48dc40287713f34612925534ddc"},"cell_type":"code","source":"label_names = ['infant','child','teenager','young_adult','adult','aged']\n\n'''Create range for each bin categories of Age.'''\ncut_points = [0,5,12,18,35,60,81]\n\n'''Create and view categorized Age with original Age.'''\nmerged['Age_binned'] = pd.cut(merged.Age, cut_points, labels = label_names)\nbold('**Age with Categorized Age:**')\ndisplay(merged[['Age', 'Age_binned']].head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6327836fc423319a23bf49e0986dac8b750a92ee"},"cell_type":"markdown","source":"### Binning Fare"},{"metadata":{"trusted":false,"_uuid":"30ee80744bcb66cf4cb3379a2e4f5e52e938b9f5"},"cell_type":"code","source":"'''Create bin categories for Fare.'''\ngroups = ['low','medium','high','very_high']\n\n'''Create range for each bin categories of Fare.'''\ncut_points = [-1, 130, 260, 390, 520]\n\n'''Create and view categorized Fare with original Fare.'''\nmerged['Fare_binned'] = pd.cut(merged.Fare, cut_points, labels = groups)\nbold('**Fare with Categorized Fare:**')\ndisplay(merged[['Fare', 'Fare_binned']].head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6ce48653f1ab45cffa9a6640ceeb068b0ba48fb"},"cell_type":"markdown","source":"## Dropping Features"},{"metadata":{"trusted":false,"_uuid":"232e186246fa7a5d4288e743ff69aa00dc0fcf4a"},"cell_type":"code","source":"\"\"\"Let's see all the variables we currently have with their category.\"\"\"\ndisplay(merged.head(2))\n\n'''Drop the features that would not be useful anymore.'''\nmerged.drop(columns = ['Name', 'Age', 'Fare'], inplace = True, axis = 1)\n\n'''Features after dropping.'''\nbold('**Features Remaining after Dropping:**')\ndisplay(merged.columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e2a2ba9e35427b567efeeee114b47b6b0c9a948"},"cell_type":"markdown","source":"## Correcting Data Types"},{"metadata":{"trusted":false,"_uuid":"d3b90ac7086fd1cb6af69324249b32ffb66249e4"},"cell_type":"code","source":"'''Checking current data types.'''\nbold('**Current Variable Data Types:**')\ndisplay(merged.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"cbb071380dc53eb98855924451765cafc0ee9eea"},"cell_type":"code","source":"'''Correcting data types, converting into categorical variables.'''\nmerged.loc[:, ['Pclass', 'Sex', 'Embarked', 'Cabin', 'Title', 'Family_size', 'Ticket']] = merged.loc[:, ['Pclass', 'Sex', 'Embarked', 'Cabin', 'Title', 'Family_size', 'Ticket']].astype('category')\n\n'''Due to merging there are NaN values in Survived for test set observations.'''\nmerged.Survived = merged.Survived.dropna().astype('int')#Converting without dropping NaN throws an error.\n\n'''Check if data types have been corrected.'''\nbold('**Data Types after Correction:**')\ndisplay(merged.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f60636a076760c30574a117801350fadf7c219c2"},"cell_type":"markdown","source":"## Encoding Categorical Variables"},{"metadata":{"trusted":false,"_uuid":"39694e53ee40df2f9ac683cf33be7cc6e65558b9"},"cell_type":"code","source":"'''Convert categorical data into numeric to feed our machine learning model.'''\nmerged = pd.get_dummies(merged)\n\n\"\"\"Let's visualize the updated dataset that would be fed to our machine learning algorithms.\"\"\"\nbold('**Preview of Processed Data:**')\ndisplay(merged.head(2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea636982fcc355d44cae936f9e7b27c8a1bd9420"},"cell_type":"markdown","source":"# Model Building and Evaluation"},{"metadata":{"trusted":false,"_uuid":"262b3f195fc7aed5ad0e4d266440608bd6061ec9"},"cell_type":"code","source":"'''Set a seed for reproducibility'''\nseed = 43\n\n\"\"\"Let's split the train and test set to feed machine learning algorithm.\"\"\"\ndf_train = merged.iloc[:891, :]\ndf_test  = merged.iloc[891:, :]\n\n'''Drop passengerid from train set and Survived from test set.'''\ndf_train = df_train.drop(columns = ['PassengerId'], axis = 1)\ndf_test = df_test.drop(columns = ['Survived'], axis = 1)\n\n'''Extract data sets as input and output for machine learning models.'''\nX_train = df_train.drop(columns = ['Survived'], axis = 1) # Input matrix as pandas dataframe (dim:891*47).\ny_train = df_train['Survived'] # Output vector as pandas series (dim:891*1)\n\n\"\"\"Extract test set\"\"\"\nX_test  = df_test.drop(\"PassengerId\", axis = 1).copy()\n\n'''See the dimensions of input and output data set.'''\nprint('Input Matrix Dimension:  ', X_train.shape)\nprint('Output Vector Dimension: ', y_train.shape)\nprint('Test Data Dimension:     ', X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4918fe4295d97b78ba52090a36d1af5f0b84e1a"},"cell_type":"markdown","source":"## Training Model"},{"metadata":{"trusted":false,"_uuid":"3b437b572fce5e9633a0f3243bbed3dd561a01d1"},"cell_type":"code","source":"\"\"\"Building machine learning models: \nWe will try 10 different classifiers to find the best classifier after tunning model's hyperparameters that will best generalize the unseen(test) data.\"\"\"\n\n'''Now initialize all the classifiers object.'''\n'''#1.Logistic Regression'''\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression()\n\n'''#2.Support Vector Machines'''\nfrom sklearn.svm import SVC\nsvc = SVC(gamma = 'auto')\n\n'''#3.Random Forest Classifier'''\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(random_state = seed, n_estimators = 100)\n\n'''#4.KNN'''\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\n\n'''#5.Gaussian Naive Bayes'''\nfrom sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\n\n'''#6.Decision Tree Classifier'''\nfrom sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(random_state = seed)\n\n'''#7.Gradient Boosting Classifier'''\nfrom sklearn.ensemble import GradientBoostingClassifier\ngbc = GradientBoostingClassifier(random_state = seed)\n\n'''#8.Adaboost Classifier'''\nfrom sklearn.ensemble import AdaBoostClassifier\nabc = AdaBoostClassifier(random_state = seed)\n\n'''#9.ExtraTrees Classifier'''\nfrom sklearn.ensemble import ExtraTreesClassifier\netc = ExtraTreesClassifier(random_state = seed)\n\n'''#10.Extreme Gradient Boosting'''\nfrom xgboost import XGBClassifier\nxgbc = XGBClassifier(random_state = seed)\n\n'''Create a function that returns train accuracy of different models.'''\ndef train_accuracy(model):\n    model.fit(X_train, y_train)\n    train_accuracy = model.score(X_train, y_train)\n    train_accuracy = np.round(train_accuracy*100, 2)\n    return train_accuracy\n\n\n'''Models with best training accuracy:'''\ntrain_accuracy = pd.DataFrame({'Train_accuracy(%)':[train_accuracy(lr), train_accuracy(svc), train_accuracy(rf), train_accuracy(knn), train_accuracy(gnb), train_accuracy(dt), train_accuracy(gbc), train_accuracy(abc), train_accuracy(etc), train_accuracy(xgbc)]})\ntrain_accuracy.index = ['LR', 'SVC', 'RF', 'KNN', 'GNB', 'DT', 'GBC', 'ABC', 'ETC', 'XGBC']\nsorted_train_accuracy = train_accuracy.sort_values(by = 'Train_accuracy(%)', ascending = False)\nbold('**Training Accuracy of the Classifiers:**')\ndisplay(sorted_train_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc57dbbb1bf571dd92401d7c2ad9a5af0cfbcdc0"},"cell_type":"markdown","source":"## Model Evaluation"},{"metadata":{"_uuid":"8c54ba75e76f72ef1e9a33de1c4115604ce70afb"},"cell_type":"markdown","source":"### K-Fold Cross Validation"},{"metadata":{"trusted":false,"_uuid":"0a2980f14dd56110c8e6d88988be556a2f3725ad"},"cell_type":"code","source":"'''Create a function that returns mean cross validation score for different models.'''\ndef x_val_score(model):\n    from sklearn.model_selection import cross_val_score\n    x_val_score = cross_val_score(model, X_train, y_train, cv = 10, scoring = 'accuracy').mean()\n    x_val_score = np.round(x_val_score*100, 2)\n    return x_val_score\n\n\"\"\"Let's perform k-fold (k=10) cross validation to find the classifier with the best cross validation accuracy.\"\"\"\nx_val_score = pd.DataFrame({'X_val_score(%)':[x_val_score(lr), x_val_score(svc), x_val_score(rf), x_val_score(knn), x_val_score(gnb), x_val_score(dt), x_val_score(gbc), x_val_score(abc), x_val_score(etc), x_val_score(xgbc)]})\nx_val_score.index = ['LR', 'SVC', 'RF', 'KNN', 'GNB', 'DT', 'GBC', 'ABC', 'ETC', 'XGBC']\nsorted_x_val_score = x_val_score.sort_values(by = 'X_val_score(%)', ascending = False) \nbold('**Models 10-fold Cross Validation Score:**')\ndisplay(sorted_x_val_score)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a1cf8acd6ed08b31adc8d0803ae63821fa558dc"},"cell_type":"markdown","source":"### Tuning Hyperparameters"},{"metadata":{"trusted":false,"_uuid":"7d996db548b94ebfdac8094c4d3cb5b56e52cd83"},"cell_type":"code","source":"\"\"\"Define all the models' hyperparameters one by one first::\"\"\"\n\n'''Define hyperparameters the logistic regression will be tuned with. For LR, the following hyperparameters are usually tunned.'''\nlr_params = {'penalty':['l1', 'l2'],\n             'C': np.logspace(0, 4, 10)}\n\n'''For GBC, the following hyperparameters are usually tunned.'''\ngbc_params = {'learning_rate': [0.01, 0.02, 0.05, 0.01],\n              'max_depth': [4, 6, 8],\n              'max_features': [1.0, 0.3, 0.1], \n              'min_samples_split': [ 2, 3, 4],\n              'random_state':[seed]}\n\n'''For SVC, the following hyperparameters are usually tunned.'''\nsvc_params = {'C': [6, 7, 8, 9, 10, 11, 12], \n              'kernel': ['linear','rbf'],\n              'gamma': [0.5, 0.2, 0.1, 0.001, 0.0001]}\n\n'''For DT, the following hyperparameters are usually tunned.'''\ndt_params = {'max_features': ['auto', 'sqrt', 'log2'],\n             'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], \n             'min_samples_leaf':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n             'random_state':[seed]}\n\n'''For RF, the following hyperparameters are usually tunned.'''\nrf_params = {'criterion':['gini','entropy'],\n             'n_estimators':[10, 15, 20, 25, 30],\n             'min_samples_leaf':[1, 2, 3],\n             'min_samples_split':[3, 4, 5, 6, 7], \n             'max_features':['sqrt', 'auto', 'log2'],\n             'random_state':[44]}\n\n'''For KNN, the following hyperparameters are usually tunned.'''\nknn_params = {'n_neighbors':[3, 4, 5, 6, 7, 8],\n              'leaf_size':[1, 2, 3, 5],\n              'weights':['uniform', 'distance'],\n              'algorithm':['auto', 'ball_tree','kd_tree','brute']}\n\n'''For ABC, the following hyperparameters are usually tunned.'''\nabc_params = {'n_estimators':[1, 5, 10, 15, 20, 25, 40, 50, 60, 80, 100, 130, 160, 200, 250, 300],\n              'learning_rate':[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5],\n              'random_state':[seed]}\n\n'''For ETC, the following hyperparameters are usually tunned.'''\netc_params = {'max_depth':[None],\n              'max_features':[1, 3, 10],\n              'min_samples_split':[2, 3, 10],\n              'min_samples_leaf':[1, 3, 10],\n              'bootstrap':[False],\n              'n_estimators':[100, 300],\n              'criterion':[\"gini\"], \n              'random_state':[seed]}\n\n'''For XGBC, the following hyperparameters are usually tunned.'''\nxgbc_params = {'n_estimators': (150, 250, 350,450,550,650, 700, 800, 850, 1000),\n              'learning_rate': (0.01, 0.6),\n              'subsample': (0.3, 0.9),\n              'max_depth': [3, 4, 5, 6, 7, 8, 9],\n              'colsample_bytree': (0.5, 0.9),\n              'min_child_weight': [1, 2, 3, 4],\n              'random_state':[seed]}\n\n\n'''Create a function to tune hyperparameters of the selected models.'''\ndef tune_hyperparameters(model, params):\n    from sklearn.model_selection import GridSearchCV\n    global best_params, best_score\n    # Construct grid search object with 10 fold cross validation.\n    grid = GridSearchCV(model, params, verbose = 2, cv = 10, scoring = 'accuracy', n_jobs = -1)\n    # Fit using grid search.\n    grid.fit(X_train, y_train)\n    best_params, best_score = grid.best_params_, np.round(grid.best_score_*100, 2)\n    return best_params, best_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"50a25d13f838322bb22a53e08a8847f075ad5c3d"},"cell_type":"code","source":"'''Tune LR hyperparameters.'''\ntune_hyperparameters(lr, params = lr_params)\nlr_best_params, lr_best_score = best_params, best_score\nprint('Best Score:', lr_best_score)\nprint('Best Parameters:', lr_best_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d3264680b981d12e546d9ce720bcfddbf55d8430"},"cell_type":"code","source":"\"\"\"Tune GBC's hyperparameters.\"\"\"\ntune_hyperparameters(gbc, params = gbc_params)\ngbc_best_score, gbc_best_params = best_score, best_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7e48035bbcf42f4ad988fb30f7f8e6d961780327"},"cell_type":"code","source":"\"\"\"Tune SVC's hyperparameters.\"\"\"\ntune_hyperparameters(svc, params = svc_params)\nsvc_best_score, svc_best_params = best_score, best_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"829373519fec3b05142bddb8f9443fb368605bf3"},"cell_type":"code","source":"\"\"\"Tune DT's hyperparameters.\"\"\"\ntune_hyperparameters(dt, params = dt_params)\ndt_best_score, dt_best_params = best_score, best_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"42ed7454541f68af5886c42cb8b26481bb055091"},"cell_type":"code","source":"\"\"\"Tune RF's hyperparameters.\"\"\"\ntune_hyperparameters(rf, params = rf_params)\nrf_best_score, rf_best_params = best_score, best_params\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"40904c5d12df2cf18693aff1ad397012dd6b3834"},"cell_type":"code","source":"\"\"\"Tune KNN's hyperparameters.\"\"\"\ntune_hyperparameters(knn, params = knn_params)\nknn_best_score, knn_best_params = best_score, best_params\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"8e881bacabf2efba39b1c66be14934030c1de9ee"},"cell_type":"code","source":"\"\"\"Tune ABC's hyperparameters.\"\"\"\ntune_hyperparameters(abc, params = abc_params)\nabc_best_score, abc_best_params = best_score, best_params\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f13e3be7970bcd911e7f41e6218c431d4794da6a"},"cell_type":"code","source":"\"\"\"Tune ETC's hyperparameters.\"\"\"\ntune_hyperparameters(etc, params = etc_params)\netc_best_score, etc_best_params = best_score, best_params\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2825abf6dea299583b722f7c86397fd5d8c10481"},"cell_type":"markdown","source":"### Model Selection"},{"metadata":{"trusted":false,"_uuid":"aff055d6f4b2a0a9b9bc1eee9d537762b14b1ed2"},"cell_type":"code","source":"'''Create a dataframe of tunned scores and sort them in descending order.'''\ntunned_scores = pd.DataFrame({'Tunned_accuracy(%)': [lr_best_score, gbc_best_score, svc_best_score, dt_best_score, rf_best_score, knn_best_score, abc_best_score, etc_best_score]})\ntunned_scores.index = ['LR', 'GBC', 'SVC', 'DT', 'RF', 'KNN', 'ABC', 'ETC']\nsorted_tunned_scores = tunned_scores.sort_values(by = 'Tunned_accuracy(%)', ascending = False)\nbold('**Models Accuracy after Optimization:**')\ndisplay(sorted_tunned_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e2012e9f5d93b7b0dfbc8f19b60ccbdd075dc215"},"cell_type":"code","source":"'''#4.Create a function that compares cross validation scores with tunned scores for different models by plotting them.'''\ndef compare_scores(accuracy):\n    global ax1   \n    font_size = 15\n    title_size = 18\n    ax1 = accuracy.plot.bar(legend = False,  title = 'Models %s' % ''.join(list(accuracy.columns)), figsize = (18, 5), color = 'sandybrown')\n    ax1.title.set_size(fontsize = title_size)\n    # Removes square brackets and quotes from column name after to converting list.\n    pct_bar_labels()\n    plt.ylabel('% Accuracy', fontsize = font_size)\n    plt.show()\n\n'''Compare cross validation scores with tunned scores to find the best model.'''\nbold('**Comparing Cross Validation Scores with Optimized Scores:**')\ncompare_scores(sorted_x_val_score)\ncompare_scores(sorted_tunned_scores)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"21f519090b74c08f2c75c0599846db5e71107d44"},"cell_type":"markdown","source":"## Retrain and Predict Using Optimized Hyperparameters"},{"metadata":{"trusted":false,"_uuid":"2124ff8960579abc9fb4913687f56510fd9ec819"},"cell_type":"code","source":"'''Instantiate the models with optimized hyperparameters.'''\nrf  = RandomForestClassifier(**rf_best_params)\ngbc = GradientBoostingClassifier(**gbc_best_params)\nsvc = SVC(**svc_best_params)\nknn = KNeighborsClassifier(**knn_best_params)\netc = ExtraTreesClassifier(**etc_best_params)\nlr  = LogisticRegression(**lr_best_params)\ndt  = DecisionTreeClassifier(**dt_best_params)\nabc = AdaBoostClassifier(**abc_best_params)\n\n'''Train all the models with optimised hyperparameters.'''\nmodels = {'RF':rf, 'GBC':gbc, 'SVC':svc, 'KNN':knn, 'ETC':etc, 'LR':lr, 'DT':dt, 'ABC':abc}\nbold('**10-fold Cross Validation after Optimization:**')\nscore = []\nfor x, (keys, items) in enumerate(models.items()):\n    # Train the models with optimized parameters using cross validation.\n    # No need to fit the data. cross_val_score does that for us.\n    # But we need to fit train data for prediction in the follow session.\n    from sklearn.model_selection import cross_val_score\n    items.fit(X_train, y_train)\n    scores = cross_val_score(items, X_train, y_train, cv = 10, scoring = 'accuracy')*100\n    score.append(scores.mean())\n    print('Mean Accuracy: %0.4f (+/- %0.4f) [%s]'  % (scores.mean(), scores.std(), keys))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"70485de9dc5c132cf3cac3c8dc91716cffba5980"},"cell_type":"code","source":"'''Make prediction using all the trained models.'''\nmodel_prediction = pd.DataFrame({'RF':rf.predict(X_test), 'GBC':gbc.predict(X_test), 'ABC':abc.predict(X_test),\n                                 'ETC':etc.predict(X_test), 'DT':dt.predict(X_test), 'SVC':svc.predict(X_test), \n                                 'KNN':knn.predict(X_test), 'LR':lr.predict(X_test)})\n\n\"\"\"Let's see how each model classifies a prticular class.\"\"\"\nbold('**All the Models Prediction:**')\ndisplay(model_prediction.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d0f68f8d5c8734768b943ee27cc00de0713f3a7"},"cell_type":"markdown","source":"## Feature Importance"},{"metadata":{"trusted":false,"_uuid":"200c8246b50ec55bc247a79fbce9be12f5361237"},"cell_type":"code","source":"'''Create a function that plot feature importance by the selected tree based models.'''\ndef feature_importance(model):\n    importance = pd.DataFrame({'Feature': X_train.columns,\n                              'Importance': np.round(model.feature_importances_,3)})\n    importance = importance.sort_values(by = 'Importance', ascending = False).set_index('Feature')\n    return importance\n\n'''Create subplots of feature impotance of rf, gbc, dt, etc, and abc.'''\nfig, axes = plt.subplots(3,2, figsize = (20,40))\nfig.suptitle('Tree Based Models Feature Importance', fontsize = 28)\ntree_models = [rf, gbc, dt, etc, abc]\ntree_names = ['RF', 'GBC', 'DT', 'ETC', 'ABC']\n\nfor ax, model, name in zip(axes.flatten(), tree_models, tree_names):\n    feature_importance(model).plot.barh(ax = ax, title = name, fontsize = 16, color = 'green')\nfig.delaxes(ax = axes[2,1]) # We don't need the last subplot.\nfig.tight_layout(rect = [0, 0.03, 1, 0.97])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"fda164de403ac8132a9aef286361ed5f9eb70bf0"},"cell_type":"code","source":"\"\"\"Let's plot feature importance of LR.\"\"\"\ncoeff = pd.DataFrame({'Feature':X_train.columns,'Importance':np.transpose(lr.coef_[0])})\ncoeff.sort_values(by = 'Importance').set_index('Feature').plot.bar(title = 'Feature Importance of Linear Model (LR)', color = 'green', figsize = (18,2.5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"502d296d4589cb5e1bdc9233041f723c7867572a"},"cell_type":"markdown","source":"## Learning Curve"},{"metadata":{"trusted":false,"_uuid":"512a73b6cdb8a142a8b7e60fd790e9fc51a90377"},"cell_type":"code","source":"'''Create a function that returns learning curves for different classifiers.'''\ndef plot_learning_curve(model):\n    from sklearn.model_selection import learning_curve\n    # Create feature matrix and target vector\n    X, y = X_train, y_train\n    # Create CV training and test scores for various training set sizes\n    train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv = 10,\n                                                    scoring='accuracy', n_jobs = -1, \n                                                    train_sizes = np.linspace(0.01, 1.0, 17), random_state = seed)\n                                                    # 17 different sizes of the training set\n\n    # Create means and standard deviations of training set scores\n    train_mean = np.mean(train_scores, axis = 1)\n    train_std = np.std(train_scores, axis = 1)\n\n    # Create means and standard deviations of test set scores\n    test_mean = np.mean(test_scores, axis = 1)\n    test_std = np.std(test_scores, axis = 1)\n\n    # Draw lines\n    plt.plot(train_sizes, train_mean, 'o-', color = 'red',  label = 'Training score')\n    plt.plot(train_sizes, test_mean, 'o-', color = 'green', label = 'Cross-validation score')\n    \n    # Draw bands\n    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha = 0.1, color = 'r') # Alpha controls band transparency.\n    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha = 0.1, color = 'g')\n\n    # Create plot\n    font_size = 15\n    plt.xlabel('Training Set Size', fontsize = font_size)\n    plt.ylabel('Accuracy Score', fontsize = font_size)\n    plt.xticks(fontsize = font_size)\n    plt.yticks(fontsize = font_size)\n    plt.legend(loc = 'best')\n    plt.grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"acde1afe3574e47177182b8ee31ba0881b76a4cc"},"cell_type":"code","source":"'''Now plot learning curves of the optimized models in subplots.'''\nplt.figure(figsize = (25,25))\nlc_models = [rf, gbc, dt, etc, abc, knn, svc, lr]\nlc_labels = ['RF', 'GBC', 'DT', 'ETC', 'ABC', 'KNN', 'SVC', 'LR']\n\nfor ax, models, labels in zip (range(1,9), lc_models, lc_labels):\n    plt.subplot(4,2,ax)\n    plot_learning_curve(models)\n    plt.title(labels, fontsize = 18)\nplt.suptitle('Learning Curves of Optimized Models', fontsize = 28)\nplt.tight_layout(rect = [0, 0.03, 1, 0.97])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06a4c46a5262b8e299c3c241abcaff8ce28429ae"},"cell_type":"markdown","source":"# More Evaluation Metrics "},{"metadata":{"_uuid":"462a91dabf0c8b72b17a31fa73b0d5f7b7ce3495"},"cell_type":"markdown","source":"## Confusion Matrix "},{"metadata":{"trusted":false,"_uuid":"be45574e89e7c094aee4b56b5176c7b20adcbef0"},"cell_type":"code","source":"'''Return prediction to use it in another function.'''\ndef x_val_predict(model):\n    from sklearn.model_selection import cross_val_predict\n    predicted = cross_val_predict(model, X_train, y_train, cv = 10)\n    return predicted # Now we can use it in another function by assigning the function to its return value.\n\n'''Function to return confusion matrix.'''\ndef confusion_matrix(model):\n    predicted = x_val_predict(model)\n    confusion_matrix = pd.crosstab(y_train, predicted, rownames = ['Actual'], colnames = ['Predicted/Classified'], margins = True) # We use pandas crosstab\n    return display(confusion_matrix)\n\n'''Now calculate confusion matrix of rf and gbc.'''\nbold('**RF Confusion Matrix:**')\nconfusion_matrix(rf)\nbold('**GBC Confusion Matrix:**')\nconfusion_matrix(gbc)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f36e3852ca48f4c7e3a9c4858f1982ada148f3c"},"cell_type":"markdown","source":"## Precision Score "},{"metadata":{"trusted":false,"_uuid":"65d4f72ad511158d113bb761798221822faa8323"},"cell_type":"code","source":"'''Function to calculate precision score.'''\ndef precision_score(model):\n    from sklearn.metrics import precision_score\n    predicted = x_val_predict(model)\n    precision_score = precision_score(y_train, predicted)\n    return np.round(precision_score*100, 2)\n\n'''Compute precision score for rf and gbc.'''\nprint('RF  Precision Score:', precision_score(rf))\nprint('GBC Precision Score:', precision_score(gbc))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e9222c936d376f5f121f5e1d92ac4d95d228a38"},"cell_type":"markdown","source":"## Specificity ( or True Negative Rate) "},{"metadata":{"trusted":false,"_uuid":"9db2445216b4ed5a8a651ee3d5584a14eb1e7bd5"},"cell_type":"code","source":"'''Function for specificity score.'''\ndef specificity_score(model):\n    from sklearn.metrics import confusion_matrix\n    predicted = x_val_predict(model)\n    tn, fp, fn, tp = confusion_matrix(y_train, predicted).ravel()\n    specificity_score = tn / (tn + fp)\n    return np.round(specificity_score*100, 2)\n\n'''Calculate specificity score for rf and gbc.'''\nprint('RF  Specificity Score:', specificity_score(rf))\nprint('GBC Specificity Score:', specificity_score(gbc))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a1c060afaaa770da4018ac5521bf2f6f33003e4"},"cell_type":"markdown","source":"## F1 Score "},{"metadata":{"trusted":false,"_uuid":"3aab2756571514890af5c6ed8988475a0824f42e"},"cell_type":"code","source":"'''Function for F1 score.'''\ndef f1_score(model):\n    from sklearn.metrics import f1_score\n    predicted = x_val_predict(model)\n    f1_score = f1_score(y_train, predicted)\n    return np.round(f1_score*100, 2)\n\n'''Calculate f1 score for rf and gbc.'''\nprint('RF  F1 Score:', f1_score(rf))\nprint('GBC F1 Score:', f1_score(gbc))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce3152d2af366f9f0d68d07d4def5acb21ed0c19"},"cell_type":"markdown","source":"## Classification Report Â¶"},{"metadata":{"trusted":false,"_uuid":"99e0294450135daa9f6ce1f004903bb26d83a803"},"cell_type":"code","source":"'''Function to compute classification report.'''\ndef classification_report(model):\n    from sklearn.metrics import classification_report\n    predicted = x_val_predict(model)\n    classification_report = classification_report(y_train, predicted)\n    return print(classification_report)\n\n'''Now calculate classification report for rf and gbc.'''\nbold('**RF Classification Report:**')\nclassification_report(rf)\nbold('**GBC Classification Report:**')\nclassification_report(gbc)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7351cff77450c4a6e02039ed35e890b978a958f"},"cell_type":"markdown","source":"## Precision-Recall vs Threshold Curve "},{"metadata":{"trusted":false,"_uuid":"0408367f79ba4214235b26b238124ccf26b0a8d7"},"cell_type":"code","source":"'''#7Function for plotting precision-recall vs threshold curve.'''\ndef precision_recall_vs_threshold(model, title):\n    from sklearn.metrics import precision_recall_curve\n    probablity = model.predict_proba(X_train)[:, 1]\n    plt.figure(figsize = (18, 5))\n    precision, recall, threshold = precision_recall_curve(y_train, probablity)\n    plt.plot(threshold, precision[:-1], 'b-', label = 'precision', lw = 3.7)\n    plt.plot(threshold, recall[:-1], 'g', label = 'recall', lw = 3.7)\n    plt.xlabel('Threshold')\n    plt.legend(loc = 'best')\n    plt.ylim([0, 1])\n    plt.title(title)\n    plt.show()\n\n'''Now plot precision-recall vs threshold curve for rf and gbc.'''\nprecision_recall_vs_threshold(rf, title = 'RF Precision-Recall vs Threshold Curve' )\nprecision_recall_vs_threshold(gbc, title = 'GBC Precision-Recall vs Threshold Curve')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1232b27364c153c9fc49e328aec65c718698c5c"},"cell_type":"markdown","source":"## Precision-Recall Curve "},{"metadata":{"trusted":false,"_uuid":"21f993ba21d151a96a692d4b690f67f435af12b4"},"cell_type":"code","source":"'''Function to plot recall vs precision curve.'''\ndef plot_precision_vs_recall(model, title):\n    from sklearn.metrics import precision_recall_curve\n    probablity = model.predict_proba(X_train)[:, 1]\n    plt.figure(figsize = (18, 5))\n    precision, recall, threshold = precision_recall_curve(y_train, probablity)\n    plt.plot(recall, precision, 'r-', lw = 3.7)\n    plt.ylabel('Recall')\n    plt.xlabel('Precision')\n    plt.axis([0, 1.5, 0, 1.5])\n    plt.title(title)\n    plt.show()\n\n'''Now plot recall vs precision curve of rf and gbc.'''\nplot_precision_vs_recall(rf, title = 'RF Precision-Recall Curve')\nplot_precision_vs_recall(gbc, title = 'GBC Precision-Recall Curve')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8aaa6322cc69da0b8ad4e7821f1aee0e0310ab47"},"cell_type":"markdown","source":"## ROC Curve & AUC Score"},{"metadata":{"trusted":false,"_uuid":"fa62811fc14b9f74530867122bd65cc8d4a02772"},"cell_type":"code","source":"'''Function to plot ROC curve with AUC score.'''\ndef plot_roc_and_auc_score(model, title):\n    from sklearn.metrics import roc_curve, roc_auc_score\n    probablity = model.predict_proba(X_train)[:, 1]\n    plt.figure(figsize = (18, 5))\n    false_positive_rate, true_positive_rate, threshold = roc_curve(y_train, probablity)\n    auc_score = roc_auc_score(y_train, probablity)\n    plt.plot(false_positive_rate, true_positive_rate, label = \"ROC CURVE, AREA = \"+ str(auc_score))\n    plt.plot([0, 1], [0, 1], 'red', lw = 3.7)\n    plt.xlabel('False Positive Rate (1-Specificity)')\n    plt.ylabel('True Positive Rate (Sensitivity)')\n    plt.axis([0, 1, 0, 1])\n    plt.legend(loc = 4)\n    plt.title(title)\n    plt.show()\n\n'''Plot roc curve and auc score for rf and gbc.'''\nplot_roc_and_auc_score(rf, title = 'RF ROC Curve with AUC Score')\nplot_roc_and_auc_score(gbc, title = 'GBC ROC Curve with AUC Score')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52b9527ec177e41a5c461d30d402af866c1d9c0c"},"cell_type":"markdown","source":"# Prediction & Submission"},{"metadata":{"trusted":false,"_uuid":"76482abda74fe4c8b198ed13d2f65f7ebfcb85ea"},"cell_type":"code","source":"'''Submission with the most accurate random forest classifier.'''\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": rf.predict(X_test)})\nsubmission.to_csv('submission_rf.csv', index = False)\n\n\n'''Submission with the most accurate gradient boosting classifier.'''\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": gbc.predict(X_test)})\nsubmission.to_csv('submission_gbc.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}