{"nbformat": 4, "cells": [{"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "330b779713868285eba5e84c33a8a88df07ccd6a", "_cell_guid": "94c90b14-9f92-48d1-9928-57720a119bfa", "collapsed": false}, "outputs": [], "cell_type": "markdown", "source": "This is my first kernel in Kaggle. As there are many kind & detail investigations on this, I tried not to be too much biased on storytelling & explanations for shorter notebook, hoping that code itself can be fairly enough explanations. "}, {"execution_count": null, "outputs": [], "source": "# Import necessaries, read files.\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Load the dataset\ntry:\n    train_data = pd.read_csv(\"../input/train.csv\")\n    train_label = train_data['Survived']\n    train_data.drop(['Survived'], axis = 1, inplace = True)\n    concat_set = pd.concat((train_data, pd.read_csv(\"../input/test.csv\"))).reset_index()\n    concat_set.drop(['PassengerId'], axis = 1, inplace = True) \n    print(\"Dataset has been loaded.\")\nexcept:\n    print(\"Dataset could not be loaded. Is the dataset missing?\")", "cell_type": "code", "metadata": {"_cell_guid": "4fd3f6c6-d8b3-416c-bde9-ea488f0b1965", "_uuid": "be3c9db730c8e2a8bdea826160dc6895b4d2f262", "trusted": false, "_execution_state": "idle"}}, {"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "253874989a829a9a69a5ec41246aa926d90e3963", "trusted": false, "_cell_guid": "262d94d8-7d37-40cc-8d60-805a9bd8c5a8", "collapsed": false}, "outputs": [], "cell_type": "code", "source": "# Dictionary for title mapping using names (Thanks to Ahmed BESBES).\nTitle_Dictionary = {\n                    \"Capt\":       \"Officer\",\n                    \"Col\":        \"Officer\",\n                    \"Major\":      \"Officer\",\n                    \"Jonkheer\":   \"Royalty\",\n                    \"Don\":        \"Royalty\",\n                    \"Sir\" :       \"Royalty\",\n                    \"Dr\":         \"Officer\",\n                    \"Rev\":        \"Officer\",\n                    \"the Countess\":\"Royalty\",\n                    \"Dona\":       \"Royalty\",\n                    \"Mme\":        \"Mrs\",\n                    \"Mlle\":       \"Miss\",\n                    \"Ms\":         \"Mrs\",\n                    \"Mr\" :        \"Mr\",\n                    \"Mrs\" :       \"Mrs\",\n                    \"Miss\" :      \"Miss\",\n                    \"Master\" :    \"Master\",\n                    \"Lady\" :      \"Royalty\"\n                    }"}, {"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "771a4d926d8a841ac22224d808fecbe2a85a4b0b", "trusted": false, "_cell_guid": "cdbea391-3ba7-4b2d-a1e5-2d7145286123", "collapsed": false}, "outputs": [], "cell_type": "code", "source": "# Data cleaning, by random generating, filling medians for missing rows, etc.\nage_avg \t   = concat_set['Age'].mean()\nage_std \t   = concat_set['Age'].std()\nage_null_count = concat_set['Age'].isnull().sum()\n\nage_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\nconcat_set['Age'][np.isnan(concat_set['Age'])] = age_null_random_list\nconcat_set['Age'] = concat_set['Age'].astype(int)    \nconcat_set['CategoricalAge'] = pd.cut(concat_set['Age'], 5)\n\nconcat_set['Fare'].fillna((concat_set['Fare'].median()), inplace=True)\nconcat_set['Embarked'].fillna('S', inplace=True)\nconcat_set['Title'] = concat_set['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\nconcat_set['Title'] = concat_set.Title.map(Title_Dictionary)\nconcat_set['FamilySize'] = concat_set['SibSp'] + concat_set['Parch'] + 1\nconcat_set['IsAlone'] = 0\nconcat_set.loc[concat_set['FamilySize'] == 1, 'IsAlone'] = 1\nconcat_set['CategoricalFare'] = pd.qcut(concat_set['Fare'], 4)\n\n# Feature Dropping\ndrop_elements = ['index','Name', 'Ticket', 'Cabin', 'SibSp','FamilySize', 'Parch', 'Fare', 'Age']\nconcat_set.drop(drop_elements, axis = 1, inplace=True)\n\n# Let's make it all numerical values (it's just my preference)\nfor feature in concat_set.keys():\n    concat_set[feature] = pd.Categorical(concat_set[feature]).codes "}, {"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "3e1f086cb37e868d1a0d059781ba1cb38b62ce5a", "trusted": false, "_cell_guid": "59788c81-6e2d-4bc0-8cb5-da4bebc1be70", "collapsed": false}, "outputs": [], "cell_type": "code", "source": "# This part is for classifier comparison (for model selection)\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    GaussianNB(),\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis(),\n    LogisticRegression()]\n\nlog_cols = [\"Classifier\", \"Accuracy\"]\nlog      = pd.DataFrame(columns=log_cols)\n\n\nsss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n\nX, y = concat_set[:891].values, train_label.values\n\nacc_dict = {}\n\nfor train_index, test_index in sss.split(X, y):\n\tX_train, X_test = X[train_index], X[test_index]\n\ty_train, y_test = y[train_index], y[test_index]\n\t\n\tfor clf in classifiers:\n\t\tname = clf.__class__.__name__\n\t\tclf.fit(X_train, y_train)\n\t\ttrain_predictions = clf.predict(X_test)\n\t\tacc = accuracy_score(y_test, train_predictions)\n\t\tif name in acc_dict:\n\t\t\tacc_dict[name] += acc\n\t\telse:\n\t\t\tacc_dict[name] = acc\n\nfor clf in acc_dict:\n\tacc_dict[clf] = acc_dict[clf] / 10.0\n\tlog_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=log_cols)\n\tlog = log.append(log_entry)\n\nplt.xlabel('Accuracy')\nplt.title('Classifier Accuracy')\n\nsns.set_color_codes(\"muted\")\nsns.barplot(x='Accuracy', y='Classifier', data=log, color=\"g\")"}, {"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "2f789613fe7a574f3e8400192fc4242fa8c6b10e", "trusted": false, "_cell_guid": "c2283454-25dd-4f28-8960-a7dee284713c", "collapsed": false}, "outputs": [], "cell_type": "code", "source": "# splitting the train & test data set\ntrain_X, train_Y = concat_set[:891], train_label\ntest_X = concat_set[891:]"}, {"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "e5e13681f2feb10a0cf7ad83027bbdbd22484b42", "trusted": false, "_cell_guid": "1444cfdc-11db-4589-b312-42fb0516039b", "collapsed": false}, "outputs": [], "cell_type": "code", "source": "# picked the best performing classifier.\nlogreg = SVC(probability=True)\nlogreg.fit(train_X, train_Y)"}, {"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "cff815d5dacd0680945fa2a6050f836e772b2174", "trusted": false, "_cell_guid": "0d47fab3-6d84-4fd9-9def-f989affcccf1", "collapsed": false}, "outputs": [], "cell_type": "code", "source": "# performance check\nfrom sklearn.model_selection import cross_val_score\ncross_val_score(logreg, train_X, train_Y, cv=10).mean()"}, {"execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "3851832e7ff0db0cf84575a16878e09940ca3e57", "trusted": false, "_cell_guid": "b3ac7d35-e2c8-47a2-a9b4-a71d1468793e", "collapsed": false}, "outputs": [], "cell_type": "code", "source": "# write a result file\nf = open('SVC_DataCleaning_FeatureTransformation_Numericalized.csv', 'w')\nf.write('PassengerId,Survived\\n')\nfor i, v in enumerate(logreg.predict(test_X)):\n    f.write(str(i+892)+','+str(v)+'\\n')\nf.close()"}, {"cell_type": "markdown", "outputs": [], "source": "Thanks for reading this kernel. Let me know if there's anything ambiguous/unclear point here. Glad to hear.", "execution_count": null, "metadata": {"_uuid": "adc3e970edae321797539cba32c1e62032391022", "_execution_state": "idle", "collapsed": false}}], "nbformat_minor": 0, "metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "mimetype": "text/x-python", "version": "3.6.1", "file_extension": ".py", "name": "python", "pygments_lexer": "ipython3"}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}}