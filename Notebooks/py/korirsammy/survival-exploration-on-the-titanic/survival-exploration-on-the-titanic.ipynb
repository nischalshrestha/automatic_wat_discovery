{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9b5639ab-8b4e-65ba-e205-88b34d72cf54"
      },
      "source": [
        "# Objective\n",
        "\n",
        "The main objective of this data exploration is to predict the survival or the death of a given passenger based on a set of variables such as age and gender."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c0f1b3b4-fd26-f712-74a6-b5605f2537a1"
      },
      "source": [
        "# 2. Data Exploration\n",
        "\n",
        "# 2.1  Import Important Libraries\n",
        "\n",
        " We need to import python libraries with all the functionality that we will need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "da556e59-f4bc-c006-9a63-67bd63f984dd"
      },
      "outputs": [],
      "source": [
        "# remove warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Import Important Libraries\n",
        "import numpy as np # linear algebra\n",
        "\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "pd.options.display.max_columns = 100\n",
        "\n",
        "# Modelling Algorithms\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\n",
        "# Modelling Helpers\n",
        "from sklearn.preprocessing import Imputer , Normalizer , scale\n",
        "from sklearn.cross_validation import train_test_split , StratifiedKFold\n",
        "from sklearn.feature_selection import RFECV\n",
        "\n",
        "# Visualisation\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as pylab\n",
        "import seaborn as sns\n",
        "\n",
        "# Configure visualisations\n",
        "%matplotlib inline\n",
        "mpl.style.use( 'ggplot' )\n",
        "sns.set_style( 'white' )\n",
        "pylab.rcParams[ 'figure.figsize' ] = 8 , 6\n",
        "pd.options.display.max_rows = 100\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# The script below lists all  the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "96991293-6da5-9ead-cb6b-441aa66646af"
      },
      "source": [
        "# 2.2 Helper functions setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fda8d0d0-89f2-42f5-e66a-54a6ff119022"
      },
      "outputs": [],
      "source": [
        "def plot_histograms( df , variables , n_rows , n_cols ):\n",
        "    fig = plt.figure( figsize = ( 16 , 12 ) )\n",
        "    for i, var_name in enumerate( variables ):\n",
        "        ax=fig.add_subplot( n_rows , n_cols , i+1 )\n",
        "        df[ var_name ].hist( bins=10 , ax=ax )\n",
        "        ax.set_title( 'Skew: ' + str( round( float( df[ var_name ].skew() ) , ) ) ) # + ' ' + var_name ) #var_name+\" Distribution\")\n",
        "        ax.set_xticklabels( [] , visible=False )\n",
        "        ax.set_yticklabels( [] , visible=False )\n",
        "    fig.tight_layout()  # Improves appearance a bit.\n",
        "    plt.show()\n",
        "\n",
        "def plot_distribution( df , var , target , **kwargs ):\n",
        "    row = kwargs.get( 'row' , None )\n",
        "    col = kwargs.get( 'col' , None )\n",
        "    facet = sns.FacetGrid( df , hue=target , aspect=4 , row = row , col = col )\n",
        "    facet.map( sns.kdeplot , var , shade= True )\n",
        "    facet.set( xlim=( 0 , df[ var ].max() ) )\n",
        "    facet.add_legend()\n",
        "\n",
        "def plot_categories( df , cat , target , **kwargs ):\n",
        "    row = kwargs.get( 'row' , None )\n",
        "    col = kwargs.get( 'col' , None )\n",
        "    facet = sns.FacetGrid( df , row = row , col = col )\n",
        "    facet.map( sns.barplot , cat , target )\n",
        "    facet.add_legend()\n",
        "\n",
        "def plot_correlation_map( df ):\n",
        "    corr = titanic.corr()\n",
        "    _ , ax = plt.subplots( figsize =( 12 , 10 ) )\n",
        "    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n",
        "    _ = sns.heatmap(\n",
        "        corr, \n",
        "        cmap = cmap,\n",
        "        square=True, \n",
        "        cbar_kws={ 'shrink' : .9 }, \n",
        "        ax=ax, \n",
        "        annot = True, \n",
        "        annot_kws = { 'fontsize' : 12 }\n",
        "    )\n",
        "\n",
        "def describe_more( df ):\n",
        "    var = [] ; l = [] ; t = []\n",
        "    for x in df:\n",
        "        var.append( x )\n",
        "        l.append( len( pd.value_counts( df[ x ] ) ) )\n",
        "        t.append( df[ x ].dtypes )\n",
        "    levels = pd.DataFrame( { 'Variable' : var , 'Levels' : l , 'Datatype' : t } )\n",
        "    levels.sort_values( by = 'Levels' , inplace = True )\n",
        "    return levels\n",
        "\n",
        "def plot_variable_importance( X , y ):\n",
        "    tree = DecisionTreeClassifier( random_state = 99 )\n",
        "    tree.fit( X , y )\n",
        "    plot_model_var_imp( tree , X , y )\n",
        "    \n",
        "def plot_model_var_imp( model , X , y ):\n",
        "    imp = pd.DataFrame( \n",
        "        model.feature_importances_  , \n",
        "        columns = [ 'Importance' ] , \n",
        "        index = X.columns \n",
        "    )\n",
        "    imp = imp.sort_values( [ 'Importance' ] , ascending = True )\n",
        "    imp[ : 10 ].plot( kind = 'barh' )\n",
        "    print (model.score( X , y ))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1374d926-ef26-50d5-6c2b-b693d28c6651"
      },
      "source": [
        "# Available Data\n",
        "\n",
        "There are two datasets available; a training set and a test set. We build predictive model using the training data set, and evaluate our model using the test dataset .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8eb6350a-08f9-87b2-2a80-ed2a83a06236"
      },
      "source": [
        "# 2.3  Load training and test data sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1cf22782-73c1-6bc3-84a3-c7d9b6c13fcf"
      },
      "outputs": [],
      "source": [
        "# get titanic & test csv files as a DataFrame\n",
        "train = pd.read_csv(\"../input/train.csv\")\n",
        "test    = pd.read_csv(\"../input/test.csv\")\n",
        "\n",
        "full = train.append( test , ignore_index = True )\n",
        "titanic = full[ :891 ]\n",
        "\n",
        "del train , test\n",
        "\n",
        "print ('Datasets:' , 'full:' , full.shape , 'titanic:' , titanic.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "47be4ecc-3f3b-e447-a005-2476b2790642"
      },
      "source": [
        "# 2.4 Statistics and visualisations\n",
        "\n",
        "For better understanding of our data,we consider some important facts about various variables including their relationship with the target variable. In this case, our target variable is survival.\n",
        "\n",
        "Let's begin by having a look at our data. Pandas allows us to have a sneak peak at our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "530fdbf6-8e67-8129-d693-890ac8519b9a"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "titanic.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0c3f0794-36ab-aa38-55f5-73cde8ef00f7"
      },
      "source": [
        "# 2.4.1  Check some key information about the variables\n",
        "\n",
        "Survived column is our target variable. The value 1 indicates that the passenger survived and 0 means that the passenger died.\n",
        "\n",
        "\n",
        "\n",
        "Other descriptive variables are:\n",
        " 1. Age\n",
        " 2. List item\n",
        " 3. Sex\n",
        " 4. PassengerId: and id given to each traveler on the boat\n",
        " 5. Pclass: the passenger class. It has three possible values: 1,2,3\n",
        " 6. Name\n",
        " 7. SibSp: number of siblings and spouses traveling with the passenger\n",
        " 8. Parch: number of parents and children traveling with the passenger\n",
        " 9. The ticket number\n",
        " 10. The ticket Fare\n",
        " 11. The cabin number\n",
        " 12. The embarkation. Which has three possible values S,C,Q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "76a729ee-d3d0-c7e2-c069-51f28c6f766f"
      },
      "outputs": [],
      "source": [
        "titanic.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d2e5f91c-3464-73af-cc3e-f5cdabc63f45"
      },
      "source": [
        "# Check if there are null values in Age column. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "580eef95-87de-22d0-c378-492e29a88e95"
      },
      "outputs": [],
      "source": [
        "sum(pd.isnull(titanic['Age']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c0db82c6-9a5d-228e-aeca-7008d526b71b"
      },
      "source": [
        "We find that there are 177 values missing the Age column.This needs to be fixed in order to avoid errors later\n",
        "\n",
        "To fix this, we  replace the null values with the median age which is more robust to outliers than the mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cea82950-3bd9-2380-88f9-9c9ad9fe82df"
      },
      "outputs": [],
      "source": [
        "titanic['Age'].fillna(titanic['Age'].median(), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1e7ffe3a-b8e1-3205-cc4f-917e0836721b"
      },
      "source": [
        "# 2.4.2 Plot a heatmap \n",
        "\n",
        "This will help us to determine the most important variables in our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2c599ae0-1e53-98b7-9b3c-27554db8b973"
      },
      "outputs": [],
      "source": [
        "plot_correlation_map( titanic )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "eeaad6f5-ad65-57d9-06f2-6180e6de135c"
      },
      "source": [
        "# 2.4.3  Further Analysis\n",
        "\n",
        "Explore the relationship between features and survival of passengers.\n",
        "\n",
        "Check the relationship between age and survival."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2d04e3d2-1c66-03cd-5443-e8f563e46290"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plot distributions of Age of passangers who survived or did not survive\n",
        "plot_distribution( titanic , var = 'Age' , target = 'Survived' , row = 'Sex' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b96666b1-a89d-91a8-3f28-41ee14632375"
      },
      "source": [
        "# Visualize survival based on the gender."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f30a65e9-25fe-e3e2-0c5a-3e48865ae26f"
      },
      "outputs": [],
      "source": [
        "survived_sex = titanic[titanic['Survived']==1]['Sex'].value_counts()\n",
        "dead_sex = titanic[titanic['Survived']==0]['Sex'].value_counts()\n",
        "df = pd.DataFrame([survived_sex,dead_sex])\n",
        "df.index = ['Survived','Dead']\n",
        "df.plot(kind='bar',stacked=True, figsize=(15,8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "99b172e6-2876-7a51-9c55-e4d923ad23ca"
      },
      "source": [
        "Sex variable seems to be an important feature. More women were more likely to survive than men."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "15ca474b-d32e-3686-8c35-7c4757b58348"
      },
      "source": [
        "# Correlate the survival with the age variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "345cdd11-3823-a8ee-6029-31f43a67da8e"
      },
      "outputs": [],
      "source": [
        "figure = plt.figure(figsize=(15,8))\n",
        "plt.hist([titanic[titanic['Survived']==1]['Age'],titanic[titanic['Survived']==0]['Age']], stacked=True, color = ['g','r'],\n",
        "         bins = 30,label = ['Survived','Dead'])\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Number of passengers')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8ba1588b-4b92-2d97-0630-4541e99f30ec"
      },
      "source": [
        "We can see that passengers who were less than 10 were more likely to survive than older passengers of ages between 12 and  50. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4b283a4b-f116-5e94-17b6-ca30602066ad"
      },
      "source": [
        "# Investigate numeric variables\n",
        "\n",
        "Plot the distributions of Fare of passengers who survived or did not survive.This could be a good predictive variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "50130135-d8c0-bed5-6c71-340551b73aaf"
      },
      "outputs": [],
      "source": [
        "figure = plt.figure(figsize=(15,8))\n",
        "plt.hist([titanic[titanic['Survived']==1]['Fare'],titanic[titanic['Survived']==0]['Fare']], stacked=True, color = ['g','r'],\n",
        "         bins = 30,label = ['Survived','Dead'])\n",
        "plt.xlabel('Fare')\n",
        "plt.ylabel('Number of passengers')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "79b873cb-165c-109f-5851-ea7687bd47d5"
      },
      "source": [
        "We can observe that Passengers with cheaper ticket fares were more likely to die. In other words , passengers with more expensive tickets, seemed to have been rescued first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c8b3856b-e268-908d-d742-6fc5ad9f14a2"
      },
      "source": [
        "# Combine Age, Fare, and Survival variables in a single chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d2d207a2-d523-07c2-0af5-9b0e532b4d7c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "ax = plt.subplot()\n",
        "ax.scatter(titanic[titanic['Survived']==1]['Age'],titanic[titanic['Survived']==1]['Fare'],c='green',s=40)\n",
        "ax.scatter(titanic[titanic['Survived']==0]['Age'],titanic[titanic['Survived']==0]['Fare'],c='red',s=40)\n",
        "ax.set_xlabel('Age')\n",
        "ax.set_ylabel('Fare')\n",
        "ax.legend(('survived','dead'),scatterpoints=1,loc='upper right',fontsize=15,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "694f5cc0-80a4-dd91-390c-16e77d13bf8c"
      },
      "source": [
        "A distinct cluster of dead passengers (the red one) appears on the chart. Those people are adults (aged between 15 and 50) of lower class (lowest ticket fares).\n",
        "In fact, the ticket fare correlates with the class as we see it in the chart below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a0b4440c-3e39-f535-e5d6-ab2951ab5a29"
      },
      "outputs": [],
      "source": [
        "ax = plt.subplot()\n",
        "ax.set_ylabel('Average fare')\n",
        "titanic.groupby('Pclass').mean()['Fare'].plot(kind='bar',figsize=(15,8), ax = ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6c3e5212-7b21-b48a-2ab3-06a296b2dfcd"
      },
      "source": [
        "Now let's  see how the embarkation sites affected survival."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "48d63c96-f8db-8085-5c2c-3ed38f797df5"
      },
      "outputs": [],
      "source": [
        "survived_embark = titanic[titanic['Survived']==1]['Embarked'].value_counts()\n",
        "dead_embark = titanic[titanic['Survived']==0]['Embarked'].value_counts()\n",
        "df = pd.DataFrame([survived_embark,dead_embark])\n",
        "df.index = ['Survived','Dead']\n",
        "df.plot(kind='bar',stacked=True, figsize=(15,8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b0b93056-76f9-c1c4-9c16-b29d0a8e8c74"
      },
      "source": [
        "We can observe that there is no distinct correlation between embarkation and survival "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3a6248b8-43a1-0940-797a-c5e7ac81312f"
      },
      "source": [
        "# Investigating categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a357bcd1-2ac3-c690-1da4-23f2ddb00bfc"
      },
      "outputs": [],
      "source": [
        "# Plot distributions of Fare of passangers who survived or did not survive\n",
        "plot_categories( titanic , cat = 'Fare' , target = 'Survived' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "deacd330-2335-ce86-b64f-29fb6080abcc"
      },
      "outputs": [],
      "source": [
        "# Plot survival rate by Embarked\n",
        "plot_categories( titanic , cat = 'Embarked' , target = 'Survived' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f2089619-35be-cd25-6560-cbe4e43fc693"
      },
      "outputs": [],
      "source": [
        "# Plot survival rate by Sex\n",
        "plot_categories( titanic , cat = 'Sex' , target = 'Survived' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dceffb37-c918-3210-4b13-ee85d92a1de8"
      },
      "outputs": [],
      "source": [
        "# Plot survival rate by Pclass\n",
        "plot_categories( titanic , cat = 'Pclass' , target = 'Survived' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c45ad2c0-93ec-2773-1d4c-ceab9f92f0b0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plot survival rate by SibSp\n",
        "plot_categories( titanic , cat = 'SibSp' , target = 'Survived' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "68dc9713-885a-7016-6a2f-831e4ba8ca7f"
      },
      "outputs": [],
      "source": [
        "# Plot survival rate by Parch\n",
        "plot_categories( titanic , cat = 'Parch' , target = 'Survived' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a4f102da-8704-ca96-731d-c46f135f9f08"
      },
      "source": [
        "# 3. Feature engineering\n",
        "\n",
        "From previous observations, we noticed some interesting correlations between variables. However, we could not analyze more some features like the names or the tickets because these features requires further processing. In the next section we will transform these specific features so that they can easily fed into machine learning algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "36aeba43-13c5-ed68-886e-acbdb4db2a07"
      },
      "source": [
        "# 3.1  Transform Categorical variables into numeric variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "155b83df-8a93-3ea0-d7a1-0130652224c3"
      },
      "source": [
        " Transform Categorical variables into numeric variables\n",
        "\n",
        "But first, let's define a print function that asserts whether or not a feature has been processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dd57dbf8-5aa8-00d1-f53b-9875925c7a67"
      },
      "outputs": [],
      "source": [
        "# Define a function that check if a feature has been processed or not\n",
        "def status(feature):\n",
        "    print ('Processing',feature,': ok')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "281735c5-70d7-b89f-7804-450b07a3c62c"
      },
      "source": [
        "# 3.2 Combine training and test data sets\n",
        "It is always advisable to combine the training data set and the test data sets. This is particularly useful especially if your test data set appears to have a feature that doesn't exist in the training set. Therefore, if we don't combine the two sets, testing our model on the test set will fail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "68fefdda-fe60-1329-2b41-b8f45619eb1f"
      },
      "outputs": [],
      "source": [
        "def get_combined_data():\n",
        "    # reading train data\n",
        "    train = pd.read_csv('../input/train.csv')\n",
        "    \n",
        "    # reading test data\n",
        "    test = pd.read_csv('../input/test.csv')\n",
        "\n",
        "    # extracting and then removing the targets from the training data \n",
        "    targets = train.Survived\n",
        "    train.drop('Survived',1,inplace=True)\n",
        "    \n",
        "\n",
        "    # merging train data and test data for future feature engineering\n",
        "    combined = train.append(test)\n",
        "    combined.reset_index(inplace=True)\n",
        "    combined.drop('index',inplace=True,axis=1)\n",
        "    \n",
        "    return combined\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "497739be-e989-4b1c-15c0-abfcf9ad8a5b"
      },
      "outputs": [],
      "source": [
        "combined = get_combined_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6e0d9aa4-39f7-5edc-d67a-807d62d0bc0b"
      },
      "outputs": [],
      "source": [
        "combined.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9588e8a3-79ab-de16-409b-e17e3f83d7b8"
      },
      "source": [
        "# 3.3 Extracting the passenger titles\n",
        "\n",
        "The names variable has some additional information that can help us determine the social status of a passenger. For example, a name with a title such as \u201cPeter, Master. Michael J\u201d can tell us that the passenger is a master. We therefore need to we introduce additional information about the social status of a passenger by simply parsing the name and extracting its title."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ff9b9c57-9f79-ba8c-0a24-8bffb0d3fb6c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to parse and exract titles from passanger names\n",
        "def get_titles():\n",
        "\n",
        "    global combined\n",
        "    \n",
        "    # we extract the title from each name\n",
        "    combined['Title'] = combined['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
        "    \n",
        "    # a map of more aggregated titles\n",
        "    Title_Dictionary = {\n",
        "                        \"Capt\":       \"Officer\",\n",
        "                        \"Col\":        \"Officer\",\n",
        "                        \"Major\":      \"Officer\",\n",
        "                        \"Jonkheer\":   \"Royalty\",\n",
        "                        \"Don\":        \"Royalty\",\n",
        "                        \"Sir\" :       \"Royalty\",\n",
        "                        \"Dr\":         \"Officer\",\n",
        "                        \"Rev\":        \"Officer\",\n",
        "                        \"the Countess\":\"Royalty\",\n",
        "                        \"Dona\":       \"Royalty\",\n",
        "                        \"Mme\":        \"Mrs\",\n",
        "                        \"Mlle\":       \"Miss\",\n",
        "                        \"Ms\":         \"Mrs\",\n",
        "                        \"Mr\" :        \"Mr\",\n",
        "                        \"Mrs\" :       \"Mrs\",\n",
        "                        \"Miss\" :      \"Miss\",\n",
        "                        \"Master\" :    \"Master\",\n",
        "                        \"Lady\" :      \"Royalty\"\n",
        "\n",
        "                        }\n",
        "    \n",
        "    # we map each title\n",
        "    combined['Title'] = combined.Title.map(Title_Dictionary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5c56fe56-9990-0113-2e71-b27b0bf649fc"
      },
      "source": [
        "The above function parses the names and extracts titles from passenger names. It then maps the extracted titles to categories of titles we selected : Officer,Royalty,Mr,Mrs,Miss, and Master."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "02f37133-f29c-111c-53e7-e4119077eec7"
      },
      "outputs": [],
      "source": [
        "# Check the new titles feature\n",
        "get_titles()\n",
        "combined.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c6aaac4c-0d4b-c8f9-b56d-6de9166a31eb"
      },
      "source": [
        "# 3.4 Processing Age\n",
        "\n",
        "We noticed earlier that Age variable was missing 177 values. We fixed this issue by replacing the missing values with the median age. This is not be the best solution because age may differ between groups and categories of passengers.\n",
        "\n",
        "To illustrate this, let's group our data by sex, Title, and passenger class and for each subset and compute the median age."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d5ed024a-ccf1-a6dc-6f57-aaf343d257ef"
      },
      "outputs": [],
      "source": [
        "grouped = combined.groupby(['Sex','Pclass','Title'])\n",
        "grouped.median()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6eb19b24-2a13-c0cd-6995-8912b07a9f23"
      },
      "source": [
        "From the above data, it is clear that the median age in the Age column is different based on the Sex, Pclass, and Title put together.\n",
        "\n",
        "For example, if the passenger is female, from Pclass 1, with royalty title, the median age is 39.Whereas if the passenger is male, from Pclass 3, with a title Mr., the median age is 26.\n",
        "\n",
        "We therefore create a function that fills in the missing age in the combined data set based on the different attributes of the passengers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "90853602-160a-1dfa-8e91-46fbfd37cdb9"
      },
      "outputs": [],
      "source": [
        "def process_age():\n",
        "    \n",
        "    global combined\n",
        "    \n",
        "    # a function that fills the missing values of the Age variable\n",
        "    \n",
        "    def fillAges(row):\n",
        "        if row['Sex']=='female' and row['Pclass'] == 1:\n",
        "            if row['Title'] == 'Miss':\n",
        "                return 30\n",
        "            elif row['Title'] == 'Mrs':\n",
        "                return 45\n",
        "            elif row['Title'] == 'Officer':\n",
        "                return 49\n",
        "            elif row['Title'] == 'Royalty':\n",
        "                return 39\n",
        "\n",
        "        elif row['Sex']=='female' and row['Pclass'] == 2:\n",
        "            if row['Title'] == 'Miss':\n",
        "                return 20\n",
        "            elif row['Title'] == 'Mrs':\n",
        "                return 30\n",
        "\n",
        "        elif row['Sex']=='female' and row['Pclass'] == 3:\n",
        "            if row['Title'] == 'Miss':\n",
        "                return 18\n",
        "            elif row['Title'] == 'Mrs':\n",
        "                return 31\n",
        "\n",
        "        elif row['Sex']=='male' and row['Pclass'] == 1:\n",
        "            if row['Title'] == 'Master':\n",
        "                return 6\n",
        "            elif row['Title'] == 'Mr':\n",
        "                return 41.5\n",
        "            elif row['Title'] == 'Officer':\n",
        "                return 52\n",
        "            elif row['Title'] == 'Royalty':\n",
        "                return 40\n",
        "\n",
        "        elif row['Sex']=='male' and row['Pclass'] == 2:\n",
        "            if row['Title'] == 'Master':\n",
        "                return 2\n",
        "            elif row['Title'] == 'Mr':\n",
        "                return 30\n",
        "            elif row['Title'] == 'Officer':\n",
        "                return 41.5\n",
        "\n",
        "        elif row['Sex']=='male' and row['Pclass'] == 3:\n",
        "            if row['Title'] == 'Master':\n",
        "                return 6\n",
        "            elif row['Title'] == 'Mr':\n",
        "                return 26\n",
        "    \n",
        "    combined.Age = combined.apply(lambda r : fillAges(r) if np.isnan(r['Age']) else r['Age'], axis=1)\n",
        "    \n",
        "    status('age')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e8e55e36-3e6d-5896-e3bc-bb61656ceafd"
      },
      "outputs": [],
      "source": [
        "process_age()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "15ce0538-31b7-21a4-a626-1f99d0aa22a0"
      },
      "outputs": [],
      "source": [
        "combined.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "dae16cd2-56e4-71d9-741b-187df1a1e7b5"
      },
      "source": [
        "We can see that the missing ages have been replaced. However, we notice a missing value in Fare, two missing values in Embarked and a lot of missing values in Cabin. We'll come back to these variables later.\n",
        "\n",
        "Let's now process the names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ddb0c259-9003-4b9a-5656-53d8357f4ac4"
      },
      "outputs": [],
      "source": [
        "def process_names():\n",
        "    \n",
        "    global combined\n",
        "    # we clean the Name variable\n",
        "    combined.drop('Name',axis=1,inplace=True)\n",
        "    \n",
        "    # encoding in dummy variable\n",
        "    titles_dummies = pd.get_dummies(combined['Title'],prefix='Title')\n",
        "    combined = pd.concat([combined,titles_dummies],axis=1)\n",
        "    \n",
        "    # removing the title variable\n",
        "    combined.drop('Title',axis=1,inplace=True)\n",
        "    \n",
        "    status('names')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "01678493-8fc9-f6d8-64c0-fb9f097f2b0e"
      },
      "source": [
        "The above function drops the Name column since we won't be using it anymore because we created a Title column.\n",
        "\n",
        "It then we encodes the title values using a dummy encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2ad9ae16-df39-6b07-8490-0341c6d911b2"
      },
      "outputs": [],
      "source": [
        "process_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1d308986-bbcb-b4aa-2eae-d8050b1eca65"
      },
      "outputs": [],
      "source": [
        "combined.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "66c32210-892a-c0af-80e4-b7ed73b6828c"
      },
      "source": [
        "# 3.5 Processing Fare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f3c48984-e73e-b4c1-ca28-e62a609442f6"
      },
      "outputs": [],
      "source": [
        "#This function  replaces one missing Fare value by the mean\n",
        "def process_fares():\n",
        "    \n",
        "    global combined\n",
        "    # there's one missing fare value - replacing it with the mean.\n",
        "    combined.Fare.fillna(combined.Fare.mean(),inplace=True)\n",
        "    \n",
        "    status('fare')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "abfd3c02-2b8c-1341-d6f7-8fa38af919ae"
      },
      "outputs": [],
      "source": [
        "process_fares()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ac31a2ac-7cc9-a81b-53f3-3590558f2b8c"
      },
      "source": [
        "# 3.6 Processing Embarked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2e4b28e2-fc79-a41c-930d-1f8694c607bb"
      },
      "outputs": [],
      "source": [
        "# This functions replaces the two missing values of Embarked with the most frequent Embarked value.\n",
        "def process_embarked():\n",
        "    \n",
        "    global combined\n",
        "    # two missing embarked values - filling them with the most frequent one (S)\n",
        "    combined.Embarked.fillna('S',inplace=True)\n",
        "    \n",
        "    # dummy encoding \n",
        "    embarked_dummies = pd.get_dummies(combined['Embarked'],prefix='Embarked')\n",
        "    combined = pd.concat([combined,embarked_dummies],axis=1)\n",
        "    combined.drop('Embarked',axis=1,inplace=True)\n",
        "    \n",
        "    status('embarked')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "26f33a5b-b62f-c221-4cf4-fa617f958014"
      },
      "outputs": [],
      "source": [
        "process_embarked()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "73970a26-71af-d93c-d001-5f81385a3022"
      },
      "source": [
        "# 3.7 Processing Cabin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "42e42fd3-02c6-5430-fb48-61cc33f24ef1"
      },
      "outputs": [],
      "source": [
        "# This function replaces NaN values with U (for Unknow). \n",
        "# It then maps each Cabin value to the first letter. \n",
        "#Then it encodes the cabin values using dummy encoding .\n",
        "def process_cabin():\n",
        "    \n",
        "    global combined\n",
        "    \n",
        "    # replacing missing cabins with U (for Uknown)\n",
        "    combined.Cabin.fillna('U',inplace=True)\n",
        "    \n",
        "    # mapping each Cabin value with the cabin letter\n",
        "    combined['Cabin'] = combined['Cabin'].map(lambda c : c[0])\n",
        "    \n",
        "    # dummy encoding ...\n",
        "    cabin_dummies = pd.get_dummies(combined['Cabin'],prefix='Cabin')\n",
        "    \n",
        "    combined = pd.concat([combined,cabin_dummies],axis=1)\n",
        "    \n",
        "    combined.drop('Cabin',axis=1,inplace=True)\n",
        "    \n",
        "    status('cabin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e2407599-d71f-39ee-bc41-14596107bf46"
      },
      "outputs": [],
      "source": [
        "process_cabin()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "77028313-9f96-efb8-2285-fe429d6cf7af"
      },
      "outputs": [],
      "source": [
        "combined.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "32f20c70-fb5f-8009-d15a-4ddfc817fce8"
      },
      "source": [
        "We can see that we don't have a ny missing values now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "12f8a42b-6e46-7fc1-d450-a18adb438c0e"
      },
      "outputs": [],
      "source": [
        "combined.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0848915a-25b3-cc74-85d9-55a431c5cea6"
      },
      "source": [
        "# 3.8 Processing Sex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e5b8290f-a501-ab64-7e19-d15fe6144d66"
      },
      "outputs": [],
      "source": [
        "#This function maps the string values male and female to 1 and 0 respectively.\n",
        "def process_sex():\n",
        "    \n",
        "    global combined\n",
        "    # mapping string values to numerical one \n",
        "    combined['Sex'] = combined['Sex'].map({'male':1,'female':0})\n",
        "    \n",
        "    status('sex')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1f2ea287-81d1-bb91-8504-ec3fdb14c625"
      },
      "outputs": [],
      "source": [
        "process_sex()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "69e0dfb2-eb43-052d-23ea-c440a165aa4a"
      },
      "source": [
        "# 3.9 Processing Pclass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d34f18a0-5ce9-f47b-a451-aed6b68f07e1"
      },
      "outputs": [],
      "source": [
        "# This function encodes the values of Pclass (1,2,3) using a dummy encoding.\n",
        "def process_pclass():\n",
        "    \n",
        "    global combined\n",
        "    # encoding into 3 categories:\n",
        "    pclass_dummies = pd.get_dummies(combined['Pclass'],prefix=\"Pclass\")\n",
        "    \n",
        "    # adding dummy variables\n",
        "    combined = pd.concat([combined,pclass_dummies],axis=1)\n",
        "    \n",
        "    # removing \"Pclass\"\n",
        "    \n",
        "    combined.drop('Pclass',axis=1,inplace=True)\n",
        "    \n",
        "    status('pclass')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e1c58701-92d1-093d-6202-250f0750c3be"
      },
      "outputs": [],
      "source": [
        "process_pclass()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "50f7cabd-718d-f34b-165a-6bf3c6aebf69"
      },
      "source": [
        "# 3.10 Processing Ticket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "200d931a-6549-26a6-f280-bb43b01e0977"
      },
      "outputs": [],
      "source": [
        "def process_ticket():\n",
        "    \n",
        "    global combined\n",
        "    \n",
        "    # a function that extracts each prefix of the ticket, returns 'XXX' if no prefix (i.e the ticket is a digit)\n",
        "    def cleanTicket(ticket):\n",
        "        ticket=''\n",
        "        ticket = ticket.replace('.','')\n",
        "        ticket = ticket.replace('/','')\n",
        "        ticket = ticket.split()\n",
        "        ticket = map(lambda t : t.strip() , ticket)\n",
        "        ticket = list(filter(lambda t : not t.isdigit(), ticket))       \n",
        "        if len(ticket) > 0:\n",
        "            return ticket[0]\n",
        "        else: \n",
        "            return 'XXX'\n",
        "    \n",
        "\n",
        "    # Extracting dummy variables from tickets:\n",
        "\n",
        "    combined['Ticket'] = combined['Ticket'].map(cleanTicket)\n",
        "    tickets_dummies = pd.get_dummies(combined['Ticket'],prefix='Ticket')\n",
        "    combined = pd.concat([combined, tickets_dummies],axis=1)\n",
        "    combined.drop('Ticket',inplace=True,axis=1)\n",
        "\n",
        "    status('ticket')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f8560ef6-42f8-4334-e8f0-3d6c209af707"
      },
      "outputs": [],
      "source": [
        "process_ticket()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b3d54de1-6136-198f-58f8-f70fc43f28da"
      },
      "source": [
        "# 3.11 Processing Family\n",
        "This part includes creating new variables based on the size of the family.\n",
        "\n",
        "We create these variable with the assumption that large families are grouped together, hence they are more likely to get rescued than people traveling alone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0dafe670-bf50-4acf-bb27-bf57163de3c5"
      },
      "source": [
        "The above function introduces 4 new features;\n",
        "\n",
        " 1. FamilySize : the total number of relatives including the passenger (him/her)self.\n",
        " 2. Sigleton : a boolean variable that describes families of size = 1\n",
        " 3. SmallFamily : a boolean variable that describes families of 2 <= size <= 4\n",
        " 4. LargeFamily : a boolean variable that describes families of 5 < size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e0547f3f-aa1b-bafb-d57b-5b6ced89aeac"
      },
      "outputs": [],
      "source": [
        "def process_family():\n",
        "    \n",
        "    global combined\n",
        "    # introducing a new feature : the size of families (including the passenger)\n",
        "    combined['FamilySize'] = combined['Parch'] + combined['SibSp'] + 1\n",
        "    \n",
        "    # introducing other features based on the family size\n",
        "    combined['Singleton'] = combined['FamilySize'].map(lambda s : 1 if s == 1 else 0)\n",
        "    combined['SmallFamily'] = combined['FamilySize'].map(lambda s : 1 if 2<=s<=4 else 0)\n",
        "    combined['LargeFamily'] = combined['FamilySize'].map(lambda s : 1 if 5<=s else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bd8f1fa3-2d72-4dd0-5b9c-8c7a071f7e7d"
      },
      "outputs": [],
      "source": [
        "process_family()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fa41b026-93dc-a471-25d6-331ef867b82f"
      },
      "outputs": [],
      "source": [
        "combined.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ac9db483-2ab1-4c20-97cf-9181e36765be"
      },
      "source": [
        "We end up with a total of 68 features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "43ef77ae-ec99-71a4-5909-95bebf67132c"
      },
      "outputs": [],
      "source": [
        "combined.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f8a5adf2-a869-738c-4142-4c7b58c44fda"
      },
      "source": [
        "As you can see, the features range in different intervals. Let's normalize all of them in the unit interval. All of them except the PassengerId that we'll need for the submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8eb0a094-7961-25df-9a3a-c81ef26ef4a7"
      },
      "outputs": [],
      "source": [
        "def scale_all_features():\n",
        "    \n",
        "    global combined\n",
        "    \n",
        "    features = list(combined.columns)\n",
        "    features.remove('PassengerId')\n",
        "    combined[features] = combined[features].apply(lambda x: x/x.max(), axis=0)\n",
        "    \n",
        "    print ('Features scaled successfully !')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fff76352-a718-1280-0d18-270ff09a1b54"
      },
      "outputs": [],
      "source": [
        "scale_all_features()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0db92a9a-dcce-25ed-bb05-1fa861e46c0c"
      },
      "source": [
        "# 4. Modeling\n",
        "\n",
        "In this part, we use our knowledge of the passengers based on the features we created and then build a statistical model. You can think of this model as a black box that crunches the information of any new passenger and decides whether or not he survives.\n",
        "There is a wide range of models to use, from logistic regression to decision trees and more sophisticated ones such as random forests and gradient boosted trees.\n",
        "\n",
        "We'll be using Random Forests because ensemble methods work well with most machine learning problem. Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set.\n",
        "\n",
        "Back to our problem, we now have to:\n",
        "\n",
        " 1. Break the combined dataset in train set and test set.\n",
        " 2. Use the train set to build a predictive model.\n",
        " 3. Evaluate the model using the train set.\n",
        " 4. Test the model using the test set and generate and output file for the submission.\n",
        "\n",
        "Let's start by importing the useful libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aae3fbb0-e39c-7dbb-001f-c7eecd2e94d3"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.cross_validation import StratifiedKFold\n",
        "from sklearn.grid_search import GridSearchCV\n",
        "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
        "from sklearn.cross_validation import cross_val_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d43df45d-8def-a02c-a616-21a5cd5cfe92"
      },
      "source": [
        "To evaluate our model we'll be using a 5-fold cross validation with the Accuracy metric.\n",
        "\n",
        "To do that, we'll define a small scoring function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "68ab3eea-ba94-4801-1249-cfa84dec9d61"
      },
      "outputs": [],
      "source": [
        "def compute_score(clf, X, y,scoring='accuracy'):\n",
        "    xval = cross_val_score(clf, X, y, cv = 5,scoring=scoring)\n",
        "    return np.mean(xval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1c6dee96-27fc-33e1-d2e2-d2ef6dd879c7"
      },
      "source": [
        "Recover the train set and the test set from the combined dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0a5c3906-1914-62b5-6261-e3de70e65888"
      },
      "outputs": [],
      "source": [
        "def recover_train_test_target():\n",
        "    global combined\n",
        "    \n",
        "    train0 = pd.read_csv('../input/train.csv')\n",
        "    \n",
        "    targets = train0.Survived\n",
        "    train = combined.ix[0:890]\n",
        "    test = combined.ix[891:]\n",
        "    \n",
        "    return train,test,targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "254f5880-edf8-08ba-8898-ebf8cb507069"
      },
      "outputs": [],
      "source": [
        "train,test,targets = recover_train_test_target()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "39bd8d93-d5db-76d9-9b9d-77a231aa65d7"
      },
      "source": [
        "# 5.0 Feature selection\n",
        "\n",
        "We have 68 features so far. This number is quite large.\n",
        "\n",
        "When feature engineering is done, we usually tend to decrease the dimensionality by selecting the \"right\" number of features that capture the essential.\n",
        "\n",
        "Feature selection comes with many benefits:\n",
        "\n",
        " 1. It decreases redundancy among the data\n",
        " 2. It speeds up the training process\n",
        " 3. It reduces overfitting\n",
        "\n",
        "Tree-based estimators can be used to compute feature importance, which in turn can be used to discard irrelevant features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "944b809e-e557-2622-467e-015489be9c2e"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "clf = ExtraTreesClassifier(n_estimators=200)\n",
        "clf = clf.fit(train, targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2d266dce-e99c-bd3b-ca71-e224542eee58"
      },
      "source": [
        "# 5.1 Check the importance of each feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4ece06e2-6d4a-0792-19be-829990537bcf"
      },
      "outputs": [],
      "source": [
        "features = pd.DataFrame()\n",
        "features['feature'] = train.columns\n",
        "features['importance'] = clf.feature_importances_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "30bb7642-0e23-393f-4d02-6bbb53ff2558"
      },
      "outputs": [],
      "source": [
        "features.sort(['importance'],ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cf9a9dfe-256f-006b-8d61-2409db941bd2"
      },
      "source": [
        "As you you can see, there is a great importance linked to Title_Mr, Age, Fare, and Sex.\n",
        "\n",
        "There is also an important correlation with the Passenger_Id.\n",
        "\n",
        "Let's now transform our train set and test set in a more compact datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3b945d3a-1c4d-7da2-93e8-727a2f308d51"
      },
      "outputs": [],
      "source": [
        "model = SelectFromModel(clf, prefit=True)\n",
        "train_new = model.transform(train)\n",
        "train_new.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4a0f8c22-2b10-51f6-bee0-97affd2d93c0"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_new = model.transform(test)\n",
        "test_new.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "16498f2e-d879-557f-2367-4edd5200b14d"
      },
      "source": [
        "We have now reduced our features to 8 features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4b55efdd-0e0b-acc4-a0e6-5c889e77304e"
      },
      "source": [
        "# 6.0  Hyperparameters tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "beb32da5-98e6-d062-b250-92bee043fdc9"
      },
      "outputs": [],
      "source": [
        "\n",
        "forest = RandomForestClassifier(max_features='sqrt')\n",
        "\n",
        "parameter_grid = {\n",
        "                 'max_depth' : [4,5,6,7,8],\n",
        "                 'n_estimators': [200,210,240,250],\n",
        "                 'criterion': ['gini','entropy']\n",
        "                 }\n",
        "\n",
        "cross_validation = StratifiedKFold(targets, n_folds=5)\n",
        "\n",
        "grid_search = GridSearchCV(forest,\n",
        "                           param_grid=parameter_grid,\n",
        "                           cv=cross_validation)\n",
        "\n",
        "grid_search.fit(train_new, targets)\n",
        "\n",
        "print('Best score: {}'.format(grid_search.best_score_))\n",
        "print('Best parameters: {}'.format(grid_search.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1eb1fdde-9866-44d0-833b-349df96d9127"
      },
      "source": [
        "# 7.0 Generate an output file to submit on Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f6f3b254-94c1-b5aa-9d9c-42bc0b751acb"
      },
      "outputs": [],
      "source": [
        "output = grid_search.predict(test_new).astype(int)\n",
        "df_output = pd.DataFrame()\n",
        "df_output['PassengerId'] = test['PassengerId']\n",
        "df_output['Survived'] = output\n",
        "df_output[['PassengerId','Survived']].to_csv('titanic_pred.csv',index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}