{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for the stacking\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n                              GradientBoostingClassifier, ExtraTreesClassifier)\nfrom sklearn.svm import SVC\nfrom sklearn.cross_validation import KFold","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"# Loading data\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\npassenger_Id = test['PassengerId']\ntrain.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc42fe8146b83f44635ffb81520677fc297be6bf"},"cell_type":"code","source":"# Feature engineering\n\nfull_data = [train, test]\n\nfor dataset in full_data:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\nprint(pd.crosstab(train['Title'], train['Sex']))\n\nfor dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"2e206c7e224bdc4decdbad92d8cd3de7c44e369c"},"cell_type":"code","source":"# Creating features\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n\nfor dataset in full_data:\n    \n    # Feature that describes the person\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)   \n    # Feature that tells if the person had a cabin\n    dataset['has_cabin'] = dataset['Cabin'].apply(lambda x: 0 if type(x) == float else 1)\n    # Feature that tells the FamilySize\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n    # Feature that tells if a person was alone\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n    \ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3595a35dc3ea0cd6ca346c41c8078067ecfc6274"},"cell_type":"code","source":"# Eliminating columns that will not be used (Feature Selection)\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch'] # Categorical Features that will not be part of prediction\ntrain = train.drop(drop_elements, axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"bffa3a7fd1bbdbb985d989339b8f260fb09b7c8d"},"cell_type":"code","source":"# Check which columns have null values\nnull_columns_train=train.columns[train.isnull().any()]\nnull_columns_test=test.columns[test.isnull().any()]\n\nprint(train[null_columns_train].isnull().sum())\nprint(test[null_columns_test].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eef36057519c615b5168677bc4b3beb9c7b41929"},"cell_type":"code","source":"# Getting rid of nulls without changing data distribution\nfull_data = [train, test]\n\nfor dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S') # Fill it with the Mode\n    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median()) # Fill it with the Median\n        \n    age_avg = dataset['Age'].mean()\n    age_std = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75942cabc980f715093a113d3c28dde1c0613c64"},"cell_type":"code","source":"# Check which columns have null values\nnull_columns_train=train.columns[train.isnull().any()]\nnull_columns_test=test.columns[test.isnull().any()]\n\nprint(train[null_columns_train].isnull().sum())\nprint(test[null_columns_test].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"e59c70845ce10238a16cb270b8138df95a095740"},"cell_type":"code","source":"full_data = [train, test]\n\n# Without null values, apply a grouping technique to Age and Fare\nfor dataset in full_data:    \n    dataset.loc[dataset['Fare'] <= dataset['Fare'].quantile(0.2), 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > dataset['Fare'].quantile(0.2)) & (dataset['Fare'] <= dataset['Fare'].quantile(0.4)), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > dataset['Fare'].quantile(0.4)) & (dataset['Fare'] <= dataset['Fare'].quantile(0.6)), 'Fare'] = 2\n    dataset.loc[(dataset['Fare'] > dataset['Fare'].quantile(0.6)) & (dataset['Fare'] <= dataset['Fare'].quantile(0.8)), 'Fare'] = 3\n    dataset.loc[dataset['Fare'] > dataset['Fare'].quantile(0.8), 'Fare'] = 4\n    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n\n# Mapping categorical features to integer values\nfor dataset in full_data:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain.head(5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e52d1e10d20f924b549614dd5134d655a6dfff7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"664abd0a7d5b8faa155400a022213f691101a6c1"},"cell_type":"code","source":"# Checking correlation between features\n\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18179d1019ce34f3f7c32fdb78c76efd9f1c1a16"},"cell_type":"code","source":"features = train.drop(\"Survived\", axis=1)\nlabels = train[\"Survived\"]\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split( features, labels, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49b2babf7776bf3423a338cfb11452ee901e44a0"},"cell_type":"code","source":"# SVM\n\nfrom sklearn.metrics import fbeta_score, accuracy_score\nclf = SVC(kernel='rbf', C=10, gamma=0.6)\nclf.fit(x_train, y_train)\nprint(\"Accuracy for training data\")\npreds = clf.predict(x_train)\nprint(accuracy_score(y_train, preds))\nprint(\"Accuracy for testing data\")\npreds = clf.predict(x_test)\nprint(accuracy_score(y_test, preds))\nprint(\"F-score\")\nprint(fbeta_score(y_test, preds, beta=0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c41f150736007b0bb87162582df801e8f9434a31"},"cell_type":"code","source":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(x_train, y_train)\ny_pred = random_forest.predict(x_test)\nrandom_forest.score(x_train, y_train)\nacc_random_forest = round(random_forest.score(x_train, y_train) * 100, 2)\nprint(\"Accuracy for training data \" + str(acc_random_forest))\nprint(\"Accuracy for testing data \" + str(round(accuracy_score(y_pred, y_test) * 100, 2)))\nprint('F score: ' + str(fbeta_score(y_test, preds, beta=0.5)))\nforest_features = random_forest.feature_importances_\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"7fa8a414f337dec2678287069ac159afc915248a"},"cell_type":"code","source":"cols = train.columns.values\n\n# Scatter plot \ntrace = go.Scatter(\n    y = forest_features,\n    x = cols,\n    mode='markers',\n    marker=dict(\n        sizemode = 'diameter',\n        sizeref = 1,\n        size = 25,\n#       size= feature_dataframe['AdaBoost feature importances'].values,\n        #color = np.random.randn(500), #set color equal to a variable\n        color = forest_features,\n        colorscale='Portland',\n        showscale=True\n    ),\n    text = cols\n)\ndata = [trace]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Random Forest Feature Importance',\n    hovermode= 'closest',\n#     xaxis= dict(\n#         title= 'Pop',\n#         ticklen= 5,\n#         zeroline= False,\n#         gridwidth= 2,\n#     ),\n    yaxis=dict(\n        title= 'Feature Importance',\n        ticklen= 5,\n        gridwidth= 2\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig,filename='scatter2010')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff51cd66bd0909c4378f238daa90b4e75a251275"},"cell_type":"code","source":"# Submission area\n\nmodel_pred = clf.predict(test) # Test data provided by the competition for submission\n\nsubmission = pd.DataFrame({\n        \"PassengerId\": passenger_Id,\n        \"Survived\": model_pred\n    })\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}