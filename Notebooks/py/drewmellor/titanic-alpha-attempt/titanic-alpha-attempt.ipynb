{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0181b9cb-75c4-f041-6120-911c5a817e42"
      },
      "source": [
        "Predicting Surviving the Sinking of the Titanic\n",
        "-----------------------------------------------\n",
        "\n",
        " \n",
        "This represents my first attempt at training up some classifiers for the titanic dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "022637d5-9f3e-79c3-ccbc-511882408624"
      },
      "outputs": [],
      "source": [
        "# data analysis and wrangling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "\n",
        "# visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# machine learning\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "23d71426-0da3-9177-a05a-81b2ddf097d4"
      },
      "outputs": [],
      "source": [
        "# get titanic & test csv files as a DataFrame\n",
        "train_df = pd.read_csv(\"../input/train.csv\")\n",
        "test_df = pd.read_csv(\"../input/test.csv\")\n",
        "combine = [train_df, test_df]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9daa4250-e7eb-b5ce-abd1-3bb0b7823f93"
      },
      "source": [
        "# Data exploration #\n",
        "\n",
        "First get some summary statistics about the datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7e6f7c48-86f3-e936-e108-533ebd456209"
      },
      "outputs": [],
      "source": [
        "# view column labels\n",
        "print(train_df.columns.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "072e3ae2-8ce0-c5b3-c19b-9f8ae5c0ec19"
      },
      "outputs": [],
      "source": [
        "# preview the data\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c6dc302f-248d-1ee3-33b4-57773743fa5a"
      },
      "source": [
        "Now transpose the first few rows in order to see all attributes more easily as row labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9b0b32ad-7697-f43b-d1f8-8b7066228768"
      },
      "outputs": [],
      "source": [
        "train_df.head(3).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "476a17fe-1076-44cd-79ff-8641dfe15b09"
      },
      "outputs": [],
      "source": [
        "# missing values, data types\n",
        "train_df.info()\n",
        "print('-'*40)\n",
        "test_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e7e7ec16-5675-1e59-13c3-46f72fe90c28"
      },
      "source": [
        "The above info shows that columns (from training data) with missing/empty values are:\n",
        "\n",
        " - Age (177 missing values)\n",
        " - Cabin (687 missing values)\n",
        " - Embarked (2 missing values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a34afc7e-3192-78df-c3cb-9247b5fb0db2"
      },
      "outputs": [],
      "source": [
        "# describe numeric columns\n",
        "train_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0466563d-7054-72d7-64d5-09a4038208af"
      },
      "source": [
        "In the training dataset there are 891 passengers with an overall survival rate of 38.4%.\n",
        "The oldest person is 80 years and the youngest is 5 months (0.42*12). The average fare is 32.20 dollars but the median fare is 14.45. This suggests outliers at the upper end of the fare, and indeed the maximum fare is $512.33."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cf88e644-c6c6-0cfc-97dc-fc0ed831d00c"
      },
      "outputs": [],
      "source": [
        "# describe categorical columns\n",
        "train_df.describe(include=['O'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "25e81062-db55-82f8-6672-32a06fbe5795"
      },
      "outputs": [],
      "source": [
        "# just for fun, examine the records of ten year olds (there are only two) \n",
        "train_df[train_df.Age == 10].stack()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9ff06206-c63b-c977-cb75-d9fedd286451"
      },
      "source": [
        "# Detailed data investigation #\n",
        "\n",
        "A closer look at each of the attributes (columns) and their relationship to survival."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3f253f7e-056f-e444-a534-64f91264a954"
      },
      "source": [
        "##Sex##\n",
        "\n",
        "Sex is a *nominal* attribute with two categories (i.e. it is dichotomous). Let's plot some counts and survival rates by sex. Note that survival values are 0/1, thus rates can be be calculated simply via the mean survive value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cb5d3e1f-c356-389e-97bf-6db88ff9d2bb"
      },
      "outputs": [],
      "source": [
        "# count passengers by sex\n",
        "plt.subplot(211) # 3 digit convenience notation for arguments (last digit represents plot number)\n",
        "sns.countplot(x='Sex', data=train_df, palette='Greens_d')\n",
        "\n",
        "# survival rate by sex\n",
        "# note that barplot plots mean() on y by default\n",
        "plt.subplot(212)\n",
        "sns.barplot(x='Sex', y='Survived', data=train_df, palette='Greens_d') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4a1fc99e-427c-52e8-fa8d-4b3b0c2ca797"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        " - Many more males than females\n",
        " - Survival rate of females much greater than males\n",
        "\n",
        "Let's get the actual numbers below using pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cdadaf68-5b83-34a2-2944-d5365d72427e"
      },
      "outputs": [],
      "source": [
        "# count passengers by sex\n",
        "train_df.groupby('Sex').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7b2ba4b2-1de9-66da-4711-ab6529a56aa1"
      },
      "outputs": [],
      "source": [
        "# survival rates by sex\n",
        "train_df.groupby(['Sex'])['Survived'].mean().sort_values()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6d1aa2c6-befb-85f6-729b-e8cf99b7bc7d"
      },
      "source": [
        "Thus, 18.9% of males (from the training set) survived compared to 74.2% of females."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2dd6265e-1f67-e899-a626-528267dfcd2c"
      },
      "source": [
        "##Passenger class##\n",
        "\n",
        "Passenger class (Pclass) is an *ordinal* attribute with three categories, 1, 2 and 3. The three categories have an order (representing socioeconomic status) but although the categories are given numeric labels, this attribute *is not* numeric! To see this, consider that 3rd class = 1st + 2nd class is a nonsense. This will be important later when we construct features. Again, let's plot some counts and survival rates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e5abbd94-229e-4de9-d903-e34c2978905d"
      },
      "outputs": [],
      "source": [
        "# size of groups in passenger class\n",
        "plt.subplots(figsize=(8,6))\n",
        "plt.subplot(211) \n",
        "sns.countplot(x='Pclass', data=train_df, palette='Purples_d') # _d = dark palette\n",
        "\n",
        "# survival rate by sex\n",
        "plt.subplot(212)\n",
        "sns.barplot(x='Pclass', y='Survived', data=train_df, palette='Purples_d') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b8dc5fb1-f855-ded1-cac7-d96572aafb76"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        " - Three classes\n",
        " - Most passengers travelled by 3rd class (more than half; see below)\n",
        " - Survival rate increases with class\n",
        "\n",
        "Again, let's get the actual numbers below using pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4764250c-0498-08f3-3c5c-632c854bdbb2"
      },
      "outputs": [],
      "source": [
        "# count passengers by passenger class\n",
        "train_df.groupby(['Pclass']).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6108d506-24cc-bd4c-9503-7be085889489"
      },
      "outputs": [],
      "source": [
        "# survival rates by passenger class\n",
        "train_df.groupby(['Pclass'])['Survived'].mean().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "54ac41ed-6061-d009-bab3-8e8f5b8581ab"
      },
      "source": [
        "##Age##\n",
        "\n",
        "Age is a *ratio* attribute (it is properly numeric, see [Types of data measurement scales][1]). Ages < 1 indicate age in months.\n",
        "\n",
        "\n",
        "  [1]: http://www.mymarketresearchmethods.com/types-of-data-nominal-ordinal-interval-ratio/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5bccd2af-58a3-1f9c-38b7-1c3c09d2b07c"
      },
      "outputs": [],
      "source": [
        "# count the number of passengers for first 25 ages\n",
        "train_df.groupby('Age').size().head(25)\n",
        "\n",
        "# another way to do the above\n",
        "#train_df['Age'].value_counts().sort_index().head(25) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "293ba1c4-c728-852f-9215-2b8801a39182"
      },
      "outputs": [],
      "source": [
        "# convert ages to ints\n",
        "age = train_df[['Age','Survived']].dropna() # returns a copy with blanks removed\n",
        "age['Age'] = age['Age'].astype(int) # floors floats\n",
        "\n",
        "# count passengers by age (smoothed via gaussian kernels)\n",
        "plt.subplots(figsize=(18,6))\n",
        "plt.subplot(311)\n",
        "sns.kdeplot(age['Age'], shade=True, cut=0)\n",
        "\n",
        "# count passengers by age (no smoothing)\n",
        "plt.subplot(312)\n",
        "sns.countplot(x='Age', data=age, palette='GnBu_d')\n",
        "\n",
        "# survival rates by age\n",
        "plt.subplot(313)\n",
        "sns.barplot(x='Age', y='Survived', data=age, ci=None, palette='Oranges_d') # takes mean by default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bb429537-2b24-ce6c-f473-6bb5c039624c"
      },
      "source": [
        "Observations:\n",
        "\n",
        " - Under 16s tend to have the highest survival rates\n",
        " - Very high survival rates at 53, 63 and 80\n",
        " - Survival of over 16s is fairly noisy. Possible that survival might increase with age."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1e7b0bfe-1dac-2bfa-79b5-4abf5f5980f0"
      },
      "source": [
        "## Survival by age group and sex ##\n",
        "\n",
        "Now let's look at survival by age groups *and* sex to see if any patterns become clearer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a686426a-1ac4-5eb5-cf2d-4363b6225bd6"
      },
      "outputs": [],
      "source": [
        "# bin age into groups\n",
        "train_df['AgeGroup'] = pd.cut(train_df['Age'],[0,4,15,25,35,45,65,100])\n",
        "test_df['AgeGroup'] = pd.cut(test_df['Age'],[0,4,15,25,35,45,65,100])\n",
        "\n",
        "# survival by age group\n",
        "train_df.groupby('AgeGroup')['Survived'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0a12f816-37ac-ce84-b2c9-7c1a11e53516"
      },
      "outputs": [],
      "source": [
        "# survival by age group and sex\n",
        "train_df[['Survived','AgeGroup', 'Sex']].groupby(['Sex', 'AgeGroup']).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2399cfdd-8a45-6b64-b45b-5dcebd49a93d"
      },
      "outputs": [],
      "source": [
        "# count passengers by age group and sex\n",
        "sns.factorplot(x='AgeGroup', col='Sex', data=train_df, kind='count')\n",
        "\n",
        "# survival by age group and sex\n",
        "sns.factorplot(x='AgeGroup', y='Survived', col='Sex', data=train_df, kind='bar')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "861896c0-0e9e-35af-d17f-398ac20b5f50"
      },
      "source": [
        "The relationship between survival and age group looks very different for males and females:\n",
        "\n",
        "- Males: survival rates increase *inversely* with age for (0, 25] and (25, 100). That is, younger boys fare better than older boys and younger men survive more than older men.  \n",
        "- Females: no obvious relationship between surviving and age. In particular, girls and baby girls do not fare better than women; in fact, girls (4, 15] have the *lowest* survival rates of females. \n",
        "\n",
        "A feature space containing (child, man, woman) would do a decent job of representing this relationship to survivability. \n",
        "\n",
        "Non-linear classifiers (e.g. decision trees, multi-layer nn, nearest neighbour) applied to both sex and age group might do even better because of the noticeable relationship between survivability and age group for males.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9b8e654e-a1f2-7a29-d523-14b481c1ae56"
      },
      "source": [
        "## Family Size##\n",
        "\n",
        "We create a new feature, FamilySize, that sums Parch and SibSp. This will enable us to drop Parch and SibSp from the datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c2af1d24-1e80-9bd8-4cdc-1f2394d9dc01"
      },
      "outputs": [],
      "source": [
        "# calculate family size\n",
        "train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1\n",
        "test_df['FamilySize'] = test_df['SibSp'] + test_df['Parch'] + 1\n",
        "\n",
        "# count passengers by age group and sex\n",
        "plt.subplot(211)\n",
        "sns.countplot(x='FamilySize', data=train_df)\n",
        "\n",
        "# survival by age group and sex\n",
        "plt.subplot(212)\n",
        "sns.barplot(x='FamilySize', y='Survived', data=train_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9c05d932-0cd9-76d8-2e22-7edaeef0724c"
      },
      "source": [
        "Survival increases with family size, until families of size 4. Family sizes of 5 and above have reduced survival."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "72d0a3ff-7f4b-467c-6d70-d763d30c304b"
      },
      "source": [
        "Deck\n",
        "----\n",
        "\n",
        "Cabin might be conceivably be related to survival, but unfortunately most values are missing. Nevertheless, by way of an exercise, we will extract the feature, Deck, from cabin by taking the first character of the label and analyze survival rates by deck."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "83dbf9ce-dd36-34f9-4449-2e3141a523bd"
      },
      "outputs": [],
      "source": [
        "# deck is the first letter of cabin\n",
        "train_df['Deck'] = train_df['Cabin'].dropna().apply(lambda x: str(x)[0])\n",
        "train_df[['PassengerId','Name', 'Cabin', 'Deck']].head(2).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aac93282-594e-ae34-47ee-77a1b961cdbb"
      },
      "outputs": [],
      "source": [
        "# count passengers by the deck their cabin is on\n",
        "plt.subplots(figsize=(8,6))\n",
        "plt.subplot(211) \n",
        "sns.countplot(x='Deck', data=train_df)\n",
        "\n",
        "# survival rate by deck\n",
        "plt.subplot(212)\n",
        "sns.barplot(x='Deck', y='Survived', data=train_df) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7b44019c-4733-f022-b00b-1be236360b98"
      },
      "source": [
        "## Other attributes ##\n",
        "For this first attempt, I am ignoring the attributes below as they seem unlikely to be related to survival:\n",
        "\n",
        " - PassengerId\n",
        " - Name (however, extracting titles from names might be informative)\n",
        " - Ticket\n",
        " - Fare (could be related to socioeconomic status but we already have a class attribute)\n",
        " - Embarked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4579ca58-1951-cfad-bbd7-739a89d1b077"
      },
      "source": [
        "# Data wrangling - Age group#\n",
        "\n",
        "Fill missing age group values. We don't want to drop them as this would lose many rows. Instead, we will randomly generate age groups according to the frequency that they occur in the data. We will calculate the frequency separately for males and females."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "714fa003-85c1-109b-beae-c6a0133673b7"
      },
      "outputs": [],
      "source": [
        "# number of males/females without an age\n",
        "def get_na(dataset):\n",
        "    na_males = dataset[dataset.Sex == 'male'].loc[:,'AgeGroup'].isnull().sum()\n",
        "    na_females = dataset[dataset.Sex == 'female'].loc[:,'AgeGroup'].isnull().sum()\n",
        "    return {'male': na_males, 'female': na_females}\n",
        "\n",
        "# number of males and females by age group\n",
        "def get_counts(dataset):\n",
        "    return dataset.groupby(['Sex', 'AgeGroup']).size()\n",
        "\n",
        "# randomly generate a list of age groups based on age group frequency (for each sex separately) \n",
        "def generate_age_groups(num, freq):\n",
        "    age_groups = {}\n",
        "    for sex in ['male','female']:\n",
        "        relfreq = freq[sex] / freq[sex].sum()\n",
        "        age_groups[sex] = np.random.choice(freq[sex].index, size=num[sex], replace=True, p=relfreq)    \n",
        "    return age_groups\n",
        "\n",
        "# insert the new age group values\n",
        "def insert_age_group_values(dataset, age_groups):\n",
        "    for sex in ['male','female']:\n",
        "        tmp = pd.DataFrame(dataset[(dataset.Sex == sex) & dataset.Age.isnull()]) # filter on sex and null ages \n",
        "        tmp['AgeGroup'] = age_groups[sex] # index age group values\n",
        "        dataset = dataset.combine_first(tmp) # uses tmp to fill holes\n",
        "    return dataset\n",
        "\n",
        "# fill holes for train_df\n",
        "na = get_na(train_df)\n",
        "counts = get_counts(train_df)\n",
        "counts['female']\n",
        "age_groups = generate_age_groups(na, counts)\n",
        "age_groups['female']\n",
        "train_df = insert_age_group_values(train_df, age_groups)\n",
        "train_df.info() # check all nulls have been filled    \n",
        "print('-'*40)\n",
        "\n",
        "# repeat for test_df\n",
        "na = get_na(test_df)\n",
        "counts = get_counts(train_df) # reuse the frequencies taken over the training data as it is larger\n",
        "age_groups = generate_age_groups(na, counts)\n",
        "test_df = insert_age_group_values(test_df, age_groups)\n",
        "test_df.info() # check all nulls have been filled     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9fe77a1c-a535-82bd-70af-e15886936f4d"
      },
      "source": [
        "# Feature engineering #\n",
        "\n",
        "Now that we've explored the data let's create some features:\n",
        "\n",
        " - **Sex:** Convert to a single binary feature, Female. No need to create a feature for Male, that would be redundant.\n",
        " - **Pclass:** Convert to two binary features, PClass_1 and PClass_2. Similar to Male above, having a PClass_3 would be redundant.\n",
        " - **Age group:** The age attribute binned using separators [0, 4, 15, 25, 35, 45, 65, 100]. Convert to a number of binary features, one for each age group.\n",
        " - **Family size:** The sum of SibSp and Parch plus 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8f18660e-37c5-7edc-6d4e-dad310e515c8"
      },
      "outputs": [],
      "source": [
        "# Sex -> Female\n",
        "\n",
        "# training set\n",
        "dummy = pd.get_dummies(train_df['Sex'])\n",
        "dummy.columns = ['Female','Male']\n",
        "train_df = train_df.join(dummy['Female'])\n",
        "\n",
        "# test set\n",
        "dummy = pd.get_dummies(test_df['Sex'])\n",
        "dummy.columns = ['Female','Male']\n",
        "test_df = test_df.join(dummy['Female'])\n",
        "\n",
        "train_df[['Name', 'Sex', 'Female']].head(2).T\n",
        "#train_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "36b70db1-65ce-3245-a48e-c0af5996f47f"
      },
      "outputs": [],
      "source": [
        "# Pclass -> PClass_1, PClass_2\n",
        "\n",
        "# training set\n",
        "dummy  = pd.get_dummies(train_df['Pclass'])\n",
        "dummy.columns = ['PClass_1','PClass_2','PClass_3']\n",
        "train_df = train_df.join(dummy[['PClass_1', 'PClass_2']])\n",
        "\n",
        "# test set\n",
        "dummy  = pd.get_dummies(test_df['Pclass'])\n",
        "dummy.columns = ['PClass_1','PClass_2','PClass_3']\n",
        "test_df = test_df.join(dummy[['PClass_1', 'PClass_2']])\n",
        "\n",
        "train_df[['Name', 'Pclass', 'PClass_1', 'PClass_2']].head(2).T\n",
        "#train_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8ee6302e-20dc-1052-871e-f0547301bce4"
      },
      "outputs": [],
      "source": [
        "# AgeGroup -> binary features\n",
        "\n",
        "# training set\n",
        "dummy  = pd.get_dummies(train_df['AgeGroup'])\n",
        "dummy.columns = ['Ages_4','Ages_15','Ages_25','Ages_35','Ages_45','Ages_65','Ages_100']\n",
        "train_df = train_df.join(dummy)\n",
        "\n",
        "# test set\n",
        "dummy  = pd.get_dummies(test_df['AgeGroup'])\n",
        "dummy.columns = ['Ages_4','Ages_15','Ages_25','Ages_35','Ages_45','Ages_65','Ages_100']\n",
        "test_df = test_df.join(dummy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9900e83a-985d-2e52-ef4d-cb5ca4aaa307"
      },
      "source": [
        "## Experimental features ##\n",
        "Some additional features to explore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c108abfc-4b9d-60d2-8abb-851a8bd6c861"
      },
      "outputs": [],
      "source": [
        "# Fare\n",
        "\n",
        "# there is a single missing \"Fare\" value\n",
        "test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)\n",
        "\n",
        "# convert from float to int (floor)\n",
        "#train_df['Fare'] = train_df['Fare'].astype(int)\n",
        "#test_df['Fare'] = test_df['Fare'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2eef5fb8-dad0-001b-4137-d6dfffbad5c8"
      },
      "outputs": [],
      "source": [
        "# Embarked -> PortC, PortQ\n",
        "\n",
        "# Fill missing values with the most occurred value\n",
        "print(train_df.groupby('Embarked').size().sort_values())\n",
        "train_df['Embarked'] = train_df['Embarked'].fillna('S')\n",
        "\n",
        "# training set\n",
        "dummy = pd.get_dummies(train_df['Embarked'])\n",
        "#dummy.columns\n",
        "dummy.columns = ['Port_C','Port_Q','Port_S']\n",
        "#train_df = train_df.join(dummy[['Port_C','Port_Q']])\n",
        "\n",
        "# test set\n",
        "dummy  = pd.get_dummies(test_df['Embarked'])\n",
        "dummy.columns = ['Port_C','Port_Q','Port_S']\n",
        "#test_df = test_df.join(dummy[['Port_C','Port_Q']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "72c7320e-45d2-d5af-c664-5aa60693f4d6"
      },
      "source": [
        "## Dropping attributes ##\n",
        "Drop unused attributes to avoid detecting spurious relationships."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2e6153a1-3654-2246-4ffa-39eefda3cf8e"
      },
      "outputs": [],
      "source": [
        "# drop the attributes that will be unused\n",
        "train_df.drop(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', \n",
        "                   'SibSp', 'Parch', 'Ticket', 'Cabin', 'Fare', \n",
        "                   'Embarked', 'Deck', 'AgeGroup'], axis=1, inplace=True)\n",
        "\n",
        "test_df.drop(['Pclass', 'Name', 'Sex', 'Age', \n",
        "                   'SibSp', 'Parch', 'Ticket', 'Cabin', 'Fare',\n",
        "                   'Embarked', 'AgeGroup'], axis=1, inplace=True)\n",
        "\n",
        "train_df.head(10).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a64d8dab-8a62-5983-3d74-d68adf01cbde"
      },
      "source": [
        "The sample above shows the features and their values for the first ten training examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "69aaf0ba-7311-09b3-3b9c-4f798f1d7f05"
      },
      "source": [
        "# Modeling #\n",
        "\n",
        "Our task is a binary classification problem: we want to formulate a relationship that predicts an output (Survived or not) from engineered features (Sex, Age group, Family size...). This is type of learning is supervised learning, since a model will be trained on a dataset containing pairs of inputs and outputs. \n",
        "\n",
        "Suitable methods for performing classification include:\n",
        "\n",
        " - Logistic Regression*\n",
        " - Perceptron*\n",
        " - Support Vector Machines (SVMs)* \n",
        " - Naive Bayes classifier* \n",
        " - KNN or k-Nearest Neighbors\n",
        " - Decision Tree\n",
        " - Random Forrest\n",
        " - Artificial neural network\n",
        " - Relevance Vector Machine\n",
        "\n",
        "The methods marked * either discover linear classification boundaries (logistic regression, perceptron, and SVMs if using linear kernels) or assume no relationship between features (naive bayes) and thus are not expected to perform as well (see the section above on the relationship between survival, age group and sex)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "14f2767e-04a0-0912-1a05-16ddff5dd8f2"
      },
      "source": [
        "## Training data ##\n",
        "Let's use cross validation to perform the evaluation. This method will give a reasonable indication of predictive accuracy as evaluation will take place on data that is not seen during training. The package **`sklearn.model_selection`** includes support for cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f036490c-79e9-b269-5bfc-970c35ecc3ff"
      },
      "outputs": [],
      "source": [
        "# split the datasets into matched input and ouput pairs\n",
        "X_train = train_df.drop(\"Survived\", axis=1) # X = inputs\n",
        "Y_train = train_df[\"Survived\"] # Y = outputs\n",
        "X_test  = test_df.drop(\"PassengerId\", axis=1).copy()\n",
        "X_train.shape, Y_train.shape, X_test.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b173f7cb-2707-5396-b478-77b7c712b2c0"
      },
      "source": [
        "Model fitting\n",
        "----------\n",
        "(Some of this section is based on [this titanic tutorial][1].)\n",
        "\n",
        "Logistic Regression is a useful model to run early in the workflow. Logistic regression measures the relationship between the categorical dependent variable (feature) and one or more independent variables (features) by estimating probabilities using a logistic function, which is the cumulative logistic distribution. See [Logistic regression on Wikipedia][2].\n",
        "\n",
        "Note the confidence score generated by the model based on our training dataset.\n",
        "\n",
        "\n",
        "  [1]: https://www.kaggle.com/startupsci/titanic/titanic-data-science-solutions\n",
        "  [2]: https://en.wikipedia.org/wiki/Logistic_regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "348257ba-157e-ed1d-ce3f-9aec73994ca1"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "scores = cross_val_score(logreg, X_train, Y_train, cv=10)\n",
        "acc_log = round(scores.mean() * 100, 2)\n",
        "acc_log\n",
        "#Y_pred = logreg.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d4f021ab-f8fa-6281-4e27-e97f6854ddfa"
      },
      "source": [
        "We can use Logistic Regression to validate our assumptions and decisions for feature creating and completing goals. This can be done by calculating the coefficient of the features in the decision function.\n",
        "Positive coefficients increase the log-odds of the response (and thus increase the probability), and negative coefficients decrease the log-odds of the response (and thus decrease the probability)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "edc54c42-d209-f8bf-6587-dad428a4c708"
      },
      "outputs": [],
      "source": [
        "logreg.fit(X_train, Y_train)\n",
        "coeff_df = pd.DataFrame(train_df.columns.delete(0))\n",
        "coeff_df.columns = ['Feature']\n",
        "coeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n",
        "\n",
        "coeff_df.sort_values(by='Correlation', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "943da0b3-c318-040c-a7ed-941604195c4e"
      },
      "outputs": [],
      "source": [
        "# Gaussian Naive Bayes\n",
        "\n",
        "gaussian = GaussianNB()\n",
        "scores = cross_val_score(gaussian, X_train, Y_train, cv=10)\n",
        "acc_gaussian = round(scores.mean() * 100, 2)\n",
        "acc_gaussian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "55d5260f-e787-6085-b484-16ed25c6b9ff"
      },
      "outputs": [],
      "source": [
        "# Perceptron (a single layer neural net)\n",
        "\n",
        "perceptron = Perceptron()\n",
        "scores = cross_val_score(perceptron, X_train, Y_train, cv=10)\n",
        "acc_perceptron = round(scores.mean() * 100, 2)\n",
        "acc_perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8cc0934e-05d6-7154-8b57-a460bdec92a5"
      },
      "outputs": [],
      "source": [
        "# Neural Network (a multi layer neural net)\n",
        "\n",
        "neural_net = MLPClassifier()\n",
        "scores = cross_val_score(neural_net, X_train, Y_train, cv=10)\n",
        "acc_neural_net = round(scores.mean() * 100, 2)\n",
        "acc_neural_net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fc25a07e-3443-3d4c-506b-079df54adc44"
      },
      "outputs": [],
      "source": [
        "# Stochastic Gradient Descent\n",
        "\n",
        "sgd = SGDClassifier()\n",
        "scores = cross_val_score(sgd, X_train, Y_train, cv=10)\n",
        "acc_sgd = round(scores.mean() * 100, 2)\n",
        "acc_sgd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f03ea270-625a-35b4-057b-f615a456b988"
      },
      "outputs": [],
      "source": [
        "# Linear SVC\n",
        "\n",
        "linear_svc = LinearSVC()\n",
        "scores = cross_val_score(linear_svc, X_train, Y_train, cv=10)\n",
        "acc_linear_svc = round(scores.mean() * 100, 2)\n",
        "acc_linear_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c43d52a5-1f88-1908-a924-a4c85516939e"
      },
      "outputs": [],
      "source": [
        "# Support Vector Machine\n",
        "\n",
        "svc = SVC() # uses a rbf kernel by default (i.e. can discover non-linear boundaries)\n",
        "scores = cross_val_score(svc, X_train, Y_train, cv=10)\n",
        "acc_svc = round(scores.mean() * 100, 2)\n",
        "acc_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b2df606a-a288-c0ad-654e-2311653489f8"
      },
      "outputs": [],
      "source": [
        "# Decision Tree\n",
        "\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "scores = cross_val_score(decision_tree, X_train, Y_train, cv=10)\n",
        "acc_decision_tree = round(scores.mean() * 100, 2)\n",
        "acc_decision_tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "86d600c8-6541-1f78-9fa7-e18bac96789b"
      },
      "outputs": [],
      "source": [
        "# Random Forest - an ensemble model\n",
        "\n",
        "random_forest = RandomForestClassifier(n_estimators=100)\n",
        "scores = cross_val_score(random_forest, X_train, Y_train, cv=10)\n",
        "acc_random_forest = round(scores.mean() * 100, 2)\n",
        "acc_random_forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4a864bd5-8175-4895-387d-5f6648579475"
      },
      "outputs": [],
      "source": [
        "# AdaBoost - an ensemble method\n",
        "\n",
        "ada_boost = AdaBoostClassifier(n_estimators=100)\n",
        "scores = cross_val_score(ada_boost, X_train, Y_train, cv=10)\n",
        "acc_ada_boost = round(scores.mean() * 100, 2)\n",
        "acc_ada_boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c2db3638-4f4c-68b2-a730-7a5b8dfe4d4f"
      },
      "outputs": [],
      "source": [
        "# k-Nearest Neighbors - a non-parametric method\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors = 5)\n",
        "scores = cross_val_score(knn, X_train, Y_train, cv=10)\n",
        "acc_knn = round(scores.mean() * 100, 2)\n",
        "acc_knn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d508a3ad-c872-f709-5f3e-b3c951070901"
      },
      "source": [
        "Model evaluation\n",
        "----------------\n",
        "\n",
        "We now rank the models and choose a high performing one for our problem. The Support Vector Machine consistently tops the chart. \n",
        "\n",
        "Decision Tree and Random Forest also both score high, but we prefer Random Forest as it avoids overfitting to the training set better than a decision tree and is therefore likely to perform better on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "44c80fb2-3e1e-c9c9-3a14-f4c0ea9df07f"
      },
      "outputs": [],
      "source": [
        "models = pd.DataFrame({\n",
        "    'Model': ['Support Vector Machine', 'kNN', 'Logistic Regression', \n",
        "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
        "              'Stochastic Gradient Descent', 'Linear SVC', \n",
        "              'Decision Tree', 'AdaBoost', 'Neural Network'],\n",
        "    'Score': [acc_svc, acc_knn, acc_log, \n",
        "              acc_random_forest, acc_gaussian, acc_perceptron, \n",
        "              acc_sgd, acc_linear_svc, acc_decision_tree, \n",
        "              acc_ada_boost, acc_neural_net]})\n",
        "models.sort_values(by='Score', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "17578f95-6543-756e-fa97-4d10da12220f"
      },
      "outputs": [],
      "source": [
        "# using random forest for submission\n",
        "random_forest.fit(X_train, Y_train)\n",
        "Y_pred = random_forest.predict(X_test)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "        \"PassengerId\": test_df[\"PassengerId\"],\n",
        "        \"Survived\": Y_pred\n",
        "    })\n",
        "submission.to_csv('titanic_submission_1.csv', index=False)\n",
        "#pd.set_option('display.max_rows', len(submission))\n",
        "#submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7e2d3a2a-8382-417d-3254-3b6640489a3a"
      },
      "source": [
        "Use cross validation to assess predictive accuracy\n",
        "--------------------------------------------------\n",
        "\n",
        "We can easily improve the above scores by evaluating on the training data (compare the random forest scores above and below). However, scores produced like this are not truly indicative of predictive accuracy and should be avoided. To see why, consider that a classifier that simply memorizes each input and output pair will score perfectly but be unable to generalise to other examples. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8ec82a64-6a56-49d1-d3b1-2d98926f0964"
      },
      "outputs": [],
      "source": [
        "# Random Forest : scoring on training data\n",
        "\n",
        "random_forest = RandomForestClassifier(n_estimators=100)\n",
        "random_forest.fit(X_train, Y_train)\n",
        "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
        "acc_random_forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ac177d0b-5adb-4814-9519-3e091bd6ccb1"
      },
      "source": [
        "What next? \n",
        "-------------------------------\n",
        "\n",
        "**_More feature exploration:_**\n",
        "Including *Fare* significantly increases the best accuracy to about 92% when *fare* is floored and 94% otherwise. Additionally including *Embarked* brings it up to 95%. It may worth be investigating if any relationship between these attributes and survival can be detected, especially for *fare*.\n",
        "\n",
        "Other possibilities for features include *Deck* and *Title*, which can be extracted from *Cabin* and *Name* respectively.\n",
        "\n",
        "Could also try two or more overlapping binnings for age groups (e.g. bins as defined by cutting on [0,4,15,25,35,45,65,100] and [10,20,30,40,55,100]). If going down this path, focus on introducing extra bins for age groups that contain many passengers and have a steeper gradient on the survival curve (such as for the twenties, e.g. cut on [10,20,30]).\n",
        "\n",
        "**_Refitting:_**\n",
        "Most of the models above used their default parameters. Choose a few promising models and attempt to optimize their (hyper-)parameters. The sklearn library used above offers a couple of ways to do this automatically (via grid search and cross-validated models, see [Model selection][1] and [Tuning the hyper-parameters of an estimator][2]).\n",
        "\n",
        "\n",
        "  [1]: http://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html\n",
        "  [2]: http://scikit-learn.org/stable/modules/grid_search.html#grid-search"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}