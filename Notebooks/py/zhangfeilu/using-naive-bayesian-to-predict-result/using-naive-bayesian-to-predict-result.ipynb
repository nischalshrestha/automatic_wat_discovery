{"nbformat_minor": 1, "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.3", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "mimetype": "text/x-python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}}}, "nbformat": 4, "cells": [{"source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "%matplotlib inline\n", "# Load the training data in a dataframe\n", "train = pd.read_csv(\"../input/train.csv\")\n", "\n", "# Load the test data in a dataframe\n", "test = pd.read_csv(\"../input/test.csv\")\n", "# test data don't have survived value\uff0c but when we doing feature engineer put it together with train data\n", "merged = train.append(test)\n", "#data.astype\n", "merged.head()"], "cell_type": "code", "metadata": {"_cell_guid": "68976b22-51c6-4b2f-ba76-3c18aa4ae3b1", "_uuid": "0be75250c4e42beda1f0633ce562b5b37c0c3896"}, "outputs": [], "execution_count": 1}, {"source": ["print(merged.isnull().sum()) #checking for total null values, null survived value from test data"], "cell_type": "code", "metadata": {"_cell_guid": "a2caef00-e2d4-46d4-ad65-719c82f7ad5f", "_uuid": "56f09e556e21a298695ae95a1ef143b5e5e8f39e"}, "outputs": [], "execution_count": 2}, {"source": ["The **Age, Cabin and Embarked **have null values. I will try to fix them."], "cell_type": "markdown", "metadata": {"_cell_guid": "4d5282c3-396d-4d3d-b169-8672fb6cde4f", "_uuid": "86faf8dfa85485f4fba6ef027260189edb145179"}}, {"source": ["As we had seen earlier, the Age feature has 177 null values. To replace these NaN values, we can assign them the mean age of the dataset.\n", "\n", "But the problem is, there were many people with many different ages. We just cant assign a 4 year kid with the mean age that is 29 years. Is there any way to find out what age-band does the passenger lie??\n", "\n", "Bingo!!!!, we can check the Name feature. Looking upon the feature, we can see that the names have a salutation like Mr or Mrs. Thus we can assign the mean values of Mr and Mrs to the respective groups.\n", "\n", "Okay so there are some misspelled Initials like Mlle or Mme that stand for Miss. I will replace them with Miss and same thing for other values."], "cell_type": "markdown", "metadata": {"_cell_guid": "d56e7cfe-adf7-4f85-8f04-2fdf4fa46ea6", "_uuid": "69e5fb95a2ad182cb328ae9fc292e970a9165689"}}, {"source": ["merged['NameTitle']=0\n", "for i in merged:\n", "    merged['NameTitle']=merged.Name.str.extract('([A-Za-z]+)\\.') #lets extract the Salutations\n", "print(pd.unique(merged['NameTitle'].values))    "], "cell_type": "code", "metadata": {"_cell_guid": "ff9e133e-fe96-487a-9eab-0ca5f4308251", "_uuid": "a43abc9547aa4eddc7299cfff2ea32494e7c330c"}, "outputs": [], "execution_count": 3}, {"source": ["    merged['NameTitle'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr'],inplace=True)"], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "2aa5e3f1-0b2b-40ea-bfd8-9a374b2b9ab9", "_uuid": "6a873c6f5cebcbb9b8219b55313c8cc66ee2f342"}, "outputs": [], "execution_count": 4}, {"source": ["merged.groupby('NameTitle')['Age'].mean() #lets check the average age by Initials"], "cell_type": "code", "metadata": {"_cell_guid": "1278dac7-e9d0-48d6-9adf-0ac8052fe2fe", "_uuid": "a3234a706e7ffefbf9ed2257c93874629922a5f6"}, "outputs": [], "execution_count": 5}, {"source": ["## Assigning the NaN Values with the Ceil values of the mean ages\n", "merged.loc[(merged.Age.isnull())&(merged.NameTitle=='Mr'),'Age']=33\n", "merged.loc[(merged.Age.isnull())&(merged.NameTitle=='Mrs'),'Age']=37\n", "merged.loc[(merged.Age.isnull())&(merged.NameTitle=='Master'),'Age']=5\n", "merged.loc[(merged.Age.isnull())&(merged.NameTitle=='Miss'),'Age']=22\n", "merged.loc[(merged.Age.isnull())&(merged.NameTitle=='Other'),'Age']=45\n", "merged.loc[(merged.Age.isnull())&(merged.NameTitle=='Dona'),'Age']=39"], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "119bb8bf-ce83-46f9-95e3-467cc9c8c022", "_uuid": "071173d48958427cf1d443775520f7bdba360446"}, "outputs": [], "execution_count": 6}, {"source": ["merged.Age.isnull().any()"], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "870f3bda-3ae4-40c4-abb9-9392ec273bf7", "_uuid": "7ed27bf6fa7e915e66ad5f55f196c041cf74e7a6"}, "outputs": [], "execution_count": null}, {"source": ["embarked_values = pd.unique(merged['Embarked'].values)\n", "for v in embarked_values:\n", "    print(v,len(merged.loc[merged['Embarked']==v]))"], "cell_type": "code", "metadata": {"_cell_guid": "6463b4f4-e9c0-47e6-b57b-4ad281b93c2d", "_uuid": "423b8083705176ef08cf7ccb3c9a35b68d2809d9"}, "outputs": [], "execution_count": 7}, {"source": ["# As we saw that maximum passengers boarded from Port S, we replace NaN with S.\n", "merged['Embarked'].fillna('S',inplace=True)"], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "d4d07e06-faf9-4f0f-a66f-1975cb353667", "_uuid": "f1eff0427ad1012f868c9e27897bb8bd1e622268"}, "outputs": [], "execution_count": 9}, {"source": ["Part2: Feature Engineering and Data Cleaning\n", "Now what is Feature Engineering?\n", "\n", "Whenever we are given a dataset with features, it is not necessary that all the features will be important. There maybe be many redundant features which should be eliminated. Also we can get or add new features by observing or extracting information from other features.\n", "\n", "An example would be getting the Initals feature using the Name Feature. Lets see if we can get any new features and eliminate a few. Also we will tranform the existing relevant features to suitable form for Predictive Modeling.\n", "\n", "Age_band\n", "Problem With Age Feature:\n", "As I have mentioned earlier that Age is a continous feature, there is a problem with Continous Variables in Machine Learning Models.\n", "\n", "Eg:If I say to group or arrange Sports Person by Sex, We can easily segregate them by Male and Female.\n", "\n", "Now if I say to group them by their Age, then how would you do it? If there are 30 Persons, there may be 30 age values. Now this is problematic.\n", "\n", "We need to convert these continous values into categorical values by either Binning or Normalisation. I will be using binning i.e group a range of ages into a single bin or assign them a single value.\n", "\n", "Okay so the maximum age of a passenger was 80. So lets divide the range from 0-80 into 5 bins. So 80/5=16. So bins of size 16."], "cell_type": "markdown", "metadata": {"_cell_guid": "1f6c3a40-2d02-490a-8533-2d1774f534f7", "_uuid": "f25a3596c355ab1f5b66e6cdae7001c70ac0a711"}}, {"source": ["merged['Age_band']=0\n", "merged.loc[merged['Age']<=16,'Age_band']=0\n", "merged.loc[(merged['Age']>16)&(merged['Age']<=32),'Age_band']=1\n", "merged.loc[(merged['Age']>32)&(merged['Age']<=48),'Age_band']=2\n", "merged.loc[(merged['Age']>48)&(merged['Age']<=64),'Age_band']=3\n", "merged.loc[merged['Age']>64,'Age_band']=4"], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "9675dc3d-3e48-4e4a-a270-007498efe590", "_uuid": "81028af82eca5ed647f7d10f336c1c0561bd5f90"}, "outputs": [], "execution_count": 10}, {"source": ["Family_Size and Alone\n", "At this point, we can create a new feature called \"Family_size\" and \"Alone\" and analyse it. This feature is the summation of Parch and SibSp. It gives us a combined data so that we can check if survival rate have anything to do with family size of the passengers. Alone will denote whether a passenger is alone or not."], "cell_type": "markdown", "metadata": {"_cell_guid": "7bbd575b-544f-4658-b559-791f3a675392", "_uuid": "ac93d2f200973391fe1f660ab177caedb3aeffe6"}}, {"source": ["merged['Family_Size']=0\n", "merged['Family_Size']=merged['Parch']+merged['SibSp']#family size\n", "merged['Alone']=0\n", "merged.loc[merged.Family_Size==0,'Alone']=1#Alone\n", "merged.head()"], "cell_type": "code", "metadata": {"_cell_guid": "cdb64d32-807c-471a-9156-d5995f49dbf7", "_uuid": "0a69e7769e2955fbb691c36c16b6dfdc70cf1e91"}, "outputs": [], "execution_count": 11}, {"source": ["Fare_Range\n", "Since fare is also a continous feature, we need to convert it into ordinal value. For this we will use pandas.qcut.\n", "\n", "So what qcut does is it splits or arranges the values according the number of bins we have passed. So if we pass for 5 bins, it will arrange the values equally spaced into 5 seperate bins or value ranges."], "cell_type": "markdown", "metadata": {"_cell_guid": "de88291a-ff90-4376-95e4-5977bac2c744", "_uuid": "7d7d8298272cd3368a9a9219948e4706de278300"}}, {"source": ["merged['Fare_Range']=pd.qcut(merged['Fare'],4)\n", "#print(merged.groupby(['Fare_Range'])['Survived'])"], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "564b204e-8e42-4c83-8e3a-7da08195833b", "_uuid": "06573e8f4e4b38a37c509e0a0f0e126d4999645b"}, "outputs": [], "execution_count": 12}, {"source": ["#Now we cannot pass the Fare_Range values as it is. We should convert it into singleton values same as we did in Age_Band\n", "merged['Fare_cat']=0\n", "merged.loc[merged['Fare']<=7.91,'Fare_cat']=0\n", "merged.loc[(merged['Fare']>7.91)&(merged['Fare']<=14.454),'Fare_cat']=1\n", "merged.loc[(merged['Fare']>14.454)&(merged['Fare']<=31),'Fare_cat']=2\n", "merged.loc[(merged['Fare']>31)&(merged['Fare']<=513),'Fare_cat']=3"], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "c043d601-eadb-4012-9a49-1cf037c8f0eb", "_uuid": "34b158d3dd6edd27eefa577cdc72a3086ebc8d8e"}, "outputs": [], "execution_count": 13}, {"source": ["#data.head()\n", "data = pd.DataFrame(merged.head(len(train)))\n", "submission_data = pd.DataFrame(merged.iloc[len(train):]) \n", "# after the feature engineering we need to split the test data from the train data\n", "data.head()"], "cell_type": "code", "metadata": {"_cell_guid": "ca3deb07-5285-410d-84f9-399826ac7d15", "_uuid": "3dcaca41a66ddd7531fede8aafa2694746086ed8", "scrolled": true}, "outputs": [], "execution_count": 14}, {"source": ["Dropping UnNeeded Features\n", "Name--> We don't need name feature as it cannot be converted into any categorical value.\n", "\n", "Age--> We have the Age_band feature, so no need of this.\n", "\n", "Ticket--> It is any random string that cannot be categorised.\n", "\n", "Fare--> We have the Fare_cat feature, so unneeded\n", "\n", "Cabin--> A lot of NaN values and also many passengers have multiple cabins. So this is a useless feature.\n", "\n", "Fare_Range--> We have the fare_cat feature.\n", "\n", "PassengerId--> Cannot be categorised."], "cell_type": "markdown", "metadata": {"_cell_guid": "7e91bbc8-50f4-4289-812f-ef64ca7d1e5e", "_uuid": "57c15ac47955e81fa13906208c3097ba20b95850"}}, {"source": ["#remove useless columns, it's useless column\n", "#data.drop(['Name','Age','Ticket','Fare','Cabin','Fare_Range','PassengerId'],axis=1,inplace=True)\n", "\n", "total_count = len(data)\n", "train_count = int(len(data) * 0.8)\n", "test_count = total_count - train_count\n", "\n", "train_data = data[:train_count]\n", "test_data = data[train_count-1:-1]\n", "# define columns of X and column of Y\n", "x_columns = ['Pclass','Sex','Age_band','SibSp','Parch','Fare_cat','Embarked','Alone','Family_Size','NameTitle']\n", "y_columns = ['Survived']\n", "train_data_X = train_data[x_columns]\n", "train_data_Y = train_data[y_columns]\n", "test_data_X = test_data[x_columns]\n", "test_data_Y = test_data[y_columns]\n", "test_data_X.head()\n", "#print(total_count,train_count, test_count, len(train_data),len(test_data))\n", "#891 712 179 712 179\n", "p0 = len(train_data.loc[train_data['Survived']==0])/len(train_data)\n", "p1 = len(train_data.loc[train_data['Survived']==1])/len(train_data)"], "cell_type": "code", "metadata": {"_cell_guid": "9856a498-eac8-4dc6-b6d5-34555c703c51", "_uuid": "4e1244bdede56fe403055d14860e0b96ca479440"}, "outputs": [], "execution_count": 41}, {"source": ["# get each attribute conditional probability\n", "def getConditionProb(data,attribute,y_attribute):\n", "    probDict = {}\n", "    data_y0 = data.loc[data[y_attribute]==0]\n", "    data_y1 = data.loc[data[y_attribute]==1]\n", "    y0_count = len(data_y0)\n", "    y1_count = len(data_y1)\n", "    for att in attribute:\n", "        att_values = pd.unique(data[att].values)\n", "        for att_v in att_values:\n", "            # laplace smoothing\n", "            #print(\"Pclass=3\", len(data_y0.loc[data_y0[]]))\n", "            p_att_v_y0 = (len(data_y0.loc[data_y0[att]==att_v]) + 1)/(y0_count + len(att_values))\n", "            p_att_v_y1 = (len(data_y1.loc[data_y1[att]==att_v]) + 1)/(y1_count + len(att_values))\n", "            #print(\"att:\" , att , \", att_v:\" , att_v, p_att_v_y0, p_att_v_y1)\n", "            y0_key= str(att) + \"_\" + str(att_v) + \"_y0\"\n", "            y1_key= str(att) + \"_\" + str(att_v) + \"_y1\"\n", "            #probDict[att  \"_\"  att_v  \"_y0\"] = p_att_v_y0\n", "            #probDict[att  \"_\"  att_v  \"_y1\"] = p_att_v_y1\n", "            probDict[y0_key] = p_att_v_y0\n", "            probDict[y1_key] = p_att_v_y1\n", "    return probDict"], "cell_type": "code", "metadata": {"_cell_guid": "e7839d1b-3b05-4318-9c27-80ea7d635036", "_uuid": "06d1a71f04ac39c5bd4f93739fb1cca6bab50ff5"}, "outputs": [], "execution_count": 53}, {"source": ["# use only sex attribute to predict\n", "# train the model\n", "\n", "def classifyPassenger(passenger, attrs,probDict, p0, p1):\n", "    # use log to avoid overflow\n", "    p_survived = np.log(p1)  \n", "    p_not_survived = np.log(p0)  \n", "    for att in attrs:\n", "        att_v = passenger[att]\n", "        y0_key= str(att) + \"_\" + str(att_v) + \"_y0\"\n", "        y1_key= str(att) + \"_\" + str(att_v) + \"_y1\"\n", "        #print(y1_key + \":\" + str(probDict[y1_key]))\n", "        #print(y0_key + \":\" + str(probDict[y0_key]))\n", "        p_survived = p_survived + np.log(probDict[y1_key])\n", "        p_not_survived = p_not_survived + np.log(probDict[y0_key])\n", "    if p_survived > p_not_survived:\n", "        return 1\n", "    return 0\n", "\n", "def get_err_rate(data,data_Y):\n", "    data_Y['predict'] = data.apply(lambda row: classifyPassenger(row,['Sex','Age_band'],probDict,p0,p1),axis=1)\n", "    data_Y['notEqual'] = data_Y['predict'] - data_Y['Survived']\n", "    #data.head(20)\n", "    # calculate the error rate\n", "    err_rate = len(data_Y.loc[data_Y['notEqual']!=0])/len(data_Y)\n", "    print(err_rate)\n", "    return err_rate\n", "probDict = getConditionProb(data, x_columns, 'Survived')\n", "\n", "train_err_rate = get_err_rate(data, data)\n", "#test_err_rate = get_err_rate(test_data_X, test_data_Y)\n", "#print(train_err_rate)\n", "# create a submission file, use sex only the score is 0.76555\n", "#test_data_for_submission = pd.read_csv('../input/test.csv')# test data don't have survived value\n", "submission_data['predict'] = submission_data.apply(lambda row: classifyPassenger(row,['Sex','Age_band'],probDict,p0,p1),axis=1)\n", "submission01 = pd.DataFrame({'PassengerId':submission_data['PassengerId'],'Survived':submission_data['predict']})\n", "submission01.to_csv('submission01.csv',index=False)    "], "cell_type": "code", "metadata": {"_cell_guid": "61b51afe-89d0-4a5b-a0f4-2df4ff5b032b", "_uuid": "be356ab85c5eaf887bcaa4cd6f23bff3d3ebf784", "scrolled": false}, "outputs": [], "execution_count": 59}, {"source": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "61b643b9-36ad-463c-94a3-eb6194bc7b8a", "_uuid": "7603bec37c8e569e9078a9699cef74727376f3e6"}, "outputs": [], "execution_count": null}]}