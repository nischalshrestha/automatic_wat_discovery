{"nbformat_minor": 1, "metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python", "file_extension": ".py", "mimetype": "text/x-python", "version": "3.6.1", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "cells": [{"outputs": [], "metadata": {"_uuid": "559b1c6d4ba0ca9ca57d275692911bff58338693", "_cell_guid": "a2799f28-2415-4d81-8036-d5ead93426a9"}, "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "execution_count": 2}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "8b9342d881d4afd756013cb0d7902418c3602e95", "_cell_guid": "adcc3e8b-a0ad-43d8-818c-478e06552ef4"}, "cell_type": "code", "source": ["from sklearn.preprocessing import LabelEncoder\n", "from sklearn.metrics import accuracy_score\n", "import matplotlib.pylab as plt\n", "import seaborn as sns\n", "import pandas as pd\n", "import numpy as np\n", "import random\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "\n", "DATA_DIR = '../input/'"], "execution_count": 3}, {"outputs": [], "metadata": {"_uuid": "a580f12f3c4029888b8acbe4cee718e104d39d69", "_cell_guid": "c9babb8a-1fa2-410d-9d42-235d8c616508"}, "cell_type": "code", "source": ["train_csv = pd.read_csv(DATA_DIR + 'train.csv')\n", "test_csv = pd.read_csv(DATA_DIR + 'test.csv')\n", "\n", "print('There are %s examples in the training set and %s examples in the test set' % (train_csv.shape[0], test_csv.shape[0]))\n", "print('\\n')\n", "print('The different variables that we have at our disposal are : %s' % ', '.join(list(train_csv.columns)))"], "execution_count": 4}, {"metadata": {"_uuid": "139f733105a740d5f55850b4d486609eb48cfe76", "_cell_guid": "0f152daf-6382-487e-98dc-839107bbce89"}, "cell_type": "markdown", "source": ["# Who Should Live And Die\n", "\n", "Based on some a priori we can assume that some categories of people are, unfortunately, more inclined to to die that others."]}, {"outputs": [], "metadata": {"_uuid": "41235b256ac79ec5b41a9437068a66561b293695", "_cell_guid": "0494efc8-05bc-40c0-87da-18042288e754"}, "cell_type": "code", "source": ["plt.figure()\n", "plt.suptitle('Proportion of male and female that survived')\n", "g = sns.countplot(x=\"Sex\", hue='Survived', data=train_csv);\n", "plt.show()"], "execution_count": 5}, {"metadata": {"_uuid": "cf55cef7ab1f433c79a3c0d9d71e125ed66bee8d", "_cell_guid": "8a0b0c5a-dc2f-4ffb-bb96-5baa5b190c84"}, "cell_type": "markdown", "source": ["We can see that if you were a woman on board you had far more luck to stay alive."]}, {"outputs": [], "metadata": {"_uuid": "1826eb373d6bde46c611ec8f03e19051bf673cda", "_cell_guid": "ff81bbbd-1bcd-4c68-af50-a35d0940692e"}, "cell_type": "code", "source": ["plt.figure()\n", "plt.suptitle('Proportion of people that survived depending on their socio-economic status')\n", "g = sns.countplot(x=\"Pclass\", hue='Survived', data=train_csv);\n", "plt.show()"], "execution_count": 6}, {"metadata": {"_uuid": "0628a2f18496ed4867c8d42582a0a2906056b060", "_cell_guid": "ec883731-bc38-4efa-8d4d-d028c486180a"}, "cell_type": "markdown", "source": ["Again we can see that chances are not equal for everyone. If you are from a 'lower' status you had far more chance to die that if you came from a 'upper' status."]}, {"metadata": {"_uuid": "f54d9313f91376f9c2aff2b8d8191a567b955ecc", "_cell_guid": "fbfa454f-a2ff-4c12-8ac1-91e274c7f3d2"}, "cell_type": "markdown", "source": ["# Model Building"]}, {"metadata": {"_uuid": "c7ce60da2b5c2696525cd32755f7db20e7bc9937", "_cell_guid": "ca4beecc-82a2-438d-a312-92914aeaf8ec"}, "cell_type": "markdown", "source": ["## Useful functions"]}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "e4437c4253580033bbfbb7df87d9c919dba240bd", "_cell_guid": "1d7d914a-a160-454a-8954-0fa6561a17bb"}, "cell_type": "code", "source": ["def label_encoding(dataframe, labels):\n", "    \"\"\"\n", "    Encode categorical variable into numerical values\n", "    \"\"\"\n", "\n", "    le = LabelEncoder()\n", "    for label in labels:\n", "        le.fit(dataframe[label])\n", "        dataframe[label] = le.transform(dataframe[label])\n", "\n", "    return dataframe\n", "\n", "def normalize_features(X_train):\n", "    \"\"\"\n", "    Normalize the features by substracting the mean \n", "    and dividing by the standard deviation\n", "    \"\"\"\n", "\n", "    for features in X_train:\n", "        feats = X_train[features].tolist()\n", "        mean = np.mean(feats)\n", "        std = np.std(feats)\n", "        feats = (feats - mean)/std\n", "        X_train[features] = feats\n", "\n", "    return X_train\n", "\n", "def get_training_data():\n", "    \"\"\"\n", "    Clean the data by processing the nan values\n", "    and normalizing the features\n", "    \"\"\"\n", "    train_csv = pd.read_csv(DATA_DIR + 'train.csv')\n", "\n", "    train_csv['Cabin'] = train_csv['Cabin'].fillna('C0')\n", "    train_csv['Embarked'] = train_csv['Embarked'].fillna('0')\n", "    train_csv['Age'] = train_csv['Age'].fillna(train_csv['Age'].mean())\n", "    train_csv = label_encoding(train_csv, ['Sex', 'Ticket', 'Cabin', 'Embarked'])\n", "\n", "    X_train = train_csv[['Pclass', 'Sex', 'Age',  'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']]\n", "    Y_train = train_csv['Survived']\n", "\n", "    normalize_features(X_train)\n", "\n", "    return X_train.as_matrix(), Y_train.as_matrix()\n", "\n", "def get_testing_data():\n", "\n", "    test_csv = pd.read_csv(DATA_DIR + 'test.csv')\n", "\n", "    test_csv['Cabin'] = test_csv['Cabin'].fillna('C0')\n", "    test_csv['Embarked'] = test_csv['Embarked'].fillna('0')\n", "    test_csv['Age'] = test_csv['Age'].fillna(test_csv['Age'].mean())\n", "    test_csv['Fare'] = test_csv['Fare'].fillna(test_csv['Fare'].mean())\n", "    test_csv = label_encoding(test_csv, ['Sex', 'Ticket', 'Cabin', 'Embarked'])\n", "\n", "    X_test = test_csv[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']]\n", "\n", "    normalize_features(X_test)\n", "\n", "    return X_test.as_matrix(), test_csv['PassengerId']"], "execution_count": 7}, {"metadata": {"_uuid": "2fd6105015228ee272411a1273859fa4d358f101", "_cell_guid": "58623b86-4af2-4d33-bfa0-9adb2889a2d2"}, "cell_type": "markdown", "source": ["## Logistic regression training "]}, {"outputs": [], "metadata": {"_uuid": "be699dcb5ddad78ce912c6c6e300a8fcf3f548e0", "_cell_guid": "b544f14f-a332-489f-b47b-4ff4a05b765d"}, "cell_type": "code", "source": ["X_train, Y_train = get_training_data()\n", "\n", "X_train, Y_train = get_training_data()\n", "\n", "# Hyperparameters initialization\n", "lr = 0.05\n", "\n", "# Parameters initialization\n", "weights = np.random.normal(0, 0.1, 9)\n", "biais = random.normalvariate(0, 0.1)\n", "\n", "m = X_train.shape[0]\n", "for epoch in range(300):\n", "\n", "    # Forward pass\n", "    Z = np.dot(X_train, weights) + biais\n", "    A = 1 / (1 + np.exp(-Z))\n", "\n", "    #Loss Computation\n", "    J = np.sum(-(Y_train * np.log(A) + (1 - Y_train) * np.log(1 - A))) / m\n", "\n", "    # Gradient computation\n", "    dZ = A - Y_train\n", "    dw = np.dot(dZ, X_train) / m\n", "    db = np.sum(dZ) / m\n", "\n", "    # Update weights\n", "    weights = weights - lr * dw\n", "    biais = biais - lr * db\n", "    \n", "    if epoch % 10 == 0:\n", "        print(\"epoch %s - loss %s\" % (epoch, J))"], "execution_count": 8}, {"metadata": {"_uuid": "ea7c5f20b6b4294a595cda498c6aa28cb2d3bf7e", "_cell_guid": "ebe45077-3090-499c-b2a9-4ff78cca5b0d"}, "cell_type": "markdown", "source": ["## Logistic regression prediction "]}, {"outputs": [], "metadata": {"_uuid": "b89007f0912c82c78724ffe61f7a28becde40df5", "_cell_guid": "5babea57-dba2-45f6-9d8d-66c685fdb1f5"}, "cell_type": "code", "source": [" X_test, PassengerId = get_testing_data()\n", "\n", "preds = []\n", "for feats in X_test:\n", "\n", "    z = np.dot(feats, weights) + biais\n", "    a = 1 / (1 + np.exp(-z))\n", "\n", "    if a > 0.5:\n", "        preds.append(1)\n", "    elif a <= 0.5:\n", "        preds.append(0)\n", "      \n", "sample_ids = np.random.choice(PassengerId, 10)\n", "\n", "for id, value in enumerate(sample_ids):\n", "    print('Passenger id : %s - Survived : %s' % (value, preds[id]))\n", "    \n", "gendermodel_csv = pd.read_csv(DATA_DIR + 'gendermodel.csv')\n", "accuracy = accuracy_score(list(gendermodel_csv['Survived']), preds)\n", "print('\\n')\n", "print('The accuracy of the model is of %s : ' % accuracy)"], "execution_count": 9}], "nbformat": 4}