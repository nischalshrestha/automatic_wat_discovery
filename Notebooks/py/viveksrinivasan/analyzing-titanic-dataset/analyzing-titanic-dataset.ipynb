{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0f19c2db-4267-daac-c75b-51e9c1d0c11e"
      },
      "source": [
        "This Ipython notebook helps you understand titanic data and build new features from existing ones thereby preparing data for model building. The notebook is divided into five basic parts\n",
        "\n",
        " - Visualizing Data\n",
        " - Feature Engineering\n",
        " - Logistic Regression Model\n",
        " - Feature Selection\n",
        " - Random Forest Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "763b3350-1268-0c97-ea9f-4b2d8277a223"
      },
      "source": [
        "## Visualizing Data ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "021ab962-612f-b872-dd89-1e3f373b3503"
      },
      "source": [
        "Here we are trying to visualize survival vs Gender | Embankment | Age | Fare.\n",
        "The feature has got many missing values, so it has be handled before using. As of now we will be filling the missing value with median age for analysis. Later in feature engineering steps we will dealing the missing values in lot more meaningful way.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a38492b3-40d6-f1d4-e4c9-449bbd96f784"
      },
      "outputs": [],
      "source": [
        "##### Importing Libraries #####\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "##### Setting Options #######\n",
        "matplotlib.style.use('ggplot')\n",
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.max_rows = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "926ea28d-2620-766c-74af-af91a1e506f9"
      },
      "outputs": [],
      "source": [
        "###### Reading Train and Test Csv #####\n",
        "data = pd.read_csv('../input/train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e3dd3b67-7313-48a5-413d-6fecd9bb849a"
      },
      "outputs": [],
      "source": [
        "##### Imputing Missing Values for Age ######\n",
        "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "170e625e-81fa-8025-b086-555ab7fbad21"
      },
      "outputs": [],
      "source": [
        "###### Gender Vs Survival Chart ######\n",
        "survived_sex = data[data['Survived']==1]['Sex'].value_counts()\n",
        "dead_sex = data[data['Survived']==0]['Sex'].value_counts()\n",
        "df = pd.DataFrame([survived_sex,dead_sex])\n",
        "df.index = ['Survived','Dead']\n",
        "df.plot(kind='bar',stacked=True, figsize=(9,6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e4d596a2-4fa9-173b-b36b-a21ef09ad2bb"
      },
      "outputs": [],
      "source": [
        "##### Embarkment Vs Survival \n",
        "survived_embark = data[data['Survived']==1]['Embarked'].value_counts()\n",
        "dead_embark = data[data['Survived']==0]['Embarked'].value_counts()\n",
        "df = pd.DataFrame([survived_embark,dead_embark])\n",
        "df.index = ['Survived','Dead']\n",
        "df.plot(kind='bar',stacked=True, figsize=(9,6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "46bd63f5-54ca-f5ec-5330-9b3df5443658"
      },
      "outputs": [],
      "source": [
        "####### Age Vs Survival Chart ####\n",
        "figure = plt.figure(figsize=(9,6))\n",
        "plt.hist([data[data['Survived']==1]['Age'],data[data['Survived']==0]['Age']], stacked=True, color = ['g','r'],\n",
        "         bins = 30,label = ['Survived','Dead'])\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Number of passengers')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7ef8de04-4b6c-166d-6e98-9788fe1aaa35"
      },
      "outputs": [],
      "source": [
        "######## Fare Vs Survival #####\n",
        "figure = plt.figure(figsize=(9,6))\n",
        "plt.hist([data[data['Survived']==1]['Fare'],data[data['Survived']==0]['Fare']], stacked=True, color = ['g','r'],\n",
        "         bins = 30,label = ['Survived','Dead'])\n",
        "plt.xlabel('Fare')\n",
        "plt.ylabel('Number of passengers')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8201dac6-b44f-af72-28b9-665ed8d69478"
      },
      "outputs": [],
      "source": [
        "##### Age Vs Fare Vs Survival ####\n",
        "plt.figure(figsize=(9,6))\n",
        "ax = plt.subplot()\n",
        "ax.scatter(data[data['Survived']==1]['Age'],data[data['Survived']==1]['Fare'],c='green',s=40)\n",
        "ax.scatter(data[data['Survived']==0]['Age'],data[data['Survived']==0]['Fare'],c='red',s=40)\n",
        "ax.set_xlabel('Age')\n",
        "ax.set_ylabel('Fare')\n",
        "ax.legend(('survived','dead'),scatterpoints=1,loc='upper right',fontsize=15,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f90c95f7-7fca-c12c-434e-826d88c878ff"
      },
      "source": [
        "## Feature Engineering ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3970f1df-a2a4-312a-308a-8303a0d8a282"
      },
      "source": [
        "We cannot use the data for model building as they are non numerical columns in the data. So we will combination of following cleaning steps for all the columns.\n",
        "\n",
        " - Filling missing values\n",
        " - Dummifying the column\n",
        " - Extracting new features from existing column (For example title and family)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2117a257-1131-7c4e-d585-392589dbbde6"
      },
      "outputs": [],
      "source": [
        "########## Combining Test And Train Data For Feature Engineering #####\n",
        "def get_combined_data():\n",
        "    # reading train data\n",
        "    train = pd.read_csv('../input/train.csv')\n",
        "    \n",
        "    # reading test data\n",
        "    test = pd.read_csv('../input/test.csv')\n",
        "\n",
        "    # extracting and then removing the targets from the training data \n",
        "    targets = train.Survived\n",
        "    train.drop('Survived',1,inplace=True)\n",
        "    \n",
        "\n",
        "    # merging train data and test data for future feature engineering\n",
        "    combined = train.append(test)\n",
        "    combined.reset_index(inplace=True)\n",
        "    combined.drop('index',inplace=True,axis=1)\n",
        "    \n",
        "    return combined\n",
        "\n",
        "combined = get_combined_data()\n",
        "combined.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e75a0ff5-978f-a48b-8309-e421f856b4c0"
      },
      "outputs": [],
      "source": [
        "####### Extracting the passenger titles #####\n",
        "def get_titles():\n",
        "\n",
        "    global combined\n",
        "    \n",
        "    # we extract the title from each name\n",
        "    combined['Title'] = combined['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
        "    \n",
        "    # a map of more aggregated titles\n",
        "    Title_Dictionary = {\n",
        "                        \"Capt\":       \"Officer\",\n",
        "                        \"Col\":        \"Officer\",\n",
        "                        \"Major\":      \"Officer\",\n",
        "                        \"Jonkheer\":   \"Royalty\",\n",
        "                        \"Don\":        \"Royalty\",\n",
        "                        \"Sir\" :       \"Royalty\",\n",
        "                        \"Dr\":         \"Officer\",\n",
        "                        \"Rev\":        \"Officer\",\n",
        "                        \"the Countess\":\"Royalty\",\n",
        "                        \"Dona\":       \"Royalty\",\n",
        "                        \"Mme\":        \"Mrs\",\n",
        "                        \"Mlle\":       \"Miss\",\n",
        "                        \"Ms\":         \"Mrs\",\n",
        "                        \"Mr\" :        \"Mr\",\n",
        "                        \"Mrs\" :       \"Mrs\",\n",
        "                        \"Miss\" :      \"Miss\",\n",
        "                        \"Master\" :    \"Master\",\n",
        "                        \"Lady\" :      \"Royalty\"\n",
        "\n",
        "                        }\n",
        "    \n",
        "    # we map each title\n",
        "    combined['Title'] = combined.Title.map(Title_Dictionary)\n",
        "    \n",
        "get_titles()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "39d71248-c15e-b16e-6526-ba0afbd20169"
      },
      "outputs": [],
      "source": [
        "##### Filling Missing Values In Age Column #####\n",
        "combined[\"Age\"] = combined.groupby(['Sex','Pclass','Title'])['Age'].transform(lambda x: x.fillna(x.median()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "43f4236c-418e-339c-7914-3eac0b08bb89"
      },
      "outputs": [],
      "source": [
        "def process_names():\n",
        "    \n",
        "    global combined\n",
        "    # we clean the Name variable\n",
        "    combined.drop('Name',axis=1,inplace=True)\n",
        "    \n",
        "    # encoding in dummy variable\n",
        "    titles_dummies = pd.get_dummies(combined['Title'],prefix='Title')\n",
        "    combined = pd.concat([combined,titles_dummies],axis=1)\n",
        "    \n",
        "    # removing the title variable\n",
        "    combined.drop('Title',axis=1,inplace=True)\n",
        "    \n",
        "process_names()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "463c355e-49ad-cebb-73f3-299a7f2ef183"
      },
      "outputs": [],
      "source": [
        "##### Processing Fare ######\n",
        "def process_fares():\n",
        "    \n",
        "    global combined\n",
        "    # there's one missing fare value - replacing it with the mean.\n",
        "    combined.Fare.fillna(combined.Fare.mean(),inplace=True)\n",
        "    \n",
        "process_fares()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "273b19ba-64c0-64d0-9409-f24c04b6a4b3"
      },
      "outputs": [],
      "source": [
        "###### Processing Embarked #####\n",
        "\n",
        "def process_embarked():\n",
        "    \n",
        "    global combined\n",
        "    # two missing embarked values - filling them with the most frequent one (S)\n",
        "    combined.Embarked.fillna('S',inplace=True)\n",
        "    \n",
        "    # dummy encoding \n",
        "    embarked_dummies = pd.get_dummies(combined['Embarked'],prefix='Embarked')\n",
        "    combined = pd.concat([combined,embarked_dummies],axis=1)\n",
        "    combined.drop('Embarked',axis=1,inplace=True)\n",
        "\n",
        "process_embarked()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2f69675c-03fa-3579-164c-7977cb7cb287"
      },
      "outputs": [],
      "source": [
        "##### Processing Cabin #####\n",
        "def process_cabin():\n",
        "    \n",
        "    global combined\n",
        "    \n",
        "    # replacing missing cabins with U (for Unknown)\n",
        "    combined.Cabin.fillna('U',inplace=True)\n",
        "    \n",
        "    # mapping each Cabin value with the cabin letter\n",
        "    combined['Cabin'] = combined['Cabin'].map(lambda c : c[0])\n",
        "    \n",
        "    # dummy encoding ...\n",
        "    cabin_dummies = pd.get_dummies(combined['Cabin'],prefix='Cabin')\n",
        "    \n",
        "    combined = pd.concat([combined,cabin_dummies],axis=1)\n",
        "    \n",
        "    combined.drop('Cabin',axis=1,inplace=True)\n",
        "\n",
        "process_cabin()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ba9e7aed-8a54-5036-7597-22e4e757d9ab"
      },
      "outputs": [],
      "source": [
        "##### Processing Gender #####\n",
        "def process_gender():\n",
        "    \n",
        "    global combined\n",
        "    # mapping string values to numerical one \n",
        "    combined['Sex'] = combined['Sex'].map({'male':1,'female':0})\n",
        "    \n",
        "process_gender()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0e78d73f-4425-ca11-82c4-3e89c3e893d2"
      },
      "outputs": [],
      "source": [
        "#### Processing Pclass\n",
        "\n",
        "def process_pclass():\n",
        "    \n",
        "    global combined\n",
        "    # encoding into 3 categories:\n",
        "    pclass_dummies = pd.get_dummies(combined['Pclass'],prefix=\"Pclass\")\n",
        "    \n",
        "    # adding dummy variables\n",
        "    combined = pd.concat([combined,pclass_dummies],axis=1)\n",
        "    \n",
        "    # removing \"Pclass\"\n",
        "    \n",
        "    combined.drop('Pclass',axis=1,inplace=True)\n",
        "    \n",
        "\n",
        "process_pclass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f2b35852-dd5a-6198-59c0-3ac1107cc57d"
      },
      "outputs": [],
      "source": [
        "def process_ticket():\n",
        "    \n",
        "    global combined\n",
        "    \n",
        "    # a function that extracts each prefix of the ticket, returns 'XXX' if no prefix (i.e the ticket is a digit)\n",
        "    def cleanTicket(ticket):\n",
        "        ticket = ticket.replace('.','')\n",
        "        ticket = ticket.replace('/','')\n",
        "        ticket = ticket.split()\n",
        "        ticket = map(lambda t : t.strip() , ticket)\n",
        "        ticket = list(filter(lambda t : not t.isdigit(), ticket))\n",
        "        if len(ticket) > 0:\n",
        "            return ticket[0]\n",
        "        else: \n",
        "            return 'XXX'\n",
        "    \n",
        "\n",
        "    # Extracting dummy variables from tickets:\n",
        "\n",
        "    combined['Ticket'] = combined['Ticket'].map(cleanTicket)\n",
        "    tickets_dummies = pd.get_dummies(combined['Ticket'],prefix='Ticket')\n",
        "    combined = pd.concat([combined, tickets_dummies],axis=1)\n",
        "    combined.drop('Ticket',inplace=True,axis=1)\n",
        "\n",
        "ticket  = process_ticket()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aa30c61f-5bc9-51fa-9287-505b1d7301a1"
      },
      "outputs": [],
      "source": [
        "####### Processing Family ######\n",
        "\n",
        "def process_family():\n",
        "    \n",
        "    global combined\n",
        "    # introducing a new feature : the size of families (including the passenger)\n",
        "    combined['FamilySize'] = combined['Parch'] + combined['SibSp'] + 1\n",
        "    \n",
        "    # introducing other features based on the family size\n",
        "    combined['Singleton'] = combined['FamilySize'].map(lambda s : 1 if s == 1 else 0)\n",
        "    combined['SmallFamily'] = combined['FamilySize'].map(lambda s : 1 if 2<=s<=4 else 0)\n",
        "    combined['LargeFamily'] = combined['FamilySize'].map(lambda s : 1 if 5<=s else 0)\n",
        "    \n",
        "process_family()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "89c7e183-74fb-6fae-9ebd-3502d679b41d"
      },
      "outputs": [],
      "source": [
        "###### Split Test And Train #####\n",
        "def recover_train_test_target():\n",
        "    global combined\n",
        "    \n",
        "    train0 = pd.read_csv('../input/train.csv')\n",
        "    \n",
        "    targets = train0.Survived\n",
        "    train = combined.ix[0:890]\n",
        "    test = combined.ix[891:]\n",
        "    \n",
        "    return train,test,targets\n",
        "\n",
        "train,test,targets = recover_train_test_target()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a3b74965-1e66-0d73-6a2d-67b318696e31"
      },
      "source": [
        "## Logistic Regression Model ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "46412219-f6d4-f96a-ab28-65d1a9942ffa"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc,confusion_matrix,classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e1a88ae9-83da-f1f8-3913-2b32149b3e0a"
      },
      "outputs": [],
      "source": [
        "# Initialize logistic regression model\n",
        "log_model = linear_model.LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "log_model.fit(X = train,y = targets)\n",
        "\n",
        "# Make predictions\n",
        "preds = log_model.predict(X= train)\n",
        "\n",
        "# Check trained model intercept\n",
        "print (log_model.intercept_)\n",
        "\n",
        "# Check trained model coefficients\n",
        "print (log_model.coef_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dfc6dc57-90ba-e05d-e946-9c4519048292"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    import itertools\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1c1bd6d0-9447-c277-5488-6148978d3c1e"
      },
      "outputs": [],
      "source": [
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_true=targets,y_pred=preds)\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=[\"Dead\",\"Survived\"],\n",
        "                      title='Confusion matrix')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "# plt.figure()\n",
        "# plot_confusion_matrix(cnf_matrix, classes=[\"Dead\",\"Survived\"], normalize=True,\n",
        "#                       title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "819b9028-ddf7-d5d7-2b75-742bde74fb5e"
      },
      "outputs": [],
      "source": [
        "###### Constructing ROC And AUC ####\n",
        "fpr, tpr, threshold = metrics.roc_curve(targets, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "plt.title('ROC Curve')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('1 - False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4cfc31a4-e239-1d8a-7812-d9436da96c5e"
      },
      "outputs": [],
      "source": [
        "# Make test set predictions\n",
        "test_preds = log_model.predict(X=test)\n",
        "\n",
        "# Create a submission for Kaggle\n",
        "submission = pd.DataFrame({\"PassengerId\":test[\"PassengerId\"],\n",
        "                           \"Survived\":test_preds})\n",
        "\n",
        "# Save submission to CPassengerId,Survived\n",
        "submission.to_csv(\"tutorial_logreg_submission.csv\", index=False)       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bf204b31-fb4f-3f63-131e-1c736e77fc0d"
      },
      "source": [
        "## Feature Selection ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fab01b9d-e50f-c03b-c0a3-da1f4a427577"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "clf = ExtraTreesClassifier(n_estimators=200)\n",
        "clf = clf.fit(train, targets)\n",
        "features = pd.DataFrame()\n",
        "features['feature'] = train.columns\n",
        "features['importance'] = clf.feature_importances_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "efa3c32c-2e98-5c60-49bb-a3f2eefb1f13"
      },
      "outputs": [],
      "source": [
        "features.sort(['importance'],ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "64f2abf9-e9b5-7de1-aa7c-138a64944c1e"
      },
      "outputs": [],
      "source": [
        "model = SelectFromModel(clf, prefit=True)\n",
        "train_new = model.transform(train)\n",
        "print (train_new.shape)\n",
        "\n",
        "\n",
        "test_new = model.transform(test)\n",
        "print (test_new.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2a193990-7b79-7d6f-d6af-0ede29466607"
      },
      "source": [
        "## Random Forest ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "941edcf5-0023-90b7-4af3-fb5824ee1c28"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.cross_validation import StratifiedKFold\n",
        "from sklearn.grid_search import GridSearchCV\n",
        "\n",
        "forest = RandomForestClassifier(max_features='sqrt')\n",
        "\n",
        "parameter_grid = {\n",
        "                 'max_depth' : [4,5,6,7,8],\n",
        "                 'n_estimators': [200,210,240,250],\n",
        "                 'criterion': ['gini','entropy']\n",
        "                 }\n",
        "\n",
        "cross_validation = StratifiedKFold(targets, n_folds=5)\n",
        "\n",
        "grid_search = GridSearchCV(forest,\n",
        "                           param_grid=parameter_grid,\n",
        "                           cv=cross_validation)\n",
        "\n",
        "grid_search.fit(train_new, targets)\n",
        "\n",
        "preds = grid_search.predict(train_new).astype(int)\n",
        "\n",
        "print('Best score: {}'.format(grid_search.best_score_))\n",
        "print('Best parameters: {}'.format(grid_search.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2a390c21-9f72-333f-19d0-cc9dcfa66e69"
      },
      "outputs": [],
      "source": [
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_true=targets,y_pred=preds)\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=[\"Dead\",\"Survived\"],title='Confusion matrix')\n",
        "\n",
        "# Plot normalized confusion matrix\n",
        "# plt.figure()\n",
        "# plot_confusion_matrix(cnf_matrix, classes=[\"Dead\",\"Survived\"], normalize=True,\n",
        "#                       title='Normalized confusion matrix')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b592384c-fb4f-7cfb-224e-3c2970edc328"
      },
      "outputs": [],
      "source": [
        "###### Constructing ROC And AUC ####\n",
        "fpr, tpr, threshold = metrics.roc_curve(targets, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "plt.title('ROC Curve')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8f3a8e4b-80bd-52f1-8832-f4677e1f93dd"
      },
      "outputs": [],
      "source": [
        "# Make test set predictions\n",
        "test_preds = grid_search.predict(X=test_new)\n",
        "\n",
        "# Create a submission for Kaggle\n",
        "submission = pd.DataFrame({\"PassengerId\":test[\"PassengerId\"],\"Survived\":test_preds})\n",
        "\n",
        "# Save submission to CSV\n",
        "submission.to_csv(\"tutorial_random_forest_submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "69d3b994-15de-7dfe-a038-bda793fcea34"
      },
      "source": [
        "**Kindly Upvote If You Find It Useful**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8ef11bf9-9454-83c2-5ff1-eab8708c510d"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}