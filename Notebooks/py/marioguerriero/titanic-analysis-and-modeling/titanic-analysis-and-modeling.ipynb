{"cells":[{"metadata":{"_cell_guid":"48e36a98-2e66-4241-984f-a54b4ceb497e","_uuid":"68e976eee50f2fbc9b15852928354b6ff2cda89c"},"cell_type":"markdown","source":"# Importing necessary libraries and dataset and defining utility functions"},{"metadata":{"_cell_guid":"1998990b-f685-47ef-bfe6-9c84b30fef72","_uuid":"295bacb3329d41635ef540b68caf965cea9c2309","collapsed":true,"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport re, math\n\nfrom sklearn import svm, tree\nfrom sklearn.preprocessing import Imputer, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n\ndef turn_dummy(df, prop):\n    dummies = pd.get_dummies(df[prop], prefix=prop)\n    df.drop(prop, axis=1, inplace=True)\n    return pd.concat([df, dummies], axis=1)","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"63ca99ef-7eff-4224-b740-ff2c9753216f","_uuid":"7f14cf58a80c01220e253ab45ca3c5f4d2db0ba4","scrolled":true,"trusted":true},"cell_type":"code","source":"# Read datasets\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\ntest_passenger_id = test_df['PassengerId']\ntrain_df.head()","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ffe4cfe9fe4712f3499429b6d70fb4042a1539fb"},"cell_type":"code","source":"test_df['Survived'] = np.nan\ndataset = train_df.append(test_df)\ndataset = dataset.drop(['PassengerId', 'Name', 'Parch', 'Ticket', 'Cabin'], axis=1)\n\nfor col in dataset.columns.tolist():\n    if dataset[col].dtype == 'object':\n        dataset = turn_dummy(dataset, col)","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"bcbea5c1-2af5-449b-8528-98f351635cc2","_uuid":"4ecf0f7856efad779d9712adb6d33e28216d97de","collapsed":true,"trusted":true},"cell_type":"code","source":"def show_cor(df, x, y):\n    print(df[[x, y]].groupby([x], as_index=False).mean())\n    \ndef make_bins(df, feature, n_bins):\n    \"\"\"\n    In place creation of bins\n    \"\"\"\n    bin_label = feature + '_Bin'\n    df[bin_label] = pd.cut(df[feature], n_bins)\n    label = LabelEncoder()\n    df[bin_label] = label.fit_transform(df[bin_label])\n    \ndef autolabel(rects):\n    \"\"\"\n    Attach a text label above each bar displaying its height\n    \"\"\"\n    for rect in rects:\n        height = rect.get_height()\n        ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n                '%d' % int(height),\n                ha='center', va='bottom')\n        \ndef plot_cor(x, y, labels=None, title=None, xlabel=None, ylabel=None):\n    _,ax = plt.subplots()\n    if xlabel is not None:\n        ax.set_xlabel(xlabel)\n    if ylabel is not None:\n        ax.set_ylabel(ylabel)\n    rect = ax.bar(x, y, align='center', tick_label=labels)\n    ax.set_title(title)\n    \ndef parameters_grid_search(classifier, params, x, y, cv=10):\n    \"\"\"\n    Grid Search to find best parameters for a certain classifier whose\n    performances are evaluated using cross-validation\n    \"\"\"\n    gs = GridSearchCV(classifier(), params, cv=cv)\n    gs.fit(x, y)    \n    return (gs.cv_results_['mean_test_score'].mean(), gs.best_estimator_, gs.best_params_)","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"aabdaf0a-d7a4-45ec-9c74-c68fb6ab10a8","_uuid":"2613333259aaf8412956b6aac46fb7160e028f53"},"cell_type":"markdown","source":"# Exploratory Analysis\nLet's examine the correlation between each feature and the output label and let's see if we can extract some additional information from the existing data."},{"metadata":{"_cell_guid":"2687fec5-ccde-4179-9e0f-fcee770a09f9","_uuid":"cc5fc798cb5ca63c0334c7f5abb2f96b48494094"},"cell_type":"markdown","source":"## Check for missing values\nNumber of missing attributes per class:"},{"metadata":{"_cell_guid":"31a94f2c-07f7-4368-bcfb-02baa90736eb","_uuid":"6ad93919217d6a0c26c5c2d40c0095b494a2a666","trusted":true},"cell_type":"code","source":"train_df.isnull().sum()","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"62480adc-0cde-4f61-8975-0e457849d405","_uuid":"e638884e85071a42180413fa3dd6fba6c97fe750"},"cell_type":"markdown","source":"## PClass\nNot much to do here. Just check percentage of survived people per class."},{"metadata":{"_cell_guid":"fe3fc6f4-b322-4e8b-a39d-281d9818adc1","_uuid":"9eb0bbb632d3419603dec3976a157cde298b6021","trusted":true},"cell_type":"code","source":"tmp = train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean()\n\n_,ax = plt.subplots()\nrect = ax.bar(tmp['Pclass'], tmp['Survived'], align='center', tick_label=[1,2,3])\nax.set_title('% of survival per class')","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"4fdaa395-e116-456a-841f-43a7bb631ae4","_uuid":"17011fb960e9055297e7b5545401cca949b47e35"},"cell_type":"markdown","source":"## Gender\nTurn gender information into a numeric value. And see its correlation with the output label."},{"metadata":{"_cell_guid":"28beb40c-18e1-478e-8e47-ac432bebeeb2","_uuid":"7f650fdf0d60bafab46882bab221e619528d7ea7","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df['Sex'] = train_df['Sex'].map({'male': 0, 'female':1})\ntest_df['Sex'] = test_df['Sex'].map({'male': 0, 'female':1})","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"22587011-04e1-4f8a-8ab7-cd7c6eb3e46b","_uuid":"a80a1834bce4d12a12b9c649cd657dfc65a4499f","trusted":true},"cell_type":"code","source":"# Plot correlation\ntmp = train_df[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean()\nplot_cor(tmp['Sex'], tmp['Survived'], ['Male', 'Female'], '% of survival per gender')","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"3c09dc1e-42f9-4cf8-a22c-9ddc82cb69ee","_uuid":"0217f3b32f3f0f5b8689a126ae1804a9ac78b769"},"cell_type":"markdown","source":"## Age\nDeal with missing values as there are 177 of them."},{"metadata":{"_cell_guid":"c5eaf541-a4f0-4e63-8ece-872c63ad12ba","_uuid":"7f47a1cffedb740864f3f9ab8dc12860064899d5","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df['Age'].fillna(train_df['Age'].median(), inplace = True)\ntest_df['Age'].fillna(test_df['Age'].median(), inplace = True)","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"875f18f7-c7b8-48d9-b1ba-cb6c02990e91","_uuid":"10d1d5a75c41898f93b7a77a0010f48a62bb3e79"},"cell_type":"markdown","source":"Divide age values into bin a check correlations between bins and the output label."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Build age ranges\nn_bins = 5\nmake_bins(train_df, 'Age', n_bins)\nmake_bins(test_df, 'Age', n_bins)\ntmp = train_df[['Age_Bin', 'Survived']].groupby(['Age_Bin'], as_index=False).mean()\nplot_cor(tmp['Age_Bin'], tmp['Survived'], title='% of survival per age bin', xlabel='Age range')","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"2fdf5202-d0c2-4560-bf22-cb0a75fe1de1","_uuid":"0d3744c5cb9e0d942868f715b96b6d4df69bdcac"},"cell_type":"markdown","source":"## Name/Title\nDo some feature engineering on the name, trying to extract nobiliar titles. People with higher nobiliar titles are usually richer and richer people had more chances of survival as seen from the survival percentage per ticket class."},{"metadata":{"_cell_guid":"682385ea-ac8e-4a8a-ad16-90041a7c36ab","_uuid":"6d7e35fba8668785db6cb1c62a0ebb25235e2eaa","trusted":true},"cell_type":"code","source":"def title_engineering(df):\n    df['Title'] = df['Name'].map(lambda x: re.compile(', ([a-zA-Z]*).').findall(x)[0])\n    df['Title'] = df['Title'].apply(lambda x: 'Woman' if x in ['Mrs', 'Ms','Mlle', 'Mme', 'Miss'] else x)\n    df['Title'] = df['Title'].apply(lambda x: 'Man' if x == 'Mr' else x)\n    df['Title'] = df['Title'].apply(lambda x: 'Noble_Man' if x in ['Dr', 'Master', 'Rev', 'Jonkheer', 'Capt', 'Don', 'Major', 'Col', 'Sir'] else x)\n    df['Title'] = df['Title'].apply(lambda x: 'Noble_Lady' if x in ['Dona', 'Lady', 'the Countess', 'the'] else x)\n    \ntitle_engineering(train_df)\ntitle_engineering(test_df)\n\n# Display correlation between titles and survival changes\ntmp = train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\nplot_cor(tmp['Title'], tmp['Survived'], title='% of survival per nobiliar title', xlabel='Nobiliar Title Group')\n\n# Now factorize nobiliar title for future numerical analysis\ntrain_df['Title'] = pd.factorize(train_df['Title'])[0]\ntest_df['Title'] = pd.factorize(test_df['Title'])[0]","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"e3b38dff-a957-4255-8f5c-a3e0f41fb70d","_uuid":"7e7894bd5ad4f42e86e56b4d4ff7ad4362e647dc"},"cell_type":"markdown","source":"## Cabin\nCabin position may have been a key factor for the survival of certain people. However the cabin feature has a lot of missing values wich may affect our model performances. Since 78% of the total cabin values are missing both in the training set and in the test set, it makes no sense in further analyzing it for now so I will just skip on this."},{"metadata":{"_cell_guid":"fde77e53-de8c-4248-8572-503f93003783","_uuid":"36cb0b5123edf0ed1c1684cca3961e522efda0ed"},"cell_type":"markdown","source":"## Family\nPeople with bigger families may have had less chances to survive. Let's explore this possibility."},{"metadata":{"_cell_guid":"ac8c203e-ed48-4f59-9c20-61667ba14066","_uuid":"33ff05b9df0072f2d4aeb93c850c97243ca9d2d5","trusted":true},"cell_type":"code","source":"def family_engineering(df):\n    # Compute family size\n    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n    # Check if the person was alone\n    df['Is_Alone'] = (df['FamilySize'] == 1).astype(int)\n    n_bins = 3\n    make_bins(df, 'FamilySize', n_bins)\n    \ndef family_engineering1(df):\n    # Check for chances of survival of entire families\n    df['LastName'] = df['Name'].apply(lambda x: str.split(x, \",\")[0])\n    DEFAULT_SURVIVAL_VALUE = 0.5\n    df['FamilySurvival'] = DEFAULT_SURVIVAL_VALUE\n\n    for grp, grp_df in df[['Survived','Name', 'LastName', 'Fare', 'Ticket', 'PassengerId',\n                               'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['LastName', 'Fare']):\n        if (len(grp_df) != 1):\n            # A Family group is found.\n            for ind, row in grp_df.iterrows():\n                smax = grp_df.drop(ind)['Survived'].max()\n                smin = grp_df.drop(ind)['Survived'].min()\n                passID = row['PassengerId']\n                if (smax == 1.0):\n                    df.loc[df['PassengerId'] == passID, 'FamilySurvival'] = 1\n                elif (smin==0.0):\n                    df.loc[df['PassengerId'] == passID, 'FamilySurvival'] = 0\n\nfamily_engineering(train_df)\nfamily_engineering1(train_df)\n\nfamily_engineering(test_df)\n\n# Display correlation between titles and survival changes\ntmp = train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean()\nplot_cor(tmp['FamilySize'], tmp['Survived'], title='% of survival per family size', xlabel='Family Size')\n\n# Display correlation between family size and survival chances\ntmp = train_df[['FamilySize_Bin', 'Survived']].groupby(['FamilySize_Bin'], as_index=False).mean()\nplot_cor(tmp['FamilySize_Bin'], tmp['Survived'], title='% of survival per family size group', xlabel='Family Size Group')\n\n# Display correlation between lone people and survival chances\ntmp = train_df[['Is_Alone', 'Survived']].groupby(['Is_Alone'], as_index=False).mean()\nplot_cor(tmp['Is_Alone'], tmp['Survived'], title='% of survival of lone people')\n\n# Display correlation between family survival and survival chances\ntmp = train_df[['FamilySurvival', 'Survived']].groupby(['FamilySurvival'], as_index=False).mean()\nplot_cor(tmp['FamilySurvival'], tmp['Survived'], \n         labels=['Not Survived', 'Unknown', 'Survived'], xlabel='Family\\'s fate', title='% of survival if entire family survived')","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"d2c5de86-7e66-49e8-ade2-7e0665ec0ef3","_uuid":"b89c20494d711e3e765b91ad5935560effd2ead6"},"cell_type":"markdown","source":"The most meaningful correlation I can see here is the one regairding plain family size groups. In fact, smaller families are more likely to survive."},{"metadata":{"_uuid":"b1d8f285dd2f98a3a74d11714027a0d8f91ef48a"},"cell_type":"markdown","source":"# Modeling\n\n## Missing values"},{"metadata":{"trusted":true,"_uuid":"8df88eb33915d7ed6c4978ca5d7d454977b57879"},"cell_type":"code","source":"def compute_missing_values(dataset):\n    tmp_df = dataset.drop(['Survived'], axis=1)\n    total = tmp_df.isnull().sum().sort_values(ascending=False)\n    percent = (tmp_df.isnull().sum()/tmp_df.isnull().count() * 100).sort_values(ascending=False)\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percentage'])\n    return missing_data[missing_data['Percentage'] > 0]\n\ncompute_missing_values(dataset)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5bb47f885b7cdb0a8a0efef660677f820340782"},"cell_type":"code","source":"dataset['Age'].fillna(0, inplace=True)\ndataset['Fare'].fillna(0, inplace=True)\ncompute_missing_values(dataset)","execution_count":33,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"9d69a8ecc65aeb7acdcffea0bd8f87cfb1a48bb7"},"cell_type":"code","source":"train_df = dataset[:len(train_df)].copy()\ntest_df = dataset[-len(test_df):].copy()","execution_count":34,"outputs":[]},{"metadata":{"_cell_guid":"5d0d9dca-740c-4f9c-bcd2-82ed54ee97a7","_uuid":"b4777785c5dd32acd49c97277485a4e353248ab2"},"cell_type":"markdown","source":"## Data Preparation\nLet's prepare data to send in order to make it possible to work on them. I decided to use only the following features: `['Pclass', 'Sex', 'Age_Bin', 'Title', 'FamilySize_Bin']`"},{"metadata":{"_cell_guid":"7cd165a9-7c12-4f6d-ae71-30d6a803d6a0","_uuid":"d637ad08b62be29f4064cbd5eee4218f90325a6a","trusted":true},"cell_type":"code","source":"# Data for the training stage\nX_train = train_df.drop(['Survived'], axis=1).as_matrix()#[['Pclass', 'Sex', 'Age_Bin', 'Title', 'FamilySize_Bin']].values\ny = train_df[['Survived']].values.ravel()\n\n# Data for the test stage\nX_test = test_df.drop(['Survived'], axis=1).as_matrix()#[['Pclass', 'Sex', 'Age_Bin', 'Title', 'FamilySize_Bin']].values","execution_count":35,"outputs":[]},{"metadata":{"_cell_guid":"170b244f-e564-4ab1-8e1e-21e3fb02da02","_uuid":"8dcbaf64e7c0e25b52bfbfa80c44bfc3412b93fb"},"cell_type":"markdown","source":"## Stacking Classifier"},{"metadata":{"_uuid":"c5bd98bf979022d5d796b13e30a4d2aa1e5231d9","trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB \nfrom sklearn.ensemble import RandomForestClassifier\nfrom mlxtend.classifier import StackingClassifier\nfrom xgboost import XGBClassifier\n\nimport numpy as np\n\nclf1 = KNeighborsClassifier(n_neighbors=3)\nclf2 = RandomForestClassifier(n_estimators=20, random_state=1)\nclf3 = GaussianNB()\nxgboost = XGBClassifier()\nlr = LogisticRegression()\nsclf = StackingClassifier(classifiers=[clf1, clf2, clf3, xgboost], \n                          meta_classifier=lr)\n\nprint('10-fold cross validation:\\n')\n\nfor clf, label in zip([clf1, clf2, clf3, sclf], \n                      ['KNN', \n                       'Random Forest', \n                       'Naive Bayes',\n                       'StackingClassifier']):\n\n    scores = model_selection.cross_val_score(clf, X_train, y, \n                                              cv=10, scoring='accuracy')\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n          % (scores.mean(), scores.std(), label))","execution_count":43,"outputs":[]},{"metadata":{"_uuid":"65f09f68a6298317b40d4d5cbf70cd628f3782c7","trusted":true},"cell_type":"code","source":"sclf.fit(X_train, y)","execution_count":44,"outputs":[]},{"metadata":{"_cell_guid":"deaba4cd-7a42-47e2-a119-2820911e0ad7","_uuid":"6024e11a5703701e5f9b6d09d6a41088ab8fa295"},"cell_type":"markdown","source":"# Produce output\nHere I will just use the stacking classifier I just built."},{"metadata":{"_cell_guid":"2ee9fddc-e790-4197-a059-ef75161fa203","_uuid":"9af8b5b2cd5741ba20708239a89e2e6e2ce84b71","collapsed":true,"trusted":true},"cell_type":"code","source":"# Predict values\nprediction = sclf.predict(X_test)\n\n# Build output dataframe\nout_df = pd.DataFrame({\n    'PassengerId': test_passenger_id,\n    'Survived': prediction.astype(int)\n})\n\n# Write to CSV\nout_df.to_csv('titanic-result.csv', index=False)","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"4d0d4c26-66a9-4c09-8a47-0f460a331c63","_uuid":"9eb8d4e093b0cce809117b983c544613ee831e8a"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}