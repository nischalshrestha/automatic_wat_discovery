{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ac9d7490-0131-2d88-0315-f6185d81c44f"
      },
      "source": [
        "# Excercises with the Titanic Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d8d1dfd5-bea6-1065-8ad5-172d035800a5"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import re\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "103e4926-57e2-c806-801c-1a04375b7bfa"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../input/train.csv')\n",
        "df_test = pd.read_csv('../input/test.csv')\n",
        "#df = pd.read_csv('train.csv')\n",
        "#df_test = pd.read_csv('test.csv')\n",
        "\n",
        "print(\"Cols: \", df.columns)\n",
        "\n",
        "print(\"Cab\", len(df[df['Cabin'].isnull()][['Cabin', 'Name' ]]))\n",
        "print(\"Emb\", len(df[df['Embarked'].isnull()][['Embarked', 'Name' ]]))\n",
        "print(\"Sex\", len(df[df['Sex'].isnull()][['Sex', 'Name' ]]))\n",
        "print(\"Age\", len(df[df['Age'].isnull()][['Age', 'Name' ]]))\n",
        "print(\"Par\", len(df[df['Parch'].isnull()][['Parch', 'Name' ]]))\n",
        "print(\"Sib\", len(df[df['SibSp'].isnull()][['SibSp', 'Name' ]]))\n",
        "print(\"Far\", len(df[df['Fare'].isnull()][['Fare', 'Name' ]]))\n",
        "print(\"Tic\", len(df[df['Ticket'].isnull()][['Ticket', 'Name' ]]))\n",
        "print(\"Pcl\", len(df[df['Pclass'].isnull()][['Pclass', 'Name' ]]))\n",
        "\n",
        "# Filling NAs\n",
        "df[\"Embarked\"] = df[\"Embarked\"].fillna('C')\n",
        "\n",
        "# Fill missing fields with columns means\n",
        "df = df.fillna(df.mean())\n",
        "df['Cabin'] = df['Cabin'].fillna('U')\n",
        "\n",
        "# Fill missing fields with columns means\n",
        "df_test = df_test.fillna(df_test.mean())\n",
        "df_test['Cabin'] = df_test['Cabin'].fillna('U')\n",
        "\n",
        "\n",
        "# Extracting numeric part from tickets and creating a new feature\n",
        "ticketnos = []\n",
        "for s in df['Ticket']:\n",
        "    ticketnos.append(''.join([n for n in s.split() if n.isdigit()]))\n",
        "df['TicketNo'] = pd.to_numeric(pd.Series(ticketnos))\n",
        "df['TicketNo'] = df['TicketNo'].fillna(df['TicketNo'].median())\n",
        "\n",
        "ticketnos = []\n",
        "for s in df_test['Ticket']:\n",
        "    ticketnos.append(''.join([n for n in s.split() if n.isdigit()]))\n",
        "df_test['TicketNo'] = pd.to_numeric(pd.Series(ticketnos))\n",
        "\n",
        "\n",
        "print(df.describe())\n",
        "print(df.dtypes)\n",
        "\n",
        "# Transforming cabin code to a deck, adding 'U' (unknown) for the missing ones\n",
        "df['Deck'] = pd.Series([re.split('(\\d.*)',s)[0][0] for s in df['Cabin']])\n",
        "df_test['Deck'] = pd.Series([re.split('(\\d.*)',s)[0][0] for s in df_test['Cabin']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c61ac054-0220-0882-b8f3-1cf648758dbb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c85bba1e-711b-a9d0-7377-4e5f010c3e40"
      },
      "outputs": [],
      "source": [
        "#--------------------\n",
        "# Under-18 feature\n",
        "df['U18'] = df['Age'] < 18\n",
        "df_test['U18'] = df_test['Age'] < 18\n",
        "\n",
        "bins = [0, 18, 23, 55, 80]\n",
        "df['AgeGroup'] = pd.cut(df['Age'], bins)\n",
        "df_test['AgeGroup'] = pd.cut(df_test['Age'], bins)\n",
        "\n",
        "sns.factorplot(x=\"AgeGroup\", y=\"Survived\", data=df)\n",
        "print(df[\"AgeGroup\"].unique())\n",
        "\n",
        "#--------------------\n",
        "# Family size\n",
        "df['FamilySize'] = (df['Parch'] + df['SibSp'])\n",
        "df_test['FamilySize'] = (df_test['Parch'] + df_test['SibSp'])\n",
        "\n",
        "bins = [-1, 2, 5, 7, 11]\n",
        "df['FamilySizeGroup'] = pd.cut(df['FamilySize'], bins)\n",
        "df_test['FamilySizeGroup'] = pd.cut(df_test['FamilySize'], bins)\n",
        "\n",
        "sns.factorplot(x=\"FamilySizeGroup\", y=\"Survived\", data=df)\n",
        "print(df[\"FamilySizeGroup\"].unique())\n",
        "\n",
        "#--------------------\n",
        "# Name length\n",
        "df['NameLen'] = [len(n) for n in df['Name']]\n",
        "df_test['NameLen'] = [len(n) for n in df_test['Name']]\n",
        "\n",
        "bins = [0, 20, 40, 57, 85]\n",
        "df['NameLenGroup'] = pd.cut(df['NameLen'], bins)\n",
        "df_test['NameLenGroup'] = pd.cut(df_test['NameLen'], bins)\n",
        "\n",
        "sns.factorplot(x=\"NameLenGroup\", y=\"Survived\", data=df)\n",
        "print(df[\"NameLenGroup\"].unique())\n",
        "#--------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fc8a1a93-65eb-59aa-2e2e-59c2a5d78a6b"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d1d3bcf2-1e9c-e794-f3cd-a89516ec8fb5"
      },
      "outputs": [],
      "source": [
        "titles = ['Mr.', 'Mrs.', 'Miss.', 'Master.', 'Dr.', 'Col.', 'Capt.', 'Sir.', 'Lady.', 'Countess.', 'Dona.'\n",
        "          , 'Major.', 'Don.', 'Rev.', 'Father', 'Jonkheer.', 'Mlle.', 'Ms.', 'Mme.']\n",
        "\n",
        "df['Title'] = df['Name'].apply(lambda n: str(set([w for w in n.split()]) & set(titles)) )\n",
        "df_test['Title'] = df_test['Name'].apply(lambda n: str(set([w for w in n.split()]) & set(titles)) )\n",
        "\n",
        "df['Title'].unique()\n",
        "df_test['Title'].unique()\n",
        "\n",
        "#df['Name'][df['Title']=='set()']\n",
        "#df_test['Name'][df_test['Title']=='set()']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "57abdd26-df28-d401-f267-813e2c1b1ba5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6eef751a-5850-e398-3822-21e01416b59a"
      },
      "outputs": [],
      "source": [
        "\n",
        "labels = ['Sex', 'Embarked', 'Deck', 'NameLenGroup', 'FamilySizeGroup', 'AgeGroup', 'Title']\n",
        "les = {}\n",
        "\n",
        "for l in labels:\n",
        "    print('labeling ' + l)\n",
        "    les[l] = LabelEncoder()\n",
        "    #print(df[l])\n",
        "    les[l].fit(df[l].append(df_test[l]))\n",
        "    tr = les[l].transform(df[l]) \n",
        "    df.loc[:, l + '_feat'] = pd.Series(tr, index=df.index)\n",
        "\n",
        "    tr_test = les[l].transform(df_test[l]) \n",
        "    df_test.loc[:, l + '_feat'] = pd.Series(tr_test, index=df_test.index)\n",
        "\n",
        "\n",
        "#print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4f98fa9c-d1d0-7784-8b3e-11e48dccb08a"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e978669a-86e6-dc94-4784-aec580caff8a"
      },
      "outputs": [],
      "source": [
        "X_train = df.drop(labels, 1) \\\n",
        "    .drop('Survived', 1) \\\n",
        "    .drop('Cabin', 1) \\\n",
        "    .drop('Ticket', 1) \\\n",
        "    .drop('NameLen', 1) \\\n",
        "    .drop('Name', 1) \\\n",
        "    .drop('PassengerId', 1)\n",
        "y_train = df['Survived']\n",
        "\n",
        "X_test = df_test.drop(labels, 1) \\\n",
        "    .drop('Cabin', 1) \\\n",
        "    .drop('Ticket', 1) \\\n",
        "    .drop('NameLen', 1) \\\n",
        "    .drop('Name', 1) \\\n",
        "    .drop('PassengerId', 1)\n",
        "\n",
        "print(\"X_train shape\", X_train.shape)\n",
        "print(\"X_test  shape\", X_test.shape)\n",
        "\n",
        "#X_train.describe()\n",
        "#X_test.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "af377d57-6861-9312-023f-5647769b396a"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "41f50796-9eb0-6099-4c6f-07ead51341a9"
      },
      "outputs": [],
      "source": [
        "\n",
        "full_set = X_train[:]\n",
        "full_set['Survived'] = y_train\n",
        "\n",
        "plt.title('Pearson Correlation for training set')\n",
        "sns.heatmap(full_set.astype(float).corr(),\n",
        "            linewidths=0.1,\n",
        "            vmax=1.0, \n",
        "            square=True, \n",
        "            cmap=\"PuBuGn\", \n",
        "            linecolor='w', \n",
        "            annot=False)\n",
        "\n",
        "full_set.corr()['Survived'].abs().sort_values(ascending = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4bd80219-450f-a539-80e9-b9f0bf5dbaa7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "325573d7-2bb1-9b39-cc16-e1336e1d9bc2"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.drop('SibSp', 1) \\\n",
        "    .drop('Parch', 1) \n",
        "\n",
        "X_test = X_test.drop('SibSp', 1) \\\n",
        "    .drop('Parch', 1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c5df8095-efec-8e13-daba-95b4e181098d"
      },
      "outputs": [],
      "source": [
        "def dummies(train, test, columns ):\n",
        "    for column in columns:\n",
        "        train[column] = train[column].apply(lambda x: str(x))\n",
        "        test[column] = test[column].apply(lambda x: str(x))\n",
        "        good_cols = [column+'_'+i for i in train[column].unique() if i in test[column].unique()]\n",
        "        train = pd.concat((train, pd.get_dummies(train[column], prefix = column)[good_cols]), axis = 1)\n",
        "        test = pd.concat((test, pd.get_dummies(test[column], prefix = column)[good_cols]), axis = 1)\n",
        "        del train[column]\n",
        "        del test[column]\n",
        "    return train, test\n",
        "X_train, X_test = dummies(X_train, X_test, columns=['Pclass'\n",
        "                                                    , 'Sex_feat'\n",
        "                                                    , 'Embarked_feat'\n",
        "                                                    , 'Deck_feat'\n",
        "                                                    , 'TicketNo'\n",
        "                                                    , 'Title_feat'\n",
        "                                                    , 'AgeGroup_feat'\n",
        "                                                    , 'FamilySizeGroup_feat'\n",
        "                                                    , 'NameLenGroup_feat'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a7382460-6d20-9415-2c5d-6c13da52ea00"
      },
      "outputs": [],
      "source": [
        "full_set = X_train[:]\n",
        "full_set['Survived'] = y_train\n",
        "\n",
        "full_set.corr()['Survived'].abs().sort_values(ascending = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3f968ae6-829e-3bce-3fe5-04ff2f847e9e"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8a0b429d-b60f-71c0-2309-a92f030ebd50"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "\n",
        "X_tr, X_ts, y_tr, y_ts = train_test_split(X_train, y_train, test_size=0.10, random_state=42)\n",
        "print(X_tr.shape, y_tr.shape, X_ts.shape, y_ts.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "790ab01a-1ed6-7637-9002-9ef42397f69c"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "99853907-7f80-217a-4d5c-820acd656ea5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7915a7c4-25c9-9dd6-7f45-6bd7f915b9a9"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f3c822b0-1323-c6fe-6f21-53a7913b6256"
      },
      "outputs": [],
      "source": [
        "#forest = RandomForestClassifier(max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\n",
        "#param_grid = { \"criterion\" : [\"gini\", \"entropy\"]\n",
        "#              , \"min_samples_leaf\" : [1, 5, 10]\n",
        "#              , \"min_samples_split\" : [2, 4, 10, 12, 16]\n",
        "#              , \"n_estimators\": [25, 50, 100, 400, 700]}\n",
        "#gs = GridSearchCV(estimator=forest, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
        "#gs = gs.fit(X_tr, y_tr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "79d72866-74c4-428f-bcad-cb278e1de0dc"
      },
      "outputs": [],
      "source": [
        "#print(gs.best_score_)\n",
        "#print(gs.best_params_)\n",
        "#print(gs.cv_results_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "651a61a9-8262-0c5b-5820-7c02c4b75417"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier( criterion='entropy', \n",
        "                             n_estimators=400,\n",
        "                             min_samples_split=16,\n",
        "                             min_samples_leaf=1,\n",
        "                             max_features='auto',\n",
        "                             oob_score=True,\n",
        "                             random_state=1,\n",
        "                             n_jobs=-1)\n",
        "\n",
        "rf.fit(X_tr, y_tr)\n",
        "pred = rf.predict(X_ts)\n",
        "\n",
        "score = rf.score(X_ts, y_ts)\n",
        "err = math.sqrt(((pred - y_ts)**2).mean())\n",
        "print(\"Error: %.3f Score: %.3f\" % (err, score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "51d56216-7bf2-fc25-f2fe-5a98977177fb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "480c1bcd-4204-71af-e9a5-3bc1444d48f9"
      },
      "outputs": [],
      "source": [
        "pd.concat((pd.DataFrame(X_train.iloc[:, 1:].columns, columns = ['variable']), \n",
        "           pd.DataFrame(rf.feature_importances_, columns = ['importance'])), \n",
        "          axis = 1).sort_values(by='importance', ascending = False)[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "26b74832-bc0d-134a-19f1-fc92a5f5b520"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "992979c8-9e04-c1b7-d2b0-202d72f71a65"
      },
      "outputs": [],
      "source": [
        "# Training the validated model with the whole training set\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "pred = rf.predict(X_test)\n",
        "\n",
        "df_test['Survived'] = pd.Series(pred)\n",
        "sub = df_test[['PassengerId','Survived']]\n",
        "\n",
        "sub.to_csv('submission_forest.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}