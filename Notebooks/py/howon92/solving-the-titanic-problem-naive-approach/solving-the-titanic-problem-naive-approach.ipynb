{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1234e32d-db00-eca6-c1b7-d62d08b35d98"
      },
      "source": [
        "#My first notebook on Kaggle :)\n",
        "### In this notebook, we will do the following:\n",
        "1. Preprocess the Titanic dataset\n",
        "2. Build different classifiers without tweaking parameters (i.e. the most naive way)\n",
        "3. Compare the performances of different classifiers\n",
        "4. Pick the best classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "635894b9-c45f-2364-f1f1-6e9257510bf7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sklearn\n",
        "\n",
        "# all the classifiers that we will use\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "59d7da10-b93e-ad06-0a3d-ec3be351a918"
      },
      "source": [
        "### Load the input data as pandas datatable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5a32977e-1ce0-e7b6-e152-4c83a55b2b5b"
      },
      "outputs": [],
      "source": [
        "raw_train_df = pd.read_csv(\"../input/train.csv\")\n",
        "\n",
        "# Let's first split raw_train_df into training_set: validation_set = 8 : 2\n",
        "# We are going to use this validation set to see how well a classifier performs later\n",
        "[train_df, valid_df] = sklearn.model_selection.train_test_split(raw_train_df, test_size=0.2)\n",
        "\n",
        "# Let's look at the data to see how we should preprocess it\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2e63c515-bbdf-5cbe-2700-a54460ea3dd7"
      },
      "source": [
        "### Preprocess data\n",
        "\n",
        "#### From observing the above datatable, we notice that\n",
        "1. PassengerId, Name and Ticket columns seem to be useless (by intuition)\n",
        "2. Age and Cabin columns have empty rows\n",
        "3. Some values are numerical while others are categorical (i.e. not a number)\n",
        "\n",
        "#### We do the following to preprocess the data\n",
        "1. Drop Name and Ticket columns\n",
        "2. Populate Age and Cabin columns\n",
        "3. Encode categorical values (e.g. map \"male\" to 0, \"female\" to 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "be7b13ad-e78e-c2ac-6515-3212a5740bb2"
      },
      "outputs": [],
      "source": [
        "def drop_cols(df, cols_to_drop):\n",
        "    for col in cols_to_drop:\n",
        "        df = df.drop(col, 1)\n",
        "    return df\n",
        "        \n",
        "def encode_cols(df, cols_to_encode):\n",
        "    for col in cols_to_encode:\n",
        "        df[col] = df[col].astype('category').cat.codes\n",
        "    return df\n",
        "\n",
        "non_null_cabin_col = train_df['Cabin'][train_df['Cabin'].notnull()]\n",
        "def get_random_cabin():\n",
        "    return non_null_cabin_col.sample(n=1).values[0]\n",
        "\n",
        "def preprocess(train_df):\n",
        "    train_df = drop_cols(train_df, ['PassengerId', 'Name', 'Ticket'])\n",
        "    train_df = encode_cols(train_df, ['Cabin', 'Embarked', 'Sex'])\n",
        "\n",
        "    # Fill Columns\n",
        "    train_df['Age'] = train_df['Age'].fillna(train_df['Age'].mean())\n",
        "    train_df['Cabin'] = train_df['Cabin'].apply(lambda x: get_random_cabin() if pd.isnull(x) else x)\n",
        "    return train_df\n",
        "\n",
        "train_df = preprocess(train_df)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "499f4210-bd61-f859-9cd5-3a66c4b9915c"
      },
      "source": [
        "### We are now ready to build a classifier. Let's start with a linear SVM without any parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e1f94873-f9e5-ae19-ac77-141bcf11bd09"
      },
      "outputs": [],
      "source": [
        "# X = all feature columns\n",
        "# Y = label column (\"Survived\")\n",
        "train_df_x = train_df.drop('Survived', 1)\n",
        "train_df_y = train_df['Survived']\n",
        "\n",
        "# Build and train the model with the training set\n",
        "svm = SVC()\n",
        "svm.fit(train_df_x, train_df_y)\n",
        "svm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1cac8de0-01d0-9211-8bde-bc5794a515b4"
      },
      "source": [
        "### See how the trained SVM classifier performs with a validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "85586a2d-b17a-0734-6610-18dbaa4f4140"
      },
      "outputs": [],
      "source": [
        "# test_df = pd.read_csv(\"../input/test.csv\")\n",
        "# We make a validation set by splitting the training set\n",
        "\n",
        "valid_df = preprocess(valid_df)\n",
        "valid_df_x = valid_df.drop('Survived', 1)\n",
        "valid_df_y = valid_df['Survived']\n",
        "\n",
        "def get_accuracy(trained_classifier, x, y):\n",
        "    predicted_vals = trained_classifier.predict(x)\n",
        "    result = (y == predicted_vals).value_counts()\n",
        "    return float(result[True]) / float(len(predicted_vals))\n",
        "\n",
        "get_accuracy(svm, valid_df_x, valid_df_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4b4543dc-37a0-fb38-6038-f0fab04511e4"
      },
      "source": [
        "### Let's build different classifiers and see if we can achieve a better accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "01669d9e-6c81-195a-a205-2855d5eaca44"
      },
      "outputs": [],
      "source": [
        "classifiers = {\n",
        "    \"Nearest Neighbors\": KNeighborsClassifier(3),\n",
        "    \"Most Naive SVM\": SVC(), # our initial classifier\n",
        "    \"Linear SVM\": SVC(kernel=\"linear\", C=0.025),\n",
        "    \"RBF SVM\": SVC(gamma=2, C=1),\n",
        "    \"Gaussian Process\": GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(max_depth=5),\n",
        "    \"Random Forest\": RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    \"Neural Net\": MLPClassifier(alpha=1),\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"QDA\": QuadraticDiscriminantAnalysis(),\n",
        "}\n",
        "\n",
        "# Reuse train_df_x and train_df_y\n",
        "trained_classifiers = {}\n",
        "for key in classifiers.keys():\n",
        "    classifier = classifiers[key]\n",
        "    trained_classifiers[key] = classifier.fit(train_df_x, train_df_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "05ba53f6-98d2-0e6f-fc6c-ac3b9f631b5d"
      },
      "outputs": [],
      "source": [
        "# Compare performances of different classifiers\n",
        "for classifier_name in trained_classifiers.keys():\n",
        "    classifier = trained_classifiers[classifier_name]\n",
        "    print(classifier_name, get_accuracy(classifier, valid_df_x, valid_df_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c30a9b5c-4440-287b-d6c0-f85e3fca37b5"
      },
      "source": [
        "## Based on the above results, QDA classifier seems to do well.\n",
        "\n",
        "- We want to run k-fold cross validations to see if we're overfitting.\n",
        "- We can tweak the parameters to see if we can do better.\n",
        "\n",
        "For now, let's just try to submit predicted values using the QDA classifier and see where we rank."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8893b143-078e-27db-594b-4cddb609b477"
      },
      "outputs": [],
      "source": [
        "# Test set is same as training set, except it doesn't have the labels ('Survived')\n",
        "# Use our classifier to predict the Survived column\n",
        "test_df = pd.read_csv(\"../input/test.csv\")\n",
        "passenger_ids = test_df['PassengerId']\n",
        "test_df_x = preprocess(test_df)\n",
        "# test_df_x has a row where Fare is empty. Let's populate it with a mean\n",
        "# Q. How do I find/populate such a row in the data set less manually?\n",
        "test_df_x['Fare'] = test_df_x['Fare'].fillna(test_df_x['Fare'].mean())\n",
        "\n",
        "# We are now ready to make our predictions\n",
        "classifier = trained_classifiers['QDA']\n",
        "predicted_values = classifier.predict(test_df_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "20b32070-0229-14a3-16b1-730f796e171f"
      },
      "outputs": [],
      "source": [
        "# Let's make our predicted_values in a submission format\n",
        "submission = pd.DataFrame(columns=['PassengerId', 'Survived'])\n",
        "submission['PassengerId'] = passenger_ids\n",
        "submission['Survived'] = predicted_values\n",
        "submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "83dff56c-ed57-a56a-4868-e0115d04201b"
      },
      "source": [
        "### Let's create a link to download the csv and submit it to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fd601927-f956-5204-7d0a-2ce798d863fc"
      },
      "outputs": [],
      "source": [
        "from IPython.display import FileLink, FileLinks\n",
        "\n",
        "submission.to_csv('titanic.csv', index=False)\n",
        "FileLink('titanic.csv')"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}