{"cells":[{"metadata":{"_uuid":"1e993ded497ecbb897d5dcaf7a9040833b927515"},"cell_type":"markdown","source":"> **Problem overview**\n\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"# import library\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n# import model function from sklearn\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# import model selection from sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\n\n# import model evaluation classification metrics from sklearn\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de6e202f7040b54dd07391f7cd599aa9357d3bde"},"cell_type":"markdown","source":"> **Acquiring training and testing data**\n\nWe start by acquiring the training and testing datasets into Pandas DataFrames."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# acquiring training and testing data\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24bff222024972fc64e461db4447b0033b48413e"},"cell_type":"code","source":"# visualize head of the training data\ntrain_df.head(n=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1a82ed550e61005fe8d4e7aff213263416bfd01"},"cell_type":"code","source":"# visualize tail of the testing data\ntest_df.tail(n=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1fc21cdab746330cc5bd3b31702f8c4f033bc4c"},"cell_type":"code","source":"# combine training and testing dataframe\ntrain_df['DataType'], test_df['DataType'] = 'training', 'testing'\ntest_df.insert(1, 'Survived', np.nan)\ndata_df = pd.concat([train_df, test_df])\ndata_df.head(n=3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e4a0cdc7373d3738742d8171f057c147effb105e"},"cell_type":"markdown","source":"> **Feature exploration, engineering and cleansing**\n\nHere we generate descriptive statistics that summarize the central tendency, dispersion and shape of a datasetâ€™s distribution together with exploring some data."},{"metadata":{"trusted":true,"_uuid":"f473735bf74dda6fcb89036e99bb03e219dde1d0"},"cell_type":"code","source":"# describe training and testing data\ndata_df.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77d131a034e59690356f059601ffb07ff8761ecd"},"cell_type":"code","source":"# feature extraction: surname\ndata_df['Surname'] = data_df['Name'].str.extract(r'([A-Za-z]+),', expand=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e30586c57a83e6d7be73daba7e328a5b776374a"},"cell_type":"code","source":"# feature extraction: title\ndata_df['Title'] = data_df['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\ndata_df['Title'] = data_df['Title'].replace(['Capt', 'Rev'], 'Crew')\ndata_df['Title'] = data_df['Title'].replace('Ms', 'Miss')\ndata_df['Title'] = data_df['Title'].replace(['Col', 'Countess', 'Don', 'Dona', 'Jonkheer', 'Lady', 'Major', 'Mlle', 'Mme', 'Sir'], 'Royal')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ca9e738237ff999d198a310920f068ab491748d"},"cell_type":"code","source":"# feature extraction: age\ndata_df['Age'] = data_df['Age'].fillna(data_df.groupby(by=data_df['Title'])['Age'].transform('mean'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"852dde69b1805424d535d3b17b886fad56923192"},"cell_type":"code","source":"# feature extraction: is woman and is child\ndata_df['IsWoman'] = data_df['Sex'].apply(lambda x: 1 if x == 'female' else 0)\ndata_df['IsChild'] = data_df['Title'].apply(lambda x: 1 if x == 'Master' else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cdba932bd35f5728681ebdb3f3e05df7cb7a1feb"},"cell_type":"code","source":"# feature extraction: family size\ndata_df['FamilySize'] = data_df['SibSp'] + data_df['Parch'] + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"872d30a62ee7c3994a70b47291057a238d4c95e8"},"cell_type":"code","source":"# feature extraction: is alone\ndata_df['IsAlone'] = data_df['FamilySize'].apply(lambda x: 1 if x == 1 else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"558c2457b3a4670d74ef10449f777263253f2ee1"},"cell_type":"code","source":"# feature extraction: ticket string\ndata_df['TicketString'] = data_df['Ticket'].str.extract(r'([A-Za-z]+)', expand=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87f46cfaa910e7e4fa639b6f40f5c43c543051cc"},"cell_type":"code","source":"# feature extraction: has ticket string\ndata_df['HasTicketString'] = data_df['TicketString'].apply(lambda x: 0 if pd.isnull(x) else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"907335fbd0a287feceb7f15eb1cbe2548fbf0a65"},"cell_type":"code","source":"# feature extraction: fare per person\ndata_df['Fare'] = data_df['Fare'].fillna(data_df.groupby(by=data_df['Pclass'])['Fare'].transform('mean'))\ndata_df['FarePerPerson'] = data_df['Fare'] / data_df['FamilySize']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2209f387779db55304304abfc15472020cf390d"},"cell_type":"code","source":"# feature extraction: has fare\ndata_df['HasFare'] = data_df['Fare'].apply(lambda x: 0 if x == 0 else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9232502d22529f7e1337162eae08273b5268f584"},"cell_type":"code","source":"# feature extraction: cabin string\ndata_df['Cabin'] = data_df['Cabin'].fillna(0)\ndata_df['CabinString'] = data_df['Cabin'].str.extract(r'([A-Za-z]+)', expand=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d92a0d3c4b2cb46c7410d6aead7aa7b818ad47e"},"cell_type":"code","source":"# feature extraction: has cabin\ndata_df['HasCabin'] = data_df['CabinString'].apply(lambda x: 0 if pd.isnull(x) else 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7dfcd1ece6921695ecbedc9768ef07466eb03dda"},"cell_type":"code","source":"# feature extraction: embarked\ndata_df['Embarked'] = data_df['Embarked'].fillna(data_df['Embarked'].value_counts().idxmax())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91c50ae72228136c7fb30934665736e03c8fd320"},"cell_type":"code","source":"# feature extraction: tour\ndata_df['Tour'] = np.where(data_df['FamilySize'] == 1, '-1', data_df['Ticket'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7994ea05c5926139a9a8a95a4dae1527d0a96d1a"},"cell_type":"code","source":"# feature extraction: woman and child tour\ntemp_df = data_df.groupby('Tour')['IsWoman', 'IsChild'].transform('sum')\ntemp_df.loc[data_df['Tour'] == '-1', ['IsWoman', 'IsChild']] = 0\ndata_df['WomanChildTour'] = (temp_df['IsWoman'] >= 1) & (temp_df['IsChild'] >= 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa1e26976cb8e8d6cd9c90e40db480a74d295113"},"cell_type":"code","source":"# feature extraction: average survived for the same tour\ndata_df['SurvivedTour'] = data_df.groupby('Tour')['Survived'].transform('mean')\ndata_df.loc[(data_df['Tour'] == '-1') | (data_df['WomanChildTour'] == False), 'SurvivedTour'] = -1\ndata_df['SurvivedTour'] = data_df['SurvivedTour'].fillna(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ad1df4853a770c5e158be5cf6d01043142894b0"},"cell_type":"code","source":"# feature extraction: survived\ndata_df['Survived'] = data_df['Survived'].fillna(0).astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4467441b3d12fdff9a5453baf89cfcf089969d45"},"cell_type":"code","source":"data_df.head(n=3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0890d3f5b4a1452c6d86fba480160ed6201f9cb"},"cell_type":"markdown","source":"After extracting all features, it is required to convert category features to numerics features, a format suitable to feed into our Machine Learning models."},{"metadata":{"trusted":true,"_uuid":"0d916a5019ce50ad48b75c8ff7941108523f9874"},"cell_type":"code","source":"# verify dtypes object\ndata_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68c7a1f5e5f47060ada9fd562ae0078aacb3078e"},"cell_type":"code","source":"# convert dtypes object to category\ncol_obj = data_df.select_dtypes(['object']).columns\ndata_df[col_obj] = data_df[col_obj].astype('category')\ndata_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69009239ae79df42b249c6a87c48bd7c85bc3246"},"cell_type":"code","source":"# convert dtypes category to category codes\ncol_cat = data_df.select_dtypes(['category']).columns\ndata_df[col_cat] = data_df[col_cat].apply(lambda x: x.cat.codes)\ndata_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d759efb40f32960b42c5ee4ccbd8e3273001dd8"},"cell_type":"code","source":"data_df.head(n=3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d5fe0b8b38f9572a2f2ba482de68ad63ea2f219"},"cell_type":"markdown","source":"> **Analyze and identify patterns by visualizations**\n\nLet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilize the Seaborn plotting package which allows us to plot very conveniently as follows.\n\nThe Pearson Correlation plot can tell us the correlation between features with one another. If there is no strongly correlated between features, this means that there isn't much redundant or superfluous data in our training data. This plot is also useful to determine which features are correlated to the observed value."},{"metadata":{"trusted":true,"_uuid":"4d055977366bc81fdd394102d857c05e4738b692"},"cell_type":"code","source":"# compute pairwise correlation of columns, excluding NA/null values and present through heat map\ncorr = data_df[data_df['DataType'] == 1].corr()\nfig, ax = plt.subplots(figsize=(20, 15))\nheatmap = sns.heatmap(corr, annot=True, cmap=plt.cm.RdBu, fmt='.1f', square=True);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"199fa0d3be9e0becd7b5266cebb557775e731276"},"cell_type":"markdown","source":"The pairplots is also useful to observe the distribution of the training data from one feature to the other."},{"metadata":{"trusted":true,"_uuid":"2ecd958aad2bb567d1015bf93b3a5ff238434347"},"cell_type":"code","source":"# plot pairwise relationships in a dataset\npairplot = sns.pairplot(data_df[data_df['DataType'] == 1], diag_kind='kde', diag_kws=dict(shade=True), hue='Survived')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee8205f98e7590a59e4a119b9b9ece182bd87cab"},"cell_type":"markdown","source":"The pivot table is also another useful method to observe the impact between features."},{"metadata":{"trusted":true,"_uuid":"6a4f996fde6847d3b8c70bde887f5827c17fe15d"},"cell_type":"code","source":"# pivot table: women and children in the same tour\npivottable = pd.pivot_table(data_df[(data_df['DataType'] == 1) & (data_df['IsAlone'] == 0)], aggfunc=np.mean,\n                            columns=None, index=['WomanChildTour', 'Tour'], values='Survived').applymap(lambda x: 1 if x in (0, 1) else 0)\npivottable = pivottable.groupby(level='WomanChildTour').mean()\npivottable.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f9bb556d4d7e9026fc05654f3474170ddfbcebf"},"cell_type":"code","source":"# pivot table\npivottable = pd.pivot_table(data_df[data_df['DataType'] == 1], aggfunc=np.mean,\n                            columns=['Sex'], index=['IsAlone'], values='Survived')\npivottable.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49b30f024c6eb254db7fe2238fad79b967a291be"},"cell_type":"markdown","source":"> **Model, predict and solve the problem**\n\nNow, it is time to feed the features to Machine Learning models."},{"metadata":{"trusted":true,"_uuid":"10929afdbb661c340a8216cf00a4efe9cb131376"},"cell_type":"code","source":"# select all features to evaluate the feature importances\nx = data_df[data_df['DataType'] == 1].drop(['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin', 'DataType', 'Tour', 'SurvivedTour'], axis=1)\ny = data_df[data_df['DataType'] == 1]['Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d02280646bb98e10c34f0d4d1dfc6c67fcc97fc"},"cell_type":"code","source":"x.head(n=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8c5716d6c20f86054a3b5f23e724ca15e158608"},"cell_type":"code","source":"# set up random forest classifier to find the feature importances\nforestclf = RandomForestClassifier(max_depth=99, n_estimators=2000, random_state=0).fit(x, y)\nfeat = pd.DataFrame(data=forestclf.feature_importances_, index=x.columns, columns=['FeatureImportances']).sort_values(['FeatureImportances'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c952e90a37fd6fcba53de71e5b90afacfd173b44"},"cell_type":"code","source":"# plot the feature importances\nfig, ax = plt.subplots(figsize=(20, 5))\nplt.title('Feature Importances')\nplt.bar(feat.index, feat['FeatureImportances'])\nplt.axhline(0.02, color=\"grey\")\nax.set_xticklabels(feat.index, rotation='vertical')\nax.set_yscale('log')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ede31fd09b396d1a0e1955a7c216ce88cd2a5f1"},"cell_type":"code","source":"# list all features\ndata_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b871b8550fd2cb69cbfde6468014a6cb7056f94"},"cell_type":"code","source":"# list feature importances\nfeat[feat['FeatureImportances'] > 0.02].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"465c4677287eeb7a6434087222146e2c6b6deabb"},"cell_type":"code","source":"# select the important features\nx = data_df[data_df['DataType'] == 1][feat[feat['FeatureImportances'] > 0.02].index]\ny = data_df[data_df['DataType'] == 1]['Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2669b8eacba8495a8bb1550f8ed6d85e2762d7e8"},"cell_type":"code","source":"x.head(n=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11161ad5b93b91800bfa45f87b7563196758a33d"},"cell_type":"code","source":"# perform train-test (validate) split\nx_train, x_validate, y_train, y_validate = train_test_split(x, y, random_state=0, test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9b14a895cbe9b63a0fa8a89ca8f8f0cb6b66324"},"cell_type":"code","source":"# model prediction\nlogreg = LogisticRegression().fit(x_train, y_train)\nlogreg_ypredict = logreg.predict(x_validate)\nlogreg_f1score, logreg_auc = f1_score(y_validate, logreg_ypredict), roc_auc_score(y_validate, logreg_ypredict)\nlogreg_cvscores = cross_val_score(logreg, x, y, cv=5, scoring='accuracy')\nprint('logistic regression\\n  f1 score: %0.4f, auc: %0.4f, cross validation score: %0.4f (+/- %0.4f)' %(logreg_f1score, logreg_auc, logreg_cvscores.mean(), 2 * logreg_cvscores.std()))\n\ntreeclf = DecisionTreeClassifier(max_depth=20, min_samples_split=5, splitter='best').fit(x_train, y_train)\ntreeclf_ypredict = treeclf.predict(x_validate)\ntreeclf_f1score, treeclf_auc = f1_score(y_validate, treeclf_ypredict), roc_auc_score(y_validate, treeclf_ypredict)\ntreeclf_cvscores = cross_val_score(treeclf, x, y, cv=5, scoring='accuracy')\nprint('decision tree classifier\\n  f1 score: %0.4f, auc: %0.4f, cross validation score: %0.4f (+/- %0.4f)' %(treeclf_f1score, treeclf_auc, treeclf_cvscores.mean(), 2 * treeclf_cvscores.std()))\n\nforestclf = RandomForestClassifier(max_depth=20, min_samples_split=5, n_estimators=250, random_state=0).fit(x_train, y_train)\nforestclf_ypredict = forestclf.predict(x_validate)\nforestclf_f1score, forestclf_auc = f1_score(y_validate, forestclf_ypredict), roc_auc_score(y_validate, forestclf_ypredict)\nforestclf_cvscores = cross_val_score(forestclf, x, y, cv=5, scoring='accuracy')\nprint('random forest classifier\\n  f1 score: %0.4f, auc: %0.4f, cross validation score: %0.4f (+/- %0.4f)' %(forestclf_f1score, forestclf_auc, forestclf_cvscores.mean(), 2 * forestclf_cvscores.std()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a51e614f92f7ace5d3111d0285a4583169db7d7"},"cell_type":"markdown","source":"> **Supply or submit the results**\n\nOur submission to the competition site Kaggle is ready. Any suggestions to improve our score are welcome."},{"metadata":{"trusted":true,"_uuid":"be8f2863279ac3dd857877009dfcb9058d063846"},"cell_type":"code","source":"# model selection\nmodel = forestclf\n\n# prepare testing data and compute the observed value\nx_test = data_df[data_df['DataType'] == 0][feat[feat['FeatureImportances'] > 0.02].index]\ny_test = pd.DataFrame(model.predict(x_test), columns=['Survived'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c6c886a41c95173945efe9b1c4285b165dd71b0"},"cell_type":"code","source":"# overwrite same tour as training set\ntemp_df = data_df.loc[(data_df['DataType'] == 0) & (data_df['SurvivedTour'] > -1)]['SurvivedTour']\ny_test.loc[temp_df.index, 'Survived'] = temp_df.apply(lambda x: 0 if x < 0.5 else 1).astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10b0be05e1be8e0f936846dfaebb725a29c0ac91"},"cell_type":"code","source":"# summit the results\nout = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': y_test['Survived']})\nout.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47f5e9915fec030caefc642a140249d1c2370fc2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}