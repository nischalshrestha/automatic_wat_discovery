{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# ライブラリのインポート\nimport pandas as pd\nimport pandas_profiling\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\n\n# Jupyter Notebookの中でインライン表示する場合の設定（これが無いと別ウィンドウでグラフが開く）\n%matplotlib inline\n\n# データの読み込み\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c0200cc3edcaa8b6a48c86c4e41a038a68798ce"},"cell_type":"code","source":"# トレーニングデータのProfile Reportを作成\n# (出力結果が膨大なのでコメントアウト。必要な時だけ実行)\n# pandas_profiling.ProfileReport(train)\n\n# テストデータのProfile Reportを作成\n# (出力結果が膨大なのでコメントアウト。必要な時だけ実行)\n# pandas_profiling.ProfileReport(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cbcafaaf6abb2aa5e0fc8f3ae52b7ea8e0b17bb"},"cell_type":"code","source":"# データタイプの確認\ntrain.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34d6e32475ccd6084b111d7bd6cc515e00264c79"},"cell_type":"code","source":"def preprocess(df):\n    # NameからMr/Mrs/Miss/Masterを取り出し\n    df[\"Mr\"] = df[\"Name\"].apply(lambda x: x.count(\"Mr.\"))\n    df[\"Mrs\"] = df[\"Name\"].apply(lambda x: x.count(\"Mrs.\"))\n    df[\"Miss\"] = df[\"Name\"].apply(lambda x: x.count(\"Miss.\"))\n    df[\"Master\"] = df[\"Name\"].apply(lambda x: x.count(\"Master.\"))\n    return df\ntrain = preprocess(train)\ntest = preprocess(test)\n# いらなそうな名前を削除\ntrain=train.drop('Name', axis='columns')\ntest=test.drop('Name', axis='columns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0877eff316fa23154ebf54f51b64fc751adc3cc2"},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"\n\n\n\n# 文字列をラベル化した数値に変換する為のライブラリをインポート\nfrom sklearn.preprocessing import LabelEncoder\n\n# データタイプがobjectの列の値をラベル化した数値に変換\nlbl = LabelEncoder()\n\nlbl.fit(list(train['Sex'].values) + list(test['Sex'].values))\ntrain['Sex'] = lbl.transform(list(train['Sex'].values))\ntest['Sex'] = lbl.transform(list(test['Sex'].values))\n\nlbl.fit(list(train['Ticket'].values) + list(test['Ticket'].values))\ntrain['Ticket'] = lbl.transform(list(train['Ticket'].values))\ntest['Ticket'] = lbl.transform(list(test['Ticket'].values))\n\nlbl.fit(list(train['Cabin'].values) + list(test['Cabin'].values))\ntrain['Cabin'] = lbl.transform(list(train['Cabin'].values))\ntest['Cabin'] = lbl.transform(list(test['Cabin'].values))\n\nlbl.fit(list(train['Embarked'].values) + list(test['Embarked'].values))\ntrain['Embarked'] = lbl.transform(list(train['Embarked'].values))\ntest['Embarked'] = lbl.transform(list(test['Embarked'].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc447dc033fad6ab17ce64bb727a9900967f2477"},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4a7a5af520565abcca698a53dc4ca93f3fcd07b"},"cell_type":"code","source":"# トレーニングデータのNaNの数\ntrain_nan = train.isnull().sum()\ntrain_nan = train_nan[train_nan > 0]\ntrain_nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d91ba9ea5b6a0794680d685e467b21c64d50d6d","scrolled":true},"cell_type":"code","source":"# テストデータのNaNの数\ntest_nan = test.isnull().sum()\ntest_nan = test_nan[test_nan > 0]\ntest_nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e14548db555b6724e0348398c87b5f3f081dee5"},"cell_type":"code","source":"# Ageをpclassごとの平均値で埋める\n\nAgedf = pd.DataFrame(train.loc[:,['Age','Pclass']])\nPclass1 = Agedf[Agedf.Pclass == 1]\nmeanAge1 = Pclass1.mean().Age\nPclass2 = Agedf[Agedf.Pclass == 2]\nmeanAge2 = Pclass2.mean().Age\nPclass3 = Agedf[Agedf.Pclass == 3]\nmeanAge3 = Pclass3.mean().Age\ntrain.loc[(train[\"Pclass\"].values == 1) & (train[\"Age\"].isnull()), \"Age\"] = meanAge1\ntrain.loc[(train[\"Pclass\"].values == 2) & (train[\"Age\"].isnull()), \"Age\"] = meanAge2\ntrain.loc[(train[\"Pclass\"].values == 3) & (train[\"Age\"].isnull()), \"Age\"] = meanAge3\n\nAgedf = pd.DataFrame(test.loc[:,['Age','Pclass']])\nPclass1 = Agedf[Agedf.Pclass == 1]\nmeanAge1 = Pclass1.mean().Age\nPclass2 = Agedf[Agedf.Pclass == 2]\nmeanAge2 = Pclass2.mean().Age\nPclass3 = Agedf[Agedf.Pclass == 3]\nmeanAge3 = Pclass3.mean().Age\n\ntest.loc[(test[\"Pclass\"].values == 1) & (test[\"Age\"].isnull()), \"Age\"] = meanAge1\ntest.loc[(test[\"Pclass\"].values == 2) & (test[\"Age\"].isnull()), \"Age\"] = meanAge2\ntest.loc[(test[\"Pclass\"].values == 3) & (test[\"Age\"].isnull()), \"Age\"] = meanAge3\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5ebfe210c6195122cefdcd3cfc4473b7bbdb248"},"cell_type":"code","source":"train_nan = train.isnull().sum()\ntrain_nan = train_nan[train_nan > 0]\ntrain_nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"042e6341f51c0ab937989dfd27eb9096f56a5a7e"},"cell_type":"code","source":"# keep ID for submission\ntrain_ID = train['PassengerId']\ntest_ID = test['PassengerId']\n\n# split data for training\ny_train = train['Survived']\nX_train = train.drop(['PassengerId','Survived'], axis=1)\nX_test = test.drop('PassengerId', axis=1)\n\n# dealing with missing data\nXmat = pd.concat([X_train, X_test])\n# 欠損値の少ないカラムのNaNは中央値(median)で埋める\nXmat = Xmat.fillna(Xmat.median())\n\n# check whether there are still nan\nXmat_nan = Xmat.isnull().sum()\nXmat_nan = Xmat_nan[Xmat_nan > 0]\nXmat_nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9dcddeec2f2a8d0f1d4759cae77f26d85c2fc5f2"},"cell_type":"code","source":"# trainデータとtestデータを含んでいるXmatを、再度trainデータとtestデータに分割\nX_train = Xmat.iloc[:train.shape[0],:]\nX_test = Xmat.iloc[train.shape[0]:,:]\n\n# ランダムフォレストをインポート\nfrom sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators=80, max_features='auto')\nrf.fit(X_train, y_train)\nprint(\"Training done using Random Forest\")\n\n# np.argsort()はソート結果の配列のインデックスを返す。引数の頭に\"-\"をつけると降順。\n# つまり\"-rf.feature_importances_\"を引数にする事で重要度の高い順にソートした配列のインデックスを返す。\nranking = np.argsort(-rf.feature_importances_)\nf, ax = plt.subplots(figsize=(11, 9))\nsns.barplot(x=rf.feature_importances_[ranking], y=X_train.columns.values[ranking], orient='h')\nax.set_xlabel(\"feature importance\")\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb176adb253127635d56c3243282ff19df2d3189"},"cell_type":"code","source":"# use the top 10 features only\nX_train = X_train.iloc[:,ranking[:10]]\nX_test = X_test.iloc[:,ranking[:10]]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b62d37d545df0ef61ae6998f98089f681e62e54"},"cell_type":"code","source":"# z-scoreにて標準化\n# (値 - 平均) / 標準偏差\n# X_train = (X_train - X_train.mean()) / X_train.std()\n# X_test = (X_test - X_test.mean()) / X_test.std()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5882db712c0dbbfae7599d31c63f4baa0fd3b376"},"cell_type":"code","source":"# 正規化　Prof.UMEMURAをパクリスペクト\n\n# 正規化\nX_train = X_train.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\nX_test = X_test.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"a266b1cf109b8394e4c6c693841da02c53ec317f"},"cell_type":"code","source":"# アルゴリズムにロジスティック回帰を採用\nlr = LogisticRegression(C=1000)\n\n# fit関数で学習開始\nlr.fit(X_train,y_train)\ny_test_pred = lr.predict(X_test)\ny_test_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fbc4ee9d2fbff7711291d2287dda91f32da59bde"},"cell_type":"code","source":"# Adaboostなるものをためしてみる\nfrom sklearn.ensemble import AdaBoostClassifier as abc\nbdt = abc()\n\nbdt.fit(X_train,y_train)\ny_test_ada = bdt.predict(X_test)\ny_test_ada","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07c1532417a73b0b5952160403223d13cfed86c2"},"cell_type":"code","source":"# 次は決定木\nfrom sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier(random_state=0)\nclf.fit(X_train,y_train)\ny_test_dtc = clf.predict(X_test)\ny_test_dtc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa3588990d3f5b2a068c61868f7541faf255f167"},"cell_type":"code","source":"y_test_data = y_test_pred + y_test_ada + y_test_dtc\ny_test_data = y_test_data / 3\ny_test_data = (y_test_data + 0.5).astype(np.int)\ny_test_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15baacb78b93d7a72adcd078b9b683e82085e19c"},"cell_type":"code","source":"# submission\nsubmission = pd.DataFrame({\n    \"PassengerId\": test_ID,\n    \"Survived\": y_test_pred\n})\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}