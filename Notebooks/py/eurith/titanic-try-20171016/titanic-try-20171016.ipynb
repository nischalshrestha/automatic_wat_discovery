{"metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "version": "3.6.3", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "mimetype": "text/x-python"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "cells": [{"execution_count": null, "metadata": {"_cell_guid": "1a01bec0-faa7-421d-989d-299fd86c4a80", "_uuid": "b0f5e7c8a5e28f93d56746194e8b40d993f36aec"}, "outputs": [], "cell_type": "code", "source": ["# coding: utf-8\n", "#What I'm trying to do\n", "#1: Before generating the feature quantity, confirm the specific data and decide the policy.\n", "#2: Generate feature quantities from each item and fill in missing values other than age. Ticket is excluded this time. Unnecessary feature quantities are appropriately reduced.\n", "#3: The algorithm uses a random forest. Use the grid search to get the best parameters.\n", "#4: Make data for submission using the best result parameter.\n", "\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "%matplotlib inline\n", "\n", "train = pd.read_csv(\"../input/train.csv\")\n", "test_data = pd.read_csv(\"../input/test.csv\")\n", "test_result = pd.read_csv(\"../input/genderclassmodel.csv\")\n", "\n", "#For data processing, make train, test and answer all together and make over 1300 data sets. (To divide later)\n", "\n", "test = pd.merge(test_data, test_result, how=\"outer\", on=\"PassengerId\")\n", "df = pd.concat([train, test], axis=0).reset_index(drop=True)\n", "df.head()"]}, {"execution_count": null, "metadata": {"_cell_guid": "92fe39b7-bbd7-4ee1-be88-b5f633f48c8b", "_uuid": "ca16b9b53829e509cae5e8220ddbdc13af3fdd3d"}, "outputs": [], "cell_type": "code", "source": ["#1: Before generating the feature quantity, confirm the specific data and decide the policy.\n", "\n", "#Confirm about Parch\n", "g = sns.factorplot(y=\"Survived\", x=\"Parch\", data=df, kind=\"bar\")\n", "g.despine(left=True)\n", "g = g.set_ylabels(\"Survival Probability\")\n", "\n", "#High survival rate 1, 2, 3. 9 may be abnormal value, so confirmation is necessary.\n", "df[df[\"Parch\"]==9].head()"]}, {"execution_count": null, "metadata": {"_cell_guid": "0701ca34-410e-446d-bdf5-f75efb14ef14", "_uuid": "2a7b08d6b3e91be8c2a16e6fe806b292754aa95e"}, "outputs": [], "cell_type": "code", "source": ["#Confirm about SibSp\n", "g = sns.factorplot(y=\"Survived\", x=\"SibSp\", data=df, kind=\"bar\")\n", "g.despine(left=True)\n", "g = g.set_ylabels(\"Survival Probability\")\n", "\n", "#1 and 2 have a high survival rate. The survival rate decreases as the number increases."]}, {"execution_count": null, "metadata": {"_cell_guid": "f179bbcb-3584-4bc7-95c8-3e8b708f4fa2", "_uuid": "153d7c035f6e39b284244458a141e9361abff5aa"}, "outputs": [], "cell_type": "code", "source": ["#2: Generate feature quantities from each item and fill in missing values other than age. Ticket is excluded this time. Unnecessary feature quantities are appropriately reduced.\n", "\n", "df = pd.get_dummies(df, columns=[\"Embarked\"], prefix=\"Em\")\n", "df = pd.get_dummies(df, columns=[\"Pclass\"], prefix=\"Pc\")\n", "df = pd.get_dummies(df, columns=[\"Sex\"])\n", "df.drop(labels=[\"Ticket\",\"Sex_male\"], axis=1, inplace=True)\n", "df.head()"]}, {"execution_count": null, "metadata": {"_cell_guid": "6b315ec9-93eb-460c-b7d1-925d21fac8bc", "_uuid": "103b114c6bb8b9a61b6c2c6eb921d6d93b875236"}, "outputs": [], "cell_type": "code", "source": ["#Detects the title from the name and converts it into the feature quantity\n", "df_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in df[\"Name\"]]\n", "df[\"Title\"] = pd.Series(df_title)\n", "#df[\"Title\"].value_counts() #Because Mlle looked like Mile and made a spelling mistake, for confirmation\n", "g = sns.countplot(x=\"Title\", data=df)\n", "g = plt.setp(g.get_xticklabels(), rotation=45)"]}, {"execution_count": null, "metadata": {"_cell_guid": "f0e0289f-9d94-4348-aac0-7db048c92e17", "_uuid": "cec8eea948ba6752751bb3cfbbda4ab9edb69131"}, "outputs": [], "cell_type": "code", "source": ["df[\"Title\"] = df[\"Title\"].replace(['the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n", "df[\"Title\"] = df[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\":1, \"Mme\":1, \"Mlle\":1, \"Lady\":1, \"Mrs\":2, \"Mr\":3, \"Rare\":4})\n", "df[\"Title\"] = df[\"Title\"].astype('int')\n", "df.drop(labels=[\"Name\"], axis=1, inplace=True)\n", "df.head()"]}, {"execution_count": null, "metadata": {"_cell_guid": "3c56c85b-cd9a-4bd0-bc62-6306cd054be6", "_uuid": "dc8e14fd343563727e7a84203cb97ae0015f8c6b"}, "outputs": [], "cell_type": "code", "source": ["#What is the distribution when adding Parch and SibSp? (+1 at the end adds the boat person himself / herself)\n", "df[\"Fsize\"] = df[\"Parch\"] + df[\"SibSp\"] + 1\n", "g = sns.factorplot(y=\"Survived\", x=\"Fsize\", data=df, kind=\"bar\")\n", "g.despine(left=True)\n", "g = g.set_ylabels(\"Survival Probability\")\n", "\n", "#High numbers outstanding 2, 3 and 4. I want to divide it into 4 groups of \"single person\", \"small family\", \"middle family\", \"large family\"\n", "df[\"F_single\"] = df[\"Fsize\"].map(lambda s: 1 if s == 1 else 0)\n", "df[\"F_small\"] = df[\"Fsize\"].map(lambda s: 1 if 2 <= s <= 4 else 0)\n", "df[\"F_middle\"] = df[\"Fsize\"].map(lambda s: 1 if 5 <= s <= 7 else 0)\n", "df[\"F_large\"] = df[\"Fsize\"].map(lambda s: 1 if 8 <= s else 0)\n", "\n", "df.drop(labels=[\"Parch\",\"SibSp\",\"Fsize\"], axis=1, inplace=True)\n", "\n", "df.head()"]}, {"execution_count": null, "metadata": {"_cell_guid": "6fd03c85-51de-42c2-b78d-36a66fe7411a", "_uuid": "60668d8422493ef1f7920620613743bc1355deea"}, "outputs": [], "cell_type": "code", "source": ["#Confirm the data of the person corresponding to the missing value of Fare. Estimate death from the condition \"3rd cabin, male, 60.5 years old\" and fill it with 0\n", "df[\"Fare\"] = df[\"Fare\"].fillna(0)\n", "df.head()"]}, {"execution_count": null, "metadata": {"_cell_guid": "7e2ab054-cc31-4eba-ac87-5625c0b3179f", "_uuid": "49e89d50690182eec2e74a2a7fd7ee383123fe00"}, "outputs": [], "cell_type": "code", "source": ["#The cabin is taken from the initials of Cabin and in the case of Nan it is X\n", "df[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in df[\"Cabin\"]])\n", "g = sns.factorplot(y=\"Survived\", x=\"Cabin\", data=df, kind=\"bar\", order=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"T\",\"X\"])\n", "\n", "#Code for creating feature quantity with low survival rate X as 0 and others as 1 (not used because score decreased by about 0.015 Reference code)\n", "#df[\"Cabin\"] = df[\"Cabin\"].map({\"A\":1, \"B\":1, \"C\":1, \"D\":1, \"E\":1, \"F\":1, \"G\":1, \"T\":1, \"X\":0})\n", "#df[\"Cabin\"] = df[\"Cabin\"].astype(\"int\")\n", "\n", "df = pd.get_dummies(df, columns=[\"Cabin\"], prefix=\"Cab\")\n", "#df.drop(labels=\"Cab_1\", axis=1, inplace=True)\n", "df.head()"]}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "e0c64d33-df00-442d-988f-d02d2cafc7b8", "_uuid": "f1bc2f783faa0949b9f114b3acdf79a7d3ae3130"}, "outputs": [], "cell_type": "code", "source": ["#Missing values of age are filled with linear regression\n", "\n", "df_age_train = pd.DataFrame(df[:])\n", "df_age_train = df_age_train.dropna()\n", "df_age_train_X = pd.DataFrame(df_age_train[:])\n", "\n", "df_age_train_Y = pd.Series(df_age_train_X[\"Age\"])\n", "df_age_train_X.drop(labels=[\"Age\"], axis=1, inplace=True)\n", "\n", "df_age_test_X = pd.DataFrame(df[df[\"Age\"].isnull()])\n", "df_age_test_X.drop(labels=[\"Age\"], axis=1, inplace=True)"]}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "d636c132-6df8-46fe-bdf9-4702278242ff", "_uuid": "9d9eb1f05d42be832967c5d37740acdfd0a5b6fc"}, "outputs": [], "cell_type": "code", "source": ["from sklearn.linear_model import LinearRegression\n", "\n", "A_clf = LinearRegression()\n", "A_clf.fit(df_age_train_X, df_age_train_Y)\n", "\n", "ID_test_age = df_age_test_X[\"PassengerId\"].reset_index(drop=True)\n", "age_pred = pd.Series(A_clf.predict(df_age_test_X), name=\"Age\")\n", "df_age_test = pd.concat([ID_test_age, age_pred], axis=1)\n", "\n", "df_age_test = pd.merge(df_age_test, df_age_test_X, how=\"outer\", on=\"PassengerId\")\n", "\n", "df = pd.concat([df_age_train, df_age_test], axis=0)\n", "df = df.sort_values(['PassengerId'], ascending=[True]).reset_index(drop=True)\n", "df[\"Age\"] = df[\"Age\"].where(df[\"Age\"] < 0, 1)\n", "df[\"Age\"] = df[\"Age\"].astype('int')"]}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "1469df58-deb7-4169-b598-d4c22487fa2d", "_uuid": "235362e0da88cda00e4a2c13b30c6c1808d781b0"}, "outputs": [], "cell_type": "code", "source": ["#Repartition the data set back to the training set and test set.\n", "\n", "X_train = pd.DataFrame(df[:len(train)])\n", "X_test = pd.DataFrame(df[len(train):])\n", "\n", "Y_train = pd.Series(X_train[\"Survived\"])\n", "X_train.drop(labels=[\"Survived\",\"PassengerId\"], axis=1, inplace=True)\n", "\n", "X_test.drop(labels=[\"Survived\",\"PassengerId\"], axis=1, inplace=True)"]}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "ca20ee3f-00de-44e4-a2f9-84babe6816d3", "_uuid": "e7aaf8f26d66f859503b1af0c019decba1904281"}, "outputs": [], "cell_type": "code", "source": ["#3: The algorithm uses a random forest. Use the grid search to get the best parameters.\n", "\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve"]}, {"execution_count": null, "metadata": {"_cell_guid": "b1bfa194-06af-4267-9925-b58a8fe03851", "_uuid": "db1f57f7040db038da0c22bc59b2a119362e8e21"}, "outputs": [], "cell_type": "code", "source": ["RFC = RandomForestClassifier()\n", "RF_Param_Grid = {\n", "    \"max_depth\": [4,8,16,32],\n", "    \"min_samples_split\": [2,4,8,16],\n", "    \"min_samples_leaf\": [1,3],\n", "    \"bootstrap\": [False],\n", "    \"n_estimators\": [50,100],\n", "    \"criterion\": [\"gini\"]\n", "}\n", "kfold = StratifiedKFold(n_splits=10)\n", "\n", "g_clf = GridSearchCV(RFC, param_grid=RF_Param_Grid, cv=kfold, scoring=\"accuracy\", n_jobs=4, verbose=1)\n", "g_clf.fit(X_train, Y_train)"]}, {"execution_count": null, "metadata": {"_cell_guid": "ac71beb3-a202-4176-9dae-dd9310ac389b", "_uuid": "ce69fd611405d3ab735da884fe49e6a50db5532a"}, "outputs": [], "cell_type": "code", "source": ["g_clf.best_score_"]}, {"execution_count": null, "metadata": {"_cell_guid": "9f75bf1d-5ce2-4442-ad73-f4fdcb95fcf0", "_uuid": "8c703a703f9bb9ab83f8859a74757ea415280bee"}, "outputs": [], "cell_type": "code", "source": ["g_clf.best_params_"]}, {"execution_count": null, "metadata": {"_cell_guid": "485df47f-34c5-4eaa-a8c6-11d967b41075", "_uuid": "963fdab096d8eb7a3b454083ad3ee498eb73bf06"}, "outputs": [], "cell_type": "code", "source": ["#4: Make data for submission using the best result parameter.\n", "\n", "bp = g_clf.best_params_\n", "\n", "clf = RandomForestClassifier(\n", "    bootstrap=bp[\"bootstrap\"], \n", "    criterion=bp[\"criterion\"], \n", "    max_depth=bp[\"max_depth\"], \n", "    min_samples_leaf=bp[\"min_samples_leaf\"], \n", "    min_samples_split=bp[\"min_samples_split\"], \n", "    n_estimators=bp[\"n_estimators\"]\n", ")\n", "clf.fit(X_train, Y_train)"]}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "81e03721-e794-4315-9b6a-72d89a0a29e9", "_uuid": "0b18aae919d585d7b033de7a6cb8e49d14ca4421"}, "outputs": [], "cell_type": "code", "source": ["IDtest = test_data[\"PassengerId\"]\n", "test_Survived = pd.Series(clf.predict(X_test), name=\"Survived\")\n", "results = pd.concat([IDtest, test_Survived], axis=1)"]}], "nbformat_minor": 1, "nbformat": 4}