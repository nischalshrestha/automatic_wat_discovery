{"nbformat": 4, "cells": [{"cell_type": "code", "execution_count": null, "outputs": [], "source": ["import pandas as pd\n", "import random\n", "\n", "import re\n", "import tensorflow as tf\n", "import numpy as np\n", "#from sklearn import metrics, cross_validation\n", "from sklearn.cross_validation import train_test_split\n", "from sklearn.metrics import accuracy_score\n", "from tensorflow.contrib import layers\n", "from tensorflow.contrib import learn\n"], "metadata": {"_uuid": "797d03e167690a968a250d789a609045033113dc", "_cell_guid": "126a0e0f-c73b-4c8b-ac3c-7558fd63ad43"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["\n", "test_orig = pd.read_csv(\"../input/test.csv\")\n", "train_orig = pd.read_csv(\"../input/train.csv\")\n", "train = train_orig.copy()\n", "test = test_orig.copy()\n"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["def isNaN(x):\n", "    return x != x\n", "#fileds present in the data \n", "train.columns"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["#Lets focus on converting all the column data to be numaric, We can see if missing data is going to cause problems after the first iteration is done\n", "#easy to convert text data \n", "for key in train.columns:\n", "    print(\"Number of Classes in \", key, \" = \", len(train[key].unique()), \n", "          \" Number of NAN = \" ,sum(isNaN(train[key])))\n"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Age has  177 missing\n", "# Cabin has 687 missing\n", "# Embarked 2 missing\n", "from sklearn.preprocessing import LabelEncoder"], "metadata": {"collapsed": true}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["#Replace Missing Embarked value \n", "for k in ['Embarked', 'Sex']:\n", "    for tr2 in [train, test]:\n", "        tr2[k] = tr2[k].fillna('N')\n", "        le = LabelEncoder().fit(tr2[k])\n", "        tr2[k] = le.transform(tr2[k])"], "metadata": {"collapsed": true}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["# lets check name next \n", "def getPName(st):\n", "    if isNaN(st):\n", "        return st\n", "    dt = st.split(',')\n", "    lastName = dt[0]\n", "    fullName = dt[1].split(' ')\n", "    fullName = list(filter(lambda f:f!='', fullName))\n", "    pn = fullName[0]\n", "    if pn == 'Mlle.':\n", "        pn = 'Miss.'\n", "    elif pn == 'Mme.':\n", "        pn = 'Mrs.'\n", "    elif pn == 'Ms.':\n", "        pn = 'Miss.'\n", "    return pn\n", "def getLName(st):\n", "    if isNaN(st):\n", "        return st\n", "    dt = st.split(',')\n", "    lastName = dt[0]\n", "    return lastName\n", "titleMap = {}\n", "cnt =0\n", "for tr2 in [train, test]:\n", "    titles = tr2.apply(lambda r:getPName(r['Name']), axis=1).unique()\n", "    for idx in range(0, len(titles)):\n", "        if not titles[idx] in titleMap:\n", "            titleMap[titles[idx]] = cnt\n", "            cnt+=1\n", "for tr2 in [train, test]:\n", "    tr2['Titles'] = tr2.apply(lambda r:titleMap[getPName(r['Name'])], axis=1)\n", "print(train['Titles'].unique())\n", "print(titleMap)"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["lnameMap = {}\n", "cnt = 0\n", "for tr2 in [train, test]:\n", "    lname = tr2.apply(lambda r:getLName(r['Name']), axis=1).unique()\n", "    for idx in range(0, len(lname)):\n", "        if not lname[idx] in lnameMap:\n", "            lnameMap[lname[idx]] = cnt\n", "            cnt +=1\n", "for tr2 in [train, test]:\n", "    tr2['LName'] = tr2.apply(lambda r:lnameMap[getLName(r['Name'])], axis=1)\n", "\n", "train['LName_t'] = learn.ops.categorical_variable(train['LName'], \n", "                                                  len(train['LName'].unique()),\n", "                                                 embedding_size=6, name='LName')"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Age has lot of missing data  (177 entries)\n", "# Let's try to fill them based on average data based on different titles \n", "titleMapAvgAge = {}\n", "for k in titleMap:\n", "    num_valid = sum((train['Titles'] == titleMap[k]) & ~isNaN(train['Age'] ))\n", "    num_nan = sum((train['Titles'] == titleMap[k]) & isNaN(train['Age'] ))\n", "    sum_age   = sum(train.loc[(train['Titles'] == titleMap[k]) & ~isNaN(train['Age']),'Age'])\n", "    if (num_valid != 0):\n", "        avg = sum_age/num_valid\n", "    else:\n", "        avg = 0\n", "    titleMapAvgAge[titleMap[k]] = avg\n", "    print('title=',k, ' NumberOfItems:',num_valid,'/',num_nan, ' Average Age:',avg)\n", "# Plugin all the missing ages based on title \n", "\n", "def plugAge(r):\n", "    if not isNaN(r['Age']):\n", "        return r['Age']\n", "    return titleMapAvgAge[r['Titles']]\n", "train['Age'] = train.apply(lambda r:plugAge(r), axis=1)\n", "test['Age'] = test.apply(lambda r:plugAge(r), axis=1)\n"], "metadata": {}}, {"cell_type": "markdown", "source": ["The data is preped now, most of the columns are mapped to numbers. Some of the missing data has be plugged in with averages. Column [Name, Ticket, Cabin] is to be ignored as they have been mapped to numeric values. This gives us features that are our input features X = [ Pclass, Sex, Age, SibSp, Parch, Fare, Embarked,, Titles, LName, ]"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["train.columns"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["featureListKey =[ 'Embarked', 'Sex', 'SibSp', 'Parch', 'Titles', 'LName', 'Age', 'Fare', \n", "                 'Pclass'  \n", "            ]\n"], "metadata": {"collapsed": true}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["fullDt = pd.concat([train, test])\n", "X = train[featureListKey].copy()\n", "y = train['Survived'].copy()\n", "\n", "#normalize Age\n", "for key in ['Age', 'Fare']:\n", "    X[key]=((X[key] - X[key].mean())/(X[key].max() - X[key].min()))\n", "X['Pclass'] = X['Pclass'] - 1\n", "\n", "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.2, random_state=42)\n", "\n"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["# Tensor flow feature setup \n", "f_embarked = tf.feature_column.numeric_column(key='Embarked')\n", "f_sex = tf.feature_column.numeric_column(key='Sex')\n", "f_sibsp = tf.feature_column.numeric_column(key='SibSp')\n", "f_parch = tf.feature_column.numeric_column(key='Parch')\n", "f_age = tf.feature_column.numeric_column(key='Age')\n", "f_titles = tf.feature_column.numeric_column(key='Titles')\n", "#f_fare = tf.feature_column.numeric_column(key='Fare')\n", "f_pclass = tf.feature_column.embedding_column(\n", "    tf.feature_column.categorical_column_with_identity(key='Pclass',num_buckets=3), 3)\n", "#f_titles = tf.feature_column.embedding_column(\n", "#    tf.feature_column.categorical_column_with_hash_bucket(key='Titles',hash_bucket_size=20), 10)\n", "f_columns= [ f_embarked, f_sex, f_sibsp, f_parch, f_pclass, f_age, f_titles]\n", "train_input_fn = tf.estimator.inputs.pandas_input_fn(x=XTrain, \n", "                                                y=yTrain,\n", "                                                batch_size=100,\n", "                                                num_epochs=None,\n", "                                                shuffle=True)\n", "test_input_fn = tf.estimator.inputs.pandas_input_fn(x=XTest, \n", "                                                y=yTest,\n", "                                                num_epochs=1,\n", "                                                shuffle=False)\n", "starter_learning_rate = 0.02\n", "global_step = tf.Variable(0, trainable=False)\n", "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n", "                                           1000, 0.96, staircase=True)\n", "my_nn = tf.estimator.DNNClassifier(feature_columns=f_columns,\n", "                                  hidden_units=[40,40],\n", "                                  activation_fn = tf.nn.relu,\n", "                                  dropout=0.1,\n", "                                  n_classes=2,\n", "                                  optimizer=tf.train.FtrlOptimizer(\n", "                                          learning_rate=0.02, \n", "                                           l2_regularization_strength=0.2\n", "                                ))"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["my_nn.train(input_fn=train_input_fn, steps=500 )\n", "ev=my_nn.evaluate(input_fn=test_input_fn)\n", "print(\"Loss:%s\" %ev[\"loss\"], \" Accuracy:\", ev['accuracy'])"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["XEval=test[featureListKey].copy()\n", "for key in ['Age', 'Fare']:\n", "    XEval[key]=((XEval[key] - XEval[key].mean())/(XEval[key].max() - XEval[key].min()))\n", "XEval['Pclass'] = XEval['Pclass'] - 1\n"], "metadata": {"collapsed": true}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["pred_input_fn = tf.estimator.inputs.pandas_input_fn(x=XEval, \n", "                                                num_epochs=1,\n", "                                                shuffle=False)\n", "pred = my_nn.predict(input_fn=pred_input_fn)\n"], "metadata": {"collapsed": true}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["v=[]\n", "for i, p in enumerate(pred):\n", "    v.append(p['class_ids'][0])\n"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["result = pd.DataFrame({'PassengerId':test['PassengerId'],'Survived':v})\n", "result.to_csv('result.csv', index=False)"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": [], "metadata": {"collapsed": true}}], "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.1", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 1}