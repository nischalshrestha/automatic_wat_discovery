{"cells":[{"metadata":{"_uuid":"c7b1ed302b5868f331447aa4c891790e263761e7"},"cell_type":"markdown","source":"# Titanic Competition Solutions"},{"metadata":{"_uuid":"a619548fd23d3ce1cba916b14d528569cd6227f1"},"cell_type":"markdown","source":"## Import necessary libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"def warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\n\nimport numpy as np\nimport pandas as pd\nimport os\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05501a120436b1954ab1725f7ae5b543f3424ae8"},"cell_type":"markdown","source":"## Read in data to dataframes"},{"metadata":{"trusted":true,"_uuid":"04bf36b3466d3034be36dbf223f539b32c70232a"},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ngender_sub = pd.read_csv('../input/gender_submission.csv')\ntest_df = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d6c46ea5be490165762a3b1d516ac783e7bc2b2"},"cell_type":"markdown","source":"## Identify problem\n* Description: Predict the survival or death of members of the Titanic given data about them as inputs\n* Type of Problem: Categorical"},{"metadata":{"_uuid":"76abcbaccfb89cacc122ad2b4f895897554b9883"},"cell_type":"markdown","source":"## Describe data\n\n* Numerical\n  * Continuous: Fare\n  * Discrete: PassengerId, Age, SibSp, Parch\n* Categorical: Survived, Sex, Embarked\n* Ordinal: Pclass\n* Mixed: Cabin, Ticket\n* String: Name"},{"metadata":{"trusted":true,"_uuid":"6bbb99718f545cad9d59d828a986be676a4f4a70"},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ddd295efa9c318c15b16fa6edb28a5e05ff91a9"},"cell_type":"markdown","source":"## Analyze data with pivot tables (Sex and Pclass)\n\nLet's start off with Sex and Pclass just from intuition that they may have an impact on survival. We can use pivot tables for these as they contain less than 5 categories each.\n\n**Obervations**\n* Sex and Pclass have significant coorelations with survival rate."},{"metadata":{"trusted":true,"_uuid":"bf99994839488c389af14b14943cafcdc4a0ff16"},"cell_type":"code","source":"train_df[['Sex', 'Survived']].groupby(['Sex']).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"b8ab8cbcd33a252181e053d51df1ae9b18dc4057"},"cell_type":"code","source":"train_df[['Pclass', 'Survived']].groupby(['Pclass']).mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"99653218187fed756c12223fc04e4a6438d9e6f8"},"cell_type":"markdown","source":"## Analyze data by visualization (Age)\n\nThe data for Age is continuous thus makes creating a pivot table currently not very weildly due to the length it would be. To fix this, we are first going to viusalize the distribution of who survived based on age and then split age up into bands so that we can see the survival probability distribution of certain age brackets.\n\n**Observations**\n\nIt is clear that the Age plays a significant part in who survives as seen in that over half of those from infant age until 16 survived, while less than 10% of those over 64 survived."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"e008f7dd1e93cfa24e916ac07e06dd4c4e225799"},"cell_type":"code","source":"g = sns.FacetGrid(train_df, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"220ebc5e4fa0bdb507b4cf8f6935a867ab973c18"},"cell_type":"code","source":"train_df['AgeBand'] = pd.cut(train_df['Age'], 5)\ntrain_df[['AgeBand', 'Survived']].groupby('AgeBand').mean().sort_values(by='AgeBand', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6e4c8a700bfaf830190baaf284368303b2a3268"},"cell_type":"markdown","source":"After this analysis, we will not need the AgeBand column anymore so we will drop it."},{"metadata":{"trusted":true,"_uuid":"f5dfe7914f226358b47c045fbca543f3e566b9c6"},"cell_type":"code","source":"del train_df['AgeBand']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"41a899e3a4aa6d61c2621efed26643c02e24d46c"},"cell_type":"markdown","source":"## Feature Engineering and Creation\n\nWe have now discovered that Age, Sex, and Pclass all have strong coorelations to survival ratings, so we decide to include them in our model. \n\nHowever, in order for models to be trained on this data, the data must be in encoded form according to how it should be weighted, ie. Pclass should not be ordinal as 3rd class doesn't have mean that this characteristic is worth three of a first-class characteristic-it should just be an identifier.\n\n1. Let's make an array of train_df and test_df as we will need these changes on both in order for our model testing as well as submitted prediction to take them into account. \n2. We are going to create dummy columns then one-hot encode these features as described below:\n  * Age\n  * Sex\n  * Pclass"},{"metadata":{"trusted":true,"_uuid":"3f434ba1e6f58166391972464e1d01518a0b418e"},"cell_type":"code","source":"combine = [train_df,test_df]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"206514f87aabab15008d9b991ac262f875955764"},"cell_type":"code","source":"for dataset in combine:\n    dataset[\"Age1\"] = 0\n    dataset[\"Age2\"] = 0\n    dataset[\"Age3\"] = 0\n    dataset[\"Age4\"] = 0\n    dataset[\"Age5\"] = 0\n\nfor dataset in combine:\n    dataset.loc[dataset['Age'] <= 16, 'Age1'] = 1\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age2'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age3'] = 1\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age4'] = 1\n    dataset.loc[(dataset['Age'] > 64) & (dataset['Age'] <= 80), 'Age5'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"013cb58d318792c1f9fa1518a01d337631f8b8f1"},"cell_type":"code","source":"for dataset in combine:\n    dataset['Male'] = 0\n    dataset['Female'] = 0\n    \nfor dataset in combine:\n    dataset.loc[dataset['Sex'] == 'male', 'Male'] = 1\n    dataset.loc[dataset['Sex'] == 'female', 'Female'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4365891956e95c3f361473f92e5b6c8d780537e4"},"cell_type":"code","source":"for dataset in combine:\n    dataset['Pclass1'] = 0\n    dataset['Pclass2'] = 0\n    dataset['Pclass3'] = 0\n    \nfor dataset in combine:\n    dataset.loc[dataset['Pclass'] == 1, 'Pclass1'] = 1\n    dataset.loc[dataset['Pclass'] == 2, 'Pclass2'] = 1\n    dataset.loc[dataset['Pclass'] == 3, 'Pclass3'] = 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc1bbfd7b30aec49be2aedad10841e5947334af1"},"cell_type":"markdown","source":"## Cleaning Up Data\n\nNow that we have one-hot encoded Age, Sex, and Pclass, we can drop the Age, Sex, and Pclass columns from the tables that we are working with.\n\nWe also are going to drop the columns that we are not working on currently to create a base model centered on Age, Sex, and Pclass that we can build upon.\nHowever, we are going to save the Passenger Ids of test_df so that we can use them in the submission process.\n\n**Dropping:**\n* Passenger_Id\n* Age\n* Pclass\n* Sex\n* Name\n* SibSp\n* Parch\n* Ticket\n* Fare\n* Cabin\n* Embarked\n\n**Saving:**\n* test_df's Passenger_Id as Test_Pass_Id"},{"metadata":{"trusted":true,"_uuid":"d3d50fe02184ff21fa562e5ff48d1e166f7bfb85"},"cell_type":"code","source":"Test_Pass_Id = test_df['PassengerId']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36db15a4c1cbe387ee1cff15ea9b39b3ee0ffa7c"},"cell_type":"code","source":"train_df = train_df.drop(['PassengerId', 'Age', 'Pclass', 'Sex', 'Name', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'], axis=1)\ntest_df = test_df.drop(['PassengerId', 'Age', 'Pclass', 'Sex', 'Name', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d72f5c39c91bd1a7bade53ceb86b28977cbe7094"},"cell_type":"markdown","source":"## Model Fitting and Evaluation\n\nOur data is all in order now and we are going to run through the different models that we have at our disposal, training each one on the data and looking at its accuracy.\n\nModels to test:\n* Logistic Regression\n* Support Vector Machines\n* Random Forest Classifier\n\nSteps:\n1. Split train_df into train_X and train_Y which will be all data other than Survived and Survived respectively.\n2. Split the data into train_X, train_Y, test_Y, and test_Y.\n3. Fit each model to train_X and train_Y, then score with test_X and test_Y.\n4. Then use cross_val_score for each model to use cross validation with each model to ensure that the fit is not skewed by which parts of train_df are used as X and Y respectively.\n5. Compare these two scores for each, but ultimately use the cross validation score to rank models."},{"metadata":{"_uuid":"68801ac84028ad268e24d0e78682974ce5e3e20a"},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true,"_uuid":"02472501ccfa5730ea0e441302be4ed257de151a"},"cell_type":"code","source":"train_X = train_df.drop(['Survived'], axis=1)\ntrain_Y = train_df['Survived']\n\n# With Cross Validation\nlreg = LogisticRegression()\nacc_logreg_cross_val = cross_val_score(lreg, train_X,train_Y, cv=5).mean()\n\n# With Single Split\nlreg = LogisticRegression()\ntrain_X, test_X, train_Y, test_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=0)\nlreg.fit(train_X, train_Y)\nacc_logreg_single_split = lreg.score(test_X, test_Y)\n\nprint('Single Split:', acc_logreg_single_split, 'Cross Validation:', acc_logreg_cross_val)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb0e356991f24c587e1d4a9ac3dcd2e586299057"},"cell_type":"markdown","source":"### Support Vector Machines"},{"metadata":{"trusted":true,"_uuid":"667fcee121b15dbe8414b6dd57b14633962497df"},"cell_type":"code","source":"train_X = train_df.drop(['Survived'], axis=1)\ntrain_Y = train_df['Survived']\n\n# With Cross Validation\nsvc = SVC(C = 0.1, gamma=0.1)\nacc_svc_cross_val = cross_val_score(svc, train_X,train_Y, cv=5).mean()\n\n# With Single Split\nsvc = SVC(C = 0.1, gamma=0.1)\ntrain_X, test_X, train_Y, test_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=0)\nsvc.fit(train_X, train_Y)\nacc_svc_single_split = svc.score(test_X, test_Y)\n\nprint('Single Split:', acc_svc_single_split, 'Cross Validation:', acc_svc_cross_val)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d350e7ac96901b0ab00c0f84b67a9246ca09a33"},"cell_type":"markdown","source":"### Random Forest Classifier"},{"metadata":{"trusted":true,"_uuid":"a189d86e974b5ce750044617593614bfa24eed0e"},"cell_type":"code","source":"train_X = train_df.drop(['Survived'], axis=1)\ntrain_Y = train_df['Survived']\n\n# With Cross Validation\nrand_forest = RandomForestClassifier()\nacc_rf_cross_val = cross_val_score(rand_forest, train_X,train_Y, cv=5).mean()\n\n# With Single Split\nrand_forest = RandomForestClassifier()\ntrain_X, test_X, train_Y, test_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=0)\nrand_forest.fit(train_X, train_Y)\nacc_rf_single_split = rand_forest.score(test_X, test_Y)\n\nprint('Single Split:', acc_rf_single_split, 'Cross Validation:', acc_rf_cross_val)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35d36e95d04bffbce9cc59df28d05116bfe2bac0"},"cell_type":"markdown","source":"## Model Evaluation and Submission"},{"metadata":{"_uuid":"3c7aaed129bdfe747b2630ee2f2872a6cef8bcfe"},"cell_type":"markdown","source":"In comparing the cross validation accuracies of our three models, we decide that Random Tree has the highest confidence score and is thus the model we would like to predict the data which we are going to submit with."},{"metadata":{"trusted":true,"_uuid":"e884dbff1a1bfa37d4107a14fa42ce14c325647a"},"cell_type":"code","source":"compare_models = pd.DataFrame({'Model': ['Logistic Regression', 'SVC', 'Random Tree'], 'Score' : [acc_logreg_cross_val, acc_svc_cross_val, acc_rf_cross_val]})\ncompare_models.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5edec13493558dece1ece310da155169484caac4"},"cell_type":"code","source":"submission = pd.DataFrame({'PassengerId' : Test_Pass_Id, 'Survived' : rand_forest.predict(test_df)})\nsubmission.to_csv('titanic_csv_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}