{"metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"version": "3.6.3", "name": "python", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python"}}, "nbformat_minor": 1, "cells": [{"source": ["# Titanic Survivor Geometry\n", "\n", "Titanic is the project for beginners on Kaggle. It is a relatively small dataset with a well known story and features.\n", "This is why most data analysis on the Titanic start just there: they look at the features single or in combination. \n", "We sometimes find correlation matrices, but what is we could glimpse at the geometry as a whole?\n", "\n", "## Can we see the geometry of the Survivor Classification?\n", "\n", "I recently came across an algorithm, that does just that: it projects the problem onto a 2 dimensional plain and preserves thereby as much of the distance between observations as possible.\n", "\n", "## Background\n", "The kernel uses the **t-SNE Algorithm**.\n", "\n", "It is a dimensionality reduction algorithm, that has its focus on preserving the distances of the datapoints as much as possible, whille mapping them on a plain, that can be easily visualized by us humans.\n", "\n", "If you want to know more about that algorithm: here is an article for you: It is free, but to read it, you need to login at Oreilly's website:\n", "[An illustrated introduction to the t-SNE algorithm](https://www.oreilly.com/learning/an-illustrated-introduction-to-the-t-sne-algorithm)\n", "\n", "# Content\n", "1. Loading the Libraries\n", "2. Loadinging and preparing the data\n", "3. Applying the t-SNE algorithm\n", "4. Visualization of the Survivor Geometry\n", "5. Interpretation of the Result\n", "6. K-Nearest Neighbor Algorithm"], "cell_type": "markdown", "metadata": {"_uuid": "1f3e616f0eb715b226bbc57fabc06f106a77a225", "collapsed": true, "_cell_guid": "13198882-5a4a-432a-9f02-5b685461a83e"}}, {"source": ["## 1. Loading Libraries\n", "We need only the standard libraries for this:\n", "- numpy\n", "- pandas\n", "- matplotlib\n", "- seaborn"], "cell_type": "markdown", "metadata": {"_uuid": "712689190c297438972a6e5edc9495efdfbf925f", "_cell_guid": "0c0b7d3f-09ba-44ba-831a-5b54d752a2b8"}}, {"execution_count": null, "source": ["# use numpy and pandas\n", "import numpy as np\n", "import pandas as pd\n", "\n", "# We need sklearn for preprocessing and for the TSNE Algorithm.\n", "import sklearn\n", "from sklearn.preprocessing import Imputer, scale\n", "from sklearn.manifold import TSNE\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.metrics import accuracy_score\n", "\n", "# WE employ a random state.\n", "RS = 20150101\n", "\n", "# We'll use matplotlib for graphics.\n", "import matplotlib.pyplot as plt\n", "import matplotlib.patches as mpatches\n", "%matplotlib inline\n", "\n", "# We import seaborn to make nice plots.\n", "import seaborn as sns"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "854172494aca513ad355769828941aa07b652784", "collapsed": true, "_cell_guid": "bc41a90e-82db-4e48-aea0-64c1e063937d"}}, {"source": ["## 2. Loading and preparing the data\n", "We need only the train data, since we want to visualize how well the festures separate the target.\n", "\n", "### The Algorithm expects\n", "- numeric input\n", "- no missing values are allowed\n", "- the data must be sorted by its target\n", "\n", "### Therefore we make some **basic transformations**:\n", "- Sex is encoded as 0/1 instead of 'male'/'female'\n", "- Embarked is encoded as 0/1/2 instead of 'S'/'C'/'Q': so the sequence of enbarkment is kept\n", "- Cabin is encoded with 0/1 depending whether it is filled or not\n", "- Name, TicketNr and PassengerId are excluded\n", "\n", "### We sort the data\n", "Our sort criteria is the 'Survived' colunm."], "cell_type": "markdown", "metadata": {"_uuid": "8a2f8ad9cdd7a5038173956cddb3a8bbc774c152", "_cell_guid": "9dfbb6f8-f35f-4713-8513-36ef82165f5d"}}, {"execution_count": null, "source": ["# import the data: we just need the training data for this visualization\n", "# since we need a target!\n", "X = pd.read_csv('../input/train.csv')\n", "\n", "# sort by target\n", "X.sort_values(by='Survived', inplace=True)\n", "\n", "# separate the target\n", "y = X['Survived']\n", "\n", "# transform all fields that are not numeric:\n", "def prepare_for_ml(X):\n", "    # Cabin is 0 if nan or 1 if filled\n", "    X.Cabin = X.Cabin.apply(lambda x: 0 if pd.isnull(x) else 1) \n", "\n", "    # Sex is turned into 0/1 for male/female\n", "    X.Sex = X.Sex.apply(lambda x: 0 if x == 'male' else 1)\n", "\n", "    # Embarked is encoded as 1,2,3 maintaining the order of ports S -> C -> Q\n", "    def get_port_nr(embarked):\n", "        if embarked == 'C':\n", "            return 2\n", "        elif embarked == 'Q':\n", "            return 3 \n", "        else: # cases nan or 'S'\n", "            return 1\n", "\n", "    X.Embarked = X.Embarked = X.Embarked.apply(lambda x: get_port_nr(x))\n", "\n", "    # Name Ticket and PassengerId are dropped\n", "    X.drop(['Survived', 'Name', 'Ticket', 'PassengerId'], inplace=True, axis=1)\n", "    \n", "    print(\"Features: \", X.columns)\n", "\n", "    # now the missing values are imputed, which are Fare and Age, since Embarked has \n", "    # already been filled!\n", "    imputer = Imputer()\n", "    X = imputer.fit_transform(X)\n", "    \n", "    # scale the feature values \n", "    X = scale(X)\n", "    \n", "    return X\n", "\n", "# apply transformation\n", "X = prepare_for_ml(X)"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "5d13e11dfbf9e2f309313ef760dd7598da6ec279", "_cell_guid": "439133c9-463b-4430-a0a8-d01b9eb19270"}}, {"source": ["## 3. Applying the t-SNE algorithm\n", "We are now ready for applying the algorithm:\n", "- X is numeric\n", "- there are no missing values"], "cell_type": "markdown", "metadata": {"_uuid": "57d51cefa6ab29299794ac677bc00435e541adb5", "_cell_guid": "5d39ff28-4214-4f77-a890-fa635918fad9"}}, {"execution_count": null, "source": ["# run the TSNE Algorithm\n", "titanic_proj = TSNE(random_state=RS).fit_transform(X)\n", "titanic_proj.shape"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "70406caa2775c42fd77113a71e96a90dc9e6282b", "_cell_guid": "5d508bd2-33a3-4e2e-b058-ca81664a23ef"}}, {"source": ["## 4. Visualization of the Survivor Geometry\n", "\n", "Now we can visualize the result\n", "- we use matplotlib and seaborn for this task"], "cell_type": "markdown", "metadata": {"_uuid": "31cf883b031975b74cd2b9d7e0faede61ea1b08f", "_cell_guid": "002053b6-7962-4c53-bbd7-f6ff95c4f6a7"}}, {"execution_count": null, "source": ["def scatter(x, colors):\n", "    \"\"\"this function plots the result\n", "    - x is a two dimensional vector\n", "    - colors is a code that tells how to color them: it corresponds to the target\n", "    \"\"\"\n", "    \n", "    # We choose a color palette with seaborn.\n", "    palette = np.array(sns.color_palette(\"hls\", 2))\n", "\n", "    # We create a scatter plot.\n", "    f = plt.figure(figsize=(10, 8))\n", "    ax = plt.subplot(aspect='equal')\n", "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n", "                    c=palette[colors.astype(np.int)])\n", "    \n", "    ax.axis('off') # the axis will not be shown\n", "    ax.axis('tight') # makes sure all data is shown\n", "    \n", "    # set title\n", "    plt.title(\"Featurespace Visualization Titanic\", fontsize=25)\n", "    \n", "    # legend with color patches\n", "    survived_patch = mpatches.Patch(color=palette[1], label='Survived')\n", "    died_patch = mpatches.Patch(color=palette[0], label='Died')\n", "    plt.legend(handles=[survived_patch, died_patch], fontsize=20, loc=1)\n", "\n", "    return f, ax, sc\n", "\n", "# Use the data to draw ths scatter plot\n", "scatter(titanic_proj, y)"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "8cf389f8021810e8a8d1fd0229b9ab03e46ccddb", "_cell_guid": "4b26ab02-17bb-4119-a2d6-4d8548811685"}}, {"source": ["## 5. Interpretation of the Result\n", "\n", "### Some charateristics coincidented with a higher chance of survival\n", "so some feature made survival more likely, such as\n", "- being female\n", "- young children\n", "- higher passenger class\n", "\n", "### For other characteristics survival was just fate\n", "- for other groups: survivers and non survivers could not be distinguished by there features.\n", "- so survival just boiled down to luck!\n", "\n", "### That makes survival hard to predict\n", "- we should meet a limit in our prediction accuracy, that can be overcome, that part is pure luck!"], "cell_type": "markdown", "metadata": {"_uuid": "ee697c5f966b4e296de3b2c61d957f2d4df99f37", "_cell_guid": "9ceaa18d-01d6-4b61-a2b4-ff5ce29c86a9"}}, {"source": ["## 6. K-Nearest Neighbor Algorithm\n", "I am just trying one ML algorithm here: kNearest Neighbor, I might compare other algorithms later on."], "cell_type": "markdown", "metadata": {"_uuid": "23d6f1b1e21264d5cd7c8cc495bd1f7db6cc4f65", "_cell_guid": "3057d44c-186b-4d83-b4a8-7bf043f82d52"}}, {"execution_count": null, "source": ["# split data into train and test sets\n", "seed = 7\n", "test_size = 0.33\n", "X_train, X_test, y_train, y_test = train_test_split(X, y,\n", "    test_size=test_size, random_state=seed)\n", "\n", "# fit model no training data\n", "model = KNeighborsClassifier(n_neighbors=5)\n", "model.fit(X_train, y_train)\n", "print(model)\n", "\n", "# make predictions for test data\n", "y_pred = model.predict(X_test)\n", "predictions = [round(value) for value in y_pred]\n", "\n", "# evaluate predictions\n", "accuracy = accuracy_score(y_test, predictions)\n", "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n", "\n", "from sklearn.metrics import roc_auc_score\n", "roc_auc = roc_auc_score(y_test, predictions)\n", "print(roc_auc)"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "ca84f2125e120addd0c543cf069dda787e4f9a4d", "collapsed": true, "_cell_guid": "215d080a-1c87-484a-be93-a56a56af3349"}}], "nbformat": 4}