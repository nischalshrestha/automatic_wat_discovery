{"metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"name": "python", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.4", "nbconvert_exporter": "python"}}, "cells": [{"metadata": {"_uuid": "11464db525f7ec49126dbae91ac3daad35d62def", "_cell_guid": "0a2ddf40-9679-4062-8ed5-ac25825721d5"}, "source": ["# Introduction"], "cell_type": "markdown"}, {"metadata": {"_uuid": "e31d54848ec7d65ce5752fb529bd0301c761953b", "_cell_guid": "c0d120b4-fc53-473f-85ba-4b9f3d424a1f"}, "source": ["I have deided to work with the Titanic dataset again. this kernel is focusing on comparing the performance of several machine learning algorithms. I use several clasification model to create a model predicting survival on the Titanic. \n", "I am hoping to learn a lot from this site, so feedback is very welcome! This kernel is always improving because of your feedback!!!\n", "\n", "There are three parts to my script as follows:\n", "\n", "1. Load the library and data\n", "2. Data cleaning\n", "3. Data spliting\n", "4. Training,testing, and Peformance comparison\n", "5. Tuning the algorithm\n", "\n", "If you like this work and want to see my other works, you can check it here:\n", "\n", "https://www.kaggle.com/aldemuro\n"], "cell_type": "markdown"}, {"metadata": {"_uuid": "4aad80a65ef42c8f2a5e68081db353e295a7d2f4", "_cell_guid": "c30a5d6f-950a-4979-bc1f-cf8372a12f7d"}, "source": ["# 1. Load the library and data\n", "\n", "In this section the library and the data used are loaded into the sytem\n", "\n", "## 1.1 Load the library"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_uuid": "b70ac4f850fc8a5fd9273f2ac392ef0aa4081f5f", "_cell_guid": "ee10e4f8-4b89-494f-9e77-b041e073b530"}, "source": ["#sklearn\n", "from sklearn.cross_validation import train_test_split, cross_val_score\n", "from sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score, auc,roc_curve\n", "from sklearn import ensemble, linear_model, neighbors, svm, tree, neural_network\n", "from sklearn.pipeline import make_pipeline\n", "from sklearn.linear_model import Ridge\n", "from sklearn.preprocessing import PolynomialFeatures\n", "from sklearn import svm,model_selection, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n", "\n", "#load package\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "#from math import sqrt\n", "import seaborn as sns\n", "\n", "import warnings\n", "warnings.filterwarnings('ignore')"], "outputs": [], "cell_type": "code"}, {"metadata": {"_uuid": "980bdfeb4abf0c780e0886f6e458724d320ca7ca", "_cell_guid": "48ec9e33-65bf-4491-92ba-809340f44aa4"}, "source": ["## 1.2 Load the data"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_uuid": "c52495b58ce2aee1646a54298d235c55e92aae71", "_cell_guid": "d19fb6d8-4c84-4182-9a5e-660fc1471f47"}, "source": ["## Read in file\n", "train_original = pd.read_csv('../input/train.csv')\n", "test_original = pd.read_csv('../input/test.csv')\n", "train_original.sample(10)\n", "total = [train_original,test_original]\n"], "outputs": [], "cell_type": "code"}, {"metadata": {"_uuid": "7588737bbc934345566356896f349faca4270e32", "_cell_guid": "ae655b98-d6e4-4404-b686-a72accb59655"}, "source": ["# 2. Data Cleaning\n", "## 2.1 Retrive the salutation and Eliminating unused variable\n", "\n", "'Salutation' variable can be retrieved from 'Name' column by taking the string between space string and '.' string."], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "scrolled": true, "_uuid": "5e195355dd768ca366bb3dc6bc5bddb21fcafa84", "_cell_guid": "9e02406e-3f28-46f9-b0a1-e4f0b6109d11"}, "source": ["#Retrive the salutation from 'Name' column\n", "for dataset in total:\n", "    dataset['Salutation'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)    "], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "079f2c8a235f6ae5b054a4f160dd7bc3b705aba9", "_cell_guid": "1b7c4e4b-2e03-4be6-9d54-d1fad42404a7"}, "source": ["pd.crosstab(train_original['Salutation'], train_original['Sex'])"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "4783c53e5dc0b85577bf20cf21ea64b463571bff", "_cell_guid": "ba72482c-b42b-455d-83ad-afc96aa3a885"}, "source": ["pd.crosstab(test_original['Salutation'], test_original['Sex'])"], "outputs": [], "cell_type": "code"}, {"metadata": {"_uuid": "364e5af29b30a8a8c18e1af4058f1e7cb9adb1c4", "_cell_guid": "02434704-f5e0-4b38-8ed1-9d1baf795444"}, "source": [" afterward, 'Salutation' column should be factorized to be fit in our future model"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_uuid": "49a82ca42b2c21b562d29cc5cbb14b22a1e454fe", "_cell_guid": "1a89a86b-a6e7-4a04-bca8-366cdb9cb421"}, "source": ["for dataset in total:\n", "    dataset['Salutation'] = dataset['Salutation'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n", "    dataset['Salutation'] = dataset['Salutation'].replace('Mlle', 'Miss')\n", "    dataset['Salutation'] = dataset['Salutation'].replace('Ms', 'Miss')\n", "    dataset['Salutation'] = dataset['Salutation'].replace('Mme', 'Mrs')\n", "    dataset['Salutation'] = pd.factorize(dataset['Salutation'])[0]\n", "    \n", "\n", "\n", "#total.Salutation = pd.factorize(total.Salutation)[0]   \n"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "70e84bcad7c5f2527a54386aa4ab44403e9b10ee", "_cell_guid": "73fac9b7-bd1a-40a0-bcd2-2ac812fe2f61"}, "source": ["pd.crosstab(train_original['Salutation'], train_original['Sex'])"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "55fa37686454f00ec1f618ab9ae33139039573e6", "_cell_guid": "7177935c-509a-49e8-9c76-84babd71c399"}, "source": ["pd.crosstab(test_original['Salutation'], test_original['Sex'])"], "outputs": [], "cell_type": "code"}, {"metadata": {"_uuid": "a7a078a42a727dda12c004a9664e338c2d8d0182", "_cell_guid": "3b78597f-9b49-41cc-a72a-719debe14735"}, "source": ["The next step is deletin column that will not be used in our models."], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_uuid": "ea2a91ae2aa11be8c17f8cae434c1630bdf464e9", "_cell_guid": "4099a1c8-2dab-4847-8af8-8fa254c0d14a"}, "source": ["#clean unused variable\n", "train=train_original.drop(['PassengerId','Name','Ticket','Cabin'], axis=1)\n", "test=test_original.drop(['PassengerId','Name','Ticket','Cabin'], axis=1)\n", "total = [train,test]\n", "\n", "train.shape, test.shape"], "outputs": [], "cell_type": "code"}, {"metadata": {"_uuid": "3083fa7dd5eea531babe2529a35dcf1b86306155", "_cell_guid": "33612e1b-6757-419b-b45c-22189400ec2a"}, "source": ["## 2.2 Detect and fill the missing data"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_uuid": "bbb8e4058586e1ee84acb809cb31ad7badac7e4d", "_cell_guid": "784e5c3f-2627-4a37-b1db-ae50f936ca33"}, "source": ["#Detect the missing data in 'train' dataset\n", "train.isnull().sum()"], "outputs": [], "cell_type": "code"}, {"metadata": {"_uuid": "de685bc7d49a374b7ab8e635c19335691c64ba4d", "_cell_guid": "163c4012-aef4-42fd-affc-c46d80c345ee"}, "source": ["As it is shown above, there are 2 columns which have missing data. the way I'm handling missing 'Age' column is by filling them by the median of age in every passenger class. there are only two data missing in 'Embarked' column. Considering Sex=female and Fare=80, Ports of Embarkation (Embarked) for two missing cases can be assumed to be Cherbourg (C)."], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_uuid": "62ca0a81696c01b5703f66a453a208e0bbc936bc", "_cell_guid": "fdf7765c-2418-4eaa-bfce-d081024ca60e"}, "source": ["## Create function to replace missing data with the median value\n", "def fill_missing_age(dataset):\n", "    for i in range(1,4):\n", "        median_age=dataset[dataset[\"Salutation\"]==i][\"Age\"].median()\n", "        dataset[\"Age\"]=dataset[\"Age\"].fillna(median_age)\n", "        return dataset\n", "\n", "train = fill_missing_age(train)"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "befd20b592fa017d63d6ee04be916a0fd8ff678d", "_cell_guid": "5ac37dfb-577c-4c96-82b7-88223ad5299c"}, "source": ["## Embarked missing cases \n", "train[train['Embarked'].isnull()]"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true, "_uuid": "dac11d46d5378d33d9581ae66e5e05c2732d95bd", "_cell_guid": "0465aa38-1a9d-49fb-87e0-056f4250299f"}, "source": ["train[\"Embarked\"] = train[\"Embarked\"].fillna('C')"], "outputs": [], "cell_type": "code"}, {"metadata": {"_uuid": "518c041c127440518f9670369bc218b7c78de6f1", "_cell_guid": "23b9a87f-b677-4329-88d1-401fd4bac2e5"}, "source": ["Detecting the missing data in 'test' dataset is done to get the insight which column consist missing data. as it is shown below, there are 2 column which have missing value. they are 'Age' and 'Fare' column. The same function is used in order to filled the missing 'Age' value. missing 'Fare' value is filled by finding the median of 'Fare' value in the 'Pclass' = 3 and 'Embarked' = S."], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_uuid": "8a7a8db3c3e7d0a269b8ed1ec0edf714a69825b1", "_cell_guid": "6bf4193b-1720-4369-aac6-b2c0ce5d43dc"}, "source": ["test.isnull().sum()"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "121700f339735e1ea77030598be7feec09b389e4", "_cell_guid": "ca30fd3e-fe47-4d2f-8f66-b74e6f0c1b66"}, "source": ["test[test['Age'].isnull()].head()"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true, "_uuid": "f579f46c3b160ef088bfb8a8c4f79a661ca9a6ab", "_cell_guid": "bfbc423c-f2fb-4d67-a57e-d6a68b26b4e8"}, "source": ["#apply the missing age method to test dataset\n", "test = fill_missing_age(test)"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "b959f364a9873b5b8b50a76acec1826aeae2317c", "_cell_guid": "7d5f6beb-8289-49b6-a599-729407fdefa8"}, "source": ["test[test['Fare'].isnull()]"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true, "_uuid": "bb6fa66632964248621efe6be4ac7a2e7802eca3", "_cell_guid": "0f74451b-75f4-404c-ab98-e180ecbc3417"}, "source": ["#filling the missing 'Fare' data with the  median\n", "def fill_missing_fare(dataset):\n", "    median_fare=dataset[(dataset[\"Pclass\"]==3) & (dataset[\"Embarked\"]==\"S\")][\"Fare\"].median()\n", "    dataset[\"Fare\"]=dataset[\"Fare\"].fillna(median_fare)\n", "    return dataset\n", "\n", "test = fill_missing_fare(test)"], "outputs": [], "cell_type": "code"}, {"metadata": {"_uuid": "8077269190ae7ad86144457f2e28f4f5f19c4210", "_cell_guid": "ae502066-3ace-4bb0-9961-af7ce600303c"}, "source": ["## 2.3 Re-Check for missing data"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_uuid": "bbee0325bfc81989bfd7666a5c19f5f56bc9a453", "_cell_guid": "94e63257-cbfe-4025-af7c-d259feab5e95"}, "source": ["## Re-Check for missing data\n", "train.isnull().any()"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "5365126b24f3e8df53ac09d3bdc8d31a3ad4c2e6", "_cell_guid": "b77c8e3b-7f3b-46ea-a30e-47fa2d9cff60"}, "source": ["## Re-Check for missing data\n", "test.isnull().any()"], "outputs": [], "cell_type": "code"}, {"metadata": {"_uuid": "d2f78915b16804bb1580a057c72ed6f429708d35", "_cell_guid": "1b074c74-701d-4ab1-9dad-7e54d6e50325"}, "source": ["discretize Age feature"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_uuid": "d0423e17c5833ca2a091e62419d8f37945232775", "_cell_guid": "31479972-c323-404b-9cff-7548fcdcf9bd"}, "source": ["\n", "for dataset in total:\n", "    dataset.loc[dataset[\"Age\"] <= 9, \"Age\"] = 0\n", "    dataset.loc[(dataset[\"Age\"] > 9) & (dataset[\"Age\"] <= 19), \"Age\"] = 1\n", "    dataset.loc[(dataset[\"Age\"] > 19) & (dataset[\"Age\"] <= 29), \"Age\"] = 2\n", "    dataset.loc[(dataset[\"Age\"] > 29) & (dataset[\"Age\"] <= 39), \"Age\"] = 3\n", "    dataset.loc[(dataset[\"Age\"] > 29) & (dataset[\"Age\"] <= 39), \"Age\"] = 3\n", "    dataset.loc[dataset[\"Age\"] > 39, \"Age\"] = 4\n"], "outputs": [], "cell_type": "code"}, {"metadata": {"_uuid": "afe3c4910f18316a4b3223c0c96d3673375ab2b6", "_cell_guid": "28df829d-5fd4-442e-bbfc-3eb0b2229ee3"}, "source": ["Discretize Fare"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_uuid": "f2332a3801a0f29f8b95a5a0e6dddfd0d9b903ac", "_cell_guid": "9f691e75-64be-40bb-b922-1516b68ce6ec"}, "source": ["pd.qcut(train[\"Fare\"], 8).value_counts()"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"collapsed": true, "_uuid": "32997f259d7375e254dda625b44cc3ea29107309", "_cell_guid": "a26c58e1-b205-4b9e-80a6-0a5ae3db3512"}, "source": ["for dataset in total:\n", "    dataset.loc[dataset[\"Fare\"] <= 7.75, \"Fare\"] = 0\n", "    dataset.loc[(dataset[\"Fare\"] > 7.75) & (dataset[\"Fare\"] <= 7.91), \"Fare\"] = 1\n", "    dataset.loc[(dataset[\"Fare\"] > 7.91) & (dataset[\"Fare\"] <= 9.841), \"Fare\"] = 2\n", "    dataset.loc[(dataset[\"Fare\"] > 9.841) & (dataset[\"Fare\"] <= 14.454), \"Fare\"] = 3   \n", "    dataset.loc[(dataset[\"Fare\"] > 14.454) & (dataset[\"Fare\"] <= 24.479), \"Fare\"] = 4\n", "    dataset.loc[(dataset[\"Fare\"] >24.479) & (dataset[\"Fare\"] <= 31), \"Fare\"] = 5   \n", "    dataset.loc[(dataset[\"Fare\"] > 31) & (dataset[\"Fare\"] <= 69.487), \"Fare\"] = 6\n", "    dataset.loc[dataset[\"Fare\"] > 69.487, \"Fare\"] = 7"], "outputs": [], "cell_type": "code"}, {"metadata": {"_uuid": "267fb8ff63700c53dd634b56ac9a2748aae8fca6", "_cell_guid": "50a244b0-34c4-4cf6-96b3-37dc35656617"}, "source": ["Factorized 2 of the column whic are 'Sex' and 'Embarked'"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_uuid": "b3c3d48e1a47eefdfc3412b11f9689f94a7bbbbc", "_cell_guid": "3eea8cdf-ef6c-4e56-ae03-59867f30b5d1"}, "source": ["for dataset in total:\n", "    dataset['Sex'] = pd.factorize(dataset['Sex'])[0]\n", "    dataset['Embarked']= pd.factorize(dataset['Embarked'])[0]\n", "train.head()"], "outputs": [], "cell_type": "code"}, {"metadata": {"_uuid": "8bb72691ee33ceacea5bc9f734755a3f941bf630", "_cell_guid": "156c04cf-afa6-494b-ba55-c48a4afe9be2"}, "source": ["Checking the correlation between features"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_uuid": "37c80b837e639bca8a4dea25b3cf048c600a35ee", "_cell_guid": "fb6d52f4-3184-4ba2-9820-4fb9339d10eb"}, "source": ["#correlation map\n", "f,ax = plt.subplots(figsize=(18, 18))\n", "sns.heatmap(train.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)"], "outputs": [], "cell_type": "code"}, {"metadata": {"_uuid": "8091e256827c126399bc6b4a87172309c274a190", "_cell_guid": "ac0aa14a-b300-465d-a905-1045646433cc"}, "source": ["# 3. Spliting the data"], "cell_type": "markdown"}, {"metadata": {"_uuid": "a2803a70e5467b82a0ab49153cdbba38358bf97e", "_cell_guid": "d0f812dd-374a-4066-bf4e-252ba1b71ad9"}, "source": ["Seperate input features from target feature"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_uuid": "6ac06ba4084a76dc7afcc686067f4e3f69f69869", "_cell_guid": "95c41514-1b8b-4911-9d08-021fd6c14609"}, "source": ["x = train.drop(\"Survived\", axis=1)\n", "y = train[\"Survived\"]"], "outputs": [], "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "858d7f184e16528c51fc9753b09f7070d3f4e436", "_cell_guid": "fb7432ee-ec54-4338-8471-2ecc0434db3b"}, "source": ["Split the data into training and validation sets"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_uuid": "179f0f3ee731874fbd934272d91c99d78496085d", "_cell_guid": "82288f65-2c48-4da6-95e9-cc73be3dc7be"}, "source": ["x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=.25,random_state=1)"], "outputs": [], "cell_type": "code"}, {"metadata": {"_uuid": "76ae0e6a4480d100e5f118d92a2a695bac60ca37", "_cell_guid": "6cc571f0-4e61-459a-b240-438f9888ad03"}, "source": ["# 4. Performance Comparison"], "cell_type": "markdown"}, {"metadata": {"_uuid": "ade6d1ef6e4ca609592a6753f921b3949b493622", "_cell_guid": "75e396a6-ca52-4ae2-8a14-7a5fe835ef50"}, "source": ["List of Machine Learning Algorithm (MLA) used"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_uuid": "9b8348354b567e0e44070e58d60adf1ce07aac7c", "_cell_guid": "032ca31c-82c5-4303-9fc1-20a5f736a986"}, "source": ["\n", "MLA = [\n", "    #Ensemble Methods\n", "    ensemble.AdaBoostClassifier(),\n", "    ensemble.BaggingClassifier(),\n", "    ensemble.ExtraTreesClassifier(),\n", "    ensemble.GradientBoostingClassifier(),\n", "    ensemble.RandomForestClassifier(),\n", "\n", "    #Gaussian Processes\n", "    gaussian_process.GaussianProcessClassifier(),\n", "    \n", "    #GLM\n", "    linear_model.LogisticRegressionCV(),\n", "    linear_model.PassiveAggressiveClassifier(),\n", "    linear_model. RidgeClassifierCV(),\n", "    linear_model.SGDClassifier(),\n", "    linear_model.Perceptron(),\n", "    \n", "    #Navies Bayes\n", "    naive_bayes.BernoulliNB(),\n", "    naive_bayes.GaussianNB(),\n", "    \n", "    #Nearest Neighbor\n", "    neighbors.KNeighborsClassifier(),\n", "    \n", "    #SVM\n", "    svm.SVC(probability=True),\n", "    svm.NuSVC(probability=True),\n", "    svm.LinearSVC(),\n", "    \n", "    #Trees    \n", "    tree.DecisionTreeClassifier(),\n", "   #tree.ExtraTreeClassifier(),\n", "    \n", "    ]\n"], "outputs": [], "cell_type": "code"}, {"metadata": {"_uuid": "36919c53b63ee72cdc91674966ecf84094b72a36", "_cell_guid": "b6680a8a-67aa-4f9d-a64e-6f82deaa31c5"}, "source": ["Train the data into the model and calculate the performance"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_uuid": "260ebc51f433fe862565997aec3f34f40e397a3b", "_cell_guid": "37d74b14-2595-4537-995d-991cb6c25d1f"}, "source": ["MLA_columns = []\n", "MLA_compare = pd.DataFrame(columns = MLA_columns)\n", "\n", "\n", "row_index = 0\n", "for alg in MLA:\n", "    \n", "    \n", "    predicted = alg.fit(x_train, y_train).predict(x_test)\n", "    fp, tp, th = roc_curve(y_test, predicted)\n", "    MLA_name = alg.__class__.__name__\n", "    MLA_compare.loc[row_index,'MLA Name'] = MLA_name\n", "    MLA_compare.loc[row_index, 'MLA Train Accuracy'] = round(alg.score(x_train, y_train), 4)\n", "    MLA_compare.loc[row_index, 'MLA Test Accuracy'] = round(alg.score(x_test, y_test), 4)\n", "    MLA_compare.loc[row_index, 'MLA Precission'] = precision_score(y_test, predicted)\n", "    MLA_compare.loc[row_index, 'MLA Recall'] = recall_score(y_test, predicted)\n", "    MLA_compare.loc[row_index, 'MLA AUC'] = auc(fp, tp)\n", "\n", "\n", "\n", "\n", "\n", "    row_index+=1\n", "    \n", "MLA_compare.sort_values(by = ['MLA Test Accuracy'], ascending = False, inplace = True)    \n", "MLA_compare"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "903b8e68f3fd448d4d4aed88541ff24112c73b96", "_cell_guid": "a9c822e7-c622-4919-8bbe-4fa04685a2d0"}, "source": ["plt.subplots(figsize=(15,6))\n", "sns.barplot(x=\"MLA Name\", y=\"MLA Train Accuracy\",data=MLA_compare,palette='hot',edgecolor=sns.color_palette('dark',7))\n", "plt.xticks(rotation=90)\n", "plt.title('MLA Train Accuracy Comparison')\n", "plt.show()"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "dac3b87fc029a33dd1c4c3917bbdd7608712a38b", "_cell_guid": "9fdc6ddd-2215-40b5-9635-9e3242b78e5d"}, "source": ["plt.subplots(figsize=(15,6))\n", "sns.barplot(x=\"MLA Name\", y=\"MLA Test Accuracy\",data=MLA_compare,palette='hot',edgecolor=sns.color_palette('dark',7))\n", "plt.xticks(rotation=90)\n", "plt.title('MLA Test Accuracy Comparison')\n", "plt.show()"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "714a08da8856e6726cd6156f11c8b475c0bd9b0d", "_cell_guid": "50785c81-eda1-4e73-80c0-f1eddcf90b7c"}, "source": ["plt.subplots(figsize=(15,6))\n", "sns.barplot(x=\"MLA Name\", y=\"MLA Precission\",data=MLA_compare,palette='hot',edgecolor=sns.color_palette('dark',7))\n", "plt.xticks(rotation=90)\n", "plt.title('MLA Precission Comparison')\n", "plt.show()"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "81cdc016520dd6c21bf35c262362f933ce8bbc88", "_cell_guid": "36f964be-d1b2-41c5-9167-2dcefa110c7b"}, "source": ["plt.subplots(figsize=(15,6))\n", "sns.barplot(x=\"MLA Name\", y=\"MLA Recall\",data=MLA_compare,palette='hot',edgecolor=sns.color_palette('dark',7))\n", "plt.xticks(rotation=90)\n", "plt.title('MLA Recall Comparison')\n", "plt.show()"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "9cad05b5eb74f53b00dccc696ab96385af810207", "_cell_guid": "dacbea26-3794-4e61-9564-f958d737018a"}, "source": ["plt.subplots(figsize=(15,6))\n", "sns.barplot(x=\"MLA Name\", y=\"MLA AUC\",data=MLA_compare,palette='hot',edgecolor=sns.color_palette('dark',7))\n", "plt.xticks(rotation=90)\n", "plt.title('MLA AUC Comparison')\n", "plt.show()"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "edc9e5e16b47f603cdf5320d0d05da2fa23b1b2d", "_cell_guid": "04308839-4a91-4f5b-8204-0ab0520304f1"}, "source": ["index = 1\n", "for alg in MLA:\n", "    \n", "    \n", "    predicted = alg.fit(x_train, y_train).predict(x_test)\n", "    fp, tp, th = roc_curve(y_test, predicted)\n", "    roc_auc_mla = auc(fp, tp)\n", "    MLA_name = alg.__class__.__name__\n", "    plt.plot(fp, tp, lw=2, alpha=0.3, label='ROC %s (AUC = %0.2f)'  % (MLA_name, roc_auc_mla))\n", "   \n", "    index+=1\n", "\n", "plt.title('ROC Curve comparison')\n", "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n", "plt.plot([0,1],[0,1],'r--')\n", "plt.xlim([0,1])\n", "plt.ylim([0,1])\n", "plt.ylabel('True Positive Rate')\n", "plt.xlabel('False Positive Rate')    \n", "plt.show()"], "outputs": [], "cell_type": "code"}, {"metadata": {"_uuid": "d36eb20798f578c53493e69ac04194765769a4d3", "_cell_guid": "74595de8-b019-4dbe-9d05-397a65edf7fb"}, "source": ["# 4. Tuning the algorithm"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_uuid": "068c27666860465835cfe7918ef47094773190b8", "_cell_guid": "2fc5d07b-9dbe-4d2d-8f71-506c87806813"}, "source": ["tunealg = ensemble.ExtraTreesClassifier() #Select the algorithm to be tuned\n", "tunealg.fit(x_train, y_train)\n", "\n", "print('BEFORE tuning Parameters: ', tunealg.get_params())\n", "print(\"BEFORE tuning Training w/bin set score: {:.2f}\". format(tunealg.score(x_train, y_train))) \n", "print(\"BEFORE tuning Test w/bin set score: {:.2f}\". format(tunealg.score(x_test, y_test)))\n", "print('-'*10)\n", "\n"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "b861583413eb515d9fd332e1bda427079dc9fa0e", "_cell_guid": "33155afd-69a3-48f5-962e-168d4713fd1d"}, "source": ["#tune parameters\n", "param_grid = {#'bootstrap': [True, False],\n", "              'class_weight': ['balanced' , None],\n", "              #'max_depth': [1, 2,3,4, None],\n", "              #'max_features': ['log2', 'auto'],\n", "              #'max_leaf_nodes': [0,1,2,3,4, None],\n", "              #'min_impurity_decrease': [True, False, None],\n", "              #'min_impurity_split': [True, False],\n", "              #'min_samples_leaf': [1, 2,3,4,5],\n", "              #'min_samples_split': [1,2,3,4,5],\n", "              #'min_weight_fraction_leaf': [0.0,1.0,2.0,3.0,4.0,5.0], \n", "              #'n_estimators': [10,15,25,35,45], \n", "              'n_jobs':  [1,2,3,4,5], \n", "              #'oob_score': [True, False], \n", "              'random_state': [0,1, 2,3,4, None], \n", "              #'verbose': [0,1, 2,3,4, 5], \n", "              'warm_start': [True, False]\n", "             }\n", "# So, what this GridSearchCV function do is finding the best combination of parameters value that is set above.\n", "tune_model = model_selection.GridSearchCV(linear_model.PassiveAggressiveClassifier(), param_grid=param_grid, scoring = 'roc_auc')\n", "tune_model.fit (x_train, y_train)\n", "\n", "print('AFTER tuning Parameters: ', tune_model.best_params_)\n", "print(\"AFTER tuning Training w/bin set score: {:.2f}\". format(tune_model.score(x_train, y_train))) \n", "print(\"AFTER tuning Test w/bin set score: {:.2f}\". format(tune_model.score(x_test, y_test)))\n", "print('-'*10)"], "outputs": [], "cell_type": "code"}], "nbformat": 4, "nbformat_minor": 1}