{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2afc37b9-5458-debd-9ea7-1cf7dde4c540"
      },
      "source": [
        "# Microsoft LightGBM\n",
        "https://github.com/Microsoft/LightGBM\n",
        "https://github.com/garethjns/Kaggle-Titanic  \n",
        "\n",
        "I've seen a few forum questions about Mircosoft's LightGMB recently and I've been trying it out on the Titanic dataset, so figured I'd post a few usage examples for anyone interested. I'd also like to hear ideas and suggestions regarding optimum workflow with LightGBM.\n",
        "\n",
        "Generally, it feels similar to use to XGBoost (expect a million times easier to compile and install in Python/Windows), but the way it builds trees is somewhat different. I'm not entirely familiar with its intricacies or all the parameters yet, but it seems relatively straight forward to get a reasonable score here with some parameter tuning and only basic features. This will hopefully provide a good starting point for others wishing to try it out.\n",
        "\n",
        "This notebook includes:  \n",
        "\n",
        " - Basic feature engineering (similar to a number of other notebooks, but deliberately kept short)  \n",
        " - Data preparation for LightGBM  \n",
        "      - Creating dataset objects  \n",
        "      - Setting labels  \n",
        "      - Setting categorical features  \n",
        " - Fitting with early stopping on a validation set using different metrics  \n",
        "      - Example parameters to play with  \n",
        "      - Scores ~0.785  \n",
        " - Model assessment   \n",
        "      - General AUC, accuracy.  \n",
        "      - Plotting and using feature importance  \n",
        " - Predicting  \n",
        "      - Weirdly (?) not using a dataset object  \n",
        " - Using LightGBM in a skLearn pipeline for parameter tuning  \n",
        "      - Scores ~0.795  \n",
        " - Running k-fold cross validation  \n",
        "      - Just an example, not used to create a submission here  \n",
        "\n",
        "This notebook lacks:  \n",
        "\n",
        "  - More sophisticated feature engineering  \n",
        "  - Well tuned hyperparameters  \n",
        "  - Benchmarking of speed and performance vs XGBoost   \n",
        "  \n",
        "I'd be interested to see how well people can get LightGBM performing with some good features and some more guided parameter tuning!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9dc581f9-bf57-ac9f-c94a-090f54660219"
      },
      "outputs": [],
      "source": [
        "#%% Imports\n",
        "\n",
        "# The usuals\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Regular expressions (urrggghhhhhhhhh) for handling string features\n",
        "import re\n",
        "\n",
        "# LightGBM\n",
        "import lightgbm as lgb\n",
        "\n",
        "# sklearn tools for model training and assesment\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (roc_curve, auc, accuracy_score)\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "dbc4fb3a-4c43-429b-e447-9b31810180f3"
      },
      "source": [
        "## Feature engineering  \n",
        "This section of the notebook deals with cleaning the data and creation of new features. I've deliberately kept it as short as possible as it's not really my focus here, but I'd certainly encourage anyone looking to improve this script to start here. The following steps are performed:\n",
        "\n",
        " - Data is imported  \n",
        " - Some cabin-related features are created  \n",
        " - Feature relating to family are added  \n",
        " - Title column is cleaned and handled as per other notebooks  \n",
        " - Categorical columns are converted to pd.Categorical's and then replaced with their cat codes. This is lazy, and drops information that would be useful in assessing feature importance later.  \n",
        " - Missing Age values are replaced with the median of the whole dataset - see other notebooks for better ways of dealing with these values.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3c96752d-e053-79ac-29f0-ae1cd3e9f893"
      },
      "outputs": [],
      "source": [
        "#%% Import data\n",
        "\n",
        "# Import both data sets\n",
        "trainRaw = pd.read_csv('../input/train.csv')\n",
        "testRaw = pd.read_csv('../input/test.csv')\n",
        "\n",
        "# And concatonate together\n",
        "nTrain = trainRaw.shape[0]\n",
        "full = pd.concat([trainRaw, testRaw], axis=0)\n",
        "\n",
        "\n",
        "#%% Cabins\n",
        "\n",
        "def ADSplit(s):\n",
        "    \"\"\"\n",
        "    Function to try and extract cabin letter and number from the cabin column.\n",
        "    Runs a regular expression that finds letters and numbers in the \n",
        "    string. These are held in match.group, if they exist.\n",
        "    \"\"\"\n",
        "\n",
        "    match = re.match(r\"([a-z]+)([0-9]+)\", s, re.I)\n",
        "    \n",
        "    try:\n",
        "        letter = match.group(1)\n",
        "    except:\n",
        "        letter = ''\n",
        "    \n",
        "    try:\n",
        "        number = match.group(2)\n",
        "    except:\n",
        "        number = 9999\n",
        "\n",
        "    return letter, number\n",
        "\n",
        "\n",
        "def DR(s):\n",
        "    \"\"\"\n",
        "    From the cabin string, try and extract letter, number, and number of cabins\n",
        "    \"\"\"\n",
        "    \n",
        "    # Check contents\n",
        "    if isinstance(s, (int, float)):\n",
        "        # If field is empty, return nothing\n",
        "        letter = ''\n",
        "        number = ''\n",
        "        nRooms = 9999\n",
        "    else:\n",
        "        # If field isn't empty, split sting on space. Some strings contain \n",
        "        # multiple cabins.\n",
        "        s = s.split(' ')\n",
        "        # Count the cabins based on number of splits\n",
        "        nRooms = len(s)\n",
        "        # Just take first cabin for letter/number extraction\n",
        "        s = s[0]\n",
        "        \n",
        "        letter, number = ADSplit(s)\n",
        "   \n",
        "    return [letter, number, nRooms]\n",
        "\n",
        "# Apply DR function to each cell in Cabin column using pandas apply method.    \n",
        "out = full['Cabin'].apply(DR)\n",
        "# Outout tuple with 3 values for each row, convert this to pandas df\n",
        "out = out.apply(pd.Series)\n",
        "# And name the columns\n",
        "out.columns = ['CL', 'CN', 'nC']\n",
        "    \n",
        "# Then concatenate these columns to the dataset\n",
        "full = pd.concat([full, out], axis=1)\n",
        "    \n",
        "\n",
        "#%% Family \n",
        "\n",
        "# Add some family features directly to new columns in the dataset\n",
        "# Size\n",
        "full['fSize'] = full['SibSp'] + full['Parch'] + 1\n",
        "# Ratio\n",
        "full['fRatio'] = (full['Parch']+1) / (full['SibSp']+ 1)\n",
        "# Adult?\n",
        "full['Adult'] = full['Age']>18    \n",
        "\n",
        "\n",
        "#%% Names\n",
        "# Extract titles from Name column, standardise\n",
        "\n",
        "titleDict = {\n",
        "    \"Capt\": \"Officer\",\n",
        "    \"Col\": \"Officer\",\n",
        "    \"Major\": \"Officer\",\n",
        "    \"Jonkheer\": \"Sir\",\n",
        "    \"Don\": \"Sir\",\n",
        "    \"Sir\": \"Sir\",\n",
        "    \"Dr\": \"Dr\",\n",
        "    \"Rev\": \"Rev\",\n",
        "    \"theCountess\": \"Lady\",\n",
        "    \"Dona\": \"Lady\",\n",
        "    \"Mme\": \"Mrs\",\n",
        "    \"Mlle\": \"Miss\",\n",
        "    \"Ms\": \"Mrs\",\n",
        "    \"Mr\": \"Mr\",\n",
        "    \"Mrs\": \"Mrs\",\n",
        "    \"Miss\": \"Miss\",\n",
        "    \"Master\": \"Master\",\n",
        "    \"Lady\": \"Lady\"\n",
        "}\n",
        "\n",
        "\n",
        "def splitName(s, titleDict):\n",
        "    \"\"\"\n",
        "    Extract title from name, replace with value in title dictionary. Also \n",
        "    return surname.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Remove '.' from name string\n",
        "    s = s.replace('.', '')\n",
        "    # Split on spaces\n",
        "    s = s.split(' ')\n",
        "    # get surname\n",
        "    surname = s[0]\n",
        "\n",
        "    # Get title - loop over titleDict, if s matches a key, take the \n",
        "    # corresponding value as the title\n",
        "    title = [t for k,t in titleDict.items() if str(k) in s]\n",
        "   \n",
        "    # If no matching keys in title dict, use 'Other'.\n",
        "    if title == []:\n",
        "        title = 'Other'\n",
        "    else:\n",
        "        # Title is a list, so extract contents\n",
        "        title = title[0]\n",
        "    \n",
        "    # Return surname (stripping remaining ',') and title as string\n",
        "    return surname.strip(','), title\n",
        "\n",
        "\n",
        "# Apply functions to df and concatenate new columns as before\n",
        "out = full['Name'].apply(splitName, args=[titleDict])\n",
        "out = out.apply(pd.Series)\n",
        "out.columns = ['Surname', 'Title']\n",
        "  \n",
        "full = pd.concat([full, out], axis=1)\n",
        "\n",
        "\n",
        "#%% Categorical columns\n",
        "\n",
        "# List of categorical columns to recode\n",
        "catCols = ['Sex', 'Embarked', 'CL', 'CN', 'Surname', 'Title']\n",
        "\n",
        "# Recode\n",
        "for c in catCols:\n",
        "    # Convert column to pd.Categotical\n",
        "    full[c] = pd.Categorical(full[c])\n",
        "    # Extract the cat.codes and replace the column with these\n",
        "    full[c] = full[c].cat.codes\n",
        "    # Convert the cat codes to categotical...    \n",
        "    full[c] = pd.Categorical(full[c])\n",
        "\n",
        "\n",
        "# Generate a logical index of categorical columns to maybe use with LightGBM later\n",
        "catCols = [i for i,v in enumerate(full.dtypes) if str(v)=='category']\n",
        "\n",
        "\n",
        "#%% Age\n",
        "\n",
        "# Replace missing age values with median. \n",
        "# See ither kernels for more sophisticated ways of doing this!\n",
        "full.loc[full.Age.isnull(), 'Age'] = np.median(full['Age'].loc[full.Age.notnull()])\n",
        "\n",
        "\n",
        "#%% Split datasets\n",
        "\n",
        "train = full.iloc[0:nTrain,:]\n",
        "test = full.iloc[nTrain::,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7d1da43f-eb57-a504-2395-77984b215cea"
      },
      "source": [
        "## Model fitting\n",
        "\n",
        "LightGBM handles data in a similar fashion to XGBoost in that it uses its own dataset objects. These are created with **lgb.Dataset** and hold the data, labels, lists of categorical features, etc.\n",
        "\n",
        "For some reason, for prediction LightGBM expects raw data as input rather than its own dataset object, so the following function prepares the data:  \n",
        "\n",
        "  - The class column, if specified, is split off in to a separate vector (labels)  \n",
        "  - The ID column, if specified, is split off in to a separate vector (IDs)  \n",
        "  - Columns specified in fDrop are removed  \n",
        "  - The data set object is created from the remaining columns and with the labels specified separately. Categorical features are set to auto, so this set according to the datatype of each pandas dataframe column.\n",
        "  - The corresponding raw data set is also returned for use with the prediction functions   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a8f89b32-1de0-19a1-d5e3-6e227900d53c"
      },
      "outputs": [],
      "source": [
        "def prepLGB(data, classCol = '', IDCol = '', fDrop = []):\n",
        "    \n",
        "        # Drop class column\n",
        "        if classCol != '':\n",
        "            labels = data[classCol]\n",
        "            fDrop = fDrop + [classCol]\n",
        "        else:\n",
        "            labels = []\n",
        "    \n",
        "        if IDCol != '':\n",
        "            IDs = data[IDCol]\n",
        "        else:\n",
        "            IDs = []\n",
        "\n",
        "        if fDrop != []:\n",
        "           data =  data.drop(fDrop, axis=1)\n",
        "       \n",
        "        # Create LGB mats        \n",
        "        lData = lgb.Dataset(data, label=labels, free_raw_data=False, \n",
        "                            feature_name=list(data.columns),\n",
        "                            categorical_feature = 'auto')\n",
        "        \n",
        "        return lData, labels, IDs, data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c493e9f3-9fef-5e53-c27c-4aedb11ce68a"
      },
      "source": [
        "### Fitting with early stopping\n",
        "\n",
        "Initially scored ~0.785, but I've faffed around a lot with the parameters since then. \n",
        "\n",
        "Training is done using **lgb.train** and takes a **lgb.Dataset**. The metric specified in params is applied to the valid_sets on each step, and early stopping is based on the last set specified.\n",
        "\n",
        "Prediction is done for each set using the raw data, and the best iteration from early stopping is used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e802d819-311e-a666-31f0-8e5947e56270"
      },
      "outputs": [],
      "source": [
        "# Specify columns to drop\n",
        "fDrop = ['Ticket', 'Cabin', 'Name']\n",
        "\n",
        "# Split training data in to training and validation sets. \n",
        "# Validation set is used for early stopping.\n",
        "trainData, validData = train_test_split(train, test_size=0.4)\n",
        "\n",
        "# Prepare the data sets\n",
        "trainDataL, trainLabels, trainIDs, trainData = prepLGB(trainData, \n",
        "                                                 classCol = 'Survived', \n",
        "                                                 IDCol = 'PassengerId',\n",
        "                                                 fDrop = fDrop)\n",
        "                                                 \n",
        "validDataL, validLabels, validIDs, validData = prepLGB(validData, \n",
        "                                                 classCol = 'Survived', \n",
        "                                                 IDCol = 'PassengerId',\n",
        "                                                 fDrop = fDrop)\n",
        "\n",
        "testDataL, _, _ , testData = prepLGB(test, \n",
        "                                 classCol = 'Survived', \n",
        "                                 IDCol = 'PassengerId',\n",
        "                                 fDrop = fDrop)\n",
        "\n",
        "# Set params\n",
        "# Scores ~0.784    \n",
        "params = {'boosting_type': 'gbdt',\n",
        "          'max_depth' : -1,\n",
        "          'objective': 'binary', \n",
        "          'nthread': 5, \n",
        "          'silent': True,\n",
        "          'num_leaves': 64, \n",
        "          'learning_rate': 0.05, \n",
        "          'max_bin': 512, \n",
        "          'subsample_for_bin': 200,\n",
        "          'subsample': 1, \n",
        "          'subsample_freq': 1, \n",
        "          'colsample_bytree': 0.8, \n",
        "          'reg_alpha': 5, \n",
        "          'reg_lambda': 10,\n",
        "          'min_split_gain': 0.5, \n",
        "          'min_child_weight': 1, \n",
        "          'min_child_samples': 5, \n",
        "          'scale_pos_weight': 1,\n",
        "          'num_class' : 1,\n",
        "          'metric' : 'binary_error'}\n",
        "\n",
        "# Train model\n",
        "gbm = lgb.train(params, \n",
        "                trainDataL, \n",
        "                100000, # Max number of trees\n",
        "                valid_sets=[trainDataL, validDataL],\n",
        "                early_stopping_rounds = 50,\n",
        "                verbose_eval = 4)\n",
        "\n",
        "\n",
        "# Run prediction on training, validation, and test sets using raw data\n",
        "# Specify which model iteration to use\n",
        "predsValid = gbm.predict(validData, num_iteration=gbm.best_iteration)\n",
        "predsTrain = gbm.predict(trainData, num_iteration=gbm.best_iteration)\n",
        "predsTest = gbm.predict(testData, num_iteration=gbm.best_iteration)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a6c3c75a-688d-ebfc-2f74-86e223bb2302"
      },
      "source": [
        "### Model assessment\n",
        "\n",
        "Assess accuracy and AUC for the model. Also, plot feature importance ranked by \"split\" and \"gain\". See ?**lgb.plot_importance** for more info."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2ba4192f-33a7-75b7-be7f-b4bef7fee00b"
      },
      "outputs": [],
      "source": [
        "  def assessMod(predsTrain, yTrain, predsValid=[], yValid=[], \n",
        "              report=True, plot=True):\n",
        "    \"\"\"\n",
        "    Using sklearn functions, return accuracy and ROC metrics (tpr, fpr, auc)\n",
        "    for training data and validation data (if included).\n",
        "    \n",
        "    preds should be model preditions, yTrain and yValid should be labels.\n",
        "    \n",
        "    \"\"\"\n",
        "    trainAcc = accuracy_score(yTrain, np.round(predsTrain))\n",
        "    fprTrain, tprTrain, thresholdsTrain = roc_curve(yTrain, predsTrain)\n",
        "    trainAUC =  auc(fprTrain, tprTrain)\n",
        "    \n",
        "    if predsValid != []:\n",
        "        accuracy_score(yValid, np.round(predsValid))\n",
        "        fprValid, tprValid, thresholdsValid = roc_curve(yValid, predsValid)\n",
        "        validAcc = accuracy_score(yValid, np.round(predsValid))\n",
        "        validAUC = auc(fprValid, tprValid)\n",
        "    else: \n",
        "        validAcc = np.nan\n",
        "        fprValid = np.nan\n",
        "        tprValid = np.nan\n",
        "        validAUC = np.nan\n",
        "   \n",
        "    if report:\n",
        "        print('Train accuracy:', trainAcc, '| Train AUC:', \n",
        "             trainAUC)\n",
        "        if not isinstance(predsValid, list):\n",
        "            print('Validation accuracy:', validAcc, '| Test AUC:', \n",
        "                  validAUC)\n",
        "        \n",
        "        print('-'*30)\n",
        "    \n",
        "    # Plot\n",
        "    if plot:\n",
        "        plotROC(tprTrain, fprTrain, label='Train')\n",
        "        if not isinstance(predsValid, list):\n",
        "            plotROC(tprValid, fprValid, label='Valid')\n",
        "      \n",
        "    # Stats output\n",
        "    stats = {'fprTrain' : fprTrain,\n",
        "             'fprValid' : fprValid,\n",
        "             'tprTrain' : tprTrain,\n",
        "             'tprValid' : tprValid,\n",
        "             'trainAcc' : trainAcc,\n",
        "             'validAcc' : validAcc,\n",
        "             'trainAUC' : trainAUC,\n",
        "             'validAUC' : validAUC}\n",
        "\n",
        "    return stats\n",
        "  \n",
        "    \n",
        "def plotROC(tpr, fpr, label=''):\n",
        "    \"\"\"\n",
        "    Plot ROC curve from tpr and fpr.\n",
        "    \"\"\"\n",
        "    plt.plot(fpr, tpr, label=label)\n",
        "    plt.legend()\n",
        "    plt.ylabel('True positive rate.')\n",
        "    plt.xlabel('False positive rate')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Report model performance on training and validation sets                       \n",
        "assessMod(predsTrain, trainLabels, \n",
        "          predsValid = predsValid, yValid = validLabels, \n",
        "          report=True, plot=True)             \n",
        "\n",
        "# Plot importance\n",
        "lgb.plot_importance(gbm, importance_type=\"split\", title=\"split\")\n",
        "plt.show()\n",
        "\n",
        "lgb.plot_importance(gbm, importance_type=\"gain\", title='gain')\n",
        "plt.show()\n",
        "\n",
        "# Importance values are also available in:\n",
        "print(gbm.feature_importance(\"split\"))\n",
        "print(gbm.feature_importance(\"gain\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b88dab0c-e2d7-b82c-ee43-15cdc5d50d4a"
      },
      "outputs": [],
      "source": [
        "# Save submission\n",
        "sub = pd.DataFrame()\n",
        "sub['PassengerId'] = test['PassengerId']\n",
        "sub['Survived'] = np.int32(predsTest>0.5)\n",
        "sub.to_csv('sub1.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c5ac0f92-ba89-8d0c-0d4c-7dd619038c6c"
      },
      "source": [
        "## Parameter tuning\n",
        "\n",
        "LightGBM is compatible with scikit's grid search. This approach sets a parameter grid to search (this is a small problem, so go crazy), creates the grid using **lgb.LGBMClassifier**, and extracts the best parameters based on 5-fold CV.\n",
        "\n",
        "This grid of parameters should score ~0.795."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4def8f0e-1eda-1b18-ab7d-6ce949597f06"
      },
      "outputs": [],
      "source": [
        "# Prepare data set using all the training data\n",
        "allTrainDataL, allTrainLabels, _ , allTrainData = prepLGB(train, \n",
        "                                                 classCol = 'Survived', \n",
        "                                                 IDCol = 'PassengerId',\n",
        "                                                 fDrop = fDrop)\n",
        "# Create parameters to search\n",
        "gridParams = {\n",
        "    'learning_rate': [0.01],\n",
        "    'n_estimators': [24,48],\n",
        "    'num_leaves': [6,12,20,30],\n",
        "    'boosting_type' : ['gbdt'],\n",
        "    'objective' : ['binary'],\n",
        "    'seed' : [500],\n",
        "    'colsample_bytree' : [0.7,0.8],\n",
        "    'subsample' : [0.7,1],\n",
        "    'reg_alpha' : [1],\n",
        "    'reg_lambda' : [0,1],\n",
        "    }\n",
        "\n",
        "# Create classifier to use. Note that parameters have to be input manually\n",
        "# not as a dict!\n",
        "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt', \n",
        "          objective='binary', \n",
        "          nthread= 5, \n",
        "          silent= True,\n",
        "          max_depth= -1,\n",
        "          max_bin= 128, \n",
        "          subsample_for_bin= 500,\n",
        "          subsample= 1, \n",
        "          subsample_freq= 1, \n",
        "          min_split_gain = 0.5, \n",
        "          min_child_weight = 1, \n",
        "          min_child_samples = 5, \n",
        "          scale_pos_weight = 1)\n",
        "\n",
        "# To view the default model params:\n",
        "mdl.get_params().keys()\n",
        "\n",
        "# Create the grid\n",
        "grid = GridSearchCV(mdl, gridParams, verbose=1, cv=5, n_jobs=-1)\n",
        "# Run the grid\n",
        "grid.fit(allTrainData, allTrainLabels)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(grid.best_params_)\n",
        "print(grid.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8fb6c9ae-3624-bdf5-2f58-6c98fd093fbd"
      },
      "source": [
        "### Retrain, predict\n",
        "\n",
        "Using the parameters from above, train a new model. Here I'm doing this using early stopping again, but as we have an idea of the optimum number of trees to use, it might be worth sepcifying these and training on the entire training set without early stopping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d78493ea-586f-26a5-8852-fab9adfe1454"
      },
      "outputs": [],
      "source": [
        "# Using parameters already set above, replace in the best from the grid search\n",
        "params['colsample_bytree'] = grid.best_params_['colsample_bytree']\n",
        "params['learning_rate'] = grid.best_params_['learning_rate'] \n",
        "# params['max_bin'] = grid.best_params_['max_bin']\n",
        "params['num_leaves'] = grid.best_params_['num_leaves']\n",
        "params['reg_alpha'] = grid.best_params_['reg_alpha']\n",
        "params['reg_lambda'] = grid.best_params_['reg_lambda']\n",
        "params['subsample'] = grid.best_params_['subsample']\n",
        "# params['subsample_for_bin'] = grid.best_params_['subsample_for_bin']\n",
        " \n",
        "# Train     \n",
        "gbm = lgb.train(params, \n",
        "                trainDataL, \n",
        "                100000, \n",
        "                valid_sets=[trainDataL, validDataL],\n",
        "                early_stopping_rounds = 50,\n",
        "                verbose_eval=4)\n",
        "\n",
        "\n",
        "# Plot importance\n",
        "lgb.plot_importance(gbm)\n",
        "plt.show()\n",
        "\n",
        "# Predict\n",
        "predsValid = gbm.predict(validData, num_iteration=gbm.best_iteration)\n",
        "predsTrain = gbm.predict(trainData, num_iteration=gbm.best_iteration)\n",
        "predsTest = gbm.predict(testData, num_iteration=gbm.best_iteration)\n",
        "\n",
        "# Print assessment\n",
        "assessMod(predsTrain, trainLabels, predsValid=predsValid, yValid= validLabels, \n",
        "          report=True, plot=True)               \n",
        "\n",
        "# Save submission\n",
        "sub = pd.DataFrame()\n",
        "sub['PassengerId'] = test['PassengerId']\n",
        "sub['Survived'] = np.int32(predsTest>0.5)\n",
        "sub.to_csv('sub2.csv', index=False)                       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8c8edd36-789e-9268-f0db-a7e0e44eeb7c"
      },
      "source": [
        "## K-fold crossvalidation\n",
        "\n",
        "Run k-fold crossvalidation on a set of parameters using lgb.cv. This ouputs a cv_result object, which contains the mean and std of each fold's model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "edc96602-e1a7-37d3-4607-1c3709abfdbb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Using a set of parameters (just using those from above)   \n",
        "params = {'metric' : 'binary_error'}\n",
        "\n",
        "# Run k-fold crossvalidation on all the training data \n",
        "cv_results = lgb.cv(params, \n",
        "                     allTrainDataL, # Using all training data\n",
        "                     num_boost_round = 10000, \n",
        "                     nfold = 20, \n",
        "                     stratified = False, \n",
        "                     shuffle = True, \n",
        "                     early_stopping_rounds = 20, \n",
        "                     verbose_eval = 10, \n",
        "                     show_stdv = True, \n",
        "                     seed = 0)\n",
        "\n",
        "# Example plot\n",
        "plt.errorbar(x=range(0, len(cv_results['binary_error-mean'])),\n",
        "             y=cv_results['binary_error-mean'], \n",
        "             yerr=cv_results['binary_error-stdv'])\n",
        "plt.xlabel('Num trees')\n",
        "plt.ylabel('Binary_error')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}