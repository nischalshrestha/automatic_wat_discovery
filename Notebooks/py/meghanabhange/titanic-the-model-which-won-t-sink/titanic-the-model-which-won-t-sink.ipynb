{"cells":[{"metadata":{"_uuid":"dedead91cbeb09af60341564e85cde5c5362ddc9"},"cell_type":"markdown","source":"**Titanic: The Model Which Won't Sink**\n\nDisclaimer: First Kaggle competition ever. \n\nSo, for the titanic database, out first approach was to work on creating a purely numpy /pandas based Logistic Regression Model, to improve our understanding of how the Logistic Regression works. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\nfrom sklearn import datasets\nimport numpy as np\nfrom sklearn import cross_validation\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.preprocessing import normalize\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier","execution_count":59,"outputs":[]},{"metadata":{"_uuid":"57b5f2b373585c0a7559ef102f6dd15ef0487da8"},"cell_type":"markdown","source":"Initiate_data is a funtion that takes in the in_loc of the data, and gives a clean dataframe as an output. "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"def initiate_data(in_loc):\n    df = pd.read_csv(in_loc)\n    df = df.drop('Name', 1)\n    df = df.drop('Ticket', 1)\n    a = df[['Fare']]\n    df['Sex'] = df['Sex'].map( {'female': 1, 'male': 2} ).astype(int)\n    \n    df['Embarked'] = df['Embarked'].fillna('S')\n    df['Embarked'] = df['Embarked'].map( {'C': 1, 'S': 2,'Q': 3} )\n    \n    age_avg = df['Age'].mean()\n    age_std = df['Age'].std()\n    age_null_count = df['Age'].isnull().sum()\n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    df['Age'][np.isnan(df['Age'])] = age_null_random_list\n    df['Age'] = df['Age'].astype(int)\n    \n    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n    df[\"Fare\"] = df[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)\n    \n    df = df.drop('Cabin', 1)\n    return df\n\n\n\n    \ndf = initiate_data('../input/train.csv') \ndf = df.dropna()\n'''df['Class_Age'] = df.loc[:,'Age']*df.loc[:,'Pclass']\ndf['Class_Age'] = df['Class_Age'].fillna(df['Class_Age'].median())\ndf['Sex_Age']   = df.loc[:,'Sex']*df.loc[:,'Age']\ndf['Sex_Age'] = df['Sex_Age'].fillna(df['Sex_Age'].median())'''\ndf.head()","execution_count":50,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"48aad6cca59785708d9e6f176f3b406a10932708"},"cell_type":"code","source":"def sigmoid(z):\n    '''\n    Sigmoid: It takes in the score and give the probabality of the outcome. \n    It gives the class probabality of the output. \n    \n    '''\n    z=z.astype(float)\n    return (1.0/(1.0+np.exp(-1.0*z)))\n\ndef log_likelihood(target, features,weights):\n    '''\n    This is a loss funtion. The log-likelihood can be viewed as a sum over all the training data.\n    \n    '''\n    score=np.dot(features,weights)\n    score=score.astype(float)\n    return(sum(target*score)-np.log(1+np.exp(score)))\ndef gradient_log_likelihood(features,predicted,target):\n    return(np.dot(features.T,np.subtract(target,predicted)))","execution_count":51,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"824abbedc3bc3c8fecb76faecfc9720e5100ab15"},"cell_type":"code","source":"def logistic_regression(learning_rate=0.0003,steps=100000, add_intercept=False):\n    ind = 0\n    tot_features = np.array(df.loc[:,('Pclass','Sex','SibSp','Parch','Age','Fare','Embarked')])\n    tot_target   = np.array(df.loc[:,('Survived')])\n    weights = np.zeros(tot_features.shape[1])\n    for i in range(steps):\n        if(ind>=701):\n            ind=0\n        features=tot_features[ind:ind+10]\n        target=tot_target[ind:ind+10]\n        count = 0\n        scores    = np.dot(features,weights)\n        predicted = sigmoid(scores)\n        scores=scores.astype(float)\n        loss      = log_likelihood(target,features,weights)\n        \n        weights   = np.add(gradient_log_likelihood(features, predicted, target)*learning_rate,weights)\n        difference= abs(predicted-target)\n        count     = len(difference)-sum(difference)\n        ind       = ind+11\n    return(weights)\n\nweights = logistic_regression() ","execution_count":52,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c54966dedd6e492a09ca2c28e6741b2cc8c89a3","collapsed":true},"cell_type":"code","source":"\ntest_data = initiate_data('../input/test.csv')\ntest_data.head()","execution_count":53,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33b438a3d03a19dd2e2d3dc46ee3a48227b94a4a","collapsed":true},"cell_type":"code","source":"def testing_data(test_data): \n    '''\n    Function to test the accuracy on unknown data. \n    \n    Input:\n    \n    out_loc- Location of the targets for CSV\n    test_data- Dataframe of the test data. Genrally test.csv\n    '''\n    predicted = []\n    features  = np.array(test_data.loc[:,('Pclass','Sex','SibSp','Parch','Age','Fare','Embarked')])\n    scores    = np.dot(features,weights)\n    scores    = scores.astype(float)\n    predicted = np.round(sigmoid(scores),0)\n    output_data = []\n    newdf     = pd.DataFrame({'PassengerId':np.array(test_data['PassengerId']),'Survived':predicted})\n    return (newdf)\n                   \noutput_data = testing_data(test_data)                   \noutput_data.head()","execution_count":58,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39ca775ac2ea27503ece9b108b37ce4791e8f886","collapsed":true},"cell_type":"code","source":"\ndf = initiate_data('../input/train.csv')\ndf.loc[0,:]\n\ndf['Class_Age'] = df.loc[:,'Age']*df.loc[:,'Pclass']\ndf['Class_Age'] = df['Class_Age'].fillna(df['Class_Age'].median())\ndf['Sex_Age']   = df.loc[:,'Sex']*df.loc[:,'Age']\ndf['Sex_Age'] = df['Sex_Age'].fillna(df['Sex_Age'].median())\ndf.head()","execution_count":60,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4338ff456ea36a0e457f6c77f9d84253704c57bf"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n    df.loc[:, ('Pclass','Sex','SibSp','Parch','Age','Fare','Embarked','Class_Age','Sex_Age')], df.loc[:, ('Survived')], test_size=0.20, random_state=6)","execution_count":61,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff6d910cb5f41d1e13f3b7e16ef642fb79967c8e","collapsed":true},"cell_type":"code","source":"'''\nmin_max_scaler = preprocessing.MinMaxScaler()\nnp_scaled = min_max_scaler.fit_transform(df)\ndf_normalized = pd.DataFrame(np_scaled)\n'''\n#df = df_normalized\nModel = RandomForestClassifier()\nModel.fit(X_train, y_train)\nPredicted = Model.predict(X_test)\naccuracy = accuracy_score(y_test, Predicted)\nprint('RandomForestClassifier: ', accuracy)\n","execution_count":62,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2efa65500f18ff804083c0b6a2bc19c775d11ab","collapsed":true},"cell_type":"code","source":"Model = LogisticRegression()\nModel.fit(X_train, y_train)\nPredicted = Model.predict(X_test)\naccuracy = accuracy_score(y_test, Predicted)\nprint('Logistic Regression: ', accuracy)","execution_count":63,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd9e11b093f2082857750a0cebf9f9217d641313","collapsed":true},"cell_type":"code","source":"Model = DecisionTreeClassifier()\nModel.fit(X_train,y_train)\nPredicted = Model.predict(X_test)\naccuracy = accuracy_score(y_test,Predicted)\nprint('Decison Tree: ',accuracy)","execution_count":64,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5420e4e9bb864bf502e377767e78274fbb83764b","collapsed":true},"cell_type":"code","source":"#KNeighborsClassifier\nModel = KNeighborsClassifier()\nModel.fit(X_train,y_train)\nPredicted = Model.predict(X_test)\naccuracy = accuracy_score(y_test,Predicted)\nprint('KNeighborsClassifier: ',accuracy)","execution_count":65,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e2a6f95baf55f70b72f1358d671d1868272f53d","collapsed":true},"cell_type":"code","source":"Model = SVC()\nModel.fit(X_train, y_train)\nPredicted = Model.predict(X_test)\naccuracy = accuracy_score(y_test, Predicted)\nprint('SVM: ', accuracy)","execution_count":66,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"492074bd33f2d8449cc9892ac38ea45d8a0f4e1d","collapsed":true},"cell_type":"code","source":"Model = MLPClassifier(solver='lbfgs', alpha=0.03,hidden_layer_sizes=(12,17,8,), activation='relu',learning_rate='adaptive')\nModel.fit(X_train, y_train)\nPredicted = Model.predict(X_test)\naccuracy = accuracy_score(y_test, Predicted)\nprint('NN: ', accuracy)","execution_count":67,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2780cb427ef01bff41de710b18b4019b7f0d574","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8d35b8768de894ff0a71f7dfb57d2ea9e20d6149"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}