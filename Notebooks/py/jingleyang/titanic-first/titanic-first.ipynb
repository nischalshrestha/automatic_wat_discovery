{"nbformat": 4, "nbformat_minor": 1, "cells": [{"cell_type": "code", "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from IPython.display import Image\n", "%matplotlib inline\n", "\n", "# Modelling Algorithms\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.svm import SVC, LinearSVC\n", "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\n", "\n", "# Modelling Helpers\n", "from sklearn.preprocessing import Imputer , Normalizer , scale\n", "from sklearn.cross_validation import train_test_split , StratifiedKFold\n", "from sklearn.feature_selection import RFECV\n", "\n", "# Visualisation\n", "import matplotlib as mpl\n", "import matplotlib.pyplot as plt\n", "import matplotlib.pylab as pylab\n", "import seaborn as sns\n", "\n", "# Configure visualisations\n", "%matplotlib inline\n", "mpl.style.use( 'ggplot' )\n", "sns.set_style( 'white' )\n", "pylab.rcParams[ 'figure.figsize' ] = 8 , 6\n", "\n", "\n", "\n", "data_train = pd.read_csv('../input/train.csv')\n", "data_test = pd.read_csv('../input/test.csv')\n", "data_train.sample(5)\n", "\n", "sns.barplot(x=\"Pclass\",y=\"Survived\", hue=\"Sex\", data=data_train)"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "291321a93ae8d53ae21f551eda7405c998226917", "_cell_guid": "9f151459-3113-78df-8af8-0f52d99d1a73"}}, {"cell_type": "code", "source": ["sns.pointplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=data_train,\n", "              palette={\"male\": \"blue\", \"female\": \"pink\"},\n", "              markers=[\"*\", \"o\"], linestyles=[\"-\", \"--\"]);"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "cd58febb4e873af905bfebbccbcfa8ef4717e2f8", "_cell_guid": "89608921-8aca-467b-a298-247cdbad5c89"}}, {"cell_type": "code", "source": ["def simplify_ages(df):\n", "    mean = df.Age.mean()\n", "    df.Age = df.Age.fillna(mean)\n", "    bins=(-1,0,5,12,18,25,30,60,120)\n", "    group_names=['Error','Baby','Child','Teen','Student','Young','Adult','Senior']\n", "    categories = pd.cut(df.Age,bins, labels=group_names)\n", "    df.Age = categories\n", "    return df\n", "\n", "def simplify_cabins(df):\n", "    df.Cabin = df.Cabin.fillna('X')\n", "    df.Cabin = df.Cabin.apply(lambda x:x[0].upper())\n", "    return df\n", "\n", "def simplify_fares(df):\n", "    mean = df.Fare.mean()\n", "    df.Fare = df.Fare.fillna(mean)\n", "    bins = (-1,0,8,15,32,1000)\n", "    group_names = ['Error','low','normal','high','VIP']\n", "    categories = pd.cut(df.Fare,bins, labels = group_names)\n", "    df.Fare = categories\n", "    return df\n", "\n", "def title_map_func(val):\n", "    if val in ['Mr','Mrs','Miss','Dr','Capt','Col','Major','Ms','Master']:\n", "        return val\n", "    else:\n", "        return 'Empty'\n", "def format_name(df):\n", "    df['Lname'] = df.Name.apply(lambda x: x.split()[0][:-1])\n", "    df['Title'] = df.Name.apply(lambda x: x.split()[1][:-1])\n", "    df['Title'] = df.Title.apply(title_map_func)\n", "    return df\n", "def drop_features(df):\n", "    df = df.drop(['Ticket','PassengerId','Name','SibSp','Parch','Lname','Family'],axis=1)\n", "    return df\n", "def family_size(df):\n", "    df['Family'] = df['SibSp']+df['Parch']\n", "    df['IsAlone'] = df.Family.apply(lambda x: 'alone' if x==0 else 'not')\n", "    return df\n", "\n", "def fillna_embarked(df):\n", "    df.Embarked = df.Embarked.fillna('X')\n", "    return df\n", "def lable_pclass(df):\n", "    level_map={1:'First',2:'Middle',3:'Low'}\n", "    df.Pclass = df.Pclass.map(level_map)\n", "    return df\n", "\n", "def transform_features(df):\n", "    df = simplify_ages(df)\n", "    df = simplify_cabins(df)\n", "    df = simplify_fares(df)\n", "    df = format_name(df)\n", "    df = family_size(df)\n", "    df = fillna_embarked(df)\n", "    df = lable_pclass(df)\n", "    df = drop_features(df)\n", "    return df\n", "\n", "data_train = transform_features(data_train)\n", "data_test = transform_features(data_test)\n", "data_train.head(10)"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "0a6401622bef70ab0809bf0d0dc10ef21f17467a", "_cell_guid": "6ba1301d-a037-49ad-8593-0eef1532788e"}}, {"cell_type": "code", "source": [], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "5bb2a6fcf226b133b4529863bc237b08fe4c9cdd", "_cell_guid": "39eebc51-43c0-422d-a53e-ae3d46185d09"}}, {"cell_type": "code", "source": ["from sklearn import preprocessing\n", "\n", "def encode_features(df_train, df_test):\n", "    features = list(data_train.columns.values)\n", "    features.remove('Survived')\n", "    #print(features)\n", "    df_combined = pd.concat([df_train[features],df_test[features]])\n", "    #print(df_combined.sample(5))\n", "    for f in features:\n", "        le = preprocessing.LabelEncoder()\n", "        le = le.fit(df_combined[f])\n", "        df_train[f] = le.transform(df_train[f])\n", "        df_test[f] = le.transform(df_test[f])\n", "        \n", "        ohe = preprocessing.OneHotEncoder()\n", "        ohe = ohe.fit(df_combined[f])\n", "        df_train[f] = ohe.transform(df_train[f])\n", "        df_test[f] = ohe.transform(df_test[f])\n", "        \n", "    return df_train, df_test\n", "\n", "#encode_features(data_train, data_test)\n", "features = list(data_train.columns.values)\n", "features.remove('Survived')\n", "df_combined = pd.concat([data_train[features],data_test[features]])\n", "print(df_combined.sample(10))\n", "print(data_train.shape,data_test.shape, df_combined.shape)\n", "df_combined = pd.get_dummies(df_combined)"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "7404e554a8d069af8bfacf3b7068945e73f99909", "_cell_guid": "bf1681e4-0c49-43e6-baa9-cb7079d1ae88"}}, {"cell_type": "code", "source": ["from sklearn.model_selection import train_test_split\n", "\n", "X_all = df_combined.head(data_train.shape[0])\n", "y_all = data_train['Survived']\n", "num_test = 0.2\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=23)\n", "X_test.sample(10)"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "b06f804389f72af560fabaa8ec2ee6a197536a56", "_cell_guid": "9e398eba-619f-4b42-9e73-8fbab20b0ce3"}}, {"cell_type": "code", "source": [], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "e590dd195833824e0919399f83f382bad8522fb3", "_cell_guid": "59e633fb-9a39-46b3-a939-da42b7005435"}}, {"cell_type": "code", "source": ["from sklearn.ensemble import RandomForestClassifier\n", "from mlxtend.plotting import plot_decision_regions\n", "\n", "forest = RandomForestClassifier(criterion='entropy',\n", "                               n_estimators=10,\n", "                               random_state=0,\n", "                               n_jobs=2)\n", "\n", "forest.fit(X_train, y_train)\n", "print(forest)\n", "print(forest.score(X_test, y_test))\n", "print(forest.feature_importances_)\n", "colums_size = X_train.shape[1]\n", "plt.plot(range(0,colums_size), forest.feature_importances_)"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "6b06f168cec6102a920cc59836ccf1462e7edc7a", "_cell_guid": "297acdd1-fd36-425b-b276-80c65565b5f3"}}, {"cell_type": "code", "source": ["from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.metrics import make_scorer, accuracy_score\n", "from sklearn.model_selection import GridSearchCV\n", "\n", "#clf = RandomForestClassifier()\n", "\n", "parameters = {'n_estimators': [4, 10], \n", "              'max_features': ['log2', 'sqrt','auto'], \n", "              'criterion': ['entropy', 'gini'],\n", "              'max_depth': [2,6], \n", "              'min_samples_split': [2, 5],\n", "              'min_samples_leaf': [1,4]\n", "             }\n", "\n", "#acc_scorer = make_scorer(accuracy_score)\n", "#grid_obj = GridSearchCV(clf, parameters, scoring = acc_scorer)\n", "\n", "#grid_obj = grid_obj.fit(X_train,y_train)\n", "#clf = grid_obj.best_estimator_\n", "clf = RandomForestClassifier(criterion='entropy',\n", "                               n_estimators=10,\n", "                               random_state=0,\n", "                               n_jobs=2)\n", "clf.fit(X_train,y_train)"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "1e9bc0499d10fc05d9903a10dba4c41ca4991a0d", "_cell_guid": "19914ad4-35d2-4576-ba4c-68e328b2f86c"}}, {"cell_type": "code", "source": ["print(clf)\n", "print(clf.score(X_test, y_test))\n", "print(clf.feature_importances_)"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "d42e05ea39e891b6ab5ae129d043d826f60f388f", "_cell_guid": "4c655652-9ade-4095-840e-a93ab290e128"}}, {"cell_type": "code", "source": ["clf = SVC()\n", "print(clf.fit(X_train,y_train))\n", "print(clf.score(X_test, y_test))"], "outputs": [], "execution_count": null, "metadata": {}}, {"cell_type": "code", "source": ["clf = GradientBoostingClassifier()\n", "print(clf.fit(X_train,y_train))\n", "print(clf.score(X_test, y_test))"], "outputs": [], "execution_count": null, "metadata": {}}, {"cell_type": "code", "source": ["clf = KNeighborsClassifier(n_neighbors = 3)\n", "print(clf.fit(X_train,y_train))\n", "print(clf.score(X_test, y_test))"], "outputs": [], "execution_count": null, "metadata": {}}, {"cell_type": "code", "source": ["clf = GaussianNB()\n", "print(clf.fit(X_train,y_train))\n", "print(clf.score(X_test, y_test))"], "outputs": [], "execution_count": null, "metadata": {}}, {"cell_type": "code", "source": ["clf = LogisticRegression()\n", "print(clf.fit(X_train,y_train))\n", "print(clf.score(X_test, y_test))"], "outputs": [], "execution_count": null, "metadata": {}}, {"cell_type": "code", "source": ["clf = SVC(kernel='rbf', random_state=0,gamma=0.1, C=10)\n", "print(clf.fit(X_train,y_train))\n", "print(clf.score(X_test, y_test))\n"], "outputs": [], "execution_count": null, "metadata": {}}, {"cell_type": "code", "source": ["from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler\n", "import matplotlib.pyplot as plt\n", "from sklearn.decomposition import PCA\n", "from sklearn.linear_model import LogisticRegression\n", "from mlxtend.plotting import plot_decision_regions\n", "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true}}, {"cell_type": "code", "source": ["sc = StandardScaler()\n", "X_train_std = sc.fit_transform(X_train)\n", "X_test_std = sc.transform(X_test)\n", "\n", "lda = LDA(n_components=2)\n", "X_train_lda = lda.fit_transform(X_train_std, y_train)\n", "X_test_lda = lda.transform(X_test_std)\n", "\n", "clf = LogisticRegression()\n", "print(clf.fit(X_train_lda,y_train))\n", "print(clf.score(X_test_lda, y_test))\n", "\n", "\n", "plot_decision_regions(X_test_lda, y_test.values, clf)\n", "plt.show()"], "outputs": [], "execution_count": null, "metadata": {}}, {"cell_type": "code", "source": ["pca = PCA()\n", "X_train_pca = pca.fit_transform(X_train_std)\n", "var_len = len(pca.explained_variance_ratio_)\n", "plt.bar(range(1,var_len+1), pca.explained_variance_ratio_)\n", "plt.step(range(1,var_len+1), np.cumsum(pca.explained_variance_ratio_))\n", "plt.show()\n", "\n", "pca = PCA(n_components=2)\n", "X_train_pca = pca.fit_transform(X_train_std)\n", "X_test_pca = pca.transform(X_test_std)\n", "\n", "plt.scatter(X_train_pca[:,0],X_train_pca[:,1])\n", "plt.show()\n", "\n", "clf = SVC()\n", "clf = clf.fit(X_train_pca, y_train)\n", "\n", "plot_decision_regions(X_test_pca, y_test.values, clf)\n", "plt.show()"], "outputs": [], "execution_count": null, "metadata": {}}, {"cell_type": "code", "source": ["import xgboost as xgb\n", "clf= xgb.XGBClassifier()"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true}}, {"cell_type": "code", "source": ["from sklearn.cross_validation import KFold\n", "def run_kfold(clf):\n", "    tot_size = X_all.shape[0]\n", "    kf = KFold(tot_size,  n_folds = 5)\n", "    outcomes = []\n", "    fold = 0\n", "    for train_index, test_index in kf:\n", "        fold +=1\n", "        X_train, X_test = X_all.values[train_index], X_all.values[test_index]\n", "        y_train, y_test = y_all.values[train_index], y_all.values[test_index]\n", "        sc = StandardScaler()\n", "        X_train_std = sc.fit_transform(X_train)\n", "        X_test_std = sc.transform(X_test)\n", "        clf.fit(X_train_std, y_train)\n", "        outcomes.append(clf.score(X_test_std, y_test))\n", "    return outcomes\n", "print(clf)\n", "out = run_kfold(clf)\n", "mean_val = np.mean(out)\n", "print(out)\n", "print(mean_val)"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "8388b75930aa3999969d05b65f3f6768d0fb9eb0", "_cell_guid": "1003c683-8000-4328-b492-29f5bedc6687"}}, {"cell_type": "code", "source": ["# train them all\n", "clf.fit(X_all,y_all)"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "c03647a58a2ea0eabb527e02dbd91fd18860d58b", "_cell_guid": "fc10d5ca-78de-41e8-ae2e-1bf1388ff9fa"}}, {"cell_type": "code", "source": ["X_all.sample(10)\n"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "beed5c886e7e2b5a4bcbbb91bc64609f0847aa8a", "_cell_guid": "e5f7cfcf-5c37-4028-98d9-2ce26a8eb3fd"}}, {"cell_type": "code", "source": ["data_test = pd.read_csv('../input/test.csv')\n", "data_test.sample(10)\n", "ids = data_test['PassengerId']\n", "\n", "predict_input = df_combined.tail(data_test.shape[0])\n", "\n", "predict_output = clf.predict(predict_input)\n", "\n", "output = pd.DataFrame({'PassengerId':ids, 'Survived':predict_output })\n", "print(output.head())\n", "print(output.tail())\n", "print(clf)\n", "output.to_csv(\"titanic-output-0113-v2.csv\",index=False)"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "b13b7ad978b94566149286259fce04b272d4719e", "_cell_guid": "7ca750b6-2935-459b-906c-e9113ac46cfe"}}, {"cell_type": "code", "source": ["\n"], "outputs": [], "execution_count": null, "metadata": {}}, {"cell_type": "code", "source": ["def plot_histograms( df , variables , n_rows , n_cols ):\n", "    fig = plt.figure( figsize = ( 16 , 12 ) )\n", "    for i, var_name in enumerate( variables ):\n", "        ax=fig.add_subplot( n_rows , n_cols , i+1 )\n", "        df[ var_name ].hist( bins=10 , ax=ax )\n", "        ax.set_title( 'Skew: ' + str( round( float( df[ var_name ].skew() ) , ) ) ) # + ' ' + var_name ) #var_name+\" Distribution\")\n", "        ax.set_xticklabels( [] , visible=False )\n", "        ax.set_yticklabels( [] , visible=False )\n", "    fig.tight_layout()  # Improves appearance a bit.\n", "    plt.show()\n", "\n", "def plot_distribution( df , var , target , **kwargs ):\n", "    row = kwargs.get( 'row' , None )\n", "    col = kwargs.get( 'col' , None )\n", "    facet = sns.FacetGrid( df , hue=target , aspect=4 , row = row , col = col )\n", "    facet.map( sns.kdeplot , var , shade= True )\n", "    facet.set( xlim=( 0 , df[ var ].max() ) )\n", "    facet.add_legend()\n", "\n", "def plot_categories( df , cat , target , **kwargs ):\n", "    row = kwargs.get( 'row' , None )\n", "    col = kwargs.get( 'col' , None )\n", "    facet = sns.FacetGrid( df , row = row , col = col )\n", "    facet.map( sns.barplot , cat , target )\n", "    facet.add_legend()\n", "\n", "def plot_correlation_map( df ):\n", "    corr = titanic.corr()\n", "    _ , ax = plt.subplots( figsize =( 12 , 10 ) )\n", "    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n", "    _ = sns.heatmap(\n", "        corr, \n", "        cmap = cmap,\n", "        square=True, \n", "        cbar_kws={ 'shrink' : .9 }, \n", "        ax=ax, \n", "        annot = True, \n", "        annot_kws = { 'fontsize' : 12 }\n", "    )\n", "\n", "def describe_more( df ):\n", "    var = [] ; l = [] ; t = []\n", "    for x in df:\n", "        var.append( x )\n", "        l.append( len( pd.value_counts( df[ x ] ) ) )\n", "        t.append( df[ x ].dtypes )\n", "    levels = pd.DataFrame( { 'Variable' : var , 'Levels' : l , 'Datatype' : t } )\n", "    levels.sort_values( by = 'Levels' , inplace = True )\n", "    return levels\n", "\n", "def plot_variable_importance( X , y ):\n", "    tree = DecisionTreeClassifier( random_state = 99 )\n", "    tree.fit( X , y )\n", "    plot_model_var_imp( tree , X , y )\n", "    \n", "def plot_model_var_imp( model , X , y ):\n", "    imp = pd.DataFrame( \n", "        model.feature_importances_  , \n", "        columns = [ 'Importance' ] , \n", "        index = X.columns \n", "    )\n", "    imp = imp.sort_values( [ 'Importance' ] , ascending = True )\n", "    imp[ : 10 ].plot( kind = 'barh' )\n", "    print (model.score( X , y ))"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true}}, {"cell_type": "code", "source": ["plot_variable_importance(X_train, y_train)"], "outputs": [], "execution_count": null, "metadata": {}}], "metadata": {"language_info": {"name": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}, "version": "3.6.4", "nbconvert_exporter": "python", "file_extension": ".py"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "_change_revision": 0, "_is_fork": false}}