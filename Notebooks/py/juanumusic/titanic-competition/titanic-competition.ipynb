{"cells": [{"source": ["# Import Libraries"], "cell_type": "markdown", "metadata": {"_cell_guid": "8eca8957-1338-48fd-b276-c9f02f8ce68d", "_uuid": "e8d7309922894899e915df9c0ba40c6c3165b51c"}}, {"execution_count": null, "source": ["import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "%matplotlib inline\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "b29c3d0a-4135-41bf-b737-34ad85292b2f", "_uuid": "e56ff94f5af73a1556a83e876974d4a271d14949"}}, {"source": ["# Load CSV\n", "First, we load the CSV FIles"], "cell_type": "markdown", "metadata": {"_cell_guid": "7203d2c0-ac1a-4247-9e59-2b803bf372d4", "_uuid": "61226e32de5d9ade4ec1fe7fb812f7442e1e7a4f"}}, {"execution_count": null, "source": ["df_train = pd.read_csv('../input/train.csv')\n", "df_test = pd.read_csv('../input/test.csv')\n", "\n", "# Combine both datasets to apply common operations\n", "combine = [df_train, df_test]"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "99e355a8-2b4f-4255-9513-f06b5c6180b1", "_uuid": "8bee0dfb8ff51e63edd2b8a0ab16b503a7fde9cf", "collapsed": true}}, {"source": ["# Inspect the datasets\n", "\n", "We inspect the data to see how it's formed.\n", "We note the following for each dataset (train and test):\n", "[](http://)\n", "## Training Data\n", "- There are 891 rows of data, 1 for each passenger\n", "- The *Age* column has 177 **(19.86%)** missing values.\n", "-  The *Cabin* column has 694 **(77.89%)** missing values\n", "- The *Embarked* column has 2 **(0.002%)** missing values\n", "## Test Data\n", "- There are 418 rows of data, 1 for each passenger.\n", "- The *Age* column has 86 **(20.57%)** missing values (similar to the training data).\n", "- The *Cabin* column has 327 **(78.22%)** missing values (similar to the training data).\n", "- The *Fare* column has 1 **(0.002%)** missing value.\n"], "cell_type": "markdown", "metadata": {"_cell_guid": "fd06ab89-0078-4fd6-b7f9-dfe3f56b13c5", "_uuid": "939d39400b4a2d345f770d3596376cceb83ea8b6"}}, {"execution_count": null, "source": ["# Print the training data information\n", "print('TRAIN INFO \\n',df_train.info())\n", "# Print a separator line\n", "print('-'*50)\n", "# Print the test data information\n", "print('TEST INFO \\n',df_test.info())"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "dfc7e449-26ac-4f85-a21a-d2e8f81087e8", "_uuid": "341d6a3ab4d26311f12c433f2cc2aa5bfc8aa921"}}, {"source": ["## Categorical values\n", "The following columns are categorical:\n", "- **Survived**: Boolean indicating 1 if the passenger survived or 0 if the passenger did not survive.\n", "- **Pclass**: An int describing the ticket class, which also refers to the passenger's socio-economic class. Values are: \n", "    - 1: Upper\n", "    - 2: Middle\n", "    - 3: Lower\n", "\n", "- **Sex**: A string describing the passenger's gender.\n", "- **Embarked**: A string representing the port of embarcation. Values are:\n", "    - C = Cherbourg\n", "    - Q = Queenstown\n", "    - S = Southampton"], "cell_type": "markdown", "metadata": {"_cell_guid": "daa5986c-c255-476d-b282-fcf947cdaa5f", "_uuid": "545271755a1d8eedb5488a3ed0b62f1edb4ef137"}}, {"execution_count": null, "source": ["df_train.head()"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "c2c8952b-ca17-4aa2-9162-d9403be85c7f", "_uuid": "ce56d6cd3653b75c379437889ec8bbef3739a705"}}, {"source": ["## Distribution of numerical data\n", "From the distribution of the training data, we can make the following assumptions:\n", "- 38.38% of the passengers survived\n", "* - Most passengers traveled without parents or children"], "cell_type": "markdown", "metadata": {"_cell_guid": "f900a347-d34b-4b02-bd87-1de465ad58d1", "_uuid": "e3d560e0cce61f8256274c6776fbae2eb78c3dde"}}, {"execution_count": null, "source": ["df_train.describe()"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "063d74eb-181a-4365-add9-f083f6ca780a", "_uuid": "5ce6580ee93ca0e61069d070c1e0a381c143ada4"}}, {"source": ["## Distribution of dategorical data\n", "- Cabin only has values on 204 rows, and seems that there are many duplicates (unique: 147)\n", "- Ticket has values on all rows, but contains many duplicates (unique 681)"], "cell_type": "markdown", "metadata": {"_cell_guid": "4efe7287-1373-4cb1-9c11-2078d29e9d11", "_uuid": "c666414ed151aa6ae76239dada326a9ecd906a06"}}, {"execution_count": null, "source": ["df_train.describe(include=['O'])"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "1551cc30-f565-430d-b9a7-5fbcab1f9890", "_uuid": "61a822d19b61e16ee19445fd7da85ad4491fbfce"}}, {"source": ["# Exploratory Analysis\n", "### Survival rate by Pclass <br>\n", "We check the survival rate by Pclass and see that there seem's to be a relationship bewteen Pclass and Survival rate"], "cell_type": "markdown", "metadata": {"_cell_guid": "341c40b9-cd10-4ce1-b3db-7c3b7325c8a9", "_uuid": "d862f2a3bd85ac18bd56e53bbd02996a5d2ca446"}}, {"execution_count": null, "source": ["sns.barplot(x='Pclass', y='Survived', data=df_train.groupby('Pclass', as_index=False).agg({'Survived':'mean'}))\n", "plt.xlabel(s='Pclass',fontsize=16)\n", "plt.ylabel(s='Survival Rate',fontsize=16)\n", "plt.title('Survival Rate by Pclass', fontsize=18)"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "bf8ffa8c-5a38-46f1-9ec0-0ffa15251c37", "_uuid": "5e8568fe159ed57be5e269c3ed87ed6eab8a0e7b"}}, {"source": ["### Survival rate by Gender\n", "Another variable to check is the gender. In this case we see that Gender was also a KEY factor in survival rates"], "cell_type": "markdown", "metadata": {"_cell_guid": "1ad84ede-bb82-42a0-95c2-d49ec3d52b61", "_uuid": "9ce0f5c922444e192ad56abf1562b73ab0854817"}}, {"execution_count": null, "source": ["sns.barplot(x='Sex', y='Survived', data=df_train.groupby('Sex', as_index=False).agg({'Survived':'mean'}))\n", "plt.xlabel(s='Gender',fontsize=16)\n", "plt.ylabel(s='Survival Rate',fontsize=16)\n", "plt.title('Survival Rate by Gender', fontsize=18)"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "8a295bc3-2c8b-435b-8462-9afd44815f76", "_uuid": "bfa2091f91d94e67cb8318dc55a2ed2baf086658"}}, {"source": ["### Survival Distribution by Age\n", "- We can see that passengers with age 0 to 4 had a high survival rate.\n", "- Passengers with ages 15 to 35 had a lower survival rate."], "cell_type": "markdown", "metadata": {"_cell_guid": "71552bae-8390-46d7-a768-f0c2925beaf6", "_uuid": "3bc2bb076a4f91b22b734c355c82ff5f72f6bd1d"}}, {"execution_count": null, "source": ["g = sns.FacetGrid(df_train, col='Survived')\n", "g.map(plt.hist, 'Age', bins=20)"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "bc85d0d5-2fba-4d5d-901d-99d6f7061a68", "_uuid": "a51b133c49330a041b400342de44906af54377f6"}}, {"source": ["### Survival by Port of Embarcation and Gender\n", "Plot the survival rate by segmented by port of embarkation and gender.<br>\n", "Again we see a strong survival rate for females in all ports, but the ratio bewteen ports and gender varies:\n", "- In order of survival:\n", "    - Females survived most when embarked on Port C, then Port Q and least on Port S\n", "    - Males survived most when embarked on Port C, then Port S and least on Port Q"], "cell_type": "markdown", "metadata": {"_cell_guid": "bbe28655-5586-47fd-99b4-a84898bd8cde", "_uuid": "2187c6534e9636e788c9d97c13349db42bc11e70"}}, {"execution_count": null, "source": ["df_embarked_gender = df_train.groupby(['Embarked','Sex'], as_index=False).agg({'Survived':'mean'})\n", "sns.barplot(x='Embarked', y='Survived', hue='Sex', data=df_embarked_gender)\n", "plt.xlabel(s='Embarked',fontsize=16)\n", "plt.ylabel(s='Survival Rate',fontsize=16)\n", "plt.title('Survival Rate by Embarked port and Gender', fontsize=18)"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "bc12174e-32e7-4ef6-810e-e415de14d2c5", "_uuid": "5d49db0e1c0cb21491291c36fcf9ce2e655c7ff2"}}, {"source": ["# Data Munging\n"], "cell_type": "markdown", "metadata": {"_cell_guid": "fff8e84d-459b-41fa-8875-148635cc00b9", "_uuid": "701e85938af171d3dd20507ac45ea140a0ec5ed6"}}, {"source": ["## Cleaning and imputing values\n", "- Since the Cabin column has so many duplicates, and missing values, we are going to drop this column from both datasets\n", "- Ticket has values on all rows, but contains many duplicates"], "cell_type": "markdown", "metadata": {"_cell_guid": "f6e22e28-1eee-4d87-8bfb-53fb5aa70623", "_uuid": "4f483b032543c446518493cc4191c98f57960820"}}, {"execution_count": null, "source": ["# Drop columns Cabin and Ticket on both datasets\n", "df_train = df_train.drop(['Cabin','Ticket'], axis=1)\n", "df_test = df_test.drop(['Cabin','Ticket'], axis=1)\n", "\n", "combine = [df_train, df_test]"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "e9291425-c3e6-4826-a8f4-2feda7581b94", "_uuid": "1555f64ad32b9588d3c25ad4e7c5fba8d4d19ed4", "collapsed": true}}, {"source": ["### Impute Age Values\n", "Using the Sex, Embarked and Pclass , we wil ltry to impute the age using the mean of each category"], "cell_type": "markdown", "metadata": {"_cell_guid": "6e36888e-f4c3-48e8-a4e2-ce61d9089465", "_uuid": "827ca1d843913480be35707f7533c270853a5648"}}, {"execution_count": null, "source": ["for dataset in combine: # For each Dataset\n", "    for gender in dataset['Sex'].unique(): # For each gender\n", "        for embarked in dataset.loc[~dataset['Embarked'].isnull(),'Embarked'].unique(): # For each port\n", "            for pclass in dataset.loc[~dataset['Pclass'].isnull(),'Pclass'].unique(): # For each class\n", "                \n", "                # Get a Dataframe with not null values to guess the age (using dropna)\n", "                guess_df = dataset.loc[(dataset['Sex'] == gender) & (dataset['Embarked'] == embarked) & (dataset['Pclass'] == pclass),'Age'].dropna()\n", "                \n", "                # Get the mean\n", "                guessed_age = guess_df.mean()\n", "                \n", "                # Set it to the dataset\n", "                dataset.loc[(dataset['Age'].isnull()) & (dataset['Sex'] == gender) & (dataset['Embarked'] == embarked) & (dataset['Pclass'] == pclass),'Age'] = guessed_age"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "bfbf5830-e506-44a6-b752-3225bb9cfdd7", "_uuid": "dbd8adf9ef5de2885bbfc762549431b26f792b48", "collapsed": true}}, {"source": ["### Impute Fare null values\n", "- Fare null values will be imputed using the Median of Port, PClass and Age band<br>\n"], "cell_type": "markdown", "metadata": {"_cell_guid": "f29540ab-a52c-470a-9c42-d265fea89063", "_uuid": "3e68eef9c76da766dd25fc1221df3ddef5e48672"}}, {"execution_count": null, "source": ["for dataset in combine: # For each Dataset\n", "    for gender in dataset['Sex'].unique(): # For each gender\n", "        for embarked in dataset.loc[~dataset['Embarked'].isnull(),'Embarked'].unique(): # For each port\n", "            for pclass in dataset.loc[~dataset['Pclass'].isnull(),'Pclass'].unique(): # For each class\n", "                for age in dataset.loc[~dataset['Age'].isnull(),'Age'].unique(): # For each age\n", "                    \n", "                    # Get a Dataframe with not null values to guess the fare (using dropna)\n", "                    guess_df = dataset.loc[(dataset['Sex'] == gender) & (dataset['Embarked'] == embarked) & (dataset['Pclass'] == pclass) & (dataset['Age'] == age),'Fare'].dropna()\n", "                \n", "                    # Get the median\n", "                    guessed_fare = guess_df.median()\n", "                    \n", "                    # Set it to the dataset\n", "                    dataset.loc[(dataset['Fare'].isnull()) & (dataset['Sex'] == gender) & (dataset['Embarked'] == embarked) & (dataset['Pclass'] == pclass) & (dataset['Age'] == age),'Fare'] = guessed_fare\n", "\n", "\n", "\n", "# Assign the median of the entire dataset for the rows we couldn't guess the fare\n", "fare_median = df_train.loc[~df_train['Fare'].isnull(), 'Fare'].median()\n", "\n", "df_train.loc[df_train['Fare'].isnull(), 'Fare'] = fare_median\n", "df_test.loc[df_test['Fare'].isnull(), 'Fare'] = fare_median\n", "\n", "combine = [df_train, df_test]"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "3a90c58f-4f3a-404d-9132-5eaa2b5f5c6f", "_uuid": "d13e8f06c319b01da42c920eb98055af7a73e21a", "collapsed": true}}, {"source": ["### Impute Embarked null values\n", "- Embarked null values will be imputed using the Median of Sex, Fare Category, PClass and Age band"], "cell_type": "markdown", "metadata": {"_cell_guid": "f67d945d-3948-428e-8b4e-0bd88e2a213e", "_uuid": "b91b3d299a1b2356cd6fa26b186d3d918848c294"}}, {"execution_count": null, "source": ["def impute_embarked(use_fare=True):\n", "    for dataset in combine: # For each Dataset\n", "        # Should use fare to impute Embark port?\n", "        if(use_fare):\n", "            for gender in dataset['Sex'].unique(): # For each gender\n", "                for fare in dataset.loc[~dataset['Fare'].isnull(),'Fare'].unique(): # For each fare\n", "                    for pclass in dataset.loc[~dataset['Pclass'].isnull(),'Pclass'].unique(): # For each class\n", "                        for age in dataset.loc[~dataset['Age'].isnull(),'Age'].unique(): # For each age\n", "                        \n", "                            # Get a Dataframe with not null values to guess the fare (using dropna)\n", "                            guess_df = dataset.loc[(dataset['Sex'] == gender) & (dataset['Fare'] == fare) & (dataset['Pclass'] == pclass) & (dataset['Age'] == age),'Embarked'].dropna()\n", "                        \n", "                            # if the dataframe has values\n", "                            if (len(guess_df) > 0):\n", "                                # Get the mode\n", "                                guessed_port = guess_df.mode()[0]\n", "                            \n", "                                # Set it to the dataset\n", "                                dataset.loc[(dataset['Embarked'].isnull()) & (dataset['Sex'] == gender) & (dataset['Fare'] == fare) & (dataset['Pclass'] == pclass) & (dataset['Age'] == age),'Embarked'] = guessed_port\n", "        # Dont use fare to impute Embarked port\n", "        else:\n", "            for gender in dataset['Sex'].unique(): # For each gender\n", "                for pclass in dataset.loc[~dataset['Pclass'].isnull(),'Pclass'].unique(): # For each class\n", "                    for age in dataset.loc[~dataset['Age'].isnull(),'Age'].unique(): # For each age\n", "                        \n", "                        # Get a Dataframe with not null values to guess the fare (using dropna)\n", "                        guess_df = dataset.loc[(dataset['Sex'] == gender) & (dataset['Pclass'] == pclass) & (dataset['Age'] == age),'Embarked'].dropna()\n", "                    \n", "                        # if the dataframe has values\n", "                        if (len(guess_df) > 0):\n", "                            # Get the mode\n", "                            guessed_port = guess_df.mode()[0]\n", "                        \n", "                            # Set it to the dataset\n", "                            dataset.loc[(dataset['Embarked'].isnull()) & (dataset['Sex'] == gender) & (dataset['Pclass'] == pclass) & (dataset['Age'] == age),'Embarked'] = guessed_port\n", "                            \n", "impute_embarked(use_fare=False)\n", "\n", "# Get the most frequent Port from all data for the ones that we couldn't find.\n", "freq_port = df_train.loc[~df_train['Embarked'].isnull(),'Embarked'].mode()[0]\n", "# Set the most frequent port to the null values\n", "df_train.loc[df_train['Embarked'].isnull(),'Embarked'] = freq_port\n", "df_test.loc[df_test['Embarked'].isnull(),'Embarked'] = freq_port\n", "\n", "combine = [df_train, df_test]"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "3cb673a8-57a7-4562-998e-c2a2244dc69d", "_uuid": "f7c4be47f23dd83f737c6667d6e37a80d3bc7d64", "collapsed": true}}, {"source": ["## Convert Categorical Values\n", "- We are going to convert the categorical values into dummies\n"], "cell_type": "markdown", "metadata": {"_cell_guid": "d9b5d89d-df39-49bd-88c8-d31d6b37198c", "_uuid": "f183652473f2634a7c625a88541f100eabbe2a44"}}, {"source": ["### Gender to Dummies"], "cell_type": "markdown", "metadata": {"_cell_guid": "c69a8924-8404-4d4e-9c13-70e4fd6c2939", "_uuid": "1493fab9d2e7c677e33095d209dd2e9f5f694e5f"}}, {"execution_count": null, "source": ["# Get Dummies for Sex Column\n", "df_sex_dummies = pd.get_dummies(df_train['Sex'], prefix='sex_', drop_first=True)\n", "df_train = pd.concat([df_train, df_sex_dummies], axis=1)   \n", "df_train = df_train.drop('Sex', axis=1)\n", "\n", "df_sex_dummies = pd.get_dummies(df_test['Sex'], prefix='sex_', drop_first=True)\n", "df_test = pd.concat([df_test, df_sex_dummies], axis=1)   \n", "df_test = df_test.drop('Sex', axis=1)"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "3820d7ab-d45a-464e-8407-a9f8eeb29cb0", "_uuid": "353dff1aa123e6f4151deef611d4d728c2a54a1d"}}, {"source": ["## Dummies for Port of Embark"], "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "source": ["# Get Dummies for Sex Column\n", "df_sex_dummies = pd.get_dummies(df_train['Embarked'], prefix='embarked_', drop_first=True)\n", "df_train = pd.concat([df_train, df_sex_dummies], axis=1)   \n", "df_train = df_train.drop('Embarked', axis=1)\n", "\n", "df_sex_dummies = pd.get_dummies(df_test['Embarked'], prefix='embarked_', drop_first=True)\n", "df_test = pd.concat([df_test, df_sex_dummies], axis=1)   \n", "df_test = df_test.drop('Embarked', axis=1)"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "f88d7f21-3c79-4cc3-9066-1a37bbfbb0ca", "_uuid": "63ffcb80ac12f0ac6d0c4a1aece128883bb8301d", "collapsed": true}}, {"source": ["## Dummie for Pclass"], "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "source": ["# Get Dummies for Sex Column\n", "df_sex_dummies = pd.get_dummies(df_train['Pclass'], prefix='pclass_', drop_first=True)\n", "df_train = pd.concat([df_train, df_sex_dummies], axis=1)   \n", "df_train = df_train.drop('Pclass', axis=1)\n", "\n", "df_sex_dummies = pd.get_dummies(df_test['Pclass'], prefix='pclass_', drop_first=True)\n", "df_test = pd.concat([df_test, df_sex_dummies], axis=1)   \n", "df_test = df_test.drop('Pclass', axis=1)"], "outputs": [], "cell_type": "code", "metadata": {"collapsed": true}}, {"source": ["## Creating Title Feature (not!)\n", "On the [Titanic Data Science Solutions Notebook](https://www.kaggle.com/startupsci/titanic-data-science-solutions) by [Manav Sehgal](https://www.kaggle.com/startupsci) he wrote a routine to get the Title from the passengers name, and created a new feature. <br>\n", "My main analysis for NOT doing this, is that makes the data more complex and it doesn't really add much value, since Title is heavily tied to Sex, so we skip this proposed step.\n", "![](http://)** Taking this into account we can safely drop the Name Column**"], "cell_type": "markdown", "metadata": {"_cell_guid": "a3d43696-a033-4da2-b0f9-618311f15fef", "_uuid": "9060e38d87ae448c76461a2006db13667dd6ef87"}}, {"execution_count": null, "source": ["# Drop the Name column on both datasets\n", "df_train = df_train.drop(['Name'], axis=1)\n", "df_test = df_test.drop(['Name'], axis=1)\n", "\n", "combine = [df_train, df_test]"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "025fef23-81aa-4816-8794-ed58027a535c", "_uuid": "d37eb0c59e0f5cf7002cf86c98916e5ad9690d9d", "collapsed": true}}, {"source": ["## Creating family related features\n", "Based on the Manav Seghal notebook, we also create a feature called Familysize, which combines Parch and SibSp features.\n", "[](http://) <br>\n", "Also, we create the IsAlone Feature semented by Gender wich indicates if the passenger had family with a boolean instead of the number of family members and the gender, since the chances of survivng being Alone are different for males and females. <br>\n", "A correlation heatmap can show a small correlation between these values (0.43 and 0.34)."], "cell_type": "markdown", "metadata": {"_cell_guid": "8679f892-2b8a-4872-aeb0-3634cc2079dc", "_uuid": "a18c8cda193a1288324dbed6b891431888b7eb07"}}, {"execution_count": null, "source": ["for dataset in combine:\n", "    # Family Size Feature\n", "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n", "\n", "    # Is alone Feature\n", "    dataset['IsAlone'] = 0\n", "    dataset.loc[(dataset['FamilySize'] == 1), 'IsAlone'] = 1\n", "\n", "\n", "# Display a heatmap to see the correlation between the values.\n", "sns.heatmap(df_train[['FamilySize','Survived','IsAlone']].corr(), annot=True)"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "55f72771-a92e-4cb2-be9a-f86d3e724aae", "_uuid": "4112104aed06ce46d6ed40de7011c1b5896eb8f3"}}, {"source": ["### Drop Family Size Feature\n", "The Family Size feature helped us create the IsAlone feature, but has no actual correlation to the survival chance, so we can drop it."], "cell_type": "markdown", "metadata": {"_cell_guid": "b5f5c7ef-022a-4882-80cc-f6161e003491", "_uuid": "2a5da754106de101690f71a10a5819b5282eecd7"}}, {"execution_count": null, "source": ["df_train = df_train.drop(['FamilySize','SibSp','Parch'], axis=1)\n", "df_test = df_test.drop(['FamilySize','SibSp','Parch'], axis=1)\n", "\n", "combine = [df_train, df_test]"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "91b53767-58c7-4015-aae1-19d9097ad6a9", "_uuid": "3b7cb2564ca578a89fca3331fbc66b5bca13c760", "collapsed": true}}, {"source": ["# Model Prediction"], "cell_type": "markdown", "metadata": {"_cell_guid": "ad04c097-8725-492b-b124-c7b1ff04331d", "_uuid": "d6afc724278e917ed168cc355f1c7c82b488f987"}}, {"execution_count": null, "source": ["# Get the Features without the Label\n", "X_train = df_train.drop(['Survived','PassengerId'], axis=1)\n", "Y_train = df_train['Survived']\n", "\n", "# Get the Test values\n", "X_test = df_test.drop(['PassengerId'], axis=1).copy()"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "1f32e21c-5ca6-4f50-a939-efc7fc247596", "_uuid": "996a40664a29cae93d21192a1d76882ac5d162ea", "collapsed": true}}, {"source": ["## Random Forests\n", "Based on Manav's notebook, the Random Forests is the best option for prediction on this Dataset.\n", "Let's see how well we did.<br>"], "cell_type": "markdown", "metadata": {"_cell_guid": "074124e0-19aa-46e2-be76-96b4f2f4cd6e", "_uuid": "c8b1da703d6fb6f97c50bf73c3c2289c63ac4131"}}, {"execution_count": null, "source": ["from sklearn.ensemble import RandomForestClassifier\n", "\n", "random_forest = RandomForestClassifier(n_estimators=50)\n", "random_forest.fit(X_train, Y_train)\n", "Y_pred = random_forest.predict(X_test)\n", "score = random_forest.score(X_train, Y_train)\n", "\n", "print('Accuracy',score)"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "e9ab86ff-fa01-49cc-a3d4-03f0343b6724", "_uuid": "81a9a64887cff4c1b219414a08fbe2cbb0a81868"}}, {"execution_count": null, "source": ["submission = pd.DataFrame(\n", "    {\n", "        'PassengerId': df_test['PassengerId'],\n", "        'Survived': Y_pred\n", "    })\n", "\n", "#submission.to_csv('../input/my_submission.csv', index=False)\n", "submission\n"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "b1a88538-68cf-40f6-bc69-5946f9f0a7fa", "_uuid": "de51e34c641bf1c636ccae2bb9fb55d9446f5a68"}}, {"execution_count": null, "source": ["\n"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "5a505118-4fa3-48e2-967a-dc5c3c1cb4bd", "_uuid": "8d67254da4e3f829c64681bd59a6fc485470746e", "collapsed": true}}], "metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "mimetype": "text/x-python", "name": "python", "file_extension": ".py", "nbconvert_exporter": "python", "version": "3.6.1"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "nbformat_minor": 1, "nbformat": 4}