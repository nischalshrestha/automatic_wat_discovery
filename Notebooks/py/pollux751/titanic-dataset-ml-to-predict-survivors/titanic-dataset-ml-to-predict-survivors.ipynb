{"cells": [{"source": ["# Introduction\n", "This notebook serves two purposes: To help me hone my skills as an amateur data scientist, and to help beginners learn the basics of building an accurate machine learning model.  \n", "\n", "As I understand it, there is a process to building an accurate machine learning model:\n", ">1. Exploratory data analysis\n", "2. Cleaning/Parsing Data\n", "3. Building the algorithm/Evaluation\n", "\n", "I hope that others comment and suggest ways for me to improve on my skills, and I will post what I have updated. \n", "\n"], "metadata": {"_uuid": "4afb7640b07c8338092611148eb9449c2a65d6e4", "_cell_guid": "4b252363-7459-49d5-9610-c6c023a40c3a"}, "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_uuid": "7f2ffbffe45b42965ecc3a7e22ebde96756c9b5e", "_cell_guid": "0f6eb3d3-890e-4fe4-a0ca-66c6e6aa6db1"}, "outputs": [], "cell_type": "code", "source": ["# Import necessary libraries and data files\n", "import numpy as np \n", "import pandas as pd \n", "\n", "training_df = pd.read_csv(r\"../input/train.csv\")\n", "testing_df = pd.read_csv(r\"../input/test.csv\")"]}, {"source": ["# Exploratory Data Analysis (EDA)\n", "Exploratory data analysis is very important since getting familiar with the data leads to seeing what steps you need to take to\n", "clean up the data. Also this helps decide on what algorithms to use.\n", "\n", "I used to treat machine learning like a black box. I would just plug in data into my algorithm of choice and wonder why my algorithm score wouldn't improve. Exploratory data analysis is a must since you can't expect good results if you can't understand the inputs."], "metadata": {"_uuid": "c53ef4a3dce7c8cfe5c6a284e095b95f26f59c09", "_cell_guid": "264a322f-7a93-4c30-8dae-0cb61d1734c1"}, "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_uuid": "5c2cb5f42d86023bd807a0108af7d63e12d3da34", "_cell_guid": "a8496790-47da-490b-882d-6ad47e282257"}, "outputs": [], "cell_type": "code", "source": ["# Get some desciptive information on the data\n", "training_df.info() # Noticed so many nulls in the age and cabin fields"]}, {"execution_count": null, "metadata": {"_uuid": "cf08361ee8dbc6bd8a74444f4cb6f9a838c7b0d5", "_cell_guid": "b9f80c81-a4e0-49b2-8a6f-0ada2af41fb6"}, "outputs": [], "cell_type": "code", "source": ["#Descriptive statistics on the data set\n", "training_df.describe()"]}, {"execution_count": null, "metadata": {"_uuid": "f2a9bfe57a0381f0eaa32a68f86c1fce3a5dcd45", "_cell_guid": "6369a374-5761-4bd2-826b-64a0647748cd"}, "outputs": [], "cell_type": "code", "source": ["# To see what the data set looks like\n", "training_df.head() # Name, ticket, and cabin do not seem to be very useful fields"]}, {"execution_count": null, "metadata": {"_uuid": "49bc720ea73fdf68e6a2cc414ac27ab18e6f3c81", "_cell_guid": "e76ca0dc-d82f-4439-b9b3-6bca1e8d8e90"}, "outputs": [], "cell_type": "code", "source": ["# Univariate/Bivariate data analysis\n", "import seaborn as sns\n", "from matplotlib import pyplot\n", "sns.set_style(\"ticks\")\n", "\n", "# Investigating Survival by Gender\n", "sns.factorplot(data=training_df, x=\"Sex\", \n", "                   col=\"Survived\", kind=\"count\", \n", "                   size=5, palette=\"deep\")"]}, {"execution_count": null, "metadata": {"_uuid": "dc9d8f927833071e1b87d095f9ad3a7d5eb89223", "_cell_guid": "72f4852b-f645-4c74-90ae-c4aaf2a3d77a"}, "outputs": [], "cell_type": "code", "source": ["# Comparing survival among pclass\n", "sns.factorplot(data=training_df, x=\"Pclass\", \n", "                   col=\"Survived\", kind=\"count\", \n", "                   size=5, palette=\"deep\")"]}, {"execution_count": null, "metadata": {"_uuid": "1c02a6c34f18b0da57e81a988c7d231adc53697c", "_cell_guid": "f2e61e73-14dd-438c-888c-641a6da3f0b8"}, "outputs": [], "cell_type": "code", "source": ["# Survival among embarkment\n", "sns.factorplot(data=training_df, x=\"Embarked\", \n", "                   col=\"Survived\", kind=\"count\", \n", "                   size=5, palette=\"deep\")"]}, {"execution_count": null, "metadata": {"_uuid": "efc49c62cb4aef88eed5efb3fcadc42f7cd9cb7a", "_cell_guid": "ff19eaef-74a3-4f4e-950c-b423a5a56fd3"}, "outputs": [], "cell_type": "code", "source": ["# Survival with age\n", "sns.factorplot(data=training_df, x=\"Survived\", y=\"Age\",\n", "              kind=\"box\", size=5)"]}, {"execution_count": null, "metadata": {"_uuid": "7484c5bdc5712874b353237bfaf51a352c6d3e83", "_cell_guid": "a917d715-45f9-4f16-8bb1-85a3753afbeb"}, "outputs": [], "cell_type": "code", "source": ["# Sibling/Spouse\n", "sns.factorplot(data=training_df, x=\"Survived\", y=\"SibSp\",\n", "              kind=\"box\", size=5)"]}, {"execution_count": null, "metadata": {"_uuid": "9a3c1cc1466cfa8c7d2030170807372daf84c7b3", "_cell_guid": "adefcb01-d3fe-400c-8fce-cf2d0e65e2fe"}, "outputs": [], "cell_type": "code", "source": ["# Parent/child\n", "sns.factorplot(data=training_df, x=\"Survived\", y=\"Parch\",\n", "              kind=\"box\", size=5)"]}, {"execution_count": null, "metadata": {"_uuid": "6bd96457a5dc613420892c8edbf84e4fe513cb73", "_cell_guid": "dbbc5cc3-5330-43f1-8f7a-9ec21b442f3f"}, "outputs": [], "cell_type": "code", "source": ["# Fare\n", "sns.factorplot(data=training_df, x=\"Survived\", y=\"Fare\",\n", "              kind=\"box\", size=5)"]}, {"source": ["# Data Parsing/Cleaning <a name=\"parsing\"></a>\n", "* Dropping useless columns\n", "* Filling in NaN values with the most occuring value\n", "* Make new columns for categorical data (One hot encoding)"], "metadata": {"collapsed": true, "_uuid": "d11dece19f371740ad32a04268665738cdcc4607", "_cell_guid": "8afe9258-304c-4918-8a2e-9333548e54dc"}, "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_uuid": "1ad3d6012770f1591dc19f56cdba22b64ec31209", "_cell_guid": "f6c6ff22-f50b-479b-95e1-e80f659965b4"}, "outputs": [], "cell_type": "code", "source": ["# Must drop useless columns \n", "def drop_useless_cols(df):\n", "    return df.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1)\n", "\n", "training_df = drop_useless_cols(training_df)\n", "testing_df = drop_useless_cols(testing_df)\n", "\n", "training_df.head()"]}, {"source": ["## Engineered Features\n", "\n", "I believe that having any family on board could affect survival rate on the titanic. I wish there were a way to separate the children count from the parent count, since I feel that the more siblings you have, the less likely your are to survive. \n", "\n", "Maybe having any kind of family on board would contribute to a higher chance of survival, so I created a family feature, which consists of the parch feature plus the sibsp feature."], "metadata": {"_uuid": "a4b14652b443fc0728f61dfd343b223156e1259d", "_cell_guid": "bf90ef64-66d8-4bdd-b624-980aaef920a6"}, "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_uuid": "354de1cfd254c058351c0fc10e782bc7bb2f23e3", "_cell_guid": "e63283bb-3464-4089-8ab3-af30f9010aab"}, "outputs": [], "cell_type": "code", "source": ["# def family_feature(df):\n", "#     df[\"Family\"] = df[\"Parch\"] - df[\"SibSp\"]\n", "#     return df.drop([\"Parch\",\"SibSp\"], axis=1)\n", "\n", "# training_df = family_feature(training_df)\n", "# testing_df = family_feature(testing_df)"]}, {"execution_count": null, "metadata": {"_uuid": "104e0838e2e4bdb7167d773318a3eb0e5af7fa01", "_cell_guid": "f038e6a0-154e-4597-b4b5-02abe3ee5c5c"}, "outputs": [], "cell_type": "code", "source": ["training_df.head()"]}, {"source": ["## Create dummy columns for the Pclass variable"], "metadata": {"_uuid": "c98bcc60e6b52feda99fbbda90224c55dd9e65d2", "_cell_guid": "86c884ae-a322-474a-b891-9398143337da"}, "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_uuid": "9f1f71524e875fa662b1e59620992286b33907f0", "_cell_guid": "d9aab045-795d-482a-b791-e4b9b92bd7f8"}, "outputs": [], "cell_type": "code", "source": ["# Create new columns for the Pclass categories\n", "# Pclass is categorical data and should have separate columns\n", "\n", "def create_pclass_cols(df):\n", "    # Creates new column for each pclass\n", "    df[\"pclass_1\"] = df[\"Pclass\"].apply(lambda x : 1 if x == 1 else 0) \n", "    df[\"pclass_2\"] = df[\"Pclass\"].apply(lambda x : 1 if x == 1 else 0)\n", "    df[\"pclass_3\"] = df[\"Pclass\"].apply(lambda x : 1 if x == 1 else 0)\n", "    \n", "    return df.drop(\"Pclass\", axis=1)\n", "\n", "training_df = create_pclass_cols(training_df)\n", "testing_df = create_pclass_cols(testing_df)\n", "\n", "training_df.head()"]}, {"source": ["## One Hot Encoding\n", "There are two NaNs in the Embarked column that must be filled before getting the dummy variables"], "metadata": {"_uuid": "744bbee331ab356d633d0a24b2573b8098e8f9da", "_cell_guid": "a4937099-8df4-4730-87e6-9a068a03b9f8"}, "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_uuid": "a1b5cddea8b7427f146e2cca3c940e023081a455", "_cell_guid": "6abfc1cb-7359-476e-bed2-9d53a58e0f09"}, "outputs": [], "cell_type": "code", "source": ["training_df[\"Embarked\"].unique()"]}, {"execution_count": null, "metadata": {"_uuid": "1741f69643e379fb79d466bb116b34a6147b6832", "_cell_guid": "3b0dc661-227e-4d1a-9be5-310b81360c6e"}, "outputs": [], "cell_type": "code", "source": ["training_df[\"Embarked\"].mode()[0]"]}, {"execution_count": null, "metadata": {"collapsed": true, "_uuid": "309c9691fa6da6dba856e3b5ebdb3e06d11ce6a2", "_cell_guid": "dc0230ed-cca7-4418-9e4a-f46ed9437d9f"}, "outputs": [], "cell_type": "code", "source": ["def one_hot_encoding(df):\n", "    #Fill the embarked column with most occuring value\n", "    #since imputer doesnt work well with categorical data\n", "    fill_value = df[\"Embarked\"].mode()[0]\n", "    df[\"Embarked\"].fillna(fill_value, inplace=True)\n", "    \n", "    return pd.get_dummies(df)\n", "\n", "training_df = one_hot_encoding(training_df)\n", "testing_df = one_hot_encoding(testing_df)"]}, {"execution_count": null, "metadata": {"_uuid": "b05a435494413aaf9d549a0fd8f9febb56b9b7d3", "_cell_guid": "397f8c29-a1b9-47ea-9d22-ec1a157fbf59"}, "outputs": [], "cell_type": "code", "source": ["training_df.head()"]}, {"source": [" # Machine Learning\n", " \n", " ## Built with Pipeline\n", " \n", " >### Imputer\n", " In the case of missing values (NaNs) I will fill them in with the most frequent value of that column by using sklearn's Imputer.\n", " \n", " >### Feature Selection\n", " To avoid overfitting on noisy data, I will use SelectPercentile to choose the most useful features\n", " \n", " >### Classifier (Random Forest) \n", "\n", ">Now that all the data is parsed, I will go ahead and make a classifier using a random forest. First I will need to split up the training data set into two parts: training set and testing set"], "metadata": {"_uuid": "e18e9acdbfbb91b90afb1c60c8645e55e2195d68", "_cell_guid": "ab7bc919-898d-4302-86a1-561ad0dbf2e8"}, "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "scrolled": true, "_uuid": "b481d2651763b17e549948c3a47ec29a4fc4d2a5", "_cell_guid": "d9de81a3-2aec-4de2-91d7-ea464bb42e48"}, "outputs": [], "cell_type": "code", "source": ["# Split features from labels\n", "# I also get rid of the PassengerId column since it does not provide any useful data\n", "features = training_df.drop([\"PassengerId\",\"Survived\"], axis=1).values\n", "labels = training_df[\"Survived\"].values\n", "\n", "# Split the dataset in two equal parts\n", "from sklearn.model_selection import train_test_split\n", "X_train, X_test, y_train, y_test = train_test_split(\n", "    features, labels, test_size=0.3, random_state=0)"]}, {"execution_count": null, "metadata": {"scrolled": true, "_uuid": "752944a389a1cb47add8cb362be05caab3dc3385", "_cell_guid": "600b3963-6254-4145-b97f-cd8df10c1357"}, "outputs": [], "cell_type": "code", "source": ["# Import necessary items to set up pipeline\n", "from sklearn.preprocessing import Imputer, MinMaxScaler\n", "from sklearn.feature_selection import SelectPercentile\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.svm import SVC\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.pipeline import Pipeline\n", "\n", "pipeline = Pipeline([(\"imputer\", Imputer(strategy=\"most_frequent\")),\n", "                    (\"selection\", SelectPercentile()),\n", "                    (\"scaler\", MinMaxScaler(feature_range=(-1,1))),\n", "                    #(\"svm\", SVC()),\n", "                    (\"rf\", RandomForestClassifier())\n", "                    ])\n", "\n", "parameters = {\"selection__percentile\":range(10,100,10),\n", "                 \"rf__n_estimators\":range(100,200,20),\n", "                 \"rf__max_features\":[\"sqrt\", \"log2\", \"auto\"]\n", "             }\n", "\n", "# svm_parameters = {\"selection__percentile\":range(10,100,10),\n", "#                   \"svm__C\":[1,10,100,1000,10000],\n", "#                   \"svm__gamma\":[0,0.1,0.001,0.0001,0.000001,\"auto\"]\n", "#              }\n", "\n", "grid = GridSearchCV(pipeline, parameters, cv=5)\n", "\n", "grid.fit(X_train,y_train)\n", "\n", "print(\"The best params are %s with a score of %0.2f\"\n", "      % (grid.best_params_, grid.best_score_))"]}, {"execution_count": null, "metadata": {"_uuid": "415cd2a72900801110bdf76589b1ddc0c56d663d", "_cell_guid": "1af651da-d706-46f4-8e86-fe6327efa347"}, "outputs": [], "cell_type": "code", "source": ["# Validate the score on the test set\n", "grid.score(X_test, y_test)"]}, {"source": ["# Create Predictions and Upload Submission"], "metadata": {"collapsed": true, "_uuid": "040c25330660dcb462e5c0c8f189577836487a23", "_cell_guid": "f1a01b87-30b4-4f98-9754-63e663ac94a7"}, "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "scrolled": true, "_uuid": "a118032f18286f977b021bb5514caf1b62b04c0a", "_cell_guid": "0d52f69f-eb56-4162-a2c1-2622f2ba032f"}, "outputs": [], "cell_type": "code", "source": ["predictions = grid.predict(testing_df.drop(['PassengerId'], axis=1))\n", "\n", "submission = pd.DataFrame({\n", "        \"PassengerId\": testing_df[\"PassengerId\"],\n", "        \"Survived\": predictions\n", "    })\n", "\n", "submission.to_csv('prediction_submission.csv', index=False)"]}, {"execution_count": null, "metadata": {"_uuid": "d51067c1c5087879cbbc4a8e94c079b0c3fcadaf", "_cell_guid": "9df39559-441c-4cf5-bb72-4afac0764ec9"}, "outputs": [], "cell_type": "code", "source": ["submission.head()"]}], "nbformat_minor": 1, "metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "name": "python", "version": "3.6.3", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "nbconvert_exporter": "python"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "nbformat": 4}