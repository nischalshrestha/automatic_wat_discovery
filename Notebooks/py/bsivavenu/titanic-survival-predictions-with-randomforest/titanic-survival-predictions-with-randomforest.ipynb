{"nbformat": 4, "cells": [{"metadata": {"_uuid": "0f1652c48a8b78f5db024e4db8a8d1178b1acd30", "_cell_guid": "eefd75f2-54cf-439f-bbce-93607df309be"}, "source": ["**Please upvote ** your upvotes encourages me to do more."], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "47a6423365ecf7211184d9497eea4b58652db60e", "_cell_guid": "dd28ae4d-fa6e-4df8-a886-e09933e91925"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: htatps://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "358c3397606ab897dc5b6b26a45329ed4a7829a9", "collapsed": true, "_cell_guid": "d7e5e94f-9dce-41eb-af17-b34d53161ae6"}, "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "%matplotlib inline"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "f6c0178c478f6545e7d1b528e05575ec3f0ea682", "_cell_guid": "87d8e2c4-e1de-4015-b685-0e769a44a408"}, "source": ["data_train = pd.read_csv('../input/train.csv')\n", "data_test = pd.read_csv('../input/test.csv')\n", "\n", "data_train.sample(3)#randomly taking 3 values"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "36b0d188c5f73a205c59ad469eef5a12cc08480c", "_cell_guid": "87f99882-939d-48e6-89cd-4a2574cfcc45"}, "source": ["data_test.head(3)"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "769664f90ac7464e1c90b16a22b9a2dfb2d62cf9", "_cell_guid": "45b1a2b5-e896-41f1-8752-f8ff0c315714"}, "source": ["data_train.describe()"], "cell_type": "code"}, {"metadata": {}, "source": ["### describe illustrates the numerical values and their distribution in any dataset. Now we'll see how they are distributed in this train dataset.\n", "- from the above we can say mean  age is 29 and max age is 80\n", "- sibsp is siblingsspouse and the max value is 8\n", "- parch is parent parent children and the max value is 6\n", "- Fare is the ticket price and the max value is $512 and average value is $32."], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "039b23ac198525948bae9f612a311870796ace3c", "_cell_guid": "ad851f84-815f-42a8-a86d-cc4299039a1b"}, "source": ["data_train.shape,data_test.shape"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {}, "source": ["data_train.isnull().sum().sort_values(ascending=False)"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "333558f9b391b5e0f326077f6df2bd3173c57b4e", "_cell_guid": "16041fba-a4d2-4218-a1ef-ea2210d08eed"}, "source": ["#we have to find the null cols\n", "null_cols = data_train.columns[data_train.isnull().any()]\n", "null_cols\n"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "c6574743eefcad99f170c34868172818b15d0e8c", "_cell_guid": "3b9e4720-1b3a-42b4-a666-11fce569c5a2"}, "source": ["a = data_train.isnull().sum()\n", "a[a>0]"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "2f232a987619f80e140db9b67bc1d43ad7c00f8f", "_cell_guid": "5544f04a-bc1e-4d5a-966b-5cb2a31d962c"}, "source": ["b = data_test.isnull().sum()\n", "b[b>0]"], "cell_type": "code"}, {"metadata": {"_uuid": "67c23662c1b75d4fbd49f790d8574a9d605f7c22", "_cell_guid": "fd57a1b8-bc1f-4800-88ff-72ad57cf9cb9"}, "source": ["**Visualization**"], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "a7483e240041aeb4ca90a3707f7806ddbe5fca5f", "_cell_guid": "cfee171d-59c7-45f1-905a-4193b3af7342"}, "source": ["import seaborn as sns\n", "g = sns.FacetGrid(data_train,col = 'Sex',row = 'Survived')\n", "g.map(plt.hist,'Age')"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "9a88e0ff40748f1ae80bd3acfc641dc077ebc6d2", "_cell_guid": "33ad2905-85c2-45c8-a1ae-1af750d8fd07"}, "source": ["sns.boxplot(x= 'Sex',y = 'Age',hue  = 'Survived',data = data_train)"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "0c357e54272535cf76afb4360868cad870e7002c", "_cell_guid": "d997677e-46cd-468a-a9f4-69c164904b6f"}, "source": ["sns.boxplot(x = 'Pclass',y = 'Age',hue = 'Survived',data = data_train)"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "6fac52e4c8911a558fbfb2002eb86e6e185930c3", "_cell_guid": "794a812d-413b-4f59-8eee-a0a3439f8c63"}, "source": ["g = sns.FacetGrid(data_train,'Survived',col = 'Pclass',margin_titles=True,palette={1:\"green\",0:\"red\"})\n", "g = g.map(plt.scatter,'Fare','Age').add_legend();"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "7aeb79f1b1ca389e83f4bae25c54276441a7957f", "_cell_guid": "ab399eb4-0243-44a8-8001-dffc1da229c6"}, "source": ["data_train.Embarked.value_counts().plot(kind = 'bar')\n", "plt.title('passengers/boarding location')\n", "plt.xticks(rotation=0)"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "b8a163960e834ecbab0b82d1a646ff6e73530549", "_cell_guid": "6774bb0c-7a7c-4db4-a143-60aaa9e5b0fc"}, "source": ["sns.barplot('Embarked','Pclass',hue = 'Survived',data = data_train)"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "fb9e30aa43da40d6596da98ea165219de9f432db", "_cell_guid": "92fc18cb-5386-48e5-9ad2-681fca963f5d"}, "source": ["sns.barplot(y = 'Pclass',x = 'Sex',data = data_train)"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "0a9d133b256f7cedddbd0100bdbf92150820aece", "_cell_guid": "f2264723-08f2-4ae6-9d60-29a17f285433"}, "source": ["sns.boxplot('Pclass','Age',data = data_train,hue = 'Sex')"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "7edb4b829acf83bfdbc4945879fe02ca6649d3e0", "_cell_guid": "fcb33e7b-ce7a-4bb0-9278-baab2dfd81eb"}, "source": ["data_train.Age[data_train.Pclass == 1].plot(kind='kde')    \n", "data_train.Age[data_train.Pclass == 2].plot(kind='kde')\n", "data_train.Age[data_train.Pclass == 3].plot(kind='kde')\n", " # plots an axis lable\n", "plt.xlabel(\"Age\")    \n", "plt.title(\"Age Distribution within classes\")\n", "# sets our legend for our graph.\n", "plt.legend(('1st Class', '2nd Class','3rd Class'),loc='best') ;"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "e05633b9ee16ff1c22e983d3e6d7e51836864899", "_cell_guid": "2022c6f8-a567-461f-b88e-97e13315b2f8"}, "source": ["plt.figure(figsize=(10,10))\n", "sns.heatmap(data_train.corr(),square=True,annot=True,linewidths=.01,linecolor='white',vmax=.8)"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "ad2ec497b4edf40eb61cfe4b1030d99d0e426183", "_cell_guid": "8032d997-4a5c-4085-940f-2560fbf1acf5"}, "source": ["data_train.corr()['Survived']"], "cell_type": "code"}, {"metadata": {}, "source": ["Now we'll see how each feature is correalted/distributed in dataset."], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "bd0e829b2038a563aa99544c08a08f992e710bcb", "_cell_guid": "c384b4e4-0fbc-4b06-b562-686ba1f81d4e"}, "source": ["surv_col = 'green'\n", "nosurv_col = 'red'\n", "cols = ['Survived','Pclass','Age','SibSp','Parch','Fare']\n", "g = sns.pairplot(data = data_train.dropna(),hue = 'Survived', vars = cols,palette= [nosurv_col,surv_col],size=3)\n", "g.set(xticklabels=[])\n"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "b4a9abed7e48052bcbfecb6f4fe4f7c0abede707", "_cell_guid": "9987ce9d-2c0a-45dd-9bad-6b82e7bec6fc"}, "source": ["plt.figure(figsize=(8,8))\n", "sns.violinplot('Embarked','Age',hue = 'Survived',data = data_train,split = True,dodge=True)"], "cell_type": "code"}, {"metadata": {"_uuid": "2822fad1f533d2e16eee57e30d0c1f05920d222d", "_cell_guid": "84dca092-9111-48fa-9a43-6f275197f369"}, "source": ["## Transforming Features\n", "\n", "1. Aside from 'Sex', the 'Age' feature is second in importance. To avoid overfitting, I'm grouping people into logical human age groups. \n", "2. Each Cabin starts with a letter. I bet this letter is much more important than the number that follows, let's slice it off. \n", "3. Fare is another continuous value that should be simplified. I ran `data_train.Fare.describe()` to get the distribution of the feature, then placed them into quartile bins accordingly. \n", "4. Extract information from the 'Name' feature. Rather than use the full name, I extracted the last name and name prefix (Mr. Mrs. Etc.), then appended them as their own features. \n", "5. Lastly, drop useless features. (Ticket and Name)"], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "0841eed154f477247d3f2eac62b13429861d9ff0", "_cell_guid": "6a0093ac-b38a-4ee1-a476-add7f461e486"}, "source": ["def simplify_ages(df):\n", "    df.Age = df.Age.fillna(-0.5)\n", "    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n", "    group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n", "    categories = pd.cut(df.Age, bins, labels=group_names)\n", "    df.Age = categories\n", "    return df\n", "\n", "def simplify_cabins(df):\n", "    df.Cabin = df.Cabin.fillna('N')\n", "    df.Cabin = df.Cabin.apply(lambda x: x[0])\n", "    return df\n", "\n", "def simplify_fares(df):\n", "    df.Fare = df.Fare.fillna(-0.5)\n", "    bins = (-1, 0, 8, 15, 31, 1000)\n", "    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n", "    categories = pd.cut(df.Fare, bins, labels=group_names)\n", "    df.Fare = categories\n", "    return df\n", "\n", "def format_name(df):\n", "    df['Lname'] = df.Name.apply(lambda x: x.split(' ')[0])\n", "    df['NamePrefix'] = df.Name.apply(lambda x: x.split(' ')[1])\n", "    return df    \n", "    \n", "def drop_features(df):\n", "    return df.drop(['Ticket', 'Name', 'Embarked'], axis=1)\n", "\n", "def transform_features(df):\n", "    df = simplify_ages(df)\n", "    df = simplify_cabins(df)\n", "    df = simplify_fares(df)\n", "    df = format_name(df)\n", "    df = drop_features(df)\n", "    return df\n", "\n", "data_train = transform_features(data_train)\n", "data_test = transform_features(data_test)\n", "data_train.head()"], "cell_type": "code"}, {"metadata": {"_uuid": "c182820fb7c5c3d98665763de6699249c570fb44", "_cell_guid": "296bd631-6d22-406a-af92-0c4dee7e1090"}, "source": ["## Some Final Encoding\n", "\n", "The last part of the preprocessing phase is to normalize labels. The LabelEncoder in Scikit-learn will convert each unique string value into a number, making out data more flexible for various algorithms. \n", "\n", "The result is a table of numbers that looks scary to humans, but beautiful to machines. "], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "a6e707c9c86c314fffe7e5a782c03c9402011395", "_cell_guid": "d4f02a2c-2d76-4b99-b3f8-f3a4f67fd44b"}, "source": ["from sklearn import preprocessing\n", "def encode_features(df_train, df_test):\n", "    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']\n", "    df_combined = pd.concat([df_train[features], df_test[features]])\n", "    \n", "    for feature in features:\n", "        le = preprocessing.LabelEncoder()\n", "        le = le.fit(df_combined[feature])\n", "        df_train[feature] = le.transform(df_train[feature])\n", "        df_test[feature] = le.transform(df_test[feature])\n", "    return df_train, df_test\n", "    \n", "data_train, data_test = encode_features(data_train, data_test)\n", "data_train.head()"], "cell_type": "code"}, {"metadata": {"_uuid": "7cf94916cd55aa44bc5aaf352ad291e58fdc5071", "_cell_guid": "f6b743b0-c16d-4004-97f8-b3f01769a086"}, "source": ["## Splitting up the Training Data\n", "\n", "Now its time for some Machine Learning. \n", "\n", "First, separate the features(X) from the labels(y). \n", "\n", "**X_all:** All features minus the value we want to predict (Survived).\n", "\n", "**y_all:** Only the value we want to predict. \n", "\n", "Second, use Scikit-learn to randomly shuffle this data into four variables. In this case, I'm training 80% of the data, then testing against the other 20%.  \n", "\n", "Later, this data will be reorganized into a KFold pattern to validate the effectiveness of a trained algorithm. "], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "ca8e1bfaaa9e4db0431c9601ef11983fc30de070", "collapsed": true, "_cell_guid": "465b0d94-b91f-419e-9eea-fde497b2b070"}, "source": ["from sklearn.model_selection import train_test_split\n", "\n", "X_all = data_train.drop(['Survived', 'PassengerId'], axis=1)\n", "y_all = data_train['Survived']\n", "\n", "num_test = 0.20\n", "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=23)"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "4a00da5afc97019e9084de77aed38795a37d21fa", "_cell_guid": "cbf26716-fbc8-4b15-a1d8-a2121ad9fd27"}, "source": ["X_train.shape, X_test.shape, y_train.shape, y_test.shape "], "cell_type": "code"}, {"metadata": {"_uuid": "652b2ecad48618e596cdd01dec01418319802d83", "_cell_guid": "d9a696f3-3c23-4b05-a0f5-dcb518531bcb"}, "source": ["## Fitting and Tuning an Algorithm\n", "\n", "Now it's time to figure out which algorithm is going to deliver the best model. I'm going with the RandomForestClassifier, but you can drop any other classifier here, such as Support Vector Machines or Naive Bayes. "], "cell_type": "markdown"}, {"metadata": {}, "source": [], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "8e1b82f54b13d2433fd3c2a56e909cca8b2a16c8", "_cell_guid": "d3050b46-1e28-461b-a6c5-931de8d0825b"}, "source": ["from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.metrics import make_scorer, accuracy_score\n", "from sklearn.model_selection import GridSearchCV\n", "\n", "# Choose the type of classifier. \n", "clf = RandomForestClassifier()\n", "\n", "# Choose some parameter combinations to try\n", "parameters = {'n_estimators': [10, 15, 20], \n", "              'max_features': ['log2', 'sqrt','auto'], \n", "              'criterion': ['entropy', 'gini'],\n", "              'max_depth': [2, 3, 5, 10], \n", "              'min_samples_split': [2, 3, 5],\n", "              'min_samples_leaf': [1,5,8]\n", "             }\n", "\n", "# Type of scoring used to compare parameter combinations\n", "acc_scorer = make_scorer(accuracy_score)\n", "\n", "# Run the grid search\n", "grid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer)\n", "grid_obj = grid_obj.fit(X_train, y_train)\n", "\n", "# Set the clf to the best combination of parameters\n", "clf = grid_obj.best_estimator_\n", "\n", "# Fit the best algorithm to the data. \n", "clf.fit(X_train, y_train)\n", "\n"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "0d48c52c8bfa8623c04f08b6fbc6ece00d3e34b4", "_cell_guid": "5cf92de0-b298-4890-b12c-30d17d6a08bb"}, "source": ["predictions = clf.predict(X_test)\n", "print(accuracy_score(y_test, predictions))"], "cell_type": "code"}, {"metadata": {"_uuid": "6bea10c6f55942c86018ecb83cd270daf8dcc0ec", "_cell_guid": "4aa422d3-2386-4aaa-9d5c-80da618a0ffb"}, "source": ["## Validate with KFold\n", "\n", "Is this model actually  good? It helps to verify the effectiveness of the algorithm using KFold. This will split our data into 10 buckets, then run the algorithm using a different bucket as the test set for each iteration. "], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "b759f15121e6c2e215e0062b89a2e881c0e08a0c", "_cell_guid": "eac948ec-5560-4451-9e61-ee26942235b1"}, "source": ["from sklearn.cross_validation import KFold\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "\n", "def run_kfold(clf):\n", "    kf = KFold(891, n_folds=10)\n", "    outcomes = []\n", "    fold = 0\n", "    for train_index, test_index in kf:\n", "        fold += 1\n", "        X_train, X_test = X_all.values[train_index], X_all.values[test_index]\n", "        y_train, y_test = y_all.values[train_index], y_all.values[test_index]\n", "        clf.fit(X_train, y_train)\n", "        predictions = clf.predict(X_test)\n", "        accuracy = accuracy_score(y_test, predictions)\n", "        outcomes.append(accuracy)\n", "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy))     \n", "    mean_outcome = np.mean(outcomes)\n", "    print(\"Mean Accuracy: {0}\".format(mean_outcome)) \n", "\n", "run_kfold(clf)\n"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "351c81ee5e2c5d3acb8ef77a79f9a40429e471c3", "collapsed": true, "_cell_guid": "0f0f06df-997e-4c21-afe2-5703925cf679"}, "source": ["from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.metrics import make_scorer, accuracy_score\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.svm import SVC, LinearSVC\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.linear_model import Perceptron\n", "from sklearn.linear_model import SGDClassifier\n", "from sklearn.tree import DecisionTreeClassifier"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "ef6a8880be5a050a9f8db16a7115a7ab5a374569", "_cell_guid": "50bec231-7836-4f76-b137-bbdd6cd739cb"}, "source": ["# Support Vector Machines\n", "from sklearn.svm import SVC\n", "clf = SVC()\n", "svc.fit(X_train, y_train)\n", "Y_pred = svc.predict(X_test)\n", "acc_svc = round(svc.score(X_train, y_train) * 100, 2)\n", "acc_svc"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "bc66933860afbd8ab43ecd30ff122810cef5b064", "_cell_guid": "0606695e-185e-47f0-9cda-40e3cd68262b"}, "source": ["\n", "knn = KNeighborsClassifier(n_neighbors = 3)\n", "knn.fit(X_train, y_train)\n", "Y_pred = knn.predict(X_test)\n", "acc_knn = round(knn.score(X_train, y_train) * 100, 2)\n", "acc_knn"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "014ac3d7abc58841ddb70d321c075b0536feebe2", "_cell_guid": "b48b99dc-dc7c-4f59-847c-d8839d95cea5"}, "source": ["# Gaussian Naive Bayes\n", "\n", "gaussian = GaussianNB()\n", "gaussian.fit(X_train, y_train)\n", "Y_pred = gaussian.predict(X_test)\n", "acc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)\n", "acc_gaussian"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "c59253db5322aa9b5080356ba62dc1dbc29c3743", "_cell_guid": "70b008c0-64c4-4ce2-a415-99c840ce7522"}, "source": ["# Perceptron\n", "import warnings\n", "warnings.filterwarnings(\"ignore\")\n", "perceptron = Perceptron()\n", "perceptron.fit(X_train, y_train)\n", "Y_pred = perceptron.predict(X_test)\n", "acc_perceptron = round(perceptron.score(X_train, y_train) * 100, 2)\n", "acc_perceptron"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "218d87d672f49e3c5f2928b6c22e2dc5cae5e4ca", "_cell_guid": "b4927f4c-5646-47bf-a391-742d792764b6"}, "source": ["# Linear SVC\n", "\n", "linear_svc = LinearSVC()\n", "linear_svc.fit(X_train, y_train)\n", "Y_pred = linear_svc.predict(X_test)\n", "acc_linear_svc = round(linear_svc.score(X_train, y_train) * 100, 2)\n", "acc_linear_svc"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "9efadb90841d2e3534f9c552bbe46bc13ca27494", "_cell_guid": "a484f7ee-a4e4-4534-946f-42d3eecd11b3"}, "source": ["# Stochastic Gradient Descent\n", "\n", "sgd = SGDClassifier()\n", "sgd.fit(X_train, y_train)\n", "Y_pred = sgd.predict(X_test)\n", "acc_sgd = round(sgd.score(X_train, y_train) * 100, 2)\n", "acc_sgd"], "cell_type": "code"}, {"metadata": {"_uuid": "d64a3a28e0a02a9a4021981a269af95105546310", "_cell_guid": "3c0e2bc4-3fb0-45bc-9fd7-d7b9cb8bbce7"}, "source": ["\n", "## Predict the Actual Test Data\n", "\n", "And now for the moment of truth. Make the predictions, export the CSV file, and upload them to Kaggle."], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "e00cfe7d71e62fb8f1d87e73d743eea055ae1f0d", "_cell_guid": "5be13ccf-e6ea-4918-a616-1621b85aa351"}, "source": ["ids = data_test['PassengerId']\n", "predictions = clf.predict(data_test.drop('PassengerId', axis=1))\n", "\n", "\n", "output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\n", "output.to_csv('titanic-predictions.csv', index = False)\n", "output.head()"], "cell_type": "code"}, {"metadata": {"_uuid": "9b02a7833fd05a3bb161ba6a453b280ef19c46d8", "_cell_guid": "6bd58fb2-156b-4405-9dbf-3466d665dbd9"}, "source": ["* Hope it helps you. I'll come up with more indepth techniques in future.\n", "* please upvote.\n", "* Thank you :)"], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "metadata": {"_uuid": "09868ab35c6b7f75e76d6be2d27cf0afe85d9ac7", "collapsed": true, "_cell_guid": "f8f6db2b-1829-4591-a8fb-43c69d8f9450"}, "source": [], "cell_type": "code"}], "nbformat_minor": 1, "metadata": {"language_info": {"nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "version": "3.6.3", "file_extension": ".py", "name": "python", "pygments_lexer": "ipython3"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}}