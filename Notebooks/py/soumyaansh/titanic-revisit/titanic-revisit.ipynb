{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9034c0fc-67c6-43ab-aa40-e35cc67d143b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "#Print you can execute arbitrary python code\n",
        "train_df = pd.read_csv(\"../input/train.csv\", dtype={\"Age\": np.float64}, )\n",
        "test_df = pd.read_csv(\"../input/test.csv\", dtype={\"Age\": np.float64}, )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "211b2a19-8f31-0ad0-bb99-e59556f4d1fa"
      },
      "source": [
        "Training set Information\n",
        "------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6e3e0e4e-2add-273e-71cd-9ced5ab18103"
      },
      "outputs": [],
      "source": [
        "print(train_df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9d797d93-b16b-9f03-188b-5cd7e0901b94"
      },
      "source": [
        "Test set Information\n",
        "--------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f0cbf84a-8d16-86cf-6ef5-20d4c13094c1"
      },
      "outputs": [],
      "source": [
        "print(test_df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e4ef3b7d-05a1-9ae1-8b5a-fc2a18f480e1"
      },
      "source": [
        "Feature Cleaning\n",
        "----------------\n",
        "\n",
        "Remove unwanted features and transform data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "93a8208c-dea7-426e-b06f-bd1df2f20372"
      },
      "outputs": [],
      "source": [
        "def changeFeatureDataType(df):\n",
        "    \n",
        "    # convert sex to numeric value\n",
        "    df.loc[df['Sex'] == 'male','Sex'] = 0\n",
        "    df.loc[df['Sex'] == 'female','Sex'] = 1\n",
        "    \n",
        "    # convert the Embarked values to numeric values s=0, c=1, q=2\n",
        "    df.loc[df['Embarked']=='S','Embarked'] = 0\n",
        "    df.loc[df['Embarked']=='C','Embarked'] = 1\n",
        "    df.loc[df['Embarked']=='Q','Embarked'] = 2\n",
        "    \n",
        "    return df\n",
        "       \n",
        "def removeUnwantedfeatures(df):\n",
        "    drop_columns = ['Ticket','Name','Cabin']\n",
        "    df = df.drop(drop_columns, 1)\n",
        "    return df\n",
        "    \n",
        "# transform and clean the dataset\n",
        "\n",
        "def transform_features(df):\n",
        "    df = changeFeatureDataType(df)\n",
        "    df = removeUnwantedfeatures(df)\n",
        "    return df\n",
        "\n",
        "train_df = transform_features(train_df)\n",
        "test_df = transform_features(test_df)\n",
        "\n",
        "print(train_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a3cec979-fdfe-f71d-5b28-636e58db70a0"
      },
      "source": [
        "Imputing missing values\n",
        "-----------------------\n",
        "\n",
        "Lets check all the missing values of the features before addressing the missing values. <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5931bf7c-24f9-352f-0f1d-fc4b3253cb65"
      },
      "outputs": [],
      "source": [
        "print(train_df.isnull().sum())\n",
        "print('-----------------------------')\n",
        "print(test_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a523d621-bd02-aefc-875d-df6993f75cb2"
      },
      "source": [
        "Fare Feature:<br>\n",
        "Fare feature has 1 null value which could be filled by using the median value but let go deeper and see <br> if we can predict something more sensible to replace it with.  <br><br>\n",
        "what if we get a relation between Fare, Embarked and Pclass ? \n",
        "<br> Lets check what's the value of Embarked and Pclass of the rows which has Fare feature as null.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e06dd926-263c-8e49-c547-ce0e5337832c"
      },
      "outputs": [],
      "source": [
        "print(test_df.loc[test_df['Fare'].isnull(),['Embarked','Pclass']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d17f4a80-d175-dcec-553d-de6c9135746d"
      },
      "outputs": [],
      "source": [
        "#check all the similar Fare values of this combination and see if we can get a sorted conclusion\n",
        "fare_distribution =  train_df.loc[(train_df.Embarked == 0) & (train_df.Pclass == 3), ['Fare']]\n",
        "fare_distribution = fare_distribution['Fare'].value_counts().head(20)\n",
        "fare_distribution = fare_distribution.reset_index()\n",
        "fare_distribution.columns = ['Fare', 'Counts']\n",
        "print(fare_distribution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "68ce023b-3d80-64f9-285e-4c26d29bb6cd"
      },
      "outputs": [],
      "source": [
        "g = sns.lmplot('Fare', 'Counts',data=fare_distribution,fit_reg=False,hue='Fare',x_jitter=5.0,y_jitter=5.0,size=8,scatter_kws={\"s\": 100})\n",
        "g.set(xlim=(0, None))\n",
        "g.set(ylim=(0, None))\n",
        "plt.title('Embarked = S and Pclass == 3')\n",
        "plt.xlabel('Fare')\n",
        "plt.ylabel('Counts')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "83b3e8e8-ef5c-0d15-54f0-0ef6861eea4e"
      },
      "outputs": [],
      "source": [
        "#Lets put 8.0500 value in the missing fare \n",
        "test_df['Fare'] = test_df['Fare'].fillna(8.0500)\n",
        "print(test_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a4a28dcf-554a-1b20-f3b8-bc369ada5620"
      },
      "source": [
        "Embarked Feature:<br> There are 2 missing values of Embarked in the test_df. We can fill the missing values by searching other similar occurances where Embarked  is null and then we will consider the their Fare and Pclass values for filling up the null values. The assumption is all the people who paid same Fare and availed same Pclass should have embarked similar destination. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "12f26656-8e9c-dc89-5697-05f5e95f4321"
      },
      "outputs": [],
      "source": [
        "# check the Fare and Pclass of train_df \n",
        "print(train_df.loc[train_df['Embarked'].isnull(),['Fare','Pclass']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0cb7ed0b-3684-c2ed-99f6-0aba501cb6a4"
      },
      "source": [
        "Now that We know that the fare is 80.0 and pclass is 1, we will fetch all the similar rows from the dataset and try to get the Embarked from those values and see if we can reach to any meaningfull values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c34b7001-0db1-4175-5726-e6d2885758d6"
      },
      "outputs": [],
      "source": [
        "print(train_df.loc[(train_df['Pclass'] == 1) & (train_df['Fare'] == 80.0),['Embarked']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f0a537cf-cfb5-e018-4262-a6a8298e8d16"
      },
      "source": [
        "Ooops, so we don't have any other combination with similar values, lets see if we can get any values with almost identical values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5bb771c9-e7ca-0e16-394d-998c93ec38b5"
      },
      "outputs": [],
      "source": [
        "Embarked_distribution = train_df.loc[(train_df['Fare'] > 79.0) & (train_df['Fare'] < 81.0) & (train_df['Pclass'] == 1), ['Fare','Embarked']]\n",
        "print(Embarked_distribution['Embarked'].value_counts())\n",
        "# 1=c and 0=s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "01303b65-64ca-3a4f-1a76-2619a513f416"
      },
      "source": [
        "Lets fill the null values with value 1, Embarked = 'C'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "253e13cc-df43-2cf6-df35-6f933069d33e"
      },
      "outputs": [],
      "source": [
        "train_df['Embarked'] = train_df['Embarked'].fillna(1)\n",
        "print(train_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9dcbba90-aca8-c317-d692-d3cb8917802b"
      },
      "source": [
        "Age Feature: <br>\n",
        "Age is having a lot of missing values in train and test dataframes and it's also an important feature to include. There are total 263 missing Age values.<br> <br>\n",
        "Lets combine both the datasets so that we can get a clear picture of impact of survival on Age feature. <br>for the sake of showing the plot for each and every age we will drop all the null values and remove the outlier age values from the Age feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "834cc8dc-9c8d-4921-d50f-46722e763247"
      },
      "outputs": [],
      "source": [
        "#combine both the datasets so that we can get a clear picture of impact of survival on Age feature\n",
        "titanic_df = train_df.append(pd.DataFrame(data = test_df), ignore_index=True)\n",
        "\n",
        "titanic_df['Age'] = titanic_df['Age'].fillna(titanic_df['Age'].median())\n",
        "train_df['Age'] = train_df['Age'].fillna(train_df['Age'].median())\n",
        "test_df['Age'] = test_df['Age'].fillna(test_df['Age'].median())\n",
        "\n",
        "# for the sake of showing the plot for each and every age we will drop all the null values \n",
        "# remove the outlier age values from the Age feature\n",
        "titanic_df['Age1'] = titanic_df.Age\n",
        "titanic_df['Age1'] = titanic_df[titanic_df['Age1'] < 60]\n",
        "\n",
        "#Impact visualization of Age on Survival through graph\n",
        "fig = plt.figure(figsize=(13, 5))\n",
        "average_age = titanic_df[[\"Age1\", \"Survived\"]].groupby(['Age1'],as_index=False).mean()\n",
        "average_age['Age1'] = average_age['Age1'].astype(int)\n",
        "sns.barplot(\"Age1\", \"Survived\",data=average_age)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "96cd028a-6d6b-b141-3297-a2e01515eace"
      },
      "source": [
        " By looking at the below graph we can make out that kids with age less than 8 has more chances of survival and they made through the tragic on the other hand all the young and adult have a bad survival curve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "da2e0275-7384-0c2e-6c20-bbb6f93b5f40"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(13, 5))\n",
        "alpha = 0.3\n",
        "\n",
        "titanic_df[titanic_df.Survived==0].Age.value_counts().plot(kind='density', color='#6ACC65', label='Not Survived', alpha=alpha)\n",
        "titanic_df[titanic_df.Survived==1].Age.value_counts().plot(kind='density', color='#FA2379', label='Survived', alpha=alpha)\n",
        "\n",
        "plt.xlim(0,80)\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Survival Count')\n",
        "plt.title('Age Distribution')\n",
        "plt.legend(loc ='best')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ad76152b-c9cd-a2c8-f336-d62a55da6039"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(13, 5))\n",
        "alpha = 0.3\n",
        "\n",
        "titanic_df[titanic_df.Survived==0].Sex.value_counts().plot(kind='bar', color='#00FFFF', label='Not Survived', alpha=alpha)\n",
        "titanic_df[titanic_df.Survived==1].Sex.value_counts().plot(kind='bar', color='#6ACC65', label='Survived', alpha=alpha)\n",
        "\n",
        "plt.xlabel('Sex')\n",
        "plt.ylabel('Survival Count')\n",
        "plt.title('Impact of sex on Survival')\n",
        "plt.legend(loc ='best')\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "64e05616-47d1-bb36-b6ac-17e9d7b93d4c"
      },
      "source": [
        "\n",
        "**Impact visualization of Age,Sex,Embarked and Parch (Parents and Childrens) on Survival through plots <br>**\n",
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "28c88b2c-bb67-45bc-b0eb-a9ebdf986328"
      },
      "outputs": [],
      "source": [
        "sex_survived = pd.crosstab(train_df[\"Sex\"],train_df[\"Survived\"])\n",
        "parch_survived = pd.crosstab(train_df[\"Parch\"],train_df[\"Survived\"])\n",
        "pclass_survived = pd.crosstab(train_df[\"Pclass\"],train_df[\"Survived\"])\n",
        "\n",
        "fig, (axis1,axis2) = plt.subplots(1,2,figsize=(12,5))    \n",
        "sns.barplot(train_df[\"Sex\"], train_df[\"Survived\"], palette=\"Set3\" ,ax=axis1)\n",
        "sns.barplot(train_df[\"Parch\"], train_df[\"Survived\"], palette=\"Set3\", ax=axis2)\n",
        "\n",
        "fig, (axis3,axis4) = plt.subplots(1,2,figsize=(12,5))  \n",
        "sns.barplot(train_df[\"Parch\"], train_df[\"Survived\"], palette=\"Set3\", ax=axis3)\n",
        "sns.barplot(train_df[\"Embarked\"], train_df[\"Survived\"], palette=\"Set3\", ax=axis4)\n",
        "\n",
        "plt.xticks(rotation=90)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a821cb57-fe13-ff47-a68e-6af387179de3"
      },
      "source": [
        "Predictive Modelling : Logistic Regression\n",
        "------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "195717f3-5121-037c-9e9c-e715232b7839"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import cross_validation\n",
        "\n",
        "imp_features = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\",\"SibSp\", \"Parch\"]\n",
        "\n",
        "model = LogisticRegression(random_state=1)\n",
        "scores = cross_validation.cross_val_score(\n",
        "    model,\n",
        "    train_df[imp_features],\n",
        "    train_df[\"Survived\"],\n",
        "    cv=3\n",
        ")\n",
        "\n",
        "print(scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7fdcb820-610b-0940-33ac-53808e1c31ff"
      },
      "source": [
        "Predictive Modelling : Random Forest Classification\n",
        "---------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b538a8c3-ccaf-c96e-aa97-8c0e9ae57cc9"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import cross_validation\n",
        "\n",
        "imp_features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
        "\n",
        "model = RandomForestClassifier(\n",
        "    random_state=1,\n",
        "    n_estimators=150,\n",
        "    min_samples_split=4,\n",
        "    min_samples_leaf=2\n",
        ")\n",
        "\n",
        "scores = cross_validation.cross_val_score(\n",
        "    model,\n",
        "    train_df[imp_features],\n",
        "    train_df[\"Survived\"],\n",
        "    cv=3\n",
        ")\n",
        "\n",
        "print(scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "384e4c6a-d5f1-99e5-65f5-bb06961451c4"
      },
      "source": [
        "Submission Of Result\n",
        "--------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7247025c-8ed5-c85f-7f31-23d8757dd0e3"
      },
      "outputs": [],
      "source": [
        "def submission_result(model, train_df, test_df, predictors, filename):\n",
        "\n",
        "    model.fit(train_df[predictors], train_df[\"Survived\"])\n",
        "    predictions = model.predict(test_df[predictors])\n",
        "\n",
        "    submission = pd.DataFrame({\n",
        "        \"PassengerId\": test_df[\"PassengerId\"],\n",
        "        \"Survived\": predictions\n",
        "    })\n",
        "    \n",
        "    submission.to_csv(filename, index=False)\n",
        "    \n",
        "    \n",
        "# call the submission_result function to submit the result\n",
        "submission_result(model, train_df, test_df, imp_features, \"titanic_result.csv\")\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}