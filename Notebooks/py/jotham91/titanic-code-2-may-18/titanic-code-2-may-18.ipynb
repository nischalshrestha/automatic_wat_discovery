{"cells":[{"metadata":{"collapsed":true,"trusted":false,"_uuid":"6b9d087f200f1114649fc55ab10aa3c859119c95"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport scipy as sp\nfrom IPython import display\n\n# common model algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n# common model helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\n# visiualisation\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nfrom pandas.tools.plotting import scatter_matrix\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport time\n\n%matplotlib inline\nmpl.style.use('ggplot')\nsns.set_style('white')","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"bdddb4d734520a436fa685ecd26e73fc976a1bb9"},"cell_type":"markdown","source":"**Load Data**"},{"metadata":{"trusted":false,"_uuid":"d1aac0061375270939f91f04e55f76c6fde8d13a"},"cell_type":"code","source":"# import training and test set\ndata_raw = pd.read_csv('../input/train.csv')\ndata_val = pd.read_csv('../input/test.csv')\n\n# Make a copy of the training set to wrangle\ndata1 = data_raw.copy(deep=True)\n\n# Put both in a list so we can clean both datasets at once\ndata_cleaner = [data1, data_val]\n\n# Get an overview of the data\nprint(data_raw.info())\ndata1.head()","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d26688385a540bc5a59171d7d21743c5107db0ca"},"cell_type":"markdown","source":"**Get overview of data and missing values**"},{"metadata":{"trusted":false,"_uuid":"0728f62db23ba6cdf52c4f000f8c449be467d5e3"},"cell_type":"code","source":"# Check for null values in training and test set\nprint('Training set null values\\n', data1.isnull().sum())\nprint('-'*20)\nprint('Test set null values\\n', data_val.isnull().sum())","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"d441f44dd64367a56b79126699cf105c6ac2e708"},"cell_type":"markdown","source":"test df null values: Age, Cabin and Embarked<br>\ntraining df null values: Age, Fare, Cabin"},{"metadata":{"trusted":false,"_uuid":"8ed11c9b25f3dd95c55d49927a7c6da77ef9e042"},"cell_type":"code","source":"# Check for outliers / weird values\ndata_raw.describe(include='all')","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"caf15222b0dffd7eab92e25ab241a7d1b3fae48b"},"cell_type":"markdown","source":"## Complete Data\n\n**Data to Complete**<br>\nAge: Use median to compute missing values<br>\nEmbarked: Use mode to complete missing values<br>\nFare: Use median to complete missing fare\n\n**Data to Drop**<br>\nCabin: Too many missing values, furthermore doesnt make sense to use this as a predictor for survival rate"},{"metadata":{"trusted":false,"_uuid":"e2886d249c4e5d7fe235fbb024b371cd2cdb3b00"},"cell_type":"code","source":"# Complete data for both training and test sets\nfor dataset in data_cleaner:\n    dataset['Age'].fillna(value=dataset['Age'].median(), inplace=True)\n    dataset['Embarked'].fillna(value=dataset['Embarked'].mode()[0], inplace=True)\n    dataset['Fare'].fillna(value=dataset['Fare'].median(), inplace=True)\n\n# drop columns in test set\ndrop_columns = ['PassengerId', 'Cabin', 'Ticket']\ndata1.drop(drop_columns, axis=1, inplace=True)\n\n# check if data completed for both training and test set\nprint(data1.isnull().sum())\nprint('-'*20)\nprint(data_val.isnull().sum())","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"4ac25120f23923d7b7f1bb783eb15ab4cc5d19a7"},"cell_type":"markdown","source":"## Create (Feature Engineering)\n\n**New Features To Create**<br>\nFamilySize: Parch + Sibsp + 1<br>\nIsAlone: 1 if alone else 0 if there are siblings<br>\nTitle feature: Take out the titles from the names to see if people who have titles have higher chance of survival<br>\n\n**Numerical features that can be converted to categorial**<br>\nFareBin: Cut Fare into 4 equal bins<br>\nAgeBin: Cut Age into 5 bins "},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"b396ac3f127b24335b082f76197074138c2b6f6c"},"cell_type":"code","source":"# Create new features in both the training and test set\n\nfor dataset in data_cleaner:\n    # Create feature for FamilySize\n    dataset['FamilySize'] = dataset['Parch'] + dataset['SibSp'] + 1\n    \n    # Create feature for IsAlone. 1 for alone, 0 if there have siblings or children\n    dataset['IsAlone'] = 1\n    dataset['IsAlone'].loc[dataset['FamilySize'] > 1] = 0\n    \n    # Create Title feature\n    dataset['Title'] = dataset['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n    \n    # Create Age Bins\n    dataset['AgeBin'] = pd.cut(dataset['Age'], 5)\n    \n    # Create Fare Bins\n    dataset['FareBin'] = pd.qcut(dataset['Fare'], 4)","execution_count":6,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"18caffda663330f2872177f344994126aef8c968"},"cell_type":"code","source":"# Replace wrong designations\ndata1['Title'] = data1['Title'].replace({'Ms': 'Miss', 'Mme': 'Mrs', 'Mlle':'Miss'})\n\n# Group uncommon designations as misc\nstat_min = 10\ntitle_names = data1['Title'].value_counts() < stat_min\n\ndata1['Title'] = data1['Title'].apply(lambda x: 'Misc' if title_names.loc[x] == True else x)\nprint(data1['Title'].value_counts())","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"1330f9b8a3d874ed8fca8d9cc48fccd445c25463"},"cell_type":"markdown","source":"## Convert Features \n\nConvert text data to ordinal (LabelEncoder), then convert to OneHot (pd.get_dummies)\n\n**Categorical Data**: Sex, Pclass, Embarked, Title, SibSp, Parch, Age, Fare,FamilySize, FamilySize, IsAlone"},{"metadata":{"trusted":false,"_uuid":"d346d05cc491e685c1ce3f0a21a88d4026889069"},"cell_type":"code","source":"data1.head()","execution_count":8,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"dbd855499a1934be086f58d77c4b0748e4bf4340"},"cell_type":"code","source":"# code categorical data\nlabel = LabelEncoder()\n\nfor dataset in data_cleaner:\n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])\n    dataset['Title_Code'] = label.fit_transform(dataset['Title'])\n    dataset['AgeBin_Code'] = label.fit_transform(dataset['AgeBin'])\n    dataset['FareBin_Code'] = label.fit_transform(dataset['FareBin'])\n    \n# define y variable for target/outcome\nTarget = ['Survived']\n\n# define x variable for original features aka feature selection\ndata1_x = ['Sex', 'Pclass', 'Embarked', 'Title', 'SibSp', 'Parch', 'Age', 'Fare', 'FamilySize', 'IsAlone']\n\n# pretty name/values for charts\ndata1_x_calc = ['Sex', 'Pclass', 'Embarked_Code', 'Title_Code', 'SibSp', 'Parch', 'Age', 'Fare'] # coded for algo calc\n\ndata1_xy = Target + data1_x\nprint('Original X Y: ',data1_xy,'\\n' )\n\n\n# define x variables for original with bin features. Categorical coded numerically instead of in words.\ndata1_x_bin = ['Sex_Code', 'Pclass', 'Embarked_Code', 'Title_Code', 'FamilySize', 'AgeBin_Code', 'FareBin_Code']\ndata1_xy_bin = Target + data1_x_bin\nprint('Bin X Y: ', data1_xy_bin, '\\n')\n\n\n# Establish dummy variables\ndata1_dummy = pd.get_dummies(data1[data1_x])\ndata1_x_dummy = data1_dummy.columns.tolist()\ndata1_xy_dummy = Target + data1_x_dummy\nprint('Dummy X Y: ', data1_xy_dummy, '\\n')\n\ndata1_dummy.head()","execution_count":9,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7d8307c911d5175066e242d1084b1393ddd9fabd"},"cell_type":"code","source":"data_val.info()","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"d0ee4589488c0a9face929613d5efc44e1b165ff"},"cell_type":"markdown","source":"## Split data into training and test set"},{"metadata":{"trusted":false,"_uuid":"c18d1e082bfb267209f8f54e691ee28c06e7699f"},"cell_type":"code","source":"# Split data into training and test set\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state=0)\ntrain1_x_bin, test1_x_bin, train1_y_bin, test1_y_bin = model_selection.train_test_split(data1[data1_x_bin], data1[Target], random_state=0)\ntrain1_x_dummy, test1_x_dummy, train1_y_dummy, test1_y_dummy = model_selection.train_test_split(data1_dummy[data1_x_dummy], data1[Target], random_state=0)\n\nprint('Data1 Shape:', data1.shape)\nprint('Train1 Shape:', train1_x.shape)\nprint('Test1 Shape:', test1_x.shape)\n\ntrain1_x_bin.head()","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"f136362a85b6576abaad0bb040e79b3d4b082d96"},"cell_type":"markdown","source":"## Perform exploratory analysis with statistics"},{"metadata":{"_uuid":"def17a01e813fb28226346bcdc1cc9be9e537e52"},"cell_type":"markdown","source":"Create a pivot table to observe each predictor's correlation with the Target (survival)"},{"metadata":{"trusted":false,"_uuid":"946fecdeb48cac6b91bb202996e31926cf45a776"},"cell_type":"code","source":"# Discrete variable correlation by survival using groupby pivot table\nfor x in data1_x:\n    if data1[x].dtype != 'float64':\n        print('Survival Correlation by: ', x)\n        print(data1[[x, Target[0]]].groupby(by=x, as_index=False).mean())\n        print('-'*40,'\\n')\n        \n# Using crosstabs\nprint(pd.crosstab(data1['Title'], data1[Target[0]]))","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"6523c68274c666e597f3f85320185202787cc508"},"cell_type":"markdown","source":"## Plot numerical continuous variables\n\nLook at distribution of numerical continuous variables"},{"metadata":{"trusted":false,"_uuid":"688641520b7b0c4c4abadd1195b78c8e8da89275"},"cell_type":"code","source":"plt.figure(figsize=(16,12))\n0\nplt.subplot(231)\nplt.boxplot(data1['Fare'], meanline=True, showmeans=True);\nplt.xlabel('Fare Boxplot')\nplt.ylabel('Fare ($)')\nplt.title('Fare Boxplot')\n\nplt.subplot(232)\nplt.boxplot(data1['Age'], meanline=True, showmeans=True);\nplt.xlabel('Age Boxplot')\nplt.ylabel('Age (Years)')\nplt.title('Age Boxplot')\n\nplt.subplot(233)\nplt.boxplot(data1['FamilySize'], meanline=True, showmeans=True);\nplt.xlabel('FamilySize Boxplot')\nplt.ylabel('Family Size (#)')\nplt.title('Family Boxplot')\n\nplt.subplot(234)\nplt.hist(x=[data1[data1['Survived'] == 1]['Fare'], data1[data1['Survived'] == 0]['Fare']], stacked=True, color=['g', 'r'], label=['Survived', 'Dead'])\nplt.xlabel('Fare ($)')\nplt.ylabel('# of Passengers')\nplt.title('Fare Histogram by Survival')\nplt.legend()\n\nplt.subplot(235)\nplt.hist(x=[data1[data1['Survived'] == 1]['Age'], data1[data1['Survived'] == 0]['Age']], stacked=True, color=['g', 'r'], label=['Survived', 'Dead'])\nplt.xlabel('Age (# of years)')\nplt.ylabel('# of Passengers')\nplt.title('Age Histogram by Survival')\nplt.legend()\n\nplt.subplot(236)\nplt.hist(x=[data1[data1['Survived'] == 1]['FamilySize'], data1[data1['Survived'] == 0]['FamilySize']], stacked=True, color=['g', 'r'], label=['Survived', 'Dead'])\nplt.xlabel('Family Size')\nplt.ylabel('# of Passengers')\nplt.title('Family Size Histogram by Survival')\nplt.legend();","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"c24b8aa13d012da37fad8cb2086c225235bc526f"},"cell_type":"markdown","source":"## Plot categorical features"},{"metadata":{"trusted":false,"_uuid":"b7f1acb51e67ac4ab6173b021e775717e027015f"},"cell_type":"code","source":"fig, saxis = plt.subplots(2,3,figsize=(16,12))\n\nsns.barplot(x= 'Embarked', y= 'Survived', data=data1, ax= saxis[0,0])\nsns.barplot(x = 'Pclass', y='Survived', data=data1, ax=saxis[0,1])\nsns.barplot(x = 'IsAlone', y='Survived', data=data1, ax=saxis[0,2], order=[1,0])\n\nsns.pointplot(x='FareBin', y='Survived', data=data1, ax=saxis[1,0])\nsns.pointplot(x='AgeBin', y='Survived', data=data1, ax=saxis[1,1])\nsns.pointplot(x='FamilySize', y='Survived', data=data1, ax=saxis[1,2])","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"b617da8ee2467bb98921ba58bac463d3c11cf1ac"},"cell_type":"markdown","source":"- Passegers from port C had a significantly higher chance of survival\n- May be multicollinearity, where passengers who had higher fare / class boarding from port C\n- Passengers from better class higher chance of survival\n- Passengers who were not alone had a higher chance of survival<br><br>\n\n- Passengers who paid higher fares had higher chance of survival. Again, may be multicollinearity between Fare and PClass"},{"metadata":{"_uuid":"11081c26a110f113432ff9885441c04c65b41ada"},"cell_type":"markdown","source":"## Graph distribution of Pclass w.r.t other variables (fare, age, family size)"},{"metadata":{"trusted":false,"_uuid":"617f42881c8064e5cbadb077bc0bec3647fa892f"},"cell_type":"code","source":"fig, (ax1,ax2,ax3) = plt.subplots(1,3, figsize=(14,12))\n\nsns.boxplot(x='Pclass', y='Fare', hue='Survived', data=data1, ax=ax1)\nax1.set_title('Pclass vs Fare Survival Comparison')\n\nsns.violinplot(x='Pclass', y='Age', hue='Survived', data=data1, ax=ax2, split=True)\nax2.set_title('Pclass vs Age Survival Comparison')\n\nsns.boxplot(x='Pclass', y='FamilySize', hue='Survived', data=data1, ax=ax3)\nax3.set_title('Pclass vs Family Size Survival Comparison')","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"1ae23ad84f185be5f691992f2654ec9005989699"},"cell_type":"markdown","source":"- Passengers from higher classes paid a higher fare\n- Passengers who are older tend to be from higher classes\n- No clear relationship between FamilySize and PClass"},{"metadata":{"_uuid":"78d9c55a476f8d54e30a92e8bad580d2e7b80a34"},"cell_type":"markdown","source":"## Graph Distribution of  Sex Variable"},{"metadata":{"trusted":false,"_uuid":"80bdabbff83c1fe1e42b3b5cc8af392321005dd3"},"cell_type":"code","source":"# graph distribution of qualitative data: sex\n\nfig, qaxis = plt.subplots(1,3,figsize=(14,12))\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Embarked', data=data1, ax = qaxis[0])\nqaxis[0].set_title('Sex vs Embarked Survival Comparison')\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'Pclass', data=data1, ax = qaxis[1])\nqaxis[1].set_title('Sex vs Pclass Survival Comparison')\n\nsns.barplot(x = 'Sex', y = 'Survived', hue = 'IsAlone', data=data1, ax = qaxis[2])\nqaxis[2].set_title('Sex vs IsAlone Survival Comparison');","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"42deaac10a6d99bff1836f2bab8af8db766ce452"},"cell_type":"markdown","source":"- Obvious that females had a much higher chance of survival as compared to males"},{"metadata":{"trusted":false,"_uuid":"26503443140b8f6715298700f17a4318c76b6ea6"},"cell_type":"code","source":"# More side by side comparisons of FamilySize and Pclass vs the dependent variable\n\nfig, (maxis1, maxis2) = plt.subplots(1,2,figsize=(14,12))\n\n# family size with survival and sex compare\nsns.pointplot(x='FamilySize', y='Survived', hue='Sex', data=data1, ax=maxis1, palette={'male': 'blue', 'female': 'pink'},\n             markers=['*', 'o'], linestyles=['-', '--'])\n\n# Pclass with survival and sex compare\nsns.pointplot(x='Pclass', y='Survived', hue='Sex', data=data1, ax=maxis2, palette={'male': 'blue', 'female': 'pink'},\n             markers=['*', 'o'], linestyles=['-', '--']);","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"9aeb12b85fd0c6acbccf9d74656642fb9e13ed06"},"cell_type":"markdown","source":"- Again clear that females have higher chance of survival\n- No clear relationship between FamilySize and Survival\n- Clear relationship between PClass and survival"},{"metadata":{"trusted":false,"_uuid":"d9e3992d3ffa4df60dfb842a5539297b40b2a343"},"cell_type":"code","source":"# Plot distribution of passengers who survived vs died\na = sns.FacetGrid(data1, hue='Survived', aspect=4)\na.map(sns.kdeplot, 'Age', shade=True)\na.set(xlim=(0, data1['Age'].max()))\na.add_legend()","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"6731c65829e73dd0a02cc9388735f6b79e88e4d0"},"cell_type":"markdown","source":"- Higher proportion of young children (below 15) survived - More survived than died\n- Lower proportion of middle aged (20 - 35) survived - More died than survived\n- Above 35, about equal percentages survived and died"},{"metadata":{"trusted":false,"_uuid":"12516d650051421fd38c5e9c5f69a5bf57e73f8b"},"cell_type":"code","source":"# Comparison of Sex, Class, and Age\ns = sns.FacetGrid(data1, row='Sex', col='Pclass', hue='Survived')\ns.map(plt.hist, 'Age', alpha=0.5)\ns.add_legend()","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"a924c4d8167be6800aad56b678dab2ad86d2b690"},"cell_type":"markdown","source":"- We can see that the vast proportion of those who died are **males from 2nd and 3rd class**\n- Almost all females from the 1st and 2nd classes survived"},{"metadata":{"trusted":false,"_uuid":"280a2a6b53ac13df51d99734f52b3318ab8bfd1f"},"cell_type":"code","source":"#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorrelation_heatmap(data1)","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"2dd0fa8aa33ef7c35228f28c14d47602d483f4f5"},"cell_type":"markdown","source":"Corr heatmaps shows the following:\n- Strong negative correlation between PClass and FareBin (higher fare, lower the class)\n- Strong negative correlation between FareBin_Code and IsAlone\n- As noted earlier, strong correlation between Sex and Survived\n- As noted earlier, moderate negative correlation between PClass and Survived\n- Modete positive correlation between Title and Age. Makes sense\n\nOf course, strong correlation between the below features as they were engineered:\n- SibSp and Parch and the additional features that we derived from them: Family Size and IsAlone\n- "},{"metadata":{"_uuid":"0ab4fbfd9303f6252b8809cb602fc580bded17c6"},"cell_type":"markdown","source":"# Model Data\n\nCreate a table with all the base models, evaluating the CV train and test accuracy, as well as the standard deviation"},{"metadata":{"trusted":false,"_uuid":"248d111962a84b48b3dfe5bcad0e6557de947bc4"},"cell_type":"code","source":"# Machine Learning Algo Selection and Initialization\nMLA = [\n    # Ensemble methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n    \n    # Gaussian Process\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #General Linear Models\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(),\n    linear_model.Perceptron(),\n    \n    # Naive Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    \n    # Nearest Neighbour\n    neighbors.KNeighborsClassifier(),\n    \n    # SVM\n    svm.SVC(probability=True),\n    svm.NuSVC(probability=True),\n    svm.LinearSVC(),\n    \n    # Trees\n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n    \n    # Discriminant Analysis\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n    \n    # XGBoost\n    XGBClassifier()\n]\n\n# Split dataset in cross-validation with sklearn shuffle split. This is an alternative to train_test_split\n# run the model 10x, with a train/test split of 60/30, intentionally leaving out 10%\ncv_split = model_selection.ShuffleSplit(n_splits=10, test_size=0.3, train_size=0.6, random_state=0)\n\n# Create table to compare MLA metrics\nMLA_columns = ['MLA Name', 'MLA Parameters', 'MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD', 'MLA Time']\nMLA_compare = pd.DataFrame(columns=MLA_columns)\n\n# Create table to compare MLA predictions\nMLA_predict = data1[Target]\n\n# loop through MLA and save performance in the table\nrow_index = 0\nfor alg in MLA:\n    \n    # Set names and parameters\n    MLA_name = alg.__class__.__name__\n    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n    \n    # Score model with cross validation\n    cv_results = model_selection.cross_validate(alg, data1[data1_x_bin], data1[Target], cv=cv_split)\n    \n    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()\n    \n    # Find std, and if this is non-bias random sample, +/- 3 stdev from mean should statistically\n    # capture 99.7% of the subsets\n    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3\n    \n    # Fit and predict for each MLA and save in df\n    alg.fit(data1[data1_x_bin], data1[Target])\n    MLA_predict[MLA_name] = alg.predict(data1[data1_x_bin])\n    \n    row_index += 1\n    \n# Print and sort table\nMLA_compare.sort_values(by=['MLA Test Accuracy Mean'], ascending=False, inplace=True)\nMLA_compare","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"9716581db8ff9037629a01138e5b62952f1ebd72"},"cell_type":"markdown","source":"Plot the results of each classifier to see which one has the highest Test Accuracy"},{"metadata":{"trusted":false,"_uuid":"131a4eb68d4aca37c857df780bc74ff788e8c69b"},"cell_type":"code","source":"# Plot results of each classifier\nplt.figure(figsize=(16,12))\nsns.barplot(x='MLA Test Accuracy Mean', y='MLA Name', data=MLA_compare, color='m')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm');","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"68a76e49123fa5aa467f0706fb8db248c2b88f97"},"cell_type":"markdown","source":"# Tune Models\n\n\n**Tune model's hyper parameters**<br>\nUse ParameterGrid to get all possible combinations parameters, and then GridSearchCV. Evaluate it using sklearn scoring, ROC_AUC scores"},{"metadata":{"trusted":false,"_uuid":"089fa3aec7a103dd2ce58cc094013f6ea387ccc5"},"cell_type":"code","source":"# Intialise base model\ndtree = tree.DecisionTreeClassifier(random_state=0)\nbase_results = model_selection.cross_validate(dtree, data1[data1_x_bin], data1[Target], cv=cv_split)\ndtree.fit(data1[data1_x_bin], data1[Target])\n\nprint('Before DT Parameters', dtree.get_params())\nprint('Before DT Training w/bin score mean: {:.2f}'.format(base_results['train_score'].mean()*100) )\nprint('Before DT Test w/bin score mean: {:.2f}'.format(base_results['test_score'].mean()*100))\nprint('Before DT Test w/bin score 3*std: +/- {:.2f}'.format(base_results['test_score'].std()*100*3))\nprint('-'*60)\n\n# Tune hyper parameters\n# Use Gridsearch to get run all permutations of the hyper parameters. Put permutations in dict first\nparam_grid = {'criterion': ['gini', 'entropy'], 'max_depth':[2,4,6,8,10,None], 'random_state': [0]}\n\ntune_model = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring='roc_auc', n_jobs=-1, cv=cv_split)\ntune_model.fit(data1[data1_x_bin], data1[Target])\n\nprint('Afrer DT Parameters', tune_model.best_params_)\nprint('After DT Training w/bin score mean: {:.2f}'.format(tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100))\nprint('After DT Test w/bin score mean: {:.2f}'.format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\nprint('After DT Test w/bin score 3*std: +/- {:.2f}'.format(tune_model.cv_results_['std_test_score'][tune_model.best_index_]*100*3))","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"45c64ec6ba680c1fce59c0000161c3b75d770152"},"cell_type":"markdown","source":"**Tune model using feature selection**<br>\nMore predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. Sklearn has several options, we will use recursive feature elimination (RFE) with cross validation (CV) to select the best features"},{"metadata":{"trusted":false,"_uuid":"9b81e214b55f5c1a72e1b5e4c8f7835abbe4a908"},"cell_type":"code","source":"# Get data from base model for comparison\nprint('Before DT RFE Training Shape Old', data1[data1_x_bin].shape)\nprint('Before DT RFT Training Columns Old', data1[data1_x_bin].columns.values)\n\nprint('Before DT RFE Training w/bin score mean: {:.2f}'.format(base_results['train_score'].mean()*100) )\nprint('Before DT RFE Test w/bin score mean: {:.2f}'.format(base_results['test_score'].mean()*100))\nprint('Before DT RFE Test w/bin score 3*std: +/- {:.2f}'.format(base_results['test_score'].std()*100*3))\nprint('-'*60)\n\n# Feature selection\ndtree_rfe = feature_selection.RFECV(dtree, step=1, cv=cv_split, scoring='accuracy')\ndtree_rfe.fit(data1[data1_x_bin], data1[Target])\n\n# get predictors after RFE\nX_rfe = data1[data1_x_bin].columns.values[dtree_rfe.get_support()]\n\n# Use the columns, and run the dtree again scoring using CV\nrfe_results = model_selection.cross_validate(dtree, data1[X_rfe], data1[Target], cv=cv_split)\n\n# Print out results\nprint('After DT RFE Training Shape New: ', data1[X_rfe].shape)\nprint('After DT RFE Training Columns New: ', X_rfe)\n\nprint('After DT RFE Training w/bin score mean: {:.2f}'.format(rfe_results['train_score'].mean()*100))\nprint('After DT RFE Test w/bin score mean: {:.2f}'.format(rfe_results['test_score'].mean()*100))\nprint('After DT RFE Test w/bin score 3*std: +/- {:.2f}'.format(rfe_results['test_score'].std()*100*3))\nprint('-'*60)\n\n# Tune RFE model with gridsearch\nrfe_tune_model = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring='roc_auc', cv=cv_split)\nrfe_tune_model.fit(data1[X_rfe], data1[Target])\n\n# Print out results of tuned DT RFE model\nprint('After DT RFE Parameters', rfe_tune_model.best_params_)\nprint('After RFE DT Training w/bin score mean: {:.2f}'.format(rfe_tune_model.cv_results_['mean_train_score'][rfe_tune_model.best_index_]*100))\nprint('After RFE DT Test w/bin score mean: {:.2f}'.format(rfe_tune_model.cv_results_['mean_test_score'][rfe_tune_model.best_index_]*100))\nprint('After RFE DT Test w/bin score 3*std: +/- {:.2f}'.format(rfe_tune_model.cv_results_['std_test_score'][rfe_tune_model.best_index_]*100*3))","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"09e350bb7b76085e67312e3dd1e53fe6eabf264b"},"cell_type":"markdown","source":"# Validate and Implement Model\n\nLook at the correlation between models. The models with lower correlations tend to aggregate to a better ensemble model. "},{"metadata":{"trusted":false,"_uuid":"7c8b0070d50bdd8b086ff8011d9632e08e445c15"},"cell_type":"code","source":"correlation_heatmap(MLA_predict)\n# the blue and light red models have low corr, can create an ensemble of models ","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"4c8184436fefeef17b4dd96741a05551a1326ef6"},"cell_type":"markdown","source":"**Voting Classifier**\n\nCreate an ensemble using sklearn's Voting Classifier"},{"metadata":{"trusted":false,"_uuid":"8e7ab226240da327dffdde695485948005e64497"},"cell_type":"code","source":"# Create the list of models\nvote_est = [\n    \n    # Ensemble methods\n    ('ada', ensemble.AdaBoostClassifier()),\n    ('bc', ensemble.BaggingClassifier()),\n    ('etc', ensemble.ExtraTreesClassifier()),\n    ('gbc', ensemble.GradientBoostingClassifier()),\n    ('rfc', ensemble.RandomForestClassifier()),\n    \n    # Gaussian Processes\n    ('gpc', gaussian_process.GaussianProcessClassifier()),\n    \n    # General Linear Model\n    ('lr', linear_model.LogisticRegressionCV()),\n    \n    # Naive Bayes\n    ('bnb', naive_bayes.BernoulliNB()),\n    ('gnb', naive_bayes.GaussianNB()),\n    \n    # Nearest Neighbour\n    ('knn', neighbors.KNeighborsClassifier()),\n    \n    # SVM\n    ('svc', svm.SVC(probability=True)),\n    \n    # XGBoost\n    ('xgb', XGBClassifier())\n]\n\n# Create a hard vote ensemble (majority rules)\nvote_hard = ensemble.VotingClassifier(vote_est, voting='hard', n_jobs=-1)\nvote_hard_cv = model_selection.cross_validate(vote_hard, data1[data1_x_bin], data1[Target], cv=cv_split)\nvote_hard.fit(data1[data1_x_bin], data1[Target])\n\n# Print out results for vote hard classifier\nprint('Hard voting training score mean: {:.2f}'.format(vote_hard_cv['train_score'].mean()*100))\nprint('Hard voting test score mean: {:.2f}'.format(vote_hard_cv['test_score'].mean()*100))\nprint('Hard voting 3*std: +/- {:.2f}'.format(vote_hard_cv['test_score'].std()*100*3))\nprint('-'* 60)\n\n# Create a soft vote ensemble (weighted probabilities)\nvote_soft = ensemble.VotingClassifier(vote_est, voting='soft', n_jobs=-1)\nvote_soft_cv = model_selection.cross_validate(vote_soft, data1[data1_x_bin], data1[Target], cv= cv_split)\nvote_soft.fit(data1[data1_x_bin], data1[Target])\n\n# Print out results for soft voting classifer\nprint('Soft voting training score mean: {:.2f}'.format(vote_soft_cv['train_score'].mean()*100))\nprint('Soft voting test score mean: {:.2f}'.format(vote_soft_cv['test_score'].mean()*100))\nprint('Soft voting 3*std: +/- {:.2f}'.format(vote_soft_cv['test_score'].std()*100*3))","execution_count":26,"outputs":[]},{"metadata":{"_uuid":"0d2873e3866dd7697cf193635ac80939de9b6935"},"cell_type":"markdown","source":"**Tune Voting Classifier**"},{"metadata":{"trusted":false,"_uuid":"46cf1baf3ce167fddba50313a0b1099b7ff32adc"},"cell_type":"code","source":"# Warning, running is computationally expensive\n\ngrid_n_estimator = [10, 50, 100, 300]\ngrid_ratio = [.1, .25, .5, .75, 1.0]\ngrid_learn = [.01, .03, .05, .1, .25]\ngrid_max_depth = [2, 4, 6, 8, 10, None]\ngrid_min_samples = [5, 10, .03, .05, .10]\ngrid_criterion = ['gini', 'entropy']\ngrid_bool = [True, False]\ngrid_seed = [0]\n\ngrid_param = [\n    # Adaboost Classifier\n    [{\n        'n_estimators': grid_n_estimator, #default=50\n            'learning_rate': grid_learn, #default=1\n            #'algorithm': ['SAMME', 'SAMME.R'], #default=â€™SAMME.R\n            'random_state': grid_seed\n    }],\n    \n    # Bagging Classifier\n    [{'n_estimators': grid_n_estimator,\n      'max_samples': grid_ratio,\n      'random_state': grid_seed\n    }],\n    \n    # ExtraTreesClassifier\n    [{'n_estimators': grid_n_estimator,\n      'criterion': grid_criterion,\n      'max_depth': grid_max_depth,\n      'random_state': grid_seed\n    }],\n    \n    # GradientBoostingClassifier\n    [{'learning_rate': grid_learn,\n      'n_estimators': grid_n_estimator,\n      'max_depth': grid_max_depth,\n      'random_state': grid_seed\n    }],\n    \n    # RandomForestClassifier\n    [{'n_estimators': grid_n_estimator,\n      'criterion': grid_criterion,\n      'max_depth': grid_max_depth,\n      'oob_score': [True],\n      'random_state': grid_seed\n    }],\n    \n    # GaussianProcessClassifier\n    [{'max_iter_predict': grid_n_estimator,\n    'random_state': grid_seed\n     }],\n    \n    # Logistic Regression\n    [{'fit_intercept': grid_bool,\n      'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n      'random_state': grid_seed\n    }],\n    \n    # BernoulliNB\n    [{'alpha': grid_ratio\n    }],\n    \n    # GaussianNB\n    [{}],\n    \n    # K Nearest Neighbours\n    [{'n_neighbors': [1,2,3,4,5,6,7],\n      'weights': ['uniform', 'distance'],\n      'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n    }],\n    \n    # SVM\n    [{'C': [1,2,3,4,5],\n      'gamma': grid_ratio,\n      'decision_function_shape': ['ovo', 'ovr'],\n      'probability': [True],\n      'random_state': grid_seed\n    }],\n    \n    #XGBoost\n    [{'learning_rate': grid_learn,\n      'max_depth': [1,2,4,6,8,10],\n      'n_estimators': grid_n_estimator,\n      'seed': grid_seed\n    }]\n]\n\n\nstart_total = time.perf_counter()\nfor clf, param in zip(vote_est, grid_param):\n    \n    start = time.perf_counter()\n    best_search = model_selection.GridSearchCV(estimator=clf[1], param_grid=param, cv=cv_split, scoring='roc_auc')\n    best_search.fit(data1[data1_x_bin], data1[Target])\n    run = time.perf_counter() - start\n    \n    best_param = best_search.best_params_\n    print('The best parameter for {} is {}, runtime: {:.2f} seconds.'.format(clf[1].__class__.__name__, best_param, run))\n    clf[1].set_params(**best_param)\n    \nrun_total = time.perf_counter() - start_total\nprint('Total optimization time is {:.2f} minutes'.format(run_total/60))\nprint('-'*60)","execution_count":27,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"16e86093f28782288ae10544035d89fb1dbe09bb"},"cell_type":"code","source":"# Create a hard vote ensemble (majority rules)\ngrid_hard = ensemble.VotingClassifier(vote_est, voting='hard', n_jobs=-1)\ngrid_hard_cv = model_selection.cross_validate(grid_hard, data1[data1_x_bin], data1[Target], cv=cv_split)\ngrid_hard.fit(data1[data1_x_bin], data1[Target])\n\n# Print out results for vote hard classifier\nprint('Hard voting (tuned hyperparameters) training score mean: {:.2f}'.format(grid_hard_cv['train_score'].mean()*100))\nprint('Hard voting (tuned hyperparameters) test score mean: {:.2f}'.format(grid_hard_cv['test_score'].mean()*100))\nprint('Hard voting (tuned hyperparameters) 3*std: +/- {:.2f}'.format(grid_hard_cv['test_score'].std()*100*3))\nprint('-'* 60)\n\n# Create a soft vote ensemble (weighted probabilities)\ngrid_soft = ensemble.VotingClassifier(vote_est, voting='soft', n_jobs=-1)\ngrid_soft_cv = model_selection.cross_validate(grid_soft, data1[data1_x_bin], data1[Target], cv= cv_split)\ngrid_soft.fit(data1[data1_x_bin], data1[Target])\n\n# Print out results for soft voting classifer\nprint('Soft voting (tuned hyperparameters) training score mean: {:.2f}'.format(grid_soft_cv['train_score'].mean()*100))\nprint('Soft voting (tuned hyperparameters) test score mean: {:.2f}'.format(grid_soft_cv['test_score'].mean()*100))\nprint('Soft voting (tuned hyperparameters) 3*std: +/- {:.2f}'.format(grid_soft_cv['test_score'].std()*100*3))","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"b0fd1259ed11a7470e31dbaa03a0e005be3aea8b"},"cell_type":"markdown","source":"**The tuned hard vote ensemble gives us the best test score of 82.50. Select this model on the data to predict new observations.** "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}