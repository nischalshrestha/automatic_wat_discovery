{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "dd8a53bf-cf98-5679-f842-2d89f38b1bb3"
      },
      "source": [
        "# Practicing feature selection with the Titanic database\n",
        "# modified from https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "410d89c2-3743-3b46-29f7-557c4dc94cae"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re as re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c7f49e69-6c1f-ada0-378c-9ed0b62d5655"
      },
      "outputs": [],
      "source": [
        "# GET DATA\n",
        "train = pd.read_csv('../input/train.csv', header = 0, dtype={'Age': np.float64})\n",
        "test  = pd.read_csv('../input/test.csv' , header = 0, dtype={'Age': np.float64})\n",
        "full_data = [train, test]\n",
        "\n",
        "# ADD TITLE DESCRIPTOR\n",
        "def get_title(name):\n",
        "\ttitle_search = re.search(' ([A-Za-z]+)\\.', name)\n",
        "\t# If the title exists, extract and return it.\n",
        "\tif title_search:\n",
        "\t\treturn title_search.group(1)\n",
        "\treturn \"\"\n",
        "for dataset in full_data:\n",
        "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
        "    \n",
        "for dataset in full_data:\n",
        "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
        " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "\n",
        "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
        "    \n",
        "# FILL WITH MOST LIKELY VALUE (MOST LIKELY FOR ALL ORIGINS)    \n",
        "for dataset in full_data:\n",
        "    dataset['Embarked'] = dataset['Embarked'].fillna('S')    \n",
        "    \n",
        "# INTEGERIZE DATA\n",
        "for dataset in full_data:\n",
        "    # Mapping Name\n",
        "    dataset[\"Name\"]=dataset[\"Name\"].map(lambda x: len(x))\n",
        "    \n",
        "    # Mapping Sex\n",
        "    dataset['Sex'] = dataset['Sex'].map( {'female': 2, 'male': 1} ).astype(int)\n",
        "    \n",
        "    # Mapping titles\n",
        "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
        "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
        "    dataset['Title'] = dataset['Title'].fillna(0)\n",
        "\n",
        "    # MAPPING EMBARKED\n",
        "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
        "    \n",
        "    t=dataset.Ticket.values\n",
        "    for i in range(len(t)):\n",
        "        try:\n",
        "            t[i]=int(t[i].strip().split()[-1])\n",
        "        except:\n",
        "            t[i]=0\n",
        "passengers=test[\"PassengerId\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "332b7405-67f4-5b95-95fb-f94c149ae835"
      },
      "outputs": [],
      "source": [
        "# FILL GAPS AND REGULARIZE\n",
        "def fillgaps(column1,column2,train,test):\n",
        "    \"\"\"FILL COLUMN2 WITH MOST LIKELY VALUES BASED ON COLUMN1\"\"\"\n",
        "    ddict={}\n",
        "    d1=test[[column1,column2]].dropna().values\n",
        "    d2=train[[column1,column2]].dropna().values\n",
        "    c1=np.array(d1[:,0].tolist()+d2[:,0].tolist())\n",
        "    c2=np.array(d1[:,1].tolist()+d2[:,1].tolist())\n",
        "    for ic1 in np.unique(c1):\n",
        "        ddict[ic1]=(c2[c1==ic1].mean(),c2[c1==ic1].std())\n",
        "    full_data = [train, test]\n",
        "    for dataset in full_data:\n",
        "        for missing in np.where(np.isnan(dataset[column2]))[0]:\n",
        "            m,s=ddict[dataset[column1][missing]]\n",
        "            if s<=0:\n",
        "                dataset[column2][missing]=m\n",
        "            else:\n",
        "                dataset[column2][missing]=np.random.normal(loc=m,scale=s,size=1)\n",
        "    return (train,test)\n",
        "train,test=fillgaps(\"SibSp\",\"Age\",train,test)\n",
        "train,test=fillgaps(\"Pclass\",\"Fare\",train,test)\n",
        "print(train.info())\n",
        "print(test.info())\n",
        "full_data=[train,test]\n",
        "tm=max(np.max(train.Ticket.values),np.max(test.Ticket.values))\n",
        "for dataset in full_data:\n",
        "    w=np.where(dataset.Ticket==0)[0]    \n",
        "    for i in w:\n",
        "        dataset.Ticket[w]=dataset.Ticket.median()\n",
        "    dataset.Ticket=dataset.Ticket/tm\n",
        "    dataset.Ticket=dataset.Ticket.map(lambda x: float(100*x)).astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5c3400d8-b0ca-19d1-3691-a4f3e848f0a0"
      },
      "outputs": [],
      "source": [
        "# GENERATE BETTER DESCRIPTORS\n",
        "full_data = [train, test]\n",
        "for dataset in full_data:\n",
        "    dataset[\"Familial Uniqueness\"]= np.exp(-dataset.Age/5.)*dataset.Pclass/(dataset['SibSp'] + dataset['Parch'] + 1)\n",
        "    dataset[\"Familial Uniqueness\"]=dataset[\"Familial Uniqueness\"].map(lambda x: float(20*x))\n",
        "    dataset[\"Detail oriented nature\"]=dataset.Name/dataset.Sex\n",
        "    dataset[\"Detail oriented nature\"]=dataset[\"Detail oriented nature\"].map(lambda x: float(x))\n",
        "    ms=np.array([dataset.Fare[dataset.Pclass==i].mean() for i in np.unique(dataset.Pclass)])\n",
        "    dataset.Fare=1.*dataset.Fare//ms[dataset.Pclass-1]\n",
        "    dataset.Fare=dataset.Fare.map(lambda x: float(x))\n",
        "    dataset.Age=dataset.Age.map(lambda x: float(x))\n",
        "print(train.info())\n",
        "print(test.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2f338196-0809-2469-b2c5-8c8015353502"
      },
      "outputs": [],
      "source": [
        "#DROP OLD PREDICTORS\n",
        "\n",
        "# Feature Selection\n",
        "drop_elements = [\"Cabin\",\"PassengerId\"]\n",
        "#drop_elements = ['SibSp','Parch',\"Cabin\",\"PassengerId\",\"Ticket\"]\n",
        "dtrain = train.drop(drop_elements, axis = 1)\n",
        "dtest  = test.drop(drop_elements, axis = 1)\n",
        "\n",
        "print(dtrain.info())\n",
        "print(dtest.info())\n",
        "\n",
        "dtrain = dtrain.values\n",
        "dtest  = dtest.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8867b5e7-319b-38d2-664d-193004cf0bcc"
      },
      "outputs": [],
      "source": [
        "classifiers = [\n",
        "    KNeighborsClassifier(5),\n",
        "    SVC(probability=True),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GradientBoostingClassifier(),\n",
        "    GaussianNB(),\n",
        "    LinearDiscriminantAnalysis(),\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "    LogisticRegression()]\n",
        "\n",
        "log_cols = [\"Classifier\", \"Accuracy\"]\n",
        "log  = pd.DataFrame(columns=log_cols)\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n",
        "\n",
        "X = dtrain[0::, 1::]\n",
        "y = dtrain[0::, 0]\n",
        "\n",
        "acc_dict = {}\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "\tX_train, X_test = X[train_index], X[test_index]\n",
        "\ty_train, y_test = y[train_index], y[test_index]\n",
        "\t\n",
        "\tfor clf in classifiers:\n",
        "\t\tname = clf.__class__.__name__\n",
        "\t\tclf.fit(X_train, y_train)\n",
        "\t\ttrain_predictions = clf.predict(X_test)\n",
        "\t\tacc = accuracy_score(y_test, train_predictions)\n",
        "\t\tif name in acc_dict:\n",
        "\t\t\tacc_dict[name] += acc\n",
        "\t\telse:\n",
        "\t\t\tacc_dict[name] = acc\n",
        "\n",
        "for clf in acc_dict:\n",
        "\tacc_dict[clf] = acc_dict[clf] / 10.0\n",
        "\tlog_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=log_cols)\n",
        "\tlog = log.append(log_entry)\n",
        "\n",
        "plt.xlabel('Accuracy')\n",
        "plt.title('Classifier Accuracy')\n",
        "\n",
        "sns.set_color_codes(\"muted\")\n",
        "sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"r\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cb9f152c-bc00-7c67-8eb3-957aa64436ae"
      },
      "outputs": [],
      "source": [
        "candidate_classifier=GradientBoostingClassifier()\n",
        "candidate_classifier.fit(dtrain[0::, 1::], dtrain[0::, 0])\n",
        "result = candidate_classifier.predict(dtest)\n",
        "output=open(\"results.csv\",'w')\n",
        "output.write(\"PassengerId,Survived\\n\")\n",
        "for p,r in zip(passengers,result):\n",
        "    output.write(\"{:},{:}\\n\".format(p,int(r)))\n",
        "output.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "827f3eb2-8219-7ec7-5a52-05cac9339b73"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}