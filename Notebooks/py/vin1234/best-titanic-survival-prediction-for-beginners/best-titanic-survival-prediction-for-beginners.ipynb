{"cells":[{"metadata":{"_cell_guid":"b6c4f4e8-7e39-45a7-947f-f53102224e06","_uuid":"18ad5c404b9f95496a3137b0217a223c3d64dfaf"},"cell_type":"markdown","source":"<h1 style='text-align:center'>Titanic.</h1>\n![](http://media.giphy.com/media/1Nk9bIidJVTy0/giphy.gif)\n\n<br>\n\n**Titanic** is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the **Titanic** sank after colliding with an iceberg, killing *1502* out of *2224* passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.<br><br>\n\n**What particularly we need do in this challange ?**\n\nIn this challenge, we need to complete the analysis of what sorts of people were likely to survive. In particular,  we apply the tools of machine learning to predict which passengers survived the tragedy?.\n\n\n<h2>If you are using the kaggle first time</h2>\n\nThis github link is for \n<a href='https://github.com/vikramvinay/Titanic-Machine-Learning-from-Disaster'>Beginners  who try first time kaggle</a>\n\nIn this github link i  basically explains all the thing that i did when i begin first time with kaggle .So this one just gives you the kind of connect that you need when you begin with kaggle. It will also enhance your knowledge.\n\nTo use this github repository fork it and use it and try to gain most of it.\n"},{"metadata":{"_cell_guid":"9b36c71d-a9fe-41b0-bb14-3805ab662a7e","_uuid":"270acc34e8c6ae2195f3c566b46ed4b03887142c"},"cell_type":"markdown","source":"**Importing the data**"},{"metadata":{"_cell_guid":"c0951611-1d3a-4231-b236-f184265b3d17","_uuid":"d25b701d54ac0fe6aa0c406ccb3eabaf0480265a","collapsed":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split,GridSearchCV\n\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nlabel=LabelEncoder()\n%matplotlib inline\n","execution_count":330,"outputs":[]},{"metadata":{"_cell_guid":"1a0aa0c3-b276-42ed-87f1-0a92c7862d6a","_uuid":"934c060affbb030f8bc85a395ff1a9b70186923e","collapsed":true},"cell_type":"markdown","source":"<h3>What does this data set mean.</h3>\n____"},{"metadata":{"_cell_guid":"37cbb7e9-ef04-4592-a2e1-b1b3995c7d5e","_uuid":"cd5e6fa5db8d58838845ef106833ed314cbc8615"},"cell_type":"markdown","source":"The data has been split into two groups:\n- training set (train.csv)\n- test set(test.csv)\n<br>\n\nThe training set includes passengers survival status(also know as the ground truth from the titanic tragedy) which along with other features like gender, class, fare and pclass is used to create machine learning model.\n<br><br>\nThe test set should be used to see how well my model performs on unseen data. The test set does not provide passengers survival status. We are going to use our model to predict passenger survival status.\n<br><br>\n\nLets describe whats the meaning of the features given the both train & test datasets.\n<h4>Variable Definition Key.</h4>\n- Survival\n - 0= No\n - 1= Yes\n- pclass (Ticket class)\n - 1=1st\n - 2=2nd\n - 3=3rd\n \n- sex\n<br>\n\n- age\n\n\n- sibsp (# of siblings / spouses aboard the Titanic)\n<br>\n- parch (# of parents / children aboard the Titanic)\n<br>\n- tickets\n<br>\n- fare\n<br>\n- cabin\n- embarked Port of Embarkation.\n - C = Cherbourg,\n - Q = Queenstown,\n - S = Southampton\n- pclass: A proxy for socio-economic status (SES)\n<br>\n<h4>This is important to remember and will come in handy for later analysis.</h4>\n - 1st = Upper\n - 2nd = Middle\n - 3rd = Lower\n"},{"metadata":{"_cell_guid":"f95fbbe3-220a-4eca-8a95-3482e31bce15","_uuid":"02610423c5e01f8f4eda88abb88836ff0e2ebd08","collapsed":true},"cell_type":"markdown","source":"## Cleaning the data."},{"metadata":{"_cell_guid":"11e51c0a-b93d-407b-930a-a04e5df18ecb","_uuid":"c56e9091dce4f62ebad385ef62ba52d3e3745e0b"},"cell_type":"markdown","source":"It looks like this dataset is quite organized, however, before using this dataset for analyzing and visualizing we need to deal with ..\n- Different variables\n- Null values\n\n## Different variables present in the datasets.\n - **There are four type of variables**\n  - **Numerical Features**: Age, Fare, SibSp and Parch\n  - **Categorical Features**: Sex, Embarked, Survived and Pclass\n  - **Alphanumeric Features**: Ticket and Cabin(Contains both alphabets and the numeric value)\n  - **Text Features**: Name\n\n** We really need to tweak these features so we get the desired form of input data**"},{"metadata":{"_cell_guid":"6303e80b-51a3-417f-ad09-3bd4ee2fa9bb","_uuid":"20aec52aee70e301b73073a5ab0d1ee9238e15f2"},"cell_type":"markdown","source":"We see Age  and Cabin have a lot of missing value.So First we need to deal with all these NaN values.\n- As in Cabin column about 1\\3rd of the values are missing.So we get rid of this column. \n<br>\n\n## Why missing values treatment is required?\nMissing data in the training data set can reduce the power / fit of a model or can lead to a biased model because we have not analysed the behavior and relationship with other variables correctly. It can lead to wrong prediction or classification.\n\n\n"},{"metadata":{"_cell_guid":"6035fac2-a333-4635-bc71-32f061d314ce","_uuid":"1938b387a7eadd91ca5daa4bd5127af0f184625c","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import Imputer\n\ntrain_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\n#As test has only one missing value so lets fill it..\ntest_df.Fare.fillna(test_df.Fare.mean(), inplace=True)\ndata_df = train_df.append(test_df) # The entire data: train + test.\npassenger_id=test_df['PassengerId']\n\n## We will drop PassengerID and Ticket since it will be useless for our data. \ntrain_df.drop(['PassengerId'], axis=1, inplace=True)\ntest_df.drop(['PassengerId'], axis=1, inplace=True)\ntest_df.shape","execution_count":331,"outputs":[]},{"metadata":{"_cell_guid":"c961f507-605f-4249-81ba-e9af7ca1c35b","_uuid":"8cbc093d5f1c55b85e99f9a64f00a9061ee94ef1","collapsed":true},"cell_type":"markdown","source":"|**Dealing with Missing values**"},{"metadata":{"_cell_guid":"08215d03-81a5-46ab-92ac-ad99d2d70cf9","_uuid":"83dfd8413cfc271e93ced15e6f28b870a2bc3f7b","trusted":true},"cell_type":"code","source":"print (train_df.isnull().sum())\nprint (''.center(20, \"*\"))\nprint (test_df.isnull().sum())\nsns.boxplot(x='Survived',y='Fare',data=train_df)","execution_count":332,"outputs":[]},{"metadata":{"_cell_guid":"5f13e257-4a0b-4ab9-bd6e-a0ac44b4eadf","_uuid":"2aa47fffcf801838d5fbbce232a64255056c47c8","collapsed":true},"cell_type":"markdown","source":"**Transforming Sex**"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"96aaf15e6e8fbcc99d584c39cb9692d1f8d53e64"},"cell_type":"code","source":"train_df=train_df[train_df['Fare']<400]","execution_count":333,"outputs":[]},{"metadata":{"_cell_guid":"60211aab-2460-461c-83a9-477c44efbf9e","_uuid":"73f517a6704a0cc1f131a4b9fc577eb1b71a2bf5","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df['Sex'] = train_df.Sex.apply(lambda x: 0 if x == \"female\" else 1)\ntest_df['Sex'] = test_df.Sex.apply(lambda x: 0 if x == \"female\" else 1)","execution_count":334,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fcd8aa7c65f04bd455a31336089e12fbfa5e81d"},"cell_type":"code","source":"train_df","execution_count":335,"outputs":[]},{"metadata":{"_cell_guid":"87fb6e61-be55-45f3-9da1-a279be250aa6","_uuid":"596e0a74fb1a655b2331e5c65f86b67cde05bae7","trusted":true},"cell_type":"code","source":"pd.options.display.max_columns = 99\ntest_df['Fare'].fillna(test_df['Fare'].mean(),inplace=True)\ntrain_df.head()\n","execution_count":336,"outputs":[]},{"metadata":{"_cell_guid":"deb2caf0-04ba-4ace-b782-7beb803eca59","_uuid":"112c84520482541f5bd01ea16b02cc66c66f3832"},"cell_type":"markdown","source":"**Treating Missing age**"},{"metadata":{"_cell_guid":"7f46ba4b-1ab3-4c64-b297-1a45f27cabde","_uuid":"3ff3c7095e6600b6cb69b4b45ea66b3d41c80eff","trusted":true},"cell_type":"code","source":"for name_string in data_df['Name']:\n    data_df['Title']=data_df['Name'].str.extract('([A-Za-z]+)\\.',expand=True)\n    \n    \n\n#replacing the rare title with more common one.\nmapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr', 'Don': 'Mr', 'Mme': 'Miss',\n          'Jonkheer': 'Mr', 'Lady': 'Mrs', 'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\ndata_df.replace({'Title': mapping}, inplace=True)\n\ndata_df['Title'].value_counts()\ntrain_df['Title']=data_df['Title'][:891]\ntest_df['Title']=data_df['Title'][891:]\n\ntitles=['Mr','Miss','Mrs','Master','Rev','Dr']\nfor title in titles:\n    age_to_impute = data_df.groupby('Title')['Age'].median()[titles.index(title)]\n    #print(age_to_impute)\n    data_df.loc[(data_df['Age'].isnull()) & (data_df['Title'] == title), 'Age'] = age_to_impute\ndata_df.isnull().sum()\n\n\n\ntrain_df['Age']=data_df['Age'][:891]\ntest_df['Age']=data_df['Age'][891:]\ntest_df.isnull().sum()","execution_count":337,"outputs":[]},{"metadata":{"_cell_guid":"0c01fc62-96a4-44c2-92c2-8c8dcd2bd251","_uuid":"88c1ccccad1ac346a13a1f403184e10c027830aa"},"cell_type":"markdown","source":"<h2>Exploratory data analysis.</h2>\n![](http://media.giphy.com/media/m3UHHYejQ4rug/giphy.gif)\n\n**Exploratory data analysis (EDA)** is an approach to analyzing data sets to summarize their main characteristics, often with visual methods."},{"metadata":{"_cell_guid":"35793d15-0af7-4c30-b75e-48da66fa3070","_uuid":"a1213b1abcb5104f65f45693784a76d27ce5adec","trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":338,"outputs":[]},{"metadata":{"_cell_guid":"befcb476-181a-4a91-9f8e-6dc7d06055ac","_uuid":"ac2c72a7c2033dd3f61a786adca6f15fea2a3eeb","trusted":true},"cell_type":"code","source":"train_df.groupby('Survived').mean()","execution_count":339,"outputs":[]},{"metadata":{"_cell_guid":"ce395185-6d00-447d-8275-727b451b33e4","_uuid":"12abdfaf98fb2e3e99965527d26512c22aae0759","trusted":true},"cell_type":"code","source":"train_df.groupby('Sex').mean()","execution_count":340,"outputs":[]},{"metadata":{"_cell_guid":"d3f165b7-42b7-46d9-8a94-cbb662b309d6","_uuid":"2c9b5668d5e573185803ae15afbf629717564495"},"cell_type":"markdown","source":"There are a couple of points that should be noted from the statistical overview. They are..\n- About the survival rate, only 38% passenger survived during that tragedy.\n- About the survival rate for genders, 74% female passengers survived, while only 19% male passengers survived."},{"metadata":{"_cell_guid":"04a93127-72ed-4b0a-a7f8-d8f0702954eb","_uuid":"d16437166a565755eb05d46af30e91e1337205f2"},"cell_type":"markdown","source":"**Correlation Matrix and Heatmap**"},{"metadata":{"_cell_guid":"5fc9fdde-d681-4fd8-a37a-508bdbfa1000","_uuid":"2f9089390ead6f65b11c4228ee4ff3b730e98b49","trusted":true},"cell_type":"code","source":"train_df.corr()","execution_count":341,"outputs":[]},{"metadata":{"_cell_guid":"16090a1b-18df-42f9-b86b-a5586ad2aac1","_uuid":"b43ebc10e3de5bece6e40d9689a93ce7e1bb8390","trusted":true},"cell_type":"code","source":"plt.subplots(figsize = (15,8))\nsns.heatmap(train_df.corr(), annot=True,cmap=\"PiYG\")\nplt.title(\"Correlations Among Features\", fontsize = 20)","execution_count":342,"outputs":[]},{"metadata":{"_cell_guid":"1e426599-0321-4f6b-ac5f-007293a439ed","_uuid":"7adfc1e0a299997874c72f9552cfb060b10a7319"},"cell_type":"markdown","source":"**Positive Correlation Features:**\n- Fare and Survived: 0.26.\n\nThere is a positive correlation between Fare and Survived rated. This can be explained by saying that, the passenger who paid more money for their ticket were more likely to survive. "},{"metadata":{"_cell_guid":"f669afbe-1e70-4481-9d48-fa153ce56347","_uuid":"25912ce6ca47e5b0be4479ce18e17e8ac67bd9b1"},"cell_type":"markdown","source":"**Negative Correlation Features:**\n- Fare and Pclass: -0.55\n - This relationship can be explained by saying that first class passenger(1) paid more for fare then second class passenger(2), similarly second class passenger paid more than the third class passenger(3). \n- Gender and Survived: -0.54\n - Basically is the info of whether the passenger was male or female.\n- Pclass and Survived: -0.34"},{"metadata":{"_cell_guid":"1c4c383d-695d-40d9-bfaa-9e33df5b59d5","_uuid":"914e000313042274f77bc800534e1bbc29bb42c2"},"cell_type":"markdown","source":"**Gender and Survived**\n"},{"metadata":{"_cell_guid":"2c855f0b-55ef-4d62-b3ac-619616957a38","_uuid":"052a2dcf2a9768a8ab2ec6dd848502b1b63e6484","trusted":true},"cell_type":"code","source":"plt.subplots(figsize = (15,8))\nsns.barplot(x = \"Sex\", y = \"Survived\", data=train_df, edgecolor=(0,0,0), linewidth=2)\nplt.title(\"Survived/Non-Survived Passenger Gender Distribution\", fontsize = 25)\nlabels = ['Female', 'Male']\nplt.ylabel(\"% of passenger survived\", fontsize = 15)\nplt.xlabel(\"Gender\",fontsize = 15)\nplt.xticks(sorted(train_df.Sex.unique()), labels)\n\n# 1 is for male and 0 is for female.","execution_count":343,"outputs":[]},{"metadata":{"_cell_guid":"d0bec67e-0780-4da9-b83e-4d0519937e46","_uuid":"c313cc247f55c72e3893f38510cb1b0314cd1cf6"},"cell_type":"markdown","source":"This bar plot above shows the distribution of female and male survived. The x_label shows gender and the y_label shows % of passenger survived. This bar plot shows that 74% female passenger survived while only ~19% male passenger survived."},{"metadata":{"_cell_guid":"d941afb5-1dfc-4afa-9f7a-4582f350f602","_uuid":"57df5542d820aaa271eec30418539924cedf6dce","trusted":true},"cell_type":"code","source":"sns.set(style='darkgrid')\nplt.subplots(figsize = (15,8))\nax=sns.countplot(x='Sex',data=train_df,hue='Survived',edgecolor=(0,0,0),linewidth=2)\ntrain_df.shape\n## Fixing title, xlabel and ylabel\nplt.title('Passenger distribution of survived vs not-survived',fontsize=25)\nplt.xlabel('Gender',fontsize=15)\nplt.ylabel(\"# of Passenger Survived\", fontsize = 15)\nlabels = ['Female', 'Male']\n#Fixing xticks.\nplt.xticks(sorted(train_df.Survived.unique()),labels)\n## Fixing legends\nleg = ax.get_legend()\nleg.set_title('Survived')\nlegs=leg.texts\nlegs[0].set_text('No')\nlegs[1].set_text('Yes')\n","execution_count":344,"outputs":[]},{"metadata":{"_cell_guid":"3c538f80-c4c9-40db-ad9e-73f040896979","_uuid":"dd99171a2f134b1427ee1d2fdcfb5cc67d4b7e00"},"cell_type":"markdown","source":"This count plot shows the actual distribution of male and female passengers that survived and did not survive. It shows that among all the females ~ 230 survived and ~ 70 did not survive. While among male passengers ~110 survived and ~480 did not survive."},{"metadata":{"_cell_guid":"16977c5d-1f8c-45d5-968c-c0ee6f05f4ee","_uuid":"a5caf4a2a419be5f33ef8d25f45fe4f4cdef7c0d"},"cell_type":"markdown","source":"**Summary**\n- As we suspected, female passengers have survived at a much better rate than male passengers.\n- It seems about right since females and children were the priority."},{"metadata":{"_cell_guid":"0a0116bb-7ba9-4674-aecf-5071c4654504","_uuid":"656f31ef9e68f638c53e86800959dfbab73146d8"},"cell_type":"markdown","source":"**Pclass and Survived**"},{"metadata":{"_cell_guid":"a4b0721b-9b73-4ce7-a603-4a6452937fb9","_uuid":"2f4fc3528ab919f3c1f4feabfafffad0c8df8f41","trusted":true},"cell_type":"code","source":"plt.subplots(figsize = (8,8))\nax=sns.countplot(x='Pclass',hue='Survived',data=train_df)\nplt.title(\"Passenger Class Distribution - Survived vs Non-Survived\", fontsize = 25)\nleg=ax.get_legend()\nleg.set_title('Survival')\nlegs=leg.texts\n\nlegs[0].set_text('No')\nlegs[1].set_text(\"yes\")","execution_count":345,"outputs":[]},{"metadata":{"_cell_guid":"c4d33abf-7e9b-4e51-bb71-083433f2842b","_uuid":"c1b5a8e631da65a89e17c720ebd34188ffa86ae6"},"cell_type":"markdown","source":"So it clearly seems that,The survival of the people belong to 3rd class is very least.\nIt looks like ...\n-  63% first class passenger survived titanic tragedy, while\n-  48% second class and\n-  only 24% third class passenger survived."},{"metadata":{"_cell_guid":"ae90e165-2447-4874-a134-b598d1cf1d66","_uuid":"9fc1e7f34be0b4ccef6fe8cca67af458e8685675","trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(10,8))\nsns.kdeplot(train_df.loc[(train_df['Survived'] == 0),'Pclass'],shade=True,color='r',label='Not Survived')\nax=sns.kdeplot(train_df.loc[(train_df['Survived'] == 1),'Pclass'],shade=True,color='b',label='Survived' )\n\nlabels = ['First', 'Second', 'Third']\nplt.xticks(sorted(train_df.Pclass.unique()),labels)","execution_count":346,"outputs":[]},{"metadata":{"_cell_guid":"41198dd6-df4b-4141-9ac6-231587cd5dfc","_uuid":"7abfa2c32147c87da4f14168c8d97347a88906fc"},"cell_type":"markdown","source":"This kde plot is pretty self explanatory with all the labels and colors. Something I have noticed that some readers might find questionable is that in, the plot; the third class passengers have survived more than second class passnegers. It is true since there were a lot more third class passengers than first and second.\n\n"},{"metadata":{"_cell_guid":"b62a0e18-82b2-4504-9638-52d24a0f8f19","_uuid":"5911ebd52d73575f2387de5fc12d7bb773f535c9"},"cell_type":"markdown","source":"**Summary**\n\nFirst class passenger had the upper hand during the tragedy than second and third class passengers. You can probably agree with me more on this, when we look at the distribution of ticket fare and survived column."},{"metadata":{"_cell_guid":"2e021638-f2a3-4135-b256-5f233113b6e3","_uuid":"4daef6e2a23fb60c039419033df2f41647694826"},"cell_type":"markdown","source":"**Fare and Survived**"},{"metadata":{"_cell_guid":"d5acbedb-b208-4902-8689-774165f32580","_uuid":"d861942b6956508110365331a86102cb47272164","trusted":true},"cell_type":"code","source":"plt.subplots(figsize=(15,10))\n\nax=sns.kdeplot(train_df.loc[(train_df['Survived'] == 0),'Fare'],color='r',shade=True,label='Not Survived')\nax=sns.kdeplot(train_df.loc[(train_df['Survived'] == 1),'Fare'],color='b',shade=True,label='Survived' )\nplt.title('Fare Distribution Survived vs Non Survived',fontsize=25)\nplt.ylabel('Frequency of Passenger Survived',fontsize=20)\nplt.xlabel('Fare',fontsize=20)","execution_count":347,"outputs":[]},{"metadata":{"_cell_guid":"a5c09770-06af-40e4-b2e2-9b7c0db3a9de","_uuid":"6afe4c82340eb2c955d7a115f18f063126aaecd8","trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":348,"outputs":[]},{"metadata":{"_cell_guid":"f4c533f3-55bd-4bb3-8600-a7ce66e5e93d","_uuid":"7971d529bdc11a14b69dbc4618a0410fbd8668be"},"cell_type":"markdown","source":"**Age and Survived**"},{"metadata":{"_cell_guid":"86c2804f-860f-4fdc-8776-9a210a93621e","_uuid":"1c300367f4319500e5c8612106779cdfd5d5072d","trusted":true},"cell_type":"code","source":"#fig,axs=plt.subplots(nrows=2)\nfig,axs=plt.subplots(figsize=(10,8))\nsns.set_style(style='darkgrid')\nsns.kdeplot(train_df.loc[(train_df['Survived']==0),'Age'],color='r',shade=True,label='Not Survived')\nsns.kdeplot(train_df.loc[(train_df['Survived']==1),'Age'],color='b',shade=True,label='Survived')\n","execution_count":349,"outputs":[]},{"metadata":{"_cell_guid":"eb1f2f16-def3-4d19-b704-811bbc25c72c","_uuid":"3a789a48830f2e10c265b98260db51061dce0517"},"cell_type":"markdown","source":"There is nothing out of the ordinary of about this plot, except the very left part of the distribution. It shows that\n\nchildren and infants were the priority."},{"metadata":{"_cell_guid":"12f48d08-4713-4c5a-865b-b72f5eb9bff3","_uuid":"16cddb293471f69a4bb22bd7380386460424728f"},"cell_type":"markdown","source":"<h2>Feature Engineering</h2>"},{"metadata":{"_cell_guid":"ea2e1b9f-4d55-4fd2-8b2d-3180d3a03289","_uuid":"49645a739b3e59778cb92392fa787a787cd6b051","trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":350,"outputs":[]},{"metadata":{"_cell_guid":"7139adcc-cf98-47be-b39b-196ab3b784b9","_uuid":"024fdc05d5871bf394532e1d9a8cc7ee7116d6fb","collapsed":true},"cell_type":"markdown","source":"**family_size feature**"},{"metadata":{"_cell_guid":"f6e08596-a185-4ea7-919c-b1f2e4133dd1","_uuid":"f1c514491911b86dac10104854baf9dccdc65100","collapsed":true,"trusted":true},"cell_type":"code","source":"## Family_size seems like a good feature to create\ntrain_df['family_size'] = train_df.SibSp + train_df.Parch+1\ntest_df['family_size'] = test_df.SibSp + test_df.Parch+1\n","execution_count":351,"outputs":[]},{"metadata":{"_cell_guid":"c30bd0d7-17b6-43b8-aa23-36a50abaa03a","_uuid":"a3b3f821f31565db9f5d77cf9181f6cac7f50ffd","collapsed":true,"trusted":true},"cell_type":"code","source":"def family_group(size):\n    a = ''\n    if (size <= 1):\n        a = 'loner'\n    elif (size <= 4):\n        a = 'small'\n    else:\n        a = 'large'\n    return a\n\ntrain_df['family_group'] = train_df['family_size'].map(family_group)\ntest_df['family_group'] = test_df['family_size'].map(family_group)","execution_count":352,"outputs":[]},{"metadata":{"_cell_guid":"2cb3fc55-a9d9-48d4-9510-4ae5c2a220bb","_uuid":"d9bb8fc0201011b71208b1d503132500349c0c18"},"cell_type":"markdown","source":"**Is_alone feature**"},{"metadata":{"_cell_guid":"ff4a88fd-0125-4077-83f4-94a91d4042b0","_uuid":"d92ba0d6e1750aa8086252a3b2b69c1e84b96746","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df['is_alone'] = [1 if i<2 else 0 for i in train_df.family_size]\ntest_df['is_alone'] = [1 if i<2 else 0 for i in test_df.family_size]","execution_count":353,"outputs":[]},{"metadata":{"_cell_guid":"8d42849e-d169-4f09-a3ca-80610d57fdfc","_uuid":"e1dde219e7cefd274d249c23bbbec8e55812eaaa"},"cell_type":"markdown","source":"**child feature**"},{"metadata":{"_cell_guid":"f1590241-6e4f-46e0-a80d-9cfbed40cd53","_uuid":"d7e91154a98a8d1437d5f56d4467f410be759e50","trusted":true},"cell_type":"code","source":"## We are going to create a new feature \"age\" from the Age feature. \ntrain_df['child'] = [1 if i<16 else 0 for i in train_df.Age]\ntest_df['child'] = [1 if i<16 else 0 for i in test_df.Age]\ntrain_df.child.value_counts()","execution_count":354,"outputs":[]},{"metadata":{"_cell_guid":"0ffba383-3ad5-4c0d-9003-bc74dde2da48","_uuid":"f3a9f40665de7620e215f07617a19b7674b5dbe4"},"cell_type":"markdown","source":"\n**fare feature**"},{"metadata":{"_cell_guid":"305a1f4f-86f5-4a76-b597-0234fbaa43e4","_uuid":"89ebecbd23a61a98b81d6c410c1da3de9f147b89","trusted":true},"cell_type":"code","source":"train_df.head()\n#test_df.head()","execution_count":355,"outputs":[]},{"metadata":{"_cell_guid":"a4393220-eee2-47b4-bff1-633dbc1dd560","_uuid":"66dfaa765056f4ec26edbf9a302c49eb3ac13689"},"cell_type":"markdown","source":"**calculated_fare feature**"},{"metadata":{"_cell_guid":"86acada0-c9aa-41f0-82bb-849827f2f276","_uuid":"e158e3a883bd2c41ad2438a355681a3a86bf8afb","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df['calculated_fare'] = train_df.Fare/train_df.family_size\ntest_df['calculated_fare'] = test_df.Fare/test_df.family_size\n","execution_count":356,"outputs":[]},{"metadata":{"_cell_guid":"847baa1f-0120-4be5-bc71-e1cc45e51003","_uuid":"a7155eb7274018a301e451a548edbf76f7b3b076","trusted":true},"cell_type":"code","source":"train_df.calculated_fare.mean()","execution_count":357,"outputs":[]},{"metadata":{"_cell_guid":"06cf50bf-00d9-413f-9486-fe1d300b1704","_uuid":"12c51de669b24e2d20540c265d50435cc0e6af63","trusted":true},"cell_type":"code","source":"train_df.calculated_fare.mode()","execution_count":358,"outputs":[]},{"metadata":{"_cell_guid":"45db24ea-65a4-478e-b255-0a41f0bd764f","_uuid":"26de5c4c179c5c386d0d183fad03418ba38b4496","collapsed":true,"trusted":true},"cell_type":"code","source":"def fare_group(fare):\n    a= ''\n    if fare <= 4:\n        a = 'Very_low'\n    elif fare <= 10:\n        a = 'low'\n    elif fare <= 20:\n        a = 'mid'\n    elif fare <= 45:\n        a = 'high'\n    else:\n        a = \"very_high\"\n    return a\n","execution_count":359,"outputs":[]},{"metadata":{"_cell_guid":"d9fa86c9-5fc2-4b48-81d4-c456722b8c04","_uuid":"9d60e2b94aff4c3ea286c9c0d196e5a0ffe4e165","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df['fare_group'] = train_df['calculated_fare'].map(fare_group)\ntest_df['fare_group'] = test_df['calculated_fare'].map(fare_group)","execution_count":360,"outputs":[]},{"metadata":{"_cell_guid":"c4e78e94-401e-4721-8302-69119d7ed55f","_uuid":"0e4a1ca25f0aac8e947e2315cc1345790feb9931"},"cell_type":"markdown","source":"**Creating dummy variables**"},{"metadata":{"_cell_guid":"b616c14f-067f-4ae3-bd64-cc739a54c203","_uuid":"99b06518780e4ed1164ca377564b1677a17cd028","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df = pd.get_dummies(train_df, columns=['Title',\"Pclass\",'Embarked', 'family_group', 'fare_group'], drop_first=True)\ntest_df = pd.get_dummies(test_df, columns=['Title',\"Pclass\",'Embarked', 'family_group', 'fare_group'], drop_first=True)\ntrain_df.drop(['Cabin', 'family_size','Ticket','Name', 'Fare'], axis=1, inplace=True)\ntest_df.drop(['Ticket','Name','family_size',\"Fare\",'Cabin'], axis=1, inplace=True)\n","execution_count":361,"outputs":[]},{"metadata":{"_cell_guid":"e33fc358-caa0-4877-9765-fec26948f828","_uuid":"b0a532e05264acc8bb52059138ac224f41598fd4","collapsed":true,"trusted":true},"cell_type":"code","source":"pd.options.display.max_columns = 99\n","execution_count":362,"outputs":[]},{"metadata":{"_cell_guid":"d18a6c60-c97b-40e2-9a07-96a02dbd91de","_uuid":"0b6b6c9e358686bf140b2222cbd8e531a9198635","collapsed":true,"trusted":true},"cell_type":"code","source":"def age_group_fun(age):\n    a = ''\n    if age <= 1:\n        a = 'infant'\n    elif age <= 4: \n        a = 'toddler'\n    elif age <= 13:\n        a = 'child'\n    elif age <= 18:\n        a = 'teenager'\n    elif age <= 35:\n        a = 'Young_Adult'\n    elif age <= 45:\n        a = 'adult'\n    elif age <= 55:\n        a = 'middle_aged'\n    elif age <= 65:\n        a = 'senior_citizen'\n    else:\n        a = 'old'\n    return a\n        ","execution_count":363,"outputs":[]},{"metadata":{"_cell_guid":"8286b453-ae8d-4e44-a909-e7db3c64f16a","_uuid":"b42af7b368724a894590a577b8efc85e972d598d","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df['age_group'] = train_df['Age'].map(age_group_fun)\ntest_df['age_group'] = test_df['Age'].map(age_group_fun)","execution_count":364,"outputs":[]},{"metadata":{"_cell_guid":"2fa2f956-2349-4671-8e17-6ed040e33660","_uuid":"2fcf41b6d5a6dddb75595528d5d1a6083bf8d7ae","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df = pd.get_dummies(train_df,columns=['age_group'], drop_first=True)\ntest_df = pd.get_dummies(test_df,columns=['age_group'], drop_first=True)\n#Lets try all after dropping few of the column.\ntrain_df.drop(['Age','calculated_fare'],axis=1,inplace=True)\ntest_df.drop(['Age','calculated_fare'],axis=1,inplace=True)","execution_count":365,"outputs":[]},{"metadata":{"_cell_guid":"359dda98-af21-4fa2-9d89-f803396e2a5c","_uuid":"41f6405f22b2ad4bdde499090062289dc2679c3a","collapsed":true,"trusted":true},"cell_type":"code","source":"#age=pd.cut(data_df['Age'],4)\n#data_df['Age2']=label.fit_transform(age)\n#fare=pd.cut(data_df['Fare'],4)\n#data_df['Fare2']=label.fit_transform(fare)\n#train_df['Age']=data_df['Age2'][:891]\n#train_df['Fare']=data_df['Fare2'][:891]\n#test_df['Age']=data_df['Age2'][891:]\n#test_df['Fare']=data_df['Fare2'][891:]\n#train_df = pd.get_dummies(train_df,columns=['Age','Fare'], drop_first=True)\n#test_df = pd.get_dummies(test_df,columns=['Age','Fare'], drop_first=True)\n#print(test_df.shape)\n#print(train_df.shape)\ntrain_df.head()\n\ntrain_df.drop(['Title_Rev','age_group_old','age_group_teenager','age_group_senior_citizen','Embarked_Q'],axis=1,inplace=True)\ntest_df.drop(['Title_Rev','age_group_old','age_group_teenager','age_group_senior_citizen','Embarked_Q'],axis=1,inplace=True)","execution_count":366,"outputs":[]},{"metadata":{"_cell_guid":"17826e7f-e38c-4758-910a-5592984403d8","_uuid":"5805fd4ecfbedcb62dbede8bc0cb1396476b4b77"},"cell_type":"markdown","source":"**Modeling the Data**"},{"metadata":{"_cell_guid":"2398e3cd-fee8-4caa-a87c-acc476cafd45","_uuid":"ac39a9dfe0a93e89a916b9e22589ef4d62deb190"},"cell_type":"markdown","source":"I will train the data with the following models:\n- Logistic Regression\n- Gaussian Naive Bayes\n- Support Vector Machines\n- Decision Tree Classifier\n- K-Nearest Neighbors(KNN)\n -  and many other.....\n \n"},{"metadata":{"_cell_guid":"1334fb63-e866-4e9d-8f38-d1e28d6e990d","_uuid":"41fa09a4ac77a434a77cae3aaa0f87b6ee375823","collapsed":true,"trusted":true},"cell_type":"code","source":"X = train_df.drop('Survived', 1)\ny = train_df['Survived']\n#testing = test_df.copy()\n#testing.shape","execution_count":367,"outputs":[]},{"metadata":{"_cell_guid":"25e07e4b-968d-4eab-8d25-6e6d6cefbb9e","_uuid":"08760fea0a8a0fb50e7304a5ba47a888540ca3c6"},"cell_type":"markdown","source":"<h2>Classifier Comparision</h2>\n\nBy Classifier Comparison we choose which model best for the given data."},{"metadata":{"_cell_guid":"6bb0b633-7e74-44a7-a3b3-41b671cfa3ca","_uuid":"0c0dff8ade89a5dd57a3ac940911bb41b7072914","collapsed":true,"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedShuffleSplit,train_test_split\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import svm\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    svm.SVC(probability=True),\n    DecisionTreeClassifier(),\n    XGBClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    GaussianNB(),\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis(),\n    LogisticRegression()]\n    \n\n\nlog_cols = [\"Classifier\", \"Accuracy\"]\nlog= pd.DataFrame(columns=log_cols)\n","execution_count":368,"outputs":[]},{"metadata":{"_cell_guid":"d5baaf6f-b931-4052-bdd8-6c63e27bee32","_uuid":"89d4751cf93bc58e6760cc9a8005df7a1a059760","trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n\nSSplit=StratifiedShuffleSplit(test_size=0.3,random_state=7)\nacc_dict = {}\n\nfor train_index,test_index in SSplit.split(X,y):\n    X_train,X_test=X.iloc[train_index],X.iloc[test_index]\n    y_train,y_test=y.iloc[train_index],y.iloc[test_index]\n    \n    for clf in classifiers:\n        name = clf.__class__.__name__\n          \n        clf.fit(X_train,y_train)\n        predict=clf.predict(X_test)\n        acc=accuracy_score(y_test,predict)\n        if name in acc_dict:\n            acc_dict[name]+=acc\n        else:\n            acc_dict[name]=acc\n\n\n","execution_count":369,"outputs":[]},{"metadata":{"_cell_guid":"ef001bec-a26a-4f4f-852d-d28886ccd9e6","_uuid":"8814357358d1eb8aded51d2805ed9702655915fa","trusted":true},"cell_type":"code","source":"\nlog['Classifier']=acc_dict.keys()\nlog['Accuracy']=acc_dict.values()\n#log.set_index([[0,1,2,3,4,5,6,7,8,9]])\n%matplotlib inline\nsns.set_color_codes(\"muted\")\nax=plt.subplots(figsize=(10,8))\nax=sns.barplot(y='Classifier',x='Accuracy',data=log,color='b')\nax.set_xlabel('Accuracy',fontsize=20)\nplt.ylabel('Classifier',fontsize=20)\nplt.grid(color='r', linestyle='-', linewidth=0.5)\nplt.title('Classifier Accuracy',fontsize=20)\n","execution_count":370,"outputs":[]},{"metadata":{"_cell_guid":"4d2380f3-33a9-4565-8471-0327ac33d7c6","_uuid":"6985746450177e2b1b1616532987e63c3cb26c2d"},"cell_type":"markdown","source":"From the above barplot, we can clearly see that the following classifiers are good-\n- LogisticRegression\n- XGBClassifier\n- AdaBoostClassifier\n- GradiendBoostingClassifier \n- LDA\n\n** Note-**\n\nThe spliting of the test and train data is randomly done so possibility of getting different set of Best classifier that may be differ from mine one.\n\n\nBut While you running multiple time one a general scale. The given set of classifier used in this kernal are proved to be good one."},{"metadata":{"_cell_guid":"a33d93d7-bafa-42cf-8319-de9a61233c36","_uuid":"76b79e031843f5625ef82c4f7b36450504a8ee68","collapsed":true,"trusted":true},"cell_type":"code","source":"## Necessary modules for creating models. \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.metrics import accuracy_score,classification_report, precision_recall_curve, confusion_matrix","execution_count":371,"outputs":[]},{"metadata":{"_cell_guid":"52882ff1-4517-47a9-ac97-3ca38440e3fc","_uuid":"d2b06234512bb5cd32d8a12243587634c4b5f0b7"},"cell_type":"markdown","source":"**Scaling features**"},{"metadata":{"_cell_guid":"ab1c0a94-8acc-4faf-937d-12b1c73bfed9","_uuid":"dfccb3c1f53070d126930df8382f540877db9d59","trusted":true},"cell_type":"code","source":"\nstd_scaler = StandardScaler()\nX = std_scaler.fit_transform(X)\ntestframe = std_scaler.fit_transform(test_df)\ntestframe.shape\n","execution_count":372,"outputs":[]},{"metadata":{"_cell_guid":"a600a9c3-6f10-4dc7-aea2-a325b98fd08d","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"6db481bb17be157f42d582cf085be7b66fdaaab1","collapsed":true},"cell_type":"markdown","source":"**GridSearch**\n\nUsing the GridSearch ,Lets find out the most suitable parameter/hyperparmeter which gives the best result.\n"},{"metadata":{"_cell_guid":"11cd4228-401e-4d1a-9b0a-5813291fae8d","_uuid":"90d3f4693a54a9ade722ee3231561959a9fe2331","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=1000)","execution_count":373,"outputs":[]},{"metadata":{"_cell_guid":"ee20340f-eaae-46a4-86cf-d5205e163b3a","_uuid":"a60288b7f58056b6cf5a2b78aee9c97a844d2548","collapsed":true},"cell_type":"markdown","source":"**LogisticRegression**"},{"metadata":{"_cell_guid":"a1c2c093-3c2f-4c8a-8250-e1cf7a1db2a2","_uuid":"b693d9183d9b6df6f64b488bcae0e64945ae3fb3","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import precision_score,recall_score,confusion_matrix\nlogreg = LogisticRegression(solver='liblinear', penalty='l1')\nlogreg.fit(X_train,y_train)\npredict=logreg.predict(X_test)\nprint(accuracy_score(y_test,predict))\nprint(confusion_matrix(y_test,predict))\nprint(precision_score(y_test,predict))\nprint(recall_score(y_test,predict))","execution_count":374,"outputs":[]},{"metadata":{"_cell_guid":"3fceec2e-1516-4207-a51c-24945e3a8b12","_uuid":"63766bc3dca8582e82a272440c1d36b560256da9","collapsed":true},"cell_type":"markdown","source":"**Grid Search on Logistic Regression**"},{"metadata":{"_cell_guid":"7a6cdeba-c26e-4fc2-9fbc-8dd7a96816e9","_uuid":"1184044b8c06ca04cf1d576ba2605d346988a76c","collapsed":true,"trusted":true},"cell_type":"code","source":"C_vals = [0.0001, 0.001, 0.01, 0.1,0.13,0.2, .15, .25, .275, .33, 0.5, .66, 0.75, 1.0, 2.5, 4.0,4.5,5.0,5.1,5.5,6.0, 10.0, 100.0, 1000.0]\npenalties = ['l1','l2']\n\nparam = {'penalty': penalties, 'C': C_vals, }\ngrid = GridSearchCV(logreg, param,verbose=False, cv = StratifiedKFold(n_splits=5,random_state=10,shuffle=True), n_jobs=1,scoring='accuracy')","execution_count":375,"outputs":[]},{"metadata":{"_cell_guid":"46449a22-946b-429c-9de3-fa1553491668","_uuid":"317c2ebd79ea95a7b2ba6cafe116486ceca7b419","trusted":true},"cell_type":"code","source":"grid.fit(X_train,y_train)\nprint (grid.best_params_)\nprint (grid.best_score_)\nprint(grid.best_estimator_)","execution_count":376,"outputs":[]},{"metadata":{"_cell_guid":"10c20afa-d6b5-4cf5-a455-0e917585a34d","_uuid":"35959515e3f1988beea63b8f0609de548c35c293","trusted":true},"cell_type":"code","source":"#grid.best_estimator_.fit(X_train,y_train)\n#predict=grid.best_estimator_.predict(X_test)\n#print(accuracy_score(y_test,predict))\nlogreg_grid = LogisticRegression(penalty=grid.best_params_['penalty'], C=grid.best_params_['C'])\nlogreg_grid.fit(X_train,y_train)\ny_pred = logreg_grid.predict(X_test)\nlogreg_accy = round(accuracy_score(y_test, y_pred), 3)\nprint (logreg_accy)\nprint(confusion_matrix(y_test,y_pred))\nprint(precision_score(y_test,y_pred))\nprint(recall_score(y_test,y_pred))","execution_count":377,"outputs":[]},{"metadata":{"_cell_guid":"a6bd01a5-a7c6-4f73-9c06-d9c3493a72c0","_uuid":"14faeeb8451c864b4bdf73ca99adef8bca4fb606"},"cell_type":"markdown","source":"**AdaBoostClassifer**"},{"metadata":{"_cell_guid":"9a5c474e-d7b9-48bd-8c33-da502fe046f1","_uuid":"2ffa8236665af7abf494142e8103a7dd293b4767","trusted":true},"cell_type":"code","source":"ABC=AdaBoostClassifier()\n\nABC.fit(X_train,y_train)\npredict=ABC.predict(X_test)\nprint(accuracy_score(y_test,predict))\nprint(confusion_matrix(y_test,predict))\nprint(precision_score(y_test,predict))\n","execution_count":378,"outputs":[]},{"metadata":{"_cell_guid":"78a22369-7aef-4f6c-9076-a626861a22e3","_uuid":"8701f7b2acaa8681f4f62aec86f5b58a4f89f36c"},"cell_type":"markdown","source":"**GridSearch on AdaBoostClassifer**"},{"metadata":{"_cell_guid":"0c0988a0-3db5-4a6b-8d7f-127a539f2314","_uuid":"a648e6444201cb1894e118af2dc67b51bb5fed80","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nn_estimator=[50,60,100,150,200,300]\nlearning_rate=[0.001,0.01,0.1,0.2,]\nhyperparam={'n_estimators':n_estimator,'learning_rate':learning_rate}\ngridBoost=GridSearchCV(ABC,param_grid=hyperparam,verbose=False, cv = StratifiedKFold(n_splits=5,random_state=15,shuffle=True), n_jobs=1,scoring='accuracy')","execution_count":379,"outputs":[]},{"metadata":{"_cell_guid":"f8f83245-7a89-46e8-a86e-4a69b6ca752b","_uuid":"663489f72445a438ad4d0e1707ae286506dfd5a6","trusted":true},"cell_type":"code","source":"gridBoost.fit(X_train,y_train)\nprint(gridBoost.best_score_)\nprint(gridBoost.best_estimator_)","execution_count":380,"outputs":[]},{"metadata":{"_cell_guid":"ea767975-77a4-4ab0-a539-63da18065ba6","_uuid":"6614ff1861446298d98760ae2fafe5b7b5655593","trusted":true},"cell_type":"code","source":"gridBoost.best_estimator_.fit(X_train,y_train)\npredict=gridBoost.best_estimator_.predict(X_test)\nprint(accuracy_score(y_test,predict))\n","execution_count":381,"outputs":[]},{"metadata":{"_cell_guid":"44039859-e6ed-4b7f-b8da-1678ccad926d","_uuid":"164f81900d494d0cf5b739b0e61cfff030273282"},"cell_type":"markdown","source":"**XGBClassifier**"},{"metadata":{"_cell_guid":"cdfce682-2aac-448a-a443-257d70c9d84a","_uuid":"974a1c2aa67c934e44e106516af765ca9f32e204","trusted":true},"cell_type":"code","source":"xgb=XGBClassifier(max_depth=2, n_estimators=700, learning_rate=0.009,nthread=-1,subsample=1,colsample_bytree=0.8)\nxgb.fit(X_train,y_train)\npredict=xgb.predict(X_test)\nprint(accuracy_score(y_test,predict))\nprint(confusion_matrix(y_test,predict))\nprint(precision_score(y_test,predict))\nprint(recall_score(y_test,predict))","execution_count":382,"outputs":[]},{"metadata":{"_cell_guid":"a25392fe-01d6-47f8-9baa-1f07deae733e","_uuid":"ab39cf4b9d920cdc3e6b95a8feb5a14cbee1a7af","trusted":true},"cell_type":"code","source":"lda=LinearDiscriminantAnalysis()\nlda.fit(X_train,y_train)\npredict=lda.predict(X_test)\nprint(accuracy_score(y_test,predict))\nprint(precision_score(y_test,predict))\nprint(recall_score(y_test,predict))","execution_count":383,"outputs":[]},{"metadata":{"_cell_guid":"cff36b91-8a98-4a22-a4bd-df7904fe1b0b","_uuid":"1932a3680e05bbfb4d49b9033ad7fca97dc1c875"},"cell_type":"markdown","source":"**DecisionTree Classifier**"},{"metadata":{"_cell_guid":"3fea5cbd-2b65-44b8-b036-aa007d100918","_uuid":"3759d91d097af1da3bf5d6b1193052483a9b9cfd","trusted":true},"cell_type":"code","source":"#Decision Tree\n#Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\n\ndectree = DecisionTreeClassifier( criterion=\"entropy\",\n                                 max_depth=5,\n                                class_weight = 'balanced',\n                                min_weight_fraction_leaf = 0.009,\n                                random_state=2000)\ndectree.fit(X_train, y_train)\ny_pred = dectree.predict(X_test)\ndectree_accy = round(accuracy_score(y_pred, y_test), 3)\nprint(dectree_accy)\nprint(confusion_matrix(y_test,y_pred))\nprint(precision_score(y_test,y_pred))\nprint(recall_score(y_test,y_pred))\n","execution_count":384,"outputs":[]},{"metadata":{"_cell_guid":"53a182d0-6c9a-4f4a-b3e4-e51312271b46","_uuid":"b82397c35bb8fe0c7ba9e959f92e641a4738b958"},"cell_type":"markdown","source":"**Random Forest Classifier**\n"},{"metadata":{"_cell_guid":"9be95697-a631-458e-821f-3ebb4c3f331a","_uuid":"1f3ba533eb7b73e1f081cb766d41ec1848e6aa83","trusted":true},"cell_type":"code","source":"#from sklearn.ensemble import RandomForestClassifier\n#from sklearn.metrics import precision_score,recall_score,confusion_matrix\n#randomforest = RandomForestClassifier(n_estimators=100,max_depth=9,min_samples_split=6, min_samples_leaf=4)\n##randomforest = RandomForestClassifier(class_weight='balanced', n_jobs=-1)\n#randomforest.fit(X_train, y_train)\n#y_pred = randomforest.predict(X_test)\n#random_accy = round(accuracy_score(y_pred, y_test), 3)\n#print (random_accy)\n#print(confusion_matrix(y_test,y_pred))\nfrom sklearn.ensemble import RandomForestClassifier\nrandomforest = RandomForestClassifier(n_estimators=100,max_depth=5,min_samples_split=20,max_features=0.2, min_samples_leaf=8,random_state=20)\n#randomforest = RandomForestClassifier(class_weight='balanced', n_jobs=-1)\nrandomforest.fit(X_train, y_train)\ny_pred = randomforest.predict(X_test)\nrandom_accy = round(accuracy_score(y_pred, y_test), 3)\nprint (random_accy)\nprint(precision_score(y_test,y_pred))\nprint(recall_score(y_test,y_pred))\nprint(confusion_matrix(y_test,y_pred))\n","execution_count":385,"outputs":[]},{"metadata":{"_cell_guid":"627a3de7-fa8c-4f79-bfb5-d10c38db0b32","_uuid":"182523756cf2e65355a408d17e2a2a7fbcbc1be0"},"cell_type":"markdown","source":"**Bagging Classifier**\n"},{"metadata":{"_cell_guid":"49d9057f-1b91-4645-98e0-ba7a051a049d","_uuid":"bdb1d5756214b4e67b3cbb8277ab101477224e7e","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\nBaggingClassifier = BaggingClassifier()\nBaggingClassifier.fit(X_train, y_train)\ny_pred = BaggingClassifier.predict(X_test)\nbagging_accy = round(accuracy_score(y_pred, y_test), 3)\nprint(bagging_accy)","execution_count":386,"outputs":[]},{"metadata":{"_cell_guid":"fc1485f6-0b8f-440a-a689-c6283c079992","_uuid":"10f1cf8d83a9ce2e1bce5672e61bf19d2a6e1bd7"},"cell_type":"markdown","source":"**Voting Classifier**"},{"metadata":{"_cell_guid":"bc378611-9e5e-41f5-be64-d1b3da08f90e","_uuid":"a9b2e6195f182d52c8bf4f964f586da2896febbe","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\nvoting_classifier = VotingClassifier(estimators=[\n    ('logreg',logreg), \n    ('random_forest', randomforest),\n    ('decision_tree',dectree), \n    ('XGB Classifier', xgb),\n    ('BaggingClassifier', BaggingClassifier)])\nvoting_classifier.fit(X_train,y_train)\ny_pred = voting_classifier.predict(X_test)\nvoting_accy = round(accuracy_score(y_pred, y_test), 3)\nprint(voting_accy)\n   \n","execution_count":387,"outputs":[]},{"metadata":{"_cell_guid":"bd51899e-e019-4ad6-b6f5-c271eaba2e66","_uuid":"9d3037e004a3eaf75fb74ea0dc6ce3ee1e85e960","collapsed":true,"trusted":true},"cell_type":"code","source":"y_predict=randomforest.predict(testframe)\n","execution_count":388,"outputs":[]},{"metadata":{"_cell_guid":"7e751c61-769f-4011-87cf-c33b6707e5cb","_uuid":"204144a66bfa445087bee6fa61999b32142a9172"},"cell_type":"markdown","source":"**  Submit test predictions**\n\nThe given parameter is used in the  model  is found through grid search which is not shown in the code .\n\nAs it took a lot long to run ."},{"metadata":{"_cell_guid":"b3f1a4ee-ac6d-4ffc-992e-f3c18e04776a","_uuid":"e29ea2a49533f555bf91cccc73c832c93a1ce068","collapsed":true,"trusted":true},"cell_type":"code","source":"temp = pd.DataFrame(pd.DataFrame({\n        \"PassengerId\": passenger_id,\n        \"Survived\": y_predict\n    }))\n\n\ntemp.to_csv(\"../working/submission3.csv\", index = False)","execution_count":389,"outputs":[]},{"metadata":{"_cell_guid":"53813456-7437-48ed-9c2c-e917a68b760f","_uuid":"546fed63f1766e072e1d62bfc23af49a4a793e15"},"cell_type":"markdown","source":"**This kernal is still under  process for further imporvement.**\n\nI will always incorporate new concepts of data science as I master them. This journey of learning is worth sharing as well as collaborating. "},{"metadata":{"_cell_guid":"309c5cce-7a62-4e76-a5f1-d687d4bd65fb","_uuid":"5d2405058d6ff19ed2736c7578c9e3968d83836f"},"cell_type":"markdown","source":"**Any comments about further improvements   to kernel would be genuinely appreciated.**\n\n**Feel free to raise any doubt  in comment section regarding the kernel.**"},{"metadata":{"_cell_guid":"e022ce0c-15f2-4365-b07c-9ba51f4011fd","_uuid":"8640b4a2262c2738142396a3b43967be814917b1"},"cell_type":"markdown","source":"**Hope you find it useful.** \n\n**If this notebook helped you in anyway, please do upvote!**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}