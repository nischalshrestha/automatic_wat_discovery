{"cells":[{"metadata":{"_uuid":"01e073921691336f558603a9e676378334318c5c"},"cell_type":"markdown","source":"## Summary\n* fork of the [Random Forest](https://www.kaggle.com/bubblride/titanic-random-forest-4-phonetic) version\n* insteadt XGBoost is used\n* `Name` data is ignored, see [reasons here](https://www.kaggle.com/bubblride/titanic-feature-from-name)\n\n\n## Load Modules"},{"metadata":{"trusted":true,"_uuid":"3329bec06bab80ac8360b11e38f231794ee545ac","scrolled":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3d406d7d7d672d0fa356398f1811b92bdd249aa"},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"trusted":true,"_uuid":"94c5051d523247108bb95b20401454c226716591"},"cell_type":"code","source":"df = pd.read_csv(\"../input/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36c5809a3d200562b8e7ecaced97b3533288e6aa"},"cell_type":"markdown","source":"## Prep Data\n"},{"metadata":{"trusted":true,"_uuid":"a1edf37b3f26fd563c83da92575b7f53d331d8e7"},"cell_type":"code","source":"def transform(df0, clu=None, vec=None):\n    df = pd.DataFrame(index=df0.index)\n    \n    # Pclass - use the 3 labels and missing (999)\n    df['Pclass'] = df0['Pclass'].apply(lambda e: 999 if pd.isnull(e) else e)\n    \n    # Gender - male, female, missing (99)\n    df['Sex'] = 999\n    df.loc[df0['Sex']=='male', 'Sex'] = 2\n    df.loc[df0['Sex']=='female', 'Sex'] = 1\n    \n    # Age - number or missing (999)\n    df['Age'] = df0['Age'].apply(lambda e: 999 if pd.isnull(e) else e)\n    \n    # SibSp - number or missing (999)\n    df['SibSp'] = df0['SibSp'].apply(lambda e: 999 if pd.isnull(e) else e)\n\n    # Parch - number or missing (999)\n    df['Parch'] = df0['Parch'].apply(lambda e: 999 if pd.isnull(e) else e)\n    \n    # Ticket - Is numbered ticket (True) or contain strings (False)\n    df['Ticket'] = [int(str.isnumeric(e)) for e in df0.Ticket]\n    \n    # Fare - keep the numeric values or missing (-999)\n    df['Fare'] = df0['Fare'].apply(lambda e: -999 if pd.isnull(e) else e)\n    \n    # Cabin - 'C', 'E', 'G', 'D', 'A', 'B', 'F', 'T', missing (999)\n    tmp = pd.DataFrame(df0['Cabin'])\n    tmp.loc[df0['Cabin'].isnull(), 'Cabin'] = '?9999'\n    tmp['Deck'] = [e[0] for e in tmp['Cabin']]\n    tmp['Section'] = [e[1:].split(' ')[0] for e in tmp['Cabin']]\n    \n    df['Deck'] = 999\n    df.loc[tmp['Deck']=='A', 'Deck'] = 1 \n    df.loc[tmp['Deck']=='B', 'Deck'] = 2 \n    df.loc[tmp['Deck']=='C', 'Deck'] = 3 \n    df.loc[tmp['Deck']=='D', 'Deck'] = 4 \n    df.loc[tmp['Deck']=='E', 'Deck'] = 5 \n    df.loc[tmp['Deck']=='F', 'Deck'] = 6 \n    df.loc[tmp['Deck']=='G', 'Deck'] = 7 \n    df.loc[tmp['Deck']=='T', 'Deck'] = 8\n    \n    df['Section'] = np.trunc(pd.to_numeric(tmp['Section']).values / 10)\n    df.loc[df['Section'].isnull(), 'Section'] = 999\n    \n    # Embarked - S, C, Q, missing (999)\n    df['Embarked'] = 999\n    df.loc[df0['Embarked']=='S', 'Embarked'] = 1 \n    df.loc[df0['Embarked']=='C', 'Embarked'] = 2\n    df.loc[df0['Embarked']=='Q', 'Embarked'] = 3\n    \n    # done\n    return df, clu, vec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1edf37b3f26fd563c83da92575b7f53d331d8e7"},"cell_type":"code","source":"y = df['Survived'].values \n\ndf2, clu, vec = transform(df)\nx = df2.values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1adc9b97a904c8526128482af5a98b8cd5562db"},"cell_type":"markdown","source":"Find the best model"},{"metadata":{"trusted":true,"_uuid":"ab6d74677dd0ce275f40c23af238c737ceb6d323"},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f24d5fb25153d098ba34e577b827d98d2be127ba"},"cell_type":"code","source":"hyperparam = {\n    #'learning_rate': (np.exp(0.05 * np.arange(1, 7)) - 1).round(2),\n    #'max_depth': np.arange(3, 29, 4),\n    #'n_estimators': [100,150,200],\n    #'objective': ['binary:logistic'],\n    #'booster': ['gbtree', 'dart'],\n    #'gamma': np.arange(0, .2, .02),\n    #'min_child_weight': np.arange(0.8, 1.5, .1),\n    #'max_delta_step': [0, .1, .2],\n    #'subsample': np.arange(.5, .91, .1),\n    #'colsample_bytree': np.arange(.5, .91, .1),\n    #'reg_alpha': np.arange(0, 1.11, .1),\n    #'reg_lambda': np.arange(0, 1.11, .1)\n}\n\nopti = GridSearchCV(\n    estimator = XGBClassifier(\n        learning_rate=0.11, #eta learning rate (0.3)\n        max_depth=7, #max num of levels (9)\n        n_estimators=100,  #number of trees\n        objective='binary:logistic',  #type of target func\n        booster='gbtree', #type of model\n        gamma=0.12,  #minimum loss reduction on a leaf (0.0)\n        min_child_weight=1.25, #min sum of wgt per child (1.0), set >1 to underfit\n        max_delta_step=0, #set >0 for more conservative weight updates\n        subsample=.5, #pct of obs part of random subsamples (1.0)\n        colsample_bytree=.7, #max pct of features used in sub-trees (1.0)\n        colsample_bylevel=1.0, #not necessary if you use subsample\n        reg_alpha=0.7, #L1 regulization param (0.0)\n        reg_lambda=1.0, #L2 regulization param (0.1)\n        scale_pos_weight=1, #balance positive and negative weights\n        base_score=0.5, #start values\n        random_state=23, #for resampling\n        n_jobs=-1,\n        silent=True\n    ), \n    param_grid = hyperparam, \n    cv = 25,\n    n_jobs = -1,\n    return_train_score = True)\n\nopti.fit(X=x, y=y)\n\nprint(opti.best_estimator_)\n\nprint(opti.best_params_)\n\nprint(opti.best_score_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a159677312034732b2638f74bc3dea1cf362b54"},"cell_type":"markdown","source":"Display the best model"},{"metadata":{"trusted":true,"_uuid":"eec31bc561201bd94083471b6058c2686f7c6b55"},"cell_type":"code","source":"bestmodel = opti.best_estimator_\nbestmodel.fit(X=x, y=y)\n\nprint( accuracy_score(y, bestmodel.predict(x)) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"531a2b91d5870ecc66c285b70f76db2c7fed501f"},"cell_type":"code","source":"pd.DataFrame((100*bestmodel.feature_importances_).round(1), \n             index=df2.columns, \n             columns=['Importance']).sort_values(by='Importance', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a28881e9d3fa074bf5267dad715dcca688230cf1"},"cell_type":"markdown","source":"## Predict and Submit\n"},{"metadata":{"trusted":true,"_uuid":"eb7db988158409f06f7a02945c1d2cf9c85f597d"},"cell_type":"code","source":"df = pd.read_csv('../input/test.csv')\ndf2, _, _ = transform(df, clu, vec)\nx = df2.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39d7bc3c185076a78be515f1736c8dae5f2304ad"},"cell_type":"code","source":"yhat = bestmodel.predict(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65e1cbbf9dbf35c76327ffaf007e5a40e75d0796"},"cell_type":"code","source":"result = pd.DataFrame(columns=['PassengerId', 'Survived'], index=df.index)\nresult['PassengerId'] = df['PassengerId']\nresult['Survived'] = yhat\nresult.to_csv('xgboost-noname.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}