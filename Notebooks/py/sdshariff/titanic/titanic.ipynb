{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n\n#visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n#ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e9849129838e0600da450451696dcfd76b0c268"},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\n\n#take a look at the training data\ntrain.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0640b85c49ff80ba8dfd66553f541300122ccc3a"},"cell_type":"code","source":"print(train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"840e87d8016b934e8e3c4493cf3c4c9af56017f1"},"cell_type":"code","source":"train.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d8b6342a91802b58cc41e20e5e52c1968a8bd58"},"cell_type":"code","source":"train.describe(include = \"all\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a78d3d08f16c4104a4bd09f57eb04a649d359a83"},"cell_type":"code","source":"print(pd.isnull(train).sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dccf3d7a3e74ca500f72221b8dc733403745c909"},"cell_type":"code","source":"#draw a bar plot of survival by sex\nsns.barplot(x=\"Sex\", y=\"Survived\", data=train)\n\n#print percentages of females vs. males that survive\nprint(\"Percentage of females who survived:\", train[\"Survived\"][train[\"Sex\"] == 'female'][train[\"Pclass\"] == 1].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of females who survived:\", train[\"Survived\"][train[\"Sex\"] == 'female'][train[\"Pclass\"] == 2].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of females who survived:\", train[\"Survived\"][train[\"Sex\"] == 'female'][train[\"Pclass\"] == 3].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of males who survived:\", train[\"Survived\"][train[\"Sex\"] == 'male'][train[\"Pclass\"] == 1].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of males who survived:\", train[\"Survived\"][train[\"Sex\"] == 'male'][train[\"Pclass\"] == 2].value_counts(normalize = True)[1]*100)\nprint(\"Percentage of males who survived:\", train[\"Survived\"][train[\"Sex\"] == 'female'][train[\"Pclass\"] == 3].value_counts(normalize = True)[1]*100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"623a24e72a5566ca99a0c4ec47175fd8b64078a9"},"cell_type":"code","source":"#draw a bar plot of survival by Pclass\nsns.barplot(x=\"Pclass\", y=\"Survived\", data=train)\n\n#print percentage of people by Pclass that survived\nprint(\"Percentage of Pclass = 1 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 1].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of Pclass = 2 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 2].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of Pclass = 3 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 3].value_counts(normalize = True)[1]*100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b5b0459e2a0f60caaf5d0b338ab37adc6df845c"},"cell_type":"code","source":"#draw a bar plot for SibSp vs. survival\nsns.barplot(x=\"SibSp\", y=\"Survived\", data=train)\n\n#I won't be printing individual percent values for all of these.\nprint(\"Percentage of SibSp = 0 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 0].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of SibSp = 1 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 1].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of SibSp = 2 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 2].value_counts(normalize = True)[1]*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2c6098f7249409868b3e02bdcc4e2babfe6fc60"},"cell_type":"code","source":"#draw a bar plot for Parch vs. survival\nsns.barplot(x=\"Parch\", y=\"Survived\", data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c16edec766eef89f9e627bd45448cc5cd746ff1"},"cell_type":"code","source":"#sort the ages into logical categories\ntrain[\"Age\"] = train[\"Age\"].fillna(-0.5)\ntest[\"Age\"] = test[\"Age\"].fillna(-0.5)\nbins = [-1, 0, 5, 12, 18, 24, 35, 60, np.inf]\nlabels = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ntrain['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = labels)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = labels)\n\n#draw a bar plot of Age vs. survival\nsns.barplot(x=\"AgeGroup\", y=\"Survived\", data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc66ce924faab468d7978bebd6b9010a0032a194"},"cell_type":"code","source":"train[\"CabinBool\"] = (train[\"Cabin\"].notnull().astype('int'))\ntest[\"CabinBool\"] = (test[\"Cabin\"].notnull().astype('int'))\n\n#calculate percentages of CabinBool vs. survived\nprint(\"Percentage of CabinBool = 1 who survived:\", train[\"Survived\"][train[\"CabinBool\"] == 1].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of CabinBool = 0 who survived:\", train[\"Survived\"][train[\"CabinBool\"] == 0].value_counts(normalize = True)[1]*100)\n#draw a bar plot of CabinBool vs. survival\nsns.barplot(x=\"CabinBool\", y=\"Survived\", data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"182f9a4f9c870af1b0fc265c69eb898d9dd7c8aa","collapsed":true},"cell_type":"code","source":"#Cleaning DataÂ¶\ntest.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"faf8b842438c6dd6a530693a9a5be5e3162fc233"},"cell_type":"code","source":"#we'll start off by dropping the Cabin feature since not a lot more useful information can be extracted from it.\ntrain = train.drop(['Cabin'], axis = 1)\ntest = test.drop(['Cabin'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b053bb1f4207d8fb07a21b47bb2c02d5a1bdfb0","collapsed":true},"cell_type":"code","source":"#we can also drop the Ticket feature since it's unlikely to yield any useful information\ntrain = train.drop(['Ticket'], axis = 1)\ntest = test.drop(['Ticket'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0225aecc1aa2d747104e857bcef421cc9a20183"},"cell_type":"code","source":"#now we need to fill in the missing values in the Embarked feature\nprint(\"Number of people embarking in Southampton (S):\")\nsouthampton = train[train[\"Embarked\"] == \"S\"].shape[0]\nprint(southampton)\n\nprint(\"Number of people embarking in Cherbourg (C):\")\ncherbourg = train[train[\"Embarked\"] == \"C\"].shape[0]\nprint(cherbourg)\n\nprint(\"Number of people embarking in Queenstown (Q):\")\nqueenstown = train[train[\"Embarked\"] == \"Q\"].shape[0]\nprint(queenstown)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07c575d7604354bed01b0eee899319ea6c93cbbf","collapsed":true},"cell_type":"code","source":"train = train.fillna({\"Embarked\": \"S\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a63f214736891721d118cf55d50d2bb7aa1be8f"},"cell_type":"code","source":"#create a combined group of both datasets\ncombine = [train, test]\n\n#extract a title for each Name in the train and test datasets\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train['Title'], train['Sex'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63c3380138ba38bbfbe55c7c2540d0bafa1af587"},"cell_type":"code","source":"#replace various titles with more common names\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Capt', 'Col',\n    'Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n    \n    dataset['Title'] = dataset['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\ntrain[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49fb4a964e765cdf917caaff4fe55d02e115d7bc"},"cell_type":"code","source":"#map each of the title groups to a numerical value\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 6}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c08964f4e17642f27a92b311d871b0cadc0432c8","collapsed":true},"cell_type":"code","source":"# fill missing age with mode age group for each title\nmr_age = train[train[\"Title\"] == 1][\"AgeGroup\"].mode() #Young Adult\nmiss_age = train[train[\"Title\"] == 2][\"AgeGroup\"].mode() #Student\nmrs_age = train[train[\"Title\"] == 3][\"AgeGroup\"].mode() #Adult\nmaster_age = train[train[\"Title\"] == 4][\"AgeGroup\"].mode() #Baby\nroyal_age = train[train[\"Title\"] == 5][\"AgeGroup\"].mode() #Adult\nrare_age = train[train[\"Title\"] == 6][\"AgeGroup\"].mode() #Adult\n\nage_title_mapping = {1: \"Young Adult\", 2: \"Student\", 3: \"Adult\", 4: \"Baby\", 5: \"Adult\", 6: \"Adult\"}\n\n#I tried to get this code to work with using .map(), but couldn't.\n#I've put down a less elegant, temporary solution for now.\n#train = train.fillna({\"Age\": train[\"Title\"].map(age_title_mapping)})\n#test = test.fillna({\"Age\": test[\"Title\"].map(age_title_mapping)})\n\nfor x in range(len(train[\"AgeGroup\"])):\n    if train[\"AgeGroup\"][x] == \"Unknown\":\n        train[\"AgeGroup\"][x] = age_title_mapping[train[\"Title\"][x]]\n        \nfor x in range(len(test[\"AgeGroup\"])):\n    if test[\"AgeGroup\"][x] == \"Unknown\":\n        test[\"AgeGroup\"][x] = age_title_mapping[test[\"Title\"][x]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f12233d816fc48f209e01795d8847c55b0ac38b"},"cell_type":"code","source":"#map each Age value to a numerical value\nage_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\ntrain['AgeGroup'] = train['AgeGroup'].map(age_mapping)\ntest['AgeGroup'] = test['AgeGroup'].map(age_mapping)\n\ntrain.head()\n\n#dropping the Age feature for now, might change\ntrain = train.drop(['Age'], axis = 1)\ntest = test.drop(['Age'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64a157010cfe83b32494542823272fc00dfe7d77","collapsed":true},"cell_type":"code","source":"#drop the name feature since it contains no more useful information.\ntrain = train.drop(['Name'], axis = 1)\ntest = test.drop(['Name'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f1323171d457660fb9ee3333eb03d47ecc2dd04"},"cell_type":"code","source":"#map each Sex value to a numerical value\nsex_mapping = {\"male\": 0, \"female\": 1}\ntrain['Sex'] = train['Sex'].map(sex_mapping)\ntest['Sex'] = test['Sex'].map(sex_mapping)\n\ntrain.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2988af038282319b0dd3e950a5c95263dcf5037d"},"cell_type":"code","source":"#map each Embarked value to a numerical value\nembarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\ntrain['Embarked'] = train['Embarked'].map(embarked_mapping)\ntest['Embarked'] = test['Embarked'].map(embarked_mapping)\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b8fa37ada1602d3de19651084ae7a4774446215","collapsed":true},"cell_type":"code","source":"#fill in missing Fare value in test set based on mean fare for that Pclass \nfor x in range(len(test[\"Fare\"])):\n    if pd.isnull(test[\"Fare\"][x]):\n        pclass = test[\"Pclass\"][x] #Pclass = 3\n        test[\"Fare\"][x] = round(train[train[\"Pclass\"] == pclass][\"Fare\"].mean(), 4)\n        \n#map Fare values into groups of numerical values\ntrain['FareBand'] = pd.qcut(train['Fare'], 4, labels = [1, 2, 3, 4])\ntest['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1, 2, 3, 4])\n\n#drop Fare values\ntrain = train.drop(['Fare'], axis = 1)\ntest = test.drop(['Fare'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"528743013e6a1e56b2d25934ecec3466c14abdb3"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea69dd86e396f1b653a651ec5a22a759dde33926","collapsed":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8164a0903f649dfa5bdfe41a72365f28074af9e2","collapsed":true},"cell_type":"code","source":"# Choosing the Best Model\n#Splitting the Training Data\nfrom sklearn.model_selection import train_test_split\n\npredictors = train.drop(['Survived', 'PassengerId'], axis=1)\ntarget = train[\"Survived\"]\nx_train, x_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.22, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca3733e9435d79574f79982c5fc28fc644fa986b"},"cell_type":"code","source":"# Gaussian Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\n\ngaussian = GaussianNB()\ngaussian.fit(x_train, y_train)\ny_pred = gaussian.predict(x_val)\nacc_gaussian = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_gaussian)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74d8207f1675c3b038fd5623fe12edf3ff151f00"},"cell_type":"code","source":"# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_val)\nacc_logreg = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_logreg)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1016804d997fb5b2e08e61485e9aa191695f59b4"},"cell_type":"code","source":"# Support Vector Machines\nfrom sklearn.svm import SVC\n\nsvc = SVC()\nsvc.fit(x_train, y_train)\ny_pred = svc.predict(x_val)\nacc_svc = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_svc)\nprint(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8577e58a2ca508100a3bbc811aacd16595b8394"},"cell_type":"code","source":"# Linear SVC\nfrom sklearn.svm import LinearSVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(x_train, y_train)\ny_pred = linear_svc.predict(x_val)\nacc_linear_svc = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_linear_svc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f28035696d51971ac0679db2e07f91119e20fbc"},"cell_type":"code","source":"# Perceptron\nfrom sklearn.linear_model import Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(x_train, y_train)\ny_pred = perceptron.predict(x_val)\nacc_perceptron = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_perceptron)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"987d1d844b32270186891deddf7d8f2d4c321beb"},"cell_type":"code","source":"#Decision Tree\nfrom sklearn.tree import DecisionTreeClassifier\n\ndecisiontree = DecisionTreeClassifier()\ndecisiontree.fit(x_train, y_train)\ny_pred = decisiontree.predict(x_val)\nacc_decisiontree = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_decisiontree)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9379a1d91fef52247de1a111259205e4e92192e1"},"cell_type":"code","source":"# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(x_train, y_train)\ny_pred = randomforest.predict(x_val)\nacc_randomforest = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_randomforest)\nprint(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3974312c0ffa31476459acf951d9209ac40e2dd8"},"cell_type":"code","source":"# KNN or k-Nearest Neighbors\nfrom sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(x_train, y_train)\ny_pred = knn.predict(x_val)\nacc_knn = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_knn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"313cb45fdfd3771f55051628c2f4950bf8194744"},"cell_type":"code","source":"# Stochastic Gradient Descent\nfrom sklearn.linear_model import SGDClassifier\n\nsgd = SGDClassifier()\nsgd.fit(x_train, y_train)\ny_pred = sgd.predict(x_val)\nacc_sgd = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_sgd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50bd1671b03a06465155ac51c405ac45ef6d61c4"},"cell_type":"code","source":"# Gradient Boosting Classifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier()\ngbk.fit(x_train, y_train)\ny_pred = gbk.predict(x_val)\nacc_gbk = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_gbk)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27d14d0e28146628d8c87042c8e7e4c520622315"},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', 'Linear SVC', \n              'Decision Tree', 'Stochastic Gradient Descent', 'Gradient Boosting Classifier'],\n    'Score': [acc_svc, acc_knn, acc_logreg, \n              acc_randomforest, acc_gaussian, acc_perceptron,acc_linear_svc, acc_decisiontree,\n              acc_sgd, acc_gbk]})\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fb2412cdef3b26404b82164a29fd2e82cc8facb"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(x_train, y_train)\ny_pred = randomforest.predict(x_val)\nacc_randomforest = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_randomforest)\nprint(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52239df5d9f30a63daba837093c66c268d517f97"},"cell_type":"code","source":"%%timeit\nrandomforest = RandomForestClassifier(n_estimators=1000,oob_score=True,n_jobs=-1,random_state=42,max_features=\"auto\",min_samples_leaf=5)\nrandomforest.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5875f76b7b85f988049e8461399539c936b7eec","collapsed":true},"cell_type":"code","source":"%%timeit\nrandomforest = RandomForestClassifier(n_estimators=1000,oob_score=True,n_jobs=1,random_state=42,max_features=\"auto\",min_samples_leaf=5)\nrandomforest.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9a6be60e4f3da812e9cad4d1189151342a111ca"},"cell_type":"code","source":"results =[]\nn_estimator_options = [30,50,100,200,500,1000,2000]\nfrom sklearn.metrics import roc_auc_score\nfor trees in n_estimator_options:\n    model =RandomForestClassifier(trees,oob_score=True,n_jobs=1,random_state=42,max_features=\"auto\",min_samples_leaf=5)\n    model.fit(x_train, y_train)\n    print(\"trees\",trees)\n    roc =roc_auc_score(y_val,model.predict(x_val))\n    print(\"c-stat\",roc)\n    results.append(roc)\n    print(\"\")\n    \npd.Series(results,n_estimator_options).plot();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99354d997045963de1fc52e45d4b70b49bebf4fa","collapsed":true},"cell_type":"code","source":"results =[]\nmax_features_options = [\"auto\",None,\"sqrt\",\"log2\",0.9,0.2]\n\nfor max_features in max_features_options:\n    model = RandomForestClassifier(n_estimators=50,oob_score=True,n_jobs=-1,random_state=42,max_features=max_features)\n    model.fit(x_train, y_train)\n    print(\"max_features_options\",max_features)\n    roc =roc_auc_score(y_val,model.predict(x_val))\n    print(\"c-stat\",roc)\n    results.append(roc)\n    print(\"\")\n    \npd.Series(results,max_features_options).plot(kind=\"barh\",xlim=(.85,.88));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f4a16c57ca7fc8bc2831eeef306926dc325aeaa","collapsed":true},"cell_type":"code","source":"results =[]\nmin_samples_leaf_options = [1,2,3,4,5,6,7,8,9,10]\n\nfor min_samples in min_samples_leaf_options:\n    model = RandomForestClassifier(n_estimators=50,oob_score=True,n_jobs=-1,random_state=42,max_features=None,min_samples_leaf=min_samples)\n    model.fit(x_train, y_train)\n    print(\"min_samples_leaf_options\",min_samples)\n    roc =roc_auc_score(y_val,model.predict(x_val))\n    print(\"c-stat\",roc)\n    results.append(roc)\n    print(\"\")\n    \npd.Series(results,min_samples_leaf_options).plot();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae5567122bbe6b65888493912f9cd379e52d1f89"},"cell_type":"code","source":"model = RandomForestClassifier(n_estimators=50,oob_score=True,n_jobs=1,random_state=42,max_features=None,min_samples_leaf=1)\nmodel.fit(x_train, y_train)\nroc =roc_auc_score(y_val,model.predict(x_val))\nprint(\"c-stat\",roc)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2747d767724351143f981f49414a8d5f1e9c53e"},"cell_type":"code","source":"    max_depths = np.linspace(1, 32, 32, endpoint=True)\n    gbk = GradientBoostingClassifier(n_estimators=200,max_depth=4,min_samples_split=0.4)\n    gbk.fit(x_train, y_train)\n    y_pred = gbk.predict(x_val)\n    acc_gbk = round(accuracy_score(y_pred, y_val) * 100, 2)\n    print(\"estimators is\",estimators)\n    print(\"accuracy is\",acc_gbk)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51f95109d7f7a57d150abdeef36acf2590f8645a","collapsed":true},"cell_type":"code","source":"learning_rates = [1, 0.5, 0.25,0.2,0.15,0.125 ,0.1,0.09,0.08,0.07,0.06, 0.05, 0.01]\nfor eta in learning_rates:    \n    gbk = GradientBoostingClassifier(n_estimators =200,max_depth=4,min_samples_split=0.4,learning_rate=eta)\n    gbk.fit(x_train, y_train)\n    y_pred = gbk.predict(x_val)\n    acc_gbk = round(accuracy_score(y_pred, y_val) * 100, 2)\n    print(\"learning_rates is\",eta)\n    print(\"accuracy is\",acc_gbk)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71344be81b342572c10a12bfc636972c8cc310e3","collapsed":true},"cell_type":"code","source":"#set ids as PassengerId and predict survival \nids = test['PassengerId']\npredictions = gbk.predict(test.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c15fc95e3ee2720d22cb3dae60630cf1434c073","collapsed":true},"cell_type":"code","source":"\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee977d9320d0a044d6d829f1b0f1fd0d63a7bd81","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}