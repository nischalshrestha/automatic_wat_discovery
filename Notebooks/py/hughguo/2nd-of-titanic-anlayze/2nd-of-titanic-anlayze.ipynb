{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"#先import一些包\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\n#再做一些简单处理\ntrain_file = '../input/train.csv'\ntest_file = '../input/test.csv'\ntrain = pd.read_csv(train_file)\ntrain = train.set_index('PassengerId')\ntest = pd.read_csv(test_file)\ntest = test.set_index('PassengerId')","execution_count":130,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#看看训练集情况\ntrain.head()","execution_count":131,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0dc30760056205ef20f0d37484b7b6e68b1720be"},"cell_type":"code","source":"#看看测试集情况\ntest.head()","execution_count":132,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77478b11ccec297232f204f913a6751270a33d19"},"cell_type":"code","source":"train.describe()","execution_count":133,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58520ec5616003464a871028e2ff4e23a969f3c1"},"cell_type":"code","source":"train.info()","execution_count":134,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5df104e752d18310cea1e8ad00b1b96975cf471f"},"cell_type":"code","source":"### Combine_plt\n\nfig = plt.figure()\nfig = plt.figure(figsize = (16,8))\nplt.style.use('ggplot')\n\nplt.subplot2grid((2,3),(0,0))\ntrain.Survived.value_counts().plot(kind='bar')# 柱状图 \nplt.title('Survived=1,0') # 标题\nplt.ylabel('#')  \n\nplt.subplot2grid((2,3),(0,1))\ntrain.Pclass.value_counts().plot(kind=\"bar\")\nplt.ylabel('#')\nplt.title('PClass')\n\nplt.subplot2grid((2,3),(0,2))\nplt.scatter(train.Survived, train.Age)\nplt.ylabel('Age') # 设定纵坐标名称\nplt.grid(b=True, which='major', axis='y') \nplt.title('Survived by Age')\n\n\nplt.subplot2grid((2,3),(1,0), colspan=2)\ntrain.Age[train.Pclass == 1].plot(kind='kde')   \ntrain.Age[train.Pclass == 2].plot(kind='kde')\ntrain.Age[train.Pclass == 3].plot(kind='kde')\nplt.xlabel('Age')# plots an axis lable\nplt.ylabel('P') \nplt.title('Age by PClass')\nplt.legend(('L1','L2','L3'),loc='best') # sets our legend for our graph.\n\n\nplt.subplot2grid((2,3),(1,2))\ntrain.Embarked.value_counts().plot(kind='bar')\nplt.title('Embarked')\nplt.ylabel('#')  \nplt.show()","execution_count":135,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"303020ce0491122b6b3a6a6434b51ab50ed9922c"},"cell_type":"code","source":"##Survive by LEVEL\n\nSurvived_0 = train.Pclass[train.Survived == 0].value_counts()\nSurvived_1 = train.Pclass[train.Survived == 1].value_counts()\ndf=pd.DataFrame({'Surv':Survived_1, 'No_Surv':Survived_0})\ndf.plot(kind='bar', stacked=True)\nplt.title('Survive by Level')\nplt.xlabel('level') \nplt.ylabel('#') \nplt.show()","execution_count":136,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e9150173edc82895ab1b468ff5693f059e512e0"},"cell_type":"code","source":"##Survive by Gender\n\n#Survived_m = train.Survived[train.Sex == 'male'].value_counts()\n#Survived_f = train.Survived[train.Sex == 'female'].value_counts()\n#df=pd.DataFrame({'Male':Survived_m, 'Female':Survived_f})\n#df.plot(kind='bar', stacked=True)\n#plt.title('Survive by Gender')\n#plt.xlabel('Gender') \n#plt.ylabel('#')\n#plt.show()\n\nSurvived_0 = train.Sex[train.Survived == 0].value_counts()\nSurvived_1 = train.Sex[train.Survived == 1].value_counts()\ndf=pd.DataFrame({'Surv':Survived_1, 'No_Surv':Survived_0})\ndf.plot(kind='bar', stacked=True)\nplt.title('Survive by Gender')\nplt.xlabel('Gender') \nplt.ylabel('#') \nplt.show()","execution_count":137,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fbe6d4d8b4c8f8de99409c9d07beed6bab028198"},"cell_type":"code","source":"###Level + Gender\n\nfig = plt.figure(figsize = (16,8))\n#plt.style.use('ggplot')\nplt.title('Level vs Gender')\nplt.axis('off')\nax1=fig.add_subplot(161)\ntrain.Survived[train.Sex == 'female'][train.Pclass == 1].value_counts().plot(kind='bar', label=\"female L1\", color='red')\nplt.legend(['Female | L1'], loc='best')\n\nax2=fig.add_subplot(162, sharey=ax1)\ntrain.Survived[train.Sex == 'female'][train.Pclass == 2].value_counts().plot(kind='bar', label=\"female L2\", color='salmon')\nplt.legend(['Female | L2'], loc='best')\n\nax3=fig.add_subplot(163, sharey=ax1)\ntrain.Survived[train.Sex == 'female'][train.Pclass == 3].value_counts().plot(kind='bar', label='female, L3', color='pink')\nplt.legend(['Female | L3'], loc='best')\n\nax4=fig.add_subplot(164, sharey=ax1)\ntrain.Survived[train.Sex == 'male'][train.Pclass == 1].value_counts().plot(kind='bar', label='male, L1',color='lightblue')\nplt.legend(['Male | L1'], loc='best')\n\nax5=fig.add_subplot(165, sharey=ax1)\ntrain.Survived[train.Sex == 'male'][train.Pclass == 2].value_counts().plot(kind='bar', label='male, L2',color='cornflowerblue')\nplt.legend(['Male | L2'], loc='best')\n\nax6=fig.add_subplot(166, sharey=ax1)\ntrain.Survived[train.Sex == 'male'][train.Pclass == 3].value_counts().plot(kind='bar', label='male L3', color='steelblue')\nplt.legend(['Male | L3'], loc='best')\n\nplt.show()","execution_count":138,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4169bce5196d1d34ed836bb34d9b2a41e649334"},"cell_type":"code","source":"### put them in bin\nbins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]\nlevel = ['0~10', '11~20', '21~30', '31~40', '41~50', '51~60', '61~70', '71~80','81+']\ntrain['Age_Group'] = pd.cut(train['Age'], bins=bins, labels=level)\n\n###\ntitanic_data_bucket = train.groupby(['Age_Group', 'Survived'])['Survived'].count().unstack().fillna(0)\ntitanic_data_bucket.rename(columns={1:'yes', 0:'no'}, inplace=True)\n\nfig = plt.figure(figsize=(15, 7))\nax_1 = fig.add_subplot(121)\ntitanic_data_bucket['yes'].plot(kind='bar',alpha=0.5)              # 各年龄段乘客存活/未存活数分布，通过柱状图展示\ntitanic_data_bucket['no'].plot(kind='bar',alpha=0.5)\nax_1.set_xlabel('Age')\nax_1.set_ylabel('Survive / Total #')\nax_1.set_title('Survived shared Age')\nplt.xticks(rotation=45)\nax_2 = fig.add_subplot(122)\ntitanic_data_bucket[['no_percent','yes_percent']] \\\n= titanic_data_bucket.apply(lambda x: x / x.sum()*100, axis=1)\nprint (titanic_data_bucket)\n\ntitanic_data_bucket['yes_percent'].plot(kind='bar', stacked=True)  # 各年龄段乘客存活百分比\nax_2.set_xlabel('Age')\nax_2.set_ylabel('Survive%')\nax_2.set_title('Survived shared %')\nplt.xticks(rotation=45)\nplt.show()","execution_count":139,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8124614fb7f398777a8412b070ab6a9e892800a9"},"cell_type":"code","source":"train = train.drop(['Age_Group'], axis = 1)","execution_count":140,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d34e388dc49a474d3bf4dc9c633d889e0e4e9de"},"cell_type":"code","source":"Si_b_Sp = train.groupby(['SibSp','Survived']).count()['Pclass']\nSi_b_Sp","execution_count":141,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f995a0c9b95249c3c691bb66dcd54ff507a8e451"},"cell_type":"code","source":"Par_ch = train.groupby(['Parch','Survived']).count()['Pclass']\nPar_ch","execution_count":142,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40350faeac724610106e0e51aa44817792a9ffc8"},"cell_type":"code","source":"train.Cabin.value_counts()","execution_count":143,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0552d879b78c4df036f4c6ad916671b82bb1ce0"},"cell_type":"code","source":"Survived_cabin = train.Survived[pd.notnull(train.Cabin)].value_counts()\nSurvived_nocabin = train.Survived[pd.isnull(train.Cabin)].value_counts()\ndf=pd.DataFrame({'Y':Survived_cabin, 'N':Survived_nocabin}).transpose()\ndf.plot(kind='bar', stacked=True)\nplt.title('Survive with Carbin')\nplt.xlabel('Y/N') \nplt.ylabel('#')\nplt.show()","execution_count":144,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4abe7ebe5607e97cb95e1e5349c58f875d71721","collapsed":true},"cell_type":"code","source":"#补Age\nfrom sklearn.ensemble import RandomForestRegressor\n\ndef missing_ages(df):\n    age = df[['Age','Fare','Parch','SibSp','Pclass']]\n    #分为有/没有Age两部分\n    age_y = age[age.Age.notnull()].values\n    age_n = age[age.Age.isnull()].values\n    #y = target\n    y = age_y[:,0]\n    #N = profile\n    X = age_y[:,1:]\n    \n    #fit\n    rf = RandomForestRegressor(random_state = 0, n_estimators = 100, n_jobs = -1)\n    rf.fit(X,y)\n    \n    predict_age = rf.predict(age_n[:,1:])\n    \n    df.loc[(df.Age.isnull()), 'Age'] = predict_age\n    \n    return df, rf\n\n#改Cabin\ndef missing_cabin(df):\n    df.loc[(df.Cabin.notnull()),'Cabin'] = 'Y'\n    df.loc[(df.Cabin.isnull()),'Cabin'] = 'N'\n    return df\n\ntrain, rfr = missing_ages(train)\ntrain = missing_cabin(train)\ntrain = train.drop(['Name','Ticket'],axis = 1)","execution_count":145,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3066b06e6e790e120635ce3d74d18479b1e1802f"},"cell_type":"code","source":"train_data.info()","execution_count":146,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8afdf0567a841c0cc51ad002548dcf77c7a1285"},"cell_type":"code","source":"train_data.head()","execution_count":147,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ca81aaaff597263d5607f4a8973b68b5a71589d"},"cell_type":"code","source":"#快乐的dummy一下，变为特征因子化\ndummy_Pclass = pd.get_dummies(train_data['Pclass'], prefix = 'Pclass')\ndummy_Sex = pd.get_dummies(train_data['Sex'], prefix = 'Sex')\ndummy_Cabin = pd.get_dummies(train_data['Cabin'], prefix ='Cabin')\ndummy_Embarked = pd.get_dummies(train_data['Embarked'], prefix = 'Embarked')\n\ndf = pd.concat([train_data, dummy_Pclass, dummy_Sex, dummy_Cabin, dummy_Embarked], axis = 1)\ndf = df.drop(['Pclass','Sex','Cabin','Embarked'], axis = 1)\ndf.head()","execution_count":148,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cdb683f5852b966e8a567953e7c5b84ad7fde5a3"},"cell_type":"code","source":"#Age和Fare快乐的归一化\n\n\nfrom sklearn.preprocessing import StandardScaler\n#机智的把需要归一化的数据找出来单独成一个Data_Frame\n#temp = df.loc[:,['Age','Fare']].reset_index().drop(['PassengerId'], axis = 1)\n#temp.head()\n##并不机智...我们用归一化模板吧因为一会儿还要用\nscaler = StandardScaler()\nage_scale = scaler.fit(df['Age'].values.reshape(-1,1))\ndf['Age_scale'] = scaler.fit_transform(df['Age'].values.reshape(-1,1), age_scale)\nfare_scale = scaler.fit(df['Fare'].values.reshape(-1,1))\ndf['Fare_scale'] = scaler.fit_transform(df['Fare'].values.reshape(-1,1), fare_scale)\n#min_max = sklearn.preprocessing.MinMaxScaler()\n#temp = scaler.fit_transform(temp)\n#temp_df = pd.DataFrame(temp)\n#temp.head()\n\n#df = df.reset_index()\n#df['Age_scale'] = temp_df[0]\n#df['Fare_scale'] = temp_df[1]\ndf = df.drop(['Age','Fare'], axis = 1)\ndf.head()","execution_count":149,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a41f95cf1b77541a91c68db6307a8bf60436cb8d"},"cell_type":"code","source":"from sklearn import linear_model\n\n# 用正则取出我们要的feature\n#train_df = df.filter(regex='Survived|Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*')\n#train_np = train_df.as_matrix()\n#as_matrix已经要被停用了，聪明的人都用values ^_^\ntrain_np = df.values\n# y = Survival结果\ny = train_np[:, 0]\n\n# X = 特征属性值\nX = train_np[:, 1:]\n\n# fit到LogisticRegressor之中\nclf = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\nclf.fit(X, y)\n\nclf\n\n### training model is DONE~ ###","execution_count":150,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4554cb670253b139595eeb4eb3553c3758424265"},"cell_type":"code","source":"test.head()","execution_count":151,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abec9df2c467e306993fd4c458e688addd6fee35"},"cell_type":"code","source":"##def missing_ages(df) ==> rfr\n##def missing_cabin(df) ==> data_frame\n\n#Fare\ntest.loc[ (test.Fare.isnull()), 'Fare' ] = 0\ntest_temp = test[['Age','Fare','Parch','SibSp','Pclass']]\n\n#Age\nage_null = test_temp[test.Age.isnull()].values\nX = age_null[:,1:] #同一规则\npred_age = rfr.predict(X)\ntest.loc[(test.Age.isnull()),'Age'] = pred_age\n#refresh the cabin~\ntest = missing_cabin(test)\n\n#drop\ntest_data = test.drop(['Name','Ticket'],axis = 1)\n\n#dummies the str\ndummies_Pclass = pd.get_dummies(test_data['Pclass'], prefix= 'Pclass')\ndummies_Sex = pd.get_dummies(test_data['Sex'], prefix= 'Sex')\ndummies_Cabin = pd.get_dummies(test_data['Cabin'], prefix= 'Cabin')\ndummies_Embarked = pd.get_dummies(test_data['Embarked'], prefix= 'Embarked')\n\n#update the test table with same rules / fit as train\ndf_test = pd.concat([test_data, dummies_Cabin, dummies_Embarked, dummies_Sex, dummies_Pclass], axis=1)\ndf_test = df_test.drop(['Pclass', 'Sex', 'Cabin', 'Embarked'], axis=1)\n\ndf_test['Age_scale'] = scaler.fit_transform(df_test['Age'].values.reshape(-1,1), age_scale)\ndf_test['Fare_scale'] = scaler.fit_transform(df_test['Fare'].values.reshape(-1,1), fare_scale)\n\ndf_test = df_test.drop(['Age','Fare'], axis = 1)\ndf_test.head()","execution_count":152,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"471e6e307212367b426cd8d7d517cbf6d04cf0fc","collapsed":true},"cell_type":"code","source":"#test_test = df_test.filter(regex='Age_.*|SibSp|Parch|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*')\n#predictions = clf.predict(test_test)\n#test = test.reset_index()\n#result = pd.DataFrame({'PassengerId':test['PassengerId'].values, 'Survived':predictions.astype(np.int32)})\n#result.to_csv('submission.csv', index=False)","execution_count":153,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c26ee10fd50d147326d10bd40721f4c7458f4639"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nimport seaborn as sns\ntrain_heatmap = train.astype('str')\nfor column in train_heatmap.columns:\n    train_heatmap[column] = LabelEncoder().fit_transform(train_heatmap[column])\n\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train_heatmap.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\nplt.show()","execution_count":154,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f58b656ca75cdb533f7cf54e29e2549653a350b3","collapsed":true},"cell_type":"code","source":"### 加载一些进化包\n\nfrom sklearn.pipeline import Pipeline,make_pipeline\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn import cross_validation, metrics\nfrom sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n\nimport warnings\nwarnings.filterwarnings('ignore')  ###ingore all warning","execution_count":198,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05b418f89948274c621751b00ce73efc97b3c08d"},"cell_type":"code","source":"###let us combine the data together\n###how about re-import them, since we'll deep dive\n\ntrain = pd.read_csv(train_file,dtype={\"Age\": np.float64})\ntest = pd.read_csv(test_file,dtype={\"Age\": np.float64})\nPassengerId=test['PassengerId']\n\nall_data = pd.concat([train, test], ignore_index = True, sort=False)\n#all_data['Name'] = all_data['Name'].astype('str')\nall_data.info()","execution_count":199,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c63bd8f4a832052232ee4b66e10e506a291f622"},"cell_type":"code","source":"###we'll see how about the title ~~ it need some time to clean them\n###we use all_data insead of train to avoid the data plu\n#all_data['Name'] = all_data['Name'].astype('str')\nall_data['Title'] = all_data['Name'].apply(lambda x:x.split(',')[1].split('.')[0].strip())\nTitle_Dict = {}\nTitle_Dict.update(dict.fromkeys(['Capt', 'Col', 'Major', 'Dr', 'Rev'], 'Officer'))\nTitle_Dict.update(dict.fromkeys(['Don', 'Sir', 'the Countess', 'Dona', 'Lady'], 'Royalty'))\nTitle_Dict.update(dict.fromkeys(['Mme', 'Ms', 'Mrs'], 'Mrs'))\nTitle_Dict.update(dict.fromkeys(['Mlle', 'Miss'], 'Miss'))\nTitle_Dict.update(dict.fromkeys(['Mr'], 'Mr'))\nTitle_Dict.update(dict.fromkeys(['Master','Jonkheer'], 'Master'))\nall_data['Title'] = all_data['Title'].map(Title_Dict)\nsns.barplot(x=\"Title\", y=\"Survived\", data=all_data, palette='Set3')","execution_count":200,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d16a566d692dfd2a622947ad0c2737a91c0897aa"},"cell_type":"code","source":"###by Deck ~~ from Cabin\n\nall_data['Cabin'] = all_data['Cabin'].fillna('Unknown')\nall_data['Deck']=all_data['Cabin'].str.get(0)\nsns.barplot(x=\"Deck\", y=\"Survived\", data=all_data, palette='Set3')","execution_count":201,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7f6d00fcbf3c8779ac8d91cf6c3b482a185c2ee"},"cell_type":"code","source":"### 数值化 // 分Train和test\n\nall_data=all_data[['Survived','Pclass','Sex','Age','Fare','Embarked','Title','Deck','SibSp','Parch']]\nall_data.loc[(all_data.Fare.isnull()), 'Fare' ] = 0\nall_data, rfr = missing_ages(all_data)\nall_data=pd.get_dummies(all_data)\ntrain=all_data[all_data['Survived'].notnull()]\ntest=all_data[all_data['Survived'].isnull()].drop('Survived',axis=1)\nX = train.values[:,1:]\ny = train.values[:,0]","execution_count":202,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab5b464934dd697b191adf22172f7ef69208ebba"},"cell_type":"code","source":"train.info()","execution_count":203,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5de504a5c07bf359ecfccf8c1bf6030032b02cee"},"cell_type":"code","source":"###refine parameter\n#pipe=Pipeline([('select',SelectKBest(k=20)), \n#               ('classify', RandomForestClassifier(random_state = 10, max_features = 'sqrt'))])\n#\n#param_test = {'classify__n_estimators':list(range(20,50,2)), \n#              'classify__max_depth':list(range(3,60,3))}\n#gsearch = GridSearchCV(estimator = pipe, param_grid = param_test, scoring='roc_auc', cv=10)\n#gsearch.fit(X,y)\n#print(gsearch.best_params_, gsearch.best_score_)\n\n###too long time, ignore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"050277bd29c477569a9377b00f8e2ba60b4a48a5"},"cell_type":"code","source":"select = SelectKBest(k = 20)\nclf = RandomForestClassifier(random_state = 10, warm_start = True, \n                                  n_estimators = 26,\n                                  max_depth = 6, \n                                  max_features = 'sqrt')\npipeline = make_pipeline(select, clf)\npipeline.fit(X, y)","execution_count":205,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"475f09f888fb1890fbdabd6df331ce3f0c8fc82c"},"cell_type":"code","source":"### cross_check\n\ncv_score = cross_validation.cross_val_score(pipeline, X, y, cv= 10)\nprint(\"CV Score : Mean - %.7g | Std - %.7g \" % (np.mean(cv_score), np.std(cv_score)))","execution_count":206,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"29a8d29d745f67a9d64e99264de74543f04bd0c8"},"cell_type":"code","source":"predictions = pipeline.predict(test)\nsubmission = pd.DataFrame({\"PassengerId\": PassengerId, \"Survived\": predictions.astype(np.int32)})\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":207,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}