{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport sys\ntrain = pd.read_csv('../input/train.csv', header = 0, dtype={'Age': np.float64})\ntest  = pd.read_csv('../input/test.csv' , header = 0, dtype={'Age': np.float64})\nfull_data = [train, test]\nPassengerId = test['PassengerId']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"022ae0cb07234a1687b6a2bb41666ded346f6bf4"},"cell_type":"markdown","source":"# #1 Feature Exploration"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6f34de842e44dac9e5f995cec84c3ca510ddf64"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb75c38100d458754a7c115d7af03e5aaf28f620"},"cell_type":"markdown","source":"# #2 Feature Engineering\n\nPlan:  \n1)Missing values.  \n2)Parse existring features to get new.  \n3)Combine existing features to get new.  "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"135459222e77ac00cb20ecab409b00bfe7bea64e"},"cell_type":"code","source":"numerical_columns   = [c for c in train.columns if train[c].dtype.name != 'object']\ncategorical_columns = [c for c in train.columns if train[c].dtype.name == 'object']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b33ca17e0fe5de3753b3dbcedd4d1773363e0ca"},"cell_type":"markdown","source":"### Numerical data ###"},{"metadata":{"trusted":true,"_uuid":"b90d0a7d6e987de428b216b6c2a49692ec8aa806"},"cell_type":"code","source":"train[numerical_columns].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"562a79bd394f7435412897fd05b21b2c59f8c268"},"cell_type":"code","source":"for dataset in full_data:\n    age_avg \t   = dataset['Age'].mean()\n    age_std \t   = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    \n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\n    \ntrain['CategoricalAge'] = pd.cut(train['Age'], 5)\ncategorical_columns += ['CategoricalAge']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f7425e4f0eeab502d16c81bc7d4e3793ee33bf61"},"cell_type":"code","source":"for dataset in full_data:\n    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\ntrain['CategoricalFare'] = pd.qcut(train['Fare'], 4)\ncategorical_columns += ['CategoricalFare']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47ec6be47cbbc0f15e0d16bf0cedfd427fbca98f","collapsed":true},"cell_type":"code","source":"for dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\nnumerical_columns += ['FamilySize']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3bf40fd88b7898d8775b399abc2c3b66f50798a4","collapsed":true},"cell_type":"code","source":"for dataset in full_data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\nnumerical_columns += ['IsAlone']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7d4b61311f65557b01d2b6d2cea3f584f06341f"},"cell_type":"code","source":"for num_f in numerical_columns:\n    if len(train[num_f].unique()) < 11 and num_f != 'Survived':\n        print (train[[num_f, 'Survived']].groupby(num_f, as_index=False).mean())\n        print('--------------------------')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d149b5ef2e8f7a130bed71176623281a74d37b1"},"cell_type":"markdown","source":"### Categorical data ###"},{"metadata":{"trusted":true,"_uuid":"8289730c2b2be73fca084a85bd07d4f24660a5ab"},"cell_type":"code","source":"train[categorical_columns].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac1a4471aa4aac6b3e0f6104dae337d3ca87b025","collapsed":true},"cell_type":"code","source":"for dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"402e9eca7bee54684cabf117a058f104a5e339c5","collapsed":true},"cell_type":"code","source":"import re as re\ndef get_title(name):\n\ttitle_search = re.search(' ([A-Za-z]+)\\.', name)\n\t# If the title exists, extract and return it.\n\tif title_search:\n\t\treturn title_search.group(1)\n\treturn \"\"\n\nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)\n\nfor dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ncategorical_columns += ['Title']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f164d68308e5123bdaa58112192366f2e97e782a"},"cell_type":"code","source":"for cat_f in categorical_columns:\n    if len(train[cat_f].unique()) < 11 and cat_f != 'Survived':\n        print (train[[cat_f, 'Survived']].groupby(cat_f, as_index=False).mean())\n        print('--------------------------')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f249cb9b2e7f6b6e6b69929b87e788c0a84f94b1"},"cell_type":"markdown","source":"# #3 Feature Cleaning"},{"metadata":{"trusted":true,"_uuid":"b230b6d0d5c8320d5763b5076f547a4711d24e79"},"cell_type":"code","source":"for dataset in full_data:\n    # Mapping Sex\n    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n    \n    # Mapping titles\n    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    \n    # Mapping Embarked\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n    \n    # Mapping Fare\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    \n    # Mapping Age\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']                           = 4\n\n# Feature Selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n\ntest  = test.drop(drop_elements, axis = 1)\n\nprint (train.head(10))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9e58a3a1493c42b6fec1beba497e3f3a34eb66be"},"cell_type":"markdown","source":"# #4 Visualization"},{"metadata":{"trusted":true,"_uuid":"fcead4a4a6db55738b39eeaa435ce88555378aab"},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bedc98f77254b76bf23eee14496818317394f9cf"},"cell_type":"code","source":"g = sns.pairplot(train, hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\ng.set(xticklabels=[])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3fc2fef097d1e432212e95e991da74f3f3852b2d"},"cell_type":"markdown","source":"# #5 Helpers"},{"metadata":{"trusted":true,"_uuid":"b2dd5ebc28562f5295f5c2a6ec1d84a0f66e116e"},"cell_type":"code","source":"from sklearn.cross_validation import KFold\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier)\nimport sklearn\n\n\n# Some useful parameters which will come in handy later on\nntrain = train.shape[0]\nntest = test.shape[0]\nSEED = 0 # for reproducibility\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n\n# Class to extend the Sklearn classifier\nclass SklearnHelper(object):\n    def __init__(self, clf, seed=0, params=None):\n        params['random_state'] = seed\n        self.clf = clf(**params)\n\n    def train(self, x_train, y_train):\n        self.clf.fit(x_train, y_train)\n\n    def predict(self, x):\n        return self.clf.predict(x)\n    \n    def fit(self,x,y):\n        return self.clf.fit(x,y)\n    \n    def feature_importances(self,x,y):\n        return self.clf.fit(x,y).feature_importances_\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dd870ba5f368869f4461fa9328aecacc9361c4dc"},"cell_type":"code","source":"def get_oof(clf, x_train, y_train, x_test):\n    # вернет массив из нулей формы (ntrain,)\n    oof_train = np.zeros((ntrain,))\n    oof_test = np.zeros((ntest,))\n    \n    # вернет массив с пустым значениями \n    oof_test_skf = np.empty((NFOLDS, ntest))\n\n    for i, (train_index, test_index) in enumerate(kf):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n\n        clf.train(x_tr, y_tr)\n\n        oof_train[test_index] = clf.predict(x_te)\n        oof_test_skf[i, :] = clf.predict(x_test)\n\n    oof_test[:] = oof_test_skf.mean(axis=0)\n    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b3492acf08858b9981722b47612bc73db8de693"},"cell_type":"code","source":"import plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\ndef fi_vis(model_name):\n    # Scatter plot \n    trace = go.Scatter(\n        y = feature_dataframe[model_name].values,\n        x = feature_dataframe['features'].values,\n        mode='markers',\n        marker=dict(\n            sizemode = 'diameter',\n            sizeref = 1,\n            size = 25,\n            color = feature_dataframe[model_name].values,\n            colorscale='Portland',\n            showscale=True\n        ),\n        text = feature_dataframe['features'].values\n    )\n    data = [trace]\n\n    layout= go.Layout(\n        autosize= True,\n        title= model_name,\n        hovermode= 'closest',\n        yaxis=dict(\n            title= 'Feature Importance',\n            ticklen= 5,\n            gridwidth= 2\n        ),\n        showlegend= False\n    )\n    fig = go.Figure(data=data, layout=layout)\n    py.iplot(fig,filename='scatter2010')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"885960b4aab5e4e74b43060fe2600ee8824d48d2"},"cell_type":"markdown","source":"# #6 Parameters "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9e7e293d8e308b06445673a7f2829cf6eafcca9b"},"cell_type":"code","source":"# Random Forest parameters\nrf_params = {\n    'n_jobs': -1,\n    'n_estimators': 500,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 6,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n    'verbose': 0\n}\n\n# Extra Trees Parameters\net_params = {\n    'n_jobs': -1,\n    'n_estimators':500,\n    #'max_features': 0.5,\n    'max_depth': 8,\n    'min_samples_leaf': 2,\n    'verbose': 0\n}\n\n# AdaBoost parameters\nada_params = {\n    'n_estimators': 500,\n    'learning_rate' : 0.75\n}\n\n# Gradient Boosting parameters\ngb_params = {\n    'n_estimators': 500,\n     #'max_features': 0.2,\n    'max_depth': 5,\n    'min_samples_leaf': 2,\n    'verbose': 0\n}\n\n# Support Vector Classifier parameters \nsvc_params = {\n    'kernel' : 'linear',\n    'C' : 0.025\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a61b58c9e5123c9c2f088b7e322d388259c792d1","collapsed":true},"cell_type":"code","source":"rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\net = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\nada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\ngb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\nsvc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f81397ccf5882765af1c4b8088cfcdd7b3d273af","collapsed":true},"cell_type":"code","source":"# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\ny_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values # Creates an array of the train data\nx_test = test.values # Creats an array of the test data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e4de275cb2ef26124777214c16161a606a0dc97"},"cell_type":"markdown","source":"# #7 First level predictions: feature importance"},{"metadata":{"trusted":true,"_uuid":"93e8948b1b1e25c0b0d2ded17909674a82d2ba31"},"cell_type":"code","source":"# Create our OOF train and test predictions. These base results will be used as new features\net_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\nrf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \ngb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) # Gradient Boost\nsvc_oof_train, svc_oof_test = get_oof(svc,x_train, y_train, x_test) # Support Vector Classifier\nprint(\"Training is complete\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d30ce04b0e4c1e4626efd6933e90323f4a4d583"},"cell_type":"code","source":"rf_feature = rf.feature_importances(x_train,y_train)\net_feature = et.feature_importances(x_train, y_train)\nada_feature = ada.feature_importances(x_train, y_train)\ngb_feature = gb.feature_importances(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"227c21afd2d22f829a802691993f24845e9e7043","collapsed":true},"cell_type":"code","source":"cols = train.columns.values\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n     'Random Forest feature importances': rf_feature,\n     'Extra Trees  feature importances': et_feature,\n      'AdaBoost feature importances': ada_feature,\n    'Gradient Boost feature importances': gb_feature\n    })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"20b994397e0506d3d28cfd6b9fa28202cfb7c705"},"cell_type":"code","source":"fi_vis('Random Forest feature importances')\nfi_vis('Extra Trees  feature importances')\nfi_vis('AdaBoost feature importances')\nfi_vis('Gradient Boost feature importances')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a705b7668302f6021a637ce4fc6b3dfc9f6f0ab"},"cell_type":"code","source":"feature_dataframe['mean'] = feature_dataframe.mean(axis= 1) # axis = 1 computes the mean row-wise\nfeature_dataframe.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18d800d54b1503f6e3efb0abe126b396934d26f8"},"cell_type":"code","source":"y = feature_dataframe['mean'].values\nx = feature_dataframe['features'].values\ndata = [go.Bar(\n            x= x,\n             y= y,\n            width = 0.5,\n            marker=dict(\n               color = feature_dataframe['mean'].values,\n            colorscale='Portland',\n            showscale=True,\n            reversescale = False\n            ),\n            opacity=0.6\n        )]\n\nlayout= go.Layout(\n    autosize= True,\n    title= 'Barplots of Mean Feature Importance',\n    hovermode= 'closest',\n    yaxis=dict(\n        title= 'Feature Importance',\n        ticklen= 5,\n        gridwidth= 2\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='bar-direct-labels')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"774778c8fa439b5efa939ab771130db378288627"},"cell_type":"code","source":"base_predictions_train = pd.DataFrame( {'RandomForest': rf_oof_train.ravel(),\n     'ExtraTrees': et_oof_train.ravel(),\n     'AdaBoost': ada_oof_train.ravel(),\n      'GradientBoost': gb_oof_train.ravel()\n    })\nbase_predictions_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3aab19d9142c34d806f3112360df1956e04ca0fb","scrolled":true},"cell_type":"code","source":"data = [\n    go.Heatmap(\n        z= base_predictions_train.astype(float).corr().values ,\n        x= base_predictions_train.columns.values,\n        y= base_predictions_train.columns.values,\n          colorscale='Viridis',\n            showscale=True,\n            reversescale = True\n    )\n]\npy.iplot(data, filename='labelled-heatmap')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"669c7664db9d2bcaf1efae3ee096cc4176b5a3c4"},"cell_type":"code","source":"x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train, svc_oof_train), axis=1)\nx_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test, svc_oof_test), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f78da0258ff52ffeabcb9397295d90961e4cfb94"},"cell_type":"code","source":"import xgboost as xgb\n\ngbm = xgb.XGBClassifier(\n n_estimators= 2000,\n max_depth= 4,\n min_child_weight= 2,\n gamma=0.9,                        \n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread= -1,\n scale_pos_weight=1).fit(x_train, y_train)\npredictions = gbm.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42ea9c1671cb96c536a6925d64374dc337a12019"},"cell_type":"code","source":"rf_oof_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"259665b9d29245c8dc2255fc993d9a95b8b71b97"},"cell_type":"code","source":"print(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0a36a016344d4bfbfa5aec471a4a5387ec933de8"},"cell_type":"code","source":"# Generate Submission File \nStackingSubmission = pd.DataFrame({ 'PassengerId': PassengerId,\n                            'Survived': predictions })\nStackingSubmission.to_csv(\"StackingSubmission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c24e9ee2bb64c2536164fbcdd0797794316f56cd"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}