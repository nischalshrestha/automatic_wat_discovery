{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "e21ec298fdda4b3558d4530e28be00cd89b507db", "collapsed": true, "_cell_guid": "23a5f0a7-bd1e-44bf-ac1e-7abc4983089e"}, "source": ["import pandas as pd\n", "import xgboost as xgb\n", "from sklearn.preprocessing import LabelEncoder\n", "import numpy as np\n", "\n", "# Load the data\n", "data_train = pd.read_csv('../input/train.csv')\n", "data_test = pd.read_csv('../input/test.csv')\n", "combine = [data_train, data_test]"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "64e5f3e1f0d4b24baa2f6deb848b9b78ae2cee17", "collapsed": true, "_cell_guid": "ebf05e85-c629-41a1-b9f3-cf4741726d7f"}, "source": ["data_train.describe()"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "3f33bf01ed78f1163af211162903541f43e149fc", "collapsed": true, "_cell_guid": "be02384f-4d48-4736-9a61-8f487359daee"}, "source": ["data_test.describe()"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "85439f1fed65fc7a0674210e2185e55ecb10b6cf", "collapsed": true, "_cell_guid": "15f9b725-e8f5-4b89-bae8-0f72980f8c41"}, "source": ["total_df = data_train.append(data_test)\n", "total_df.info()"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "4949960b05865e272c0d2cb22147ef486512dc6c", "collapsed": true, "_cell_guid": "c04a47e3-582d-4320-ad33-4f244e4e4574"}, "source": ["Title_Dictionary = {\n", "                    \"Capt\":       \"Officer\",\n", "                    \"Col\":        \"Officer\",\n", "                    \"Major\":      \"Officer\",\n", "                    \"Countess\":   \"Royalty\",\n", "                    \"Jonkheer\":   \"Royalty\",\n", "                    \"Don\":        \"Royalty\",\n", "                    \"Sir\" :       \"Royalty\",\n", "                    \"Dr\":         \"Officer\",\n", "                    \"Rev\":        \"Officer\",\n", "                    \"the Countess\":\"Royalty\",\n", "                    \"Dona\":       \"Royalty\",\n", "                    \"Mme\":        \"Mrs\",\n", "                    \"Mlle\":       \"Miss\",\n", "                    \"Ms\":         \"Mrs\",\n", "                    \"Mr\" :        \"Mr\",\n", "                    \"Mrs\" :       \"Mrs\",\n", "                    \"Miss\" :      \"Miss\",\n", "                    \"Master\" :    \"Master\",\n", "                    \"Lady\" :      \"Royalty\"\n", "                    }\n", "for dataset in combine:\n", "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n", "    dataset['Title'] = dataset['Title'].map(Title_Dictionary)\n", "    \n", "title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \"Master\": 3, \"Royalty\": 4, \"Officer\": 5}\n", "for dataset in combine:\n", "    dataset['Title'] = dataset['Title'].map(title_mapping)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "59b01c6d9af4e6462b83e33bd9580a0e0e94c263", "collapsed": true, "_cell_guid": "48fce2f1-a75f-4995-b1d8-c5483daebd01"}, "source": ["data_train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean().sort_values(by='Title', ascending=True)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "ed685fc186ef6d05845a6aebc8de8cc123f4f345", "collapsed": true, "_cell_guid": "051aeeba-571a-4bdd-ac2a-d1c86568e668"}, "source": ["for dataset in combine:\n", "    dataset['Name_length'] = dataset['Name'].apply(len)\n", "    \n", "data_train['Name_length_Band'] = pd.qcut(data_train['Name_length'], 6)\n", "data_train[['Name_length_Band','Survived']].groupby(['Name_length_Band'], as_index=False).mean().sort_values(by='Name_length_Band', ascending=True)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "75fdbe53457127510ef2d790a92dda84546c66ff", "collapsed": true, "_cell_guid": "3b7d3a5d-dc85-40eb-b5cb-db429e75e2a6"}, "source": ["def simplify_name(df):\n", "    bins = (0, 19.0, 22.0, 25.0, 28.0, 33.0, 82.0)\n", "    group_names = ['0_in', '1_in', '2_in', '3_in', '4_in', '5_in']\n", "    categories = pd.cut(df.Name_length, bins, labels=group_names)\n", "    df.Name_length = categories\n", "    return df\n", "\n", "data_train = simplify_name(data_train)\n", "data_train = data_train.drop(['Name_length_Band'], axis=1)\n", "data_test = simplify_name(data_test)\n", "combine = [data_train, data_test]\n", "data_train.head()"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "a31d3944de2944bc341193bab7bc4128d5debf62", "collapsed": true, "_cell_guid": "dbbf1e51-996d-4e53-9fb9-64f724774d7e"}, "source": ["for dataset in combine:\n", "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch']\n", "    \n", "data_train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='FamilySize', ascending=True)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "62d8c49e3691be9681dc6f7d6c68a0043a3086ad", "collapsed": true, "_cell_guid": "d8c1a715-de0a-4eea-9c87-81994c18fa3b"}, "source": ["data_train['Age'].fillna(data_train['Age'].dropna().median(), inplace=True)\n", "data_train['AgeBand'] = pd.cut(data_train['Age'], 6)\n", "data_train[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "054f1edbf145df9dbef5c14c28ca74166404f46e", "collapsed": true, "_cell_guid": "b342d016-1f21-4518-9771-417a829ac287"}, "source": ["def simplify_ages(df):\n", "    df.Age.fillna(df.Age.dropna().median(), inplace=True)\n", "    bins = (0, 13.683, 26.947, 40.21, 53.473, 66.737, 80.0)\n", "    group_names = ['0_intv', '1_intv', '2_intv', '3_intv', '4_intv', '5_intv']\n", "    categories = pd.cut(df.Age, bins, labels=group_names)\n", "    df.Age = categories\n", "    return df\n", "\n", "data_train = simplify_ages(data_train)\n", "data_train = data_train.drop(['AgeBand'], axis=1)\n", "data_test = simplify_ages(data_test)\n", "combine = [data_train, data_test]\n", "data_train.head()"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "b8954b2523ce88d5300b7d87aade2735b10a24cd", "collapsed": true, "_cell_guid": "3c6a316b-4c50-43f1-82c3-7aff4b56945f"}, "source": ["#data_train['Fare'].fillna(data_train['Fare'].dropna().median(), inplace=True)\n", "data_train['FareBand'] = pd.qcut(data_train['Fare'], 7, precision=3)\n", "data_train[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "4ef95471ec2aad643d070192d90953e09f5fef28", "collapsed": true, "_cell_guid": "20fdcb86-70b2-4221-a325-8ef6e10ec012"}, "source": ["def simplify_fare(df):\n", "    df.Fare.fillna(df.Fare.dropna().median(), inplace=True)\n", "    bins = (-0.001, 7.751, 8.051, 12.476, 19.259, 27.901, 56.930, 512.330)\n", "    group_names = ['0_intvl', '1_intvl', '2_intvl', '3_intvl', '4_intvl', '5_intvl', '6_intvl']\n", "    categories = pd.cut(df.Fare, bins, labels=group_names, precision=3)\n", "    df.Fare = categories\n", "    return df\n", "\n", "data_train = simplify_fare(data_train)\n", "data_train = data_train.drop(['FareBand'], axis=1)\n", "data_test = simplify_fare(data_test)\n", "combine = [data_train, data_test]\n", "data_train.head()"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "e1950f82be3021924c8c62fba9c5e242a421802b", "collapsed": true, "_cell_guid": "dce3b610-0636-490a-8bad-a40f8e99ef36"}, "source": ["freq_port = data_train.Embarked.dropna().mode()[0]\n", "port_mapping = {'S': 0, 'C': 1, 'Q': 2}\n", "for dataset in combine:\n", "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n", "    dataset['Embarked'] = dataset['Embarked'].map(port_mapping)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "119914181cda66ce5589306c2c292b9bc9dd25b0", "collapsed": true, "_cell_guid": "95e8b158-ce0c-4bcb-a412-6d1cc6269cdf"}, "source": ["data_train['Has_Cabin'] = data_train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n", "data_test['Has_Cabin'] = data_test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n", "data_train[['Has_Cabin', 'Survived']].groupby(['Has_Cabin'], as_index=False).mean().sort_values(by='Has_Cabin', ascending=True)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "6db10e8b9852bf8a85117755fa910dff224e769b", "collapsed": true, "_cell_guid": "b425436c-d1b1-4f6c-968a-4867746924a3"}, "source": ["from sklearn import preprocessing\n", "def encode_features(df_train, df_test):\n", "    features = ['Pclass','Sex','FamilySize','Title','Name_length','Age','Fare','Embarked','Has_Cabin']\n", "    df_combined = pd.concat([df_train[features], df_test[features]])\n", "    \n", "    for feature in features:\n", "        le = preprocessing.LabelEncoder()\n", "        le = le.fit(df_combined[feature])\n", "        df_train[feature] = le.transform(df_train[feature])\n", "        df_test[feature] = le.transform(df_test[feature])\n", "    return df_train, df_test\n", "    \n", "data_train, data_test = encode_features(data_train, data_test)\n", "data_train.head()"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "210e0dfc1f154bcf67d54808fb41482078679fce", "collapsed": true, "_cell_guid": "1a27bbc8-4f06-4408-b14b-bbb893245436"}, "source": ["data_train = data_train.drop(['Name'], axis=1)\n", "data_train = data_train.drop(['Ticket'], axis=1)\n", "data_train = data_train.drop(['Cabin'], axis=1)\n", "data_train = data_train.drop(['SibSp'], axis=1)\n", "data_train = data_train.drop(['Parch'], axis=1)\n", "data_train.head()"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "15cf8b453779e6961344ba7ad3028ab2b1b4be73", "collapsed": true, "_cell_guid": "5fe2b0aa-eadb-4dff-a65a-b6c7dbbba26c"}, "source": ["data_test = data_test.drop(['Name'], axis=1)\n", "data_test = data_test.drop(['Ticket'], axis=1)\n", "data_test = data_test.drop(['Cabin'], axis=1)\n", "data_test = data_test.drop(['SibSp'], axis=1)\n", "data_test = data_test.drop(['Parch'], axis=1)\n", "data_test.head()"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "2d20a698ecb809aa212363f95490477bf58b7888", "collapsed": true, "_cell_guid": "93fe47d1-b75a-4404-afb3-52e3a410fada"}, "source": ["from sklearn.model_selection import train_test_split\n", "\n", "X_all = data_train.drop(['Survived', 'PassengerId'], axis=1)\n", "y_all = data_train['Survived']\n", "\n", "num_test = 0.10\n", "X_train, X_test, Y_train, Y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=123)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "19d8df607da4c20b675fd245a8109d5ed5f0ac8b", "collapsed": true, "_cell_guid": "6c981dde-f4a4-4f68-9915-9bfe56e5c098"}, "source": ["# PCA features\n", "from sklearn.decomposition import PCA\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.pipeline import make_pipeline\n", "import matplotlib.pyplot as plt\n", "\n", "# Create scaler: scaler\n", "scaler = StandardScaler()\n", "\n", "# Create a PCA instance: pca\n", "pca = PCA()\n", "\n", "# Create pipeline: pipeline\n", "pipeline = make_pipeline(scaler,pca)\n", "\n", "# Fit the pipeline to 'samples'\n", "pipeline.fit(X_all)\n", "\n", "# Plot the explained variances\n", "features = range(pca.n_components_)\n", "plt.bar(features, pca.explained_variance_)\n", "plt.xlabel('PCA feature')\n", "plt.ylabel('variance')\n", "plt.xticks(features)\n", "plt.show()\n"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "f8a1a7d2fab9e9d6ea16fa2dbe47c605dfe87c54", "_cell_guid": "2fdfd947-3e4a-4441-874f-000171f61505"}, "source": ["**Prediction via Multiple Models**"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "62cf1666111804c241292270439faeee2ed57634", "collapsed": true, "_cell_guid": "ec378586-dceb-4719-a4d0-fa0600cad5e8"}, "source": ["# machine learning\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.svm import SVC, LinearSVC\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.linear_model import Perceptron\n", "from sklearn.linear_model import SGDClassifier\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.metrics import make_scorer, accuracy_score"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "b3c45475e6f387eb4e46208a4232bd5b773dc86a", "collapsed": true, "_cell_guid": "9f4798fe-05bb-4ef8-b5d3-7fc27b51b6af"}, "source": ["model_type = []\n", "train_acc = []\n", "test_acc = []"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "f597426c1cfaeea58a8302f55b5fa7e62bfdbc4e", "collapsed": true, "_cell_guid": "beb9eb34-9029-46f8-8244-650e60b359d8"}, "source": ["# Logistic Regression\n", "\n", "logreg = LogisticRegression()\n", "logreg.fit(X_train, Y_train)\n", "Y_pred = logreg.predict(X_test)\n", "Y_pred_train = logreg.predict(X_train)\n", "print(accuracy_score(Y_train, Y_pred_train), accuracy_score(Y_test, Y_pred))\n", "model_type.append('Logistic Regression')\n", "train_acc.append(accuracy_score(Y_train, Y_pred_train))\n", "test_acc.append(accuracy_score(Y_test, Y_pred))"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "645a21a4f1cf918e5afbdfa6a26269c9aff63670", "collapsed": true, "_cell_guid": "1c23dfe9-5750-4e89-828a-771a48932661"}, "source": ["# Import necessary modules\n", "from sklearn.model_selection import GridSearchCV\n", "\n", "# Create the hyperparameter grid\n", "c_space = np.logspace(-5, 8, 15)\n", "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\n", "\n", "# Instantiate the logistic regression classifier: logreg\n", "logreg = LogisticRegression()\n", "\n", "# Instantiate the GridSearchCV object: logreg_cv\n", "logreg_cv = GridSearchCV(logreg, param_grid, cv=10)\n", "\n", "# Fit it to the training data\n", "logreg_cv.fit(X_train, Y_train)\n", "\n", "# Print the optimal parameters and best score\n", "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n", "print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "b89eee1c09f3e09631f441692d475b331b8953c8", "collapsed": true, "_cell_guid": "57797811-6847-4098-9b7e-647413fb85a5"}, "source": ["Y_pred = logreg_cv.predict(X_test)\n", "Y_pred_train = logreg_cv.predict(X_train)\n", "print(accuracy_score(Y_train, Y_pred_train), accuracy_score(Y_test, Y_pred))\n", "\n", "model_type.append('GridSearchCV Logistic Regression')\n", "train_acc.append(accuracy_score(Y_train, Y_pred_train))\n", "test_acc.append(accuracy_score(Y_test, Y_pred))"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "aa90c14fa62fc76e06446a0f02d1da1fd3385545", "collapsed": true, "_cell_guid": "b2c2361a-7760-49f3-9567-ce83b5fefba8"}, "source": ["# Import necessary modules\n", "from sklearn.linear_model import Ridge\n", "from sklearn.model_selection import cross_val_score\n", "\n", "# Setup the array of alphas and lists to store scores\n", "alpha_space = np.logspace(-5, 8, 15)\n", "ridge_scores = []\n", "ridge_scores_std = []\n", "\n", "# Create a ridge regressor: ridge\n", "ridge = Ridge(normalize=True)\n", "\n", "# Compute scores over range of alphas\n", "for alpha in alpha_space:\n", "\n", "    # Specify the alpha value to use: ridge.alpha\n", "    ridge.alpha = alpha\n", "    \n", "    # Perform 10-fold CV: ridge_cv_scores\n", "    ridge_cv_scores = cross_val_score(ridge, X_train, Y_train, cv=10)\n", "    \n", "    print(alpha, np.mean(ridge_cv_scores), np.std(ridge_cv_scores))"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "83663f01a05e255dd9c1dde9abd513ec3305fbf5", "collapsed": true, "_cell_guid": "fdce7490-378e-48d9-b841-cfdaa0dcb117"}, "source": ["# k-NN\n", "for k in range (2, 10):\n", "    knn = KNeighborsClassifier(n_neighbors = k)\n", "    knn.fit(X_train, Y_train)\n", "    Y_pred = knn.predict(X_test)\n", "    Y_pred_train = knn.predict(X_train)\n", "    print(k, accuracy_score(Y_train, Y_pred_train), accuracy_score(Y_test, Y_pred))"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "30ddc17304dd4ddadb275d02d7fd99dc8080cd81", "collapsed": true, "_cell_guid": "c7445efc-59b3-49e8-97d7-78780608caa4"}, "source": ["knn = KNeighborsClassifier(n_neighbors = 4)\n", "knn.fit(X_train, Y_train)\n", "Y_pred = knn.predict(X_test)\n", "Y_pred_train = knn.predict(X_train)\n", "\n", "model_type.append('k-NN')\n", "train_acc.append(accuracy_score(Y_train, Y_pred_train))\n", "test_acc.append(accuracy_score(Y_test, Y_pred))"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "a1a5de895539ab12627e0a3bf5e4f813acbff203", "collapsed": true, "_cell_guid": "5d782f83-d424-4ae5-b689-153b3f070b91"}, "source": ["# Decision Tree\n", "\n", "decision_tree = DecisionTreeClassifier()\n", "decision_tree.fit(X_train, Y_train)\n", "Y_pred = decision_tree.predict(X_test)\n", "Y_pred_train = decision_tree.predict(X_train)\n", "print(accuracy_score(Y_train, Y_pred_train), accuracy_score(Y_test, Y_pred))\n", "\n", "model_type.append('Decision Tree')\n", "train_acc.append(accuracy_score(Y_train, Y_pred_train))\n", "test_acc.append(accuracy_score(Y_test, Y_pred))"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "cad89bd15c4d249e45ebac30ca708a6637131b8b", "collapsed": true, "_cell_guid": "6ace33a1-d69e-4bad-99c3-9b9140a3a4a2"}, "source": ["from scipy.stats import randint\n", "from sklearn.model_selection import RandomizedSearchCV\n", "\n", "# Setup the parameters and distributions to sample from: param_dist\n", "param_dist = {\"max_depth\": [3, 5],\n", "              \"max_features\": randint(1, 6),\n", "              \"min_samples_leaf\": randint(1, 6),\n", "              \"criterion\": [\"gini\", \"entropy\"]}\n", "\n", "# Instantiate a Decision Tree classifier: tree\n", "tree = DecisionTreeClassifier()\n", "\n", "# Instantiate the RandomizedSearchCV object: tree_cv\n", "tree_cv = RandomizedSearchCV(tree,param_dist,cv=10)\n", "\n", "# Fit it to the data\n", "tree_cv.fit(X_train, Y_train)\n", "\n", "# Print the tuned parameters and score\n", "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n", "print(\"Best score is {}\".format(tree_cv.best_score_))\n", "\n", "Y_pred = tree_cv.predict(X_test)\n", "Y_pred_train = tree_cv.predict(X_train)\n", "print(accuracy_score(Y_train, Y_pred_train), accuracy_score(Y_test, Y_pred))\n", "\n", "model_type.append('RandomizedSearch Decision Tree')\n", "train_acc.append(accuracy_score(Y_train, Y_pred_train))\n", "test_acc.append(accuracy_score(Y_test, Y_pred))\n"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "a109fca58b4139657df9e43d495a75f7b7fcded1", "collapsed": true, "_cell_guid": "0247b6aa-0ca9-4e88-a7e2-6391acb7e516"}, "source": ["# Random Forest\n", "\n", "random_forest = RandomForestClassifier(n_estimators=100)\n", "random_forest.fit(X_train, Y_train)\n", "Y_pred = random_forest.predict(X_test)\n", "Y_pred_train = random_forest.predict(X_train)\n", "print(accuracy_score(Y_train, Y_pred_train), accuracy_score(Y_test, Y_pred))\n", "\n", "model_type.append('Random Forest')\n", "train_acc.append(accuracy_score(Y_train, Y_pred_train))\n", "test_acc.append(accuracy_score(Y_test, Y_pred))"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "c00a5a1273182ea0d205c441a307898bd1e8fc5e", "collapsed": true, "_cell_guid": "267b1d6d-cfc7-4138-9926-8d70a3e143ff"}, "source": ["gbm_param_grid = {\n", "    'n_estimators': np.arange(50,500,50),\n", "}\n", "\n", "# Instantiate the regressor: gbm\n", "random_forest = RandomForestClassifier()\n", "\n", "# Perform grid search: grid_mse\n", "grid_random_forest = GridSearchCV(estimator=random_forest, param_grid=gbm_param_grid, scoring=\"neg_mean_squared_error\",cv=10,verbose=1)\n", "\n", "# Fit grid_mse to the data\n", "grid_random_forest.fit(X_train, Y_train)\n", "\n", "# Print the best parameters and lowest RMSE\n", "print(\"Best parameters found: \", grid_random_forest.best_params_)\n", "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_random_forest.best_score_)))\n", "\n", "Y_pred = grid_random_forest.predict(X_test)\n", "Y_pred_train = grid_random_forest.predict(X_train)\n", "print(accuracy_score(Y_train, Y_pred_train), accuracy_score(Y_test, Y_pred))\n", "\n", "model_type.append('GridSearchCV Random Forest')\n", "train_acc.append(accuracy_score(Y_train, Y_pred_train))\n", "test_acc.append(accuracy_score(Y_test, Y_pred))"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "80a5fc2636d8ddb237b245eed48d28328c829612", "collapsed": true, "_cell_guid": "87da7628-6b37-4019-9ea8-c1c55e9e7b6e"}, "source": ["# This example uses the current build of XGBoost, from https://github.com/dmlc/xgboost\n", "gbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(X_train, Y_train)\n", "Y_pred = gbm.predict(X_test)\n", "Y_pred_train = gbm.predict(X_train)\n", "print(accuracy_score(Y_train, Y_pred_train), accuracy_score(Y_test, Y_pred))\n", "\n", "model_type.append('XGBoost')\n", "train_acc.append(accuracy_score(Y_train, Y_pred_train))\n", "test_acc.append(accuracy_score(Y_test, Y_pred))"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "eddd4298f247e53fb582be82dca62ff43631d4d5", "collapsed": true, "_cell_guid": "f6b6afc2-0a64-4bc0-ac1d-55866e1fa6db"}, "source": ["# Create the parameter grid: gbm_param_grid\n", "gbm_param_grid = {\n", "    'learning_rate': np.arange(.05, 1, .05),\n", "    'n_estimators': np.arange(50,500,50),\n", "    'max_depth': np.arange(2, 5, 1)\n", "}\n", "\n", "# Instantiate the regressor: gbm\n", "gbm = xgb.XGBClassifier()\n", "\n", "# Perform grid search: grid_mse\n", "grid_mse = GridSearchCV(estimator=gbm, param_grid=gbm_param_grid, scoring=\"neg_mean_squared_error\",cv=10,verbose=1)\n", "\n", "# Fit grid_mse to the data\n", "grid_mse.fit(X_train, Y_train)\n", "\n", "# Print the best parameters and lowest RMSE\n", "print(\"Best parameters found: \", grid_mse.best_params_)\n", "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))\n"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "0c0a96b1bc77078e2601c8fe1676fafc8835a30c", "collapsed": true, "_cell_guid": "0abd0dba-c348-4b80-9207-b7bdad138017"}, "source": ["Y_pred = grid_mse.predict(X_test)\n", "Y_pred_train = grid_mse.predict(X_train)\n", "print(accuracy_score(Y_train, Y_pred_train), accuracy_score(Y_test, Y_pred))\n", "\n", "model_type.append('GridSearchCV XGBoost')\n", "train_acc.append(accuracy_score(Y_train, Y_pred_train))\n", "test_acc.append(accuracy_score(Y_test, Y_pred))"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "e50118e2acdaaff6986eac4113a47befcd1fd89b", "_cell_guid": "de69326c-bb73-4cd9-a332-b478d3eda33b"}, "source": ["**Summary of Different Models**"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "6b3aff5e87a265af3d9e2e99ea099ceb044fc42a", "collapsed": true, "_cell_guid": "5b3876cb-914b-4bce-a8d0-621abbec865e"}, "source": ["summary = pd.DataFrame({ 'model_type' : model_type, 'train_acc': train_acc, 'test_acc': test_acc })\n", "summary"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "9c468eb1aceda1c4d34ed87f5aebb16b8fed717e", "_cell_guid": "57835ed4-c544-459f-bcbf-cd74b8e74ca4"}, "source": ["**Predict the Actual Test Data**"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "c3b4151f942b6db81cfdb00b0e13c3f52a5d5edc", "collapsed": true, "_cell_guid": "915962bc-2d1d-4ad8-9183-f56faf74cf83"}, "source": ["ids = data_test['PassengerId']\n", "    \n", "predictions = tree_cv.predict(data_test.drop('PassengerId', axis=1))\n", "\n", "output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\n", "output.head()"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "106f90456e0b10b2ffe6dcde54b0e3d85f69b9bd", "_kg_hide-output": false, "collapsed": true, "_cell_guid": "5c63dc00-3f5d-4ecc-a8bb-e78adf722fa1"}, "source": ["output.to_csv('titanic-predictions.csv', index = False)"], "outputs": []}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "0895cb46fb210cae21bfeb872443205fa6c72dd9", "collapsed": true, "_cell_guid": "60d32756-1b79-49dd-b035-8e0af0d95266"}, "source": [], "outputs": []}], "nbformat_minor": 1, "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "file_extension": ".py", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.3"}}, "nbformat": 4}