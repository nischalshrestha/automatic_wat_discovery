{"cells":[{"metadata":{"_uuid":"323bd778f3ea81e33b4d97707dc77aa0ff41730c"},"cell_type":"markdown","source":"# Titanic challenge"},{"metadata":{"_uuid":"5f73880af6f7a0089a7919a13675add56b38662e"},"cell_type":"markdown","source":"### Phase #1 Business understanding\n\n##### Competition Description\nThe sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n\nOne of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n\nIn this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n\n##### Goal\nIt is your job to predict if a passenger survived the sinking of the Titanic or not. \nFor each PassengerId in the test set, you must predict a 0 or 1 value for the Survived variable.\n\n#### Metric\nYour score is the percentage of passengers you correctly predict. This is known simply as \"accuracy”.\n"},{"metadata":{"_uuid":"d2c2a78745c07af145f765f44e4a5dd8610e1afe"},"cell_type":"markdown","source":"### Phase #2 Data Understanding\n"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"aba160007341da5c0c12d948571f13e090ec72e3"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n\n# for text / string processing\nimport re\n\n\n# for plotting\nimport matplotlib.pyplot as plt\n% matplotlib inline\n\n# to divide train and test set\nfrom sklearn.model_selection import train_test_split\n\n# feature scaling\nfrom sklearn.preprocessing import MinMaxScaler\n\n# for tree binarisation\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\n\n\n# to build the models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\n\n# to evaluate the models\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import metrics\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","execution_count":1,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c4157aac20862acec8d42505948de639a66f182","collapsed":true},"cell_type":"code","source":"data = pd.read_csv('../input/train.csv')\nsubmission = pd.read_csv('../input/test.csv')\n","execution_count":3,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"8c1ef7b11530c26c43b308bc27360095761c8549","collapsed":true},"cell_type":"code","source":"data.head()","execution_count":214,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f5723fc416887b763ff0a52a052b56843871dab5","collapsed":true},"cell_type":"code","source":"submission.head()","execution_count":215,"outputs":[]},{"metadata":{"_uuid":"4d27b4c8ce8d593dc284f4e3badc714bc645c442"},"cell_type":"markdown","source":"##### Variable Types : \nIdentify categorical and numerical variables, also variable that should not be used ( example ID), you can create a list of categotical and numericalvariables. In categorical variables you can check if some variables have mixed values with numerical and non-numerical values. In numerical is important to identify the discrete and continuous variables, also the target and unique variable sucha as ID. Create a summary of analysis, like (“X categorical , that y can be treate as mixed; W numerical, where X discrete, Y continuous , Z ID and 1 binary-targe_t”) to make sure do not lost any information"},{"metadata":{"trusted":false,"_uuid":"cc36347e2b0fa3e45a89abc477c039a42a719d34","collapsed":true},"cell_type":"code","source":"data.dtypes","execution_count":216,"outputs":[]},{"metadata":{"_uuid":"4404a4f570bba012480fb09266615bfcd4b8444e"},"cell_type":"markdown","source":" 5 Categorical :\n- Name            object \n- Sex             object \n- Ticket          object \n- Cabin           object\n- Embarked        object\n\n7 Numerical variables:\n- PassengerId      int64\n- Survived         int64\n- Pclass           int64 \n- Age            float64 \n- SibSp            int64 \n- Parch            int64\n- Fare           float64\n"},{"metadata":{"_uuid":"63b8cc309aaf420d83dc1aeaba00a39cba4db3ac"},"cell_type":"markdown","source":"PassengerId should not be used since there one for each passager:"},{"metadata":{"trusted":false,"_uuid":"9db8de90fedd5ece5ba2d2fa9e36e88e22b878c1","collapsed":true},"cell_type":"code","source":"\nprint('Number of passager labels on train : ' , len(data.PassengerId.unique()), 'of ' , len(data) , ' on dataset')\nprint('Number of passager labels on test : ' , len(submission.PassengerId.unique()))\n","execution_count":217,"outputs":[]},{"metadata":{"_uuid":"7e00c48a56cbee30fe9ac9587be581e863d6eecf"},"cell_type":"markdown","source":"Create a list of categorical:"},{"metadata":{"trusted":false,"_uuid":"e017a6228d4c0ca67d454ec6550f1a3b5fd5d04f","collapsed":true},"cell_type":"code","source":"categorical = [var for var in data.columns if data[var].dtype=='O']\nprint('There are {} categorical variables'.format(len(categorical)))","execution_count":218,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"15c861ab7aebee91d679ad6ec9bcd4a230d73d50","collapsed":true},"cell_type":"code","source":"numerical = [var for var in data.columns if data[var].dtype!='O']\nprint('There are {} numerical variables'.format(len(numerical)))","execution_count":219,"outputs":[]},{"metadata":{"_uuid":"808f51fb489df6b69d9ff71faa5bee08f9f72975"},"cell_type":"markdown","source":"Checking the categorical variables to see mixed values, we can see that Ticket and Cabin have numbers and non-numbers values"},{"metadata":{"trusted":false,"_uuid":"53a538623f3b5d059ed92918b8128afa87176881","collapsed":true},"cell_type":"code","source":"data[categorical].head()","execution_count":220,"outputs":[]},{"metadata":{"_uuid":"d50ac39c4964efc2f56958f40b87153fa24dc37a"},"cell_type":"markdown","source":"Check the numerical variable to identify the discrete and continuous"},{"metadata":{"trusted":false,"_uuid":"5e277e9028c3eb027b4ea90fb1505dd37ae473a4","collapsed":true},"cell_type":"code","source":"data[numerical].head()","execution_count":221,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"c2a3b8167f87d93eeb05869dbc5ed130a3aeb506"},"cell_type":"markdown","source":"Discrete: \n - SibSp\n - Parch\n - Pclass\n \nContinuous:\n - Age\n - Fare\n \nTarget : \n - Survided\n \nNot usefull:\n - PassengerId\n "},{"metadata":{"_uuid":"fbfa9cfe117017eeb0c42006bdc469d56248629c"},"cell_type":"markdown","source":"Check discrete variables:\n\nCan see that there are few values of discrete variables"},{"metadata":{"trusted":false,"_uuid":"f6d44f903125563374f7b74ae1bc7a61e573a2d8","collapsed":true},"cell_type":"code","source":"for var in ['SibSp', 'Parch', 'Pclass']:\n    print(var, ' :  ', data[var].unique())","execution_count":222,"outputs":[]},{"metadata":{"_uuid":"9f057359090e8a3fc5f085a910396526a6bc1bbc"},"cell_type":"markdown","source":"\n##### Summary of variable analysis:\nThere are 7 Numerical Variables  : where 3 are discrete ,  2 continuous , 1 target and 1 not useful ID\nThere are 5 Categorical Variables: where 2 are Mixed "},{"metadata":{"_uuid":"78784c9d0a0c52f5c3248c1c2df28f208f31f427"},"cell_type":"markdown","source":"____"},{"metadata":{"_uuid":"33c4bb15b6cd53361d77741b04e96f0f854877fc"},"cell_type":"markdown","source":"##### Check Missing Data : \nAt this point to understand the data is important to know if there are lot of missing data, can check the mean of NULL for each feature, can be performed using isnull().mean() function"},{"metadata":{"trusted":false,"_uuid":"269cae7f30bd4fa8a0b14ecdaf88b6be8b2ebfef","collapsed":true},"cell_type":"code","source":"data.isnull().mean()","execution_count":223,"outputs":[]},{"metadata":{"_uuid":"ac6777e0b5328f51d3571f49d2605b1769ecf605"},"cell_type":"markdown","source":"* 19.86% of Age are missing\n* 77% of Cabin are missing\n* 0.2% of Embarked are missing"},{"metadata":{"_uuid":"99e12c8499b2ced984bc798497c346c9224641c2"},"cell_type":"markdown","source":"##### Check Outliners for continuous variables (FARE and AGE) : \nBased on the list created without target and variable such as ID we can check the outliers for continuous variable using boxplot and also the discribuition in order to see if we have Gaussian or skewed distribuition, for that we can use hist."},{"metadata":{"trusted":false,"_uuid":"8842d4cbd19581212cdaee9f03063ed683f93021","collapsed":true},"cell_type":"code","source":"numerical = [var for var in numerical if var not in ['Survived','PassengerId']]\nnumerical","execution_count":224,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f58713fbd1d795554079a458b17e7b535ab5fed0","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nplt.subplot(1, 2, 1)\ndata.boxplot(column='Fare')\n\nplt.subplot(1,2,2)\ndata.boxplot(column='Age')","execution_count":225,"outputs":[]},{"metadata":{"_uuid":"d9ebafe41d48ff68c71d3bcea5898fa3c2b2cba0"},"cell_type":"markdown","source":"Both Continuous variables (Fare and Age) have outliers\n\nCheck the distribuition:\n\n - Fare is a skewed and Age is a little Gaussian"},{"metadata":{"trusted":false,"_uuid":"29533efde72c8bf08d37cc8d06601225a35c6a9d","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nplt.subplot(1, 2, 1)\nfig = data.Age.hist()\nfig.set_ylabel('# Passagers')\nfig.set_xlabel('Age')\n\nplt.subplot(1,2,2)\nfig = data.Fare.hist()\nfig.set_ylabel('# Passagers')\nfig.set_xlabel('Fare')","execution_count":226,"outputs":[]},{"metadata":{"_uuid":"f5d9d1d5a4612f1c4b78cd2d5474f47ee75a49ff"},"cell_type":"markdown","source":"* Gaussian assumption for Age\n\nFor Gaussian, a suggestion is create two variable, one called Lowerboundary with mean - 3 times standard deviation and another Upperboundary with mean + 3 times standard deviation."},{"metadata":{"trusted":false,"_uuid":"c666dd72f916340a87af8dd7792f20231263a508","collapsed":true},"cell_type":"code","source":"Lowerboundary = data.Age.mean() - 3 * data.Age.std()\nUpperboundary = data.Age.mean() + 3 * data.Age.std()\nprint('Age outliers < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lowerboundary, upperboundary=Upperboundary))","execution_count":227,"outputs":[]},{"metadata":{"_uuid":"a77878c82d1640b2eaa78b6ad4b8b487e9c2caac"},"cell_type":"markdown","source":"\n\n* Interquantile range for Fare\n\nFor Skewed, create a IQR that is quantile(0.75) - quantile(0.25), that going to be used to calculate the Lowerfence that is quantile(0.25) - (IQR * 3) and Upperfence quantile(0.75) + (IQR * 3"},{"metadata":{"trusted":false,"_uuid":"13c8793da14f394d1ed28c1436ea6d931177bcea","collapsed":true},"cell_type":"code","source":"IQR = data.Fare.quantile(0.75) - data.Fare.quantile(0.25)\nLowerfence = data.Fare.quantile(0.25) - (IQR * 3)\nUpperfence = data.Fare.quantile(0.75) + (IQR * 3)\nprint('Fare outliers < {lowerfence} or > {upperfence}'.format(lowerfence=Lowerfence,upperfence=Upperfence))","execution_count":228,"outputs":[]},{"metadata":{"_uuid":"a591f6d83e71f955d441efad44fc454b1b6fbfd9"},"cell_type":"markdown","source":"##### Summary of variable analysis #2:\n - There are 7 Numerical Variables : where 3 are discrete , 2 continuous , 1 target and 1 not useful ID \n - There are 5 Categorical Variables: where 2 are Mixed\n - Age outliers are < -13 or > 73    \n     - Maybe use Top-Coding\n - Fare outliers are < -61 or > 100\n     - Maybe use Discretization\n\n"},{"metadata":{"_uuid":"7aff5ffda5edde077f6ff0c71f5ae04fe4c6f69f"},"cell_type":"markdown","source":"##### Check Outliners for discrete variables ('SibSp', 'Parch', 'Pclass') : \n\nOutliers in discrete variables : Calculate the % of values(sample data[var].valuecounts() / np.float(len(data)) , can consider outliers those values that are present in less than 1% of the occurrences."},{"metadata":{"trusted":false,"_uuid":"60f64b9c76646beeecfd52f41a98b26ea1b01658","collapsed":true},"cell_type":"code","source":"for var in ['SibSp', 'Parch', 'Pclass']:\n    print(var , data[var].value_counts() / np.float(len(data)))\n    print()","execution_count":229,"outputs":[]},{"metadata":{"_uuid":"9c64f336f3542b19b3fc327c9471f0ced182744e"},"cell_type":"markdown","source":"##### Summary of variable analysis #3:\n - There are 7 Numerical Variables : where 3 are discrete , 2 continuous , 1 target and 1 not useful ID \n - There are 5 Categorical Variables: where 2 are Mixed\n - Age outliers are < -13 or > 73    \n     - Top-Coding\n - Fare outliers are < -61 or > 100\n     -  Discretization\n - Pclass do not have outliers\n - Parch values > 2 are outliers\n     - Top-Coding(2)\n - SibSp values > 4 are outliers\n     - Top-Coding(4)"},{"metadata":{"_uuid":"581d6df173f3130d157aa5c5bf73e6891c131c56"},"cell_type":"markdown","source":"##### Cardinality of Categofical variables: \nCheck the number of labels, in order to see the cardinality of variables, can do a loop on categorical list and check : len(data[var].unique()), here you going to have an oportunity to see the rare labels and have an idea to group or note that labels."},{"metadata":{"trusted":false,"_uuid":"5e8aef29cd39249d9f460f62b6436b1c32e944e1","collapsed":true},"cell_type":"code","source":"for var in categorical:\n    print(var, ' :  ', len(data[var].unique()), '  labels')","execution_count":230,"outputs":[]},{"metadata":{"_uuid":"32dd0858aeb4b0aa36516e35e1e6d62a1c81c468"},"cell_type":"markdown","source":"### Phase #3 Data Preparation"},{"metadata":{"_uuid":"172b45b19f0185aeb1c373978443b80b74540afc"},"cell_type":"markdown","source":"#### 1st Lets work with Mixed values for Cabin and Ticket\n\nFor Cabin lets create two new variables Cabin_numerical and Cab_categorical and delete the Cabin"},{"metadata":{"trusted":false,"_uuid":"dd09461f4e4759c75f465d8e466199c7ae6b76b9","collapsed":true},"cell_type":"code","source":"data['Cabin_numerical'] = data.Cabin.str.extract('(\\d+)')\ndata['Cabin_numerical'] = data['Cabin_numerical'].astype('float')\ndata['Cabin_categorical'] = data.Cabin.str[0]\n\nsubmission['Cabin_numerical'] = submission.Cabin.str.extract('(\\d+)')\nsubmission['Cabin_numerical'] = submission['Cabin_numerical'].astype('float')\nsubmission['Cabin_categorical'] = submission.Cabin.str[0]\n\ndata[['Cabin', 'Cabin_numerical', 'Cabin_categorical']].tail()\n","execution_count":231,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"02fe8374e1f578655b2db16f0642c5c8ba40e986"},"cell_type":"code","source":"# Remove Cabin\n\ndata.drop(labels='Cabin', inplace=True, axis=1)\nsubmission.drop(labels='Cabin', inplace=True, axis=1)","execution_count":232,"outputs":[]},{"metadata":{"_uuid":"a1c8ec4d96dd3fcde7d0d8ce35fde40c6d9e9b6d"},"cell_type":"markdown","source":"For Ticket, extract the last part of ticket as number and first part as categorical"},{"metadata":{"trusted":false,"_uuid":"95ac83f78fba549a2504ead12b72fe7199bc7049","collapsed":true},"cell_type":"code","source":"data['Ticket_numerical'] = data.Ticket.apply(lambda s: s.split()[-1])\ndata['Ticket_numerical'] = np.where(data.Ticket_numerical.str.isdigit(),data.Ticket_numerical, np.nan )\ndata['Ticket_numerical'] = data['Ticket_numerical'].astype('float')\n\ndata['Ticket_categorical'] = data.Ticket.apply(lambda s: s.split()[0])\ndata['Ticket_categorical'] = np.where(data.Ticket_categorical.str.isdigit(), np.nan, data.Ticket_categorical )\n\n\nsubmission['Ticket_numerical'] = submission.Ticket.apply(lambda s: s.split()[-1])\nsubmission['Ticket_numerical'] = np.where(submission.Ticket_numerical.str.isdigit(),submission.Ticket_numerical, np.nan )\nsubmission['Ticket_numerical'] = submission['Ticket_numerical'].astype('float')\n\nsubmission['Ticket_categorical'] = submission.Ticket.apply(lambda s: s.split()[0])\nsubmission['Ticket_categorical'] = np.where(submission.Ticket_categorical.str.isdigit(), np.nan, submission.Ticket_categorical)\n\n\ndata[['Ticket', 'Ticket_numerical', 'Ticket_categorical']].head()\n","execution_count":233,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"f407816b334d7e44795f3a501cbd3b67a72ee75c"},"cell_type":"code","source":"# Remove Ticker\n\ndata.drop(labels='Ticket', inplace=True, axis=1)\nsubmission.drop(labels='Ticket', inplace=True, axis=1)","execution_count":234,"outputs":[]},{"metadata":{"_uuid":"024ae9442d0b9e099ffa02437e73b24103f7a7e1"},"cell_type":"markdown","source":"Exploring the Ticket_categorical\n * Can be improved removing the non letters."},{"metadata":{"trusted":false,"_uuid":"a36d763cfbfd65f2dbd34c8e2eceaad4a4ce8f18","collapsed":true},"cell_type":"code","source":"data.Ticket_categorical.unique()","execution_count":235,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"07f34097f746deecec3989e3b3f40a08588e6338"},"cell_type":"code","source":"def get_title(passenger):\n    # extracts the title from the name variable\n    line = passenger\n    if re.search('Mrs', line):\n        return 'Mrs'\n    elif re.search('Mr', line):\n        return 'Mr'\n    elif re.search('Miss', line):\n        return 'Miss'\n    elif re.search('Master', line):\n        return 'Master'\n    else:\n        return 'Other'\n    \ndata['Title'] = data['Name'].apply(get_title)\nsubmission['Title'] = submission['Name'].apply(get_title)\n\ndata[['Name', 'Title']].head()\n\n# drop the original variable\ndata.drop(labels='Name', inplace=True, axis=1)\nsubmission.drop(labels='Name', inplace=True, axis=1)","execution_count":236,"outputs":[]},{"metadata":{"_uuid":"034ef41c6e7f0dd7a2507cb1f4254ea257192ef4"},"cell_type":"markdown","source":"Before lead with outliers we can create a new variable Family_size with SibSp + Parch"},{"metadata":{"trusted":false,"_uuid":"18ec8d163c85ec336d3aae17408dee934fa797ca","collapsed":true},"cell_type":"code","source":"data['Family_size'] = data['SibSp'] + data['Parch'] + 1\nsubmission['Family_size'] = submission['SibSp'] + submission['Parch'] + 1\n\nprint(data.Family_size.value_counts()/np.float(len(data)))\n(data.Family_size.value_counts()/np.float(len(data))).plot.bar()","execution_count":237,"outputs":[]},{"metadata":{"_uuid":"93dbcceffcbcb7869448a1916d58ad2346c59041"},"cell_type":"markdown","source":"#### Check the outliers for numerical new variables : \n\nas expected the new numerical variables from cabin and ticket have NAs"},{"metadata":{"trusted":false,"_uuid":"542ebd5de1ab5f0ed99ea2418b2a788dcd510918","collapsed":true},"cell_type":"code","source":"data[['Cabin_numerical', 'Ticket_numerical', 'Family_size']].isnull().mean()","execution_count":238,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4898ed0f170ef6e677800c52cf1fc53768475e1d","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nplt.subplot(1, 2, 1)\ndata.boxplot(column='Cabin_numerical')\n\nplt.subplot(1,2,2)\ndata.boxplot(column='Ticket_numerical')","execution_count":239,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a42e37e9df50e4e9fe1228dec3fba29a420422ed","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(12,5))\nplt.subplot(1, 2, 1)\nfig = data.Cabin_numerical.hist(bins=20)\nfig.set_ylabel('# Passagers')\nfig.set_xlabel('Cabin_numerical')\n\nplt.subplot(1,2,2)\nfig = data.Ticket_numerical.hist(bins=20)\nfig.set_ylabel('# Passagers')\nfig.set_xlabel('Ticket_numerical')","execution_count":240,"outputs":[]},{"metadata":{"_uuid":"c81262a5d4207d93092990e43fab30c5a348062f"},"cell_type":"markdown","source":"##### Summary of variable analysis #4:\n - There are 7 Numerical Variables : where 3 are discrete , 2 continuous , 1 target and 1 not useful ID \n - There are 5 Categorical Variables: where 2 are Mixed (DONE)\n     - 4 new variables created :\n         - Cabin_numerical and Cabin_categorical\n         - Ticket_numerical and Ticket_categorical\n - Ticket_numerical have outliers as we can see above\n - Age outliers are < -13 or > 73    \n     - Top-Coding\n - Fare outliers are < -61 or > 100\n     -  Discretization\n - Pclass do not have outliers\n - Parch values > 2 are outliers\n     - Top-Coding(2)\n - SibSp values > 4 are outliers\n     - Top-Coding(4)"},{"metadata":{"_uuid":"786eeb1643d35b01c3a1b79a5aa933cc1af7e760"},"cell_type":"markdown","source":"###### Check the outliers for Ticket_numerical "},{"metadata":{"trusted":false,"_uuid":"50b37dc30136a12e4f1504750afb52e72894a9e7","collapsed":true},"cell_type":"code","source":"IQR = data.Ticket_numerical.quantile(0.75) - data.Ticket_numerical.quantile(0.25)\nLowerfence = data.Ticket_numerical.quantile(0.25) - (IQR * 3)\nUpperfence = data.Ticket_numerical.quantile(0.75) + (IQR * 3)\nprint('Ticket_numerical outliers < {lowerfence} or > {upperfence}'.format(lowerfence=Lowerfence,upperfence=Upperfence))","execution_count":241,"outputs":[]},{"metadata":{"_uuid":"bcd04e00548d89101c813453e4e73a6b93bbb93b"},"cell_type":"markdown","source":"##### Check new categorical variables: Missing values"},{"metadata":{"trusted":false,"_uuid":"6f3054e64df10041d1d41ac9e708415fb1751225","collapsed":true},"cell_type":"code","source":"data[['Cabin_categorical', 'Ticket_categorical']].isnull().mean()","execution_count":242,"outputs":[]},{"metadata":{"_uuid":"ee2a89385e3d15ebd069a7d2cf12339ec2378dd9"},"cell_type":"markdown","source":"##### Check cardinality\n"},{"metadata":{"trusted":false,"_uuid":"81e999611cf578f615021f5645a66ee050640196","collapsed":true},"cell_type":"code","source":"for var in ['Cabin_categorical', 'Ticket_categorical']:\n    print(var, ' contains ', len(data[var].unique()), ' labels')","execution_count":243,"outputs":[]},{"metadata":{"_uuid":"417c059adee6271b77681502a3cea654c04d57ae"},"cell_type":"markdown","source":"##### Check the rare labels\n\n- For Cabin_categorical G and T are in less then 1% are rare\n- For Ticket_categorical several are rare"},{"metadata":{"trusted":false,"_uuid":"12bc93b67ce77d7b857620d0c2387236d3f2587e","collapsed":true},"cell_type":"code","source":"# rare / infrequent labels (less than 1% of passengers)\nfor var in ['Cabin_categorical', 'Ticket_categorical']:\n    print(data[var].value_counts() / np.float(len(data)))\n    print()","execution_count":244,"outputs":[]},{"metadata":{"_uuid":"aacf00e210afe0c029e69fc89e694193bdb62b59"},"cell_type":"markdown","source":"##### Summary of variable analysis #5:\n - There are 7 Numerical Variables : where 3 are discrete , 2 continuous , 1 target and 1 not useful ID \n - There are 5 Categorical Variables: where 2 are Mixed (DONE)\n     - 4 new variables created :\n         - Cabin_numerical  : Do not have outliers\n         - Ticket_numerical : have outliers   < -981730.0 or > 1343691.0\n         - Cabin_categorical: G and T are in less then 1% are rare , replace by most frequent \n         - Ticket_categorical: lot of rare, replace by rare \n         - Family_size\n - Age outliers are < -13 or > 73    \n     - Top-Coding\n - Fare outliers are < -61 or > 100\n     -  Discretization\n - Pclass do not have outliers\n - Parch values > 2 are outliers\n     - Top-Coding(2)\n - SibSp values > 4 are outliers\n     - Top-Coding(4)"},{"metadata":{"_uuid":"c9bc87f703ce03ce6cd7f04de2d7bb130d4a444f"},"cell_type":"markdown","source":"### Split the dataset:\n\n"},{"metadata":{"trusted":false,"_uuid":"039eda0ba0f3ca6cc33595d52d98210783b39a91","collapsed":true},"cell_type":"code","source":"# Let's separate into train and test set\n\nX_train, X_test, y_train, y_test = train_test_split(data, data.Survived, test_size=0.3)\nX_train.shape, X_test.shape","execution_count":245,"outputs":[]},{"metadata":{"_uuid":"518ed1df1da2fee7a98dc4f208a587e4de650b57"},"cell_type":"markdown","source":"##### Create two list :\n* Categorical\n* Numerical (without ID and Target)"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"c69ec1ca37a4dd937711eb5ebc1a87b522a4c3c2"},"cell_type":"code","source":"def find_categorical_and_numerical(df):\n    var_cat = [col for col in df.columns if df[col].dtype == 'O']\n    var_num = [col for col in df.columns if df[col].dtype != 'O']\n    return var_cat,var_num\n\ncategorical, numerical = find_categorical_and_numerical(data)       ","execution_count":246,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"cac5eaab8cc8de84d99d93e085dec9ba48012fe4","collapsed":true},"cell_type":"code","source":"print(categorical)\nprint(numerical)","execution_count":247,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"92802e49ce68f1aea3843dbe81a01fe1e7bd8ac0","collapsed":true},"cell_type":"code","source":"numerical = [var for var in numerical if var not in ['PassengerId', 'Survived']]\nnumerical","execution_count":248,"outputs":[]},{"metadata":{"_uuid":"e9fa83a7fca8be78d172cb0133bda80e192640f0"},"cell_type":"markdown","source":"##### Engineering missing values in numerical variables "},{"metadata":{"_uuid":"3f7ce49c7bf7a973944bb5d17c23ea95c61f59c5"},"cell_type":"markdown","source":"Check variable with missing data"},{"metadata":{"trusted":false,"_uuid":"7552ced3eb49caad948ea5c11179fec5517b3d15","collapsed":true},"cell_type":"code","source":"for col in numerical:\n    if X_train[col].isnull().mean()> 0:\n        print(col, X_train[col].isnull().mean())\n    ","execution_count":249,"outputs":[]},{"metadata":{"_uuid":"59bcc4732d88bcb4d820c1282fca38ffc95d17ac"},"cell_type":"markdown","source":"* Age and Ticket have < 50% of NA : Approach : create a new variable NA + Random sample imputation\n* Cabin have > 50% of NA : Approach : impute NA by value far the distribution"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"f755d73ca8e8987661f9341cd559d58e9842f136"},"cell_type":"code","source":"def impute_na(X_train, df, variable):\n    # make temporary df copy\n    temp = df.copy()\n    \n    # extract random from train set to fill the na\n    random_sample = X_train[variable].dropna().sample(temp[variable].isnull().sum())\n    \n    # pandas needs to have the same index in order to merge datasets\n    random_sample.index = temp[temp[variable].isnull()].index\n    temp.loc[temp[variable].isnull(), variable] = random_sample\n    return temp[variable]","execution_count":250,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"9ae45e8967dd2e4dfb45f50b5cc0b066c38ac4f1"},"cell_type":"code","source":"# Age and ticket\n# add variable indicating missingness\nfor df in [X_train, X_test, submission]:\n    for var in ['Age', 'Ticket_numerical']:\n        df[var+'_NA'] = np.where(df[var].isnull(), 1, 0)\n    \n# replace by random sampling\nfor df in [X_train, X_test, submission]:\n    for var in ['Age', 'Ticket_numerical']:\n        df[var] = impute_na(X_train, df, var)\n    \n\n# Cabin numerical\nextreme = X_train.Cabin_numerical.mean() + X_train.Cabin_numerical.std()*3\nfor df in [X_train, X_test, submission]:\n    df.Cabin_numerical.fillna(extreme, inplace=True)","execution_count":251,"outputs":[]},{"metadata":{"_uuid":"3ebeeaaf2b1399dc1d05f7a11165344a509d8b66"},"cell_type":"markdown","source":"##### Engineering Missing Data in categorical variables"},{"metadata":{"trusted":false,"_uuid":"39e4ba2081a78133e2e5b8dce2f2d53dd7fa331d","collapsed":true},"cell_type":"code","source":"for col in categorical:\n    if X_train[col].isnull().mean()>0:\n        print(col, X_train[col].isnull().mean())","execution_count":252,"outputs":[]},{"metadata":{"_uuid":"db2ce34903cbad0dee85d2f53606142d82b6954b"},"cell_type":"markdown","source":"* Embarked NA imputed by most frequent category, because NA is low\n* Cabin_categorical imputed by 'Missing', because NA is high\n* Ticket_categorical imput by 'Missing', because NA is high"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"9b78eb4168a16eddb269a8d09232abba321a5034"},"cell_type":"code","source":"for df in [X_train, X_test, submission]:\n    df['Embarked'].fillna(X_train['Embarked'].mode()[0], inplace=True)\n    df['Cabin_categorical'].fillna('Missing', inplace=True)\n    df['Ticket_categorical'].fillna('Missing', inplace=True)","execution_count":253,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a53d9bd948a04fa344ac4b629dc1050d0c6bf2e1","collapsed":true},"cell_type":"code","source":"submission.isnull().mean()","execution_count":254,"outputs":[]},{"metadata":{"_uuid":"82fc453cf2dc7cb44e4619a3f7ed5d2a31f9af15"},"cell_type":"markdown","source":"* Checking the 3 datasets submission have Fare still with NA value, will replace by median"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"3d1586566e0263f13bbe65197fd807c1a344d194"},"cell_type":"code","source":"submission.Fare.fillna(X_train.Fare.median(), inplace=True)","execution_count":255,"outputs":[]},{"metadata":{"_uuid":"eb52f561994250cad730e40b8c45196da8e16c0d"},"cell_type":"markdown","source":"#### Outliers in Numerical variables"},{"metadata":{"_uuid":"313256e83f7815bc5cf320d915cfc37870efab56"},"cell_type":"markdown","source":"As have identified on last summary:\n\n\n* Ticket_numerical outliers  are < -981730.0 or > 1343691.0  -> Discretization\n* Age outliers are < -13 or > 73 -> Top-Coding(73)\n* Fare outliers are < -61 or > 100 -> Discretization\n* Parch values > 2 are outliers -> Top-Coding(2)\n* SibSp values > 4 are outliers -> Top-Coding(4)"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"03b7d74788636f029191f2b0cdbe74e1a522fd15"},"cell_type":"code","source":"def top_coding(df, variable, top):\n    return np.where(df[variable] > top, top, df[variable])\n\n\nfor df in [X_train,X_test, submission]:\n    df['Age'] = top_coding(df,'Age', 73)\n    df['Parch'] = top_coding(df,'Parch', 2)\n    df['SibSp'] = top_coding(df,'SibSp', 4)\n    df['Family_size'] = top_coding(df, 'Family_size', 7)","execution_count":256,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1e57867ac9e9d98ba3d3c9fa8f835300d8b91a53","collapsed":true},"cell_type":"code","source":"for var in ['Age','Parch','SibSp','Family_size']:\n    print(var, 'Max value : ', X_train[var].max() )","execution_count":257,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"882671e5dfdef1885a4a1e6549a80dda187d9592","collapsed":true},"cell_type":"code","source":"# find quantiles and discretise train set\nX_train['Fare'], bins = pd.qcut(x=X_train['Fare'], q=8, retbins=True, precision=3, duplicates='raise')\nX_test['Fare'] = pd.cut(x = X_test['Fare'], bins=bins, include_lowest=True)\nsubmission['Fare'] = pd.cut(x = submission['Fare'], bins=bins, include_lowest=True)\n\nt1 = X_train.groupby(['Fare'])['Fare'].count() / np.float(len(X_train))\nt2 = X_test.groupby(['Fare'])['Fare'].count() / np.float(len(X_test))\nt3 = submission.groupby(['Fare'])['Fare'].count() / np.float(len(submission))\n\ntemp = pd.concat([t1,t2,t3], axis=1)\ntemp.columns = ['train', 'test', 'submission']\ntemp.plot.bar(figsize=(12,6))","execution_count":258,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"22b375285bbecacc28084da3de3ada20b1275cf8"},"cell_type":"code","source":"# find quantiles and discretise train set\nX_train['Ticket_numerical'], bins = pd.qcut(x=X_train['Ticket_numerical'], q=8, retbins=True, precision=3, duplicates='raise')\nX_test['Ticket_numerical'] = pd.cut(x = X_test['Ticket_numerical'], bins=bins, include_lowest=True)\nsubmission['Ticket_numerical_temp'] = pd.cut(x = submission['Ticket_numerical'], bins=bins, include_lowest=True)","execution_count":259,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"39f8463dd3ac2349177743d59c3761dd41c1f236","collapsed":true},"cell_type":"code","source":"submission.Ticket_numerical_temp.isnull().sum()","execution_count":260,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a22dcc00f295c6d44a0c3b3973330be85520308f","collapsed":true},"cell_type":"code","source":"submission[submission.Ticket_numerical_temp.isnull()][['Ticket_numerical', 'Ticket_numerical_temp']]","execution_count":261,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"827903f6237256c8cc3632d07bfa2b23b1f9babf","collapsed":true},"cell_type":"code","source":"X_train.Ticket_numerical.unique()","execution_count":262,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9284037109ffbe552aa0243c3bd2a2023cecda69","collapsed":true},"cell_type":"code","source":"submission.loc[submission.Ticket_numerical_temp.isnull(), 'Ticket_numerical_temp'] = X_train.Ticket_numerical.unique()[0]\nsubmission.Ticket_numerical_temp.isnull().sum()","execution_count":263,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f0956feb14d362c0403ad52a59b6472f70fd6bb7","collapsed":true},"cell_type":"code","source":"submission['Ticket_numerical'] = submission['Ticket_numerical_temp']\nsubmission.drop(labels=['Ticket_numerical_temp'], inplace=True, axis=1)\nsubmission.head()","execution_count":264,"outputs":[]},{"metadata":{"_uuid":"fd3826812cfd08b253d6c0f1bdabde0fb2423315"},"cell_type":"markdown","source":"#### Engineering rare labels in categorical variables"},{"metadata":{"_uuid":"3508775dc8d586eb97d6a63850ea4687ee52c4f1"},"cell_type":"markdown","source":"Find the rare labels"},{"metadata":{"trusted":false,"_uuid":"e8b270212391402eb1a2f603c3b7bb403c8b32b2","collapsed":true},"cell_type":"code","source":"for var in categorical:\n    print(var, X_train[var].value_counts()/np.float(len(X_train)))\n    print()","execution_count":265,"outputs":[]},{"metadata":{"_uuid":"062bb1c7f5a3170063670b01b4eb60bb5c45290d"},"cell_type":"markdown","source":"As listed on last summary:\n- Cabin contains the rare labels G and T: replace by most frequent \n- Ticket contains a lot of infrequent labels: replace by rare\n"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"c81c0bb7fab15df0b9cee651595aeebb4bd7baad"},"cell_type":"code","source":"def rare_imputation(variable, which='rare'):    \n    # find frequent labels\n    temp = X_train.groupby([variable])[variable].count()/np.float(len(X_train))\n    frequent_cat = [x for x in temp.loc[temp>0.01].index.values]\n    \n    # create new variables, with Rare labels imputed\n    if which=='frequent':\n        # find the most frequent category\n        mode_label = X_train.groupby(variable)[variable].count().sort_values().tail(1).index.values[0]\n        X_train[variable] = np.where(X_train[variable].isin(frequent_cat), X_train[variable], mode_label)\n        X_test[variable] = np.where(X_test[variable].isin(frequent_cat), X_test[variable], mode_label)\n        submission[variable] = np.where(submission[variable].isin(frequent_cat), submission[variable], mode_label)\n    \n    else:\n        X_train[variable] = np.where(X_train[variable].isin(frequent_cat), X_train[variable], 'Rare')\n        X_test[variable] = np.where(X_test[variable].isin(frequent_cat), X_test[variable], 'Rare')\n        submission[variable] = np.where(submission[variable].isin(frequent_cat), submission[variable], 'Rare')","execution_count":266,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"7611298d8ce495a5137db0aed2b9930fa513bf49"},"cell_type":"code","source":"rare_imputation('Cabin_categorical', 'frequent')\nrare_imputation('Ticket_categorical', 'rare')","execution_count":267,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e428ce1e49cbc1f9ace6de790a2098d274d891e5","collapsed":true},"cell_type":"code","source":"# let's check that it worked\nfor var in categorical:\n    print(var, X_train[var].value_counts()/np.float(len(X_train)))\n    print()","execution_count":268,"outputs":[]},{"metadata":{"_uuid":"99a981c98c2f93e1f9c80b0e8bdb2deeb1f9e5e0"},"cell_type":"markdown","source":"#### Encode categorical variables "},{"metadata":{"trusted":false,"_uuid":"f168b0871ccd66f50cd87b2297f83b8ffd3a6068","collapsed":true},"cell_type":"code","source":"categorical","execution_count":269,"outputs":[]},{"metadata":{"_uuid":"1a41e8a6384d4711c98e7226bdaaa7a174024f01"},"cell_type":"markdown","source":"* sex we can use One-Hot Encoding\n* Others we can replace by risk probability "},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"239b87b6093821bd032029c899f2fa2ec6228203"},"cell_type":"code","source":"for df in [X_train, X_test, submission]:\n    df['Sex']  = pd.get_dummies(df.Sex, drop_first=True)","execution_count":270,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"132df46e5649caf244469f36ce696e278b919319","collapsed":true},"cell_type":"code","source":"X_train.Sex.unique()","execution_count":272,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"e759f854d5d0ec68464be0e3e2278e3f1010bb80"},"cell_type":"code","source":"def encode_categorical_variables(var, target):\n        # make label to risk dictionary\n        ordered_labels = X_train.groupby([var])[target].mean().to_dict()\n        \n        # encode variables\n        X_train[var] = X_train[var].map(ordered_labels)\n        X_test[var] = X_test[var].map(ordered_labels)\n        submission[var] = submission[var].map(ordered_labels)\n\n# enccode labels in categorical vars\nfor var in categorical:\n    encode_categorical_variables(var, 'Survived')\n    \n","execution_count":273,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"de01814878c3a564da255251e9037b9858d1a078"},"cell_type":"code","source":"# parse discretised variables to object before encoding\nfor df in [X_train, X_test, submission]:\n    df.Fare = df.Fare.astype('O')\n    df.Ticket_numerical = df.Ticket_numerical.astype('O')\n    ","execution_count":275,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bcee3db9ff5be919935beaefd0d94a56600da51b","collapsed":true},"cell_type":"code","source":"# encode labels\nfor var in ['Fare', 'Ticket_numerical']:\n    print(var)\n    encode_categorical_variables(var, 'Survived')","execution_count":276,"outputs":[]},{"metadata":{"_uuid":"1956a648c271a94c9ffee0bf97aa9c31c3d71392"},"cell_type":"markdown","source":"#### Feature scaling"},{"metadata":{"trusted":false,"_uuid":"25edee4faafdaa6fef86970c844a533584b6a0cc","collapsed":true},"cell_type":"code","source":"X_train.describe()","execution_count":277,"outputs":[]},{"metadata":{"_uuid":"3ce073a6575d1e781af2bc75b95f7fa93099f902"},"cell_type":"markdown","source":"Separate the variables to traning"},{"metadata":{"trusted":false,"_uuid":"d2d60783bf69ffd8efa6b4569af2afedc368a0b7","collapsed":true},"cell_type":"code","source":"training_vars = [var for var in X_train.columns if var not in ['PassengerId', 'Survived']]\ntraining_vars","execution_count":279,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f562985aace3c43d6f7de46bf65e0c155382a3df","collapsed":true},"cell_type":"code","source":"# fit scaler\nscaler = MinMaxScaler() # create an instance\nscaler.fit(X_train[training_vars]) #  fit  the scaler to the train set and then transform it","execution_count":280,"outputs":[]},{"metadata":{"_uuid":"6954d2623891f5b2d27a7562133a7ff1f5fe7282"},"cell_type":"markdown","source":"### Phase #4 Modeling & #5 Evaluation"},{"metadata":{"_uuid":"bab4a92eaf832300c3bc4e283c3d79c6c0bb5270"},"cell_type":"markdown","source":"##### Machine Learning algorithm building"},{"metadata":{"_uuid":"260328621147fc47338da451bffbdb3adc542ff1"},"cell_type":"markdown","source":"#### xgboost"},{"metadata":{"trusted":false,"_uuid":"f438ab5063e3d3316ba2ffea389f43a55853bbc1","collapsed":true},"cell_type":"code","source":"xgb_model = xgb.XGBClassifier()\n\neval_set = [(X_test[training_vars], y_test)]\nxgb_model.fit(X_train[training_vars], y_train, eval_metric=\"auc\", eval_set=eval_set, verbose=False)\n\npred = xgb_model.predict_proba(X_train[training_vars])\nprint('xgb train roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\npred = xgb_model.predict_proba(X_test[training_vars])\nprint('xgb test roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))","execution_count":281,"outputs":[]},{"metadata":{"_uuid":"746f4048b31dad69c2c2df076201295326b961da"},"cell_type":"markdown","source":"#### Random Florest"},{"metadata":{"trusted":false,"_uuid":"0b8175de651b9508dc54fe7500c3a550b812a7f6","collapsed":true},"cell_type":"code","source":"rf_model = RandomForestClassifier()\nrf_model.fit(X_train[training_vars], y_train)\n\npred = rf_model.predict_proba(X_train[training_vars])\nprint('RF train roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\npred = rf_model.predict_proba(X_test[training_vars])\nprint('RF test roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))","execution_count":282,"outputs":[]},{"metadata":{"_uuid":"8c7e59a521299f5c3b48d4831e3266937ed2dfe4"},"cell_type":"markdown","source":"#### Adaboost"},{"metadata":{"trusted":false,"_uuid":"2797e502a18fc14593f12ba8cc064babca167f0b","collapsed":true},"cell_type":"code","source":"ada_model = AdaBoostClassifier()\nada_model.fit(X_train[training_vars], y_train)\n\npred = ada_model.predict_proba(X_train[training_vars])\nprint('Adaboost train roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\npred = ada_model.predict_proba(X_test[training_vars])\nprint('Adaboost test roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))","execution_count":283,"outputs":[]},{"metadata":{"_uuid":"1496a8d73a7c730fd8eb8216b0f79e23b95e03a6"},"cell_type":"markdown","source":"#### Logistic Regression"},{"metadata":{"trusted":true,"_uuid":"082a0fe5feeb2bcd78493b0faf8ef5c93dc386bd"},"cell_type":"code","source":"logit_model = LogisticRegression()\nlogit_model.fit(scaler.transform(X_train[training_vars]), y_train)\n\npred = logit_model.predict_proba(scaler.transform(X_train[training_vars]))\nprint('Logit train roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\npred = ada_model.predict_proba(scaler.transform(X_test[training_vars]))\nprint('Logit test roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"0b64ede717c10008885eb48a7a04e4a1ac7d2826"},"cell_type":"markdown","source":"### Phase #6 Deployment"},{"metadata":{"_uuid":"2864bff2c1c5e04cef8baec873e4d521b2055f12"},"cell_type":"markdown","source":"#### Select threshold for maximum accuracy"},{"metadata":{"trusted":false,"_uuid":"3a7b6bf3f6d5f5d1a7944490d929a0f4181871ea","collapsed":true},"cell_type":"code","source":"pred_ls = []\nfor model in [xgb_model, rf_model, ada_model, logit_model]:\n    pred_ls.append(pd.Series(model.predict_proba(X_test[training_vars])[:,1]))\n\nfinal_pred = pd.concat(pred_ls, axis=1).mean(axis=1)\nprint('Ensemble test roc-auc: {}'.format(roc_auc_score(y_test,final_pred)))","execution_count":287,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"083eaa1bafb8266fbc093075206b4ffe98babef7","collapsed":true},"cell_type":"code","source":"tpr, tpr, thresholds = metrics.roc_curve(y_test, final_pred)\nthresholds","execution_count":288,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bd94fd9e27dbf98d4a65e91246a03e0ddda850e1","collapsed":true},"cell_type":"code","source":"accuracy_ls = []\nfor thres in thresholds:\n    y_pred = np.where(final_pred>thres,1,0)\n    accuracy_ls.append(metrics.accuracy_score(y_test, y_pred, normalize=True))\n    \naccuracy_ls = pd.concat([pd.Series(thresholds), pd.Series(accuracy_ls)],\n                        axis=1)\naccuracy_ls.columns = ['thresholds', 'accuracy']\naccuracy_ls.sort_values(by='accuracy', ascending=False, inplace=True)\naccuracy_ls.head()","execution_count":289,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"27eb86b84a6c785d8c1378d818770e9c08bb9125"},"cell_type":"code","source":"pred_ls = []\nfor model in [xgb_model, rf_model, ada_model, logit_model]:\n    pred_ls.append(pd.Series(model.predict_proba(submission[training_vars])[:,1]))\n\nfinal_pred = pd.concat(pred_ls, axis=1).mean(axis=1)","execution_count":290,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"518d95d075b4f2150e191ff9d32b3b1939b8b8ed"},"cell_type":"code","source":"final_pred = pd.Series(np.where(final_pred>0.40,1,0))","execution_count":293,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f21faf38d5bdcf96a3a9ef873510c5df5c001270","collapsed":true},"cell_type":"code","source":"temp = pd.concat([submission.PassengerId, final_pred], axis=1)\ntemp.columns = ['PassengerId', 'Survived']\ntemp.head()","execution_count":294,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"3c21fb6c392c2741c49be2a8c2302f7a80c76277"},"cell_type":"code","source":"temp.to_csv('submission.csv', index=False)","execution_count":295,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}