{"cells":[{"metadata":{"_uuid":"6f97eb35dbdb26a232ec96e211ee9a083de93086"},"cell_type":"markdown","source":"This notebook/kernel idea came to me after reading [A Neural Network in 11 lines of Python](https://iamtrask.github.io/2015/07/12/basic-python-network/)\nI advise you to read that nice article before exploring this kernel or comment on lack of explanations in it","outputs":[],"execution_count":null},{"metadata":{"_uuid":"aaf0ac49fc17eb61fc2b3676256c6f5ed5f148e1","_cell_guid":"689f65db-1232-4c18-928c-db5fe7761d34","trusted":true},"cell_type":"code","source":"'''how to basic neural network with numpy and titanic'''\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import scale\n\n# Input data files are available in the \"../input/\" directory.\ndf_train_full = pd.read_csv(\"../input/train.csv\", index_col=\"PassengerId\")\ndf_test = pd.read_csv(\"../input/test.csv\", index_col=\"PassengerId\")\n\n\n# don't really care about these\ndf_train = df_train_full.drop(['Name', 'Ticket', 'Cabin', 'Embarked', 'Survived'], axis=1)\ndf_train.info()\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5366c6a8a7bee26c299c915f015a95b492977ddc"},"cell_type":"markdown","source":"So we will work with 6 features in this example. Since we need our data be numecical, time to replace string values from Sex column and check dataset for missing values.","outputs":[],"execution_count":null},{"metadata":{"trusted":true,"_uuid":"f76ae1443250d4db4901abcf8c2d2ab306de1648"},"cell_type":"code","source":"# we need sex to be int\nfor dataset in (df_train, df_test):\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n    \n# and what about missing values?\nfor col in df_train.columns.values:\n    print(f\"any nan in{col}?:\", df_train[col].isnull().any())\n# looks like age is our only problem\ndf_train.Age.fillna(df_train.Age.mean(), inplace=True) # its a lazy example, so mean is fine\nprint(df_train['Age'].isnull().any())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c267c763c6be5d48bd2ba1d02080f8d4971f9784","_cell_guid":"f44aeb77-7807-4f7c-95f1-535d2c19f940"},"cell_type":"markdown","source":"Okay, lets start making neural network. Every network has the same algorithm:\n1. Have the layer data dot weights\n2. Use activation function on the result\n3. Get the error (target value - prediction)\n4. Change the weights to get lesser error in a next iteration\n5. ???\n6. Profit","outputs":[],"execution_count":null},{"metadata":{"_uuid":"9d564cc36fa75f71d0790e07ad8e98c65d0881ef","_cell_guid":"374d7a0b-b4d2-41aa-b167-9d5567bb957e","trusted":true},"cell_type":"code","source":"# https://en.wikipedia.org/wiki/Sigmoid_function\ndef sigmoid(x, derivative=False):\n    if derivative:\n        return x * (1 - x)\n    else:\n        return 1 / (1 + np.exp(-x))\n    \nX = scale(df_train)  # always scale\ny = df_train_full['Survived'].values\nprint(X.shape, y.shape)\n\n# nice, but we need to reshape y, to make it dot productable\ny = y.reshape(y.size, 1)\n\n# split the data to get accuracy\neighty = round(len(X) * .8)\nX_train, X_test = X[:eighty], X[eighty:]\ny_train, y_test = y[:eighty], y[eighty:]\nprint(X_train.shape, y_test.shape)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"21f9b221c700049c6f33353397c81473dd67757a","_cell_guid":"316dac79-9847-4ab4-af14-a6da293bf5ae","trusted":true},"cell_type":"code","source":"# weight\nnp.random.seed(1) # for repeatable outcome\nweight = np.random.random((6, 1)) # only part that changes over time\n\nfor i in range(1000):\n    inp_layer = X_train\n    # dot production on input data and weights and use activation function\n    out_layer = sigmoid(np.dot(inp_layer, weight))\n    # get a err size\n    err = y_train - out_layer\n    # backpropagation, use err to correct weights\n    d_out = err * sigmoid(out_layer, derivative=True)\n    weight += np.dot(inp_layer.T, d_out)\n    \n# now our nn is trained (we got expirienced weights)\ny_pred = sigmoid(np.dot(X_test, weight))\n\nprint(y_test.shape, y_pred.shape)\n# softmax\ny_pred[y_pred > 0.5] = 1\ny_pred[y_pred < 0.5] = 0\n\nprint(\"accuracy on test data: \", round(accuracy_score(y_test[:, 0], y_pred[:, 0]), 2))\n# yay, prediction level more than 50%, time to celebrate","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}