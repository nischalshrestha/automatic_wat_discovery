{"cells":[{"metadata":{"_cell_guid":"cfdaacbc-23a3-423d-8d4d-120939ac7383","_uuid":"131efbee3c3b4ab763ba79e725d1a56f60704a64","trusted":true,"scrolled":true,"collapsed":true},"cell_type":"code","source":"# pandas\nimport pandas as pd\nfrom pandas import Series,DataFrame\n\n# numpy, matplotlib, seaborn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n\n\nfrom sklearn.neural_network import MLPClassifier","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3ab4c525-a5cb-4183-9468-c1dd005c4c78","_uuid":"a90815371b457c057ef090bd9bf4b62e78bfbf4a","trusted":true,"collapsed":true},"cell_type":"code","source":"# get titanic & test csv files as a DataFrame\ntitanic_df = pd.read_csv(\"../input/train.csv\")\ntest_df    = pd.read_csv(\"../input/test.csv\")\n\n# preview the data\ntitanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"86179af8-3cb4-4661-84ea-addd2c7679d4","_uuid":"6079e253bb7e19a2ef25fbd27233bfd6420a8293","trusted":true,"collapsed":true},"cell_type":"code","source":"titanic_df.info()\nprint(\"----------------------------\")\ntest_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7faffa7c-9776-43fb-9c01-786630f237ab","_uuid":"cc78cf752775745f36727f0d7fa7f169aee255ad","trusted":true,"collapsed":true},"cell_type":"code","source":"# drop unnecessary columns, these columns won't be useful in analysis and prediction\ntitanic_df = titanic_df.drop(['PassengerId'], axis=1)\n#test_df    = test_df.drop(['Ticket'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ee39061bb14d9e828554e15a9347485e5054e15","collapsed":true},"cell_type":"code","source":"#Name\ntitanic_df_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in titanic_df[\"Name\"]]\ntest_df_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in test_df[\"Name\"]]\n\ntitanic_df[\"Title\"] = pd.Series(titanic_df_title)\ntest_df[\"Title\"] = pd.Series(test_df_title)\n\ntitanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48219107aef62d72c8c0a2a37835c968ee32341d","collapsed":true},"cell_type":"code","source":"g = sns.countplot(x=\"Title\",data=titanic_df)\n# easy to read\ng = plt.setp(g.get_xticklabels(), rotation=45)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a387839f822dac3c842a8fb093945a8f3cc27a0","collapsed":true},"cell_type":"code","source":"titanic_df[\"Title\"] = titanic_df[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ntest_df[\"Title\"] = test_df[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\ntitanic_df[\"Title\"] = titanic_df[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\ntest_df[\"Title\"] = test_df[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\n\ntitanic_df[\"Title\"] = titanic_df[\"Title\"].astype(int)\ntest_df[\"Title\"] = test_df[\"Title\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8ef3853783778a652399a1b8d5880727a454600","collapsed":true},"cell_type":"code","source":"g = sns.countplot(titanic_df[\"Title\"])\ng = g.set_xticklabels([\"Master\",\"Miss/Ms/Mme/Mlle/Mrs\",\"Mr\",\"Rare\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03286a0f260b2551942dda66b4ea044db337bd24","collapsed":true},"cell_type":"code","source":"g = sns.factorplot(x=\"Title\",y=\"Survived\",data=titanic_df,kind=\"bar\")\ng = g.set_xticklabels([\"Master\",\"Miss-Mrs\",\"Mr\",\"Rare\"])\ng = g.set_ylabels(\"survival probability\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d44326a9e2e69d731c011af3da0dad81dfa40e5","collapsed":true},"cell_type":"code","source":"titanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1df87e61a03551ffc74a86c5388ad2bf52915c5","collapsed":true},"cell_type":"code","source":"# convert to indicator values Title\ntitanic_df = pd.get_dummies(titanic_df, columns = [\"Title\"])\ntest_df = pd.get_dummies(test_df, columns = [\"Title\"])\ntitanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7bc9982395f801478a4cde6b96b3a1f5ab49aca6"},"cell_type":"code","source":"# Drop Name variable\ntitanic_df.drop(labels = [\"Name\"], axis = 1, inplace = True)\ntest_df.drop(labels = [\"Name\"], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f25fb7309f0868c8a1433957ac73775c53e4e0e6","collapsed":true},"cell_type":"code","source":"titanic_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e24c4c7617bd4eeca53e4ddf21e0e5beb3b68df6","collapsed":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1441ec8-7d77-4a69-990b-26e0b1e89b68","_uuid":"6d20ca5c866da4f4bdf212467e2c12499c415668","trusted":true,"collapsed":true},"cell_type":"code","source":"# Embarked\n\n# only in titanic_df, fill the two missing values with the most occurred value, which is \"S\".\ntitanic_df[\"Embarked\"] = titanic_df[\"Embarked\"].fillna(\"S\")\n\n# plot\nsns.factorplot('Embarked','Survived', data=titanic_df,size=4,aspect=3)\n\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(15,5))\n\n# sns.factorplot('Embarked',data=titanic_df,kind='count',order=['S','C','Q'],ax=axis1)\n# sns.factorplot('Survived',hue=\"Embarked\",data=titanic_df,kind='count',order=[1,0],ax=axis2)\nsns.countplot(x='Embarked', data=titanic_df, ax=axis1)\nsns.countplot(x='Survived', hue=\"Embarked\", data=titanic_df, order=[1,0], ax=axis2)\n\n# group by embarked, and get the mean for survived passengers for each value in Embarked\nembark_perc = titanic_df[[\"Embarked\", \"Survived\"]].groupby(['Embarked'],as_index=False).mean()\nsns.barplot(x='Embarked', y='Survived', data=embark_perc,order=['S','C','Q'],ax=axis3)\n\nembark_dummies_titanic  = pd.get_dummies(titanic_df['Embarked'])\nembark_dummies_test  = pd.get_dummies(test_df['Embarked'])\n\ntitanic_df = titanic_df.join(embark_dummies_titanic)\ntest_df    = test_df.join(embark_dummies_test)\n\ntitanic_df.drop(['Embarked'], axis=1,inplace=True)\ntest_df.drop(['Embarked'], axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1a9e2e1-1718-4e6a-b037-a2c1eca1c003","_uuid":"7232b39fd04072d0741d13107a26ffd8951ada65","trusted":true,"collapsed":true},"cell_type":"code","source":"# Fare\n\n# only for test_df, since there is a missing \"Fare\" values\ntest_df[\"Fare\"].fillna(test_df[\"Fare\"].median(), inplace=True)\n\n# convert from float to int\ntitanic_df['Fare'] = titanic_df['Fare'].astype(int)\ntest_df['Fare']    = test_df['Fare'].astype(int)\n\n# get fare for survived & didn't survive passengers \nfare_not_survived = titanic_df[\"Fare\"][titanic_df[\"Survived\"] == 0]\nfare_survived     = titanic_df[\"Fare\"][titanic_df[\"Survived\"] == 1]\n\n# get average and std for fare of survived/not survived passengers\navgerage_fare = DataFrame([fare_not_survived.mean(), fare_survived.mean()])\nstd_fare      = DataFrame([fare_not_survived.std(), fare_survived.std()])\n\n# plot\ntitanic_df['Fare'].plot(kind='hist', figsize=(15,3),bins=100, xlim=(0,50))\n\navgerage_fare.index.names = std_fare.index.names = [\"Survived\"]\navgerage_fare.plot(yerr=std_fare,kind='bar',legend=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"22ab0b38-6285-4d65-bb3e-dc923caed94b","_uuid":"12570eb5ac872b73cee37abe8cdd65a5261fc436","trusted":true,"collapsed":true},"cell_type":"code","source":"# Age \n\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,4))\naxis1.set_title('Original Age values - Titanic')\naxis2.set_title('New Age values - Titanic')\n\n# axis3.set_title('Original Age values - Test')\n# axis4.set_title('New Age values - Test')\n\n# get average, std, and number of NaN values in titanic_df\naverage_age_titanic   = titanic_df[\"Age\"].mean()\nstd_age_titanic       = titanic_df[\"Age\"].std()\ncount_nan_age_titanic = titanic_df[\"Age\"].isnull().sum()\n\n# get average, std, and number of NaN values in test_df\naverage_age_test   = test_df[\"Age\"].mean()\nstd_age_test       = test_df[\"Age\"].std()\ncount_nan_age_test = test_df[\"Age\"].isnull().sum()\n\n# generate random numbers between (mean - std) & (mean + std)\nrand_1 = np.random.randint(average_age_titanic - std_age_titanic, average_age_titanic + std_age_titanic, size = count_nan_age_titanic)\nrand_2 = np.random.randint(average_age_test - std_age_test, average_age_test + std_age_test, size = count_nan_age_test)\n\n# plot original Age values\n# NOTE: drop all null values, and convert to int\ntitanic_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)\n# test_df['Age'].dropna().astype(int).hist(bins=70, ax=axis1)\n\n# fill NaN values in Age column with random values generated\ntitanic_df[\"Age\"][np.isnan(titanic_df[\"Age\"])] = rand_1\ntest_df[\"Age\"][np.isnan(test_df[\"Age\"])] = rand_2\n\n# convert from float to int\ntitanic_df['Age'] = titanic_df['Age'].astype(int)\ntest_df['Age']    = test_df['Age'].astype(int)\n        \n# plot new Age Values\ntitanic_df['Age'].hist(bins=70, ax=axis2)\n# test_df['Age'].hist(bins=70, ax=axis4)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"952009ab-555c-46f8-b419-182f2de39ca0","_uuid":"47e584025762620ce6e0a09077b1cc4d84b94a2f","trusted":true,"collapsed":true},"cell_type":"code","source":"# .... continue with plot Age column\n\n# peaks for survived/not survived passengers by their age\nfacet = sns.FacetGrid(titanic_df, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, titanic_df['Age'].max()))\nfacet.add_legend()\n\n# average survived passengers by age\nfig, axis1 = plt.subplots(1,1,figsize=(18,4))\naverage_age = titanic_df[[\"Age\", \"Survived\"]].groupby(['Age'],as_index=False).mean()\nsns.barplot(x='Age', y='Survived', data=average_age)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ef0f0c9d-6b45-4cb0-9026-86b764084398","_uuid":"e1c738cd8d2c8f9ddca7b02d0e8f4ac9d15ce108","trusted":true,"collapsed":true},"cell_type":"code","source":"# Cabin&Ticket\ntitanic_len = len(titanic_df)\nall_dataset =  pd.concat(objs=[titanic_df, test_df], axis=0).reset_index(drop=True)\n# Replace the Cabin number by the type of cabin 'X' if not\nall_dataset[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in all_dataset['Cabin'] ])\nTicket = []\nfor i in list(all_dataset.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"/\",\"\").strip().split(' ')[0]) #Take prefix\n    else:\n        Ticket.append(\"X\")\nall_dataset[\"Ticket\"] = Ticket\n\n\n\n#g = sns.countplot(all_dataset[\"Cabin\"],order=['A','B','C','D','E','F','G','T','X'])\n#g = sns.factorplot(y=\"Survived\",x=\"Cabin\",data=all_dataset,kind=\"bar\",order=['A','B','C','D','E','F','G','T','X'])\n#g = g.set_ylabels(\"Survival Probability\")\n\nall_dataset = pd.get_dummies(all_dataset, columns = [\"Cabin\"],prefix=\"Cabin\")\nall_dataset = pd.get_dummies(all_dataset, columns = [\"Ticket\"], prefix=\"T\")\n\ntitanic_df = all_dataset[:titanic_len]\ntitanic_df = titanic_df.drop([\"PassengerId\"],axis=1)\ntitanic_df[\"Survived\"] = titanic_df[\"Survived\"].astype(int)\n\ntest_df = all_dataset[titanic_len:]\ntest_df = test_df.drop([\"Survived\"],axis=1)\ntest_df[\"PassengerId\"] = test_df[\"PassengerId\"].astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a89c93bb-e45b-44ce-8dee-430f584f4ed4","_uuid":"aa87e0ec1b94f5bb27a0890b80c5f3d445cfa2cd","trusted":true,"collapsed":true},"cell_type":"code","source":"# Family\n\n# Instead of having two columns Parch & SibSp, \n# we can have only one column represent if the passenger had any family member aboard or not,\n# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.\ntitanic_df['Family'] =  titanic_df[\"Parch\"] + titanic_df[\"SibSp\"]+1\ntest_df['Family'] =  test_df[\"Parch\"] + test_df[\"SibSp\"]+1\n\n# drop Parch & SibSp\ntitanic_df = titanic_df.drop(['SibSp','Parch'], axis=1)\ntest_df    = test_df.drop(['SibSp','Parch'], axis=1)\n\ng = sns.factorplot(x=\"Family\",y=\"Survived\",data = titanic_df)\ng = g.set_ylabels(\"Survival Probability\")\n\n\n# Create new feature of family size\ntitanic_df['Single'] = titanic_df['Family'].map(lambda s: 1 if s == 1 else 0)\ntitanic_df['SmallF'] = titanic_df['Family'].map(lambda s: 1 if  s == 2  else 0)\ntitanic_df['MedF'] = titanic_df['Family'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntitanic_df['LargeF'] = titanic_df['Family'].map(lambda s: 1 if s >= 5 else 0)\n\ntest_df['Single'] = test_df['Family'].map(lambda s: 1 if s == 1 else 0)\ntest_df['SmallF'] = test_df['Family'].map(lambda s: 1 if  s == 2  else 0)\ntest_df['MedF'] = test_df['Family'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntest_df['LargeF'] = test_df['Family'].map(lambda s: 1 if s >= 5 else 0)\n\n\ng = sns.factorplot(x=\"Single\",y=\"Survived\",data=titanic_df,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")\ng = sns.factorplot(x=\"SmallF\",y=\"Survived\",data=titanic_df,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")\ng = sns.factorplot(x=\"MedF\",y=\"Survived\",data=titanic_df,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")\ng = sns.factorplot(x=\"LargeF\",y=\"Survived\",data=titanic_df,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"23c2f140-1dc0-48cd-a6e1-9786510b2606","_uuid":"8158daf0518b4b1a9eabb7a655800377da65c916","trusted":true,"collapsed":true},"cell_type":"code","source":"# Sex\n\n# As we see, children(age < ~16) on aboard seem to have a high chances for Survival.\n# So, we can classify passengers as males, females, and child\ndef get_person(passenger):\n    age,sex = passenger\n    return 'child' if age < 16 else sex\n    \ntitanic_df['Person'] = titanic_df[['Age','Sex']].apply(get_person,axis=1)\ntest_df['Person']    = test_df[['Age','Sex']].apply(get_person,axis=1)\n\n# No need to use Sex column since we created Person column\ntitanic_df.drop(['Sex'],axis=1,inplace=True)\ntest_df.drop(['Sex'],axis=1,inplace=True)\n\n# create dummy variables for Person column, & drop Male as it has the lowest average of survived passengers\nperson_dummies_titanic  = pd.get_dummies(titanic_df['Person'])\nperson_dummies_titanic.columns = ['Child','Female','Male']\nperson_dummies_titanic.drop(['Male'], axis=1, inplace=True)\n\nperson_dummies_test  = pd.get_dummies(test_df['Person'])\nperson_dummies_test.columns = ['Child','Female','Male']\nperson_dummies_test.drop(['Male'], axis=1, inplace=True)\n\ntitanic_df = titanic_df.join(person_dummies_titanic)\ntest_df    = test_df.join(person_dummies_test)\n\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(10,5))\n\n# sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)\nsns.countplot(x='Person', data=titanic_df, ax=axis1)\n\n# average of survived for each Person(male, female, or child)\nperson_perc = titanic_df[[\"Person\", \"Survived\"]].groupby(['Person'],as_index=False).mean()\nsns.barplot(x='Person', y='Survived', data=person_perc, ax=axis2, order=['male','female','child'])\n\ntitanic_df.drop(['Person'],axis=1,inplace=True)\ntest_df.drop(['Person'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0f126c1f-74b8-4063-8ac0-f44e6b8fc0bd","_uuid":"beb03630a882d0a0762af627e632b0fc53cf3d48","trusted":true,"collapsed":true},"cell_type":"code","source":"# Pclass\n\n# sns.factorplot('Pclass',data=titanic_df,kind='count',order=[1,2,3])\nsns.factorplot('Pclass','Survived',order=[1,2,3], data=titanic_df,size=5)\n\n# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers\npclass_dummies_titanic  = pd.get_dummies(titanic_df['Pclass'])\npclass_dummies_titanic.columns = ['Class_1','Class_2','Class_3']\npclass_dummies_titanic.drop(['Class_3'], axis=1, inplace=True)\n\npclass_dummies_test  = pd.get_dummies(test_df['Pclass'])\npclass_dummies_test.columns = ['Class_1','Class_2','Class_3']\npclass_dummies_test.drop(['Class_3'], axis=1, inplace=True)\n\ntitanic_df.drop(['Pclass'],axis=1,inplace=True)\ntest_df.drop(['Pclass'],axis=1,inplace=True)\n\ntitanic_df = titanic_df.join(pclass_dummies_titanic)\ntest_df    = test_df.join(pclass_dummies_test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5214295a-19cf-44b5-abe2-8989a0ed9670","_uuid":"1f0e20a9344fe822a15fea17121d781c8e776733","trusted":true,"collapsed":true},"cell_type":"code","source":"# define training and testing sets\n\nX_train = titanic_df.drop(\"Survived\",axis=1)\nY_train = titanic_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\",axis=1).copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e625b965aca707d6c46f92dc0ec3f4be8e413c1","collapsed":true},"cell_type":"code","source":"titanic_df.info()\nprint(\"----------------------------\")\ntest_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2b5424c0-196f-4d23-b1b8-1b10ac27be10","_uuid":"9bc53c4b2ecd38d4b9311b6c7cceefc1c6555648","trusted":true,"scrolled":true,"collapsed":true},"cell_type":"code","source":"# Logistic Regression\n#class_weight ='balanced',\nlogreg = LogisticRegression(penalty='l2',solver='liblinear',multi_class='ovr')\nlogreg.fit(X_train, Y_train)\nY_pred_logreg = logreg.predict(X_test)\nlogreg.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5f27e8492b238c510c2cbbb8b8495395dd262d2","scrolled":true,"collapsed":true},"cell_type":"code","source":"#GradientBoosting\nGradientBoostingTree = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,max_depth=1, random_state=0).fit(X_train, Y_train)\nGradientBoostingTree_score=GradientBoostingTree.score(X_train, Y_train)\nGradientBoostingTree_score","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0f8b05ff-c21e-4e0e-975d-21af19c6b6b3","_uuid":"ec93f6805dec81c0e05460b7c6904f52d9b88958","trusted":true,"scrolled":true,"collapsed":true},"cell_type":"code","source":"# Random Forests\n#数据集比较简单，模型较为复杂，设置max_depth和min_samples_split参数，防止过拟合\nrandom_forest = RandomForestClassifier(n_estimators=100,max_features=9,max_depth = 6, min_samples_split=20)\nrandom_forest.fit(X_train, Y_train)\nY_pred_random_forest = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"664969e37ee3f89dde792861ae8f8148bd3f110f","collapsed":true},"cell_type":"code","source":"#SVC\nSVC_Model = SVC(C=2.5,cache_size=200, class_weight=None, coef0=0.0,decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',max_iter=-1, probability=False, random_state=None, shrinking=True,tol=0.001, verbose=False)\nSVC_Model.fit(X_train, Y_train)\nSVC_Model_score=SVC_Model.score(X_train, Y_train)\nSVC_Model_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74bc514938131b3568d880c8d46e27369939a1a2","collapsed":true},"cell_type":"code","source":"#MLP\n#MLP_model = MLPClassifier(activation='relu', solver='adam', alpha=0.0001)\n#MLP_model = MLPClassifier(activation='relu', solver='lbfgs', alpha=0.0001)\n#MLP_model.fit(X_train, Y_train)\n#MLP_model_score=SVC_Model.score(X_train, Y_train)\n#MLP_model_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce5cda162395a09f17ecff62e6e0cb2fcddd525f","scrolled":true,"collapsed":true},"cell_type":"code","source":"#voting_final = VotingClassifier(estimators=[('GB', GradientBoostingTree), ('RF', random_forest),('LR',logreg),('SVC',SVC_Model),('MLP',MLP_model)], voting='hard', n_jobs=1)\nvoting_final = VotingClassifier(estimators=[('GB', GradientBoostingTree), ('RF', random_forest),('LR',logreg),('SVC',SVC_Model)], voting='hard', n_jobs=1)\n\nvoting_final = voting_final.fit(X_train, Y_train)\nvotingY_pred = voting_final.predict(X_test)\nvoting_final.score(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36bafc6ee856e9621bc2fc1dbda0dd86cb36aea6","collapsed":true},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": votingY_pred\n    })\nsubmission.to_csv('titanic.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3c35f06f10054559be227843ac25d76856e46460"},"cell_type":"markdown","source":"kfold = StratifiedKFold(n_splits=10)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2f16f80b5e9d390c1b73cc2ad3f7ed8d936adaeb"},"cell_type":"markdown","source":"# Cross validate model with Kfold stratified cross val\nkfold = StratifiedKFold(n_splits=10)\n\n\n#compare different algorithms\nrandom_state = 2\nclassifiers = []\nclassifiers.append(SVC(random_state=random_state))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(ExtraTreesClassifier(random_state=random_state))\nclassifiers.append(GradientBoostingClassifier(random_state=random_state))\nclassifiers.append(MLPClassifier(random_state=random_state))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LogisticRegression(random_state = random_state))\nclassifiers.append(LinearDiscriminantAnalysis())\n\ncv_results = []\nfor classifier in classifiers :\n    cv_results.append(cross_val_score(classifier, X_train, y = Y_train, scoring = \"accuracy\", cv = kfold, n_jobs=1))\n\ncv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n\ncv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\"LogisticRegression\",\"LinearDiscriminantAnalysis\"]})\n\ng = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3b24b66390d70b85ac19f1c1544e59f5b8977731"},"cell_type":"markdown","source":"RFC = RandomForestClassifier()\nrf_param_grid = {\"max_depth\": [1,2,3,4,5],\n              \"max_features\": [1, 5, 10],\n               \"min_samples_leaf\": [1, 3, 10],\n              \"bootstrap\": [False],\n              \"min_samples_split\": [2, 50, 100],\n              \"n_estimators\" :[10,100,1000],\n              \"criterion\": [\"gini\"]}\ngsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 1, verbose = 1)\ngsRFC.fit(X_train,Y_train)\nRFC_best = gsRFC.best_estimator_\ngsRFC.best_score_"},{"metadata":{"trusted":true,"_uuid":"33a2414777f607a645c7fd314186064bad834335","collapsed":true},"cell_type":"markdown","source":"train_sizes, train_scores, test_scores = learning_curve(random_forest, X_train, Y_train, cv=kfold, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5))\n\ntrain_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\n\nplt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\nplt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n\nplt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n\nplt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}