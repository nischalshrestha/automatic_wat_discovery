{"cells":[{"metadata":{"_uuid":"f286d1297d926fc72d093596479284e19eb2054e"},"cell_type":"markdown","source":"**Importing All required Library**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\n#Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nfrom pandas.tools.plotting import scatter_matrix\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#Configure Visualization Defaults\n#%matplotlib inline = show plots in Jupyter Notebook browser\n%matplotlib inline\nmpl.style.use('ggplot')\nsns.set_style('white')\npylab.rcParams['figure.figsize'] = 12,8","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"21bcadf0b9803bb9662f643da404b989c97293f6"},"cell_type":"markdown","source":"**Reading CSV files**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\ntest_df_y = pd.read_csv('../input/gender_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08c6c2f58ac64ea096660c5c5de11de86b6fa8a7"},"cell_type":"markdown","source":"**Cleaning Data and adding missing values**"},{"metadata":{"_kg_hide-output":true,"trusted":true,"scrolled":true,"_uuid":"110056c8fc285c66b2493c16ee336cbf23364561"},"cell_type":"code","source":"train_df.head()\ntrain_df.describe()\ntrain_df.info()\ntrain_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"808a45e3f593519f99ba576f44635126fae634f9"},"cell_type":"code","source":"train_df['Age'].fillna(train_df['Age'].median(), inplace = True)\ntrain_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace = True)\ntrain_df['Fare'].fillna(train_df['Fare'].median(), inplace = True)\ntrain_df.sample(10)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cfb958689156f5e7eb023fb443ec076c2d6dcde5"},"cell_type":"markdown","source":"**Adding new Column for machine learning model**"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"1c617aa4e5b416c44ad51b441894178eab28df2f"},"cell_type":"code","source":"train_df['Title'] = train_df.Name.str.extract('([A-Za-z]+)\\.')\n\n#pd.crosstab(train_df['Title'], train_df['Title'].count())\n\ntrain_df['Title'] = train_df['Title'].apply(lambda x: 'Misc' if ((train_df['Title']==x).sum() < 8) else x)\n#pd.crosstab(train_df['Title'],train_df['Title'].count() )\n\n#train_df['Title'].unique()\ntrain_df['FamilySize'] = train_df ['SibSp'] + train_df['Parch'] + 1\ntrain_df['AgeBin'] = pd.cut(train_df['Age'].astype(int), 5)\ntrain_df['FareBin'] = pd.qcut(train_df['Fare'], 4)\n\ntrain_df['IsAlone'] = 1\ntrain_df['IsAlone'] = train_df['FamilySize'].apply(lambda x: 0 if x > 1 else 1)\ndrop_column = ['Name','SibSp', 'Parch','Age','Fare','PassengerId','Cabin', 'Ticket']\ntrain_df.drop(drop_column, axis=1, inplace = True)\ntrain_df.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e401a9d0bca59677d0dd738ce6ad724bc77cb23"},"cell_type":"markdown","source":"**Checking correlation between variable **"},{"metadata":{"trusted":true,"_uuid":"e22a6b768f5fd03ab054b17a153c927e8993e648","scrolled":true},"cell_type":"code","source":"#train_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n#train_df[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n#train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n#train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n#train_df[['AgeBin', 'Survived']].groupby(['AgeBin'], as_index=False).mean().sort_values(by='Survived', ascending=False)\ntrain_df[['FareBin', 'Survived']].groupby(['FareBin'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9fc95630653f4d49e7ccce315b91b07b6a620114"},"cell_type":"markdown","source":"**Visualizing Correlation Chart**"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"7b5b3fc43a4edb201f8b834cdc9122df1a9e0711"},"cell_type":"code","source":"visualization_df = train_df.copy()\n# Encoding categorical data\nlabel = LabelEncoder()\n#onehotencoder = OneHotEncoder()\nvisualization_df['Sex_Code'] = label.fit_transform(visualization_df['Sex'])\n#converted_df = onehotencoder.fit_transform(converted_df['Sex_Code']).toarray()\nvisualization_df['Embarked_Code'] = label.fit_transform(visualization_df['Embarked'])\nvisualization_df['Title_Code'] = label.fit_transform(visualization_df['Title'])\nvisualization_df['AgeBin_Code'] = label.fit_transform(visualization_df['AgeBin'])\nvisualization_df['FareBin_Code'] = label.fit_transform(visualization_df['FareBin'])\n\nsns.set(rc={'figure.figsize':(14,12)})\np =sns.heatmap(visualization_df.corr(), annot=True, cmap=sns.diverging_palette(220, 10, as_cmap=True))\n\n# Feature Scaling in case we have any continues variable\n#from sklearn.preprocessing import StandardScaler\n#sc = StandardScaler()\n#X_train = sc.fit_transform(X_train)\n#X_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3e0d5edfd6c5070f30a089472da436112b8a0ee"},"cell_type":"markdown","source":"**Preparing Final training data set also dropping first column to avoid dummy variable trap**"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"14bf0a3587bfb670bfac12eff5325b5c4897c12e"},"cell_type":"code","source":"column_name = ['Sex','Pclass', 'Embarked', 'Title', 'FamilySize', 'AgeBin', 'FareBin']\n\nconverted_df = pd.get_dummies(train_df, columns=column_name,drop_first=True)\n\nx_data = converted_df.iloc[:, 1:].values\ny_data = converted_df.iloc[:, 0].values\n\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.20, random_state = 0)\n\nconverted_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2012045b68e234371d8b8112c0e6a3173601fc27"},"cell_type":"code","source":"# Logistic Regression\n\nlogreg = linear_model.LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_test)\n\n\n#acc_log = round(logreg.score(y_test, y_pred) * 100, 2)\n\n\n#accuracy score\nacc_log = round(metrics.accuracy_score(y_test, y_pred) * 100, 2)\nacc_log\n\n\n# Making the Confusion Matrix\n#cm = metrics.confusion_matrix(y_test, y_pred)\n#sns.heatmap(cm, annot=True,annot_kws={\"size\": 16})# font size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8463ff3e8d002f238e1294e609ec4b91393d2993"},"cell_type":"code","source":"# Support Vector Machines\n\nsvc = svm.SVC(kernel = 'rbf', gamma=0.085 ,random_state = 0)\nsvc.fit(x_train, y_train)\ny_pred = svc.predict(x_test)\n\nacc_svc = round(metrics.accuracy_score(y_test, y_pred) * 100, 2)\n\nacc_svc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0cf5ea0b5fa8fd972be06f463e28ea22006c11c"},"cell_type":"code","source":"knn = neighbors.KNeighborsClassifier(n_neighbors = 3)\nknn.fit(x_train, y_train)\ny_pred = knn.predict(x_test)\n\nacc_knn = round(metrics.accuracy_score(y_test, y_pred) * 100, 2)\nacc_knn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f408bf136361b857fea213040e43d0c92f29906"},"cell_type":"code","source":"# Gaussian Naive Bayes\n\ngaussian = naive_bayes.GaussianNB()\ngaussian.fit(x_train, y_train)\ny_pred = gaussian.predict(x_test)\n\nacc_gaussian = round(metrics.accuracy_score(y_test, y_pred) * 100, 2)\nacc_gaussian","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d418541ac7726d028adde939f6aa3d0d4a664d8"},"cell_type":"code","source":"# Decision Tree\n\ndecision_tree = tree.DecisionTreeClassifier()\ndecision_tree.fit(x_train, y_train)\ny_pred = decision_tree.predict(x_test)\n\nacc_decision_tree = round(metrics.accuracy_score(y_test, y_pred) * 100, 2)\n\nacc_decision_tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee1f45367454360bf2c7d7735b1261c9779ed432"},"cell_type":"code","source":"# Random Forest\n\nrandom_forest = ensemble.RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(x_train, y_train)\ny_pred = random_forest.predict(x_test)\n\nacc_random_forest = round(metrics.accuracy_score(y_test, y_pred) * 100, 2)\n\nacc_random_forest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59ca670e635140e2888764c560b69b9696687710"},"cell_type":"code","source":"#xgboost\nxgb = XGBClassifier()\nxgb.fit(x_train, y_train)\n\n# Predicting the Test set results\ny_pred = xgb.predict(x_test)\n\nacc_xgb = round(metrics.accuracy_score(y_test, y_pred) * 100, 2)\n\nacc_xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"d41955d84c9c8f77b608d7fc222ac857b700d496"},"cell_type":"code","source":"# Applying k-Fold Cross Validation\n#accuracies = model_selection.cross_val_score(estimator = svc, X = x_train, y = y_train, cv = 10)\n#accuracies.mean()\n#accuracies.std()\n\n# Applying Grid Search to find the best model and the best parameters\nparameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n              {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.075, 0.080, 0.085, 0.090, 0.095]}]\ngrid_search = model_selection.GridSearchCV(estimator = svc,\n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           cv = 10,\n                           n_jobs = -1)\ngrid_search = grid_search.fit(x_train, y_train)\ngrid_svm_acc = grid_search.best_score_\n\ngrid_svm_acc = round(grid_svm_acc * 100, 2)\n\nbest_parameters = grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbb5b1c81faf8248fa6fe1abdd5e6388237d7ff2"},"cell_type":"code","source":"best_parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"c47e33f7448ea9db126f8204be36331c7b6731ef"},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', 'Random Forest', 'Naive Bayes', 'Decision Tree','xgboost','Grid Search'],\n    'Score': [acc_svc, acc_knn, acc_log, acc_random_forest, acc_gaussian, acc_decision_tree,acc_xgb,grid_svm_acc]})\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"703501c29c4ea2c016e3c786b4c6d5531d6dd183"},"cell_type":"markdown","source":"> **Preparing code for any new dataset**"},{"metadata":{"trusted":true,"_uuid":"3c47557e138276b4d87d1152a622a82ab24304fd"},"cell_type":"code","source":"test_df['Age'].fillna(test_df['Age'].median(), inplace = True)\ntest_df['Embarked'].fillna(test_df['Embarked'].mode()[0], inplace = True)\ntest_df['Fare'].fillna(test_df['Fare'].median(), inplace = True)\ntest_df['Title'] = test_df.Name.str.extract('([A-Za-z]+)\\.')\n\nx_test = test_df[['PassengerId','Name']]\nx_test['FamilySize'] = test_df ['SibSp'] + test_df['Parch'] + 1\nx_test['IsAlone']= 1\nx_test['IsAlone'] = x_test['FamilySize'].apply(lambda x: 0 if x > 1 else 1)\n\nx_test['Sex_male'] = test_df['Sex'].apply(lambda x: 1 if x == 'male' else 0)\nx_test['Pclass_2'] = test_df['Pclass'].apply(lambda x: 1 if x == 2 else 0)\nx_test['Pclass_3'] = test_df['Pclass'].apply(lambda x: 1 if x == 3 else 0)\nx_test['Embarked_Q'] = test_df['Embarked'].apply(lambda x: 1 if x == 'Q' else 0)\nx_test['Embarked_S'] = test_df['Embarked'].apply(lambda x: 1 if x == 'S' else 0)\nx_test['Title_Misc'] = test_df['Title'].apply(lambda x: 0 if x in ('Mr', 'Mrs', 'Miss', 'Master') else 1)\nx_test['Title_Miss'] = test_df['Title'].apply(lambda x: 1 if x == 'Miss' else 0)\nx_test['Title_Mr'] = test_df['Title'].apply(lambda x: 1 if x == 'Mr' else 0)\nx_test['Title_Mrs'] = test_df['Title'].apply(lambda x: 1 if x == 'Mrs' else 0)\nx_test['FamilySize_2'] = x_test['FamilySize'].apply(lambda x: 1 if x == 2 else 0)\nx_test['FamilySize_3'] = x_test['FamilySize'].apply(lambda x: 1 if x == 3 else 0)\nx_test['FamilySize_4'] = x_test['FamilySize'].apply(lambda x: 1 if x == 4 else 0)\nx_test['FamilySize_5'] = x_test['FamilySize'].apply(lambda x: 1 if x == 5 else 0)\nx_test['FamilySize_6'] = x_test['FamilySize'].apply(lambda x: 1 if x == 6 else 0)\nx_test['FamilySize_7'] = x_test['FamilySize'].apply(lambda x: 1 if x == 7 else 0)\nx_test['FamilySize_8'] = x_test['FamilySize'].apply(lambda x: 1 if x == 8 else 0)\nx_test['FamilySize_11'] = x_test['FamilySize'].apply(lambda x: 1 if x > 8 else 0)\nx_test['AgeBin_(16.0, 32.0]'] = test_df['Age'].apply(lambda x: 1 if (x > 16 and x <= 32) else 0)\nx_test['AgeBin_(32.0, 48.0]'] = test_df['Age'].apply(lambda x: 1 if (x > 32 and x <= 48) else 0)\nx_test['AgeBin_(48.0, 64.0]'] = test_df['Age'].apply(lambda x: 1 if (x > 48 and x <= 64) else 0)\nx_test['AgeBin_(64.0, 80.0]'] = test_df['Age'].apply(lambda x: 1 if (x > 64 and x <= 80) else 0)\nx_test['FareBin_(7.91, 14.454]'] = test_df['Fare'].apply(lambda x: 1 if (x > 7.91 and x <= 14.454) else 0)\nx_test['FareBin_(14.454, 31.0]'] = test_df['Fare'].apply(lambda x: 1 if (x > 14.454 and x <= 31.0) else 0)\nx_test['FareBin_(31.0, 512.329]'] = test_df['Fare'].apply(lambda x: 1 if (x > 31.0 and x <= 52.329) else 0)\n\n\n\ndrop_column = ['PassengerId','Name','FamilySize']\nx_test.drop(drop_column, axis=1, inplace = True)\nx_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a616ad0384b6b484bf9c919f3219f71453b86ded","scrolled":true},"cell_type":"code","source":"x_test = x_test.iloc[:, :].values\ny_test = test_df_y.iloc[:, 1].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"171c3855858e8bbad45b9fa98a5479ac7d9b7994"},"cell_type":"markdown","source":"**Predicting result using desicion tree on our new dataset**"},{"metadata":{"trusted":true,"_uuid":"49bfa4e11fa51650ca4f350ad702924d4ba75592"},"cell_type":"code","source":"y_pred = decision_tree.predict(x_test)\nacc_decision_tree = round(metrics.accuracy_score(y_test, y_pred) * 100, 2)\nacc_decision_tree","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}