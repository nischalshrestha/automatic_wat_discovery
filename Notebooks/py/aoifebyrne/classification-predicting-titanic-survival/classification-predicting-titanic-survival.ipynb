{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9e9fbc5e-f842-9b4d-1d6f-888a6c349b83"
      },
      "source": [
        "## Introduction ##\n",
        "\n",
        "This notebook is written in Python. \n",
        "\n",
        "Steps:\n",
        "\n",
        " 1. Explore and visualize the data.\n",
        " 2. Feature engineering and imputing missing data\n",
        " 3. Compare the accuracy of classifiers\n",
        " 4. Predict survival using an ensemble of classifiers\n",
        "\n",
        "###Question and problem definition###\n",
        "\n",
        "\"  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. \"\n",
        "\n",
        "\"In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cf5a49a7-6089-1040-7160-ffb54fb4ba06"
      },
      "outputs": [],
      "source": [
        "#Import libraries and data\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import re as re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "train = pd.read_csv('../input/train.csv')\n",
        "test = pd.read_csv('../input/test.csv')\n",
        "\n",
        "full_data = [train, test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7a5329f1-0914-3c19-6bd6-b50ea9e6f0d1"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "89640103-c0e5-a3b0-7819-1b0bab231c60"
      },
      "outputs": [],
      "source": [
        "print(train.head())\n",
        "train.describe()\n",
        "train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8ec54df7-1f6a-d45d-82f7-f5c122879f8e"
      },
      "source": ""
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6e99202c-d767-6616-c879-30282864f837"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "07a54a12-a99e-e092-91e1-4de9d97792c5"
      },
      "outputs": [],
      "source": [
        "from numpy import corrcoef\n",
        "\n",
        "corrcoef(train[\"PassengerId\"], train[\"Survived\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "86ba8e02-2c32-acf7-834f-12f439eca2bd"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a159236a-5436-2e06-fdb8-7f2a4526e4b0"
      },
      "outputs": [],
      "source": [
        "print (train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d477ca53-55af-298b-023f-bc1e3fd083d6"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2ca6ac2e-7ff2-3644-3e95-76e8c7eb3932"
      },
      "outputs": [],
      "source": [
        "print (train[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0480f216-bd40-b085-ec54-7c6c20bef17a"
      },
      "outputs": [],
      "source": [
        "train[\"Famsize\"] = train[\"Parch\"]+ train[\"SibSp\"]+1\n",
        "test[\"Famsize\"] = test[\"Parch\"]+ test[\"SibSp\"]+1\n",
        "\n",
        "\n",
        "print (train[[\"Famsize\", \"Survived\"]].groupby(['Famsize'], as_index=False).count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "78138c4d-0da8-3a75-14c0-600c749574fd"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cf764047-9fac-28a6-8be5-b48c26165eae"
      },
      "outputs": [],
      "source": [
        "#No parents\n",
        "\n",
        "print(train.loc[(train[\"Parch\"]==0) & (train[\"Age\"]<18)])\n",
        "\n",
        "train[\"LoneChild\"] = 0\n",
        "train.loc[(train[\"Parch\"]==0) & (train[\"Age\"]<18), \"LoneChild\"] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ecd347a5-0389-534a-0cc9-1e64bae8375c"
      },
      "outputs": [],
      "source": [
        "print (train[[\"LoneChild\", \"Survived\"]].groupby(['LoneChild'], as_index=False).mean())\n",
        "sns.factorplot(x=\"LoneChild\", y=\"Survived\", data=train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fda986df-268e-124c-1544-c0ea22a25bf6"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e411791a-6526-84f8-fc4d-6635a2a8b023"
      },
      "outputs": [],
      "source": [
        "train = train.drop(\"LoneChild\", 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "150b5c12-b154-c590-5cbc-5e895320f26a"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "69236ea7-33ae-5fec-b659-523697a88a73"
      },
      "outputs": [],
      "source": [
        "for dataset in [train, test]:\n",
        "    dataset['Alone'] = 0\n",
        "    dataset.loc[dataset['Famsize'] == 1, 'Alone'] = 1\n",
        "    \n",
        "sns.factorplot(x=\"Alone\", y=\"Survived\", data=train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2f7bc844-86bb-e8ed-5163-fa45e58dac42"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5a79a2f5-dbc1-a5c6-414a-a9c09711d5ee"
      },
      "outputs": [],
      "source": [
        "sns.factorplot('Embarked','Survived', data=train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "321a01b6-82ec-2267-61c6-dbc5cb889f75"
      },
      "outputs": [],
      "source": [
        "print(\"Mean\")\n",
        "print (train[[\"Embarked\", \"Survived\"]].groupby(['Embarked'], as_index=False).mean())\n",
        "\n",
        "print(\"Count\")\n",
        "print (train[[\"Embarked\", \"Survived\"]].groupby(['Embarked'], as_index=False).count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5842f196-beab-1be1-101b-b3a9fc5d8a0a"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x='Survived', hue=\"Embarked\", data=train, order=[1,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a2df9f47-59aa-f852-1a61-f6790e78528a"
      },
      "outputs": [],
      "source": [
        "train[\"Embarked\"] = train[\"Embarked\"].fillna('S')\n",
        "test[\"Embarked\"] = test[\"Embarked\"].fillna('S')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e2092b61-2751-a6b1-ea11-0979ddb853fa"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ced0c01b-fc2f-7de7-e352-0184557c3cc2"
      },
      "outputs": [],
      "source": [
        "for dataset in full_data:\n",
        "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bd3d2177-411e-fd7b-c2b0-fa965d2685ba"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d8dde1e3-bdfe-6492-b906-a02ee12f22a5"
      },
      "outputs": [],
      "source": [
        "for dataset in [train, test]:\n",
        "    avg_age = dataset['Age'].mean()\n",
        "    std_age = dataset['Age'].std()\n",
        "    age_null_count = dataset['Age'].isnull().sum()\n",
        "    \n",
        "    random_age = np.random.randint(avg_age - std_age , avg_age + std_age , size=age_null_count)\n",
        "    dataset['Age'][dataset['Age'].isnull()] = age_null_count\n",
        "    dataset['Age'] = dataset['Age'].astype(int)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "450532e2-e988-8a42-f402-4cd13c972233"
      },
      "outputs": [],
      "source": [
        "np.corrcoef(train[\"Age\"], train[\"Survived\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ee0fd1d1-4f37-6ba2-c9e4-790cff078f78"
      },
      "outputs": [],
      "source": [
        "# peaks for survived/not survived passengers by their age\n",
        "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=3)\n",
        "facet.map(sns.kdeplot,'Age',shade= True)\n",
        "facet.set(xlim=(0, train['Age'].max()))\n",
        "facet.add_legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ceeebbd5-2add-1f0b-6350-c604ceb5c877"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3f56d93d-bdad-baa2-0595-da58b4615438"
      },
      "outputs": [],
      "source": [
        "for dataset in [train, test]:\n",
        "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "\n",
        "print(train['Title'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eaeb2c91-591a-e83f-40aa-b45d6f08a4b2"
      },
      "outputs": [],
      "source": [
        "#cleaning up the title column\n",
        "\n",
        "for data_set in [train, test]:\n",
        "    data_set['Title'] = data_set['Title'].replace('Mlle', 'Ms')\n",
        "    data_set['Title'] = data_set['Title'].replace('Miss', 'Ms')\n",
        "    data_set['Title'] = data_set['Title'].replace('Mme', 'Mrs')\n",
        "    data_set['Title'] = data_set['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "52edd1d1-587e-087e-eec4-9578fc82a3ac"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6a48cbcb-15d1-51ec-11e1-f8bceb932d29"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "categories = ['Embarked','Sex','Title']\n",
        "\n",
        "for cat in categories:\n",
        "    train[cat] = LabelEncoder().fit_transform(train[cat])\n",
        "    test[cat] = LabelEncoder().fit_transform(test[cat])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ad08db63-b570-9a05-03c4-e553647406c0"
      },
      "outputs": [],
      "source": [
        "drop_elements = ['Name', 'Ticket', 'Cabin', 'SibSp',\\\n",
        "                 'Parch']\n",
        "\n",
        "train = train.drop(drop_elements, axis = 1)\n",
        "test = test.drop(drop_elements, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "99ebe451-eeba-9a75-fd19-75df25d2179a"
      },
      "outputs": [],
      "source": [
        "#check everything looks good\n",
        "\n",
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4617ad72-e6ce-0abd-db9b-1c67728810d9"
      },
      "outputs": [],
      "source": [
        "###Comparing algorithms#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e5fad5f8-872b-11cd-0983-6acf6cd00f32"
      },
      "outputs": [],
      "source": [
        "from sklearn.cross_validation import train_test_split\n",
        "from sklearn.cross_validation import cross_val_score\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifiers = [\n",
        "    [KNeighborsClassifier(3),'KNN'],\n",
        "    [SVC(probability=True), 'SVC'],\n",
        "    [DecisionTreeClassifier(),'Decision Tree'],\n",
        "    [RandomForestClassifier(),'Random Forest'],\n",
        "    [AdaBoostClassifier(),'ADA booster'],\n",
        "    [GradientBoostingClassifier(),'Gradient Booster'],\n",
        "    [GaussianNB(),'Gaussian Nb'],\n",
        "    [LinearDiscriminantAnalysis(),'Linear Discriminant Analysis'],\n",
        "    [QuadraticDiscriminantAnalysis(),'Quadratic Discrimination'],\n",
        "    [LogisticRegression(),'Logistic Regression']]\n",
        "\n",
        "\n",
        "X = train.drop(\"Survived\",axis=1)\n",
        "y = train[\"Survived\"]\n",
        "X_test  = test\n",
        "\n",
        "\n",
        "\n",
        "scores = []\n",
        "\n",
        "for clf in classifiers:\n",
        "    \n",
        "    clf = clf[0]\n",
        "    \n",
        "    clf.fit(X,y)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    \n",
        "    cv_scores = cross_val_score(clf, X, y, cv=5)\n",
        "\n",
        "    #score = clf.score(X,y)\n",
        "    scores.append(cv_scores.mean())\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "172450fc-f255-3214-9740-60111a87449f"
      },
      "outputs": [],
      "source": [
        "#viewing classifier scores\n",
        "\n",
        "names = [clf[1] for clf in classifiers]\n",
        "\n",
        "\n",
        "np.column_stack((names, scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "709cfdd2-9a10-ed07-0efe-55cf5b853efb"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5647e388-b5a0-0caf-3a1c-0bfcbc18f380"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "test[\"PassengerId\"] = test[\"PassengerId\"].astype(int)\n",
        "\n",
        "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"Famsize\", \"Title\", \"Alone\"]\n",
        "\n",
        "algorithms = [GaussianNB(), LinearDiscriminantAnalysis(), GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3),\n",
        "LogisticRegression(random_state=1),RandomForestClassifier(random_state=1, n_estimators = 50, min_samples_split=4, min_samples_leaf=2)]\n",
        "\n",
        "\n",
        "predictions = []\n",
        "train_target = train[\"Survived\"]\n",
        "full_test_predictions = []\n",
        "\n",
        "    # Make predictions for each algorithm on each fold\n",
        "for alg in algorithms:\n",
        "        # Fit the algorithm on the training data\n",
        "    alg.fit(train[predictors], train_target)\n",
        "        # Select and predict on the test fold \n",
        "        # We need to use .astype(float) to convert the dataframe to all floats and avoid an sklearn error\n",
        "    test_predictions = alg.predict_proba(test[predictors])[:,1]\n",
        "    full_test_predictions.append(test_predictions)\n",
        "    # Use a simple ensembling scheme&#8212;just average the predictions to get the final classification\n",
        "test_predictions = ( sum(full_test_predictions) / len(full_test_predictions) )\n",
        "    # Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction\n",
        "test_predictions[test_predictions <= .5] = 0\n",
        "test_predictions[test_predictions > .5] = 1\n",
        "predictions.append(test_predictions)\n",
        "\n",
        "# Put all the predictions together into one array\n",
        "predictions = np.concatenate(predictions, axis=0).astype(int)\n",
        "\n",
        "\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "        \"PassengerId\": test[\"PassengerId\"],\n",
        "        \"Survived\": predictions\n",
        "    })\n",
        "\n",
        "submission.to_csv('titanic-predictions-4.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "041cf812-168d-b75e-f0c2-7529cfdcd308"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}