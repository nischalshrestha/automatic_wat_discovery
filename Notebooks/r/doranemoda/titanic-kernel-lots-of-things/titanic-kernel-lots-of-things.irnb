{"cells":[{"metadata":{"_uuid":"24440e89d4699b9d26edee41a173e38f80dc9aa9","_execution_state":"idle","trusted":false},"cell_type":"code","source":"#Import datasets\ntrain<-read.csv(\"train.csv\")\ntest<-read.csv(\"test.csv\")\ntest_result<-read.csv(\"gender_submission.csv\")\ntest$Survived<-test_result[,2]\n\n#Full dataset (TRAIN+TEST)\ndata<-rbind(train,test)\nhead(data)\nstr(data)  #1309 observation of 12 variables (+title)\nsummary(data)  #NAN: Age(263);Fare(1);Embarked(2)\n\n# Change 'Survived' to factor\ndata$Survived<-as.factor(data$Survived)\n\n# change the empty values in 'Embarked' to NA\nlevels(data$Embarked)[1]<-NA\n\n# extract title by finding an alphabetical string followed by '.' (e.g. Mr., Miss.)\nlibrary(stringr)\ndata$title <- str_extract(data$Name, '[a-zA-Z]+(?=\\\\.)')\ndata$title <- as.factor(data$title)\nsummary(data$title)\n\n# group all the rare titles together\ndata$title <- as.character(data$title)\ndata$title[!(data$title %in% c('Master', 'Miss', 'Mr', 'Mrs'))] <- 'Other'\ndata$title <- as.factor(data$title)\nsummary(data$title)\n\n\n# get the mean age of each title group\ntitle.age <- aggregate(Age~title, data=data, mean)\ntitle.age$Age<-round(title.age[2],1)\ntitle.age\n\n# impute missing ages\nfor(i in 1:nrow(data)){\n  if(is.na(data[i,'Age'])){\n    data[i,'Age'] <- title.age$Age[which(title.age$title==data[i,'title']),]\n  }\n}\nsummary(data$Age)\n\n#Eclude missing values in 'Fare' and 'Embarked'\nsummary(data$Fare)                    #NaN: 1db (1044 ID)\ndata$PassengerId[is.na(data$Fare)==TRUE]\nsummary(data$Embarked)                #NaN: 2 db (62, 830 ID)\ndata$PassengerId[is.na(data$Embarked)==TRUE]\ndata<-data[c(-1044,-62,-830),]  #Done\n\nsummary(data)\n\n# split traing and testing sets\ntrain <- data[1:nrow(train), ]   #1-893 ID\ntest <- data[(nrow(train)+1):nrow(data),]  #894-1309 ID\nsummary(train)\nsummary(test)\n\nremove_cols = c(\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\",\"title\")\ntrain_new = train[,!(names(train) %in% remove_cols)]\ntest_new = test[,!(names(test) %in% remove_cols)]\nsummary(train_new)\nsummary(test_new)\nstr(train_new)\nstr(test_new)\n\n# 1a. model: Decision tree \nlibrary(caret)\nlibrary(C50)\nlibrary(gmodels)\nfit_tree<-C5.0(train_new[-1],train_new$Survived)\nsummary(fit_tree)\nfit_tree  \n\npred_tree_train<-predict(fit_tree, train_new)\nCrossTable(train$Survived,pred_tree_train)  #Train Accuracy=88.77% ((516+275)/891)\npred_tree <- predict(fit_tree, test_new)\nCrossTable(test$Survived,pred_tree)  #Test Accuracy=86.98% ((232+129)/415)\n\n# 1b. model: Decision tree + Class Weight\n\nclass_weight0 = c(0.1,0.2,0.3,0.4,0.5)\n\nfor (i in class_weight0){\n  error_cost <- matrix(c(0, 1, (1-i)/i, 0), nrow = 2)\n  fit_trees = C5.0(train_new[-1],train_new$Survived, costs = error_cost,control = C5.0Control( minCases = 1))\n  summary(fit_trees)\n  pred_train = predict(fit_trees, train_new)\n  pred_test = predict(fit_trees,test_new)\n  print(paste(\"Class weights\",\"{0:\",i,\"1:\",1-i,\"}\"))\n  CrossTable(train$Survived,pred_train)\n CrossTable(test$Survived,pred_test)\n}\n\n####\n#Class weights {0: 0.1 1: 0.9 }\n#Train Accuracy: (71+340)/891=0.46\n#Test Accuracy: (16+149)/415=0.39\n\n#Class weights {0: 0.2 1: 0.8 }\n#Train Accuracy: (441+300)/891=0.83\n#Test Accuracy: (207+149)/415=0.857\n\n#Class weights {0: 0.3 1: 0.7 }  >>>> BEST\n#Train Accuracy: (470+298)/891=0.86\n#Test Accuracy: (226+146)/415=0.896\n\n#Class weights {0: 0.4 1: 0.6 }\n#Train Accuracy: (508+287)/891=0.89\n#Test Accuracy: (228+122)/415=0.843\n\n#Class weights {0: 0.5 1: 0.5 }\n#Train Accuracy: (517+274)/891=0.887\n#Test Accuracy: (233+129)/415=0.872\n\n#Best Decision tree + Class Weight Model\nerror_cost<- matrix(c(0, 1, (1-0.3)/0.3, 0), nrow = 2)\nfit_tree_best = C5.0(train_new[-1],train_new$Survived, costs = error_cost,control = C5.0Control( minCases = 1))\npred_test = predict(fit_tree_best,test_new)\nCrossTable(test$Survived,pred_test)  #Test Acc=0.896=(226+146)/415\n\n\n# 2. model: Logistic Regression\nfit_glm<-glm(train_new$Survived~.,data=train_new,family = \"binomial\")\n\npred_glm<-probs_glm\npred_glm[probs_glm>0.5]=1\npred_glm[probs_glm<=0.5]=0\nCrossTable(train$Survived,pred_glm) #Train Accuracy=83.27% ((485+257)/891)\n\nprobs_glm_te<-predict(fit_glm,newdata=test_new,type=\"response\")  #1 valsége\npred_glm_te<-probs_glm_te\npred_glm_te[probs_glm_te>0.5]=1\npred_glm_te[probs_glm_te<=0.5]=0\nCrossTable(test$Survived,pred_glm_te) #Test Accuracy=91.33% ((238+141)/415)\n\n# 3a. model: Random Forest\nlibrary(randomForest)\nfit_rf <- randomForest(train_new$Survived~.,data=train_new,mtry=6,maxnodes=64,ntree=5000,nodesize = 1)\n\npred_rf <- predict(fit_rf,newdata = train_new,type = \"class\")\nCrossTable(train$Survived,pred_rf) #Train Accuracy=91.02% ((531+280)/891)\n\npred_rf_te <- predict(fit_rf,newdata = test_new,type = \"class\")\nCrossTable(test$Survived,pred_rf_te) #Test Accuracy=88.19% ((242+124)/415)\n\n# 3b. model: Random Forest + Grid search  >NOT WORKING\nlibrary(e1071)\nfit_rf_grid<-tune(randomForest,train_new$Survived~.,data=train_new[-1],classwt = c(0.3,0.7),\n                  ranges=list(mtry=c(5,6),maxnodes=c(32,64),ntree=c(3000,5000),nodesize = c(1,2)),\n                  tunecontrol = tune.control(cross = 5))\n\n# 4a. model: - Adaboost\nfit_ada <- C5.0(train_new[-1],train_new$Survived,trails =5000,control = C5.0Control(minCases = 1))\n\n\npred_ada <-predict(fit_ada,newdata = train_new ,type = \"class\")\nCrossTable(train$Survived,pred_ada) #Train Accuracy=88.77% ((517+274)/891)\n\npred_ada_te <- predict(fit_ada,newdata = test_new,type = \"class\")\nCrossTable(test$Survived,pred_ada_te) #Test Accuracy=87.23% ((233+129)/415)\n\n# 4b. model: - Adaboost + Error Costs\nfit_ada_weight <- C5.0(train_new[-1],train_new$Survived,trails =5000,costs = error_cost,control = C5.0Control(minCases = 1))\npred_ada_te_w <- predict(fit_ada_weight,newdata = test_new,type = \"class\")\nCrossTable(test$Survived,pred_ada_te_w) #Test Accuracy=84.57% ((206+145)/415)\n\n\n# 5a. model: SVM\nlibrary(e1071)\nfit_svm<-svm(train_new$Survived~.,data=train_new,kernel=\"linear\")\nfit_svm\n\npred_svm_train<-predict(fit_svm,train_new)\npred_svm_test<-predict(fit_svm,test_new[-1])\nCrossTable(pred_svm_train,train_new$Survived)  #Train Accuracy=78.67% ((469+232)/891)\nCrossTable(pred_svm_test,test_new$Survived)    #Test Accuracy=100% ((264+151)/415)\n#Train Accuracy=78.67% (linear), 83.61% (RBF), 83.5% (poly)\n#Test Accuracy=100% (linear), 93.97% (RBF), 90.6% (poly)\n\n# 5b. model: SVM + Tune   \nsvm_tune<-tune.svm(Survived~.,data=train_new,kernel=\"linear\",cost=c(0.1,0.3,1,10),gamma=c(0.001,0.01,0.1,1), tunecontrol = tune.control(cross = 5))\nsvm_tune_best<-svm_tune$best.model\n  \n  \npred_svm_tune_test<-predict(svm_tune_best,test_new[-1],type=\"class\")\nCrossTable(pred_svm_tune_test,test_new$Survived)    #Test Accuracy=100% ((264+151)/415)\n\n\n#################################### ENSEMBLE #################################################\n\n#ENSEMBLE - TRAIN\nprobs_tree<-predict(fit_tree, train_new,type=\"prob\")[,2]  #1 valsége >> ENSEMBLE 1. oszlop\nprobs_glm<-predict(fit_glm,newdata=train_new,type=\"response\")  #1 valsége >> ENSEMBLE 2. oszlop\nprobs_rf <- predict(fit_rf,newdata = train_new,type = \"prob\")[,2]  #1 valsége >> ENSEMBLE 3. oszlop\nprobs_ada <- predict(fit_ada,newdata = train_new ,type = \"prob\")[,2]   #1 valsége >> ENSEMBLE 4. oszlop\n\n\n# Ensemble of Models - TRAIN\nensemble <- data.frame(probs_tree,probs_glm,probs_rf,probs_ada)\n#ensemble <- cbind(ensemble,train_new$Survived)\n#names(ensemble)[5] <- \"Survived\"\nhead(ensemble)\nstr(ensemble)\n\n# Meta-classifier on top of individual classifiers\nmeta <- glm(train_new$Survived~.,data=ensemble, family = \"binomial\")\nmeta_probs <- predict(meta, ensemble,type = \"response\")\nensemble$pred_class = 0\nensemble$pred_class[meta_probs>0.5]=1\n\nCrossTable(train_new$Survived,ensemble$pred_class) #Train Accuracy=93.49% ((536+297)/891)\n\n#ENSEMBLE - TEST\nprobs_tree_te<-predict(fit_tree, test_new,type=\"prob\")[,2]  #1 valsége >> ENSEMBLE 1. oszlop\nprobs_glm_te<-predict(fit_glm,newdata=test_new,type=\"response\")  #1 valsége >> ENSEMBLE 2. oszlop\nprobs_rf_te <- predict(fit_rf,newdata = test_new,type = \"prob\")[,2]  #1 valsége >> ENSEMBLE 3. oszlop\nprobs_ada_te <- predict(fit_ada,newdata = test_new ,type = \"prob\")[,2]   #1 valsége >> ENSEMBLE 4. oszlop\n\n\n# Ensemble of Models - TEST\nensemble_test <- data.frame(probs_tree_te,probs_glm_te,probs_rf_te,probs_ada_te)\n#ensemble_test <- cbind(ensemble_test,test_new$Survived)\n#names(ensemble_test)[5] <- \"Survived\"\nrownames(ensemble_test) <- 1:nrow(ensemble_test)\nhead(ensemble_test)\nstr(ensemble_test)\n\nmeta_probs_test <- predict(meta, ensemble_test, type = \"response\")  #NOT WORKING\n#ensemble_test$pred_class = 0\n#ensemble_test$pred_class[meta_probs_test>0.5]=1\n#head(ensemble_test)\n\n#CrossTable(test_new$Survived,ensemble_test$pred_class) #Test Accuracy=??\n\n###############################################################################################\n\n\n## Saving data\n\n# If you save any files or images, these will be put in the \"output\" directory. You \n# can see the output directory by committing and running your kernel (using the \n# Commit & Run button) and then checking out the compiled version of your kernel.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}