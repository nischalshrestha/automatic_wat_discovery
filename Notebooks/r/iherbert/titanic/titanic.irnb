{"cells":[{"metadata":{"_uuid":"42474571fb620d00ae985ee965123c7387223818","_execution_state":"idle","trusted":true},"cell_type":"code","source":"## Importing packages\n\n# This R environment comes with all of CRAN and many other helpful packages preinstalled.\n# You can see which packages are installed by checking out the kaggle/rstats docker image: \n# https://github.com/kaggle/docker-rstats\n\nlibrary(tidyverse) # metapackage with lots of helpful functions\n\n## Running code\n\n# In a notebook, you can run a single code cell by clicking in the cell and then hitting \n# the blue arrow to the left, or by clicking in the cell and pressing Shift+Enter. In a script, \n# you can run code by highlighting the code you want to run and then clicking the blue arrow\n# at the bottom of this window.\n\n## Reading in files\n\n# You can access files from datasets you've added to this kernel in the \"../input/\" directory.\n# You can see the files added to this kernel by running the code below. \n\nlist.files(path = \"../input\")\n\n## Saving data\n\n# If you save any files or images, these will be put in the \"output\" directory. You \n# can see the output directory by committing and running your kernel (using the \n# Commit & Run button) and then checking out the compiled version of your kernel.\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"997ec6d27b5a90fdbe1686f2c20c1c129cdcbedc"},"cell_type":"markdown","source":"Load all our datasets:"},{"metadata":{"trusted":true,"_uuid":"fff09c911bcd4678dc0cdbe026f19f8b67714c15"},"cell_type":"code","source":"train <- read_csv(\"../input/train.csv\")\ntest <-read_csv(\"../input/test.csv\")\ngender<-read_csv(\"../input/gender_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02869c26cd29c153a980c266254667ed2b70aa68"},"cell_type":"markdown","source":"Take a look at what data we have. Make a new dataframe keeping only the fields that are likely to be useful to a first analysis. Name, ticket number, and cabin number could all potentially contain information that codes for relative wealth (which may affect survivability), but the relation (if any) is likely too subtle to be extracted from small dataset we have available, and we already have a field recording the passengers' socioeconomic class. In any case, we can set these fields aside for our first analysis. Additionally, we see that 687 of the 891 observations we have available do not even have a cabin number recorded, so this field is unlikely to be useful. "},{"metadata":{"trusted":true,"_uuid":"26669d66fad863a56725aba811afecf914a9ceee"},"cell_type":"code","source":"str(train)\nhead(train)\nNo_cabin<-train%>%filter(is.na(Cabin))%>%summarize(count = n())\nNo_cabin\n\nuseful<- train[,c(\"PassengerId\", \"Survived\", \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\")]\nhead(useful)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9336d8c12a12dc03c13c1d8a3335aa4f1927160a"},"cell_type":"markdown","source":"Let's look for which fields still have NA values, and decide how to deal with them."},{"metadata":{"trusted":true,"_uuid":"471c641ad889558ad315a5d7e32501babe23c176"},"cell_type":"code","source":"#Generate counts for NA in each of the remaining fields\nlength(which(is.na(useful$Pclass)))\nlength(which(is.na(useful$Sex)))\nlength(which(is.na(useful$Age)))\nlength(which(is.na(useful$SibSp)))\nlength(which(is.na(useful$Parch)))\nlength(which(is.na(useful$Fare)))\nlength(which(is.na(useful$Embarked)))\n\n#Find the most common embarkation point, in case it will be sensible to replace missing values with it. \nuseful%>%group_by(Embarked)%>%summarize(n())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"44106955be7cdf8dd6df11f102057783648aa543"},"cell_type":"markdown","source":"It looks like we're missing only 2 embarkation points, which is not a big deal. If we want to use Embark as a variable in our analysis, we can either throw those observations away, or play the odds and bet that they embarked at Southampton (where roughly 72% of passengers did). The more pressing problem is the 177 rows with missing ages. Let's look at the distribution of ages that we do have to see what next steps to take. A priori it feels like age might be a good determiner of survival (to the extant that it correlates to athletic fitness, or a desire to prioritize saving children, etc), but 177/891 is roughly 20% of our dataset. It would be a shame to have to ignore it. "},{"metadata":{"trusted":true,"_uuid":"42f7ef826eeb56488457242e4edaa3b9ae335faf"},"cell_type":"code","source":"range(useful$Age, na.rm=TRUE) #it looks like there are a wide range of ages, including a baby of around 5 months\nuseful%>%filter(Age==0.42) #phew,the baby survived!\n\nmedian(useful$Age, na.rm=TRUE)\nmean(useful$Age, na.rm=TRUE)\n\n\n\nggplot(useful, aes(x=Age))+geom_histogram(binwidth=5)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05551772301c7e4a1021bddc63e3b9ada9c06740"},"cell_type":"markdown","source":"The age distribution seems to be pretty concentrated around the high 20's/low 30's. The median is 28 and the mean is almost 30. Let's try just replacing the missing values with the mean, and seeing what kind of performance we get. "},{"metadata":{"trusted":true,"_uuid":"1bf0984fe9a2aaaf50afb5f181f639fb8af28bae"},"cell_type":"code","source":"#Replace NA is Embarked with Southampton\nuseful_no_na<-useful\nuseful_no_na$Embarked[which(is.na(useful_no_na$Embarked))]<-\"S\"\n\n#Replace NA in Age with mean age of other passengers\nuseful_no_na$Age[which(is.na(useful_no_na$Age))]<-mean(useful_no_na$Age, na.rm=TRUE)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b80d33a0061d9bfa5d463b8e932d23e2539881df"},"cell_type":"markdown","source":"For our first attempt at logistic regression, we can just try using all the fields we haven't eliminated so far."},{"metadata":{"trusted":true,"_uuid":"9b50131aff801fad5b1028d6bead576c886a0f43"},"cell_type":"code","source":"model1 <-glm(Survived ~ ., family = \"binomial\", data = useful_no_na)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf21969a0eb4f6e220947a93dab022972f1c469b"},"cell_type":"markdown","source":"Let's see how the test set is in terms of missing ages"},{"metadata":{"trusted":true,"_uuid":"fe19d57a95f2e57434579ec85548b844c65771f7"},"cell_type":"code","source":"length(which(is.na(test$Age))) #=86, which isn't great\n\nmean(test$Age, na.rm=1) \n#but the mean is also around 30, so replacing the missing ages with the mean here doesn't make the test distribution too far from the training one\n\ntest_no_na <- test\ntest_no_na$Age[which(is.na(test$Age))]<-mean(test$Age, na.rm=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db93a5ba71e4870e09d5a358feada8deb7c0f3da"},"cell_type":"code","source":"test_pred1<- predict(model1, newdata= test_no_na, type = \"response\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92c564d6e976bbfd0dace61903e59db71ff56e3a"},"cell_type":"code","source":"#Check how many rows in the test data were missing the other fields we chose to use\n\nlength(which(is.na(test_pred1))) #looks like we're just missing data for 1 point. Let's see what it is. \n\n\nwhich(is.na(test_pred1))\ntest_no_na[153,]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4bb1d860735a97709fee9ff486b9edfe2790f3ac"},"cell_type":"markdown","source":"We're missing Mr. Storey's fare. Since it's just one value, let's replace it with the median fare (for his reported class) to guess whether or not he survived. "},{"metadata":{"trusted":true,"_uuid":"3be66a25330bdd3a7ff6cf470ea8051e4687776f"},"cell_type":"code","source":"class3fare<-test_no_na%>%filter(Pclass==3)%>%summarize(median(Fare, na.rm=1))\ntest_no_na[153,\"Fare\"]<- class3fare\ntest_no_na[153,]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fedb7e587d71b2583b56b30153b9937e9f18bb58"},"cell_type":"markdown","source":"And run our prediction again."},{"metadata":{"trusted":true,"_uuid":"f6cda78b6e5e72a16747a6a29d45cea0b4870b96"},"cell_type":"code","source":"test_pred1<- predict(model1, newdata= test_no_na, type = \"response\")\nhead(test_pred1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"541bd342baf8e43f920c3f3e7bdfdea9bf01e42b"},"cell_type":"markdown","source":"Now to prepare the submission. Let's use a basic cutoff of 0.5. "},{"metadata":{"trusted":true,"_uuid":"ab09edacd479e6790f711b1303150482e922cb1f"},"cell_type":"code","source":"submission<-test[\"PassengerId\"]\nsubmission<-submission%>%mutate(Survived = as.integer(test_pred1>=0.5))\nhead(submission)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02b3fa3e3434d56c5d68f5ae36b9320e665f49d6"},"cell_type":"markdown","source":"Let's just do a quick sanity check that we're saving roughly the right proportion, according to the distribution in our training set"},{"metadata":{"_uuid":"da0584f0a1f09cd9e068f37c60b96e2ffb69ba12"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"0167298a33b38af845c3a0a0aa8d6733428cc320"},"cell_type":"code","source":"submission%>%filter(Survived ==1)%>%summarize(Test_survive_pct = n()/nrow(submission))\n\ntrain%>%filter(Survived==1)%>%summarize(Train_survive_pct = n()/nrow(train))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be611f4a32f8252846a5bab28a7c7a3f11095686"},"cell_type":"markdown","source":"Looks about right. Let's try it and see. "},{"metadata":{"trusted":true,"_uuid":"bc826c3832533f904ffda0081298540ae1c6362b"},"cell_type":"code","source":"submission<-submission%>%mutate(PassengerId = as.integer(PassengerId))\nwrite_csv(submission, \"submission1.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"215309234ab2646a0590e4727be4463f4d895b0f"},"cell_type":"markdown","source":"Our first submission is about 74% accurate. Not great, but better than guessing, and not too awful for what was just a first pass using all the data that might be relevant. From here, there are a number of things to try to get an improvement:\n\n1.)  Change the variables we use in the regression (probably the first thing to try is to just drop the age field and see if we do any better, since that's the one we fiddled with before)\n\n2.) Change the way we convert our predicted chance of surival into concrete guesses. We saw above that only 38% of the passengers in the training set actually surived. We can try playing around with the cutoff or some other way of selecting survival guesses, but our first pass did get us pretty close to what we believe the underlying distribution is (assuming it's the same as our training data), so it's likely that working on assigning the predicted percentages more accurately will be more fruitful.\n\n3.) Choose a different model. We're predicting a binary outcome, so we can take a look at a decision tree model as well, and see how that does. \n\nWe'll start with a combination of 1.) and 2.), since that's just a small adjustment from where we already are ."},{"metadata":{"trusted":true,"_uuid":"52cbd2b4aa2628f53a36ec7319a6361bbab07103"},"cell_type":"code","source":"#Look at a summary of the model we started with\n\nsummary(model1)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d95137b0c096bad9054b3dd0f18994a14371699"},"cell_type":"markdown","source":"It looks like the most significant variables according to our first naive model are Class, Sex, Age, and Siblings/Spouses. (It's unfortunate that this includes age, since we know some of those values were inserted by us). Let's try a model where we limit ourselves to just those variables. "},{"metadata":{"trusted":true,"_uuid":"cade8a5c10f978f18c6284502f9aa19a7adf453f"},"cell_type":"code","source":"model2<-glm(Survived~Pclass+Sex+Age+SibSp, family = \"binomial\", data = useful_no_na)\nsummary(model2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c48599a9fc52ba077a6e1c45a6c391e799c24e9d"},"cell_type":"markdown","source":"And now let's make some predictions with the new model and see how they look. "},{"metadata":{"trusted":true,"_uuid":"45e77671f3bea0c0e7f835739360a02bc32b769d"},"cell_type":"code","source":"test_pred2 = predict(model2, newdata= test_no_na, type = \"response\")\nhead(test_pred2)\n\n\nsubmission2<-test[\"PassengerId\"]\nsubmission2<-submission2%>%mutate(PassengerId = as.integer(PassengerId))%>%mutate(Survived = as.integer(test_pred2>=0.5))\nhead(submission2)\n\nsubmission2%>%filter(Survived==1)%>%summarize(Test_survive_pct = n()/nrow(submission2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7cdef720fcbca509313dfddb77ed46b3bf340abc"},"cell_type":"markdown","source":"These predictions also look reasonable. We went from 38.0% survival to 38.8%, which is slightly nicer for the passengers, but is still in the realm of 38.3% that we have for our training set. Let's load it up and see how we do. "},{"metadata":{"trusted":true,"_uuid":"e72833c0373bc91327f40c5f24a846c356849e3b"},"cell_type":"code","source":"write_csv(submission2, \"submission2.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e59422b549db6b9e35e2a0c984e12f7acd999206"},"cell_type":"markdown","source":"Well, exactly the same performance, 74.6%. Let's try taking Age out of the model."},{"metadata":{"trusted":true,"_uuid":"0169906775a131b3dc899324acb4077d65070d28"},"cell_type":"code","source":"model3<-glm(Survived~Pclass+Sex+SibSp, family = \"binomial\", data = useful_no_na)\nsummary(model3)\ntest_pred3<-predict(model3, newdata = test_no_na, type= \"response\")\nhead(test_pred3)\n\nsubmission3<-test[\"PassengerId\"]%>%mutate(PassengerId = as.integer(PassengerId))%>%mutate(Survived = as.integer(test_pred3>=0.50))\nsubmission3%>%filter(Survived ==1)%>%summarize(Test_survive_pct = n()/nrow(submission3))\nwrite_csv(submission3, \"submission3.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0906b3fa7dc06e0534f5b69a272b5984f0a55868"},"cell_type":"markdown","source":"77%! Progress! Looks like either Age wasn't a helpful predictor, or the fact that we had to guess at missing values for around 20% of the passengers undermined what the Age variable would have told us. One last thing to try, if we really think Age might be a useful predictor (and again, it seems pretty reasonable, at least naively), is to replace the missing Ages with some other, non-NA character, so we can still generate predictions for those with age values listed, and maybe not skew survival percentages for those near the median age. "},{"metadata":{"trusted":true,"_uuid":"6ae1ec14699ef55229ab3b5dc82ef647aed76c28"},"cell_type":"code","source":"# Create new data frames with \"none\" category for unknown ages. \nuseful_na_age<-useful\nuseful_na_age[which(is.na(useful$Age)), \"Age\"]<-\"none\"\nhead(useful_na_age)\n\ntest_na_age<-test\ntest_na_age[which(is.na(test$Age)), \"Age\"]<-\"none\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c8f687a9cf5c400be027cbdb43a64cd906a8a4e"},"cell_type":"code","source":"#Make a new model and get its predictions\nmodel4<-glm(Survived~Pclass +Sex+Age+SibSp, family = \"binomial\", data= useful_na_age)\nsummary(model4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c09eb91528162c345a0e9d57af7301217ae7178c"},"cell_type":"code","source":"\n#test_pred4<-predict(model4, newdata = test_na_age, type = \"response\")\n#head(test_pred4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45d0ef441a78c2e5392b2c3791b57b2ae86af024"},"cell_type":"markdown","source":"Well, here we run into an error, and if we examine the summary of the model above, we see that apart from missing some values the Age data is troublesome because once we start treating the Age field as a character, the ages that occur in the test set but not in the training set have no match and so the model doesn't know what to do with them. Exacerbating the problems is the fact that many passengers gave their ages as fraction, so there are even more possible values for the field. This is acceptable for infants, where it makes sense to keep track of their age in months, and I suppose we might let it slide for children who want to feel older and so tack on the extra half-year they've earned, but there are grown people listing their ages as 38 and a half. This is madness. \n\nWe could try just rounding all the fractions off (it seems unlikely that the difference of a few months in age would affect survival rates), but the ages 67 and 76 are whole number ages that happen to occur in the test set and not the training set, so we still wouldn't get a prediction on these passengers with this approach. In the interests of fixing this problem and also cleaning up the data, it probably makes more sense to just group the different ages into a few separate bins. This has the benefit of letting us use data about, say, 31-year-old passengers to contribute to predicting the survival rates of 32-year-old passengers. We'll do this clean-up in the next cell, using bins of 10 year increments as a start. "},{"metadata":{"trusted":true,"_uuid":"ceb034a01e0cd269bc990c1f436290156f7b8363"},"cell_type":"code","source":"#Write a function that, for a given bin size, assigns each Age value to a bin named by the range of the bin\n\nbin_namer <-function(x, binsize){\n    midpoint<-binsize/2+(binsize*floor(x/binsize))\n    boxname<-paste(as.character(binsize*floor(midpoint/binsize)),\"-\", as.character(binsize*ceiling(midpoint/binsize)))\n    return(boxname)\n}\n            \n        \nuseful_age_bin<-useful%>%mutate(Age_bin = bin_namer(Age, 10))\n       head(useful_age_bin)\ntest_age_bin<-test%>%mutate(Age_bin = bin_namer(Age, 10))\n       head(test_age_bin)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f9f04fe975be4261dd231faf8a02067a082a8a2"},"cell_type":"code","source":"#Check how the survival chances look by age bin\n\nbin_groups<-useful_age_bin%>%group_by(Age_bin)%>%summarize(Percent_survived = length(which(Survived ==1))/n())\nggplot(bin_groups, aes(x=Age_bin, y=Percent_survived))+geom_col()+labs(x=\"Age bin\", y=\"Percentage of passengers who survived\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b26a4716d27d4003ed89a660cf6cdc33fc840f51"},"cell_type":"markdown","source":"Looks like the one 80-year-old in our training set survived, which is giving that bin pretty good odds of survival. That might skew the guesses for passengers in the test set in the same bin, if Age_bin ends up being an important variable. Now that we've got the age bins set up, let's see what kind of model they give us. "},{"metadata":{"trusted":true,"_uuid":"f508ea12a640d2a5114e01fa27776aef305c9aa0"},"cell_type":"code","source":"#Construct the model\nmodel4<-glm(Survived~Pclass +Sex+Age_bin+SibSp, family = \"binomial\", data= useful_age_bin)\nsummary(model4)\n\n#Get the predictions\ntest_pred4<-predict(model4, newdata = test_age_bin, type = \"response\")\nhead(test_pred4)\n\n#Prepare the submission\nsubmission4<-test[\"PassengerId\"]%>%mutate(PassengerId = as.integer(PassengerId))%>%mutate(Survived = as.integer(test_pred4>=0.50))\nsubmission4%>%filter(Survived ==1)%>%summarize(Test_survive_pct = n()/nrow(submission4))\nwrite_csv(submission4, \"submission4.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"121d9b0000d5a041474f763e043b020bd6770ce8"},"cell_type":"markdown","source":"Well, back down to 74.6%. Let's try slightly smaller bins. Say, of width 5 years. "},{"metadata":{"trusted":true,"_uuid":"1ace685085c122d7b549e0a4ca2ef83dac1002d6"},"cell_type":"code","source":"useful_age_bin5<-useful%>%mutate(Age_bin = bin_namer(Age, 5))\n       head(useful_age_bin5)\ntest_age_bin5<-test%>%mutate(Age_bin = bin_namer(Age, 5))\n       head(test_age_bin5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb0876d4d8f6b35b6c56affec99d9869e1b90afb"},"cell_type":"code","source":"#Treat our Age_bin variable as an ordered factor\nfactored_age_bin5<-useful_age_bin5\nages<- c(\"0 - 5\",\"5 - 10\",\"10 - 15\", \"15 - 20\",\"20 - 25\", \"25 - 30\",\"30 - 35\", \"35 - 40\", \"40 - 45\", \"45 - 50\", \"50 - 55\", \"55 - 60\", \"60 - 65\", \"65 - 70\", \"70 - 75\", \"75 - 80\", \"80 - 85\", \"NA - NA\" )\nfactored_age_bin5$Age_bin<-factor(useful_age_bin5$Age_bin, ordered = TRUE, levels = ages)\nfactored_age_bin5$Survived<-factor(factored_age_bin5$Survived, levels = c(\"0\", \"1\"))\n\n\ntest_age_bin5<-test%>%mutate(Age_bin = bin_namer(Age, 5))\n       head(test_age_bin5)\ntest_age_bin5$Age_bin<-factor(test_age_bin5$Age_bin, ordered = TRUE, levels = ages)\n\n\n\nbin_groups<-factored_age_bin5%>%group_by(Age_bin)%>%mutate(Percent_survived = length(which(Survived ==1))/n())%>%mutate(Bin_count = n())\nggplot(bin_groups, aes(x=Age_bin, y = Percent_survived, size = Bin_count))+geom_point()+\ntheme(axis.text.x = element_text(angle = 90, hjust = 1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55d9b9a3dd21d1064559b1ad5a9fc4ab8cb1afa7"},"cell_type":"markdown","source":"One concern we notice from the plot above: Our training data contained no passenger in the 75-80 bin. If the test set has such a passenger, the prediction won't know what to do with him or her. We'll need to sort this out"},{"metadata":{"trusted":true,"_uuid":"4051e619e1e215372eceed3f0bbbb20afc3fa357"},"cell_type":"code","source":"test_age_bin5%>%filter(Age_bin==\"75 - 80\") #See if there are such passengers\n\n#Unfortunately, there is one. \nuseful_age_bin5%>%filter(Age_bin==\"70 - 75\") #We've got 6 passengers in the training set in bin 70-75, so let's try just throwing Mrs. Cavendish in that bin\n\nwhich(test_age_bin5$Age_bin == \"75 - 80\")\ntest_age_bin5[97, \"Age_bin\"]<-\"70 - 75\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"472093001a8422561a91c44eed8ca69806c4a8e0"},"cell_type":"code","source":"#Now build the model and predictions\n\nmodel5<-glm(Survived~Pclass +Sex+Age_bin+SibSp, family = \"binomial\", data= useful_age_bin5)\nsummary(model5)\n\n#Get predictions\ntest_pred5<-predict(model5, newdata = test_age_bin5, type = \"response\")\n\n#Generate submission\nsubmission5<-test[\"PassengerId\"]%>%mutate(PassengerId = as.integer(PassengerId))%>%mutate(Survived = as.integer(test_pred5>=0.50))\nsubmission5%>%filter(Survived ==1)%>%summarize(Test_survive_pct = n()/nrow(submission5))\nwrite_csv(submission5, \"submission5.csv\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46cc1d60dffac304f09d90775667e5d77ae8e5b6"},"cell_type":"markdown","source":"Well, 74.6% again. Looks like all this fiddling around with age isn't getting us any better at predicting (the best result so far was when we dropped the Age field altogether). Let's try staying with that strategy, but doing some more complicated regression techniques, to see if we can't squeeze some more juice out of it.  In particular, we'll split our training set into pieces and build several models to cross validate. Hopefully when we average our separate models together their teamwork will give better predictions."},{"metadata":{"trusted":true,"_uuid":"8c2b80cfb24d59ca623ef0e99cf4b91a795d46e1"},"cell_type":"code","source":"#Selecting Cross Validation Sets\nset.seed(100)\npermutation<-sample(nrow(train))\npermuted_train<-train[permutation,]\n\n#Now we've put our training set into a random order. If we just separate it into thirds, each will be randomly selected relative to the other two. \n#Then we can use each two to train a model predicting the third, and average these models together for the test.\n\ntrain1<-permuted_train[1:(nrow(train)/3),]\ntrain2<-permuted_train[((nrow(train)/3)+1):(2*nrow(train)/3),]\ntrain3<-permuted_train[((2*nrow(train)/3)+1):nrow(train), ]\nhead(train3)\n\ntrain12<-bind_rows(train1, train2)\ntrain13<-bind_rows(train1, train3)\ntrain23<-bind_rows(train2, train3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee43fb09124c71875bcf0a90a4aceeda536b1957"},"cell_type":"markdown","source":"Now, the model that has done the best so far used just Pclass, Sex, and SibSp to predict the chances of a passenger surviving, so we'll use the same model for each pair of thirds of our training set. "},{"metadata":{"trusted":true,"_uuid":"0d85d696a5e2beb92ac173c4d4ac89180eda3988"},"cell_type":"code","source":"cvmodel12<-glm(Survived~Pclass+Sex+SibSp, family = \"binomial\", data = train12)\ncvmodel13<-glm(Survived~Pclass+Sex+SibSp, family = \"binomial\", data = train13)\ncvmodel23<-glm(Survived~Pclass+Sex+SibSp, family = \"binomial\", data = train23)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3d5b458defca46e3c7b353ecc2429fbf6d1ecd5"},"cell_type":"code","source":"#Make the predictions for the missing data from each model.\npred12<- predict(cvmodel12, newdata = train3, type = \"response\")\npred13<-predict(cvmodel13, newdata = train2, type = \"response\")\npred23<- predict(cvmodel23, newdata = train1, type = \"response\")\n\nthreshold<-0.6\nprediction12<-ifelse(pred12>=threshold, 1, 0)\nprediction13<-ifelse(pred13>=threshold, 1, 0)\nprediction23<-ifelse(pred23>=threshold, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16d00a8ac8e411279c661b99f358958fba0bedcc"},"cell_type":"code","source":"#Let's see how the predictions are working out\nconf1<-table(train1$Survived, prediction23)\nconf2<-table(train2$Survived, prediction13)\nconf3<-table(train3$Survived, prediction12)\n\nconf1\nconf2\nconf3\n\naccuracy12<-sum(diag(conf3))/sum(conf3)\naccuracy13<-sum(diag(conf2))/sum(conf2)\naccuracy23<-sum(diag(conf1))/sum(conf1)\n\nc(accuracy12, accuracy13, accuracy23)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55a2206df9abd9caf325bbf61b1452b9d14624c7"},"cell_type":"markdown","source":"All pretty good accuracies! Let's try averaging their guesses about the test set together, and see if that helps at all. "},{"metadata":{"trusted":true,"_uuid":"7b322bcf4e0b08086dd4d1263dfe18bb8532e650"},"cell_type":"code","source":"test_pred12<-predict(cvmodel12, newdata=test, type=\"response\")\ntest_pred13<-predict(cvmodel13,, newdata=test, type=\"response\")\ntest_pred23<-predict(cvmodel23, newdata=test, type=\"response\")\n\ntest_pred6<- rowMeans(cbind(test_pred12, test_pred13, test_pred23))\nhead(test_pred6)\n\nsubmission6<-test[\"PassengerId\"]%>%mutate(Survived = as.integer(test_pred6>=0.5), PassengerId = as.integer(PassengerId))\n\nsubmission6%>%filter(Survived ==1)%>%summarize(n()/nrow(submission6))\nwrite_csv(submission6, \"submission6.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93889cbded248633f970449e091c644f07351c82"},"cell_type":"markdown","source":"77%. Exactly as good as without the cross validation. In fact, let's check if the predictions were different from what we got without the cross validation (we maybe should have done this before submitting, but submitting doesn't really cost us anything either). "},{"metadata":{"trusted":true,"_uuid":"dbeb0d5644e74bb1472b87fba7cb96a6e775c2f0"},"cell_type":"code","source":"length(which(submission3$Survived !=submission6$Survived))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d21af3371e9f0d2a8e589212b0b0dbc36338511c"},"cell_type":"markdown","source":"Exactly the same! We can try increasing the number of folds (and checking whether anything is changing before we submit), and if necessary, break out the big guns of leave-one-out cross validation. "},{"metadata":{"trusted":true,"_uuid":"bae9b0b5ca2aff3ef620842e64a80d9b17b86fd2"},"cell_type":"code","source":"#Separate the set into pieces. We'll write actual functions to do it this time. \n\nseparate<-function(df, n){\n    pieces<-vector(\"list\",n)\n    rows<-nrow(df)\n    width<-floor(nrow(df)/n) #if n does not evenly divide the number of rows in the dataframe, the last piece will be bigger\n    for(i in 1:(n-1)){  \n        pieces[[i]] <- df[(((i-1)*width)+1):(i*width),]\n        }\n    pieces[[n]]<-df[(((n-1)*width)+1):(nrow(df)),]\n\n    return(pieces)   \n    }\n\nbind<-function(pieces){\n    n<-length(pieces)\n    clumps<-vector(\"list\", n)\n    for(i in (1:n)){\n        clumps[[i]]<-bind_rows(pieces[c(-i)])\n    }\n    return(clumps)    \n}\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc2ceb5fdb9f2ee2c294ee96f4b23b09d19556d5"},"cell_type":"code","source":"#Now we write functions to build the models from the clumps to predict the pieces.\n\nbuild_models<-function(clumps){\n    clump_models<-vector(\"list\", length(clumps))\n    for(i in (1:length(clumps))){\n        clump_models[[i]]<-glm(Survived~Pclass+Sex+SibSp, family = \"binomial\", data = clumps[[i]])\n    }\n    return(clump_models)\n}\n\n\nget_predictions<-function(clump_models, pieces){\n    n<- length(pieces)\n    predictions<-vector(\"list\", n)\n    for(i in (1:n)){\n        predictions[[i]]<-predict(clump_models[[i]], newdata = pieces[[i]], type = \"response\")\n    \n        \n    }  \n    return(predictions)\n   \n}\n        \n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6343aa6857889ffa92cb80a3090e04a1735eae68"},"cell_type":"markdown","source":"Let's try using 10 pieces, just to see if that gets us any better. If not, we'll jump up to leave-one-out, and then maybe some stronger techniques."},{"metadata":{"trusted":true,"_uuid":"578256db78374c6677ceffb998d9674370040350"},"cell_type":"code","source":"#Now we actually do the separating and modelling\n\n#Get a random ordering of the training set\nset.seed(101)\npermutation<-sample(nrow(train))\npermuted_train<-train[permutation,]\n\n\npieces<-separate(permuted_train,10)\nclumps<-bind(pieces)\nclump_models<-build_models(clumps)\npredicted_chances<-get_predictions(clump_models, pieces)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc578341cfaa41d1a2c1b800a02ff7249a2ff088"},"cell_type":"code","source":"threshold<- 0.5\npredictions<-vector(\"list\", length(predicted_chances))\nfor(i in (1:length(predicted_chances))){\n    predictions[[i]]<-ifelse(predicted_chances[[i]]>=threshold, 1, 0)\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b4fdd0d4c43e2142a2b79148a4aef3e1f38f78a"},"cell_type":"code","source":"conf<-vector(\"list\", length(predictions))\nfor(i in (1:length(conf))){\n    conf[[i]]<-table(pieces[[i]]$Survived, predictions[[i]])\n}\n\naccuracy<-(1:length(conf))\nfor(i in 1:length(conf)){\n    accuracy[i]<-sum(diag(conf[[i]]))/sum(conf[[i]])\n}\n\naccuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b08842b995609908a0e3c48c823584017f0f0a0b"},"cell_type":"code","source":"#Make predictions on the test set and put them together\ntest_predict<-function(clump_models){\n    test_pred<-vector(\"list\", length(clump_models))\n    for(i in 1:length(test_pred)){\n        test_pred[[i]]<-predict(clump_models[[i]], newdata = test, type = \"response\")\n    }\n    return(test_pred)\n}\n\ntest_pred<-test_predict(clump_models)\npred_matrix<-test_pred[[1]]\n\nfor(i in 2:length(test_pred)){\n    pred_matrix<-cbind(pred_matrix, test_pred[[i]])\n}\n\ntest_pred7<-rowMeans(pred_matrix)\nhead(test_pred7)\n\nsubmission7<-test[\"PassengerId\"]%>%mutate(Survived = as.integer(test_pred7>=0.5), PassengerId = as.integer(PassengerId))\n\nsubmission7%>%filter(Survived ==1)%>%summarize(n()/nrow(submission7))\nwrite_csv(submission7, \"submission7.csv\")\n\nhead(submission7)\n\nlength(which(submission7$Survived!=submission3$Survived))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f7ef78b1e451590690192a0a470f8df958e22f8"},"cell_type":"markdown","source":"Alright, let's try leave-one-out cross-validation. We'll use the package \"caret.\""},{"metadata":{"trusted":true,"_uuid":"7c5b98fc14aaba7c01d40577da1371241cb0e078"},"cell_type":"code","source":"library(caret)\n\ntrainf<-train\ntrainf$Survived<-as.factor(trainf$Survived)\nstr(trainf)\nloomodel<-train(Survived ~ Pclass+Sex+SibSp, method = \"glm\", data = trainf, trControl = trainControl(method = \"LOOCV\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1912d947ee391fbf1187c58f8865f5c5d8701ec5"},"cell_type":"code","source":"test_pred8<-predict(loomodel, newdata = test, type= \"raw\")\nhead(test_pred8)\n\ntest_pred8<-matrix(as.integer(test_pred8), ncol = 1)\ntest_pred8<-test_pred8 -1\nhead(test_pred8)\nsubmission8<-test[\"PassengerId\"]%>%mutate(PassengerId = as.integer(PassengerId), Survived = test_pred8)\nhead(submission8)\nlength(which(submission8$Survived!=submission3$Survived))\n\nwrite_csv(submission8, \"submission8.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e693e49f42aaca6b98de9f0752dc2d7c9c893fc5"},"cell_type":"markdown","source":"OK. Enough of logistic regression. Let's try a decision tree model and see where that gets us."},{"metadata":{"trusted":true,"_uuid":"41526f85b2dba7c0445f61f71dd2ac9ef6a3d339"},"cell_type":"code","source":"train_tree<-train%>%mutate(Survived = as.factor(ifelse(Survived==1,\"Survived\", \"Died\")))%>%mutate(Sex = as.factor(Sex))\ntrain_tree$Embarked[which(is.na(train_tree$Embarked))]<-\"S\"\ntrain_tree<-train_tree%>%mutate(Embarked = as.factor(Embarked))\nhead(train_tree)\nstr(train_tree)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e086b0ed7490deb40fdfa002432f70ce845563b"},"cell_type":"markdown","source":"Let's reexamine Fare as a potentially useful variable. It probably correclates pretty closely to socio-economic class, so maybe it's not telling us much we don't already know more succintly, but it might also provide a finer distinction of wealth level within the 3 rough classes we get from the data. "},{"metadata":{"trusted":true,"_uuid":"7b84c516c02adecfebfd7c1edd1ea4a18665fc89"},"cell_type":"code","source":"#Let's make a box plot to see how fares are distributed in the 3 classes. \nggplot(train%>%group_by(Pclass)%>%filter(Fare<500), aes(x=Pclass, y=Fare))+geom_boxplot()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c71d6219ab1d4b3ec123012c508a902e1b4f1f9"},"cell_type":"markdown","source":"From the plot, we see that clearly that the majority 1st class passengers paid fares that are more than almost all the the lower classes paid, but there are a few outliers. Also, the distinction in fares between 2nd and 3rd class isn't that strict: it looks like the median fare for 2nd class is slightly below the 75 percentile for 3rd class. Let's see how fares correlate with survival."},{"metadata":{"trusted":true,"_uuid":"dfec6646555c10861947ef8acb6e2a7ad82560e4"},"cell_type":"code","source":"#Build a scatterplot of fares, coloring each dot by whether that passenger survived\nggplot(train%>%filter(Fare<300), aes(x=PassengerId, y=Fare, color = Survived))+geom_point() \n#We have 3 outlier2 who paid 512-pound fares(and all survived), to keep the graph simple we'll exclude them","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a791fa0e578f6b13600e25b84283b1cf34781c84"},"cell_type":"markdown","source":"It looks like definitely the higher fares had a higher chance of survival. Paying anything past 80ish pounds would give pretty good odds, whereas there's a lot of dark blue clustered around the very bottom. Finally, let's plot the different fares vs. the percent of passengers who paid that fare that survived. To keep things simple, we'll round off to the nearest 5 pounds. "},{"metadata":{"trusted":true,"_uuid":"64d83bcef7d2d8b40906046183f7bd58fa3a14e9"},"cell_type":"code","source":"#First group passengers by fare, rounded to the nearest 5 and calculate the percentage chance of survival in each group\nfare_groups<-train_tree%>%mutate(Rounded_fare = 5*round(Fare/5))%>%group_by(Rounded_fare)%>%mutate(Percent_survived = length(which(Survived ==\"Survived\"))/n() )\nggplot(fare_groups%>%group_by(Rounded_fare)%>%mutate(Fare_count = n(), Average_class = mean(Pclass))%>%filter(Fare<300), aes(x=Rounded_fare, y=Percent_survived, size = Fare_count, color =Average_class))+\ngeom_point()+scale_x_log10()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0e74549eead2a940992d8166e38696f0509bbfe"},"cell_type":"markdown","source":"Again, there's a pretty clear trend upwards. Once you've paid at least 100 pounds for a ticket, you have at least even odds of surviving, while if you pay less than 10 your odds are less than 1 in 4. There are two small outlier points with 0 percent surival, but relatively high fares. The first has fares in the 40ish range, but is colored to represent mainly 3rd class passengers. The dot is also sizable, so a number of passengers must fall into that situation.  The second is a much higher fare, but the dot is small, so it probably is just an outlier. Let's just check them out."},{"metadata":{"trusted":true,"_uuid":"f3c2669103d63899944c12035dd7a4ede08945c9"},"cell_type":"code","source":"fare_groups%>%filter(Rounded_fare<100 & Percent_survived == 0) #It looks like this was mainly a family (with 5 children) who all died together. \nfare_groups%>%filter(Rounded_fare>100 & Percent_survived == 0) #Just an outlier, no extra informations about him","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"212cbc6813e34d5786d314b9e1c9eb76e63e05aa"},"cell_type":"markdown","source":"Well, let's continue keeping track of fares, then. Now lets start building our decision tree. "},{"metadata":{"trusted":true,"_uuid":"b14d28b1133a89357d69f64e59e6b2101600cb21"},"cell_type":"code","source":"library(tree)\n\ntree_model1<- tree(Survived ~ Pclass+Age + Sex+ Fare+SibSp, data = train_tree)\nsummary(tree_model1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2fa834db264aada8abc89f44f962a8ca2d0d3184"},"cell_type":"code","source":"plot(tree_model1)\ntext(tree_model1, pretty = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87cb790c5d5e7543ffc304acc4f320861ced7a2e"},"cell_type":"code","source":"#Now prepare the test set to fit the model assumptions, and get predictions on it. \ntest_tree<-test%>%mutate(Sex = as.factor(Sex), Embarked = as.factor(Embarked))\ntree_pred1<-predict(tree_model1, newdata = test_tree, type = \"vector\")\nhead(tree_pred1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e00f4283af32dd87346bf5c961de2b01bf6a550c"},"cell_type":"code","source":"submission12<-cbind(test[\"PassengerId\"], as.integer(tree_pred1[,\"Survived\"]>=0.5))\nnames(submission12)[2]<-\"Survived\"\n\nsubmission12<-submission12%>%mutate(PassengerId = as.integer(PassengerId))\nhead(submission12)\nwrite_csv(submission12, \"submission12.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2499fcbd73823ddb6f73e8687160ed106637e9b2"},"cell_type":"markdown","source":"Woo! 79%. Finally an improvement over the logistic regression models we've been playing with. Let's see what else we can get from this. First, we note that the tree model we just built did not include the data from passengers whose age values were missing. Again, we can play around with either setting those ages to the mean, or setting them to an actual value of 'missing.'"},{"metadata":{"trusted":true,"_uuid":"170aea9bd6f6a2a6b07e52dd1ba3926dbde07cfe"},"cell_type":"code","source":"#Replace missing ages with mean\ntrain_tree_age_mean<-train_tree\ntrain_tree_age_mean$Age[which(is.na(train_tree$Age))]<-mean(train_tree$Age, na.rm = TRUE)\n\n#Build a new model with these data included\ntree_model2<- tree(Survived ~ Pclass+Age + Sex+ Fare+SibSp, data = train_tree_age_mean)\nsummary(tree_model2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d52db8bdbad44d6c84213db481ecc484009f00f"},"cell_type":"markdown","source":"According to the summary, the misclassification error is about .5% less than the first tree model we made. It's probably worth running the prediction and submitting. First, let's take a look at the tree we got. "},{"metadata":{"trusted":true,"_uuid":"fa0eb04dd698b2ff0160272b9d76256e5b938f64"},"cell_type":"code","source":"plot(tree_model2)\ntext(tree_model2, pretty = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee9598aaf5e87560a8b5d96157869d414800997d"},"cell_type":"code","source":"#Tree looks good. Let's make the predictions and submit. \ntree_pred2<-predict(tree_model2, newdata = test_tree, type = \"vector\")\n\nsubmission13<-cbind(test[\"PassengerId\"], as.integer(tree_pred2[,\"Survived\"]>=0.5))\nnames(submission13)[2]<-\"Survived\"\n\nsubmission13<-submission13%>%mutate(PassengerId = as.integer(PassengerId))\nhead(submission13)\nwrite_csv(submission13, \"submission13.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22041ac8d4dc8c9e2d86703f79e2b03d65e7c9a0"},"cell_type":"markdown","source":"79.4%! Looks like we got 2 more predictions correct. Slow and steady progress! Let's see, just for the sake of checking, how we would do if we left the missing ages missing, but included their missingness as data. We'll need to treat Age as an ordered factor, so let's bring back our Age_bins. Bins of size 5 should be fine. (The tree() funciton won't work if preidctor factors have more than 32 levels)"},{"metadata":{"trusted":true,"_uuid":"1a6df5bea168c157200b076f4f0571b532753999"},"cell_type":"code","source":"#Create a new data frame, where Age is rounded off and treated as an ordered factor, with an extra 'none' category\ntrain_tree_age_missing<-train_tree%>%mutate(Age_bin = bin_namer(Age, 5))\n\n#Treat our Age_bin variable as an ordered factor\nages<- c(\"0 - 5\",\"5 - 10\",\"10 - 15\", \"15 - 20\",\"20 - 25\", \"25 - 30\",\"30 - 35\", \"35 - 40\", \"40 - 45\", \"45 - 50\", \"50 - 55\", \"55 - 60\", \"60 - 65\", \"65 - 70\", \"70 - 75\", \"75 - 80\", \"80 - 85\", \"NA - NA\" )\n\ntrain_tree_age_missing$Age_bin<-factor(train_tree_age_missing$Age_bin, ordered = TRUE, levels = ages)\n\ntest_tree_age_missing<-test_tree%>%mutate(Age_bin = bin_namer(Age, 5))\ntest_tree_age_missing$Age_bin<-factor(test_tree_age_missing$Age_bin, ordered = TRUE, levels = ages)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23a682923f43adc36e87feadddcce4f50ebf199b"},"cell_type":"code","source":"#Build the tree model on this training set, and see how it goes.\n\ntree_model3<- tree(Survived ~ Pclass+Age_bin + Sex+ Fare+SibSp, data = train_tree_age_missing)\nsummary(tree_model3)\nplot(tree_model3)\ntext(tree_model3, pretty = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"456343288cb814f9d93d4d09fbdfddfd946bdca1"},"cell_type":"markdown","source":"It looks like this is doing worse than our earlier models. We can submit it anyway to check, but let's not get our hopes up. "},{"metadata":{"trusted":true,"_uuid":"ed60e4ceb37044c4e0542e645c061e5547ac5006"},"cell_type":"code","source":"tree_pred3<-predict(tree_model3, newdata = test_tree_age_missing, type = \"vector\")\n\nsubmission14<-cbind(test[\"PassengerId\"], as.integer(tree_pred3[,\"Survived\"]>=0.5))\nnames(submission14)[2]<-\"Survived\"\n\nsubmission14<-submission14%>%mutate(PassengerId = as.integer(PassengerId))\nhead(submission14)\nwrite_csv(submission14, \"submission14.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9994baf6e6a5737637a893555a2b5d40c1156273"},"cell_type":"markdown","source":"Well, this one did drop us back to 78.9%, which we kind of expected. The tree was also much harder to understand, so we'll keep going with the second model we made. \n"},{"metadata":{"_uuid":"11f633b84ca9e278534483f67a142d3ec08d9029"},"cell_type":"markdown","source":"Here's something interesting we noticed in the data while looking at the outliers in the fare field:\n\nAlthough we're missing almost all the data for cabin numbers, just having a cabin number at all increases a passengers chance of survival. (Most of the poorer passengers were likely traveling in steerage, where they would not have cabins assigned). "},{"metadata":{"trusted":true,"_uuid":"0317a9002310fcd690104f55c62ad8fab2233cc3"},"cell_type":"code","source":"#Make a dataframe containing just the passengers with cabins\ncabins<-train%>%filter(!is.na(Cabin))\n#Percent chance of survival for passengers in cabins\ncabins%>%summarize(Percent_Survived = sum(Survived)/n())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee53539556a1c683fefcbbcdc450d99b176804c9"},"cell_type":"markdown","source":"2/3 of passengers with a cabin survive! That kind of correlation might be worth including in the model. In fact, we can go a little deeper. We don't actually know much about what the cabin numbers mean, but the letter part is likely a section or deck reference, so we can group those in cabins by roughly where there cabin was located. We'll add new fields \"Has_cabin\" and \"Deck\", keeping track which passengers have cabins and what decks passengers accomodations are on (if given).\n\n"},{"metadata":{"trusted":true,"_uuid":"7a3c870e48d5ab82f93f64dd7b02f9cf9e8c4aaa"},"cell_type":"code","source":"train_tree_cabins<-train_tree_age_mean%>%mutate(Has_cabin = as.integer(!is.na(Cabin)), Deck = Cabin)\n\ntrain_tree_cabins$Deck[grepl(\"^A\", train_tree_cabins$Cabin)]<-\"A\"\ntrain_tree_cabins$Deck[grepl(\"^B\", train_tree_cabins$Cabin)]<-\"B\"\ntrain_tree_cabins$Deck[grepl(\"^C\", train_tree_cabins$Cabin)]<-\"C\"\ntrain_tree_cabins$Deck[grepl(\"^D\", train_tree_cabins$Cabin)]<-\"D\"\ntrain_tree_cabins$Deck[grepl(\"^E\", train_tree_cabins$Cabin)]<-\"E\"\ntrain_tree_cabins$Deck[grepl(\"^F\", train_tree_cabins$Cabin)]<-\"F\"\ntrain_tree_cabins$Deck[grepl(\"^G\", train_tree_cabins$Cabin)]<-\"G\"\ntrain_tree_cabins$Deck[is.na(train_tree_cabins$Deck)]<-\"none\"\nhead(train_tree_cabins)\n\ntrain_tree_cabins%>%group_by(Deck)%>%summarize(percent_survived = sum(Survived==\"Survived\")/n())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85d30e49ce129b739eda46bee40c9256d8a9575c"},"cell_type":"markdown","source":"We see that different decks have different percentages of surviving passengers, but all of them are much higher than the passengers with no cabin at all. We'll try including this data in our model, although it might not have much effect over the Pclass and Fare variables that are already being included.\n"},{"metadata":{"trusted":true,"_uuid":"7259fb6eb9e3ac8397ab7342539aba892c4534e5"},"cell_type":"code","source":"#Turn the Deck and Has_cabin variables into factors\ntrain_tree_cabins$Deck<-factor(train_tree_cabins$Deck, ordered = TRUE, levels = c(\"none\", \"T\", \"G\", \"F\", \"E\", \"D\", \"C\", \"B\", \"A\"))\ntrain_tree_cabins$Has_cabin<-factor(train_tree_cabins$Has_cabin, ordered = TRUE, levels = c(\"0\", \"1\"))\n\n#Build the model\ntree_model4<- tree(Survived ~ Pclass+Age + Sex+ Fare+SibSp+Has_cabin+Deck, data = train_tree_cabins)\nsummary(tree_model4)\nplot(tree_model4)\ntext(tree_model4, pretty = 0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a2229f72b32e4dcfebdcb3a7017a241d7a34d73"},"cell_type":"markdown","source":"Alright, looks pretty good. It does slightly better than our best model so far at fitting the training data. It looks like having a cabin or not is an important predictor (although the tree makes the decision as having either no deck or deck T (which is a weird outlier in the Cabin field)). Let's prepare the test set, and then get some predictions on it. "},{"metadata":{"trusted":true,"_uuid":"5ad2856bfe11eac768328dbaf2324177c01b54f9"},"cell_type":"code","source":"#Prepare the Has_cabin and Deck fields for the test set\ntest_tree_cabins<-test_tree%>%mutate(Has_cabin = as.integer(!is.na(Cabin)), Deck = Cabin)\n\ntest_tree_cabins$Deck[grepl(\"^A\", test_tree_cabins$Cabin)]<-\"A\"\ntest_tree_cabins$Deck[grepl(\"^B\", test_tree_cabins$Cabin)]<-\"B\"\ntest_tree_cabins$Deck[grepl(\"^C\", test_tree_cabins$Cabin)]<-\"C\"\ntest_tree_cabins$Deck[grepl(\"^D\", test_tree_cabins$Cabin)]<-\"D\"\ntest_tree_cabins$Deck[grepl(\"^E\", test_tree_cabins$Cabin)]<-\"E\"\ntest_tree_cabins$Deck[grepl(\"^F\", test_tree_cabins$Cabin)]<-\"F\"\ntest_tree_cabins$Deck[grepl(\"^G\", test_tree_cabins$Cabin)]<-\"G\"\ntest_tree_cabins$Deck[is.na(test_tree_cabins$Deck)]<-\"none\"\n\ntest_tree_cabins$Deck<-factor(test_tree_cabins$Deck, ordered = TRUE, levels = c(\"none\", \"T\", \"G\", \"F\", \"E\", \"D\", \"C\", \"B\", \"A\"))\ntest_tree_cabins$Has_cabin<-factor(test_tree_cabins$Has_cabin, ordered = TRUE, levels = c(\"0\", \"1\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ddbe8705a27baf6706fc96c3a8de1d29efb929b"},"cell_type":"code","source":"#Get the predictions\ntree_pred4<-predict(tree_model4, newdata = test_tree_cabins, type = \"vector\")\n\nsubmission15<-cbind(test[\"PassengerId\"], as.integer(tree_pred4[,\"Survived\"]>=0.5))\nnames(submission15)[2]<-\"Survived\"\n\nsubmission15<-submission15%>%mutate(PassengerId = as.integer(PassengerId))\nhead(submission15)\nwrite_csv(submission15, \"submission15.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c1b7e6c24758e7421bc8e9837aad29d0cebadf2"},"cell_type":"markdown","source":"79.9% Moving on up! A few more things to try that might squeeze more accuracy out of this. "},{"metadata":{"trusted":true,"_uuid":"783a417bed27b8346f7a1bfde47752ea8c8ad59f"},"cell_type":"code","source":"library(randomForest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e174c5efdce0512e6ba4c198ea0613995eae8a47"},"cell_type":"code","source":"#Prepare the training set by removing extraneous variables\ntrain_tree_cabins_nona<-train_tree_cabins[,c(\"PassengerId\",\"Survived\", \"Pclass\",\"Age\",\"Sex\", \"Fare\", \"SibSp\",\"Has_cabin\",\"Deck\")]\n\n#Build a random forest\nrf_model<-randomForest(Survived~.-PassengerId, data=train_tree_cabins_nona)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"563f552df924164736d3ba4c735e3589ee98df0f"},"cell_type":"code","source":"rf_model\nplot(rf_model)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6039e60fcb536f44ce161ede9d7905beb1746437"},"cell_type":"code","source":"#Make predictions on the test data.\n#First, fill in the missing Fare and Age values in the test data\ntest_tree_cabins_nona<-test_tree_cabins\ntest_tree_cabins_nona$Fare[is.na(test_tree_cabins$Fare)]<-median(filter(test_tree_cabins, Pclass ==  3)$Fare, na.rm=TRUE)\ntest_tree_cabins_nona$Age[is.na(test_tree_cabins$Age)]<-mean(test_tree_cabins$Age, na.rm=TRUE)\ntest_tree_cabins_nona<-test_tree_cabins_nona%>%mutate(Survived = as.factor(\"unknown\"))\ntest_tree_cabins_nona<-test_tree_cabins_nona[,c(\"PassengerId\", \"Survived\", \"Pclass\",\"Age\",\"Sex\", \"Fare\", \"SibSp\",\"Has_cabin\",\"Deck\")]\n#Now, get the predictions\ntest_pred_rf<-predict(rf_model, newdata = test_tree_cabins_nona, type = \"prob\")\n\nhead(test_pred_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c958dce5dd11f5934cd6efa55ad1624123b5d3e2"},"cell_type":"code","source":"#Prepare the submission\nsubmission16<-cbind(test[\"PassengerId\"], as.integer(test_pred_rf[,\"Survived\"]>=0.5))\nnames(submission16)[2]<-\"Survived\"\n\nsubmission16<-submission16%>%mutate(PassengerId = as.integer(PassengerId))\nhead(submission16)\nwrite_csv(submission16, \"submission16.csv\")\nlength(which(submission15$Survived!=submission16$Survived))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d94d7e440713a1721b0aa9cf4f589b53904a3798"},"cell_type":"markdown","source":"Now let's try using some Xtreme Gradient Boosting (xgboost)."},{"metadata":{"trusted":true,"_uuid":"4e2801d1e3aecdef0907934842ad880dc480f2e9"},"cell_type":"code","source":"#XGBOOST\nlibrary(xgboost)\n\n#Now, prepare our data into a Dmatrix, so we can build an xgboost model on it. All the data needs to be numeric,\n#and we need to remove any fields we're not planning on using. \n\nxgb_train<-train_tree_cabins%>%select(\"Pclass\",\"Age\",\"Sex\", \"Fare\", \"SibSp\", \"Has_cabin\", \"Deck\")\nxgb_train_labels<-train[,\"Survived\"]\n#deck<-model.matrix(~Deck-1,xgb_train)\n\n#Right now, Sex, Has_cabin, and Deck are all factors instead of numbers, but we can easily convert them\nxgb_train<-xgb_train%>%mutate(Is_female = as.numeric(Sex==\"female\"), Has_cabin = as.numeric(Has_cabin)-1, Deck_number = as.numeric(Deck)-1)%>%select(-c(Sex,Deck))\n\n#xgb_train<-cbind(xgb_train, deck)\n\nstr(xgb_train)\nstr(xgb_train_labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6aa964cc88702676800f24958c035a654c809ccd"},"cell_type":"code","source":"#Convert our dataframes to matrices, and then to a DMatrix\nxgb_train_matrix <- data.matrix(xgb_train)\nxgb_train_labels<-data.matrix(xgb_train_labels)\ndtrain<-xgb.DMatrix(data = xgb_train_matrix, label= xgb_train_labels)\n\n#Now build the model\nmodelxgb <- xgboost(data = dtrain, nround = 5, objective = \"binary:logistic\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3b83815a7d73f4e84525939968d21162d54838f"},"cell_type":"code","source":"#Now we prepare the test data the same way, and then make predictions. \nxgb_test<-test_tree_cabins%>%select(\"Pclass\",\"Age\",\"Sex\", \"Fare\", \"SibSp\",\"Has_cabin\",\"Deck\")\n#test_deck<-model.matrix(~Deck-1,xgb_test)\nxgb_test<-xgb_test%>%mutate(Is_female = as.numeric(Sex==\"female\"), Has_cabin = as.numeric(Has_cabin)-1, Deck_number = as.numeric(Deck)-1)%>%select(-c(Sex, Deck))\nxgb_test$Age[which(is.na(xgb_test$Age))]<-mean(xgb_test$Age, na.rm = TRUE)\n#xgb_test<-cbind(xgb_test, test_deck)\nxgb_test_matrix <- data.matrix(xgb_test)\ndtest<-xgb.DMatrix(data = xgb_test_matrix)\n\n#Make predictions\ntest_pred_xgb<-predict(modelxgb, newdata = dtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"259526a415ac74318205f2a8c06a462ee9d2054d"},"cell_type":"code","source":"#Prepare the submission\nsubmission17<-cbind(test[\"PassengerId\"], as.integer(test_pred_xgb>=0.5))\nnames(submission17)[2]<-\"Survived\"\n\nsubmission17<-submission17%>%mutate(PassengerId = as.integer(PassengerId))\nhead(submission17)\nwrite_csv(submission17, \"submission17.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ecedb79fe9828505c96a9b86a31d146f8a4f9929"},"cell_type":"markdown","source":"There's a naive xgboost model. It doesn't do better than the decision tree we came up with before, but there are various ways to try to tune it. Let's try some things."},{"metadata":{"_uuid":"62c624cf7d54e3c8fe0638a3c6ddd2b4326c1279"},"cell_type":"markdown","source":"First, let's split off some of our training data to use in cross-validation. That way we won't have to keep submitting our guesses to see if we're improving, and we'll get some feedback on the mistakes we're making. "},{"metadata":{"trusted":true,"_uuid":"ac8e52a9c663c15b3d3c89ef1394e15003dc9988"},"cell_type":"code","source":"#Randomize a split into a training and crossval set\nset.seed(111)\npermutation<-sample(nrow(train))\nxgb_train_permuted<-xgb_train_matrix[permutation,]\nxgb_train_labels_permuted<-xgb_train_labels[permutation,]\nhead(xgb_train_permuted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97ea6e833ff62e02e8ae3f26304b70bdd5d230e4"},"cell_type":"code","source":"dtrain<-xgb_train_permuted[1:624,]\ndcross<-xgb_train_permuted[625:891,]\ndtrain_labels<-xgb_train_labels_permuted[1:624]\ndcross_labels<-xgb_train_labels_permuted[625:891]\n\ndtrain<-xgb.DMatrix(data = dtrain, label= dtrain_labels)\ndcross<-xgb.DMatrix(data = dcross, label = dcross_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91bad410006f4c94e1f7c60245798e82d9974bbf"},"cell_type":"code","source":"#Now build some models\nnegatives<- sum(dtrain_labels == FALSE)\npositives <- sum(dtrain_labels == TRUE)\n\nmodelxgb_tune1 <- xgboost(data = dtrain, nround = 11, max.depth = 6, early_stopping_rounds = 3,\n                    objective = \"binary:logistic\", \n                    scale_pos_weight = negatives/positives\n                         )\n\n\n#Predict against our crossval set, and see how it does\ncross_pred_tune1<-predict(modelxgb_tune1, newdata = dcross)\nerr <- mean(as.numeric(cross_pred_tune1 > 0.5) != dcross_labels)\nprint(paste(\"test-error=\", err))\nprint(positives)\nprint(negatives)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"025896929b34ee30a5ef997106e6e83664e65395"},"cell_type":"code","source":"xgb.plot.multi.trees(feature_names = names(xgb_train_matrix), model = modelxgb_tune1)\nimportance_matrix <- xgb.importance(names(xgb_train_matrix), model = modelxgb_tune1)\n\nxgb.plot.importance(importance_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"438e4061f817271c67ba041bf860dcd5f222b740"},"cell_type":"code","source":"#Make predictions\ntest_pred_xgb_tune1<-predict(modelxgb_tune1, newdata = dtest)\nsubmission18<-cbind(test[\"PassengerId\"], as.integer(test_pred_xgb_tune1>=0.5))\nnames(submission18)[2]<-\"Survived\"\n\nsubmission18<-submission18%>%mutate(PassengerId = as.integer(PassengerId))\nhead(submission18)\nwrite_csv(submission18, \"submission18.csv\")\n\nwhich(submission15$Survived!=submission18$Survived)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}