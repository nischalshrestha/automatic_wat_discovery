{"cells": [{"cell_type": "markdown", "metadata": {"_uuid": "22bcd62132460d305f07d895ba801986b71e1da6", "_cell_guid": "1e64c6ff-443a-4663-8f01-e8bf95e2e57c"}, "source": ["Hi. this is my first attempt at Kaggle and at running Jupiter NB. \n", "In this file I will attempt multiple methods for data anlysis. this will be incremental work. Have Fun! \n", "\n", "I will use some of the methods covered in [Tidy TitaRnic\n", "](http://www.kaggle.com/headsortails/tidy-titarnic) so have a look there, It Is lovely!"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "086498dad69c0e3ce248d96e53fb676388a8df34", "_cell_guid": "740a38a1-1580-42d3-aad3-6cfbf6bbfe92"}, "outputs": [], "source": ["# activate librarys \n", "#tree making libraries:\n", "library(rpart) \n", "library(party) \n", "library(randomForest)\n", "#SVM:\n", "library(e1071)\n", "#Graphics:\n", "library(ggplot2)\n", "#data manging\n", "#library(dplyr)\n"]}, {"cell_type": "markdown", "metadata": {"_uuid": "c8436dc9dce5006a17b2ccf5dc1a3a29bc97c170", "_cell_guid": "a6fda8eb-0efc-4199-999f-651c393bbf9e"}, "source": ["first step is loading the DATA. I know it may be  a bad habit, but I usually do not use the \"<-\" notation.   "]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "30540951a67dd434092bfa3c0cb3fb18512f2173", "_kg_hide-input": false, "_cell_guid": "2521b38a-8897-4066-ad55-a129d40b018b"}, "outputs": [], "source": ["# get files\n", "train_full = read.csv('../input/train.csv')\n", "test  = read.csv('../input/test.csv')"]}, {"cell_type": "markdown", "metadata": {"_uuid": "c61a407af1441d7123449ad92e562a6c17781d7b", "_cell_guid": "24dd18d8-9323-487f-b19d-b358b99c562a"}, "source": ["next, I belive some exploratory methods are in order. Just to find the hands and legs. "]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "509753cb5030c908aa3e8f6c832617e0e56c6583", "_cell_guid": "e0a887c0-2ad0-4352-8b27-879350104fcd"}, "outputs": [], "source": ["str(train_full)\n", "summary(train_full)\n", "head(train_full)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "086cb665dc7089f4768471b82465cc7896ef9516", "_cell_guid": "aae3594d-1933-4b34-a2a7-e532ac9f5255"}, "source": ["since it is just the beginning  based on the rows above, I need to change some of the variables to be more cooperative.\n", "1. Pclass= needs to be a factor.\n", "2. Cabin= it would be nice to extract both the letter (I think it might represent floors), and the number as two diffrent variables,   include missing. \n", "3. Name= it would be nice to extract the prefix of someone's name and add it as a factor, include missing\n", "4. family= SibSp and Parch are somehow representing family size. i'll add them together\n", "frankly, i don't think i'll use the Ticket information.\n", "\n", "Lets get dirty!"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "dfe611d9b3d7bd72fb08f45542bb6802be484221", "_cell_guid": "f43942da-28ec-4e95-a4a8-b6fe10b8c4b3"}, "outputs": [], "source": ["#1)\n", "train_full$Pclass=factor(train_full$Pclass,labels = c(\"first\",\"second\",\"third\"))\n", "\n", "#2)\n", "#train_full$Cabin\n", "train_full$Cabin_deck=substring(train_full$Cabin, 1, 1)\n", "#this solution works but assumes that if a cell has more than one Cabin_num, the first is the correct one\n", "train_full$Cabin_deck[train_full$Cabin_deck=='']=\"MiSS\"\n", "train_full$Cabin_deck=factor(train_full$Cabin_deck)\n", "\n", "#i have tried:\n", "#train_full$Cabin_num=substring(train_full$Cabin,2,4) but the data is dirty. so i need to tern to REGEX\n", "train_full$Cabin_num=substring(train_full$Cabin, regexpr(\"(\\\\d)+\", train_full$Cabin),regexpr(\"(\\\\d)+\", train_full$Cabin)+2)\n", "#this solution works but assumes that if a cell has more than one Cabin_num, the first is the correct one\n", "train_full$Cabin_num[train_full$Cabin_num=='']=\"-1\" #this changes all the '' cells to -1 char\n", "train_full$Cabin_num=as.numeric(train_full$Cabin_num)  #the coaertion would eliminate any deck letters without numbers turning them to NA\n", "train_full$Cabin_num[!is.finite(train_full$Cabin_num)]=-1 #finaly all NA are turned to -1\n", "\n", "\n", "#3)\n", "train_full$Name=as.character(train_full$Name)\n", "pattern = \"[A-Z][a-z]*\\\\.\" #see credit for the REGEX at the next frame\n", "m = regexpr(pattern, train_full$Name)\n", "train_full$title= regmatches(train_full$Name, m)\n", "train_full$title= factor(train_full$title)\n", "\n", "#4)\n", "train_full$family_size=(train_full$SibSp+train_full$Parch)\n", "\n", "\n", "str(train_full)\n", "head(train_full)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "9b1d2e1e536c204e379257faff52a73f614ccc39", "_cell_guid": "65b6940a-93cf-4abb-a998-f75c6421cb6a"}, "source": ["*the REGEX  was taken from [tidy-titarnic](https://www.kaggle.com/headsortails/tidy-titarnic) which was given there by [nad136](https://www.kaggle.com/nad136)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "e0a2272077f0e5c509ab30ee55dc1b02bda8fe9e", "_cell_guid": "414929f6-b5c4-4830-bb70-63c514b8dca0"}, "source": ["In order to assess the model's improvement as I shell play with it, I need to have some sort of labled data which is diffrent then the training data (on which i optimize the tree). therefore, I make a DEVELOPER set from half the training set."]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "ed69cca65a13497d5ea571c4c1c416cec86593ba", "_cell_guid": "efbac918-ad27-4ae6-a432-2f7bb28bf204"}, "outputs": [], "source": ["DEV_ind=sample(nrow(train_full), floor(nrow(train_full)/2)) # gets indices of half the training data\n", "DEV=train_full[DEV_ind,]\n", "train=train_full[-DEV_ind,]"]}, {"cell_type": "markdown", "metadata": {"_uuid": "8c5135a684ed057d7b2c9a92cb52026a917d46e3", "_cell_guid": "b5b9fe30-953a-4228-91da-828790dcd217"}, "source": ["lets grow a tree!"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "0bec9b0a90b40ea9ac3996e36c51d7101a5f8abd", "_cell_guid": "9215b180-0059-4def-bff1-79ec58340de0"}, "outputs": [], "source": ["#form=formula(response ~ var1 + var2 + var3)\n", "form=formula(Survived ~ Pclass + Sex + Age  + Fare+ Embarked+Cabin_deck+Cabin_num+family_size+title)\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {"_uuid": "c6b493995021b095676935424a27ec01ab5b1822", "_cell_guid": "eae07912-3565-4d7c-9e2c-14bafbbc091e"}, "source": ["in this code, i follow this tree tutorial in  [Quick-R](http://www.statmethods.net/advstats/cart.html)"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "bd0fa8a0fa79090c44768885b28fe764e8b175f4", "_cell_guid": "0d2b3300-62e5-4370-b519-7d70f4e60e79"}, "outputs": [], "source": ["#tree\n", "model = rpart(form, method=\"class\", data=train)\n", "print(model)\n", "plot(model)\n", "text(model)\n", "post(model)\n", "\n", "#library(party)\n", "#party_model=as.party(model)\n", "#plot(party_model)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "728862cd9a6440228ce50b3c94f51063d6461bf6", "_cell_guid": "15352264-b289-4ae6-bbc9-250fc38186fe"}, "source": []}, {"cell_type": "markdown", "metadata": {"_uuid": "484d09d3886716c271cbd4b31ccc34871a8b0981", "_cell_guid": "3ea5e9c1-0c76-484e-8bfc-2b5f49d1429c"}, "source": ["**Gross**! the first tree obviously dosn't work well with factors. \n", "coarcing it to party helps a little thouge, but bugs the kernel. lets try another one with the party library. For what i have read, this already pruns the tree automaticly to reduce overfit: \n", "\n"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "bc2ed7dde4197ba84a79b0c1ee01a8da887bca32", "_cell_guid": "22a0092a-e1b1-4317-b4a0-03142108d9ec"}, "outputs": [], "source": ["model = ctree(form, data=train)\n", "plot(model, main=\"Survival of people on the Titanic\")\n", "print(model)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "4a3d61c71a8c5b73a66d6a4ac3cfcf8ab165f982", "_cell_guid": "b775693f-e824-4dcb-82d4-e9f48b1a1796"}, "source": ["I have to say this doesn't look so good as well (especialy the down bars, I feel so dumb to look at them each time and try to understand what is the prediction based on the graph). luckly I found some better ways to visualise it [Here](https://stats.stackexchange.com/questions/171301/interpreting-ctree-partykit-output-in-r):\n"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "1b363783e8e6da8dd565aabb9ced399a88792b1c", "_cell_guid": "301c398e-f274-4595-8fc6-e02085a2ff3f"}, "outputs": [], "source": ["model = ctree(form, data=train)\n", "library(\"partykit\")\n", "spmodel<-as.simpleparty(model)\n", "print(spmodel)\n", "plot(spmodel)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "fe61604ba0e1433e7b0bbd4f9e4d7a84bed9be35", "_cell_guid": "f41c704d-03ef-4307-a572-c765aaaaa0f2"}, "source": ["If I understand correctly, the fraction below is the probability of someone to live. so basicly, a prediction will be 1 if P>0.5 or Round(P)\n", "\n", "but how to PREDICT? I will try to predict on both the DEV set and the training set,to get the picture of my model working. "]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "cdbfccccb39778eec4cb9008aaa29805215809fb", "_cell_guid": "edfdf6e8-de79-4505-8a49-bc93d7c487e0"}, "outputs": [], "source": ["#Look at: pred=predict(model,DEV) #this line generates a comfidance matrix, each col reperent a cathegorical\n", "tree_pred=predict(model, DEV, type = \"response\") #this line would generate a single variable of the probability P\n", "chose_DEV=(DEV$Survived==round(tree_pred))           #checks fore each cell, if chosen right \n", "true_accuracy=sum(chose_DEV==TRUE)/length(chose_DEV)          #calculates the accuracy\n", "sprintf(\"the true accuracy of the randomly sampled tree on DEV set is: %s\", true_accuracy)\n", "\n", "tree_pred=predict(model, train, type = \"response\") \n", "chose_SELF=(train$Survived==round(tree_pred))  \n", "optimized_accuracy=sum(chose_SELF==TRUE)/length(chose_SELF)\n", "sprintf(\"the optimized accuracy of the randomly sampled tree on trainig set is: %s\", optimized_accuracy)\n"]}, {"cell_type": "markdown", "metadata": {"_uuid": "05dae117bd70df0487faf72827b48f95e6787f08", "_cell_guid": "cfbd400d-fc85-4976-bbee-4cb2175e67ee"}, "source": ["**OH YEAH! **  lets do the random forest!\n", "\n"]}, {"cell_type": "markdown", "metadata": {"_uuid": "74b080a2555193c323dc60c7f56f2badc48fd01f", "_cell_guid": "19cce44b-c6af-443e-956f-10f8dc5dc848"}, "source": ["I have tried to run the following command:"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "e2104ac884051886cd20662d3ce46a0ac706a838", "_cell_guid": "ca076fdb-63e3-46ea-b9f0-86dd9c9791c0"}, "outputs": [], "source": ["# forest_model=randomForest(form, data=train ,importance=TRUE)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "17bac3c2ce94ca586573f4600e71d6c214083b1c", "_cell_guid": "861e40b8-8ead-4ae0-98b5-43d5e34bc4c4"}, "source": ["bat that looks bad. it worked on my computer though. so It seems the large data set DEV contains NA values at some variables and it kills the proccess. I know there may be better options then to remove the missing values, but i'll need to do some homework to find those ways. \n", "\n", "maybe i'll just exclude them"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "b5aa4d8800078a84f04a321f18bac484c2fa8641", "_cell_guid": "809f9226-ea86-4cee-b33e-e3310aff7281"}, "outputs": [], "source": ["forest_model=randomForest(form, data=train ,importance=TRUE,na.action = na.exclude)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "1d23be5d28240f7f1e05f64a18e45adde509f679", "_cell_guid": "8081db65-c2c5-4d9b-b54d-d61aaaee5437"}, "source": ["I'am not so sure now If you ask me, Realy. But i'll do it anyway, thank you."]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "e89d78d4cbf72fe725bfdd46a281c7774d613c67", "_cell_guid": "a15da69b-3fe8-401a-a76f-1efd810b3389"}, "outputs": [], "source": ["forest_pred=predict(forest_model, DEV, type = \"response\")\n", "chose=(DEV$Survived==round(forest_pred))\n", "#chose\n", "accuracy=sum(chose==TRUE)/length(chose)\n", "accuracy\n"]}, {"cell_type": "markdown", "metadata": {"_uuid": "b633e3de640c082eb6cd8fce615175e9181dbf10", "_cell_guid": "1d11ff08-c9ca-4a1c-8c6d-0bc813f4a49c"}, "source": ["...it gets vexing.\n", "reminds me of an old phrase \"you enter Junk you get Junk\" the dirty in the \"Quick an' Dirty\" finaly got me. the problem is that some variables include missing values and it is really bad. Here is a crude test to look for the missing values\n", "\n"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "db8f446ea26301ddd4144b233a1e5447cbd66376", "_cell_guid": "e5bd0f93-85b3-437f-9d28-6354a428bbba"}, "outputs": [], "source": ["sum(is.na(train_full$Survived))\n", "sum(is.na(train_full$Pclass))\n", "sum(is.na(train_full$Sex))\n", "sum(is.na(train_full$Age))\n", "sum(is.na(train_full$Fare))\n", "sum(is.na(train_full$Embarked))\n", "sum(is.na(train_full$Cabin_deck))\n", "sum(is.na(train_full$Cabin_num))\n", "sum(is.na(train_full$family_size))\n", "sum(is.na(train_full$title))"]}, {"cell_type": "markdown", "metadata": {"_uuid": "2746ea6f89924f84dd308e7bd551b76823755e92", "_cell_guid": "6422fd25-664a-4938-a002-36c299ee350a"}, "source": [" am going to recode the missing values in age as an absured number. so hopefully, the information of age and missing age will still  be  used by the classifier. "]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "7bdb5375e4ca262abe834a1c9306cf726b35e6ec", "_cell_guid": "d6e0e4c3-dbba-435e-b4a9-746197f60455"}, "outputs": [], "source": ["DEV$Age[is.na(DEV$Age)]=121\n", "train$Age[is.na(train$Age)]=121\n", "# this is somthing that need to be added for later work\n", "train_full$Age[is.na(train_full$Age)]=121\n", "\n", "sum(is.na(train_full$Survived))\n", "sum(is.na(train_full$Pclass))\n", "sum(is.na(train_full$Sex))\n", "sum(is.na(train_full$Age))\n", "sum(is.na(train_full$Fare))\n", "sum(is.na(train_full$Embarked))\n", "sum(is.na(train_full$Cabin_deck))\n", "sum(is.na(train_full$Cabin_num))\n", "sum(is.na(train_full$family_size))\n", "sum(is.na(train_full$title))\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {"_uuid": "56d7f9bbd54d7a081c48f4955fd5e8f8eae5856e", "_cell_guid": "547c7e94-f468-4d11-bd15-f9484f3f0432"}, "source": ["Ok- NA are eliminated. lets roll!"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "4d3219fecf84e6bb2d0de5ed3992c6f5bda6cb23", "_cell_guid": "1f270005-06a5-4975-8de7-0d6b110ca252"}, "outputs": [], "source": ["forest_model=randomForest(form, data=train ,importance=TRUE) #no NA to remove haha\n", "\n", "forest_pred=predict(forest_model, DEV, type = \"response\") #this line would generate a single variable of the probability P\n", "chose_DEV=(DEV$Survived==round(forest_pred))           #checks fore each cell, if chosen right \n", "true_accuracy=sum(chose_DEV==TRUE)/length(chose_DEV)          #calculates the accuracy\n", "sprintf(\"the true accuracy of the random forest on DEV set is: %s\", true_accuracy)\n", "\n", "forest_pred=predict(forest_model, train, type = \"response\") \n", "chose_SELF=(train$Survived==round(forest_pred))  \n", "optimized_accuracy=sum(chose_SELF==TRUE)/length(chose_SELF)\n", "sprintf(\"the optimized accuracy of the random forest on training set is: %s\", optimized_accuracy)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "fa1ed0c3e61417a9203676db3ad3e305d048474c", "_cell_guid": "eda67383-0ceb-4c08-ba45-49e460a352f7"}, "source": ["**LOOKS GOOD :) ** what are the most important factors? it seems there is over fiting and this issue might get solved by adding extra training examples."]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "2e46387815ffb83cc8f5b1941fa47672cdcc8d23", "_cell_guid": "5d009c88-5a6a-4de9-9d80-710da14b2120"}, "outputs": [], "source": ["\n", "imp=importance(forest_model,type=1)\n", "imp"]}, {"cell_type": "markdown", "metadata": {"_uuid": "6613d029f9706d702c388ea8903a2338ae6064f3", "_cell_guid": "a17f910b-62b6-4442-a4a6-8df0527ddefb"}, "source": ["sudenly I have noticed that running all the fanctions again (this selects diffrent groups for training and dev sets) might result in better performance of the model. I wonder if I will re-train the model many times (on the training set) and keep only the model with the highest accuracy  (on the DEV set), will it preform better on the test set? I have to keep re-splitting both the training and the DEV sets many times so that on every iteration I would get diffrent samples. \n", "\n", "would re-splitting the data  to the train and dev sets be a good idea? i don't know. maybe the model will optimize to a given set that will not be appropriate to the test set. \n", "\n", "the metrics of a good model will be:\n", "1. required metric: training accuracy>0.9 ( a good fit to the training)\n", "2. optimized metric: highest true accuracy I can get on DEV set.>>      ( new model accuracy> old model accuracy)\n"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "b4b2f2d8150e375006bfa272cfd1156c70ff4064", "_cell_guid": "e44b90e3-bf41-4842-9736-af3878e187d1"}, "outputs": [], "source": ["form=formula(Survived ~ Pclass + Sex + Age  + Fare+ Embarked+Cabin_deck+Cabin_num+family_size+title)\n", "\n", "\n", "best_true=true_accuracy\n", "best_model=forest_model\n", "iter_n=10\n", "\n", "for (i in 1:iter_n){\n", "    #resplit the training data\n", "    DEV_ind=sample(nrow(train_full), floor(nrow(train_full)/2)) # gets indices of half the training data\n", "    DEV=train_full[DEV_ind,]\n", "    train=train_full[-DEV_ind,]\n", "    \n", "    forest_model=randomForest(form, data=train ,importance=FALSE) #no NA to remove haha\n", "\n", "    forest_pred=predict(forest_model, DEV, type = \"response\") #this line would generate a single variable of the probability P\n", "    chose_DEV=(DEV$Survived==round(forest_pred))           #checks fore each cell, if chosen right \n", "    true_accuracy=sum(chose_DEV==TRUE)/length(chose_DEV)          #calculates the accuracy\n", "    \n", "    forest_pred=predict(forest_model, train, type = \"response\") \n", "    chose_SELF=(train$Survived==round(forest_pred))  \n", "    train_accuracy=sum(chose_SELF==TRUE)/length(chose_SELF)\n", "       \n", "    if (train_accuracy>=0.9){\n", "        if (true_accuracy>best_true){\n", "           best_model=forest_model\n", "           best_true=true_accuracy\n", "           best_train=train_accuracy \n", "\n", "        }\n", "    }\n", "    else{\n", "        next\n", "    }\n", "    \n", "}\n", "sprintf(\"found a better model! with training accuracy: %s\", best_train)\n", "sprintf(\"and true accuracy: %s\", best_true)\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {"_uuid": "0cc8744554d5889daaa40181c94f69901de7e870", "_cell_guid": "7c46f838-b0d6-4316-a25d-2383d4e65fb9"}, "source": ["I wander if it was a good idea. any comments on that folks would be appriciated. \n"]}, {"cell_type": "markdown", "metadata": {"_uuid": "6a3612e542255ac3a3de363316e1fcf4feba560e", "_cell_guid": "4b074c12-1feb-4089-ba84-56e01ee2c7ab"}, "source": ["OK. for the last part, all I need to do is to :\n", "1. rearrange the test file so to include all the variables I have included and computed\n", "2. make a prediction besed on the optimized tree I found earlier\n", "3. compute a new Survived variable,based on the prediction, and bind it. \n", "4. submit"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "50119423da4d3dece81bbebe80ee6f3830f2a77f", "_cell_guid": "7fd4a3a3-1d4a-4889-9f9e-d5596f3836e2"}, "outputs": [], "source": ["#1. rearrange the test file so to include all the variables I have included and computed\n", "\n", "#1)\n", "test$Pclass=factor(test$Pclass,labels = c(\"first\",\"second\",\"third\"))\n", "\n", "#2)\n", "test$Cabin_deck=substring(test$Cabin, 1, 1)\n", "test$Cabin_deck[test$Cabin_deck=='']=\"MiSS\"\n", "test$Cabin_deck=factor(test$Cabin_deck)\n", "\n", "test$Cabin_num=substring(test$Cabin, regexpr(\"(\\\\d)+\", test$Cabin),regexpr(\"(\\\\d)+\", test$Cabin)+2)\n", "test$Cabin_num[test$Cabin_num=='']=\"-1\" #this changes all the '' cells to -1 char\n", "test$Cabin_num=as.numeric(test$Cabin_num)  #the coaertion would eliminate any deck letters without numbers turning them to NA\n", "test$Cabin_num[!is.finite(test$Cabin_num)]=-1 #finaly all NA are turned to -1\n", "\n", "\n", "#3)\n", "test$Name=as.character(test$Name)\n", "pattern = \"[A-Z][a-z]*\\\\.\" #see credit for the REGEX at the next frame\n", "m = regexpr(pattern, test$Name)\n", "test$title= regmatches(test$Name, m)\n", "test$title= factor(test$title)\n", "\n", "#4)\n", "test$family_size=(test$SibSp+test$Parch)\n", "\n", "#5)\n", "test$Age[is.na(test$Age)]=121\n", "\n", "\n", "\n", "head(test,10)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "7f1e7549a7eecb55d60b5da9c31de8ea11f8b182", "_cell_guid": "201e260b-1678-4d8b-96e3-39ee86cc7b37"}, "source": ["I Have tried to run the following block:"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "92482e6408f1bdd066cddc1b5b058811947d7bca", "_cell_guid": "f0ca2f60-42a1-4608-bbba-13f8bf78b94c"}, "outputs": [], "source": ["#forest_pred=predict(forest_model, test, type = \"response\")"]}, {"cell_type": "markdown", "metadata": {"_uuid": "f2fbcbbd038b238d3730e5fe492d4813aeff480d", "_cell_guid": "6cc21972-d043-438e-9136-d5b6a79722f5"}, "source": ["but there is problem in \"predict\"  found why this happens [here](https://discuss.analyticsvidhya.com/t/error-in-predict-randomforest-fit-test-type-of-predictors-in-new-data-do-not-match-that-of-the-training-data/3268).  it seems that there are diffrences in the levels of the factors between the training and the test sets.\n"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "f824d5b87e74825c1a80f679a561a1a5cdf50ed7", "_cell_guid": "4ee1e811-5522-43ca-879f-7cf99b07553b"}, "outputs": [], "source": ["#crudly check what are the levels of both variables. got any nicer way to do it?\n", "levels(test$Pclass)\n", "levels(train$Pclass)\n", "levels(test$Sex)\n", "levels(train$Sex)\n", "levels(test$Embarked)\n", "levels(train$Embarked)\n", "levels(test$Cabin_deck)\n", "levels(train$Cabin_deck)\n", "levels(test$title)\n", "levels(train$title)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "c6fd60d10cb181569761e4bb216f36a390046024", "_cell_guid": "76a22548-60b1-46aa-9807-ebd89e5c05df"}, "source": ["This is ought to do the trick [this was copied from here](https://discuss.analyticsvidhya.com/t/error-in-predict-randomforest-fit-test-type-of-predictors-in-new-data-do-not-match-that-of-the-training-data/3268):"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "360437081d4534b457170fc63b1355f3a79ba415", "_cell_guid": "a7117094-5101-4420-9d65-ebcf5ccb0e2e"}, "outputs": [], "source": ["levels(test$Embarked) = levels(train$Embarked)\n", "levels(test$Cabin_deck) = levels(train$Cabin_deck)\n", "levels(test$title) = levels(train$title)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "ad46923002ef3301fec6b0b2f07fc748d5c65f60", "_cell_guid": "4eec3cb9-221c-4e62-93d2-4a118306ca08"}, "source": ["lets hope it would work"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_kg_hide-output": false, "_uuid": "4d9b624cb2d1b7be438a7cd1b1413bf2608e26f4", "_cell_guid": "76d17264-16d4-49e4-b6ec-93179d8f8f6c"}, "outputs": [], "source": ["#form=formula(Survived ~ Pclass + Sex + Age  + Fare+ Embarked+Cabin_deck+Cabin_num+family_size+title)\n", "#forest_model=randomForest(form, data=train_full ,importance=TRUE)\n", "\n", "#2. make a prediction besed on the optimized tree I found earlier\n", "forest_pred=predict(best_model, test, type = \"response\")\n", "\n", "#3. compute a new Survived variable,based on the prediction, and bind it. \n", "Survived=round(forest_pred)\n", "test=cbind(test,Survived)\n", "\n", "submission=cbind(test$PassengerId,Survived)\n", "head(submission)\n", "#4. submit.\n", "write.csv(submission, file ='sub.csv', row.names = F)\n"]}, {"cell_type": "markdown", "metadata": {"_uuid": "5ec6f1e359483cad98573d32dd96038807ea9016", "_cell_guid": "d5ae3d6f-e54c-41d1-ab23-7a46e1ed7d85"}, "source": ["**AND WE ARE DONE :)**"]}], "nbformat": 4, "metadata": {"kernelspec": {"name": "ir", "display_name": "R", "language": "R"}, "language_info": {"name": "R", "file_extension": ".r", "mimetype": "text/x-r-source", "codemirror_mode": "r", "version": "3.4.2", "pygments_lexer": "r"}}, "nbformat_minor": 1}