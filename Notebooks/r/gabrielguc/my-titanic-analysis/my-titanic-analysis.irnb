{"nbformat_minor": 1, "metadata": {"language_info": {"name": "R", "file_extension": ".r", "mimetype": "text/x-r-source", "pygments_lexer": "r", "codemirror_mode": "r", "version": "3.4.2"}, "kernelspec": {"name": "ir", "display_name": "R", "language": "R"}}, "cells": [{"cell_type": "markdown", "metadata": {"_cell_guid": "91dd0ff5-3c4a-4293-8ed1-654b31aa6328", "_uuid": "7ebb7003c3cfb67e1d017c2516e6642de86753e9"}, "source": ["# Introduction\n", "This notebook will explore different approaches to analyze the Titanic Challenge. The aim is to give some examples of possible solutions on R programming, without reaching a fine tunning of each model.\n", "The outline of this kernel will be structured as follows:\n", "1.  Loading data\n", "1.  Preparing and exploring data\n", "1.  Bayesian approach\n", "1.  Logit regression approach (binomial)\n", "1.  Neural Network approach \n"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "68009fe2-bdad-48c1-90a6-eee4ff160743", "_uuid": "351e5f9dde675e5d140c4c8af399f57081cb42ad"}, "source": ["# This R environment comes with all of CRAN preinstalled, as well as many other helpful packages\n", "# The environment is defined by the kaggle/rstats docker image: https://github.com/kaggle/docker-rstats\n", "# For example, here's several helpful packages to load in \n", "library(ggplot2) # Data visualization\n", "library(readr) # CSV file I/O, e.g. the read_csv function\n", "library(e1071) # For Bayesian approach"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "d4a995d0-25f9-46be-9675-c26228451b4b", "_uuid": "7477402dd1a7f9c7e3660d0be94e3801a3c43151"}, "source": ["# 1. Loading data\n", "Firstly, we will load the training dataset (891 registers) with the function *read.csv*. I have used one of the options available to assign a NA value to empty attributes."]}, {"execution_count": null, "cell_type": "code", "metadata": {"_kg_hide-output": false, "_cell_guid": "27c370a7-3113-47f5-aeab-88541a287595", "_uuid": "f248b974d5529fdeae8df13087322d0c9672cd53"}, "source": ["raw_train <- read.csv(file=\"../input/train.csv\", header=TRUE, sep=\",\", na.strings=c(\"\")) #891 reg"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "8783c59b-03bf-46c0-a3a8-0fa86f177d5d", "_uuid": "fe9005c9ce4baebd814e9785a62308a08f07da02"}, "source": ["# 2. Preparing and exploring data\n", "In the next cells, it has been done a exploratory analysis to prepare data for the applying model."]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "5b197010-403d-4efb-95ab-6b3713636859", "_uuid": "fde10debe8638dd3e598a8092cfa45e9172daea0"}, "source": ["# Number of NAs for each attribute:\n", "sapply(raw_train,function(x) sum(is.na(x)))"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "db707f91-3a38-4ec0-88db-baa71f6ce690", "_uuid": "fa20855523572e122c9298d59158311914e947e3"}, "source": ["A optional (quick) treatment here is to assign the average to Age attribute where we find a NA value, and to assign the mode value for example to the Embarked missing values. These both treatments, as a I tested, will not lead to a better performance of the model.."]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "13e0b61e-eef3-4466-bcf2-d961cbe0352e", "_uuid": "c8c697fd91fb4bb28d4aacc1777d378cdaebaeb5"}, "source": ["# Function to calculate the mode of a distribution\n", "moda <- function(x) {\n", "  tab <- table(x)\n", "  return(names(tab[which.max(tab)]))\n", "}"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "fb153b4f-0d78-4d1d-8f4b-5cc678416585", "_uuid": "e77f6827486e8d79d4b4491a2ab2d131bc42e22b"}, "source": ["# Assign the average of the Age attribute:\n", "raw_train$Age[is.na(raw_train$Age)] <- mean(raw_train$Age,na.rm=T)\n", "\n", "# Assign the mode of the Embarked attribute:\n", "moda_embarked <- moda(raw_train$Embarked[!is.na(raw_train$Embarked)])\n", "raw_train$Embarked[is.na(raw_train$Embarked)] <- moda_embarked\n", "train_nb <- raw_train\n", "train_glm <- raw_train"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "6b9ef516-838c-4889-8ee7-0ae5f7bcab72", "_uuid": "b725533378a60820e1b93f50a8908bd002994581"}, "source": ["# Another option would be to remove the NA values:\n", "# train_nb <- raw_train[!is.na(raw_train$Age), ]"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "e0cd68a4-9e43-498d-bdd1-09df592e9892", "_uuid": "575b66d1319d299e5ac3a8c04f501fa996c22abe"}, "source": ["# 3. Bayesian Approach\n", "To apply a Naive Bayes model, it is necessary to assign a discrete value for each value of every feature. This Naive Bayes model does not work well with continuous variables as the Age."]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "3204c5ca-b686-462a-91f9-d53a50cf8d3e", "_uuid": "ba7bd662f266878892dcfc16caba3ed1b398cb28"}, "source": ["# Age Histogram, and the mean marked with red-dashed line.\n", "ggplot(train_nb, aes(x=Age)) +\n", "    geom_histogram(binwidth=5, colour=\"black\", fill=\"white\") +\n", "    geom_vline(aes(xintercept=mean(Age, na.rm=T)),   # Ignore NA values for mean\n", "               color=\"red\", linetype=\"dashed\", size=1)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "d8e08d8c-76f7-472d-8bdd-91f99202c23f", "_uuid": "43b1ecc52a8ada49dfd0d4b6f2abca0af134ce02"}, "source": ["# Generating a new variable discretizing the Age:\n", "train_nb$AgeTramo <- cut(train_nb$Age, breaks = seq(0,80,5))\n", "\n", "#Assigning factors to discrete variables, including de label feature (Survived):\n", "train_nb$Pclass_f <- factor(train_nb$Pclass)\n", "train_nb$SibSp_f <- factor(train_nb$SibSp)\n", "train_nb$Parch_f <- factor(train_nb$Parch)\n", "train_nb$Survived_f <- factor(train_nb$Survived)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "3da0c803-b7f7-4820-bf87-f19b029e63d7", "_uuid": "8e994225df7a17405cf3926c3689d69b7e263b2e"}, "source": ["clasificador <- naiveBayes(Survived_f ~ Pclass_f + Sex + AgeTramo + SibSp_f + Parch_f + Embarked,\n", "                            data=train_nb)\n", "train_nb_features <- train_nb[ , c(\"Pclass_f\", \"Sex\", \"AgeTramo\", \"SibSp_f\", \"Parch_f\", \"Embarked\")]\n", "predicted_train_nb<-predict(clasificador, train_nb_features)\n", "matrizconf<-table(predicted_train_nb, train_nb$Survived_f)\n", "#Resultados\n", "matrizconf\n", "sum(diag(matrizconf))/sum(matrizconf)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "642fa9f5-ca77-488c-a818-0c86ab5bb423", "_uuid": "2ee8f9cb3a708087aa4db5543d1f281ffebe179c"}, "source": ["### Accuracy for Naive Bayes predictor: 79,5%"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "55c0a9cf-543f-46b4-9443-b52061010bbd", "_uuid": "9b230c68734dfd6162c5711963aeaa60ee0d39e9"}, "source": ["# 4. Logit regression approach (binomial)\n", "Here, we will repeat the loading and preparing stage (removing NAs values for Age attribute). After the function call to apply de binomial regression is *glm*. In this case, the features need not be discretized. One important issue to take care is the threshold used to separate the positive and negative predictions."]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "9cb94cfb-f0cd-4792-9ffd-792b41bb3f2a", "_uuid": "f92c6cc85ac1281a7393dc6868b268f6f079176f"}, "source": ["raw_train <- read.csv(file=\"../input/train.csv\", header=TRUE, sep=\",\", na.strings=c(\"\")) # 891 reg\n", "train_glm <- raw_train[!is.na(raw_train$Age), ] # 712 reg"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "b8c73633-6f72-4b5d-9742-9a50c82a07b7", "_uuid": "6d4acb5efbb9995edb991f320ae33b57d263124d"}, "source": ["# Applying GLM regression model with the binomial family:\n", "clasificador_glm <- glm(formula = Survived ~ Pclass + Sex + Age + SibSp + Parch + Embarked + Fare,\n", "                        data = train_glm,\n", "                        family=binomial())\n", "summary(clasificador_glm) #output\n", "train_glm_features <- train_glm[ , c(\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Embarked\", \"Fare\")]\n", "predicted_train_glm <- predict(clasificador_glm, newdata=train_glm_features)\n", "\n", "# Segmentation of the positive and negative predictions.\n", "predicted_train_glm_bin <- ifelse(predicted_train_glm < 0.5, 0, 1)\n", "# Confusion matrix to calculate the accuracy of the model:\n", "matrizconf<-table(predicted_train_glm_bin, train_glm$Survived)\n", "matrizconf\n", "sum(diag(matrizconf))/sum(matrizconf)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "933eb05b-8730-4ce3-838b-857d9faeabf4", "_uuid": "e6c0067497e70b42120aa79ed9c47764aaff95e2"}, "source": ["### Accuracy for Logit (binomial) predictor: 81%"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "82f4a37d-62b3-40e3-b8a9-d9b9cf17328e", "_uuid": "e4cdc7c825d15089812b166c5a234d08db322eff"}, "source": ["# 5. Neural Network approach\n", "In this point, it will be used a Multi-Layered Perceptron neural network for binary classification. I will repeat a similar data preprocessing as before examples."]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "916ac67c-671e-4d32-9057-6baef0c869e4", "_uuid": "15a3a3f1888e5ca2d73bbce98ba978d656457d2c"}, "source": ["library(keras) # For Neural Network deployment"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "9fb5a18a-1b2c-4206-9f56-8888040d691c", "_uuid": "57319e159293e022730faf82b5b3ea4976a1fea1"}, "source": ["raw_train <- read.csv(file=\"../input/train.csv\", header=TRUE, sep=\",\", na.strings=c(\"\")) #891 reg\n", "raw_train <- raw_train[!is.na(raw_train$Age), ] # 714 reg\n", "raw_train <- raw_train[!is.na(raw_train$Embarked), ] # 712 reg"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "a0e97113-5326-4bcf-8fac-30a23638b895", "_uuid": "f73783bd604784a96396cafca9a1468cc10f44da"}, "source": ["It is importante to note that for this neural network approach, it is necessary to transform all categorical data to numeric data, and to rescale the values between 0 and 1."]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "7f8fbf0e-20f1-4bb6-b41f-d800a215b2fd", "_uuid": "f80d534a8bfa8ad130d2187e50fb9436e4090113"}, "source": ["# Transform categorical variables to numeric\n", "raw_train$NumSex <- as.numeric(factor(raw_train$Sex,labels=c(1,2)))\n", "raw_train$NumEmbarked <- as.numeric(factor(raw_train$Embarked,labels=c(1,2,3)))\n", "\n", "# Generate the feature matrix and the label vector:\n", "train_nn <- raw_train[ , c(\"Pclass\", \"NumSex\", \"Age\", \"SibSp\", \"Parch\", \"NumEmbarked\", \"Fare\")]\n", "label_nn <- raw_train$Survived\n", "\n", "# Rescale the values:\n", "train_nn$Pclass <-  (train_nn$Pclass - min(train_nn$Pclass)) /\n", "                    (max(train_nn$Pclass) - min(train_nn$Pclass))\n", "train_nn$NumSex <-  (train_nn$NumSex - min(train_nn$NumSex)) /\n", "                    (max(train_nn$NumSex) - min(train_nn$NumSex))\n", "train_nn$Age <-  (train_nn$Age - min(train_nn$Age)) /\n", "                    (max(train_nn$Age) - min(train_nn$Age))\n", "train_nn$SibSp <-  (train_nn$SibSp - min(train_nn$SibSp)) /\n", "                    (max(train_nn$SibSp) - min(train_nn$SibSp))\n", "train_nn$Parch <-  (train_nn$Parch - min(train_nn$Parch)) /\n", "                    (max(train_nn$Parch) - min(train_nn$Parch))\n", "train_nn$NumEmbarked <-  (train_nn$NumEmbarked - min(train_nn$NumEmbarked)) /\n", "                    (max(train_nn$NumEmbarked) - min(train_nn$NumEmbarked))\n", "train_nn$Fare <-  (train_nn$Fare - min(train_nn$Fare)) /\n", "                    (max(train_nn$Fare) - min(train_nn$Fare))\n", "\n", "# Convert dataframe to numeric matrix:\n", "colnames(train_nn)=NULL\n", "for (i in 1:7){train_nn[,i]=as.numeric(train_nn[,i])}\n", "train_nn=as.matrix(train_nn)\n", "label_nn=as.matrix(label_nn)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "b4cd1a4d-c9ce-4c03-b918-e444ed5d77fc", "_uuid": "762c67453f5a9e879a5713a6a919587be312a11e"}, "source": ["Now it is the time to generate the MLP for binary classification with the following code:"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "19907110-b09b-4d90-9d5a-b28525ac3a03", "_uuid": "bed379679137cb11d11e914ce34ee0f8142991c3"}, "source": ["set.seed(300)\n", "model <- keras_model_sequential() \n", "\n", "model %>% \n", "  layer_dense(units = 256, activation = 'relu', input_shape = dim(train_nn)[2]) %>% \n", "  layer_dropout(rate = 0.5) %>% \n", "  layer_dense(units = 256, activation = 'relu') %>%\n", "  layer_dropout(rate = 0.5) %>%\n", "  layer_dense(units = 1, activation = 'sigmoid')\n", "\n", "model %>% compile(\n", "  loss = 'binary_crossentropy',\n", "  optimizer = optimizer_rmsprop(),\n", "  metrics = c('accuracy')\n", ")\n", "\n", "history <- model %>% fit(\n", "  train_nn,label_nn,\n", "  epochs = 70, batch_size = 128\n", ")"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "d7fe1fa7-e5c1-435e-8601-0c62e73efa37", "_uuid": "af0d16b792bf5ab70ac88c1f599b6e6e5722c270"}, "source": ["plot(history)\n", "eval <- model %>% evaluate(train_nn, label_nn)\n", "eval"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "cd1f0b3d-7cc6-46aa-91e3-c7dec03a554c", "_uuid": "40f91780fac42934c3c7dfc5c53b1033a8231251"}, "source": ["### Accuracy for MLP binary classificator: 83,6%"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "42c154c9-f17c-4a18-a97c-7fe189f5e770", "_uuid": "c07624c9f0d0b1fa262518f58c8d363e5739e8ae"}, "source": [], "outputs": []}], "nbformat": 4}