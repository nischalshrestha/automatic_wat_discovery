{"cells":[{"metadata":{"_execution_state":"idle","_uuid":"031746cb65355422729de33b968706abee36eec6","trusted":false,"_cell_guid":"46a78b75-5c27-4d52-b69f-9da17945659d"},"cell_type":"code","source":"---\ntitle: \"Titanic: Ridge Implementation\"\nauthor: \"SKD\"\ndate: \"Friday, August 20, 2017\"\noutput: \n  html_document:\n    number_sections: false\n    toc: true\n    fig_width: 7\n    fg_height: 4.5\n    theme: cerulean\n    highlight: tango       \n---\n\n<style type = \"text/css\">\nbody{ /* Normal */\n  font-size: 14px;\n}\nh1{ /* Header 1 */\n  font-size: 24px;\n}\nh2{ /* Header 2 */\n  font-size: 20px;\n}\nh3{ /* Header 3 */\n  font-size: 16px;\n}\ncode.r{ /* Code Block */\n  font-size: 12px;\n}\npre{ /* Code Block */\n  font-size: 12px;\n}\n</style>\n\n# Introduction\n\nThis is an attempt at predicting survivors in the Titanic dataset, using lasso and ridge regression methods, specifically glmnet package in R. Since an early exploration of data divulges huge disparity in survival ratio between men and women, separate predictive models were trained for both. As many observations had their Age variable missing, the Multiple Imputation by Chained Equations (MICE) package has been used for imputing missing age.\n\nModels trained using ridge regression on male and lasso on female datasets yielded an accuracy of 0.81818 on public leaderboard. Interestingly, although lasso model on female dataset had marginally better misclassification error, performance on leaderboard improved on using ridge model. Furthermore, classifying the ladies above 14.5 years as 'Ms' after imputing the Age led to improved performance of 0.82297 on the public leaderboard.\n\nSince male model's prediction of survivors on the training and held-out test set was not good, it needs to be further explored using other algorithms.\n\n## Load data\n\n```{r}\ntitanic.train <- read.csv(\"../input/train.csv\", stringsAsFactor=FALSE)\ntitanic.test <- read.csv(\"../input/test.csv\", stringsAsFactor=FALSE)\n\n```\n\n## Load R library\n\n```{r,message=F,warning=FALSE}\nlibrary(plyr)\nlibrary(rpart)\nlibrary(caret)\nlibrary(caTools)\nlibrary(mice)\nlibrary(stringr)\nlibrary(Hmisc)\nlibrary(ggplot2)\nlibrary(vcd)\nlibrary(ROCR)\nlibrary(pROC)\nlibrary(VIM)\nlibrary(glmnet)    \n```\n\n\n# Exploratory Data Analysis\n\nFirst a quick peak into the dataset. \n\n```{r}\nstr(titanic.train)\nsummary(titanic.train)\ntable(titanic.train$Survived, titanic.train$Sex)\n```\n\nThere are 891 passangers in the training data, comprising of 314 female and 577 male passengers, out of which 233 females and 109 males survived the disaster. The dataset provides information about each passenger's name, age, gender, their port of embarkation, which cabin they booked, their ticket number and fare they paid along with number of family members they were travelling with.\n\nFirst step would be to check if these variables have any correlation with the response variable Survived. In the dataset provided, some of the data like Age, Cabin etc. are missing. They will be ignored for preliminary exploration of the data. \n\n## Did age influence survival?\n\nA scatter plot of age of each passenger, incorporating the information if the passenger <span style = \"color:#FF0000\">perished</span> or <span style = \"color:#0000FF\">survived</span> the disaster, show that while most of the casualty were male, those below the age of 15 years seem to have more or less same survival rate as females within that age group. Also, females above 50 seem to have better survival rate, while males above 50 are worse off than their middle-aged counterparts within their own gender groups.\n\n```{r, warning=FALSE,fig.height=3,fig.width=7}\nggplot(titanic.train, aes(x=Age, y=PassengerId, color = as.factor(Survived))) +                      \n    geom_point() + \n    facet_grid(Sex ~.) +\n    ggtitle(\"Survival vs Passenger's Age\")+\n    xlab(\"Age\") + \n    theme(legend.position = \"none\")+\n    scale_colour_manual(values = c(\"#FF0000\",\"#0000FF\"))\n```\n\nThis information can be used later while creating new features based on age.\n\n## Is survival of a passenger related to his/her Pclass and port of embarkation?\n\nSince passengers travelled in different classes, it would be worthwhile to check if there exists any correlation between his/her class of travel, from whence he/she boarded and whether they finally <span style = \"color:#FF0000\">perished</span> or <span style = \"color:#0000FF\">survived.\n\n```{r, warning=FALSE,fig.height=3,fig.width=7}\nggplot(titanic.train[titanic.train$Embarked != \"\",], aes(x=Embarked, y=PassengerId)) +  \n  geom_tile(aes(fill = as.factor(Survived))) + \n  facet_grid(. ~ Pclass) +\n  ggtitle(\"Survival vs Passenger's Pclass and Port of Embarkation\")+\n  theme(legend.position = \"none\")+\n  scale_fill_manual(values = c(\"#FF0000\",\"#0000FF\"))\n```\n\nMost of the passengers who perished had embarked from port 'S' and were travelling 3rd class.\n\n```{r, warning=FALSE,fig.height=3,fig.width=7}\nggplot(titanic.train[titanic.train$Embarked != \"\",], aes(x=Embarked, y=PassengerId)) +  \n  geom_tile(aes(fill = as.factor(Survived))) + \n  facet_grid(. ~ Sex) +\n  ggtitle(\"Survival vs Passenger's Sex and Port of Embarkation\")+\n  theme(legend.position = \"none\")+\n  scale_fill_manual(values = c(\"#FF0000\",\"#0000FF\"))\n```\n\nLooks like most of the unfortunate passengers from port 'S' travelling 3rd class were male, while most of the casualty among females also happened among passengers from the port 'S'.\n\n## Did travelling with the family mattered?\n\nThe vcd package, which provides a variety of methods for visualizing multivariate categorical data, has been used here to look at possible correlation between survival of a passengers based on their gender, age and number of family member accompanying them.\n\n```{r}\nmosaic(~ Sex + (Age > 15) + (SibSp + Parch > 0) + Survived, data = titanic.train[complete.cases(titanic.train),],\n       shade=T, legend=T)\n```\n\nPearson residuals of 2 and higher suggest inter-dependece between the variables under consideration.\n\nFinally, a combined dataframe of training and test data is created, with 'Survived' feature removed from the train dataset and saved separately. This will be added back to the train dataset after further processing of the combined data set.\n \n```{r}\nSurvived = titanic.train$Survived\ntitanic.test$Survived = NA\nall = rbind(titanic.train, titanic.test)\n```\n\n# Feature engineering\n\n## Title \n\nNames of the passengers consist of titles ascribed to each individual as per their gender, age and social status, which can be extracted and maximum and minimum age for each category can be enumerated.\n\n```{r}\nall$Title = sapply(all$Name,function(x) strsplit(x,', ')[[1]][2])\nall$Title = sapply(all$Title,function(x) strsplit(x,'\\\\. ')[[1]][1])\n\nas.data.frame(\n  cbind(\"Title\" = unique(all$Title), \n        \"No_of_passengers\" = sapply(unique(all$Title), function(x) nrow(all[all$Title == x,])),\n        \"Age_missing\" = sapply(unique(all$Title), function(x) nrow(all[all$Title == x & is.na(all$Age),])),\n        \"Minimum_Age\" = sapply(unique(all$Title), function(x) min(all[all$Title == x,'Age'], na.rm = TRUE)),\n        \"Maximum_Age\" = sapply(unique(all$Title), function(x) max(all[all$Title == x,'Age'], na.rm = TRUE))), row.names = F)\n```\n\n\nThese 18 categories can be combined into more manageable 5 categories as per their gender and age:\n```{r}\n#   Mr:     For men above 14.5 years\n#   Master: For boys below and equal to 14.5 years\n#   Miss:   For girls below and equal to 14.5 years\n#   Ms:     For women above 14.5 years, maybe unmarried\n#   Mrs:    For married women above 14.5 years\n```\n\nAll those who do not have missing age can be put into appropriate Title category on the basis of their age and gender as follows:\n\n```{r}\n\nall[(all$Title == \"Mr\" & all$Age <= 14.5 & !is.na(all$Age)),]$Title = \"Master\"\n\nall[all$Title == \"Capt\"|\n    all$Title == \"Col\"|\n    all$Title == \"Don\"|\n    all$Title == \"Major\"|\n    all$Title == \"Rev\"|      \n    all$Title == \"Jonkheer\"|\n    all$Title == \"Sir\",]$Title = \"Mr\"\n\n# None of these women are travelling with family, hence can be categorised as single women for this analysis\nall[all$Title == \"Dona\"|\n      all$Title == \"Mlle\"|\n      all$Title == \"Mme\",]$Title = \"Ms\"\n\n# Categories Lady and Countess as a married woman\nall[all$Title == \"Lady\"| all$Title == \"the Countess\",]$Title = \"Mrs\"\n\n# Categorise doctors as per their sex\nall[all$Title == \"Dr\" & all$Sex == \"female\",]$Title = \"Ms\"\nall[all$Title == \"Dr\" & all$Sex == \"male\",]$Title = \"Mr\"\n\n```\nAll the titles have been successfully categorised into five defined categories excepting for observations in category Miss. Since Age feature is missing for these observations, they will be handled after imputing the missing age. Also, there is one women who is below 14.5 years of age and is married and hence has title Mrs, which is ignored.\n\n\n```{r}\nall$Title = as.factor(all$Title)\nall$Title <- droplevels(all$Title)\nsummary(all$Title)\n```\n\n\n## FamilySize\n\nFamilySize is created based on the number of family member travelling with a passenger.\n \n```{r}\nall$FamilySize = ifelse(all$SibSp + all$Parch + 1 <= 3, 1,0) # Small = 1, Big = 0\n```\n\n## Mother\nIdentify the ladies travelling with their children.\n\n```{r}\nall$Mother = ifelse(all$Title==\"Mrs\" & all$Parch > 0, 1,0)\n```\n\n## Single\n\nIdentify people travelling solo.\n```{r}\nall$Single = ifelse(all$SibSp + all$Parch + 1 == 1, 1,0) # People travelling alone\n```\n\n## FamilyName\n\nFamily name of each individual can be extracted from their names.\n```{r}\nall$FamilyName = sapply(all$Name,function(x) strsplit(x,', ')[[1]][1])\n```\n\nSince there are possibly many people sharing same family name, it is necessary to distinguish each family separately. \n```{r}\nFamily.Ticket = all[all$Single == 0,c(\"FamilyName\", \"Ticket\")]\nFamily.Ticket = Family.Ticket[order(Family.Ticket$FamilyName),]\nhead(Family.Ticket)\n\n```\n\nBaring few exceptions, in general, a family shared the same ticket number. This can be a good way of identifying families. Here, last three digits of the ticket is extracted and attached to family names, thereby creating unique family names for each family.\n```{r}\n\nall$FamilyName  = paste(all$FamilyName , str_sub(all$Ticket,-3,-1), sep=\"\")\n```\n\n\n## FamilySurvived\n\nBased on the exploratory analysis, a feature representing the survival of family can be created. One would hope that families travelling together would have tried to escape together and their survival must be closely tied to each other.\n\n```{r}\nall$FamilySurvived = 0\n# Dataset of passengers with family\nFamilies = all[(all$Parch+all$SibSp) > 0,]\n\n# Group families by their family name and number of survivals in the family\nSurvival.GroupByFamilyName = aggregate(as.numeric(Families$Survived), by=list(\"FamilyName\" = Families$FamilyName), FUN=sum, na.rm=TRUE)\n\n# Family is considered to have survived if atleast one member survived\nFamilyWithSurvival = Survival.GroupByFamilyName[Survival.GroupByFamilyName$x > 0,]$FamilyName\nall[apply(all, 1, function(x){ifelse(x[\"FamilyName\"] %in% FamilyWithSurvival,TRUE,FALSE)}),]$FamilySurvived = 1\n\n```\n\n## AgeClass\n\nWe can categorise Age into four classes\nClass 1: Below 10\nClass 2: between 10 to 20\nClass 3: between 20 to 35\nClass 4: Above 35\n\n```{r}\nall$AgeClass = ifelse(all$Age<=10,1,\n                      ifelse(all$Age>10 & all$Age<=20,2,\n                             ifelse(all$Age>20 & all$Age<=35,3,4)))\nall$AgeClass = as.factor(all$AgeClass)\n\n```\n\nSince Age is missing for many observations, there will be some data missing here too, which can be calculated after imputing Age.\n\n# Imputing missing data\n\nThe Multiple Imputation by Chained Equations (MICE) package is used for multiple imputation through predictive mean matching method, specifically  for missing Age data, which ensures that imputed values are plausible. \n\n```{r}\nall$Pclass = as.factor(all$Pclass)\nall$Sex = as.factor(all$Sex)\nall[all$Embarked == \"\",]$Embarked = NA\nall$Embarked = as.factor(all$Embarked)\nall[all$Cabin == \"\",]$Cabin = NA\nall$Cabin = as.factor(all$Cabin)\nall$FamilySize = as.factor(all$FamilySize)\nall$Mother = as.factor(all$Mother)\nall$Single = as.factor(all$Single)\nall$FamilyName = as.factor(all$FamilyName)\n\nmd.pattern(all[,!names(all) %in% c(\"Survived\", \"Name\", \"PassengerId\", \"Ticket\", \"AgeClass\")])\n```\n\nThere are 263 observations Age feature missing from the dataset, 1 Observation with Fare, 2 observations with Embarked and 1014 observations have Cabin missing.\n\n## Embarked\n\nTwo of the passengers have the information about their port of embarkation missing. These two observations belong to passengers, both female, both survived and both were in B Type cabin travelling first class. It is assumed they embarked at S, as most of the female from first class who survived embarked either from S or C.\n\n```{r}\nall$Embarked[is.na(all$Embarked)] = 'S'\n\n```\n\n## Fare\n\nR package rpart is used to predict one missing fare data, using other features as predictors.\n\n```{r}\nfit.Fare = rpart(Fare ~ Pclass + SibSp + Parch + Age + Embarked + Title, \n                 data = all[!is.na(all$Fare),],\n                 method = \"anova\")\nall$Fare[is.na(all$Fare)] = predict(fit.Fare, newdata = all[is.na(all$Fare), ])\n```\n\n## Age\n\nIt is observed that Age of 263 passengers is missing from the combined dataset, which needs to be imputed suitably.\n\n```{r}\nmarginplot(data.frame(all$Age, all$Pclass))\n```\n\nThe missing age is not randomly distributed across all classes, but is rather concentrated amongst the passengers from 3rd class, indicating a missing at random(MAR) problem. Mice package can be used to impute these data using pmm or predictive mean matching method.\n\n```{r, warning=FALSE,results='hide'}\n\nageData <- mice(all[, !names(all) %in% c(\"Survived\", \"Name\", \"PassengerId\", \"Ticket\", \"AgeClass\", \"Cabin\", \"FamilyName\")],m=8,maxit=8,meth='pmm',seed=251863)\n```\n```{r, warning=FALSE}\n# Check out the imputed data\nhead(ageData$imp$Age)\n\n# Check if the imputed data distribution follows the existing age distribution.\nggplot(all,aes(x=Age)) + \n  geom_density(data=data.frame(all$PassengerId, complete(ageData,6)), alpha = 0.2, fill = \"blue\")+\n  geom_density(data=all, alpha = 0.2, fill = \"Red\")+\n  labs(title=\"Age Distribution\")+\n  labs(x=\"Age\")\n\n```\n\nImputed data seem to be acceptable and can be used for filling in the missing values in AgeClass and Title\n\n```{r}\n# Sixth imputed data is picked up for further analysis based on the density distribution\nall.imp <- data.frame(all$PassengerId, complete(ageData,6))\n\nall$Age = all.imp$Age\n\nall[is.na(all$AgeClass),]$AgeClass = ifelse(all[is.na(all$AgeClass),]$Age<=10,1,\n                      ifelse(all[is.na(all$AgeClass),]$Age>10 & all[is.na(all$AgeClass),]$Age<=20,2,\n                             ifelse(all[is.na(all$AgeClass),]$Age>20 & all[is.na(all$AgeClass),]$Age<=35,3,4)))\n\n# All women above age of 14.5, with title Miss are to be recategorised as Ms.\nall[all$Title == \"Miss\" & all$Age > 14.5,]$Title = \"Ms\"\n\n# Check if titles and age are as required.\ntable(all$Title, all$Age > 14.5)\n```\n\n## Cabin\n\nMissing cabin data can be imputed for people from same family, assuming they shared the cabins or had cabins nearby.\n\n```{r}\n# Extract single alphabet prefixed to each cabin number provided. Each of these letters represent the part of the deck were these cabins were located.\nall$CabinNo = sapply(all$Cabin,function(x) substr(x,1,1))\nall$CabinNo[all$CabinNo == \"\"] = NA\ntable(is.na(all$CabinNo))\n\n# Dataset of all families with cabin data\nfamilyWithCabinNo = unique(all[!is.na(all$CabinNo) & all$SibSp + all$Parch > 0,c(\"FamilyName\", \"CabinNo\")])\nhead(familyWithCabinNo)\n\n# Function to check if these people are travelling with family \ncheckIfHasCabin <- function(familyName, CabinNo){   \n  ifelse (familyName %in% familyWithCabinNo$FamilyName, familyWithCabinNo$CabinNo, CabinNo)      \n}\n\n# Assign same cabin number to those members of a single family, whose cabin number is missing \nall[is.na(all$CabinNo),]$CabinNo = apply(all[ is.na(all$CabinNo),c(\"FamilyName\", \"CabinNo\")], 1, function(y) checkIfHasCabin(y[\"FamilyName\"], y[\"CabinNo\"]))\n\ntable(is.na(all$CabinNo))\ntable(all$CabinNo, all$Pclass)\n```\n\nThere are still some missing cabin data. Divide the unknown observations for cabin no into cabins for each Pclass in the same ratio as currently available. \n\n```{r}\n# Note: This procedure has been taken from script submitted on Kaggle.\n\n# for first class obs\nA.1 = round(22/(323-65) * 65)\nB.1 = round(65/(323-65) * 65)\nC.1 = round(96/(323-65) * 65)\nD.1 = round(40/(323-65) * 65)\nE.1 = 65 - (A.1+B.1+C.1+D.1)\n# for second class\nD.2 = round(6/(277-254) * 254)\nE.2 = round(4/(277-254) * 254)\nF.2 = 254 - (D.2+E.2)\n# for third class\nE.3 = round(3/(709-691) * 691)\nF.3 = round(8/(709-691) * 691)\nG.3 = 691 - (E.3+F.3)\n\nset.seed(0)\nall[ sample( which( all$Pclass==1 & is.na(all$CabinNo)), A.1 ) , \"CabinNo\"] <- rep(\"A\", A.1)\nall[ sample( which( all$Pclass==1 & is.na(all$CabinNo)), B.1 ) , \"CabinNo\"] <- rep(\"B\", B.1)\nall[ sample( which( all$Pclass==1 & is.na(all$CabinNo)), C.1 ) , \"CabinNo\"] <- rep(\"C\", C.1)\nall[ sample( which( all$Pclass==1 & is.na(all$CabinNo)), D.1 ) , \"CabinNo\"] <- rep(\"D\", D.1)\nall[ sample( which( all$Pclass==1 & is.na(all$CabinNo)), E.1 ) , \"CabinNo\"] <- rep(\"E\", E.1)\n\nset.seed(0)\nall[ sample( which( all$Pclass==2 & is.na(all$CabinNo)), D.2 ) , \"CabinNo\"] <- rep(\"D\", D.2)\nall[ sample( which( all$Pclass==2 & is.na(all$CabinNo)), E.2 ) , \"CabinNo\"] <- rep(\"E\", E.2)\nall[ sample( which( all$Pclass==2 & is.na(all$CabinNo)), F.2 ) , \"CabinNo\"] <- rep(\"F\", F.2)\n\nset.seed(0)\nall[ sample( which( all$Pclass==3 & is.na(all$CabinNo)), E.3 ) , \"CabinNo\"] <- rep(\"E\", E.3)\nall[ sample( which( all$Pclass==3 & is.na(all$CabinNo)), F.3 ) , \"CabinNo\"] <- rep(\"F\", F.3)\nall[ sample( which( all$Pclass==3 & is.na(all$CabinNo)), G.3 ) , \"CabinNo\"] <- rep(\"G\", G.3)\n\nall$CabinNo = as.factor(all$CabinNo)\ntable(all$CabinNo, all$Pclass)\n```\n \n \nFinally, dataset is divided back into training and test set for further analysis.\n\n```{r}\nall$Ticket = NULL\nall$Name = NULL\nall$Cabin = NULL\n\nsummary(all)\n\ntrain = all[1:891,]\ntest = all[892:1309,]\n\ntrain$Survived <- as.factor(Survived)\ntrain$Survived <- as.factor(mapvalues(train$Survived, c(\"0\", \"1\"), c(\"No\",\"Yes\")))\ntrain$PassengerId = NULL\n```\n\n# Lasso and Ridge Models\n\n## Training and validation sets\nDataset is split into separate male and female datasets, with respective Training and validation sets created using sample.split function. Levels and variables that are no longer meaningful in the newly created datasets are dropped.\n\n```{r}\ntrain.male = subset(train, train$Sex == \"male\")\ntrain.female = subset(train, train$Sex == \"female\")\ntest.male = subset(test, test$Sex == \"male\")\ntest.female = subset(test, test$Sex == \"female\")\n\ntrain.male$Sex = NULL\ntrain.male$Mother = NULL\ntrain.male$Title = droplevels(train.male$Title)\n\ntrain.female$Sex = NULL\ntrain.female$Title = droplevels(train.female$Title)\n\ntest.male$Sex = NULL\ntest.male$Mother = NULL\ntest.male$Title = droplevels(test.male$Title)\n\ntest.female$Sex = NULL\ntest.female$Title = droplevels(test.female$Title)\n\n# MALE\nset.seed(100)\nsplt.m = sample.split(train.male, 0.75)  \ncv.train.m = train.male[splt.m,]\ncv.test.m = train.male[!splt.m,]\n\n# FEMALE\nset.seed(100)\nsplt.f = sample.split(train.female, 0.75)  \ncv.train.f = train.female[splt.f,]\ncv.test.f = train.female[!splt.f,]\n\n```\n\n\n## Model Training and Prediction\n\n### Male Dataset\n```{r}\nx.m = data.matrix(cv.train.m[,2:14])\ny.m = cv.train.m$Survived\n\nset.seed(356)\n# 10 fold cross validation\ncvfit.m.ridge = cv.glmnet(x.m, y.m, \n                  family = \"binomial\", \n                  alpha = 0,\n                  type.measure = \"class\")\n\ncvfit.m.lasso = cv.glmnet(x.m, y.m, \n                  family = \"binomial\", \n                  alpha = 1,\n                  type.measure = \"class\")\npar(mfrow=c(1,2))\nplot(cvfit.m.ridge, main = \"Ridge\")\nplot(cvfit.m.lasso, main = \"Lasso\")\ncoef(cvfit.m.ridge, s = \"lambda.min\")\n```\n\nRidge model gives a better misclassification error than the Lasso model, hence former is used for prediction.\n\n```{r,warning=FALSE}\n# Prediction on training set\nPredTrain.M = predict(cvfit.m.ridge, newx=x.m, type=\"class\")\ntable(cv.train.m$Survived, PredTrain.M, cv.train.m$Title)\n\n# Prediction on validation set\nPredTest.M = predict(cvfit.m.ridge, newx=data.matrix(cv.test.m[,2:14]), type=\"class\")\ntable(cv.test.m$Survived, PredTest.M, cv.test.m$Title)\n\n# Prediction on test set\nPredTest.M = predict(cvfit.m.ridge, newx=data.matrix(test.male[,3:15]), type=\"class\")\ntable(PredTest.M, test.male$Title)\n```\n\nAlthough ridge model does a fairly good job at predicting survivors among male below 14.5 years of age with very high precision and recall, i.e. for Master, it fails to predict even a single surviving adult male.\n\n### Female Dataset\n```{r}\nx.f = data.matrix(cv.train.f[,2:15])\ny.f = cv.train.f$Survived\n\nset.seed(356)\ncvfit.f.ridge = cv.glmnet(x.f, y.f, \n                  family = \"binomial\", \n                  alpha = 0,\n                  type.measure = \"class\")\ncvfit.f.lasso = cv.glmnet(x.f, y.f, \n                  family = \"binomial\", \n                  alpha = 1,\n                  type.measure = \"class\")\npar(mfrow=c(1,2))\nplot(cvfit.f.ridge, main = \"Ridge\")\nplot(cvfit.f.lasso, main = \"Lasso\")\ncoef(cvfit.f.ridge, s = \"lambda.min\")\n\n```\n\nAlthough, lasso model gives much better misclassification error than the ridge model in case of female dataset, kappa statistics on the training set is better for ridge model.\n\n```{r, warning=F,message=F}\n# Ridge Model\n# Prediction on training set\nPredTrain.F = predict(cvfit.f.ridge, newx=x.f, type=\"class\")\ntable(cv.train.f$Survived, PredTrain.F, cv.train.f$Title)\nconfusionMatrix(cv.train.f$Survived, PredTrain.F)\n\n# Prediction on validation set\nPredTest.F = predict(cvfit.f.ridge, newx=data.matrix(cv.test.f[,2:15]), type=\"class\")\ntable(cv.test.f$Survived, PredTest.F, cv.test.f$Title)\nconfusionMatrix(cv.test.f$Survived, PredTest.F)\n\n# Ridge Model\n# Prediction on training set\nPredTrain.F = predict(cvfit.f.lasso, newx=x.f, type=\"class\")\ntable(cv.train.f$Survived, PredTrain.F, cv.train.f$Title)\nconfusionMatrix(cv.train.f$Survived, PredTrain.F)\n\n# Prediction on validation set\nPredTest.F = predict(cvfit.f.lasso, newx=data.matrix(cv.test.f[,2:15]), type=\"class\")\ntable(cv.test.f$Survived, PredTest.F, cv.test.f$Title)\nconfusionMatrix(cv.test.f$Survived, PredTest.F)\n\n# Prediction on test set\nPredTest.F = predict(cvfit.f.ridge, newx=data.matrix(test.female[,3:16]), type=\"class\")\ntable(PredTest.F, test.female$Title)\n\n```\n\nFor female dataset, ridge regression has a very high recall value for all three categories of females, namely, Miss, Ms and Mrs, but it predicts some false positives, predicting more survivors than there actually.\n\n# Conclusion\n\nRidge regression seems to predict on female dataset with higher precision and recall than on the male. Since the number of survivors in the male dataset is much less than that in female dataset, it fails to predict survivors especially among the adult male. \n\n## Kaggle Results\n\n```{r}\nMySubmission.F = data.frame(PassengerId = test.female$PassengerId, Survived = ifelse(PredTest.F == \"Yes\",1,0)) \nMySubmission.M = data.frame(PassengerId = test.male$PassengerId, Survived = ifelse(PredTest.M == \"Yes\",1,0))     \n\nMySubmission = rbind(MySubmission.F, MySubmission.M)\nMySubmission = MySubmission[order(MySubmission$PassengerId),]\nnames(MySubmission) = c(\"PassengerId\",\"Survived\")   \ntable(MySubmission$Survived)\n\nwrite.csv(MySubmission, file = 'Submission_RIDGE.csv', row.names = F)\n\n```\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}