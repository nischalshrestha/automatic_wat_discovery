{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a7ccd73f-15bb-88bd-0612-33e35493b950"
      },
      "source": [
        "Pre-Process and Ensemble the Bagging and Boosting models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8171d3f7-e8df-5fac-e0ea-ea5cc499407c"
      },
      "outputs": [],
      "source": [
        "# This R environment comes with all of CRAN preinstalled, as well as many other helpful packages\n",
        "# The environment is defined by the kaggle/rstats docker image: https://github.com/kaggle/docker-rstats\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "require(caret) \n",
        "require(caretEnsemble)\n",
        "require(lattice)\n",
        "require(rpart)\n",
        "require(randomForest)\n",
        "require(ada)\n",
        "require(plyr)\n",
        "require(adabag)\n",
        "library(ggplot2) # Data visualization\n",
        "library(readr) # CSV file I/O, e.g. the read_csv function\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "setwd('D:/Narendra/!1Data Science/!5 Data Science Project/!1 Classification/Titanic Machine Learning from Disaster (Kaggle)/')\n",
        "training=read.csv(file='!Original Data/train.csv',header=T,sep=\",\",na.strings=c(\"NA\",\" \",\"\"))\n",
        "dim(training) ### Check the dimension\n",
        "str(training) ### Check the class type of variables\n",
        "summary(training) #### Check the Summary on data\n",
        "\n",
        "test=read.csv(file='!Original Data/test.csv',header=T,sep=\",\",na.strings=c(\"NA\",\" \",\"\"))\n",
        "dim(test)\n",
        "str(test)\n",
        "test$Survived=0\n",
        "\n",
        "#### Combind the data using Rbind\n",
        "Titanic_data=rbind(training,test)\n",
        "summary(Titanic_data)\n",
        "dim(Titanic_data)\n",
        "\n",
        "########## Update the missing values using the \"BagImpute\" (Preprocessing) #############################\n",
        "\n",
        "Titanic_data_preprocess=preProcess(Titanic_data[,c(\"PassengerId\",\"Age\",\"SibSp\",\"Parch\",\"Fare\")],method=c(\"bagImpute\"))\n",
        "Titanic_data_preprocess\n",
        "summary(Titanic_data_preprocess)\n",
        "Titanic_data_preprocess$method\n",
        "Titanic_data_preprocess_pred=predict(Titanic_data_preprocess,Titanic_data[,c(\"PassengerId\",\"Age\",\"SibSp\",\"Parch\",\"Ticket\",\"Fare\")])\n",
        "summary(Titanic_data_preprocess_pred)\n",
        "Titanic_data$Age=Titanic_data_preprocess_pred$Age\n",
        "Titanic_data$Fare=Titanic_data_preprocess_pred$Fare\n",
        "summary(Titanic_data)\n",
        "\n",
        "Titanic_data$Embarked[is.na(Titanic_data$Embarked=='')]=\"S\"\n",
        "Titanic_data$Name=as.character(Titanic_data$Name)\n",
        "\n",
        "######### Extract the Titles in name filed like ###############\n",
        "\n",
        "require(stringr)\n",
        "extract_Title=function(x){\n",
        "  \n",
        "  Title=str_trim(strsplit(x,split='[,.]')[[1]][2])\n",
        "  return(Title)\n",
        "}\n",
        "\n",
        "Titanic_data$Title=sapply(Titanic_data$Name,FUN=extract_Title)\n",
        "\n",
        "Titanic_data$Title=as.factor(Titanic_data$Title)\n",
        "summary(Titanic_data)\n",
        "levels(Titanic_data$Title)\n",
        "\n",
        "### Renaming the titles \n",
        "Titanic_data$Title[Titanic_data$Title=='Capt']='Mr'\n",
        "Titanic_data$Title[Titanic_data$Title=='Col']='Mr'\n",
        "Titanic_data$Title[Titanic_data$Title=='Dona']='Mr'\n",
        "Titanic_data$Title[Titanic_data$Title=='Don']='Mr'\n",
        "Titanic_data$Title[Titanic_data$Title=='Dr']='Sir'\n",
        "Titanic_data$Title[Titanic_data$Title=='Jonkheer']='Mr'\n",
        "Titanic_data$Title[Titanic_data$Title=='Lady']='Miss'\n",
        "Titanic_data$Title[Titanic_data$Title=='Major']='Mr'\n",
        "Titanic_data$Title[Titanic_data$Title=='Mlle']='Miss'\n",
        "Titanic_data$Title[Titanic_data$Title=='Ms']='Miss'\n",
        "Titanic_data$Title[Titanic_data$Title=='Sir']='Mr'\n",
        "Titanic_data$Title[Titanic_data$Title=='Mme']='Miss'\n",
        "Titanic_data$Title[Titanic_data$Title=='Rev']='Mr'\n",
        "Titanic_data$Title[Titanic_data$Title=='the Countess']='Miss'\n",
        "\n",
        "##### Save the files after PreProcess and Feature engineering\n",
        "write.csv(training_data,file=\"train.csv\",row.names=F)\n",
        "write.csv(test_data,file=\"test.csv\",row.names=F)\n",
        "#### Load Files\n",
        "train=read.csv('train.csv',header=T,sep=\",\")\n",
        "summary(train)\n",
        "dim(train)\n",
        "test=read.csv('test.csv')\n",
        "dim(test)\n",
        "#### Combind the Data\n",
        "datamerging=rbind(train,test)\n",
        "summary(datamerging)\n",
        "dim(datamerging)\n",
        "#### Change the levels\n",
        "datamerging$Survived=as.factor(datamerging$Survived)\n",
        "datamerging$Pclass=as.factor(datamerging$Pclass)\n",
        "datamerging$Ticket=as.factor(datamerging$Ticket)\n",
        "\n",
        "summary(datamerging)\n",
        "train1=datamerging[1:891,]\n",
        "test1=datamerging[892:1309,]\n",
        "### Explore the data\n",
        "dim(train1)\n",
        "class(train1)\n",
        "str(train1)\n",
        "dim(test)\n",
        "summary(train1)\n",
        "levels(train1$Survived)\n",
        "levels(train1$Pclass)\n",
        "levels(train1$Ticket)\n",
        "\n",
        "####### Ensamble the Process ###############\n",
        "set.seed(10000)\n",
        "control1=trainControl(method=\"repeatedcv\",repeats=3,savePredictions=TRUE,classProbs=TRUE)\n",
        "\n",
        "al_list=c('gbm','rf','rpart','C5.0')\n",
        "\n",
        "\n",
        "##### Changing the Levels on target variable 0,1 to X0 and X1\n",
        "?make.names \n",
        "levels(train1$Survived)=make.names(levels(factor(train1$Survived)))\n",
        "\n",
        "###### Build the model using Caretlist $ caretStack ########\n",
        "\n",
        "set.seed(10000)\n",
        "ens_model=caretList(Survived~.,data=train1,trControl=control1,methodList=al_list)\n",
        "ens_model\n",
        "ens_model_result=resamples(ens_model)\n",
        "ens_model_result\n",
        "summary(ens_model_result)\n",
        "x11()\n",
        "dotplot(ens_model_result)\n",
        "splom(ens_model_result)\n",
        "final_ens_model=caretStack(ens_model,trControl=control1,method=\"rf\",tuneLength=8)\n",
        "final_ens_model\n",
        "final_ens_model$models\n",
        "final_ens_model$ens_model\n",
        "final_ens_model$error\n",
        "x11()\n",
        "summary(final_ens_model)\n",
        "\n",
        "\n",
        "##### Predict the train result in TEST ########\n",
        "\n",
        "test1$Survived=predict(final_ens_model,test1)\n",
        "summary(test1$Survived)\n",
        "write.csv(test1[,c(\"PassengerId\",\"Survived\")],file=\"RForest_Model3aa_pred.csv\",row.names=F)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.3.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}