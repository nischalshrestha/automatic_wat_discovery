{"cells":[{"metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"_uuid":"e575ce1843739e34dd924ef0f9ea8858ff335a4e","_cell_guid":"96d310e2-838b-4180-aa6a-6b6970fbd159","_execution_state":"idle","trusted":true},"cell_type":"code","source":"# This R environment comes with all of CRAN preinstalled, as well as many other helpful packages\n# The environment is defined by the kaggle/rstats docker image: https://github.com/kaggle/docker-rstats\n# For example, here's several helpful packages to load in \n\nlibrary(ggplot2) # Data visualization\nlibrary(readr) # CSV file I/O, e.g. the read_csv function\nlibrary(lattice) # Requirement for 'caret'-package\nlibrary(caret) # Missclassification Error\nlibrary(mice) # Missing Value imputation\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nsystem(\"ls ../input\")\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"f0d314fc4511a1a81a1e8165074195de92822fe8","_cell_guid":"83ab6d2e-325a-46c8-9808-97d8ab705582"},"cell_type":"markdown","source":"The task in this competition is to classify whether a passenger survived the sinking of Titanic or not. \nSo it is a supervised learning problem with a binary respone variable.\n\nThe first thing that's coming to my mind to respect of survival is that the variable **Age**, **Sex** and **Pclass** is important.\n\nI have a hypotesis that the variable's **PassengerID**, **Name**, **SibSp**, **Ticket**, **Fare**, **Cabin** and **Embarked** is less likely to add any important information to my model.\nThere for I will focus on age, sex and ticket class. \n\nIf i get a loosy result i will investigate if the variable **parch** might add some information. And the reason that it might be important is that the children have a higher chance of survival if they have many adults around."},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"362c3c703f4943bace42812b5bb9099744fbe730","trusted":true,"_cell_guid":"0e5af8cd-53b8-4562-8a2f-6d0cf00df1e7"},"cell_type":"code","source":"#### Import training and test dataset\ntrain <- read.csv(file = '../input/train.csv')\ntest <- read.csv(file = '../input/test.csv')\n","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"5468be65ce37c2134e5cf15d9dea4e34f992e41c","_cell_guid":"f0f0e888-6f58-4c7f-8d20-4f05c34eafb5"},"cell_type":"markdown","source":"Even though this is a small dataset, a  rule of thumb that I stick to, is that I want to work with as little data as possible. \nThere for I will be checking the strucutre of the data frame, so I can select the variables i want to keep. \n"},{"metadata":{"_uuid":"59caeb77353e5d88c47e413daefa5f771e46b7c3","trusted":true,"_cell_guid":"0146bb3f-5f4d-4c62-a074-f92976555c20"},"cell_type":"code","source":"str(train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39be416d4fd20a1022922b4929fb13fedb3a2aa8","trusted":true,"_cell_guid":"a35aedd6-f698-49ce-9eab-cb953145af95"},"cell_type":"code","source":"# Subset of data\ntrainImp <- train[,c(2, 3, 5, 6)]\ntestImp <- test[,c(2, 4, 5)]","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"0d9d9c3c449dccbddbf75d63758ef53ef84491c1","_cell_guid":"81c506c6-167b-4888-82d2-0152ca7cc63c"},"cell_type":"markdown","source":"My subset of data consist of three explanatory variables and a binary response variable.\n\nFrom the output above I notice that **Age** is contains **NA** values. This is something to look into because if the variable contains a high rate of **Missing Values** it does not add very much information.\n\n\n\n\n\n"},{"metadata":{"_uuid":"cbfe501cda00d8655bf3af7af6d7dc8a11b528b6","trusted":true,"_cell_guid":"adb71276-ecc1-46d6-95c2-7ef4ec1daee1"},"cell_type":"code","source":"# Make sure to add useNA argument.\ntable(trainImp$Age, useNA = \"ifany\")\n# Percent of NA\nprint(paste0(\"Percent of NA \", mean(is.na(train$Age))))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e7586c29ed393e02f30e5d88d6605fbaf9df6924","trusted":true,"_cell_guid":"ce8cef72-cade-417a-9b31-dde07bb23c9d"},"cell_type":"code","source":"attach(trainImp)\ntable(Pclass, Survived, useNA = \"ifany\")\nprop.table(table(Pclass, Survived, useNA = \"ifany\"),1)\nprint(\"========================================\")\ntable(Sex, Survived, useNA = \"ifany\")\nprop.table(table(Sex, Survived, useNA = \"ifany\"),1)\ndetach(trainImp)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"640e0e027e0a468c4b5f2c33263bfc475b9ec641","_cell_guid":"857826c6-28b5-483d-8304-9d3838be62ff"},"cell_type":"markdown","source":"Now I know for a fact that it's only **Age** that contains **Missing Values**, the downside is the rate, allmost 20 % missing.\n\nFrom the tables above I can see the distribution and connection for survivals grouped by **Pclass** and **Sex**.\n\nThere is a big difference in survival between ticket class **1** and **2**, almost the times higher chance of survival by owning a first-class ticket.\n\nI will as well look into the **Age** variable grouped by **Survived**, but not as a table.\n\nLook at the histogram below.\n\n"},{"metadata":{"_uuid":"90839b86cd14e38b68ed11ed471ee2126c9968fc","trusted":true,"_cell_guid":"68d423bb-49cc-4d53-9351-6b4a087ed5f5"},"cell_type":"code","source":"ggplot(data = trainImp, aes(x = Age, fill = as.factor(Survived))) + geom_histogram(alpha = .5) + theme_minimal()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f0969d5c312374a4a90f516d2cca3cc391d199f","_cell_guid":"0ec76744-2636-45d6-931b-b229e0fb3b71"},"cell_type":"markdown","source":"For simplicity i will train a **Generalized Linear Model** with a **Logit-link**. I will use the built-in **stats** package and use the function **GLM**"},{"metadata":{"_uuid":"b20a84423a761cd2f6e7fcc26a75363b01fe265c","trusted":true,"_cell_guid":"90e24a6c-93c2-485a-bc40-2afe9218f5c6"},"cell_type":"code","source":"trainLogistic <- glm(formula = Survived ~ Age + Sex + Pclass,\n                     family = binomial(),\n                     data = trainImp)\nsummary(trainLogistic)\ntrainPred <- (predict(object = trainLogistic, newdata = trainImp[ ,-1]) > 1) * 1 # Remove response-variable\nconfusionMatrix(data = table(trainPred, trainImp$Survived), dnn = c(\"Prediction\", \"Reference\"))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9229228146926384c7b4f7767039d08a4e8d362a","_cell_guid":"dcc0075d-edae-4c6c-9e7c-8f151157cd04"},"cell_type":"markdown","source":"I am a bit dissapointed about the **Age** variable, it does not add very much information to the model, and the **degrees of freedom** is much lower because of the **NA** values.\nOne solution might be to try a **Imputation** method, but a common rule of thumb is to only **Impute** values if they only cover less than **5%** of the data. \nBut this is not a scientific journal, so if **Imputation** can raise the accuray that is great.\n\nAs a first try I get almost 80 % accuracy, the model missclassify many of the survivors as none-survivors.\n\nI am not completly satisfied with the result before i submit, I will try some kind of a **Imputation** method or group the **Age** variable in intervals, such as 'children', 'midle age', 'older'. I will be using the package Multivariate Imputation by Chained Equations, **MICE**.\n\nI will go back and use all the variables in the training dataset to get the best result from the **Imputation**  method."},{"metadata":{"scrolled":true,"_uuid":"b8f19905f708730e7fb4b70d87a17e94505f340a","trusted":true,"_cell_guid":"375d78aa-62d9-4733-911d-34f06e2855b5"},"cell_type":"code","source":"set.seed(123)\n\ntrainMice <- mice(data = train[ ,c(2, 3, 5, 6, 7, 8, 10)], imputationMethod = 'rf', maxit = 5, m = 1, printFlag = FALSE)\ntestMice <- mice(data = test[ ,c(1, 2, 4, 5, 6, 7)], imputationMethod = 'rf', maxit = 5, m = 1, printFlag = FALSE)\ntrainMiceComplete <- complete(trainMice)\ntestMiceComplete <- complete(testMice)\n","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"28547088582fd82e0523e395fa092675b3317ffb","trusted":true,"_cell_guid":"d450018b-f89c-4394-b45d-1b75afcae087"},"cell_type":"code","source":"trainLogisticMice <- glm(formula = Survived ~ Sex + Pclass + Age,\n                         family = binomial(),\n                         data = trainMiceComplete[,c(1, 2, 3, 4)])\nsummary(trainLogisticMice)\ntrainPred <- (predict(object = trainLogisticMice, newdata = trainImp[ ,-1]) > 1) * 1 # Remove response-variable\nconfusionMatrix(data = table(trainPred, trainImp$Survived), dnn = c(\"Prediction\", \"Reference\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca6d6b05684bdd3843432392b0faa5ab8b03b47b","_cell_guid":"31c6c21d-46fe-47b0-8b45-4aad6e6c2259"},"cell_type":"markdown","source":"Not much of a difference with **Imputation**, the result is not that big of a supprice because the **Age** variable was not significant in the first model. But it was worth a try because almost 20% of the obsevations in **Age** were missing.\nLast attempt on raising my accuray is to transform **Age** into intervals."},{"metadata":{"_uuid":"6e964a41cc6ad07def3a0d958937cf7a22e59892","trusted":true,"_cell_guid":"47ce5594-9386-4eb5-9fd2-1c2cb232306f"},"cell_type":"code","source":"trainMiceComplete$AgeInterval <- cut(trainMiceComplete$Age,\n                                    breaks = c(0, 20, 40, Inf),\n                                    labels = c('Children','MiddleAge', 'Older'),\n                                    right = FALSE)\n\ntestMiceComplete$AgeInterval <- cut(testMiceComplete$Age,\n                                    breaks = c(0, 20, 40, Inf),\n                                    labels = c('Children','MiddleAge', 'Older'),\n                                    right = FALSE)\n\ntrainLogisticMice <- glm(formula = Survived ~ Sex + Pclass + AgeInterval,\n                         family = binomial(),\n                         data = trainMiceComplete[,c(1, 2, 3, 5, 8)])\nsummary(trainLogisticMice)\ntrainPred <- (predict(object = trainLogisticMice, newdata = trainMiceComplete) > 1) * 1 # Remove response-variable\nconfusionMatrix(data = table(trainPred, trainImp$Survived), dnn = c(\"Prediction\", \"Reference\"))\n\ntestPred <- (predict(object = trainLogisticMice, newdata = testMiceComplete) > 1) * 1 # Predict test dataset\nSubmission <- data.frame(\"PassengerId\" = testMiceComplete$PassengerId, \"Survived\" = testPred)","execution_count":32,"outputs":[]},{"metadata":{"_uuid":"af47e0e738d38d8bc83ba4d8127d3a54567928df","trusted":true,"_cell_guid":"156bc8b4-1804-496b-a021-62add9433ba4"},"cell_type":"code","source":"Since this is my first Kernel and first participation in a competition on Kaggle I feel like i am satisfied.\nI will try and submit my result.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b52dde090508660a8a7938a62be90d9c3cc8d5b7","trusted":true,"_cell_guid":"4b457446-cecc-4a5e-9d6b-ce2f066790c4"},"cell_type":"code","source":"write.csv(Submission,\"Submission_titanic.csv\",row.names = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","execution_count":35,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","version":"3.4.2","name":"R","pygments_lexer":"r","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}