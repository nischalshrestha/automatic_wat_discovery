{"cells":[{"metadata":{"_cell_guid":"92430a48-6c98-46cc-87cd-e5e9ac1d7ff3","_uuid":"c930e5a1519a1a87fefb0675686b73b977efb573","collapsed":true},"cell_type":"markdown","source":"# Introduction\nOn the present notebook, we review the data available in the Titanic corpus, and try to determine their influences in the survival or not of the passengers.\n\nThe main objective of this notebook is to illustrate the handling of a dataset in a data science context, and the application of some simple statistical methods to establish a suitable prediction model.\n\n## Initialization\nFirst of all, we load every library we will need in the present notebook. We choose to do it at once at the top of the script, rather than at use, to keep ann overview of what is needed."},{"metadata":{"_cell_guid":"2ad38c57-ca6d-45d3-9fe4-a63f9e9163d9","_uuid":"fb41b69e2648a266cf747db4e572f40c7ade2280","trusted":false},"cell_type":"code","source":"quiet<-function(x){suppressWarnings(suppressMessages(x))} # quiet load\nquiet(library(plyr))         # data manipulation\nquiet(library(dplyr))        # data manipulation\nquiet(library(ggplot2))      # fancy plotting\nquiet(library(Rmisc))        # for multiplot\nquiet(library(corrplot))     # for correlation matrix plotting\nquiet(library(rpart))        # decision tree prediction\nquiet(library(rpart.plot))   # decision tree plotting\nquiet(library(randomForest)) # random forest prediction\nquiet(library(e1071))        # svm prediction\nquiet(library(caret))        # for k-fold cross-validation","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3b33dec9-021e-48f5-bc59-5617aae03a04","_uuid":"17afd134e2b111a270a95a8fc0120c2203bf101f"},"cell_type":"markdown","source":"Reading from the inputs, we define the training set and the test set; plus a _full_ set, gathering all the passengers' data in once."},{"metadata":{"_cell_guid":"0a80f356-0543-46ce-a620-d4177b18a544","_uuid":"9bc9b6ec10307ac562b494189913a742b617a22f","trusted":false},"cell_type":"code","source":"titanic_train <- read.csv(file=\"../input/train.csv\",head=TRUE)\ntitanic_test <- read.csv(file=\"../input/test.csv\",head=TRUE)\nsuppressWarnings(titanic <- bind_rows(titanic_train, titanic_test))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7c08fddb-aeb6-4d25-8792-b16d5057b392","_uuid":"0ff1b05074bc1995732b50b0d4e9b0c16ddfca54"},"cell_type":"markdown","source":"# Explore input data\n\nNow that all available data are loaded, let's have a look at them.\n\n## Available features\n\nWithout prior knowledge of the manipulated data, we use at first the `str` and `summary` functions. The first one displays the internal structure of the dataset, exposing its content fields, with examples of content. The second one produces the results of various model fitting functions on the dataset content, giving up a brief summary of the content. "},{"metadata":{"_cell_guid":"5e66618f-b486-49bd-b321-a9e24058aa1c","_uuid":"7d7bf2ff7567a9af7090a83a8095176e90d544f7","trusted":false},"cell_type":"code","source":"str(titanic)\nsummary(titanic)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d6150cc2-c454-4479-80d1-8614a32344a1","_uuid":"027da991800261cecfa7cfe3a484794dbfdd0482"},"cell_type":"markdown","source":"Here we got some informations about our variables and their class type. We are working with 12 different variables for 1309 rows, so 1309 passengers of the HMS Titanic. As all variable names aren't fully explicit, here is an exposition table of them:\n\n**Variable Name** |  **Type**   | **Description**\n--------------|---------|-------------\nSurvived      | Integer | 1 if the passenger has survived, 0 otherwise\nPclass        | Integer | The passenger's class, from 1 to 3\nName          | String  | The passenger's name\nSex           | String  | The passenger's sex, \"male\" or \"female\"\nAge           | Float   | The passenger's age\nSibSp         | Integer | The number of passenger's siblings/spouses aboard\nParch         | Integer | The number of passenger's parents/children aboard\nTicket        | String  | The passenger's ticket id\nFare          | Float   | The passenger's ticket fare\nCabin         | String  | The cabin number(s) related to passenger's ticket\nEmbarked      | Char    | The port of embarkation: S, C or Q"},{"metadata":{"_cell_guid":"d5aa70ff-0b5e-443b-8e8e-4aa04803adf6","_uuid":"fd7ef439a14cf39d100525db8b1a57341b21cefd"},"cell_type":"markdown","source":"\n## Impact of each variable on survival\n\nIn this section, we investigate how each individual features as (or not) an impact on the survival of passengers. We perform this evaluation on all variable but `PassengerId`, since it is not a real world data, just a computer variable to store and retrieve passenger data.\n\nAs we can see above, feature `Survived` has a mean of `0.3838` (based on data available by the train part of the dataset). We store this value in order to print it as a visual reference when plotting graphs."},{"metadata":{"_cell_guid":"f8a70d82-26ba-40cb-a74a-a95e7a7c1e86","_uuid":"8bd286800eeadabd8365326bbbd2842cd365db49","trusted":false},"cell_type":"code","source":"mSurv <- mean(titanic_train$Survived)\ntitanic_train <- within(titanic_train, {Survived[Survived == 1] <- \"Yes\";Survived[Survived == 0] <- \"No\"})\nadd_mSurv <- function(x) {\n  return(x + geom_hline(aes(yintercept=mSurv, linetype=factor(mSurv)), show.legend = TRUE) + scale_linetype_manual(name = \"Survival\", values = \"dashed\", label =\"average\") + guides(fill = guide_legend(override.aes = list(linetype = \"blank\"))))\n}","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"87060a80-8b10-49fc-add3-6b18bbbd4ab2","_uuid":"474504e5322afbdea1db5191f435cc1738a87b33"},"cell_type":"markdown","source":"### Passenger class\n\nLet's investigate first the impact of the passenger class of survival. For this feature, like every following ones, we will trace the graph based on the number of passenger involved to handle the set distribution, and a normalized version to handle the proportions. "},{"metadata":{"_cell_guid":"9c0b691d-d382-428b-9d0f-a7907349b75a","_uuid":"4bbdb843d4623a37888a0fbe64d12db3fa496fef","trusted":false},"cell_type":"code","source":"g1 <- ggplot(titanic_train) +\n  geom_bar(aes(Pclass, fill = Survived)) + labs(x = \"Passenger's class\", y = \"Count\")\ng2 <- add_mSurv(ggplot(titanic_train) + geom_bar(aes(Pclass, fill = Survived), position=\"fill\") + labs(x = \"Passenger's class\", y = \"Part\"))\nmultiplot(g1, g2, cols=2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"95f0ac4e-17e8-4921-b0b8-1a2feea3c19c","_uuid":"7b66f2eef2b7788c5e6fa544fd32d0c31d5edf42"},"cell_type":"markdown","source":"The number of surviving passengers from each class in mostly balanced, but the proportion of passengers from each class who survived seems really class dependent. If more than 60% of the passengers of the first class survived, less than 25% of the passengers of the third class had this chance.\n\n### Gender\nLet's have a look at the proportion of women and men who survived."},{"metadata":{"_cell_guid":"e72ea5a9-1c9a-4ab2-8aaa-66dc5efdcefa","_uuid":"45d4d3a12d41ba972a4880a0ba656d85afc5bff9","trusted":false},"cell_type":"code","source":"g1 <- ggplot(titanic_train) + geom_bar(aes(Sex, fill = Survived))\ng2 <- add_mSurv(ggplot(titanic_train) + geom_bar(aes(Sex, fill = Survived), position=\"fill\"))\nmultiplot(g1, g2, cols=2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8ab4bb4b-01c4-4d4e-9b2a-94d126d6f2f1","_uuid":"9207a6b7bbfe22f59e785a7eac35010c326fa37b"},"cell_type":"markdown","source":"It is obvious than gender had a huge importance in survival, 74% of females survived for only 19% of males.\n\n### Age\n\nOn this section, we consider the survival based on the age of the passengers. As seen before, this feature is a missing value for some of the passengers. So we compute this analysis only over passenger with a age value filled, and grouped the results by 5-years age intervals."},{"metadata":{"_cell_guid":"447ec6ba-abbb-4e5d-92b5-524a023c5fa2","_uuid":"215fac2aa0d5617262fbe02da85db1533993658c","trusted":false},"cell_type":"code","source":"g1 <- ggplot(titanic_train) + geom_histogram(aes(Age, fill = Survived), binwidth = 5, na.rm=TRUE)\ng2 <- add_mSurv(ggplot(titanic_train) + geom_histogram(aes(Age, fill = Survived), binwidth = 5, na.rm=TRUE, position=\"fill\"))\nmultiplot(g1, g2, cols=2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6225b103-2c98-4c26-a46b-4e214e406d60","_uuid":"4dcc0e7e2bf7726aa123ed7caedf6cba11575b56"},"cell_type":"markdown","source":"Survival rate among age seems quite balanced, so comments based on it appear to be hard to express. The only thing with a decent level of confidence is that being a child (having less than 10 years) mainly increase the survival rate.\n\nNo deduction can really be done from the elder groups, due to the very limited population of this age ranges.\n\n### Fare\n\nAs well as for age, we analyze only passenger for whom we got fare data, and gather them in 20Â£-ranged groups."},{"metadata":{"_cell_guid":"decfd7fc-0483-4c0e-ae47-6602c48d01fc","_uuid":"0cf9723488b6f640317b386aa475207acf596d8e","trusted":false},"cell_type":"code","source":"g1 <- ggplot(titanic_train) + geom_histogram(aes(Fare, fill = Survived), binwidth = 20, na.rm=TRUE)\ng2 <- add_mSurv(ggplot(titanic_train) + geom_histogram(aes(Fare, fill = Survived), binwidth = 20, na.rm=TRUE, position=\"fill\"))\nmultiplot(g1, g2, cols=2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"65a62ebf-424b-42a8-8513-0b7c293365c6","_uuid":"89a9eebb6393c6de109b1ebee7a475467cedf047"},"cell_type":"markdown","source":"If we can't conclude anything based on the very rare people involved in high fees, it appear that low fare passengers have a lower chance of survival.\n\nAs this is not as clear as it was for passenger class, this feature might require a more deeper analysis, which we will make further in this notebook.\n\n### Embarked location\n\nFor every passenger but two in the training set, we got information about their departure port. The superline has taken passenger as the first place at Southampton in England (S), then at Cherbourg in France (C) and finally at Queenstown - now Cobh - in Ireland (Q)."},{"metadata":{"_cell_guid":"855724ef-87b8-424b-ad7d-1d96bca90cb2","_uuid":"af7b6e56255d534498564d090228a266f46f1df9","trusted":false},"cell_type":"code","source":"g1 <- ggplot(titanic_train) + geom_bar(aes(Embarked, fill = Survived))\ng2 <- add_mSurv(ggplot(titanic_train) + geom_bar(aes(Embarked, fill = Survived), position=\"fill\"))\nmultiplot(g1, g2, cols=2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"22948d59-2d23-4b86-9aa3-2bf0136f0bec","_uuid":"82652b8bdc3150fefdb4b450db23ff56b7a1addb"},"cell_type":"markdown","source":"At the first glance, survival rate among embarked location seems for be fair balanced, with a bonus for Cherbourg.\n\nEven not really huge, why this higher value for Cherbourg? From our common sense, it seems not relevant that where the passenger came from have an impact on their survival rate. To  remove doubt on a possible derivative effect, we perform here an additional visualization by exploding the first graph by the passenger class of embarked people."},{"metadata":{"_cell_guid":"8db97451-654f-4d1f-a778-b75a6a755a24","_uuid":"d9b8873d87ac555a4dce20a523aaf3b75ac6860d","trusted":false},"cell_type":"code","source":"ggplot(titanic_train) + geom_bar(aes(Pclass, fill = Survived)) + facet_wrap(~ Embarked)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a6dbfb5b-2493-4576-8e4f-9e7602f54eaa","_uuid":"630c970d147b5857082a2a4fa508c050d0638789"},"cell_type":"markdown","source":"Third-class passenger was the larger population in the Titanic and the group with the lower survival rate. But at Cherbourg, unlike at other departure ports, the most represented class was the first class. This explains why Cherbourg has a slightly better score on the previous analysis.\n\n### Number of parents or children aboard\n\nWe now exploit the feature that tells us how many parents and children the passenger has in the Titanic with him/her."},{"metadata":{"_cell_guid":"3609fc7c-79c0-419c-a156-5fa538800179","_uuid":"4e5efda87c1c347f4df73e771d276378aacf1516","trusted":false},"cell_type":"code","source":"g1 <- ggplot(titanic_train) + geom_bar(aes(Parch, fill = Survived))\ng2 <- add_mSurv(ggplot(titanic_train) + geom_bar(aes(Parch, fill = Survived), position=\"fill\"))\nmultiplot(g1, g2, cols=2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d33907c7-3b43-450c-b3c8-0bc2a869a481","_uuid":"8d9ebc9b50a32a839168d6dccfcd173dfb53bce1"},"cell_type":"markdown","source":"The small size of the larger groups (>2) very strongly limits the observations we can make on them, but it appears a slightly better chance for survival for people with parents or children aboard.\n\nBut this may not be an independent feature. The survival rate related to the number of parents and children aboard might be linked to the nature of the passenger involved in this family relation. We already know that being a child or a women increase survival rate. This can be related to what we observe here. To discover this, let's have a look at the age and gender of passengers whom have at lease one parent or child on the boat."},{"metadata":{"_cell_guid":"3541c0bd-7fc4-4ff2-8b36-e29de1de65b5","_uuid":"996c0dd40f9f7167f38237eed86bb91c1d24814f","trusted":false},"cell_type":"code","source":"ggplot(filter(titanic_train, Parch > 0)) + geom_histogram(aes(Age, fill = Survived), binwidth = 5, na.rm=TRUE) + facet_grid(Parch ~ Sex)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a19b3f8d-c0db-4cc8-80b9-bebf14b90b89","_uuid":"cf584165db7b92eed470d816697e02bd054b8f59"},"cell_type":"markdown","source":"As expected below, survivors with parents or children aboard are mainly women (which include mothers) or young men (boys).\n\nThis feature behavior is so directly related to what we observed with age and gender features.\n\n### Number of siblings or spouses aboard\n\nLike parents and children, we perform here the same visualization with siblings or spouses."},{"metadata":{"_cell_guid":"4879c82e-7a23-4c93-8dbd-d8c919b6672c","_uuid":"b2ce67b399cb54663419c64fce60864192c26abe","trusted":false},"cell_type":"code","source":"g1 <- ggplot(titanic_train) + geom_bar(aes(SibSp, fill = Survived))\ng2 <- add_mSurv(ggplot(titanic_train) + geom_bar(aes(SibSp, fill = Survived), position=\"fill\"))\nmultiplot(g1, g2, cols=2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f7384485-c909-4f97-b256-630d617671a2","_uuid":"220dce886ef9ecc58fdebe6c1460646a86aab022"},"cell_type":"markdown","source":"This exposes mostly the same patern than for parents and children.\n\nWe perform then the same cross-visualization than before."},{"metadata":{"_cell_guid":"c574aa05-1dc6-42cc-a19a-e341babcb973","_uuid":"4e086140242e3800ee5cee03b1bd506ce947343d","trusted":false},"cell_type":"code","source":"ggplot(filter(titanic_train, SibSp > 0)) + geom_histogram(aes(Age, fill = Survived), binwidth = 5, na.rm=TRUE) + facet_grid(SibSp ~ Sex)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"74a30c85-173f-4c57-bbf6-f63bd33d1d0b","_uuid":"54b853d0cd9c7216268d373dc465dc1db69b4e4b"},"cell_type":"markdown","source":"This time, the resulting pattern seems most driven by the general previous seen influence of age and gender, rather than by the number of siblings (we assume the part of \"spouses\" in this number is limited to 1). With the exception of young boys with 3 siblings or more, which seems not more taking benefits of their age group, as observed before. However, the small number of passengers involved limits the observation.\n\n## Features we can add\nBased on the previously introduced features exposed by the dataset, we can now engineered few others, in order to get a higher confidence in our incoming previsions. More precisely, our goal is not to increase the number of features (making the guess computation even more combinatorial) but to redefine some of them, making them more accurate.\n\n### Family on board\nAs we observe similar patterns with parents and siblings, we want to generalize the feature of family, meaning the number of relatives the passenger has on board."},{"metadata":{"_cell_guid":"1a8d029d-65b2-4535-b371-2a16e1aa70d7","_uuid":"73238096ef3d44331fc73d802268b31bf99aea5c","trusted":false},"cell_type":"code","source":"titanic_train$FamilyOnBoard <- titanic_train$Parch + titanic_train$SibSp\ng1 <- ggplot(titanic_train) + geom_bar(aes(FamilyOnBoard, fill = Survived))\ng2 <- add_mSurv(ggplot(titanic_train) + geom_bar(aes(FamilyOnBoard, fill = Survived), position=\"fill\"))\nmultiplot(g1, g2, cols=2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6ce35e95-2fbf-4f68-b087-b2c50f711d55","_uuid":"8b062ecaf9bbf736aa21ff7bc5af8e162ec39fec"},"cell_type":"markdown","source":"We note here that there is a visible benefit for small families (up to 3 relatives on board with the passenger) and a penalty otherwise.\n\nThen we define our new feature, `family`, with as possible value: \"single\" (single passenger), \"small\" (up to 3 relatives on board) and \"large\" (more than 3 relatives on board)."},{"metadata":{"_cell_guid":"9423166c-280a-41c5-a04a-ca66bb62f91b","_uuid":"95446c519962b09aa5630fce1f6ee119fb3366cc","trusted":false},"cell_type":"code","source":"titanic_train$Family[(titanic_train$Parch + titanic_train$SibSp) == 0] <- \"single\"\ntitanic_train$Family[(titanic_train$Parch + titanic_train$SibSp) > 0 & (titanic_train$Parch + titanic_train$SibSp) < 4] <- \"small\"\ntitanic_train$Family[(titanic_train$Parch + titanic_train$SibSp) > 3] <- \"large\"\ntitanic_train$Family = as.factor(titanic_train$Family)\ntitanic_train$Family = factor(titanic_train$Family, levels = c(\"single\",\"small\",\"large\")) # ordering\ng1 <- ggplot(titanic_train) + geom_bar(aes(Family, fill = Survived))\ng2 <- add_mSurv(ggplot(titanic_train) + geom_bar(aes(Family, fill = Survived), position=\"fill\"))\nmultiplot(g1, g2, cols=2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"54843f61-c45b-4ffe-aca7-18e69b788587","_uuid":"3170dab217637656f388d233bc02ac4b337bf795"},"cell_type":"markdown","source":"### Individual Fare\nAn interesting thing we can observe, when crawling the data, is that every passenger who shares the same ticket as another, he always has the same `Fare` value. Here are few examples:"},{"metadata":{"_cell_guid":"ca2a0958-6201-4804-b46b-072f72566c25","_uuid":"d31de19e8687288c5c21bbf4d62c07f9f0765d0f","trusted":false},"cell_type":"code","source":"filter(titanic, Ticket == \"PC 17599\")$Fare\nfilter(titanic, Ticket == \"19950\")$Fare\nfilter(titanic, Ticket == \"3101295\")$Fare","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4624b21d-f56f-445a-9e7f-8c79c8bfb881","_uuid":"52df425084a16dcc570a4d98d08fb48a93ab5507"},"cell_type":"markdown","source":"In these circumstances, we can seriously think that the displayed fare is the cost of the ticket, meaning the shared fare for all related passenger. Another clue we can obtain is a Pearson correlation between the class and the fare: "},{"metadata":{"_cell_guid":"ac8113d9-77f9-4a56-a1e2-66221e39c6d9","_uuid":"d4f6243bc1a61864e08a5cc4b34c7980589864d2","trusted":false},"cell_type":"code","source":"cor(filter(titanic, !is.na(Fare))[,c('Pclass','Fare')])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d5707ac7-ff17-4680-93e1-a8892cbfe21e","_uuid":"f9e4e474c1188b0fd4bc02d416bdc2979764abdf"},"cell_type":"markdown","source":"As we assume that the current `Fare` is related to the `Ticket` and not to the passenger, we compute the fare per person, by counting how many people share the same ticket, and divide the fare of each passenger per the number of people on his/her ticket."},{"metadata":{"_cell_guid":"1a954ac5-a233-432f-82fd-066be3cf9fd6","_uuid":"4799520e8de3df60200945f57bacee468461ce11","trusted":false},"cell_type":"code","source":"pplOnTicket <- setNames(aggregate(titanic$Ticket,list(titanic$Ticket),length), c(\"Ticket\",\"PplOnTicket\"))\ntitanic <- left_join(titanic,pplOnTicket,by=\"Ticket\")\ntitanic['FarePerson'] <- titanic$Fare / titanic$PplOnTicket","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4d4087cc-483b-4d89-8c98-04ffb6e9ab3b","_uuid":"2469788629c27178dd8696d98ffcd87811563844"},"cell_type":"markdown","source":"If we are right, we should observe an improvment of the correlation:"},{"metadata":{"_cell_guid":"22b97ba9-798e-48d9-afc0-1392ce75d9e4","_uuid":"b410bf5b9f435883b94e918a42396dd20b786005","trusted":false},"cell_type":"code","source":"cor(filter(titanic, !is.na(FarePerson))[,c('Pclass','FarePerson')])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6201a7e4-cb7b-4660-9a53-027d5acf6f6a","_uuid":"2d39263ab6cee6f8516316e6e9f4ce23256488fb"},"cell_type":"markdown","source":"That's it! So we now use `FarePerson` rather than `Fare` in our computations.\n\n# Missing values\nBefore starting our predictions, we wish, if possible, to fill every missing data values in the dataset."},{"metadata":{"_kg_hide-input":true,"_cell_guid":"6545de7d-262f-409d-91e9-51489cbce7a2","_uuid":"5285f26caf75d0e59195c03da82f36fb798354cf","trusted":false},"cell_type":"code","source":"# apply Family on full set\ntitanic$Family[(titanic$Parch + titanic$SibSp) == 0] <- \"single\"\ntitanic$Family[(titanic$Parch + titanic$SibSp) > 0 & (titanic$Parch + titanic$SibSp) < 4] <- \"small\"\ntitanic$Family[(titanic$Parch + titanic$SibSp) > 3] <- \"large\"\ntitanic$Family = factor(titanic$Family, levels = c(\"single\",\"small\",\"large\")) # ordering","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f6bcbf97-277f-4f23-bd76-f7d566dbdbad","_uuid":"811cff6300cc8bfb4d192d45229550cbfc7620cc"},"cell_type":"markdown","source":"Let's have a look on missing values:"},{"metadata":{"_cell_guid":"9292f1aa-0e12-4b41-a0e2-e35596d12f07","_uuid":"de6c4c63e0b712f2b193c61623d6fdc9af2c84df","trusted":false},"cell_type":"code","source":"sapply (titanic, function (x) sum (is.na (x) | x == \"\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9dc6bbf4-6bc9-48de-a412-d3b4fcdeac8b","_uuid":"6963cb75fd63802ca81a1af7ce197766a4d44193"},"cell_type":"markdown","source":"First of all, 418 `Survived` values are missing. This is the test set and of course, we will not try to fill it right here: this is the job of the prediction task, our step.\n\nOn the other hand, with 1014 missing values on `Cabin` over 1309 passengers, we can't deduce anything to fill this feature and use it on the prediction step. So, we choose to ignore this feature for all passengers.\n\nRemaing data to fill are: 1 `Fare` (and 1 related `FarePerson`), 2 `Embarked` and 263 `Age`.\n\n## Fare\nOny 1 `Fare` is missing. Let's have a look on this passenger:"},{"metadata":{"_cell_guid":"59fa0a39-95e5-401f-ba73-cb2795a4a0a8","_uuid":"fb548bf076a772a68385a55a87e6d5aed3e68438","trusted":false},"cell_type":"code","source":"filter(titanic, is.na(Fare))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ccb59d6c-d622-436f-a7e2-a87d4062f171","_uuid":"96003310f98acb1ee178a3035bdd33f7c5d20cb3"},"cell_type":"markdown","source":"This passenger, who is on board with no family, as a third class ticket and embarked in Southampton. Let's see how many have paid the passengers in the same situation:"},{"metadata":{"_cell_guid":"8d7c1d8d-1207-414f-a67b-64b9ffb8b96a","_uuid":"a51f29a1d51f711bc3f8d54cf3336034eed902c1","trusted":false},"cell_type":"code","source":"median(filter(titanic, Family==\"single\", Pclass==3, Embarked==\"S\")$Fare, na.rm=TRUE)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dcd767c8-d7f5-4d3d-b7d7-1bc4b6775fc9","_uuid":"e7f3b508d650cb53f57f3bb1bb22c68e3ef4ede7"},"cell_type":"markdown","source":"So, we assume that this mean (really close to the default Titanic third class ticket fare: 8Â£), is the _most probable_ fare of the passenger, and fill his own `Fare` with it."},{"metadata":{"_cell_guid":"57439ee4-5882-456a-a136-b69f7b25e7b4","_uuid":"e63a33d67d69651654e082a6582c4720dce3e036","trusted":false},"cell_type":"code","source":"titanic$Fare[1044] <- median(filter(titanic, Family==\"single\", Pclass==3, Embarked==\"S\")$Fare, na.rm=TRUE)\ntitanic$FarePerson[1044] <- titanic$Fare[1044]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1baf2dc0-ca3c-422e-8595-3284dd9e0645","_uuid":"4165268791c84425836ad8c190f6e283cf43714b"},"cell_type":"markdown","source":"## Embarked\nLet's see who doesn't remember from where they came:"},{"metadata":{"_cell_guid":"bf495f79-75a2-4cc9-b17e-88060d6ccc3f","_uuid":"c1497752b1c8cb1d4367f091673aac96981b4940","trusted":false},"cell_type":"code","source":"filter(titanic, Embarked == \"\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79afe832-2982-4c6d-afad-db9d40e51312","_uuid":"d8ce069e8980dee415a283468f51f1f02593f9b6"},"cell_type":"markdown","source":"Here we got two ladies, not from the same family, but sharing the same ticket and the same cabin in first class. We can assume, with reasonable confidence level, she might have embarked from the same port.\n\nIf most of first class passengers have embarked from Southampton, it is not enough to conclude for these two passengers. We use an additional parameters, the fare per person they paid: 40$. Let's see the distribution of the individual fare among ports: "},{"metadata":{"_cell_guid":"38245194-7a16-415c-93f4-9563a153ff28","_uuid":"e0db700f14a0ca5f76c889c8a17e91f95faba214","trusted":false},"cell_type":"code","source":"ggplot(filter(titanic, Embarked!=\"\")) + geom_boxplot(aes(Embarked, FarePerson,color=Embarked), na.rm = TRUE) + geom_hline(yintercept=40, colour='darkred')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"04c85b89-542e-402e-9318-327d4ca638c4","_uuid":"14997caa221bcfcc00f9fda94fbd8b0b291f2b43"},"cell_type":"markdown","source":"The Fare of these two passengers, 40, are part of the extreme values for the ports of Queenstown and Southampton. However, it is part of the fourth quartile of Cherbourg and quite close of the third and the median.\n\nBased on these observations, we assign with reasonable confidence, Cherbourg as departure port for these two passengers."},{"metadata":{"_cell_guid":"d455491f-5e28-48b9-b4bc-667eb7fa46a2","_uuid":"357bdf303a99d5be999f6dcdc656cd51c8ef8ed7","trusted":false},"cell_type":"code","source":"titanic$Embarked[titanic$Embarked == \"\"] <- \"C\"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0baf9038-97f6-4124-ad4f-7ce659efa572","_uuid":"ed8fe70e546485999deae51302ba42015f02752a"},"cell_type":"markdown","source":"## Age\nDue to the quite large number of missing `Age` values, we predict them using the other variables and a decision tree model with the analysis of variance."},{"metadata":{"_cell_guid":"5c539666-6852-43b1-adcf-8184dca1d3b1","_uuid":"32e4022bf3f984284094929aea372434cb481403","trusted":false},"cell_type":"code","source":"predicted_ages <- rpart(Age ~ Pclass + Sex + Family + FarePerson + Embarked, data = filter(titanic, !is.na(Age)))\ntitanic$Age[is.na(titanic$Age)] <- predict(predicted_ages,filter(titanic, is.na(Age)))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"94f08d4c-0adb-4de7-8df5-32c45b86c12c","_uuid":"c8848b3a768ac1b5b2a86b34c63afe4cb1c81c8b"},"cell_type":"markdown","source":"It is important to notice that, by acting like this, we don't pretend do discover the \"real\" missing values of the passenger's ages. By using variance analysis based decision tree, we aim to fill the value by minimizing the impact of this filling on the whole row behavior. Another simple solution to achieve this is to fill the missing values with the mean of available ages.\n\n# Prediction\nWe shall now implement some statistical methods to generate models that predicts whether a passenger survives or not.\n\nBut right before, let's add an additional step of visualization.\n\n## Correlation\nWithout direct impact on our statistical implementation, we want produce a graphical display a correlation matrix among available features.\n\nPositive correlations are displayed in blue and negative correlations in red color. Color intensity and the size of the circle are proportional to the correlation coefficients.\n\nIn order to produce this render, we temporarily assign numerical values to all involved fields: "},{"metadata":{"_cell_guid":"d2ba82b7-95f4-4e4e-a71a-a7f2eb318438","_uuid":"1754981e0cafbbca07999d6e9ba4b434f872b9a2","trusted":false},"cell_type":"code","source":"corr <- select(titanic, -Ticket, -Fare, -Cabin, -Name, -Family)\ncorr$Sex <- as.numeric(revalue(corr$Sex, c(\"male\"=1, \"female\" = 2)))\ncorr$Embarked <- as.numeric(revalue(corr$Embarked, c(\"S\" = 1, \"C\" = 2, \"Q\" = 3)))\ncorr$Survived <- as.numeric(corr$Survived)\ncorr$Pclass <- as.numeric(corr$Pclass)\ncorr$PplOnTicket <- as.numeric(corr$PplOnTicket)\ncorr$FamilySize <- as.numeric(corr$SibSp+corr$Parch+1)\ncorr <- select(corr, -SibSp, -Parch)\ncorrplot(cor(corr),method=\"circle\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b17bcbdb-1fde-4d06-a5c7-f374a776aa1e","_uuid":"34b7b259a39661df4135f9a7c2ee2e3ff4533588"},"cell_type":"markdown","source":"Several correlations can be read here:\n* It is obvious that `PassengerID` have no role to play here, which is logical because this field is just an index of the dataset, not linked to any real data.\n* The important negative correlation between `FarePerson` and `Pclass` is quite normal, for obvious reasons.\n* We got a high correlation between `FamilySize` and `pplOnTicket`, which means that families often come on board with the same ticket, which is quite logical as well.\n* Some significant correlations are seen between `Age` and the features `Pclass` or `FarePerson`. Among all passengers, older people tends to buy slightly higher quality place than the yougner ones. This is consistent with the average standard of living throughout life.\n\nWithout revealing a hidden mystery, this correlation matrix illustrates some links that make sense. This validates the consistency of the data and its plausibility.\n\nIf we draw the matrix restricted to the train data:"},{"metadata":{"_cell_guid":"bb9847d5-33d0-4f14-889c-5b51332b0a33","_uuid":"9f284d930674e3867fd5384e85fc1919d025941b","trusted":false},"cell_type":"code","source":"corrplot(cor(filter(subset(corr,select=-PassengerId),!is.na(Survived))),method=\"circle\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3a456f03-d0c2-4714-ae78-5dc53036bc8f","_uuid":"17b2d196e7910c0bf9ebac471b6ab686a279426f"},"cell_type":"markdown","source":"We can see the relative prevalence seen before, like `Sex` and `Pclass` have on `Survived`.\n\n\n## Cleaning and formula\nWe clean the data set and select the features for the prediction formula.\n\nThese features are:\n\n**Variable Name** |  **Type**   | **Description**\n--------------|---------|-------------\nSurvived      | Factor  | 1 if the passenger has survived, 0 otherwise\nPclass        | Factor  | The passenger's class, from 1 to 3\nSex           | Factor  | The passenger's sex, \"male\" or \"female\"\nAge           | Float   | The passenger's age\nFarePerson    | Float   | The passenger's individual fare\nFamily        | Factor  | The passenger's family size on board: single, small or large\nPplOnTicket   | Integer | The number of people on passenger's ticket\nEmbarked      | Factor  | The port of embarkation: S, C or Q\n\nThe prediction formula is expressed as `Survived ~ Pclass + Sex + Age + Embarked + PplOnTicket + FarePerson + Family`\n"},{"metadata":{"_cell_guid":"0d54772b-fd98-4686-81b2-a863a82f6688","_uuid":"0b604993b93308a6fe0ea991a769295548ee2892","trusted":false},"cell_type":"code","source":"titanic <- select(titanic, -SibSp, -Parch, -Ticket, -Fare, -Cabin, -Name)\ntitanic$Survived <- as.factor(titanic$Survived)\ntitanic$Embarked <- as.factor(titanic$Embarked)\ntitanic$Sex <- as.factor(titanic$Sex)\ntitanic$Age <- as.numeric(titanic$Age)\ntitanic$Pclass <- as.factor(titanic$Pclass)\ntitanic$PplOnTicket <- as.integer(titanic$PplOnTicket)\ntitanic$FarePerson <- as.numeric(titanic$FarePerson)\ntitanic$Family <- as.factor(titanic$Family)\ntitanic_train <- filter(titanic, !is.na(Survived))\ntitanic_test <- filter(titanic, is.na(Survived))\ntitanic_formula <- (Survived ~ Pclass + Sex + Age + Embarked + PplOnTicket + FarePerson + Family)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4b7133f7-76a9-4e7c-98a2-c3bf409dbc4e","_uuid":"8125c8eb941a309fe1394a8995d7acfc46686b79"},"cell_type":"markdown","source":"## Testset validation\nIn order to pre-evaluate our prediction, we split the training set in a training set and a test set, with balanced 70% and 30% of the original training set."},{"metadata":{"_cell_guid":"6678bc9a-bcaf-4ae5-8433-255a47b5f7e9","_uuid":"ca0cb413cef0d404b974391cf41d99e3a003c2be","trusted":false},"cell_type":"code","source":"spec <- c(train = .7, test = .3)\ng <- sample(cut(\n  seq(nrow(titanic_train)),\n  nrow(titanic_train)*cumsum(c(0,spec)),\n  labels = names(spec)\n))\nmy_titanic <- split(titanic_train, g)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"87949b70-d80f-4ef4-876e-ac709b06154f","_uuid":"629b136e6448d0f8795aa645ef6a8b648280070c"},"cell_type":"markdown","source":"We now test 3 usual statistical methods on this set: Decision Tree, Random Forest and Support Vector Machine.\n\n### Decision Tree\nDecision tree is a popular tool in machine learning. It is a a flowchart-like structure in which each internal node represents a \"test\" on an attribute, each branch represents the outcome of the test, and each leaf node represents a class label. The paths from root to leaf represent classification rules.\n\nWe define a decision tree based on our formula. Then we produce a visual representation of the x-val relative error given the tree complexity."},{"metadata":{"_cell_guid":"74d07780-3871-4bcb-bd4a-bd6e9cd53473","_uuid":"a893e0c177f979c8005efd76511f1980a1c437c6","trusted":false},"cell_type":"code","source":"my_titanic_tree <- rpart(titanic_formula,data=my_titanic$train,control=rpart.control(minsplit=5,cp=0))\nplotcp(my_titanic_tree)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"240d24b6-4992-4e0a-8812-3c339d11f707","_uuid":"1187f5eb86d1a15a29ac19dab09cd2e04c5088ad"},"cell_type":"markdown","source":"\nThen, we compute an optimal tree, which minimize the measured error. After that, we print the decision tree (The optimal level can't be named here, as it is train set cut dependent, which changes at each run of the notebook)."},{"metadata":{"_cell_guid":"5267ee4c-f2e1-4382-bf7e-991f5898f5c5","_uuid":"90a733572d5b5ec0cdbbebd544879bd22b4ea117","trusted":false},"cell_type":"code","source":"my_titanic_tree_optimal <- prune(my_titanic_tree,cp=my_titanic_tree$cptable[which.min(my_titanic_tree$cptable[,4]),1])\nprp(my_titanic_tree_optimal,extra=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9e76e133-687e-4051-8460-233850a60f3d","_uuid":"8a315498854ae70d7a7d6e50532908b8735982c1"},"cell_type":"markdown","source":"Using our test set, we predict survived values, and compare them with the ground true (as our test set is in fact a part of the official train set and has `Survived` values).\n\nFinally, we print the score of the prediction."},{"metadata":{"_cell_guid":"1a06c261-370a-4971-831b-4515fa220d24","_uuid":"044a4ffe89f9b94005484b58eba8454b796dc1cb","trusted":false},"cell_type":"code","source":"isCorrect <- predict(my_titanic_tree_optimal,newdata=my_titanic$test,type=\"class\") == my_titanic$test$Survived\ndt_score <- sum(isCorrect)/length(isCorrect)\ndt_score","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"07308c9d-88b3-4a8e-b3e2-1fa62e6df28f","_uuid":"72abed41e7838810b836e19552bdd98b13affe1f"},"cell_type":"markdown","source":"As said right above, this score varies at each run. However, it often stay around between 80 and 85%.\n\nNow, let's compute Decision Tree on the full train data:"},{"metadata":{"_cell_guid":"c166e6f5-8bab-49c3-82d5-160cd8e37c84","_uuid":"f7405941017918afbcb2c712de4a364b84387ace","trusted":false},"cell_type":"code","source":"titanic_tree <- rpart(titanic_formula,data=titanic_train,control=rpart.control(minsplit=5,cp=0))\nplotcp(titanic_tree)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"26d29049-4606-4a5c-9266-a0499673742e","_uuid":"2cc489a2add11dd7ba9b50b80bcb328a575e887b","trusted":false},"cell_type":"code","source":"titanic_tree_optimal <- prune(titanic_tree,cp=titanic_tree$cptable[which.min(titanic_tree$cptable[,4]),1])\nprp(titanic_tree_optimal,extra=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"77136576-80a5-429e-9dbc-ed9eab0ef555","_uuid":"44f0b2ce7c15b08815781052c3ce67608ca36d2f"},"cell_type":"markdown","source":"The reading of the extreme branches is quite coherent: being a women on first and second class often insure survival, being an adult male with low fare often conduct to death.\n\n### Random Forest\nThe random forest is a method that operate by constructing a multitude of decision trees at training time and outputting the mean prediction of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set.\n\nAfter having initialized the random generator (with a disaster date, why not?), we build a random forest over our formula, and plot the related error rates."},{"metadata":{"_cell_guid":"f07f1ab6-5ade-4b31-b960-d4f5b04925cc","_uuid":"3eb794f0200d50ddd6569a7fbac12594513e3ed0","trusted":false},"cell_type":"code","source":"set.seed(19150415)\nmy_titanic_rf <- randomForest(titanic_formula, data = my_titanic$train)\nplot(my_titanic_rf, ylim=c(0,0.4))\nlegend('topright', colnames(my_titanic_rf$err.rate), col=1:3, fill=1:3)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3a40e1db-68ab-4b7e-af6d-1d8d46f31d9f","_uuid":"2b656c8ff900ae54d1c7ba27db3228dcbbb352d3"},"cell_type":"markdown","source":"Red line is the error on death prediction, green on survival, and black overall.\n\nUnlike Decision Tree method, we can't print a single tree to explain the model, but we can measure the importance of each feature among all involved trees."},{"metadata":{"_cell_guid":"4e1ccffe-8fb7-469d-aabf-b88192fcfd37","_uuid":"8629be1d98bf3dd2a1fb7d733631ba80c5446138","trusted":false},"cell_type":"code","source":"my_titanic_rf_importance <- importance(my_titanic_rf)\nvars_importance <- data.frame(Variables = row.names(my_titanic_rf_importance), importance = round(my_titanic_rf_importance[,'MeanDecreaseGini'],2))\nggplot(vars_importance, aes(fill = importance)) + geom_bar(aes(reorder(Variables,importance),importance), stat = \"identity\") + coord_flip()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c0317657-94f7-403f-bad4-db4fde5579d4","_uuid":"6259da4b3b1cb7172f12cb2a28bc4c109601ceed"},"cell_type":"markdown","source":"We retrieve the same feature behavior than before, with a huge importance of gender, price paid and age.\n\nWe now compute the Random Forest score on our splitted dataset:"},{"metadata":{"_cell_guid":"e1f3890a-47e9-4758-b8fa-d65da017c389","_uuid":"3cb4eac712b595c70d1eb1315f664d6a592d3e8f","trusted":false},"cell_type":"code","source":"isCorrect <- predict(my_titanic_rf,newdata=my_titanic$test,type=\"class\") == my_titanic$test$Survived\nrf_score <- sum(isCorrect)/length(isCorrect)\nrf_score","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"23591081-72fe-4693-aed2-495d01d44daa","_uuid":"7c5ae426a0003ff9ed9d7da6e13bc6501cfd0f11"},"cell_type":"markdown","source":"Like before, we compute the same method on the full dataset."},{"metadata":{"_cell_guid":"477f71a7-a92b-4852-9d7a-8ce76592c483","_uuid":"3c86dee4b375760a135f62778a05686d485b2b2a","trusted":false},"cell_type":"code","source":"set.seed(19150415)\ntitanic_rf <- randomForest(titanic_formula, data = titanic_train)\nplot(titanic_rf)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1ede2ae6-4402-44dc-893a-5c0ea4a9d1e0","_uuid":"6494d370e52f70fa119bf6d69c7a113d074ecc60","trusted":false},"cell_type":"code","source":"titanic_rf_importance <- importance(titanic_rf)\nvars_importance <- data.frame(Variables = row.names(titanic_rf_importance), importance = round(titanic_rf_importance[,'MeanDecreaseGini'],2))\nggplot(vars_importance, aes(fill = importance)) + geom_bar(aes(reorder(Variables,importance),importance), stat = \"identity\") + coord_flip()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3e801e30-0ab0-48e2-95ef-e969f3740257","_uuid":"72da5d52b4d43a7264975275f59d11f1662305e9"},"cell_type":"markdown","source":"### Support vector machine\nGiven a set of training example, a support vector machine training algorithm builds a model that assigns new examples to one category or the other (here, survival or not), making it a non-probabilistic binary linear classifier. An SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible.\n\nLike previous methods, we apply a SVM to our splitted dataset and compute its score. "},{"metadata":{"_cell_guid":"622e0ebf-d449-4c6f-ba55-7ec26ec0ecf0","_uuid":"286a01392359060df461750ad0ee1b5b26aca588","trusted":false},"cell_type":"code","source":"svm_model <- svm(titanic_formula, data=my_titanic$train)\nisCorrect <- predict(svm_model,newdata=my_titanic$test,type=\"class\") == my_titanic$test$Survived\nsvm_score <- sum(isCorrect)/length(isCorrect)\nsvm_score","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1e998be9-547c-415b-aaa1-743966b42b05","_uuid":"745175e63f9f4d535d7fb52ebc2e8b08c6f7e1bf"},"cell_type":"markdown","source":"### Comparison\n\nWe now compare the three score produced by the three presented method. "},{"metadata":{"_cell_guid":"06623309-a142-4e88-83be-58eacbc3db50","_uuid":"bf05f7e27067aa4f6547c3ce5bf6e774f8c87d2d","trusted":false},"cell_type":"code","source":"data.frame(Method=c(\"Decision Tree\",\"Random Forest\",\"Support Vector Machine\"),Score=c(dt_score,rf_score,svm_score))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"30c97e6f-e837-457b-af2b-c5bc22dd7c92","_uuid":"3738bafed8b2883a85902d56f9f36c61afd316c4"},"cell_type":"markdown","source":"As said before, these exact results change every time the notebook is run, due to the random split made in the dataset to produce a test set with solution values. However, values often fit between `0.8` and  `0.88`, with a slight lead for Random Forest.\n\nBut if we want to choose one of these methods to predict the test set of the full dataset, we should rely of a most reliable measurement than just one run of each algorithm.\n\n## K-fold cross-validation\nThe get a more precise computation, we run multiple K-fold cross-validation.\n\nOne round of cross-validation involves partitioning a sample of data into complementary subsets, performing the analysis on one subset (the training set), and validating the analysis on the other subset (the testing set). To reduce variability, multiple rounds of cross-validation are performed using different partitions, and the validation results are combined over the rounds to estimate a final predictive model.\n\nMultiple fold splits are runs, with 2, 4, 6, 8 and 10 folds. At each split in `k` folds, `k-1` folds are used as training sets and the remaining one as a test set. The mean is then used for this k-fold.\n\nWe run all of these simulations, and plot the resulting graph:"},{"metadata":{"_cell_guid":"be499d11-5d84-4b91-962c-6aadc26c607f","_uuid":"f068fa7032752a4706e90ac95bf6df0a12b9f9a0","trusted":false},"cell_type":"code","source":"# Score a model\nscore <- function(model, vData) {\n  isCorrect <- predict(model,newdata=vData,type=\"class\") == vData$Survived\n  score <- sum(isCorrect)/length(isCorrect)\n  return(score)\n}\n# Get scores for the 3 methods\ngetScores <- function(formula,tData,vData) {\n  tree <- rpart(formula,data=tData,control=rpart.control(minsplit=5,cp=0))\n  tree_model <- prune(tree,cp=tree$cptable[which.min(tree$cptable[,4]),1])\n  tree_score <- score(tree_model, vData)\n \n  rf_model <- randomForest(formula, data = tData)\n  rf_score <- score(rf_model, vData)\n \n  svm_model <- svm(formula, data=tData)\n  svm_score <- score(svm_model, vData)\n \n  return (data.frame(DecisionTree=tree_score, RandomForest=rf_score, SVM=svm_score))\n}\n\nvalidation <- data.frame()\nfor (n in seq(2,10,by=2)) {\n  folds <- split(titanic_train, cut(sample(1:nrow(titanic_train)),10))\n  x <- data.frame()\n  for (i in 1:length(folds)) {\n   test <- ldply(folds[i], data.frame)\n   train <- ldply(folds[-i], data.frame)\n   x <- rbind(x, getScores(titanic_formula,train,test))\n  }\n  validation <- rbind(validation, data.frame(DecisionTree=mean(x$DecisionTree), RandomForest=mean(x$RandomForest), SVM=mean(x$SVM)))\n}\n  sa <- stack(as.data.frame(validation))\n  sa$x <- rep(seq(2,2*nrow(validation),by=2), ncol(validation))\n\nqplot(x, values, data = sa, colour = ind, geom=\"line\", xlab=\"cross validation folds number\", ylab=\"score\") + labs(colour=\"Methods\") + theme(legend.position = \"bottom\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7fe47036-d971-4703-a5c3-8b13011e63f9","_uuid":"95401c9eebd1fdeee8edb1d25d892db4bd0456c3"},"cell_type":"markdown","source":"All results are really close, between `0.827` and `0.837`.\n\nWithout being exceptional, it is a reasonable score, and above all relatively stable.\n\n\n## Chosen solution\nAlthough all three methods have proven their relative performance equivalence, we choose the Random Forest algorithm to predict over the main dataset. Indeed, this method has a slightly higher overall efficiency on our dataset.\n\nWe aren't able, of course, to compute here the evaluation on the test set. All we can do is the print and comment the computed survival rate on the test set. "},{"metadata":{"_cell_guid":"d90fc609-a80b-4a81-b3a9-e17e528c9621","_uuid":"62ad80739fca8bad31e1502f21a4d03aaab2005e","trusted":false},"cell_type":"code","source":"prediction <- predict(titanic_rf, titanic_test)\nsummary(prediction)/length(prediction)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f3c0f38a-e5c5-41de-93d5-5ecaedc4f029","_uuid":"508defc9b42248e45fa6a52f0fb172550579e1ef"},"cell_type":"markdown","source":"Our random forest application calculates a survival rate of 33.25%, which is lower than on the train game, while remaining plausible.\n\nfinally, we store the computed solution in the requested file format."},{"metadata":{"_cell_guid":"1b0d311c-2354-485d-b807-1591882b0df6","_uuid":"013a4f3ddda3c02f7f4695d2b1e4cc67dd632866","trusted":false},"cell_type":"code","source":"solution <- data.frame(PassengerID = titanic_test$PassengerId, Survived = prediction)\nwrite.csv(solution, file = \"solution.csv\", row.names = FALSE)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cae123b7-c7f8-4fc9-8ba0-7cf97a227da6","_uuid":"28dcd95dd895283f28b4f41dccfa32372453f170"},"cell_type":"markdown","source":"# Conclusion\nthat's it! Thank you sincerely for taking the time to read through my first try on Kaggle. Any comments or suggestions are fully welcomed, and even requested."}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}