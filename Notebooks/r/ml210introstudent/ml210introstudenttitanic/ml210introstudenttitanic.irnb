{"cells":[{"metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"_uuid":"d1714839d05c4fdfee8d0d77c0de1f8a7ea2cab4","_cell_guid":"6dbfc1e9-4305-47e5-815a-91cb48a7b922","_execution_state":"idle","trusted":true},"cell_type":"code","source":"# This R environment comes with all of CRAN preinstalled, as well as many other helpful packages\n# The environment is defined by the kaggle/rstats docker image: https://github.com/kaggle/docker-rstats\n# For example, here's several helpful packages to load in \n\nlibrary(ggplot2) # Data visualization\nlibrary(readr) # CSV file I/O, e.g. the read_csv function\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nsystem(\"ls ../input\")\n\n# Any results you write to the current directory are saved as output.\n\n# Model building\n# install.packages(c(\"caret\", \"ggplot2\", \"pROC\", \"data.table\", \"glmnet\", \"randomForest\", \"mice\"))\nlibrary(\"caret\")\nlibrary(\"ggplot2\")\nlibrary(\"pROC\")\nlibrary(\"data.table\")\nlibrary(\"glmnet\")\nlibrary(\"randomForest\")\n\n# Final prediction (for scoring the output):\nfinal = T\ngetwd()\n\nsetwd(\"input/\")\n# Set it to the directory with the data\nd <- fread(\"train.csv\", stringsAsFactors=F)\n\n# This is to ensure that we have the same pipeline regardless whether \n# we build final model or \nif (final) {\n  d.test <- fread(\"test.csv\", stringsAsFactors=F)\n  d.test$Survived <- NA\n  d.test <- d.test[,names(d), with=F]\n  d <- rbind(d, d.test)\n  # y will be the output variable that will also denote \n  # Train / test split\n  # Train has label, Test is 'NA'\n  d$y.orig = d$Survived\n  d$y = d$y.orig\n} else {\n  # Set seed to make sure that results are reproducible\n  set.seed(123)       \n  ratio.train = 0.7  # 70% in train\n  d$y.orig = d$Survived\n  d$y <- ifelse(runif(nrow(d))<ratio.train, d$y.orig, NA)\n}\n\n# Basic feature fixing\nd[,Embarked:=factor(Embarked)]\n# Above is (almost) the same as:\n# d$Embarked <- factor(Embarked)\nd[,Pclass:=factor(Pclass)]\nd[,IsFemale:=as.integer(d$Sex==\"female\")]\n\n# Check who still has na's\nsapply(d, function(x) {sum(is.na(x))})\n\n# Do feature engineering \n# Usually do it in the same data.frame, to reduce errors associated \n# with forgeting to perform the engineering in the same way on test set\n#\n\n# Missing value treatment:\n\n# Median substitution for missing Embarked\nd$Embarked[d$Embarked==\"\"] <- \"S\"\nd[,Embarked:=factor(d$Embarked)]\n\n# Fare is na in test set\nd[,Fare:=ifelse(is.na(Fare), median(Fare, na.rm=T), Fare)]\n\n# MICE for Age\nlibrary(mice)\nimp.dt <- d[,c(\"y\", \"Age\", \"Fare\",\"Embarked\", \"IsFemale\", \"Pclass\"), with=F]\nimp.m <- matrix(0, 6,6); imp.m[2,2:6] <- 1\nAge.imp <- mice(imp.dt, print=F, seed=123, predictorMatrix=imp.m)\nsummary(Age.imp)\n\nfit <- glm.mids(y~., data=Age.imp, family = binomial)\n#summary(fit)\nsummary(pool(fit))\n\nd[,Age.Mice:=complete(Age.imp)$Age]\n\n# Slide: Basic Model \n\n# NOTE: This is just 'for fun', before we start doing real modelling\nif(!final){\n  # Train / test split\n  X.col <- c(\"y\", \"Pclass\", \"Age.Mice\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"IsFemale\")\n  X.train <- d[!is.na(y),X.col, with=F]\n  y.train <- d[!is.na(y),y]\n  X.test <- d[is.na(y),X.col, with=F]\n  y.test <- d[is.na(y),y.orig]\n  \n  fit <- glm(y~., family=binomial, data=X.train)\n  summary(fit)\n  \n  fit.test.prob <- predict(fit, X.test, type=\"response\")\n  fit.test.roc <- roc(y.test, fit.test.prob)\n  fit.test.roc\n  plot(fit.test.roc)\n  table(fit.test.prob>0.5, y.test)\n  confusionMatrix(as.integer(fit.test.prob>0.5), y.test, positive=\"1\")\n  rm(X.train, X.test, y.train, y.test, X.col, fit.test.roc, fit.test.prob)\n}\n\n# Handling categorical variables:\n\n# One-hot encoding of categorical variables and their DRACULA count\n# https://blogs.technet.microsoft.com/machinelearning/2015/02/17/big-learning-made-easy-with-counts/\n# https://docs.microsoft.com/en-us/azure/machine-learning/studio-module-reference/data-transformation-learning-with-counts\n#' @param d - data.table with categorical features\n#' @param feature - feature name \n#' @param output - name / position of output column\n#' @param onehot.min - minimum number of elements for onehot encoding\n#' @param smooth - laplace smoothing value for log-odds\n#' @param count - show count column\n#' @param logodds - show logodds column\n#' @param na.action - what to do, if a feature has NAs\nCategorical2Numerical <- function(d, feature, output, onehot.min=10, smooth=10, count=T, logodds=T, na.action=na.fail) {\n  stopifnot(length(unique(na.omit(d[[output]])))==2) # Not a binary classifer\n  stopifnot(na.omit(unique(d[[output]])) %in% c(0,1)) # Not the right format of the output \n  \n  # One-hot encoding\n  categories.tbl <- table(d[[feature]])\n  categories <- names(categories.tbl)[categories.tbl>=onehot.min]\n  for(cat in categories) {\n    col=paste0(\"Is\", feature, \".\", cat)\n    d[,(col):=na.action(as.integer(d[[feature]]==cat))]\n  }\n  \n  d[,OUTPUT.VAL:=d[[output]]]\n  # Counts of pos / neg\n  if(count) {\n    col.count.pos <- paste0(feature,\".N1\")\n    col.count.neg <- paste0(feature,\".N0\")\n    \n    count.pos <- d[,sum(OUTPUT.VAL, na.rm=T)]\n    count.neg <- d[,sum(1 - OUTPUT.VAL, na.rm=T)]\n    \n    d[,(col.count.pos):=sum(OUTPUT.VAL, na.rm=T), by=feature]\n    d[,(col.count.neg):=sum(1 - OUTPUT.VAL, na.rm=T), by=feature]\n  }\n  \n  # Log Odds\n  if (logodds) {\n    output.prior <- d[,mean(OUTPUT.VAL, na.rm=T)]\n    col <- paste0(feature, \".LogOdds\")\n    d[,(col):=log(sum(OUTPUT.VAL, na.rm=T) + smooth*output.prior) - log(sum(1 - OUTPUT.VAL, na.rm=T) + smooth*(1 - output.prior)), by=feature]\n  }\n  \n  # Remove temporary column\n  d[,OUTPUT.VAL:=NULL]\n  \n  # Note that in data.tables, the values will be updated without reassignment, because data.table is updated by reference\n  invisible(d)\n}\n\nCategorical2Numerical(d, \"Pclass\", \"y\")\nCategorical2Numerical(d, \"SibSp\", \"y\")\nCategorical2Numerical(d, \"Parch\", \"y\")\nCategorical2Numerical(d, \"Embarked\", \"y\")\n\n# Text processing for Name\n\nd$Name.Title <- gsub(\"^.*\\\\s+([A-Z][a-z]+)\\\\.\\\\s+.*$\", \"\\\\1\", d$Name)\nCategorical2Numerical(d, \"Name.Title\", \"y\")\n\nd$Name.Surname <- gsub(\"^(.*?),.*\", \"\\\\1\", d$Name)\nd[,Name.Surname.Count:=.N, by=Name.Surname]\n\nd$Name.HasBrackets <- as.integer(grepl(\"\\\\(\", d$Name))\nd$Name.HasQuotes <- as.integer(grepl('\"', d$Name))\n\n# Further split Age, also taking care of the missing value\nd$AgeCategory <- with(d, ifelse(is.na(Age), \"Missing\", \n                                ifelse(Age<5, \"Toddler\",\n                                       ifelse(Age<12, \"Child\", \n                                              ifelse(Age<18, \"Teen\",\n                                                     ifelse(Age<35, \"YoungAdult\",\n                                                            ifelse(Age<60, \"Adult\", \"Senior\")))))))\nd$Age.IsEstimated <- ifelse(is.na(d$Age), 0, as.integer(d$Age)==d$Age-0.5)\nCategorical2Numerical(d, \"AgeCategory\", \"y\")\n\n\nd[,Ticket.Count:=.N, by=Ticket]\n# Note: Not creating features from Category, but only FirstLetter.\n# This is because Category seems to be too fragmented.\n#d[,Ticket.Category:=gsub(\"[^A-Z]\", \"\", Ticket)]\n#d[,Ticket.FirstLetter:=gsub(\"^(.).*$\", \"\\\\1\", Ticket.Category)]\n#Categorical2Numerical(d, \"Ticket.FirstLetter\", \"y\")\n#d[,Ticket.NChar:=nchar(Ticket)]\n#Categorical2Numerical(d, \"Ticket.NChar\", \"y\", onehot.min=20)\n\n\nd$Cabin.Category <- factor(gsub(\"^(.).*$\", \"\\\\1\", gsub(\"[^A-Z]\", \"\", d$Cabin)))\nCategorical2Numerical(d, \"Cabin.Category\", \"y\")\nd$Cabin.NChar <- nchar(d$Cabin)\n\n# Have a look at the the data\n# But if you want to use freq.stats, copy it from the explore.R file\n#freq.stats(split(d$Survived, d$Name.Title), xlab=\"Title\")\n#freq.stats(split(d$Survived, d$Name.Surname.Count), xlab=\"Surname\")\n#freq.stats(split(d$Survived, d$Name.HasBrackets), xlab=\"HasBrackets\")\n#freq.stats(split(d$Survived, d$Name.HasQuotes), xlab=\"HasQuotes\")\n#freq.stats(split(d$Survived, d$Ticket.Count), xlab=\"Ticket.Count\")\n#freq.stats(split(d$Survived, d$Ticket.NChar), xlab=\"Ticket.NChar\")\n#freq.stats(split(d$Survived, d$Ticket.Category), xlab=\"Ticket.Category\")\n#freq.stats(split(d$Survived, d$Ticket.FirstLetter), xlab=\"Ticket.FirstLetter\")\n#freq.stats(split(d$Survived, d$Cabin.Category), xlab=\"Cabin.Category\")\n#freq.stats(split(d$Survived, d$Cabin.NChar), xlab=\"Cabin.NChar\")\n\n\n\n# Finish splitting train / test\nd.class <- sapply(d, class)\nX.col <- intersect(names(d)[14:ncol(d)], names(d.class[d.class %in% c(\"integer\", \"numeric\")]))\nX.col <- unique(c(X.col, \"Age.Mice\", \"SibSp\", \"Parch\", \"Fare\"))\n\n# Note that different data formats of the same dataset are generated\n# To have standarized way of putting it into functions\nX.train.dt <- d[!is.na(y),X.col, with=F]\nX.train.m <- as.matrix(X.train.dt[,-\"y\"])\nX.test.dt <- d[is.na(y),X.col, with=F]\nX.test.m <- as.matrix(X.test.dt[,-\"y\"])\n\ny.train <- d[!is.na(y), y]\ny.train.f <- factor(y.train, levels=c(0, 1), labels=c(\"X0\", \"X1\"))\ny.test <- d[is.na(y), y.orig]\ny.test.f <- factor(y.test, levels=c(0, 1), labels=c(\"X0\", \"X1\"))\n\n# Some sanity checks\nstopifnot(sum(is.na(X.train.m))==0)\nstopifnot(sum(is.na(X.test.m))==0)\nstopifnot(sum(is.na(X.train.dt))==0)\n\n\n#\n# Model training using:\n# 1) Logistic regression\n# 2) Random Forest\ntrain.ctrl = trainControl(method=\"cv\", number=8,\n                          classProbs=T, # summaryFunction=twoClassSummary,\n                          savePredictions=T, verboseIter=T, allowParallel=T)\n\n# GLM (Lasso / Ridge regression)\ntune.grid <- expand.grid(.alpha=0:2/2,.lambda=exp(seq(-7, 2, length.out=10)))\nset.seed(1234)\nfit.glmnet <- train(X.train.m, y.train.f,  method=\"glmnet\", preProc = c(\"center\", \"scale\"), metric=\"Accuracy\", trControl=train.ctrl, tuneGrid=tune.grid)\nfit.glmnet\nvarImp(fit.glmnet)\nfit.test.prob <- predict(fit.glmnet, X.test.m, type=\"prob\")[,2]\n\n# Random Forest\ntune.grid <- expand.grid(.mtry=c(2,4,6,8))\nset.seed(1234)\nfit.rf <- train(X.train.m, y.train.f,  method=\"rf\", metric=\"Accuracy\", trControl=train.ctrl, tuneGrid=tune.grid)\nfit.rf\nvarImp(fit.rf)\nfit.test.prob <- predict(fit.rf, X.test.m, type=\"prob\")[,2]\n\n# Pick the right model for the final submission \n# (or better, submit results of all models)\nif(final) {\n  setwd(\"../\")\n  prob.threshold = 0.5\n  final.dt <- data.table(\"PassengerId\"=d[is.na(y),PassengerId], \n                         \"Survived\"=as.integer(fit.test.prob>prob.threshold))\n  fwrite(final.dt, \"final.csv\")\n  \n} else {\n  fit.test.roc <- roc(y.test, fit.test.prob)\n  fit.test.roc\n  plot(fit.test.roc)\n  table(fit.test.prob>0.5, y.test)\n  confusionMatrix(as.integer(fit.test.prob>0.5), y.test, positive=\"1\")\n}\n\n# TODO: Ensembling\n# TODO: Interactions\n# TODO: Feature filtering\n# TODO: Wrapping methods\n# TRY: Check difference in accuracy between train / test\n# TRY: Is difference between train / test in ROC as high?\n# TRY: Try different split of train / test (e.g. different random seed). \n#      - Is Logistic Regression or Random Forest better?\n#      - Is there still high difference in accuracy or ROC between train /test?\n# TRY: Different models, like lda, boosted trees\n#\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}