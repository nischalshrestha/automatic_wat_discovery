{"nbformat_minor": 1, "metadata": {"kernelspec": {"display_name": "R", "language": "R", "name": "ir"}, "language_info": {"pygments_lexer": "r", "name": "R", "file_extension": ".r", "version": "3.4.2", "codemirror_mode": "r", "mimetype": "text/x-r-source"}}, "nbformat": 4, "cells": [{"source": ["---\n", "title: \"Finding the 'real' families on the Titanic\"\n", "author: \"Harsh Kumar Yadav\"\n", "output:\n", "  html_document:\n", "    number_sections: true\n", "    toc: true\n", "---\n", "\n", "```{r setup, include=FALSE}\n", "knitr::opts_chunk$set(echo = TRUE)\n", "```\n", "#Executive Summary\n", "This project is my first attempt to compete in a Kaggle Machine Learning competition in which we have to predict who survived the Titanic disaster. I enjoyed it very much and learned a lot. Key findings were:\n", "\n", "* My key to success was to dive deep into groups of people that traveled together. My grouping variable is different when compared to other kernels that I have looked at.\n", "* The main things that I have done that I have not seen in any other kernels yet is the grouping of 'second degree' family members. Uncles, grandparents, cousins, and brothers/sisters-in-law can actually be found in the data.\n", "* The random forest model of the previous version scored a public score of 0.81818 on Kaggel. As this is a top5% score, I am pretty pleased with the result.\n", "* In this version I added a simple voting ensemble that takes the majority vote of 3 models. However, as the added SVM and GBM models are 'quick and dirty', this version should be seen as a  'work in progress' version. I will first need to optimize the individual models before I can find out the possible gains of the ensemble.\n", "\n", "#Introduction\n", "\n", "Kaggel describes this comptition as [follows](https://www.kaggle.com/c/titanic):\n", "\n", "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n", "\n", "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n", "\n", "In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n", "\n", "# Loading and Exploring Data\n", "\n", "##Loading libraries required and reading the data into R\n", "\n", "Loading R packages used besides base R.\n", "\n", "```{r, message=FALSE, warning=FALSE}\n", "library(Hmisc)\n", "library(knitr)\n", "library(ggplot2)\n", "library(dplyr)\n", "library(caret)\n", "library(randomForest)\n", "library(cowplot)\n", "library(ROCR)\n", "```\n", "\n", "Below, I am reading the csv's as dataframes into R.\n", "\n", "```{r}\n", "train <- read.csv(\"../input/train.csv\", stringsAsFactors = F, na.strings = c(\"NA\", \"\"))\n", "test <- read.csv(\"../input/test.csv\", stringsAsFactors = F, na.strings = c(\"NA\", \"\"))\n", "```\n", "\n", "##Data size and structure\n", "\n", "The training set consist of 891 observations and 12 variables. I have read all the \"factors\" (for instance male/female) into R as character strings, as some of them require processing first.\n", "\n", "```{r}\n", "str(train)\n", "```\n", "\n", "A description of each variable, including description of some key values, is given below.\n", "\n", "Variable Name | Description                       |Key\n", "--------------|-----------------------------------|----------------------------------------------\n", "Survived      | Survival                          |0 = No, 1 = Yes\n", "Pclass        | Passenger's class                 |1 = 1st, 2 = 2nd, 3 = 3rd\n", "Name          | Passenger's name                  |\n", "Sex           | Passenger's sex                   |\n", "Age           | Passenger's age                   |\n", "SibSp         | Number of siblings/spouses aboard |\n", "Parch         | Number of parents/children aboard |\n", "Ticket        | Ticket number                     |\n", "Fare          | Fare                              |\n", "Cabin         | Cabin                             |\n", "Embarked      | Port of embarkation               |C = Cherbourg, Q = Queenstown, S = Southampton\n", "--------------------------------------------------------------------------------------------------\n", "\n", "The test set consists of 418 observations, with the variable \"Survived\" missing compared to the training set. \"Creating\" this variable is eventually the purpose of this project.\n", "\n", "Below I am merging test and train, as this is required for data cleaning.\n", "\n", "```{r}\n", "test$Survived <- NA\n", "all <- rbind(train, test)\n", "```\n", "\n", "\n", "##Completeness of the data\n", "\n", "First of all, I would like to see which variables contain missing values (blanks are also imported as NA (=Not Available)).\n", "```{r}\n", "sapply(all, function(x) {sum(is.na(x))})\n", "```\n", "\n", "Of course, the 418 NAs in Survived is the total number is observations in the test set. So this variable is what it should be (No NAs in train). Of the other variables, Cabin is sparsely populated. Age is also missing a substantial number of values. In addition, Embarked is missing two values and one Fare value is missing.\n", "\n", "##Exploring some of the most important variables\n", "\n", "Our response variable in the training set is complete, as well as Sex and Pclass, which seem two of the most important predictors. Since they are complete and tidy, I am converting them into factors.\n", "\n", "```{r}\n", "all$Sex <- as.factor(all$Sex)\n", "all$Survived <- as.factor(all$Survived)\n", "all$Pclass <- as.ordered(all$Pclass) #because Pclass is ordinal\n", "```\n", "\n", "###The response variable; Survived\n", "Of course, the very first thing that I want to do is explore the response variable. How many people survived, and how many died? You can see this below. Altogether, of the people in the training set (891 observations) 61.6% died. For the remaining 418 observations (test set), this is what we have to predict.\n", "\n", "```{r}\n", "ggplot(all[!is.na(all$Survived),], aes(x = Survived, fill = Survived)) +\n", "  geom_bar(stat='count') +\n", "  labs(x = 'How many people died and survived on the Titanic?') +\n", "        geom_label(stat='count',aes(label=..count..))\n", "```\n", "\n", "\n", "###Sex/gender\n", "\n", "Of the 1309 people on the Titanic, a majority of 64.4% was male. This percentage was almost the same in the training data (64.7%). Within the training data 81.1% of the men died, and 25.8% of the women died. Due to this large difference, Sex/gender seems a very important predictor.\n", "\n", "```{r}\n", "p1 <- ggplot(all, aes(x = Sex, fill = Sex)) +\n", "  geom_bar(stat='count', position='dodge') +\n", "  labs(x = 'All data') +\n", "        geom_label(stat='count', aes(label=..count..))\n", "p2 <- ggplot(all[!is.na(all$Survived),], aes(x = Sex, fill = Survived)) +\n", "  geom_bar(stat='count', position='dodge') +\n", "  labs(x = 'Training data only') +\n", "        geom_label(stat='count', aes(label=..count..))\n", "plot_grid(p1, p2)\n", "```\n", "\n", "###Passenger Class\n", "\n", "As you can see below, most people traveled in 3rd class. Also, as expected, survival is strongly correlated with the passenger class. A majority of first class passengers survived, and most people in 3rd class died. It is also noticable that almost all women in 1st and 2nd class survived. For men, 2nd class was almost as bad as 3rd class.\n", "\n", "```{r}\n", "p3 <- ggplot(all, aes(x = Pclass, fill = Pclass)) +\n", "  geom_bar(stat='count', position='dodge') +\n", "  labs(x = 'Pclass, All data') + geom_label(stat='count', aes(label=..count..)) +\n", "   theme(legend.position=\"none\")     \n", "p4 <- ggplot(all[!is.na(all$Survived),], aes(x = Pclass, fill = Survived)) +\n", "  geom_bar(stat='count', position='dodge') + labs(x = 'Training data only') +\n", "        theme(legend.position=\"none\")\n", "p5 <- ggplot(all[!is.na(all$Survived),], aes(x = Pclass, fill = Survived)) +\n", "  geom_bar(stat='count', position='stack') +\n", "  labs(x = 'Training data only', y= \"Count\") + facet_grid(.~Sex) +\n", "        theme(legend.position=\"none\")\n", "p6 <- ggplot(all[!is.na(all$Survived),], aes(x = Pclass, fill = Survived)) +\n", "  geom_bar(stat='count', position='fill') +\n", "  labs(x = 'Training data only', y= \"Percent\") + facet_grid(.~Sex) +\n", "        theme(legend.position=\"none\")\n", "plot_grid(p3, p4, p5, p6, ncol=2)\n", "```\n", "\n", "In previous version, I have been working with Pclass and Sex as separate predictors. However, I realized that the 'headline' of the model should actually be a combination of the two (also thanks to Oscar Takeshita, who also uses this idea in his excellent analysis. See: [Divide and Conquer [0.82296]](https://www.kaggle.com/pliptor/divide-and-conquer-0-82296)). Details that are lost when using the predictors separately were actually already mentioned in the beginning of this section (Pclass 1 and 2 are almost guaranteed survival for women, and Pclass 2 is almost as bad as Pclass 3 for men).\n", "\n", "```{r}\n", "all$PclassSex[all$Pclass=='1' & all$Sex=='male'] <- 'P1Male'\n", "all$PclassSex[all$Pclass=='2' & all$Sex=='male'] <- 'P2Male'\n", "all$PclassSex[all$Pclass=='3' & all$Sex=='male'] <- 'P3Male'\n", "all$PclassSex[all$Pclass=='1' & all$Sex=='female'] <- 'P1Female'\n", "all$PclassSex[all$Pclass=='2' & all$Sex=='female'] <- 'P2Female'\n", "all$PclassSex[all$Pclass=='3' & all$Sex=='female'] <- 'P3Female'\n", "all$PclassSex <- as.factor(all$PclassSex)\n", "```\n", "\n", "#Feature engineering\n", "\n", "I am not using the Title variable anymore since version 15. Although most kernals use it, I believe it double counts variance to much (overfitting). Hopefully, I will manage to 'compensate' the slight drop in public score in upcoming version by improving other predictors. For the sake of completeness, I am keeping the title section for the time being.\n", "\n", "##Creating the Title variable\n", "\n", "The name variable is complete (no NAs), but actually contains more than just a first name and surname. It also contains a Title for each person, which must be separated from the name to obtain tidy data. I am also saving the Surname (first part of the name variable, before the title), as I want to investigate the effects of families traveling together later on (matching with #siblings/spouses and #parents/children).\n", "\n", "```{r}\n", "#Extracting Title and Surname from Name\n", "all$Surname <- sapply(all$Name, function(x) {strsplit(x, split='[,.]')[[1]][1]})\n", " #correcting some surnames that also include a maiden name\n", "all$Surname <- sapply(all$Surname, function(x) {strsplit(x, split='[-]')[[1]][1]})\n", "all$Title <- sapply(all$Name, function(x) {strsplit(x, split='[,.]')[[1]][2]})\n", "all$Title <- sub(' ', '', all$Title) #removing spaces before title\n", "kable(table(all$Sex, all$Title))\n", "```\n", "\n", "After seeing this, I want to reducing the number of titles to create better and more substantial Titles that can be used for prediction. Ms. is usually used for younger married women. I will therefore join this one with Miss. I assume that Mlle stands for Mademoiselle in French. I will also join this category with Miss. I also assume that Mme stands for Madame, and I will join Madame with Mrs. For the titles with low frequecies, I will create one new category.\n", "\n", "A problem of the model is that it produces many False Negatives for men (men predicted to die while actually surviving). Because there is such a big difference in survival chances of especially the Misters in 1st class and 2nd and 3rd class, I split the Mr title in version 4. Since this split did not work anymore in version 5, I abandoned this split. However in version 9 I finally introduced a  Child variable (using clean Age data only, see section 5.1), and this split works again regarding the public score. The idea is to give Misters in 1st class some more weight.\n", "\n", "```{r}\n", "all$Title[all$Title %in% c(\"Mlle\", \"Ms\")] <- \"Miss\"\n", "all$Title[all$Title== \"Mme\"] <- \"Mrs\"\n", "all$Title[!(all$Title %in% c('Master', 'Miss', 'Mr', 'Mrs'))] <- \"Rare Title\"\n", "all$Title <- as.factor(all$Title)\n", "kable(table(all$Sex, all$Title))\n", "```\n", "\n", "```{r}\n", "ggplot(all[!is.na(all$Survived),], aes(x = Title, fill = Survived)) +\n", "  geom_bar(stat='count', position='stack') +\n", "  labs(x = 'Title')\n", "```\n", "\n", "##Finding groups of people traveling together\n", "\n", "###Families; siblings, spouses, parents and children\n", "\n", "In order to create the family size for each person on the boat, I will add up his/her number of parents/children, his/her number of siblings/spouses, and of course add one (the person himself).\n", "\n", "```{r, message=FALSE}\n", "#creating family size variable (Fsize)\n", "all$Fsize <- all$SibSp+all$Parch +1\n", "```\n", "\n", "Below, you can easily see that solo travelers had a much higher chance to die than to survive. In addition, people traveling in families of 2-4 people actually had a relatively high chance to survive. This chance is significantly lower among 5+ families.\n", "\n", "```{r}\n", "ggplot(all[!is.na(all$Survived),], aes(x = Fsize, fill = Survived)) +\n", "  geom_bar(stat='count', position='dodge') +\n", "  scale_x_continuous(breaks=c(1:11)) +\n", "  labs(x = 'Family Size')\n", "```\n", "\n", "What I now could do is convert these family sizes into categories (solo, small family, large family), but I first want to check if there are any inconsistencies in the data.\n", "\n", "###Families; what about uncles, aunts, cousins, nieces, grandparents, brothers/sisters-in law?\n", "\n", "To check the size data for inconsistencies, I am creating a variable that combines the surname and the Fsize. After that, I am going to check where these combinations lead to strange numbers of families.\n", "\n", "```{r}\n", "#composing variable that combines total Fsize and Surname\n", "all$FsizeName <- paste(as.character(all$Fsize), all$Surname, sep=\"\")\n", "\n", "SizeCheck <- all %>%\n", "        group_by(FsizeName, Fsize) %>%\n", "        summarise(NumObs=n())\n", "SizeCheck$NumFam <- SizeCheck$NumObs/SizeCheck$Fsize\n", "SizeCheck$modulo <- SizeCheck$NumObs %% SizeCheck$Fsize\n", "SizeCheck <- SizeCheck[SizeCheck$modulo !=0,]\n", "sum(SizeCheck$NumObs)\n", "kable(tail(SizeCheck))\n", "\n", "```\n", "\n", "As you can see, this check does not always add up to a round number of families (for a total of 93 passengers). Part of these are no problem. For instance, there is one large Andersson family of 7 and 2 additional women with the Surname Andersson and family size of 7. If the SibSp and Parch numbers are reliable, this just means that there must be 5 more family members in the remaining data that we don't have (Note: this was my first assumption. It will be checked in a later version as the passenger list seems complete. The other people on the boat all seem to be crew (2224-1309= 915 crew).\n", "\n", "However, I found out that there is something 'hidden' in this information that does matter. For instance, it turns out that the Hockings and the Richards' are related. The connection here is that passenger 438 travels with 2 children, 1 parent, a brother and a sister. For her, all these people count are direct family. However, other people are linked indirectly. For the 2 children for instance, only the brother and mother count as direct family. This leads to Fsizes that cannot be compared to most families as 'apples to apples'. Their Fsizes are generally too high, as it is likely that those people have split up into smaller groups. The mother may have stayed with her children, while the brother and sister probably have stayed with the grandmother.\n", "\n", "Note: this family is actually even more complex, as the grandmother also travels with a sister with the same maiden name. However, as this really seems an exception and the other Mrs Needs already has the very reasonable Fsize of 2 (it's  Mrs Wilkes Needs), I am not taking her into consideration.\n", "\n", "```{r}\n", "kable(all[all$Ticket %in% c('29104', '29105', '29106'),c(2,3,4,5,6,7,8,9,15)])\n", "```\n", "\n", "In order to fix this, I first have to 'glue' those families together using maiden names.\n", "\n", "```{r}\n", "NC <- all[all$FsizeName %in% SizeCheck$FsizeName,] #create data frame with only relevant Fsizenames\n", "\n", "#extracting maiden names\n", "NC$Name <- sub(\"\\\\s$\", \"\", NC$Name) #removing spaces at end Name\n", "NC$Maiden <- sub(\".*[^\\\\)]$\", \"\", NC$Name) #remove when not ending with ')'\n", "NC$Maiden <- sub(\".*\\\\s(.*)\\\\)$\", \"\\\\1\", NC$Maiden)\n", "NC$Maiden[NC$Title!='Mrs'] <- \"\" #cleaning up other stuff between brackets (including Nickname of a Mr)\n", "NC$Maiden <- sub(\"^\\\\(\", '', NC$Maiden) #removing opening brackets (sometimes single name, no spaces between brackets)\n", "#making an exceptions match\n", "NC$Maiden[NC$Name=='Andersen-Jensen, Miss. Carla Christine Nielsine'] <- 'Jensen'\n", "\n", "#take only Maiden names that also exist as surname in other Observations\n", "NC$Maiden2[NC$Maiden %in% NC$Surname] <- NC$Maiden[NC$Maiden %in% NC$Surname] \n", "#create surname+maiden name combinations\n", "NC$Combi[!is.na(NC$Maiden2)] <- paste(NC$Surname[!is.na(NC$Maiden2)], NC$Maiden[!is.na(NC$Maiden2)])\n", "\n", "#create labels dataframe with surname and maiden merged into one column\n", "labels1 <- NC[!is.na(NC$Combi), c('Surname','Combi')]\n", "labels2 <- NC[!is.na(NC$Combi), c('Maiden','Combi')]\n", "colnames(labels2) <- c('Surname', 'Combi')\n", "labels1 <- rbind(labels1, labels2)\n", "\n", "NC$Combi <- NULL\n", "NC <- left_join(NC, labels1, by='Surname')\n", "\n", "#Find the maximum Fsize within each newly found 'second degree' family\n", "CombiMaxF <- NC[!is.na(NC$Combi),] %>%\n", "        group_by(Combi) %>%\n", "        summarise(MaxF=max(Fsize)) #summarise(MaxF=n())\n", "NC <- left_join(NC, CombiMaxF, by = \"Combi\")\n", "\n", "#create family names for those larger families\n", "NC$FsizeCombi[!is.na(NC$Combi)] <- paste(as.character(NC$Fsize[!is.na(NC$Combi)]), NC$Combi[!is.na(NC$Combi)], sep=\"\")\n", "\n", "#find the ones in which not all Fsizes are the same\n", "FamMaid <- NC[!is.na(NC$FsizeCombi),] %>%\n", "        group_by(FsizeCombi, MaxF, Fsize) %>%\n", "        summarise(NumObs=n())\n", "FamMaidWrong <- FamMaid[FamMaid$MaxF!=FamMaid$NumObs,]\n", "\n", "kable(unique(NC[!is.na(NC$Combi) & NC$FsizeCombi %in% FamMaidWrong$FsizeCombi, c('Combi', 'MaxF')]))\n", "```\n", "\n", "As you can see, 7 combinations (total of 28 passengers) are found as families with not all members having the same Fsize, which means that they are broader families with non-direct family links included. Before I decided what to do with these, I first have to find the families who are similarly linked on the 'male' side.\n", "\n", "```{r}\n", "NC$MaxF <- NULL #erasing MaxF column maiden combi's\n", "\n", "#Find the maximum Fsize within remaining families (no maiden combi's)\n", "FamMale <- NC[is.na(NC$Combi),] %>%\n", "        group_by(Surname) %>%\n", "        summarise(MaxF=max(Fsize))\n", "NC <- left_join(NC, FamMale, by = \"Surname\")\n", "\n", "NCMale <- NC[is.na(NC$Combi),] %>%\n", "        group_by(Surname, FsizeName, MaxF) %>%\n", "        summarise(count=n()) %>%\n", "        group_by(Surname, MaxF) %>%\n", "        filter(n()>1) %>%\n", "        summarise(NumFsizes=n())\n", "\n", "NC$Combi[NC$Surname %in% NCMale$Surname] <- NC$Surname[NC$Surname %in% NCMale$Surname]\n", "\n", "kable(NCMale[, c(1,2)])\n", "```\n", "\n", "Example. Mr Julius Vander Planke is traveling with a spouse and 2 siblings. His spouse and siblings (brothers/sisters-in-law) are 'indirectly' related to each other.\n", "\n", "```{r}\n", "kable(all[all$Surname=='Vander Planke', c(2,3,4,5,6,7,8,9,15)])\n", "```\n", "\n", "This means that altogether, there are 9 families (37 passengers) that include 'second degree' family members. What I want to do is give each member in such family the same Fsize (which gives everybody in these families the same survival chances with regards to the group variable). I have chosen to make this the average of the Fsize (which are based on siblings/spouse/parents/children only).\n", "\n", "```{r}\n", "#selecting those 37 passengers In Not Correct dataframe\n", "NC <- NC[(NC$FsizeCombi %in% FamMaidWrong$FsizeCombi)|(NC$Surname %in% NCMale$Surname),]\n", "\n", "#calculating the average Fsize for those 9 families\n", "NC1 <- NC %>%\n", "        group_by(Combi) %>%\n", "        summarise(Favg=mean(Fsize))\n", "kable(NC1)\n", "```\n", "\n", "A result is that for instance the Fsize is 4 for all 6 people in the Richards-Hockings family. This exactly what I wanted, as I wanted to combine those people into a group with all members having the same Fsize (to give equal survival chances to all members within the group) but also not the maximum size as they are less likely to stay together than first degree families.\n", "\n", "```{r}\n", "NC <- left_join(NC, NC1, by = \"Combi\") #adding Favg to NC dataframe \n", "NC$Favg <- round(NC$Favg) #rounding those averages to integers\n", "NC <- NC[, c('PassengerId', 'Favg')]\n", "all <- left_join(all, NC, by='PassengerId')\n", "\n", "#replacing Fsize by Favg\n", "all$Fsize[!is.na(all$Favg)] <- all$Favg[!is.na(all$Favg)]\n", "```\n", "\n", "###Did people book together?\n", "\n", "Besides families, groups of friends can off course also travel together. A nice example of this is the ticket below.\n", "\n", "```{r}\n", "kable(all[all$Ticket=='1601', c('Survived', 'Pclass', 'Title', 'Surname', 'Age', 'Ticket', 'SibSp', 'Parch', 'Fsize')])\n", "```\n", "\n", "Below, I am adding the number of people on each ticket as variable.\n", "\n", "```{r}\n", "#composing data frame with group size for each Ticket\n", "TicketGroup <- all %>%\n", "        select(Ticket) %>%\n", "        group_by(Ticket) %>%\n", "        summarise(Tsize=n())\n", "all <- left_join(all, TicketGroup, by = \"Ticket\")\n", "```\n", "\n", "Very similarly to the family group sizes, small groups of 2-4 people traveling together on the same ticket have a higher chance of survival.\n", "```{r}\n", "ggplot(all[!is.na(all$Survived),], aes(x = Tsize, fill = Survived)) +\n", "  geom_bar(stat='count', position='dodge') +\n", "  scale_x_continuous(breaks=c(1:11)) +\n", "  labs(x = 'Ticket Size')\n", "```\n", "\n", "As there is so much overlap between family size and ticket size, I am consolidating these two variables into one group variable.\n", "\n", "```{r}\n", "\n", "all$Group <- all$Fsize\n", "for (i in 1:nrow(all)){\n", "           all$Group[i] <- max(all$Group[i], all$Tsize[i])\n", "       }\n", "```\n", "\n", "###Can we still find more groups?\n", "\n", "Am I still missing groups? Yes, at it appears that some people traveling solo with the same surname have tickets with almost the same number!\n", "\n", "```{r}\n", "#creating a variable with almost the same ticket numbers (only last 2 digits varying)\n", "all$Ticket2 <- sub(\"..$\", \"xx\", all$Ticket)\n", "```\n", "\n", "As they have no sibling/spouses and no parents/children, these people are likely cousins/uncles. If you look deeper into the data, you will see that these groups of cousins/uncles sometimes also travel with (first degree) families. However, I think the key to this exercise is not to find the absolute largest groups that people may have stayed together with. I think it should be to detect smaller groups that actually stayed together. It sounds reasonable to assume that first degree families stayed together, and that uncles/cousins also took care of each other (this is consistent with the averaging of the Fsizes in section 4.2.2). Altogether, I have found another 44 passengers that I can assign a group size to.\n", "\n", "```{r}\n", "rest <- all %>%\n", "        select(PassengerId, Title, Age, Ticket, Ticket2, Surname, Group) %>%\n", "        filter(Group=='1') %>%\n", "        group_by(Ticket2, Surname) %>%\n", "        summarise(count=n())\n", "rest <- rest[rest$count>1,]\n", "rest1 <- all[(all$Ticket2 %in% rest$Ticket2 & all$Surname %in% rest$Surname & all$Group=='1'), c('PassengerId', 'Surname', 'Title', 'Age', 'Ticket', 'Ticket2', 'Group', 'SibSp', 'Parch')]\n", "rest1 <- left_join(rest1, rest, by = c(\"Surname\", \"Ticket2\"))\n", "rest1 <- rest1 %>%\n", "        arrange(Ticket2, Surname)\n", "kable(rest1[1:12,])\n", "```\n", "\n", "```{r}\n", "#replacing Group size in my overall dataframe with the count numbers in the table above\n", "all <- left_join(all, rest1)\n", "for (i in 1:nrow(all)){\n", "        if (!is.na(all$count[i])){\n", "                all$Group[i] <- all$count[i]\n", "        }\n", "}\n", "```\n", "\n", "```{r}\n", "ggplot(all[!is.na(all$Survived),], aes(x = Group, fill = Survived)) +\n", "  geom_bar(stat='count', position='dodge') +\n", "  scale_x_continuous(breaks=c(1:11)) +\n", "  labs(x = 'Final Groups')\n", "```\n", "\n", "Now I can finally created my factorized variable for the group sizes. As '1' and '2' are large groups with their own typical survival rates, I am keeping them as separate groups. Sizes '3' and '4' clearly have the best survival chances, and the groups of 5 and more clearly have worse chances.\n", "\n", "```{r}\n", "#Creating final group categories\n", "all$GroupSize[all$Group==1] <- 'solo'\n", "all$GroupSize[all$Group==2] <- 'duo'\n", "all$GroupSize[all$Group>=3 & all$Group<=4] <- 'group'\n", "all$GroupSize[all$Group>=5] <- 'large group'\n", "all$GroupSize <- as.factor(all$GroupSize)\n", "```\n", "\n", "```{r}\n", "ggplot(all[!is.na(all$Survived),], aes(x = GroupSize, fill = Survived)) +\n", "  geom_bar(stat='count', position='dodge') +\n", "  labs(x = 'Final Group Sizes')\n", "```\n", "\n", "```{r, echo=FALSE}\n", "#clean up\n", "all$count <- NULL\n", "all$Name <- NULL\n", "rm(CombiMaxF)\n", "rm(FamMaid)\n", "rm(FamMaidWrong)\n", "rm(FamMale)\n", "rm(labels1)\n", "rm(labels2)\n", "rm(NC)\n", "rm(NC1)\n", "rm(NCMale)\n", "rm(rest)\n", "rm(rest1)\n", "rm(SizeCheck)\n", "rm(TicketGroup)\n", "rm(p1); rm(p2); rm(p3); rm(p4); rm(p5); rm(p6)\n", "```\n", "\n", "\n", "##Dealing with the Fare variable\n", "\n", "###Which data relevant to fare are missing?\n", "There are two missing values in Embarked, and one in Fare. Embarked could be important to Fare, as different Embarkement cities mean longer or shorter journeys.\n", "\n", "```{r}\n", "#display passengers with missing Embarked\n", "kable(all[which(is.na(all$Embarked)),c('Surname', 'Title', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Group') ])\n", "```\n", "\n", "Both women are traveling solo from a family perspective (Fsize=1), but must be friends as they are both are traveling on ticket 113572 (nobody else was traveling on this ticket, so Group=2). The both have the same fare, but this fare might still have been per person. I came to the conclusion that prices are indeed per ticket. As the explanation was getting lengthy, I will now just continue under the assumption that fares are per person. \n", "\n", "I want to impute the missing embarkement city with the median Fare Per Person for each Embarkement city, and per Pclass.\n", "\n", "```{r}\n", "all$FarePP <- all$Fare/all$Tsize #creating the Fare Per Person variable\n", "\n", "tab2 <- all[(!is.na(all$Embarked) & !is.na(all$Fare)),] %>%\n", "        group_by(Embarked, Pclass) %>%\n", "        summarise(FarePP=median(FarePP))\n", "kable(tab2)\n", "```\n", "\n", "As the FarePP of those two women is 40, they most likely embarked at Cherbourgh.\n", "\n", "```{r}\n", "#imputing missing Embarked values\n", "all$Embarked[all$Ticket=='113572'] <- 'C'\n", "#converting Embarked into a factor\n", "all$Embarked <- as.factor(all$Embarked)\n", "```\n", "\n", "I can actually use the same table to find a sensible fare for Mr Story. As you can see below, he traveled 3rd class and embarked at Southampton. \n", "\n", "```{r}\n", "#display passengers with missing Fare\n", "kable(all[which(is.na(all$Fare)), c('Surname', 'Title', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Group')])\n", "```\n", "\n", "```{r}\n", "#imputing FarePP (as the Fare will be dropped later on anyway)\n", "all$FarePP[1044] <- 7.8\n", "```\n", "\n", "###The Fare Per Person Variable\n", "\n", "Although there now are no missing FarePP's anymore, I also noticed that 17 Fares actually have the value 0. These people are not children that might travel for free. I think the information might actually be correct (have people won free tickets?), but I think that the zero-Fares might confuse the algorithm. For instance, there are zero-Fares within the 1st class passengers. To avoid this possible confusion, I am replacing these values by the median FarePP's for each Pclass.\n", "\n", "```{r}\n", "tab3 <- all[(!is.na(all$FarePP)),] %>%\n", "        group_by(Pclass) %>%\n", "        summarise(MedianFarePP=median(FarePP))\n", "all <- left_join(all, tab3, by = \"Pclass\")\n", "all$FarePP[which(all$FarePP==0)] <- all$MedianFarePP[which(all$FarePP==0)]\n", "```\n", "\n", "Below you can see that the FarePP is very skewed. I know that this is not desirable for some algorithms, and can be solved by taking the logarithm or normalisation (preprocessing with centering and scaling). \n", "\n", "```{r}\n", "hist(all$FarePP, main='Histogram of Fare Per Person', col='blue', xlab='Fare Per Person')\n", "```\n", "\n", "Another option is to use Fare bins instead of keeping the FarePP as a numeric variable. In version 18, I am using Fare Bin in the GBM model.\n", "\n", "```{r, message=FALSE}\n", "#Note Hmisc needs to be loaded before dplyr, as the other ways around errors occured due to the kernel using the Hmisc summarize function instead of the dplyr summarize function\n", "all$FareBins <- cut2(all$FarePP, g=5)\n", "table(all$FareBins)\n", "\n", "```\n", "\n", "##Predicting missing Age values\n", "\n", "The density plot below shows that survival chances of children are relatively high. Survival chances of ages 20-30 are below average, and I see less significant differences in the 30+ region. I think there may be a lot of solo travelers in the 20-30 category, which could explain the below averages survival chances. A possible use case of Age could be to use it to identify children. Therefore, I will focus on good looking Age imputations in the region 0-18 years old.\n", "\n", "```{r}\n", "ggplot(all[(!is.na(all$Survived) & !is.na(all$Age)),], aes(x = Age, fill = Survived)) +\n", "geom_density(alpha=0.5, aes(fill=factor(Survived))) + labs(title=\"Survival density and Age\") +\n", "scale_x_continuous(breaks = scales::pretty_breaks(n = 10))\n", "```\n", "\n", "I first want to visualize the relation between the Age. Title and Pclass seem the most important predictors for Age to me. As you can see below, there are significant differences in Age across the Titles (By the way, this graph tells me that \"Masters\" are all very young. I did not know what a master was, but googling it tells me that a master was used as a title for the eldest son only.). Similarly, there differences in Age when looking at the Title/Passenger Class combinations.\n", "\n", "```{r}\n", "ggplot(all[!is.na(all$Age),], aes(x = Title, y = Age, fill=Pclass )) +\n", "  geom_boxplot() + scale_y_continuous(breaks = scales::pretty_breaks(n = 10))\n", "```\n", "\n", "The title Master seems to be a good predictor for male children. However, female children are included in the Miss title, and of the 263 missing age values, 51 are Misses. If I would just take the median Age of the Titles (possibly also by Pclass), I would at least not predict the missing ages of female children well. I tried both Mice imputation and Linear Regression, and focused on how good the imputations for children looked. The Mice imputations looked reasonable, but I preferred Linear Regression.\n", "\n", "```{r}\n", "#predicting Age with Linear Regression\n", "set.seed(12000)\n", "AgeLM <- lm(Age ~ Pclass + Sex + SibSp + Parch + Embarked + Title + GroupSize, data=all[!is.na(all$Age),])\n", "summary(AgeLM)\n", "all$AgeLM <- predict(AgeLM, all)\n", "```\n", "\n", "As expected, the most significant predictors according to Linear Regression were Passenger Class and Title. Below you can see that the histogram of the predicted values versus the shape of the known ages. The Mice histogram actually looked nicer, but I was wondering how it could predict high ages well given the sparseness of these ages in the original data?\n", "\n", "```{r}\n", "par(mfrow=c(1,2))\n", "hist(all$Age[!is.na(all$Age)], main='Original data, non-missing', xlab='Age', col='green')\n", "hist(all$AgeLM[is.na(all$Age)], main= 'LM NA predictions', xlab='Age', col='orange', xlim=range(0:80))\n", "```\n", "\n", "As mentioned before, I especially looked at young predicted ages. Both mice and Linear Regression predicted all Masters with missing ages to be children indeed (the one in Linear Regression with a negative age did not bother me that much, as it is categorized as a child anyway). Mice predicted some Mr.'s of 14 years old, which is too young. As Linear Regression also predicted a reasonable number of Misses to be children, I eventually chose Linear Regression.\n", "\n", "```{r}\n", "#display which passengers are predicted to be children (age<18) with Linear Regression.\n", "all[(is.na(all$Age) & all$AgeLM <18), c('Sex', 'SibSp', 'Parch', 'Title', 'Pclass', 'Survived', 'AgeLM')]\n", "```\n", "\n", "```{r}\n", "#imputing Linear Regression predictions for missing Ages\n", "indexMissingAge <- which(is.na(all$Age))\n", "indexAgeSurvivedNotNA<- which(!is.na(all$Age) & (!is.na(all$Survived))) #needed in sections 4.6 and 4.7\n", "all$Age[indexMissingAge] <- all$AgeLM[indexMissingAge]\n", "```\n", "\n", "So now all missing data have been imputed. Am I going to use Age as a predictor in my model? I am not sure yet, as the substantial number of imputations will also add noise. I wil look at using it to create a Child predictor later on.\n", "\n", "##What to do with Cabin?\n", "\n", "Cabin is very sparsely populated. So I either have to ignore it, or use it somehow without making it too specific. On the internet, you can find that that the first letter corresponds to the Deck. Decks A-E are the topdecks and cabins on those decks are mostly first class.\n", "\n", "```{r}\n", "#replacing NAs with imaginary Deck U, and keeping only the first letter of ech Cabin (=Deck)\n", "all$Cabin[is.na(all$Cabin)] <- \"U\"\n", "all$Cabin <- substring(all$Cabin, 1, 1)\n", "all$Cabin <- as.factor(all$Cabin)\n", "\n", "ggplot(all[(!is.na(all$Survived)& all$Cabin!='U'),], aes(x=Cabin, fill=Survived)) +\n", "        geom_bar(stat='count') +facet_grid(.~Pclass) + labs(title=\"Survivor split by class and Cabin\")\n", "```\n", "\n", "Below, you can see that there are interesting difference among Decks. For instance, the top Deck (A) was not best place to be. Even Deck F had better survival rates.\n", "\n", "```{r}\n", "c1 <- round(prop.table(table(all$Survived[(!is.na(all$Survived)&all$Cabin!='U')], all$Cabin[(!is.na(all$Survived)&all$Cabin!='U')]),2)*100)\n", "kable(c1)\n", "```\n", "\n", "Although I feel that Deck and Deck sections (front/back of boat, sections close to stairs et cetera) would be great predictors, I am not using Cabin due to the the sparseness of the data.\n", "\n", "##How to deal with Children in the model?\n", "\n", "The survival density plot in the Age section shows that Children below roughly 14.5 (which is also the maximum Age of Masters in the data) have a better survival rate than then other Ages. However, if you look at the imputed Ages below 14.5, you will also see that all these age imputation are for Pclass 3 and most of these children actually died (10 out of 13).\n", "\n", "This makes me wonder if I should add a survival 'bonus' for all Pclasses. Below you can see that most children in P3 actually die. As these children in P3 also include age imputations which may add noise, I decided to exclude P3 from the Child predictor.\n", "\n", "```{r}\n", "ggplot(all[all$Age<14.5 & !is.na(all$Survived),], aes(x=Pclass, fill=Survived))+\n", "        geom_bar(stat='count')\n", "```\n", "\n", "\n", "\n", "```{r}\n", "all$IsChildP12 <- 'No'\n", "all$IsChildP12[all$Age<=14.5 & all$Pclass %in% c('1', '2')] <- 'Yes'\n", "all$IsChildP12 <- as.factor(all$IsChildP12)\n", "```\n", "\n", "\n", "##What does Embarked tell us?\n", "\n", "Although I feel that the city of Embarked should not be related to survival rates, I still wanted to check it. As you can see below, there somehow are significant differences between the three ports of embarkment.\n", "\n", "```{r}\n", "d1 <- ggplot(all[!is.na(all$Survived),], aes(x = Embarked, fill = Survived)) +\n", "  geom_bar(stat='count') +\n", "                    labs(x = 'Embarked', y= 'Count')\n", "d2 <- ggplot(all[!is.na(all$Survived),], aes(x = Embarked, fill = Survived)) +\n", "  geom_bar(stat='count', position= 'fill') +\n", "                    labs(x = 'Embarked', y= 'Percent')\n", "plot_grid(d1, d2)\n", "```\n", "\n", "To get a feel for where this differences may come from, I plotted them against Sex and Pclass. Roughly, differences were:\n", "\n", "* Southampton survival rates are worse than Cherbourg in all Pclass/Sex combinations\n", "* Cherbourg survival rates are better than Queenstown as many 1st class passengers boarded at Cherbourgh, while almost all Queenstown passengers boarded 3rd class (but within 3rd class, female survival rate is better than Cherbourg and male survival rate is worse than Cherbourgh).\n", "\n", "My conclusion is that at least the lower survival rate of Southampton compared to Cherbourg cannot be explained by Pclass or Sex. One thing that I want to look at is the relation between Embarked, Age and Survived, because Linear Regression surprisingly enough also labeled Embarked at Queenstown as a significant predictor for Age. Below I am only using the known Ages of the training data (714 observation = training set - 177 observations with missing Age).\n", "\n", "```{r}\n", "ggplot(all[indexAgeSurvivedNotNA,], aes(x = Age, fill = Survived)) +\n", "geom_histogram(aes(fill=factor(Survived))) + labs(title=\"Survival density, known-ages, and Embarked\") +\n", "scale_x_continuous(breaks = scales::pretty_breaks(n = 5)) + facet_grid(.~Embarked)\n", "```\n", "\n", "This shows that is very little data for especially Queenstown when looking at known Ages. Below you can see that the total number of people who embarked at Queenstown is low indeed, but especially the high percentage of missing ages in Queenstown is really high. Using imputed ages will therefore add too much noise, and combining Age and Embarked as a predictor is a bad idea.\n", "\n", "```{r}\n", "tab1 <- rbind(table(all$Embarked[!is.na(all$Survived)]),table(all$Embarked[indexAgeSurvivedNotNA]))\n", "tab1 <- cbind(tab1, (rowSums(tab1)))\n", "tab1 <- rbind(tab1, tab1[1,]-tab1[2,])\n", "tab1 <- rbind(tab1, round((tab1[3,]/tab1[1,])*100))\n", "rownames(tab1) <- c(\"All\", \"With Age\", \"Missing Age\", \"Percent Missing\")\n", "colnames(tab1) <- c(\"C\", \"Q\", \"S\", \"Total\")\n", "kable(tab1)\n", "```\n", "\n", "The only other thing that I can think of that might explain the differences is that probably people from the different embarkement cities are somehow grouped on certain sections of the decks. \n", "\n", "I kept Embarked in my model until version 16. However, after cleaning up the model, it gradually became clear that Embarked does not add anything. I am nit using it anymore in version 17.\n", "\n", "##Ticket survivors\n", "\n", "In version 17, I added a variable that checks if any people in a group did survive. The idea is that anyone in a certain group survived, chances of others also surviving are higher. I did this using the Ticket information, and it improved the scores. In the next version, I will try to extend this variable to match the group info, as it now does not take families traveling on different tickets into account. It should be seen as a promising start; it does make a positive difference, but I will need group IDs for groups such as the Richard Hockings family. However, it is harder than that, as there for instance also is a group consisting of 3 married sisters (3 different surnames, 1 maiden name).\n", "\n", "```{r}\n", "TicketSurvivors <- all %>%\n", "        group_by(Ticket) %>%\n", "        summarize(Tsize = length(Survived),\n", "                  NumNA = sum(is.na(Survived)),\n", "                  SumSurvived = sum(as.numeric(Survived)-1, na.rm=T))\n", "```\n", "\n", "```{r}\n", "all <- left_join(all, TicketSurvivors)\n", "all$AnySurvivors[all$Tsize==1] <- 'other'\n", "all$AnySurvivors[all$Tsize>=2] <- ifelse(all$SumSurvived[all$Tsize>=2]>=1, 'survivors in group', 'other')\n", "all$AnySurvivors <- as.factor(all$AnySurvivors)\n", "\n", "table(all$AnySurvivors)\n", "```\n", "\n", "#Predictions (with caret cross validation)\n", "\n", "```{r, echo=FALSE}\n", "#cleaning up\n", "all$PassengerId <- NULL\n", "all$SibSp <- NULL\n", "all$Parch <- NULL\n", "all$Ticket <- NULL\n", "all$Fare <- NULL\n", "all$Cabin <- NULL\n", "all$Surname <- NULL\n", "all$Fsize <- NULL\n", "all$FsizeName <- NULL\n", "all$Favg <- NULL\n", "all$Tsize <- NULL\n", "all$Group <- NULL\n", "all$Ticket2 <- NULL\n", "all$AgeLM <- NULL\n", "all$Child <- NULL\n", "all$HasParch <- NULL\n", "all$MedianFarePP <- NULL\n", "rm(tab1); rm(tab2); rm(tab3); rm(AgeLM); rm(c1); rm(d1); rm(d2);\n", "```\n", "\n", "```{r}\n", "#splitting data into train and test set again\n", "trainClean <- all[!is.na(all$Survived),]\n", "testClean <- all[is.na(all$Survived),]\n", "```\n", "\n", "Initially, I had some difficulties with the Caret cross validation, as the cross validated accuracies did not seem a good prodictor for the public score on Kaggle (as I have seen in many kernels). However, after studying how caret and the R formula function work together I managed to get it working in version 11. Although the formula method must be used with many algorithms, it is better to not use it with Random Forest as this causes issues with weights of predictors.\n", "\n", "##Random Forest model\n", "I started this analysis with just a Random Forest model, as it is known for high accuracy and limiting overfitting. Since version 17, I am just using 5 predictors.\n", "\n", "```{r}\n", "set.seed(2017)\n", "caret_matrix <- train(x=trainClean[,c('PclassSex', 'GroupSize', 'FarePP', 'AnySurvivors', 'IsChildP12')], y=trainClean$Survived, data=trainClean, method='rf', trControl=trainControl(method=\"cv\", number=7))\n", "caret_matrix\n", "caret_matrix$resample\n", "caret_matrix$results\n", "```\n", "\n", "```{r}\n", "varImpPlot(caret_matrix$finalModel, main=\" Variable importance\")\n", "```\n", "\n", "```{r}\n", "#using the model to make Survival predictions on the test set\n", "solution_rf <- predict(caret_matrix, testClean)\n", "#creating csv file for submission on Kaggle\n", "submission_rf <- data.frame(PassengerId = test$PassengerId, Survived = solution_rf)\n", "write.csv(submission_rf, file = 'Titanic_rf.csv', row.names = F)\n", "```\n", "\n", "##Support Vector Machine (SVM) model\n", "\n", "The second algorithm that I want to use is SVM, as it is known to work well with small datasets.\n", "\n", "```{r}\n", "set.seed(2017)\n", "caret_svm <- train(Survived~ PclassSex + GroupSize + FarePP + AnySurvivors + IsChildP12, data=trainClean, method='svmRadial', trControl=trainControl(method=\"cv\", number=7))\n", "caret_svm\n", "caret_svm$results\n", "```\n", "\n", "```{r}\n", "#using the model to make Survival predictions on the test set\n", "solution_svm <- predict(caret_svm, testClean)\n", "#creating csv file for submission on Kaggle\n", "submission_svm <- data.frame(PassengerId = test$PassengerId, Survived = solution_svm)\n", "write.csv(submission_svm, file = 'Titanic_svm.csv', row.names = F)\n", "```\n", "\n", "##Gradient Boosting Machine (GBM) model\n", "\n", "As I am already having a model that uses Bagging, I want the 3rd model to be a boosting model. Of the possible boosting algorithms, I am choosing GBM.\n", "\n", "```{r, results='hide'}\n", "set.seed(2017)\n", "caret_boost <- train(Survived~ PclassSex + GroupSize + FareBins + AnySurvivors + IsChildP12, data=trainClean, method='gbm', trControl=trainControl(method=\"cv\", number=7))\n", "```\n", "```{r}\n", "caret_boost$resample #just printing accuracy by fold to keep it simple for time being\n", "```\n", "\n", "```{r}\n", "#using the model to make Survival predictions on the test set\n", "solution_boost <- predict(caret_boost, testClean)\n", "#creating csv file for submission on Kaggle\n", "submission_boost <- data.frame(PassengerId = test$PassengerId, Survived = solution_boost)\n", "write.csv(submission_boost, file = 'Titanic_boost.csv', row.names = F)\n", "```\n", "\n", "## Majority vote ensemble of the three models\n", "\n", "A simple majority vote a multiple good models can help to increase accuracy. This idea is really well explained in [Kaggle Ensembling Guide](https://mlwave.com/kaggle-ensembling-guide/). The idea is very simple:\n", "\n", "* If 0 or 1 model predicts 'Survived', the overall prediction will be 'Died'\n", "* If 2 or 3 models predict 'Survived', the overall prediction will be 'Survived'\n", "\n", "```{r}\n", "testClean$RF <- as.numeric(solution_rf)-1\n", "testClean$SVM <- as.numeric(solution_svm)-1\n", "testClean$Boost <- as.numeric(solution_boost)-1\n", "testClean$Sum <- testClean$RF + testClean$SVM + testClean$Boost\n", "testClean$Majority <- ifelse(testClean$Sum<=1, 0, 1)\n", "```\n", "\n", "Now, the question is of course: How often do the models disagree? Below you can see that they don't all agree in 35 cases (sum=1 or sum=2). Although this may not seem much, it actually is 8.3%. This percentage is quite high, but may also be caused by the 'quick and dirty' models in this version. I will need to improve the individual models first, before I can say if the ensemble gave me some extra points or not.\n", "\n", "```{r}\n", "table(testClean$Sum)\n", "```\n", "\n", "\n", "```{r}\n", "#writing final submission file\n", "submission <- data.frame(PassengerId = test$PassengerId, Survived = testClean$Majority)\n", "write.csv(submission, file = 'Titanic_ensemble.csv', row.names = F)\n", "```\n", "\n", "\n", "##Where is room for improvement?\n", "The accuracy on the training set is 88%. As you can see below, the main problem categories are P1Male and P3Female (relatively, P3Male holds more errors but many more observations).\n", "\n", "```{r}\n", "#also create ensemble on training set\n", "trainPredictions_rf <- predict(caret_matrix, trainClean)\n", "trainPredictions_svm <- predict(caret_svm, trainClean)\n", "trainPredictions_boost <- predict(caret_boost, trainClean)\n", "trainClean$RF <- as.numeric(trainPredictions_rf)-1\n", "trainClean$SVM <- as.numeric(trainPredictions_svm)-1\n", "trainClean$Boost <- as.numeric(trainPredictions_boost)-1\n", "trainClean$Sum <- trainClean$RF + trainClean$SVM + trainClean$Boost\n", "trainClean$Predictions <- ifelse(trainClean$Sum<=1, 0, 1)\n", "trainClean$Predictions <- as.factor(trainClean$Predictions)\n", "\n", "#create confusion matrix on training set\n", "confusionMatrix(trainClean$Predictions, trainClean$Survived)\n", "\n", "#plot differences between actual survived and predictions\n", "ggplot(trainClean[trainClean$Survived != trainClean$Predictions,], aes(x=PclassSex, fill=Predictions)) + geom_bar(stat='count')\n", "```\n", "\n", "###How to fix Male in 1st class issues?\n", "This class is hard to predict, as 37% of men in P1 survived while men overall have a much lower survival rate. Predictions produce many False Negatives. However as you can see below, there is a significant difference in survival density of men below and above appromimately 40. So the survival 'bonus' that children have in general, is for P1Male 'extended' to 40.\n", "\n", "I have actually tried to include this exception in the RF model in version 17, but I did not improve the scores. I assume this is because the survival rate in P1Male under 40 now really gets close to 50/50, which makes it very hard to predict with some degree of certainty.\n", "\n", "```{r}\n", "ggplot(all[indexAgeSurvivedNotNA,] %>% filter(Pclass=='1' & Sex=='male'), aes(x = Age, fill = Survived)) + geom_density(alpha=0.5, aes(fill=factor(Survived))) + labs(title=\"Survival density and Age\")\n", "```\n", "\n", "###How to fix Female in 3rd class issues\n", "Females in 3rd class have an overall 50/50 survival chance, which is hard to predict. Similar to the males in P1, I found something that is specific to this group. Solo women in P3 were actually better off than women in groups (65% versus 41% chance to survive). Similar to the Age issue in P1Male, I have not found a way to fix this as an exception in the models yet.\n", "\n", "\n", "##Verifying the models with the ROC curve\n", "\n", "Note: this section is not updated yet. For now, it only verifies the RF model.\n", "\n", "Although this exercise does not contain anything that requires changing the threshold for Died/Survived to anything other than 50%/50% (such as lowering the threshold to find a larger group pf people that might be sick), I still want to compose the ROC curve to see if my model looks good from an ROC point of view. Generally, if the AUC (Area Under the Curve) is 0.9 or better, a model is considered a very good classification model.\n", "\n", "As you can see below, the line looks pretty smooth and draws reasonably well towards the left upper corner, as it should.\n", "\n", "```{r}\n", "all_probs <- predict(caret_matrix, trainClean, type = \"prob\")\n", "probs_survived <- all_probs[,2]\n", "pred <- prediction(probs_survived, trainClean$Survived)\n", "perf <- performance(pred, \"tpr\", \"fpr\")\n", "plot(perf)\n", "```\n", "\n", "The AUC value of my model turns out to be 0.938. Knowing this confirms to me that my model is also good from an ROC point of view.\n", "\n", "```{r}\n", "#Get the AUC value\n", "perf <- performance(pred, \"auc\")\n", "perf@y.values[[1]]\n", "```\n", "\n", "\n"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "66a2cd1ff9e418170ed21b3c3706c377625ff79d", "_cell_guid": "9033e83d-7897-4e24-8bb3-ec5ca9901e89"}, "execution_count": 2}]}