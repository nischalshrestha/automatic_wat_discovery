{"cells":[{"metadata":{"_uuid":"341887c4e67444d232147e4682b8d9f76752a3f7","trusted":true,"_cell_guid":"4857a57f-ba28-41f2-b65b-8b017a8e61a3"},"cell_type":"code","source":"## I remember this dataset from getting started with R :)\n## Let's see if I improved any since then\n\noptions(scipen=999)\n\ngetwd() ## Where am I?\ndir() ## Any files or folders here?\nobjects()## Are any objects in memory yet?\n\n## Read data\ntrain <- read.csv(\"../input/train.csv\", stringsAsFactors=F)\ntest <- read.csv(\"../input/test.csv\", stringsAsFactors=F)\n\n## Compare column names\ntable(colnames(train)==colnames(test))\ncolnames(train)[!colnames(train) %in% colnames(test)]\n## They didn't include a label column in the test csv, but other than that they match up\n\nbarplot(table(train$Survived)) ## Can I show plots in these kernels?\n## 342 people survived,549 didn't make it\n\n## Let's check if the other columns are reliably filled out\ncat(\"\\n\\nNumber of NA values per column:\")\nfor (curcol in 1:ncol(train)) {\n    cat(\"\\n\\n*\\n\")\n    print(colnames(train)[curcol])\n    print(table(is.na(train[,curcol])))\n    cat(\"*\\n\\n\")\n}\n\n## So we don't know how old some of these people were exactly\n## Is age relevant to surviving? Yes, I would say so.\n## For example, if you're a senior, you might not have the dexterity to get to safety\n## and people might help someone younger first (I certainly would - sorry seniors!)\n## Since we have a relevant feature with missing values, I guess we want to impute (fill in)\n## the missing values first\n\ntable(is.na(test$Age))  ## There's missing values in test also. Let's just put everything\n                        ## in 1 dataframe for convenience\n\ntest$Survived <- NA\ntest <- test[,colnames(train)]\n\nalldata <- rbind(train, test)\nrm(list=c(\"train\", \"test\"))\n\ntable(alldata$Sex) ## Why are we storing this as characters?\nalldata$sex_male <- as.numeric(alldata$Sex == \"male\")\nalldata <- alldata[,colnames(alldata)[colnames(alldata)!=\"Sex\"]]\n\n## Take a look at names\nsample(alldata$Name, 10)\n## I looked at 30 random names and they all followed the same pattern\n## <Name>, <Title>. Name\n## So I guess we can assume everything before the combination of comma+space is useless and remove it\n## Example:\nmyname <- \"Jelle, Grand-master. Van den Eynde\"\nloc <- regexpr(\", \", myname, fixed=T)[1]+2\nsubstr(myname, loc, nchar(myname))\n## Ok, that works\nalldata$Name <- substr(alldata$Name, as.numeric(regexpr(\", \", alldata$Name, fixed=T))+2, nchar(alldata$Name))\n## We can do the same thing and ditch the name after the point, and then we're left with the title\nalldata$title <- substr(alldata$Name, 1, regexpr(\". \", alldata$Name, fixed=T)-1)\nalldata <- alldata[,colnames(alldata)[colnames(alldata)!=\"Name\"]]\ntable(alldata$title)\n## We found some ultra rare titles that I think are basically synonyms for \"Mr\" now\nalldata[alldata$title %in% c(\"Capt\",\"Col\",\"Don\",\"Dr\", \"Sir\", \"Major\",\"Rev\"),]$title <- \"Mr\"\n## And some rare titles that are almost synonyms for \"Mrs\"\nalldata[alldata$title %in% c(\"Dona\", \"Lady\", \"the Countess\"),]$title <- \"Mrs\"\n## And some rare titles that are almost synonyms for \"Miss\"\nalldata[alldata$title %in% c(\"Ms\", \"Mme\",\"Mlle\"),]$title <- \"Miss\"\nsummary(alldata[alldata$title == \"Master\",]$Age) ## Oh, the title \"Master\" in english hints at young age\n## And I know \"jonkheer\" means \"young gentleman\" in dutch because that's my native language\nalldata[alldata$title==\"Jonkheer\",]$title <- \"Master\"\nalldata$title <- as.factor(alldata$title)\n\n## Take a look at cabin\nsample(alldata$Cabin, 10) ## Oh. I missed NAs here because they're just blank fields\ntable(alldata$Cabin==\"\")\n## Ouch. Most of these are missing.\n## I think we have two options here\n## 1. Divide into only 2 groups (had a cabin, had none)\n## 2. Divide further by cabin letter\n## I don't see how the cabin number could be useful. Maybe if we could find a layout\n## of where the cabins physically were we could find a pattern?\nalldata$Cabin <- substr(alldata$Cabin, 1, 1)\n## I can't see how it can possibly help us to keep these cabins with like 20 occurences\nalldata[alldata$Cabin %in% c(\"A\",\"D\",\"E\",\"F\",\"G\",\"T\"),]$Cabin <- \"other\"\nfor (curvar in unique(alldata$Cabin)) {\n        cat(paste(\"*\\nCabin type:\",curvar,\"\\n\"))\n        i <- alldata$Cabin == curvar\n        print(summary(alldata[i,]$Age))\n        cat(\"\\n\")\n}\n## You can see from the summary stats that Cabin type has no effect on age, \n## what could be relevant is if they have a cabin or not.\n## How about survival?\nfor (curvar in unique(alldata$Cabin)) {\n        cat(paste(\"*\\nCabin type:\",curvar,\"\\n\"))\n        i <- alldata$Cabin == curvar\n        print(length(alldata[i,]$Survived))\n        print(summary(alldata[i,]$Survived))\n        print(sd(alldata[i,]$Survived, na.rm=T))\n        cat(\"\\n\")\n}\n## There are big differences, but the samples are soo small. This is a tough question for me.\n## If we had a real sample we could make a validation test and find out what performs better\n## I guess we can look at the p values of a linear regression\ni <- !is.na(alldata$Survived & alldata$Cabin != \"\")\nmylm <- lm(data=alldata[i,], Survived~Cabin)\nsummary(mylm)\n## The estimates differ a lot and the p values are very small\n## So I would guess it's worth keeping them separate for predicting survival\nalldata[alldata$Cabin==\"\",]$Cabin <- \"none\"\nalldata$Cabin <- as.factor(alldata$Cabin)\nalldata$had_cabin <- as.numeric(alldata$Cabin != \"none\")\n\n\n## Take a look at points of embarkation data\ndata.frame(table(alldata$Embarked)) ## This also has two \"blank\" but not missing values\n## If tickets were sold in the same embarkation place at the same time, maybe we can see?\nalldata[alldata$Embarked==\"\",] ##Look at the rows, maybe it can be easily guessed\nmean(as.numeric(alldata[alldata$Embarked==\"S\",]$Ticket), na.rm=T)\nmean(as.numeric(alldata[alldata$Embarked==\"Q\",]$Ticket), na.rm=T)\nmean(as.numeric(alldata[alldata$Embarked==\"C\",]$Ticket), na.rm=T)\n## No, that doesn't seem very convincing\n## I don't have another idea right now so \n## I will just assume they were part of the overwhelming majority, \"S\"\nalldata[alldata$Embarked==\"\",]$Embarked <- \"S\"\nalldata$Embarked <- as.factor(alldata$Embarked)\n\n## There is one 60-year old gentleman whos Fare is NA\n## There are 240 other older gentlemen who generally paid alot,so I'll give him their median\nalldata[is.na(alldata$Fare),]$Fare <- median(alldata[alldata$title==\"Mr\" & alldata$Age > 50,]$Fare, na.rm=T)\n\n## Take a look at tickets\nsample(alldata$Ticket, 10) ## I'm not sure what some of the characters mean. A/5?\nhead(alldata[substr(alldata$Ticket, 1,1) == \"A\",], 20)\n## They seem to be wealthier people, but that info is already available in other columns\n## I don't see how I can garner any useful info from this column or the \"PassengerId\" column\n## edit: actually we ended up needed PassengerId to submit the result!\nalldata <- alldata[,colnames(alldata)[!colnames(alldata) %in% c(\"Ticket\")]]\n\n## Now we're finally ready to predict the missing ages\n## We know we'regoing to use had_cabin instead of Cabin\n## what model should we use? linear regression and randomForest\n## seem reasonable and safe to me\ni <- !is.na(alldata$Age)\nmyformula <- as.formula(\"Age ~ Pclass + SibSp + Parch + Fare + had_cabin + Embarked + sex_male + title\")\n\nmylm <- lm(data=alldata[i,], formula=myformula)\nsummary(mylm) ## None too impressive. Some factors are useless too, which seems to favor randomFOrest\n## Also, in the end had_cabin isn't even useful ¯\\_(ツ)_/¯\n\nrequire(randomForest)\npredictcols <- c(\"Pclass\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"title\",\"had_cabin\",\"sex_male\")\nmyforest <- randomForest(x=alldata[i,predictcols], \n                y=alldata[i,]$Age,\n                mtry=4, ntree=9000, sampsize=300, importance=T)\nvarimportance <- as.data.frame(myforest$importance)\nvarimportance <- varimportance[order(varimportance$IncNodePurity),]\n## Getting the varimportance allows you to check if ditching some of the worst variables\n## will improve your performance. This kind of tuning would have been more useful if we had\n## a bigger dataset. Because we can't really do any validation, I'm using randomForest which\n## is quite robust to overfitting\n\nalldata$agepredict <- predict(myforest, newdata=alldata[,predictcols])\nalldata[sample(1:nrow(alldata), 40),c(\"Age\",\"agepredict\")] ##hmmm.. better than nothing\nalldata[sample(1:nrow(alldata), 40),] ## I would keep trying if this was my job but let's proceed ^_^:v\nalldata[is.na(alldata$Age),]$Age <- alldata[is.na(alldata$Age),]$agepredict\nalldata$agepredict <- NULL\n\n\n## Now our data is fairly clean\n## - We're skipping validation and tuning because the dataset is so small\n## Honestly, everyone just makes 100 submissions on kaggle anyway so that's where the tuning happens\n\n## Let's try randomForest first since our datais prepped and I think it works\n## well with small datasets\n\ni <- is.na(alldata$Survived)\nmyforest <- randomForest(data=alldata[!i,], Survived ~ Pclass + Age + SibSp + Parch + Fare + Cabin + Embarked + sex_male + title,\n                             ntree=10000, sampsize = 250, mtry=4)\ntable(round(predict(myforest, newdata=alldata[!i,])) == alldata[!i,]$Survived)\nalldata$forestpred <- round(predict(myforest, newdata=alldata))\nrm(myforest)\n\n## Let's try xgboost\n## - In order to use xgboost, we need to make a numerical matrix\n\n## Convert factors to dummy variables (numerical values)\nfor (curcol in c(\"Cabin\",\"Embarked\",\"title\")) {\n    for (curlevel in as.character(unique(alldata[,curcol]))) {\n        alldata$newcol <- as.numeric(alldata[,curcol] == curlevel)\n        names(alldata)[ncol(alldata)] <- paste(curcol, curlevel, sep=\"_\")\n    }\n    alldata[,curcol] <- NULL\n}\n\n## Separate labels\nlabels <- alldata$Survived\nids <- alldata$PassengerId\nforestpredictions <- alldata$forestpred\n\n## Separate training and testing data\ntesti <- is.na(alldata$Survived)\nalldata$Survived <- NULL\nalldata$PassengerId <- NULL\nalldata$forestpred <- NULL\nalldata <- as.matrix(alldata)\nlabels <- labels[!testi]\ntestids <- ids[testi]\nforestpredictions <- forestpredictions[testi]\ntrain <- alldata[!testi,]\ntest <- alldata[testi,]\n\nrequire(xgboost)\nmyxgb <- xgboost(data=train, label=labels, \n                 max_depth=13,nrounds=60, objective = \"binary:logistic\")\n\n## Create our submission\nsubmission <- data.frame(\n    PassengerId = testids,\n    Survived = round((predict(myxgb, newdata=test)*0.2) + (forestpredictions*0.8))\n)\n\n\nwrite.csv(submission, file=\"output.csv\", row.names=F)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"947d82f5456f7c68609b67ffc4e2c6f0e743e71a","trusted":true,"_cell_guid":"bcbddab2-bbb8-42aa-b6fc-de7cc2d3e346"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}