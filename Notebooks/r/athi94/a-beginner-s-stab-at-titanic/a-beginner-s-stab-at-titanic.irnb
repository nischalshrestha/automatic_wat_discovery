{"nbformat_minor": 2, "nbformat": 4, "cells": [{"source": "Introduction\n=========\n\nHi all, this is my first Kaggle kernel and the first data science problem I've tried to tackle by myself. Any advice would be appreciated, particularly correction of errors of which I'm sure there are a few!", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "10efd95221ab0ee97dd2d05e6a869e2ded79627d", "_cell_guid": "d481a061-7128-4b58-9581-23a484164252"}, "execution_count": null}, {"source": "Prepping the Data\n================\n\nLoading\n----------", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "75144fa48a87b9355c888edc23ccf504778bb92c", "_cell_guid": "93907919-ded8-490e-b00e-c9d7fe312533"}, "execution_count": null}, {"source": "fr_train = read.csv('../input/train.csv', na.strings='')\nfr_test = read.csv('../input/test.csv', na.strings='')\n\nfr_test$Survived = rep(NA, nrow(fr_test))\nfr_train$Set = rep(\"train\", nrow(fr_train))\nfr_test$Set = rep(\"test\", nrow(fr_test))\n\nfr_titanic = rbind(fr_train, fr_test)\n\ndim(fr_train)\nhead(fr_train)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "310171af41071cea0bc4043098ffd566914aabb2", "_cell_guid": "c6b08e12-a94c-4e20-9b29-6d2d157efb2c"}, "execution_count": 1}, {"source": "Right off the bat we can spot an idiosyncracy in our dataset, namely that we seem to be missing a lot of values in our `Cabin` feature. Dealing with missing data is an important step in any machine learning pipeline, and we'll spend a bit of time on it a little later on. But first, let's continue exploring some basic properties of the training portion our dataset.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "e556e73603e99eadaa705f5d1042f566232ea1a2", "_cell_guid": "dc1d4dbc-68f1-48c2-99a7-24872958651c"}, "execution_count": null}, {"source": "summary(fr_train)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "c280857be9f9e597da6fb4c303a196f9901447c8", "_cell_guid": "653709bd-3ef9-4f98-92db-40e278129d5b"}, "execution_count": 1}, {"source": "Let's run through what we see here.\n\nFirst of all the mean of `Survived` is 0.38, meaning only 38% of people survived in this dataset. Naturally this means we have more data pertaining to passengers who died, so it wouldn't be too suprising if our model ends up being better at able to predict who dies than who survives but this is something we'll have to evaluate later.\n\nThere's also more males than females in this dataset by a fairly significant margin, 577 versus 314. Most interestingly take a look at `Cabin`, there's a whopping 687 NA's. That's a lot of missing data, note that `Age` and `Embarked` are missing values as well but not nearly as much.\n\nI like to quickly make helper functions which give me neat, explicit output about what I'm concerned with. Since we're about to deal with a lot of missing data I'm going to make a short, simple function which summarises the missing data in any generic dataframe.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "63a62f044a4241548e85f05559ceccf058fbb49b", "_cell_guid": "d30af6f8-ee7a-452a-b355-ca64285d43bd"}, "execution_count": null}, {"source": "naSummary = function(df) {\n    naCount = sapply(df, function(col) {\n        sum(is.na(col))\n    })\n    \n    return (data.frame(naCount, naPc=naCount/nrow(df)))\n}\n\nnaSummary(fr_titanic)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "e4568784fbf86d523a6f95618f63ff94abf36c98", "_cell_guid": "312d0791-1c88-4965-ba8c-f0af6b7556c1"}, "execution_count": 1}, {"source": "Remember we're only missing `Survived` data because we made NA's when merging the test and train sets. Let's take a look at our data types as the last preliminary check to make sure everything looks good.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "13ff7f2495612d02be0f2824dd0d68f08e12897a", "_cell_guid": "87296f9d-a740-4b49-9f6f-eb148ec4c892"}, "execution_count": null}, {"source": "str(fr_titanic)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "bb52e73920ea8c9d1af538647ad5573ef447f48a", "_cell_guid": "24be9c67-24ac-4b47-888f-4ac7df03d71e"}, "execution_count": 1}, {"source": "We should remove passenger ID because it's a useless feature, let's also explicitly convert `Survived` to a factor. Remember factors assume no order, categorical features with explicit order should be kept as ints, e.g. `Pclass`.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "cfa9b4e9de9e3b5a4369447d2f062de1af288a9c", "_cell_guid": "f95d146d-bd64-49bf-8516-be7dbdc5a1f7"}, "execution_count": null}, {"source": "fr_titanic$Survived = as.factor(fr_titanic$Survived)\nfr_titanic = subset(fr_titanic, select=-c(PassengerId))\n\nstr(fr_titanic)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "32d06efaa436efc77cca3fafebe057a3fff35998", "_cell_guid": "cfd4cc1d-fbc8-46b0-a2bc-a05819e57e44"}, "execution_count": 1}, {"source": "Missing Data Imputation\n----------------------\n\nThere's essentially two strategies you can employ when you have to deal with missing data. You can throw out the entries with missing variables, or you can replace the missing variables with your best guess. This latter process is called imputation. The downside of throwing data out is simply that you'll have less data to train your model on, but it's really simple to do. Strategies for imputation can range from very easy to quite complex, it's an extensive topic in and of itself and you should spend some time reading up on it.\n\n### Embarked\n\nLet's go from easy to hard, and start off with the `Embarked` feature which is only missing two values. This is a totally trivial amount of missing data so we'll just use a really simple 'most frequent' imputation which is exactly what it sounds like, replace the missing value with the most frequent level for that feature.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "bd16ff2e294f811ccdbd6f1d82bc79735271cde1", "_cell_guid": "ab3aca03-4429-4259-952e-44f7b8be8844"}, "execution_count": null}, {"source": "mcl = fr_titanic$Embarked[which.max(fr_titanic$Embarked)]\nfr_titanic$Embarked[which(is.na(fr_train$Embarked))] = mcl\n\nnaSummary(fr_titanic)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "cc4827c5d553eb3c715e332dcaa333a4b7df7185", "_cell_guid": "6fa364b2-d30a-4365-b919-b2b4d6e02fb7"}, "execution_count": 1}, {"source": "### Fare\n\nWe'll do the same thing for our one missing value of Fare, except now that it's a numeric feature we'll use a mean imputation.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "83b99de43fb2fef0ea5300cc5ccc97f7f861e062", "_cell_guid": "b454c439-0588-4f7d-a044-dc366534afe7"}, "execution_count": null}, {"source": "fr_titanic$Fare[which(is.na(fr_titanic$Fare))] = mean(fr_titanic$Fare, na.rm=TRUE)\nnaSummary(fr_titanic)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "799b8be488723b4c82f544705f03686245ca6814", "_cell_guid": "c02f67c1-199a-47b3-a38b-e826af871739"}, "execution_count": 1}, {"source": "### Age\n\n`Age` is a bit harder, we're missing a non-trivial amount of values. We're going to attempt a random regression imputation. This involves developing a regression model between `Age` and a set of predictors from the dataset, then adding a residual term to the prediction in order to reintroduce randomosity to the imputed values. Effectively this is another machine learning problem within our bigger Titanic machine learning problem!\n\nWe're going to need features so we can do a bit of feature engineering here. In particular I want to extract the Title of each passenger from the `Name` feature, a look at the data shows that the title \"Master\" seems to be reserved for males under the age of 13. I'd also expect there to be a correlation between the title \"Miss\" and younger females.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "497a3b3a18071c57a3901f493b591eda4946b5fc", "_cell_guid": "1b4024dd-dbfc-4fcd-9cd3-44d9964fd6e6"}, "execution_count": null}, {"source": "getTitle = function(name) {\n    postcom = trimws(strsplit(as.character(name), ',')[[1]][2])\n    title = strsplit(postcom, ' ')[[1]][1]\n    return (substr(title, 1, nchar(title)-1))\n}\n\nfr_titanic$Title = as.factor(sapply(fr_titanic$Name, getTitle))\nfr_titanic = fr_titanic[c(\"Survived\", \n                        \"Pclass\",  \n                        \"Name\",\n                        \"Title\",\n                        \"Sex\", \n                        \"Age\", \n                        \"SibSp\", \n                        \"Parch\", \n                        \"Ticket\", \n                        \"Fare\", \n                        \"Cabin\", \n                        \"Embarked\",\n                        \"Set\")]\n\nhead(fr_titanic)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "dd696b1db9766f66df21c322077b933858d9afd1", "_cell_guid": "2a571552-becc-4a52-828c-291e454b38e1"}, "execution_count": 1}, {"source": "So far looks good! Let's use `table()` to get a better look.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "5f573a9c48184d3849d90cdbf5cc7d53c272bdf1", "_cell_guid": "be018dfb-8583-4268-a001-837d485852ca"}, "execution_count": null}, {"source": "table(fr_titanic$Title)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "1e022cee1f10f10464d2bc2cf9670e7f9c5a3e18", "_cell_guid": "51a9c26c-84d0-44ab-9769-c39b13898732"}, "execution_count": 1}, {"source": "There's a lot of special titles being used for a small number of passengers. Let's coerce them to common values so we only deal with the following subset of titles:\n\n* Mr\n* Mrs\n* Miss\n* Master\n\nWe'll use the following mappings.\n\n* Dr, Rev, Major, Col, Jonkheer, Don, Sir, Capt -> Mr\n* Mlle, Ms -> Miss\n* Dona, Lady, Mme, th -> Mrs\n\nI think there would be some amount of predictive power to these title if we had more data, but as it stands these honorifics just don't have enough entries to act as standalone features so we're merging them with the most appropriate alternate level.\n\nSince we're removing a lot of levels we have to use the `droplevels()` command to remove them from the feature within R.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "080c0d1fba46edf5fbb2f2328811582ede709ef8", "_cell_guid": "b4572c26-530d-4211-9d8c-44941ed3aa77"}, "execution_count": null}, {"source": "mr_alias = c('Dr', 'Rev', 'Major', 'Col', 'Jonkheer', 'Don', 'Sir', 'Capt')\nmrs_alias = c('Dona', 'Lady', 'Mme', 'th')\nmiss_alias = c('Mlle', 'Ms')\n\nfr_titanic$Title[which(fr_titanic$Title %in% mr_alias)] = 'Mr'\nfr_titanic$Title[which(fr_titanic$Title %in% mrs_alias)] = 'Mrs'\nfr_titanic$Title[which(fr_titanic$Title %in% miss_alias)] = 'Miss'\n\nfr_titanic$Title = droplevels(fr_titanic$Title)\nsummary(fr_titanic$Title)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "083e9f951e8d4cf384514d908de8d8ba9645ff0a", "_cell_guid": "0dfba0c9-2b0b-4e6b-9f1f-357978fffa95"}, "execution_count": 1}, {"source": "Great! Now that's all done and we have what's hopefully a useful, additional feature for our Age random regression imputation. We can finally get started with our actual random regression to impute our missing `Age` values.\n\nFirst I'm going to define a new dataframe which contains only the features we need to deal with to train our regression model, this means excluding `Name`, `Ticket`, `Cabin` as well as all our test data. We also have to exclude `Survived` because we need to impute missing values in the test set as well.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "05fa7474e0dab7b947c708e7e1f338e802e5c934", "_cell_guid": "0081f9d9-717c-47bf-9163-eff981695bae"}, "execution_count": null}, {"source": "rr_train = subset(fr_titanic, select=-c(Survived, Name, Ticket, Cabin, Set))\nrr_train = na.omit(rr_train) # Omits test data as Survived values are all NA's\n\nhead(rr_train)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "50db118563e8bd4bafde3c726f1d12bf947b534a", "_cell_guid": "9eb7e2ea-aa5f-42ca-9024-44e7f3fe8582"}, "execution_count": 1}, {"source": "lm.fit = lm(Age ~ ., data=rr_train)\nsummary(lm.fit)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "5017dd181175aaf667a75f8207013dc356b52823", "_cell_guid": "4bede0b2-fa0e-467e-ae5a-0fb2571fbd2d"}, "execution_count": 1}, {"source": "Let's take a quick look at these p-values. `Pclass` is a statistically significant feauture in predicting `Age`, boxplots are useful in investigate the nature of the relationship further.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "c1450515257bee063df352f8651ce0655857592d", "_cell_guid": "f28d249a-bd38-4ec8-81ef-4e98c4096f29"}, "execution_count": null}, {"source": "plot(as.factor(rr_train$Pclass), rr_train$Age, xlab=\"Passenger Class\", ylab=\"Age\")", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "7f5559c1661380a9797ff7b57c4ad6503e6a52d2", "_cell_guid": "d990579c-2441-42a1-88d8-15a558666c67"}, "execution_count": 1}, {"source": "Looks like first class passengers skew older which isn't suprising. `Title` is a significant feature too so our little bit of feature engineering has paid off! `Sex` has no significance in predicting `Age` which isn't particularly surprising. The number of siblings/spouses in `SibSp` is significant as well, my guess is that younger people tend to have a higher count as they likely have siblings on board. Another boxplot should help us determine this.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "bcbe4ea431b45c2ed1201a74d4316f322d0c4f16", "_cell_guid": "2615dff2-2476-41aa-b93b-97328949944d"}, "execution_count": null}, {"source": "plot(as.factor(rr_train$SibSp), rr_train$Age, xlab=\"# siblings + spouses\", ylab=\"Age\")", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "f95c872c25fd9aee88dd98a29c27b3da75e9a6cf", "_cell_guid": "f43336f5-9d98-4069-8136-ff10d8f5f5b4"}, "execution_count": 1}, {"source": "Bingo, looks like that's exactly the trend. The last significant feature is `Embarked`, in particular if you embarked from location Q. To be honest I have no idea why, if you do know leave a comment because I'm curious!\n\nLet's create a simpler regression model which excludes the insignificant features: `Sex`, `Parch` and `Fare`.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "72d0b677a5b1934231f35d8f45430589c03e82d8", "_cell_guid": "42f7b28b-a0e3-4367-808a-e603d258997f"}, "execution_count": null}, {"source": "lm.fit = lm(Age ~ Pclass + Title + SibSp + Embarked, data=rr_train)\n\nsummary(lm.fit)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "4783d9e9da2ebfdc5573b7d41771fb58fa29c88a", "_cell_guid": "a441fa69-ca32-48f5-85de-dd7e4e68dc5b"}, "execution_count": 1}, {"source": "Now looking at our $R^2$ this definitely isn't the best `Age` predictor but remember this is just for imputation, effectively we're trying to maintain the relationships between `Age` and other variables which exist so as not to diffuse the strength of any patterns in the data when we build our actual Survival predictor. Other strategies like estimating a distribution then sampling from that randomly to fill missing values maintains the state of information we have about `Age`, but potentially weakens the patterns between `Age` and other features.\n\nFinally, let's do our imputation. But first I'm going to see if there's any people with the title \"Master\" that have missing ages, remember that title appears to be reserved for males under the age of 13. It'll be an interesting test to see if our imputed ages maintain that criteria.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "a5cbf9d15856ddfe373d9ddcb3699c7086c08e99", "_cell_guid": "7d76e060-6b1f-4824-a308-36cfae54727b"}, "execution_count": null}, {"source": "missing_age_masters = which(fr_titanic$Title == 'Master' & is.na(fr_titanic$Age))\nfr_titanic[missing_age_masters, ]", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "19186872062e278f531934e31fafc17377c841be", "_cell_guid": "c1f5822c-05a2-4092-8a7a-4b6aa3917fe8"}, "execution_count": 1}, {"source": "set.seed(10) # this makes the kernel results reproducible\n\ndet_imputed = predict(lm.fit, fr_titanic[which(is.na(fr_titanic$Age)), ])\nrandom_imputed = rnorm(length(det_imputed), det_imputed, abs(residuals(lm.fit)))\n\n# We need to round the values to integers and floor them at a value of 1\ndet_imputed[which(det_imputed < 0)] = 1\ndet_imputed = round(det_imputed)\n\nrandom_imputed[which(random_imputed < 0)] = 1\nrandom_imputed = round(random_imputed)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "a79567bbf026e92746d66aacc909663b974bc235", "_cell_guid": "dd703cee-4383-4018-bd48-a0bfa141881b"}, "execution_count": 1}, {"source": "Let's take a look at the original values vs the imputed values.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "2c1b227ae35a64c94203df044c79d4f3bb33f3a8", "_cell_guid": "03de8754-2439-4b9f-ae18-62d4f6e90004"}, "execution_count": null}, {"source": "par(mfrow=c(3,1))\nhist(rr_train$Age, breaks=10, freq=F)\nhist(det_imputed, breaks=10, freq=F)\nhist(random_imputed, breaks=10, freq=F)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "68a50c966ee27af627e2939ffeda4792f974b6fb", "_cell_guid": "bd4ed940-327b-4c5f-b7c8-6384b8b7257c"}, "execution_count": 1}, {"source": "Under the assumption that the missing values are missing completely at random and with sufficient missing values, we would expect our histograms of the imputed values to be very similar to the original values. This seems to be what we're seeing here. It's also good to compare the deterministic imputations vs the random imputations, the deterministic imputations lie on the regression line by definition. This means that it assumes there's a deterministic relationship between the predictors and the target which is clearly not likely to be accurate. The random imputations take the deterministic imputations and adds an error term proportional to the residuals in the regression fit. Effectively we try and reintroduce appropriate variance in the imputed values.\n\nViolin plots really help us see this effect.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "e1b4e6f76beed2cc4dca7d1d6870f0c5e2d9fec1", "_cell_guid": "c48c09b2-e39b-49a6-88a6-4e917ea9b68b"}, "execution_count": null}, {"source": "library(ggplot2)\n\nkde_mat = rbind(cbind(rr_train$Age, rep(\"Original\", length(rr_train$Age))),\n        cbind(det_imputed, rep(\"Deterministic Imputation\", length(det_imputed))),\n        cbind(random_imputed, rep(\"Randomised Imputation\", length(random_imputed))))\n\nkde_df = data.frame(Age=as.numeric(kde_mat[,1]), Source=as.factor(kde_mat[,2]))\n\nggplot(kde_df, aes(x=Source, y=Age, fill=Source)) + geom_violin()", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "59930c25aa670c4029729112c5a5181a2f1dc53e", "_cell_guid": "202491b7-176f-4c23-830c-ded2b4ae87aa"}, "execution_count": 1}, {"source": "Let's merge the imputed values back into our dataframe now.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "a8d705a5fc654b1dc1bf109bba434a7d5144232a", "_cell_guid": "d8e90a16-2e94-4be4-92b2-beb1e0e869b0"}, "execution_count": null}, {"source": "fr_titanic$Age[which(is.na(fr_titanic$Age))] = random_imputed\nnaSummary(fr_titanic)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "9a1e1115b74ce253c707d3898dabf91c951a023d", "_cell_guid": "0d87f31f-b8af-4e44-a062-36a824dcfa2c"}, "execution_count": 1}, {"source": "Let's go back to the 4 passengers with the \"Master\" title and missing ages now and see what the randomised imputations they received were.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "0dd0087b4ef49d9ccef2eee2592c1ce6cad18802", "_cell_guid": "0c1fe54d-69fb-48f8-8bc0-ebe8b86938a2"}, "execution_count": null}, {"source": "fr_titanic[missing_age_masters,]", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "7cfcec17a7a86e3ddf700bcc65c4649d16c6aa46", "_cell_guid": "bee2e198-294a-45de-87dc-3844de00684e"}, "execution_count": 1}, {"source": "Remember we expected them to have an `Age` of less than 13 and we do see that, this is a good indication that our random regression imputation has succeeded in preserving relationships between Age and the other features in the dataset.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "53e16d6b178bfa893ff375459221b6f99114174d", "_cell_guid": "8a5a9808-1ceb-4158-9193-c1a7578292d5"}, "execution_count": null}, {"source": "### Cabin\n\nLet's be practical, it's not really possible to impute values for `Cabin` given the nature of the data. Instead let's focus on transforming it into a useful feature in the feature engineering phase.\n\nFeature Engineering\n===========\n\nCabin\n-----\n\nSince we're missing most of our Cabin values the simplest strategy to see if this could be a useful feature would be to encode it as a simple binary variable, whether a Cabin is listed or not.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "17fa76f77ec08c5b6f1f304af0621d6fe01032f0", "_cell_guid": "3c925e13-a0a7-4d9c-aafe-61e90bf1bd71"}, "execution_count": null}, {"source": "library(reshape2)\n\nfr_titanic$hasCabin = as.factor(!is.na(fr_titanic$Cabin))\n\n# Make a convenience feature which is directly descriptive\nSurvived_Desc = ifelse(fr_titanic$Survived == 1, \"Survived\", \"Died\")\n\nfreq = table(fr_titanic$hasCabin, Survived_Desc)\nfreq_df = as.data.frame.matrix(freq)\n\nfreq_df = data.frame(Cabin=row.names(freq_df), freq_df)\nfreq_df = melt(freq_df, id.vars=\"Cabin\")\n\nggplot(freq_df, aes(x=Cabin, y=value)) + geom_bar(aes(fill = variable), position = \"dodge\", stat=\"identity\")", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "5cb47ff7809ef5ae9ceb9674baa177f666946e9f", "_cell_guid": "9e9ff83e-f952-4911-8b64-3fbef5a6f09a"}, "execution_count": 1}, {"source": "Luckily for us `hasCabin` may actually has some decent predictive power, we can see that those with a listed cabin are far more likely to survive than those without. The next step I think here is to extract the deck out of the `cabin` for each passenger with a `cabin` value and see if there's predictive power associated with that.", "outputs": [], "cell_type": "markdown", "metadata": {"collapsed": true, "_uuid": "85f28e92774e8fbc546fe900382fcce44e82767e", "_cell_guid": "d9fff799-8e42-4ea5-94e7-d949de7b76b7"}, "execution_count": null}, {"source": "fr_titanic$Deck = sapply(fr_titanic$Cabin, function(cabin) {\n    substr(as.character(cabin), 1, 1)\n})\n\nfr_titanic$Deck[which(is.na(fr_titanic$Deck))] = \"None\"\nfr_titanic$Deck = as.factor(fr_titanic$Deck)\n\nsummary(fr_titanic$Deck)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "3d58862db59b360216feb04787db266a65debf3c", "_cell_guid": "ae5fc19a-7d85-4d04-99f1-01f5a3827612"}, "execution_count": 1}, {"source": "Since there's only one value for `T` we'll just coerce it into factor `None`.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "97ef46e2c180b2b8dc480c52511c49b7d50c4102", "_cell_guid": "92522a0d-c0a3-4ccb-a85a-942dd50ed916"}, "execution_count": null}, {"source": "fr_titanic$Deck[which(fr_titanic$Deck == 'T')] = as.factor('None')\nfr_titanic$Deck = droplevels(fr_titanic$Deck)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "140eefd90d16846f225dfbe819de8a91db190784", "_cell_guid": "8bea4135-68b5-43fa-b665-3505be73c768"}, "execution_count": 1}, {"source": "freq = table(fr_titanic$Deck, Survived_Desc)\nfreq_df = as.data.frame.matrix(freq)\nfreq_df = data.frame(Deck=row.names(freq_df), freq_df)\n\nfreq_df = melt(freq_df, id.vars=\"Deck\")\n\nggplot(freq_df, aes(x=Deck, y=value)) + geom_bar(aes(fill = variable), position = \"dodge\", stat=\"identity\")", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "50d6c42b3a53f3fa05386a58b626e3464c1c2ee7", "_cell_guid": "eac6f99d-35d6-4b25-9aec-f9178a8e1662"}, "execution_count": 1}, {"source": "## Tickets\n\nSince group tickets were available, we can introduce a new feature which guesses whether a person travelled in a group and then see if that has a relationship with survival rate.\n", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "0a4e52bc3231b765f42dce517862aaf80be596a7", "_cell_guid": "f3ce3a14-22d2-4f0b-9a77-cdeb00359bd0"}, "execution_count": null}, {"source": "inGroup = as.factor(duplicated(fr_titanic$Ticket))\n\nfreq_df = as.data.frame.matrix(table(inGroup, Survived_Desc))\nfreq_df = data.frame(inGroup=row.names(freq_df), freq_df)\n\nfreq_df = melt(freq_df, id.vars=\"inGroup\")\n\nggplot(freq_df, aes(x=inGroup, y=value)) + geom_bar(aes(fill = variable), position = \"dodge\", stat=\"identity\")", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "57ff854cc8b5504babd71a45239ef11d648d486e", "_cell_guid": "d60bd2a1-a9b1-4036-b25e-563baf956a0d"}, "execution_count": 1}, {"source": "Looks like if you're not in a group you are more likely to die than those who are not, so we can add this as a proper feature in our dataframe now.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "937fa653a5463cf411d4e1ff0c63e03131632d15", "_cell_guid": "7d4c840b-bca5-4211-a9e0-e6eef23b7b7f"}, "execution_count": null}, {"source": "fr_titanic$inGroup = inGroup", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "987f032835fb1204043fe5ad4896fc655179b3d3", "_cell_guid": "c9cef19b-5469-4bfe-833c-8019643b91e2"}, "execution_count": 1}, {"source": "## Women and Children First!\n\nWe don't really have to worry about the 'woman' part seeing as that's already handled by the `Sex` feature. What we can investigate is whether there's any merit to introducing a new `Child` feature rather than just relying on ages. Or more generally binning the ages into a set of wider levels.\n\nFirst off let's plot the distribution of `Survival` vs `Age`.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "8e2d3fd84fc973daca1466414573620923264e81", "_cell_guid": "02dc7fd9-bf8b-41bf-bae0-840bb6583a33"}, "execution_count": null}, {"source": "fr_train = fr_titanic[which(fr_titanic$Set == 'train'), ]\n\nuniq_ages = sort(unique(fr_train$Age))\n\nsurvival_rates_by_age = sapply(uniq_ages, function(age) {\n    mean(fr_train[which(fr_train$Age == age), ]$Survived == 1)\n})\n\nuniq_ages", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "ef83a47449d9c73978adb5f17fb39b76cdc4ffc5", "_cell_guid": "000be72f-43b4-4ca8-86ff-cd002845922b"}, "execution_count": 1}, {"source": "Looks like in the original data there was some fractional ages. Let's round these for simplicity, redo our survival rate calculation, and plot the results.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "87d66137832c1ac4e537cf6ff0bf8077e7315639", "_cell_guid": "cce2eb61-b72f-42a3-b419-2cbf540bf7e9"}, "execution_count": null}, {"source": "fr_train$Age = round(fr_train$Age)\nuniq_ages = sort(unique(fr_train$Age))\n\nsurvival_rates_by_age = sapply(uniq_ages, function(age) {\n    selection = fr_train[which(fr_train$Age == age), ]$Survived\n    mean(selection == 1)\n})\n\nage_surv_rate_df = data.frame(Age=uniq_ages, SurvivalRate=survival_rates_by_age)\nggplot(age_surv_rate_df, aes(x=Age, y=SurvivalRate)) + geom_col()", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "c1ddc9c4286db8b75f887ce8c0a07673ab53016b", "_cell_guid": "0d0ee261-af6b-4411-a70b-ae87c8ad5a1c"}, "execution_count": 1}, {"source": "There's actually a lot of noise in this plot and it's difficult to make out a clear trend because there's not many samples for each individual age. Instead let's bin the ages into groups of 5 and plot the average survival rate for each bin.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "929d1be0d49019c125f35e32799373d7283520e0", "_cell_guid": "642aec8d-54fa-4c2c-9592-cfbda5f37ec0"}, "execution_count": null}, {"source": "age_bins = split(uniq_ages, ceiling(seq_along(uniq_ages)/5))\nbinned_surv_rate = sapply(age_bins, function(bin) {\n    mean(age_surv_rate_df[which(age_surv_rate_df$Age %in% bin), ]$SurvivalRate)\n})\n\nbinned_age_surv_df = data.frame(AgeBin=factor(names(age_bins), levels=names(age_bins)), SurvivalRate=binned_surv_rate)\nggplot(binned_age_surv_df, aes(x=AgeBin, y=SurvivalRate)) + geom_col()", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "f92e2f3b4d926d0a946fce77ac650e6cf9abf03c", "_cell_guid": "a53465d3-9e8d-42df-8631-354f1a3d3242"}, "execution_count": 1}, {"source": "This gives us a much clearer picture of what's going on. First off we see that the first bin has the highest survival rate by far, this would correspond to passengers in the age range of 0 to 4. Children typically have a higher survival rate as we can see in bins 2, 3, and 4 which corresponds to ages 5-19. The last bin only contains one measurement of survival and should be effectively considered noise. After that there's no major differences in survival rate outside of an outlier in bin 11, but there's no logical explanation for this I can think of. Based on this info let's engineer a new three level categorical feature based on Age, the levels will be `Toddler` for ages 0-4, `Child` for ages 5-18, and Adult for ages 18+.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "2b3a532c5c8e95b1e3e3f6fc534dbf3306d04922", "_cell_guid": "dfebd5ae-6bac-4c2b-a156-b73947fdf403"}, "execution_count": null}, {"source": "fr_titanic$AgeGroup = sapply(fr_titanic$Age, function(age) {\n    if (age < 5) {\n        return (1)\n    } else if (age >= 5 && age < 18) {\n        return (2)\n    } else {\n        return (3)\n    }\n})\n\ntable(as.factor(fr_titanic$AgeGroup))", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "bfe231b5670f8e1b841561df60ae1b2590805848", "_cell_guid": "00fbf301-2e75-4500-a47a-78a13c82157a"}, "execution_count": 1}, {"source": "I think this should do in terms of feature engineering for now.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "27b3a624101d6e067e3a8f96ac8b196789cb76ae", "_cell_guid": "10698e72-ebab-461c-92fc-eead14154424"}, "execution_count": null}, {"source": "Predictions\n======\n\nWe'll build both a `Support Vector Classifier` and a `Random Forest` model in this section, compare them, and choose the one that works best.\n\nSplit Train and Test Set\n-----------------------\n\nFirst we split our dataframe back into the original train and test sets. Also clean up the data and remove the now unnecessary `Name`, `Ticket`, `Cabin` and `Set` variables as well as the `Survived` variable for the test set.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "58d3f9cc5cab327e45490090e7d1b175f5a7f697", "_cell_guid": "19771177-fc49-4d48-b039-e823a2a85c91"}, "execution_count": null}, {"source": "fr_train = fr_titanic[which(fr_titanic$Set == 'train'),]\nfr_test = fr_titanic[which(fr_titanic$Set == 'test'),]\n\nfr_train = subset(fr_train, select=-c(Name, Ticket, Set, Cabin))\nfr_test = subset(fr_test, select=-c(Name, Ticket, Set, Cabin, Survived))\n\nhead(fr_train)\nstr(fr_train)\nstr(fr_test)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "053350cbe42d34f2b900a5ec01348d6ea45292b0", "_cell_guid": "807af696-562c-41ce-b9ce-3d7d7c0200d5"}, "execution_count": 1}, {"source": "Support Vector Classifier\n-------------------------", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "dfa1f4d9f98d51e20213da3d1b981d16c940ad40", "_cell_guid": "cdee7eb7-234e-439c-aa32-8cc671143533"}, "execution_count": null}, {"source": "library(e1071)\n\nset.seed(7)\n\ntuned = tune(svm, Survived ~ ., data=fr_train, kernel=\"linear\", scale=TRUE, \n             ranges=list(cost=seq(0.3, 0.6, length=20)))\n\nsummary(tuned)\nsvm.fit = tuned$best.model", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "5abed0ecc88a87b6013d6f7f112254ef6d57e3d6", "_cell_guid": "5abd26b2-aacd-473a-bd3b-6b5aeab92cad"}, "execution_count": 1}, {"source": "Random Forest\n------------", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "dd923f4d2c45a69c4e48b6e7a5dd2a365028ae43", "_cell_guid": "21729e54-9d00-4453-9a3e-c73085856280"}, "execution_count": null}, {"source": "library(randomForest)\n\nset.seed(7)\nrf.fit = randomForest(Survived ~ ., data=fr_train)\nsummary(rf.fit$err.rate)\n\n# Thanks to Megan Risdal's excellent Titanic kernel for this little error rate graph\nplot(rf.fit, ylim=c(0,0.36))\nlegend('top', colnames(rf.fit$err.rate), col=1:3, fill=1:3, bty=\"n\")", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "67688780d9440b6648be1896c71b554ff336e10b", "_cell_guid": "fa8b1560-f7a5-4255-a3ed-d577d75171c1"}, "execution_count": 1}, {"source": "The first thing to notice here is how much better we are at predicting death than survival. Remember the start of our dataset where we guessed we'd be better at predicting who died than who survived, this seems to have taken effect but in reality this is also simply a consequence of how the Random Forest model works. It'll always perform much better on the bigger class.\n\nThe random forest model also slightly outperforms our support vector classifier, which had an error rate of 17.6% as estimated by the 10-fold cross validation. A convenient feature present in the randomForest object is the ability to plot importance measures. Handy as we can see if our feature engineering actually helped us.", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "c6d9f4be868d40055998402309d22ab11faa701b", "_cell_guid": "af4a34a8-a042-4cf4-85e1-dc6d1f5ce0ea"}, "execution_count": null}, {"source": "varImpPlot(rf.fit)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "f4f512a2c5cee41cfda063c56570bbd8aa5f45d2", "_cell_guid": "9c4fe071-d725-4799-aa47-fe246f6195e8"}, "execution_count": 1}, {"source": "Unfortunately it looks like our inGroup and AgeGroup weren't very successful features, Title on the other hand did extremely well!", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "e8fa2aae9e9cb4507a3135f983ff7f4ae8fd6b25", "_cell_guid": "0ecc7514-6e79-4cbb-b822-6aa03a03a7bc"}, "execution_count": null}, {"source": "Making our Prediction File\n------------------------", "outputs": [], "cell_type": "markdown", "metadata": {"_uuid": "4e2e4dfac6de4b5f533229a6a4e5b89d30c2c135", "_cell_guid": "d5fb5ceb-c629-4ec1-827d-109286e3813f"}, "execution_count": null}, {"source": "rf.preds = predict(rf.fit, fr_test)\nrf.submission = data.frame(PassengerId=names(rf.preds), Survived=rf.preds)\nwrite.csv(rf.submission, file=\"rf_submission.csv\", row.names=FALSE)\n\nsvm.preds = predict(svm.fit, fr_test)\nsvm.submission = data.frame(PassengerId=names(svm.preds), Survived=svm.preds)\nwrite.csv(svm.submission, file=\"svm_submission.csv\", row.names=FALSE)", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": true, "trusted": false, "_uuid": "91dcb41bdfa2fea5f98e0ebf25954dcf619b8b70", "_cell_guid": "feb15285-8483-43b0-86ee-5838311c25cb"}, "execution_count": 1}], "metadata": {"language_info": {"pygments_lexer": "r", "version": "3.4.1", "codemirror_mode": "r", "file_extension": ".r", "mimetype": "text/x-r-source", "name": "R"}, "kernelspec": {"display_name": "R", "language": "R", "name": "ir"}}}