import time
import multiprocessing
import pickle
import pandas as pd
import numpy as np
import rpy2
import rpy2.robjects as robjects
from rpy2.robjects import pandas2ri
pandas2ri.activate()

import sys
sys.path.append("../")
from generate import generate_args

NUM_WORKERS = 4
PICKLE_PATH = '/Volumes/TarDisk/snippets/'
RSNIPS_PATH = "rsnips.csv"

flatten = lambda l: [item for sublist in l for item in sublist]

generated_args = generate_args(10, lang="r")

class DataframeStore:
    """Just a class to store a dict of <snippet, output> so it can be pickled"""
    pairs = {}
    def __init__(self, pairs):
        self.pairs = pairs
    def get_output(self):
       return self.pairs
    
def eval_expr(df, expr):
    """
    Evals an R expression given a dataframe.
    Currently, this does not factor in args for expr
    """
    try:
        robjects.globalenv['mslacc'] = df
        robjects.r(f"""out <- {expr}""")
        # print('expr', expr)
        # when we retrieve the dataframe from out
        output = robjects.globalenv['out']
        if type(output) == rpy2.rinterface.NULLType:
            output = robjects.globalenv['mslacc']
        robjects.r("rm(list = ls())")
        # print('type', type(output))
        return expr, output
    except Exception as e:
        # print(e)
        return e
    
def execute_statement(snip):
    test_results = []
    for i, arg in enumerate(generated_args):
        result = eval_expr(arg, snip)
        if type(result) == tuple:
            test_results.append(result[1])
        else:
            err = str(result)
            # quit early when err contains one of these strings
            if "Error in" in err or "cannot open" in err:
                return snip, ["ERROR: "+err]
            test_results.append("ERROR: "+err)
    return snip, test_results
    
def execute_statements():
    """Execute R snippets with random dataframes"""
    # Read python snippets generated by filer.py
    snips = pd.read_csv(RSNIPS_PATH)
    snippets = flatten(snips.values)
    # Eval expressions and collect successful ones paired with output: (expr, output)
    start_time = time.time()
    with multiprocessing.Pool(processes=NUM_WORKERS) as pool:
        results = pool.map_async(execute_statement, snippets)
        results.wait()
        result = dict(results.get())
    end_time = time.time()
    print(f"Total snips: {len(result)}")
    print(f"Time taken: {round((end_time - start_time), 2)} secs")
    return result

def print_full(x):
    try:
        pd.set_option('display.max_rows', len(x))
        print(x)
        pd.reset_option('display.max_rows')
    except:
        pass

if __name__ == '__main__':
    executions = execute_statements()
    df_store = DataframeStore(executions)
    pickle.dump(df_store, open(PICKLE_PATH+"r_dfs.pkl", "wb"))



