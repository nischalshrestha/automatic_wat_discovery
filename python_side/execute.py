
import time
import multiprocessing
import pickle
import pandas as pd
import sys
sys.path.append("../")
from generate import generate_args, generate_simple_arg

NUM_WORKERS=4
PY_PICKLE_PATH = '/Volumes/TarDisk/snippets/py_dfs.pkl'
PYSNIPS_PATH = 'pysnips.csv'
generated_args = generate_args(1)
# TODO iteratively improve performance, testing a small amount of arg first
# generated_args = generate_simple_arg() 

flatten = lambda l: [item for sublist in l for item in sublist]

def print_full(x):
    pd.set_option('display.max_rows', len(x))
    print(x)
    pd.reset_option('display.max_rows')

def eval_expr(mslacc, expr):
    """
    Evals an expression given a dataframe given a dataframe and an expression.

    Note: The mslacc argument will be available to the Python `eval` when executing
    the expr.

    Currently, this does not factor in args for expr
    """
    code_str = f"out = {expr}"
    try:
        code_obj = compile(code_str, '', 'single')
        eval(code_obj)
        output = locals()['out']
        # If the output is None then grab the mslacc (for now)
        if output is None:
            output = locals()['mslacc']
        return expr, output
        # print('out', out)
    except Exception as e:
        # print(e)
        return e

def execute_statement(snip):
    """
    Given a Python snippet (one-liner), this executes it against the generated
    argument which are lists of different dataframes.
    """
    test_results = []
    for i, arg in enumerate(generated_args):
        result = eval_expr(arg, snip)
        if type(result) == tuple:
            # For now just accept a snippetsfor which the output is a Dataframe
            # TODO make this more generic using a variable for the type we include
            if type(result[1]) == pd.DataFrame:
                test_results.append(result[1])
            else:
                return None
        else:
            # err = str(result)
            # test_results.append("ERROR: "+err)
            return None
    rtn = {'expr': snip, 'test_results': test_results}
    return rtn

class DataframeStore:
    """Just a class to store a dict of <snippet, output> so it can be pickled"""
    pairs = {}
    def __init__(self, pairs):
        self.pairs = pairs
    def get_output(self):
       return self.pairs

def execute_statements():
    """Execute python snippets with random dataframes"""
    # Read python snippets generated by filer.py
    snips = pd.read_csv(PYSNIPS_PATH)
    snippets = flatten(snips.values)
    # Eval expressions and collect successful ones paired with output: (expr, output)
    start_time = time.time()
    with multiprocessing.Pool(processes=NUM_WORKERS) as pool:
        results = pool.map_async(execute_statement, snippets, chunksize=len(snippets)//4)
        results.wait()
        result = results.get()
    end_time = time.time()
    filtered = list(filter(None, result))
    print(f"Time taken: {round((end_time - start_time), 2)} secs")
    # For ~6.6K snippets:
    # Time taken: 1.05 secs
    return filtered

def test_pyexec():
    # Save results
    executions = execute_statements()
    # print(len(executions))
    df_store = DataframeStore(executions)
    pickle.dump(df_store, open(PY_PICKLE_PATH, "wb"))

if __name__ == '__main__':
    # TODO add optional argument for types of outputs we want to store the executions of
    # TODO accept argument for how many input arguements to use and max row/col
    test_pyexec()
