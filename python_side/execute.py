
import time
import multiprocessing
import pickle
import pandas as pd
import sys
sys.path.append("../")
from generate import generate_args, generate_simple_arg

NUM_WORKERS=4
PICKLE_PATH = '/Volumes/TarDisk/snippets/'
PYSNIPS_PATH = 'pysnips.csv'
# generated_args = generate_args(1)
generated_args = generate_simple_arg()

flatten = lambda l: [item for sublist in l for item in sublist]

def eval_expr(mslacc, expr):
    """
    Evals an expression given a dataframe.
    Currently, this does not factor in args for expr
    """
    code_str = f"out = {expr}"
    try:
        code_obj = compile(code_str, '', 'single')
        eval(code_obj)
        output = locals()['out']
        # If the output is None then grab the mslacc (for now)
        if output is None:
            output = locals()['mslacc']
        return expr, output
        # print('out', out)
    except Exception as e:
        # print(e)
        return e

def print_full(x):
    pd.set_option('display.max_rows', len(x))
    print(x)
    pd.reset_option('display.max_rows')

class DataframeStore:
    """Just a class to store a dict of <snippet, output> so it can be pickled"""
    pairs = {}
    def __init__(self, pairs):
        self.pairs = pairs
    def get_output(self):
       return self.pairs
    
def execute_statement(snip):
    # TODO change the return value to be a dict that has keys: expr, outputs
    test_results = []
    for i, arg in enumerate(generated_args):
        result = eval_expr(arg, snip)
        if type(result) == tuple:
            # if type(result[1]) == pd.DataFrame:
            test_results.append(result[1])
        else:
            err = str(result)
            # quit early if any one of these are in error message; likely all
            # subsequent tests will fail for the same reason.
            if "not defined" in str(result) \
                or "not contained" in err \
                or "no attribute" in err \
                or "does not exist" in err: 
                return snip, ["ERROR: "+str(result)]
            test_results.append("ERROR: "+err)
    # return (snip, test_results) if len(test_results) == len(generated_args) else None
    return snip, test_results
    
def execute_statements():
    """Execute python snippets with random dataframes"""
    # Read python snippets generated by filer.py
    snips = pd.read_csv(PYSNIPS_PATH)
    snippets = flatten(snips.values)
    # snippets = [snippets[snippets.index("mslacc=mslacc.drop([column_name],axis=1)")]]
    # print(snippets)
    # Eval expressions and collect successful ones paired with output: (expr, output)
    start_time = time.time()
    with multiprocessing.Pool(processes=NUM_WORKERS) as pool:
        results = pool.map_async(execute_statement, snippets)
        results.wait()
        result = dict(results.get())
        # print(type(result))
    end_time = time.time()
    # print('before', len(result))
    # filtered = list(filter(None, result))
    # print('after', len(filtered))
    # result = dict(list(filtered)) # just in case
    print(f"Time taken: {round((end_time - start_time), 2)} secs")
    return result

def test_pyexec():
    import sys
    # Save results
    executions = execute_statements()
    df_store = DataframeStore(executions)
    pickle.dump(df_store, open(PICKLE_PATH+"py_dfs.pkl", "wb"))
    # testing if we are able to load the pickle in memory: we're good for now
    # test_dict = pickle.load(open(PICKLE_PATH+"py_dfs.pkl", "rb")).pairs
    # print(test_dict["mslacc.drop(['Fare'],1,inplace=True)"][0])

if __name__ == '__main__':
    test_pyexec()
